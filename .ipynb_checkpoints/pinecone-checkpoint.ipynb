{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bbc91f-e276-46da-88fa-dfbdb9d10dc5",
   "metadata": {},
   "source": [
    "# 파인콘\n",
    "## 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5690a9ca-2f67-48d5-95b4-0248e5cb621a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| label: misinfo-setup\n",
    "# !pip install pinecone-client\n",
    "import dotenv\n",
    "import os\n",
    "import pinecone\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    environment=os.getenv(\"PINECONE_API_ENV\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978b10e-ed89-4e06-a9f7-0bc78fa2c612",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b00e56fd-a63c-41b6-b7d3-48eaa6cc89c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['helloworld-index']: IndexDescription(name='helloworld-index', metric='cosine', replicas=1, dimension=4.0, shards=1, pods=1, pod_type='p1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n"
     ]
    }
   ],
   "source": [
    "#| label: misinfo-index\n",
    "# pinecone.create_index(\"helloworld-index\", dimension=1024)\n",
    "active_indexes = pinecone.list_indexes()\n",
    "index_description = pinecone.describe_index(\"helloworld-index\")\n",
    "print(f'{active_indexes}: {index_description}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c0f9a-e976-44de-803d-6123bcabb756",
   "metadata": {},
   "source": [
    "## 데이터 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "def19a09-c7e3-4550-8d9a-8a953d72e959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| label: misinfo-insert\n",
    "index = pinecone.Index(\"helloworld-index\")\n",
    "\n",
    "upsert_response = index.upsert(\n",
    "    vectors=[\n",
    "        (\n",
    "         \"vec1\",                # Vector ID \n",
    "         [0.1, 0.2, 0.3, 0.4],  # Dense vector values\n",
    "         {\"genre\": \"drama\"}     # Vector metadata\n",
    "        ),\n",
    "        (\n",
    "         \"vec2\", \n",
    "         [0.2, 0.3, 0.4, 0.5], \n",
    "         {\"genre\": \"action\"}\n",
    "        )\n",
    "    ],\n",
    "    namespace=\"helloworld-namespace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d3820-5e8b-4c35-96cf-46e93f8b714c",
   "metadata": {},
   "source": [
    "## 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de437f5b-e067-4565-8279-984ade6f9c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.3, 0.4, 0.5]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: misinfo-fetch\n",
    "fetch_response = index.fetch(ids=[\"vec1\", \"vec2\"], namespace=\"helloworld-namespace\")\n",
    "fetch_response['vectors']['vec2']['values']\n",
    "# print(fetch_response['values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff83070-7fc7-4367-ab77-929b3a22fc9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 오정보 미트업\n",
    "## 텍스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7676d1f7-ff12-46a6-8f67-b54ca20d1987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I \n"
     ]
    }
   ],
   "source": [
    "#| label: misinfo-txt\n",
    "with open('../data/LibriSpeech/misinfo_chatGPT.txt', 'r') as f:\n",
    "    contents = f.read()\n",
    "print(contents[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509bd08-18d3-44c4-b95d-808e982c6466",
   "metadata": {},
   "source": [
    "## 토큰수\n",
    "\n",
    "https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "\n",
    "### 정규표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d98f048f-55df-45f7-8870-9ea4b2a8658e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규표현식 추정토큰수: 7974\n"
     ]
    }
   ],
   "source": [
    "#| label: misinfo-regex\n",
    "import re\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b|\\S', text)\n",
    "    return len(tokens)\n",
    "\n",
    "print(f\"정규표현식 추정토큰수: {estimate_tokens(contents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce2870-b5cd-40aa-a0bc-d77070dcc23c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `tiktoken`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2add284-2705-48f0-8922-834959ad6a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7852"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: misinfo-tiktoken\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"    \n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# num_tokens_from_string(\"Hello World!\",)\n",
    "num_tokens=num_tokens_from_string(contents)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "435e3c56-6907-4a8f-8a73-65a0979e3d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 7852\n",
      "\n",
      "MODEL        VERSION    COST\n",
      "-----------------------------------\n",
      "Ada\t\tv1\t$0.031408\n",
      "Babbage\t\tv1\t$0.03926\n",
      "Curie\t\tv1\t$0.15704\n",
      "Davinci\t\tv1\t$1.570400\n",
      "Ada\t\tv2\t$0.003140\n"
     ]
    }
   ],
   "source": [
    "#| label: misinfo-price\n",
    "# 출처: https://github.com/OpsConfig/OpenAI_Lab/blob/3a8c55160a6790fc790ef1c2c797d83c716eee94/Context-based-search-Version2.ipynb\n",
    "# Based on https://openai.com/api/pricing/ on 01/29/2023\n",
    "# If you were using this for approximating pricing with Azure OpenAI adjust the values below with: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "\n",
    "#MODEL\tUSAGE\n",
    "#Ada     v1\t$0.0040 / 1K tokens\n",
    "#Babbage v1\t$0.0050 / 1K tokens\n",
    "#Curie   v1\t$0.0200 / 1K tokens\n",
    "#Davinci v1\t$0.2000 / 1K tokens\n",
    "\n",
    "#MODEL\tUSAGE\n",
    "#Ada     v2\t$0.0004 / 1K tokens\n",
    "#This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. \n",
    "\n",
    "n_tokens_sum = num_tokens\n",
    "\n",
    "ada_v1_embeddings_cost = (n_tokens_sum/1000) *.0040\n",
    "babbage_v1_embeddings_cost = (n_tokens_sum/1000) *.0050\n",
    "curie_v1_embeddings_cost = (n_tokens_sum/1000) *.02\n",
    "davinci_v1_embeddings_cost = (n_tokens_sum/1000) *.2\n",
    "\n",
    "ada_v2_embeddings_cost = (n_tokens_sum/1000) *.0004\n",
    "\n",
    "print(\"Number of tokens: \" + str(n_tokens_sum) + \"\\n\")\n",
    "\n",
    "print(\"MODEL        VERSION    COST\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Ada\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(ada_v1_embeddings_cost))\n",
    "print(\"Babbage\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(babbage_v1_embeddings_cost))\n",
    "print(\"Curie\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(curie_v1_embeddings_cost))\n",
    "print(\"Davinci\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(davinci_v1_embeddings_cost))\n",
    "print(\"Ada\" + \"\\t\\t\" + \"v2\" + \"\\t$\" + '%.8s' %str(ada_v2_embeddings_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f408bcf-c4e3-448b-8f2a-a857b5bcbd55",
   "metadata": {},
   "source": [
    "## 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c464ee75-4913-465a-8037-526a3f2066a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| label: misinfo-embedding2\n",
    "import openai\n",
    "\n",
    "openai.api_key  = os.getenv('ENV_OPENAI_API_KEY')\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "contents_embedding = generate_embeddings(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eec208e9-8455-446b-ba84-dfa52a5c5710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f02b4-1bde-4a4e-8619-c28abf6e47e8",
   "metadata": {},
   "source": [
    "## 텍스트 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "323d85d2-d9ed-4160-be63-6ad65256668c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                   text\n",
      "0                                                                                                                                                         Well, thank you very much, Dr\n",
      "1                                                                                                                                                                                   Ahn\n",
      "2                                                                                                                          This is a real pleasure to be able to speak across the ocean\n",
      "3  I wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington, and that was a real pleasure\n",
      "4                                                                                                                                                                  So thank you so much\n"
     ]
    }
   ],
   "source": [
    "#| label: misinfo-pandas\n",
    "import pandas as pd\n",
    "\n",
    "sentences = contents.split(\". \")\n",
    "\n",
    "df = pd.DataFrame(sentences, columns=['text'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8eea67-ebf5-4975-9849-93fff956ef05",
   "metadata": {},
   "source": [
    "## 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8b117084-0a0c-471d-bc29-664c379bfbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| label: misinfo-embedding\n",
    "\n",
    "def get_embedding(text: str, model=\"text-embedding-ada-002\") -> list[float]:\n",
    "    return openai.Embedding.create(input=[text], model=model)[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# embedding = get_embedding(\"Your text goes here\", model=\"text-embedding-ada-002\")\n",
    "# print(len(embedding))\n",
    "# df['n_tokens'] = df[\"embedding\"].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "df[\"embedding\"] = df.text.apply(lambda x: get_embedding(x))\n",
    "df['vector_id'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "df.to_csv(\"misinfo-embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9852c-7b4b-4491-a65d-bca90e294f0a",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bb7f3bf5-d606-4cc9-8e1e-d7ef7ac39f20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misinfo']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a name for the new index\n",
    "index_name = 'misinfo'\n",
    "\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "    \n",
    "# Creates new index\n",
    "pinecone.create_index(name=index_name, dimension=len(df['embedding'][0]))\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Confirm our index was created\n",
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213737f-f9a8-4ccb-8372-0463edc96d4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 임베딩 DB 삽입\n",
    "\n",
    "https://towardsdatascience.com/crud-with-pinecone-ee6b6f8b54e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e72d427a-78c8-4678-b546-a6ee28f6502f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 368},\n",
       "                'misinfo_namespace': {'vector_count': 368}},\n",
       " 'total_vector_count': 736}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: misinfo-upsert\n",
    "import itertools\n",
    "\n",
    "def chunks(iterable, batch_size=100):\n",
    "    it = iter(iterable)\n",
    "    chunk = tuple(itertools.islice(it, batch_size))\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = tuple(itertools.islice(it, batch_size))\n",
    "\n",
    "for batch in chunks([(str(t), v) for t, v in zip(df.vector_id, df.embedding)]):\n",
    "    index.upsert(vectors=batch, namespace = \"misinfo_namespace\")\n",
    "\n",
    "index.describe_index_stats()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55afb23-9fa1-48a1-aa3b-e1a99bdf1d4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2d402e4b-2525-46b1-92a7-62fafa59f5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186    And we know that, you know, our surgeon general and other major leaders around the world have recognized the ways in which misinformation can affect our health, and they can affect the health of democracies\n",
       "130                                                                                                                                                                And bullshit is a part of the misinformation story\n",
       "16                                                                                                                We've studied misinformation during the pandemic and during elections and all sorts of other topics\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: misinfo-query\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "df_similarities = df.copy()\n",
    "\n",
    "def search_docs(df, user_query, top_n=3):\n",
    "    embedding = get_embedding(user_query, model=\"text-embedding-ada-002\")\n",
    "\n",
    "    df_similarities[\"similarities\"] = df.embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df_similarities.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    \n",
    "    return res\n",
    "\n",
    "question = \"why misinformation is dangerous?\\n\\n\"\n",
    "\n",
    "res = search_docs(df, question, top_n=3)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3326d-4a6f-49fe-b744-e2ed78877d1c",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f3ec6-c832-45b5-9944-d1f870030680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nomic import atlas\n",
    "import nomic\n",
    "\n",
    "nomic.login(os.getenv('NOMIC_API_KEY'))\n",
    "\n",
    "project = atlas.map_embeddings(\n",
    "    embeddings=df['embedding'].to_numpy()    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
