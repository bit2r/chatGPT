[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 1 백만 사용자 \n\n1 백만 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다.\n\n\n\n\n\n2 패러다임\n\n\nAndrej Karpathy Twit\n\n\n\nPre-Software: Special-purpose computer\nSoftware 1.0: Design the Algorithm\nSoftware 2.0: Design the Dataset\nSoftware 3.0: Design the Prompt\n\n3 Prompt engineering\n\nInstructions\nQuestion\nInput data\nExamples\n\nXavier (Xavi) Amatriain(January 5, 2023), “Prompt Engineering 101 - Introduction and resources”, Linkedin,Prompt Engineering - Learn how to use AI models with prompt engineering\n\n4 Genearative AI\n\n구분\n\ngeneration: text → image\nclassification: image → text\ntransformation: image → image (or text → text)\n\n\nAI 프로젝트\n\nGPT-3\nDalle.2 (text-to-image)\nMeta’s AI (text-to-video)\nGoogle AI (text-to-video)\nStable Diffusion (text-to-image)\nTesla AI (humanoid robot + self-driving)\n\n\ntext-to-X\n\ntext-to-gif (T2G)\ntext-to-3D (T2D)\ntext-to-text (T2T)\ntext-to-NFT (T2N)\ntext-to-code (T2C)\ntext-to-image (T2I)\ntext-to-audio (T2S)\ntext-to-video (T2V)\ntext-to-music (T2M)\ntext-to-motion (T2Mo)\n\n\n기타\n\nbrain-to-text (B2T)\nimage-to-text (I2T)\nspeech-to-text (S2T)\naudio-to-audio (A2A)\ntweet-to-image (Tt2I)\ntext-to-sound (T2S)\n\n\n\n\n\n\n\n\n5 데이터와 하드웨어\n\n\n\n\n\n6 Open Assistant\n\n\n\n\nLabel Asssistant Reply\n\n\n\n\nInitial Prompt\n\n\n\n\nLabel Prompter Reply\n\n\n\n\n\n\nReply as Assistant\n\n\n\n\nReply as User\n\n\n\n그림 1: Open Assistant"
  },
  {
    "objectID": "project.html#shiny-flex-dashboard---sales-forecasting-and-anomaly-detection",
    "href": "project.html#shiny-flex-dashboard---sales-forecasting-and-anomaly-detection",
    "title": "chatGPT 와 데이터 과학",
    "section": "Shiny Flex Dashboard - Sales forecasting and anomaly detection",
    "text": "Shiny Flex Dashboard - Sales forecasting and anomaly detection\n\n\nImage 2\n\n\n\nDescription 2"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\nCode1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html",
    "href": "posts/20230126-vscode/ide_vscode.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "R을 설치한다.\n\nlanguageserver 패키지를 설치한다.\n\n\ninstall.packages(\"languageserver\")\n\n\nVisual Studio Code 에서 R extension을 설치한다.\n\n.R 파일에 개발을 시작한다.\n\n\nR extension을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. VS Code 에 필수적인 R extension은 다음을 꼽을 수 있다. R extension을 설치하면 RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 편리하다.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Code를 실행하고 R Extension 설치\n\n\n\nR Extension 설치되면 코드 창 상단에 실행버튼이 활성화되고 Ctrl + Enter 혹은 Ctrl + Shift + Enter\n\n\nR 코드 실행화면"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "href": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "title": "Visual Studio Code",
    "section": "keybindings.json",
    "text": "keybindings.json\nkeybindings.json 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 등록시킨다. 자료출처: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: '이광춘'\\ndate: '2023-01-31'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#html-미리보기",
    "href": "posts/20230126-vscode/ide_vscode.html#html-미리보기",
    "title": "Visual Studio Code",
    "section": "HTML 미리보기",
    "text": "HTML 미리보기\n.Rmd 파일을  CTRL  +  Shift  +  k  단축키로 컴파일시키면 .html 파일이 생성된다. .html 파일 결과를 직접 실시간으로 확인하고자 한다면, 마이크로소프트가 개발한 Live Preview - VS Code Extension 플러그인을 설치한다."
  },
  {
    "objectID": "posts/20230127-ide/ide_war.html",
    "href": "posts/20230127-ide/ide_war.html",
    "title": "AI가 쏘아올린 작은 공",
    "section": "",
    "text": "데이터 과학 편집기\n데이터 과학 제품과 서비스 개발을 위해서 IDE(통합개발환경)을 두고 RStudio와 Jupyter 두 진영으로 나눠 치열한 경쟁을 펼쳤다. 각자 장점을 두고 범위를 확대하면서 진정한 데이터 과학 패자가 되고자 한편의 드라마를 펼쳤다.\n그 중심에는 RStudio와 아나콘다가 있으며 마치 현대차와 기아차처럼 동일한 자동차인데 세부 구성과 디자인에 차이만 있을 뿐 어느 것이 더 우월하고 좋다는 마케팅을 펼쳤다.\n\n\n\n마이크로소프트의 등장\n데이터 과학 편집기에 Visual Studio Code가 등장하면서 큰 변화가 일어나고 있다. 특히 인공지능 기능을 탑재한 Extension이 VS Code에 추가되면서 기존 RStudio와 쥬피터 IDE가 하던 기능을 넘어 새로운 지평을 열어가고 있다.\n그 중심에는 GitHub을 마이크로소프트가 인수하면서 새로 출시한 부조종사(Copilot)이 있고 조만간 CodeGPT도 도입되면 기존 RStudio와 Jupyter는 기존과 전혀 다른 위상을 가지게 될 것으로 보인다."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "chatGPT가 연 새로운 시대를 데이터 과학자와 함께 합니다."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "블로그",
    "section": "",
    "text": "AI가 쏘아올린 작은 공\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAI가 기존 데이터 과학 패러다임을 바꾸고 있습니다.\n\n\n\n\n\n\nJan 27, 2023\n\n\n이광춘\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\n비쥬얼 스튜디오 코드 IDE를 사용하여 개발 생산성을 높인다.\n\n\n\n\n\n\nJan 26, 2023\n\n\n이광춘\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chatGPT",
    "section": "",
    "text": "가자…\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nAI가 쏘아올린 작은 공\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAI가 기존 데이터 과학 패러다임을 바꾸고 있습니다.\n\n\n\n\n\n\n2023년 02월 12일\n\n\n이광춘\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\n비쥬얼 스튜디오 코드 IDE를 사용하여 개발 생산성을 높인다.\n\n\n\n\n\n\n2023년 01월 26일\n\n\n이광춘\n\n\n\n\n\n\n일치 없음"
  },
  {
    "objectID": "codex.html",
    "href": "codex.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 Codex\nLow-code and GPT-3: easier said than done with OpenAI Codex\n\n주석을 코드로 전환\n맥락을 보고 다음 코드를 자동 작성\n라이브러리, API 등 추천을 통해 새로운 지식 전달\n주석 자동 추가\n동일한 기능을 갖지면 효율성 좋은 코드로 변환\n\n2 이미지 생성\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nastronaut <- image_read(response$data$url)\nprint(astronaut)\n#> # A tibble: 1 × 7\n#>   format width height colorspace matte filesize density\n#>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n#> 1 PNG      256    256 sRGB       FALSE   197109 72x72\n\n\n\n\n\n\n\n\n3 예측모형\n\n코드penguins_classification_instruction <- \n  glue::glue(\"# R language\\n\",\n             \"Build sex classification machine learning model withe palmer penguin datatset\\n\",\n             \"Use palmer penguins data package for dataset\\n\",\n             \"Use tidymodels framework\\n\",\n             \"Use random forest model\\n\",\n             \"Include evaluation metrics including accruacy, precision, reall\")\n\nbuild_model <- create_completion(\n    model=\"code-davinci-002\",\n    prompt = penguins_classification_instruction,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\n\n\n코드\nparsed_code <- str_split(build_model$choices$text, \"\\n\")[[1]]\n\nwrite_lines(parsed_code, \"palmer_penguins.Rmd\")"
  },
  {
    "objectID": "palmer_penguins.html",
    "href": "palmer_penguins.html",
    "title": "chatGPT",
    "section": "",
    "text": "Install packages library  palmerpenguins  and tidymodels\n\n코드install.packages('palmerpenguins')\ninstall.packages('tidymodels')\n\n\n\nLoad libraries\n\n코드library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n코드library(palmerpenguins)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\n코드library(ggplot2)\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.8     ✔ purrr   0.3.5\n✔ tidyr   1.2.1     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ data.table::between() masks dplyr::between()\n✖ dplyr::filter()       masks stats::filter()\n✖ data.table::first()   masks dplyr::first()\n✖ dplyr::lag()          masks stats::lag()\n✖ data.table::last()    masks dplyr::last()\n✖ purrr::transpose()    masks data.table::transpose()\n\n코드library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.1     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.3     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ data.table::between() masks dplyr::between()\n✖ scales::discard()     masks purrr::discard()\n✖ dplyr::filter()       masks stats::filter()\n✖ data.table::first()   masks dplyr::first()\n✖ recipes::fixed()      masks stringr::fixed()\n✖ dplyr::lag()          masks stats::lag()\n✖ data.table::last()    masks dplyr::last()\n✖ yardstick::spec()     masks readr::spec()\n✖ recipes::step()       masks stats::step()\n✖ purrr::transpose()    masks data.table::transpose()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\n코드library(ggfortify)\n\nRegistered S3 method overwritten by 'ggfortify':\n  method          from   \n  autoplot.glmnet parsnip\n\n코드library(recipes)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\n코드library(profvis)\nlibrary(purrr)"
  },
  {
    "objectID": "palmer_penguins.html#load-data",
    "href": "palmer_penguins.html#load-data",
    "title": "chatGPT",
    "section": "Load data",
    "text": "Load data\n\n코드penguins <- penguins %>% \n  mutate_if(is.character, as.factor) %>% \n  drop_na()"
  },
  {
    "objectID": "palmer_penguins.html#eda",
    "href": "palmer_penguins.html#eda",
    "title": "chatGPT",
    "section": "EDA",
    "text": "EDA\nThe penguins dataset includes measurements of flow characteristics of the components. Only pterosaur data are considered in this project\n\n코드glimpse(penguins)\n\nRows: 333\nColumns: 7\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6…\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2…\n$ flipper_length_mm <int> 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18…\n$ body_mass_g       <int> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800…\n$ sex               <fct> male, female, female, female, male, female, male, fe…\n\n\n\n코드summary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :146   Biscoe   :163   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :123   1st Qu.:39.50   1st Qu.:15.60  \n Gentoo   :119   Torgersen: 47   Median :44.50   Median :17.30  \n                                 Mean   :43.99   Mean   :17.16  \n                                 3rd Qu.:48.60   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex     \n Min.   :172       Min.   :2700   female:165  \n 1st Qu.:190       1st Qu.:3550   male  :168  \n Median :197       Median :4050               \n Mean   :201       Mean   :4207               \n 3rd Qu.:213       3rd Qu.:4775               \n Max.   :231       Max.   :6300               \n\n\n\n코드penguins %>% select_if(Negate(is.factor)) %>% \n  cor() %>% \n  as.data.frame() %>% \n  rowid_to_column() %>% \n  pivot_longer(- rowid) %>% \n  arrange(desc(abs(value))) %>% \n  filter(value != 1)\n\n# A tibble: 12 × 3\n   rowid name               value\n   <int> <chr>              <dbl>\n 1     3 body_mass_g        0.873\n 2     4 flipper_length_mm  0.873\n 3     1 flipper_length_mm  0.653\n 4     3 bill_length_mm     0.653\n 5     1 body_mass_g        0.589\n 6     4 bill_length_mm     0.589\n 7     2 flipper_length_mm -0.578\n 8     3 bill_depth_mm     -0.578\n 9     2 body_mass_g       -0.472\n10     4 bill_depth_mm     -0.472\n11     1 bill_depth_mm     -0.229\n12     2 bill_length_mm    -0.229\n\n\n\n코드site_number <- 1:4\npdf('penguin_data.pdf')\npar(mfrow = c(2, 2))\nfor (i in site_number)\n{\n  penguins %>% \n    filter(site_number == i) %>% \n    ggplot(aes(x= species, y= flipper_length_mm, fill = species, color= species)) +\n    geom_boxplot() +\n    labs(x = 'Species', y = 'Flipper length (mm)', title = paste('Fvuwerfvczefcfzccfgct', i)) +\n    theme(axis.text = element_text(size = 8))\n}\ndev.off()\n\n\n\n코드ggviolin(penguins, x = species,\n        y = bill_length_mm+bill_depth_mm,\n        fill = species)\n\n\n\n코드glimpse(penguins$sex)\ntable(penguins$sex, useNA='ifany')"
  },
  {
    "objectID": "palmer_penguins.html#data-preparation",
    "href": "palmer_penguins.html#data-preparation",
    "title": "chatGPT",
    "section": "Data preparation",
    "text": "Data preparation\nSet for training and testing data\n\n코드set.seed(3223)\ntrain_test_split <- penguins %>% initial_split(prop = .7)\npenguin_train <- training(train_test_split)\npenguin_test <- testing(train_test_split)\nglimpse(penguin_train)\n\n\nCreate recipe\n\n코드softmaxkitchen <- recipe(sex ~ ., data = penguin_train) %>%\n step_other(antipodean_island, all_nominal())%>%\nstep_novel(all_nominal())%>%\nstep_other(bill_length_mm, one_of('median-virginica'))%>%\nstep_other(bill_depth_mm, one_of('median-virginica'))"
  },
  {
    "objectID": "palmer_penguins.html#visualize-recipe-steps",
    "href": "palmer_penguins.html#visualize-recipe-steps",
    "title": "chatGPT",
    "section": "Visualize recipe steps",
    "text": "Visualize recipe steps\n\n코드print(softmaxkitchen)\n\n\n\n코드prepped_penguin <- prep(softmaxkitchen, new_data = penguin_train)\nprepped_penguin %>% juice() %>% get_condition(pen_length_mm) -> penguin_ped_len\nprepped_penguin %>% juice() %>% get_condition(flipper_length_mm) -> penguin_flipper_len\npenguin_ped_len\npenguin_flipper_len\npenguin_sex\nprepped_penguin %>% bake(new_data = penguin_train) -> penguin_data\npenguin_data %>% juice() -> penguin_data_j\npenguin_data_j\npenguin_pen_len <- penguin_data_j %>"
  },
  {
    "objectID": "image2image.html",
    "href": "image2image.html",
    "title": "chatGPT",
    "section": "",
    "text": "역사상 가장 유명한 화풍을 chatGPT로부터 추천받아 이를 다양한 방식으로 시각화해보자. 무병장수(無病長壽)를 주제로 그림을 그려보자.\n\n무병장수 세상을 르네상스 화풍으로 그려줘 : ‘draw good health and long life world in a Renaissance style’\n\n\nrecommend the most famous painting style in history\n\n\n\n\n\n\ncompletion\n\n\n\n\n\nHere are some of the most famous painting styles in history:\n\nRenaissance: The Renaissance was a cultural movement in Italy from the 14th to the 17th century, characterized by a renewed interest in classical art, philosophy, and science. Renaissance paintings are known for their realism, balance, and harmony.\nBaroque: The Baroque style was popular in Europe from the late 16th to the early 18th century. Baroque paintings are known for their dramatic lighting, intense emotions, and dynamic compositions.\nImpressionism: Impressionism was a modernist movement in French painting in the late 19th century. Impressionist paintings are known for their loose brushstrokes, light-filled compositions, and focus on capturing fleeting moments.\nSurrealism: Surrealism was a cultural movement in the 20th century that aimed to liberate the imagination and explore the subconscious. Surrealist paintings are known for their dreamlike and fantastical imagery.\nAbstract Expressionism: Abstract Expressionism was a modernist movement in American painting in the mid-20th century. Abstract Expressionist paintings are known for their large canvases, gestural brushstrokes, and emphasis on the process of creation.\n\nThese are just a few examples of famous painting styles in history. There are many other styles that have influenced and shaped the course of art history.\n\n\n\nOpen AI - Create image API\n\n\n르네상스(Renaissance)\n바로크(Baroque)\n인상주의(Impressionism)\n초현실주의(Surrealism)\n추상표현주의(Abstract Expressionism)\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance <- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque <- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism <- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism <- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism <- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")"
  },
  {
    "objectID": "math.html",
    "href": "math.html",
    "title": "chatGPT",
    "section": "",
    "text": "함수 \\(f(x)=x^3+3 x^2+x-1\\) 에 대하여 \\(f^{\\prime}(1)\\) 의 값은?\n\n\n코드library(tidyverse)\nlibrary(openai)\n\nsolve_math_02 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. 함수 } f(x)=x^3+3 x^2+x-1 \\\\text { 에 대하여 } f^{\\\\prime}(1) \\\\text { 의 값은? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#> \n#> \n#> f'(1)의 값은 5입니다.\n#> f(x)는 x^3+3x^2+x-1이므로, 미분하면 f'(x) = 3x^2 + 6x + 1이 됩니다. 그리고 x = 1일 때, f'(1) = 3*1^2 + 6*1 + 1 = 5가 됩니다.\n\n\n\n\n등차수열 \\(\\left\\{a_n\\right\\}\\) 에 대하여 \\[\na_2=6, \\quad a_4+a_6=36\n\\] 일 때, \\(a_{10}\\) 의 값은?\n\n\n코드solve_math_03 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '등차수열 $\\left\\{a_n\\right\\}$ 에 대하여\n$$\na_2=6, \\quad a_4+a_6=36\n$$\n일 때, $a_{10}$ 의 값은?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\n등차수열의 정의에 따라 \\(a_n = a_1 + (n-1)d\\) 이므로, \\(a_1\\) 과 \\(d\\) 를 구해야 합니다.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]"
  },
  {
    "objectID": "rcoding.html",
    "href": "rcoding.html",
    "title": "chatGPT",
    "section": "",
    "text": "gpttools GitHub 저장소에서 바로 설치한다.\nrequire(remotes)\nremotes::install_github(\"JamesHWade/gpttools\")"
  },
  {
    "objectID": "rcoding.html#주석달기",
    "href": "rcoding.html#주석달기",
    "title": "chatGPT",
    "section": "\n4.1 주석달기",
    "text": "4.1 주석달기"
  },
  {
    "objectID": "rcoding.html#roxygen-추가",
    "href": "rcoding.html#roxygen-추가",
    "title": "chatGPT",
    "section": "\n4.2 Roxygen 추가",
    "text": "4.2 Roxygen 추가"
  },
  {
    "objectID": "rcoding.html#스크립트-함수",
    "href": "rcoding.html#스크립트-함수",
    "title": "chatGPT",
    "section": "\n4.3 스크립트 → 함수",
    "text": "4.3 스크립트 → 함수"
  },
  {
    "objectID": "rcoding.html#함수에-단위-테스트-추천",
    "href": "rcoding.html#함수에-단위-테스트-추천",
    "title": "chatGPT",
    "section": "\n4.4 함수에 단위 테스트 추천",
    "text": "4.4 함수에 단위 테스트 추천"
  },
  {
    "objectID": "interview.html",
    "href": "interview.html",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n기계학습 분류모형개발할 때 클래스 불균형(class imbalance) 문제를 어떻게 처리하나요?\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n기계학습모형에서 bias 와 variance trade-off에서 존재합니다. 어떤 기계학습 모형이 bias 와 variance를 줄이는데 효과적으로 알려져 있나요?\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n리스트와 데이터프레임 자료구조의 차이점에 대해서 말씀해 주세요.\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansing이 어떻게 다른지 설명하세요.\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n제품 설명 등 텍스트 필드 칼럼이 있습니다. 기계학습 알고리즘 분류나 예측 모형에 적용시킬 수 있는 방법을 설명해주세요."
  },
  {
    "objectID": "interview.html#visualization",
    "href": "interview.html#visualization",
    "title": "chatGPT",
    "section": "\n2.1 Visualization",
    "text": "2.1 Visualization\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\nData Analytics에서 시각화는 매우 중요합니다. 어떻게 가르칠것인지 커러큘럼, 교수방법, 프로젝트 진행방법, 평가방법에 대해서 말씀해주세요. (5분)"
  },
  {
    "objectID": "interview.html#eda",
    "href": "interview.html#eda",
    "title": "chatGPT",
    "section": "\n2.2 EDA",
    "text": "2.2 EDA\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n탐색적 데이터 분석(EDA)가 훌륭한 기계학습 알고리즘 개발과 함께 매우 중요합니다. 어떻게 가르칠것인지 커러큘럼, 교수방법, 프로젝트 진행방법, 평가방법에 대해서 말씀해주세요. (5분)"
  },
  {
    "objectID": "hf.html",
    "href": "hf.html",
    "title": "chatGPT",
    "section": "",
    "text": "파이썬을 계속 사용하다보니 무조건 가상환경을 사용해야 한다는 걸 절실히 느끼게 된다. 시간이 지나면 어떤 패키지들을 설치했었는지 확인이 되지 않고 어떤 것이 문제가 되어 잘 돌던 코드가 제대로 실행되지 않는지 파악이 힘드는 지경에 이르게 된다.\n파이썬3에서 venv, virtualenv 두가지 가상환경 팩키지가 제공되는데 선택을 해야한다. 결론은 파이썬3에서 venv가 지원되니 별도 패키지 설치없이 venv로 가는 것이 좋다.\n\npython3 -m venv <가상환경 명칭>\nsource <가상환경 명칭>/bin/activate\npip install -U pip\npip install pandas\npip freeze > requirements.txt\n\n가상환경 생성부터 주요한 가상환경 설정 방법을 순차적으로 파악해보자.\n\n\n생성\n활성화\n파이썬\npip 설치\n판다스 설치\nfreeze\nrequirements.txt\n가상환경 구조\ndeactivate\n\n\n\npy-3.10.9 tidyverse in ~/venv\n○ → python3 -m venv venv\n\n\npy-3.10.9 tidyverse in ~/venv\n○ → source venv/bin/activate\n\n## .\\venv\\Scripts\\activate ## 윈도우즈\n\n\n○ → which python\n/Users/tidyverse/venv/venv/bin/python\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install -U pip\nRequirement already satisfied: pip in ./venv/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Using cached pip-23.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install pandas\nCollecting pandas\n  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 5.7 MB/s eta 0:00:00\nCollecting pytz>=2020.1\n  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\nCollecting numpy>=1.20.3\n  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.8/19.8 MB 4.3 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.1\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting six>=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, six, numpy, python-dateutil, pandas\nSuccessfully installed numpy-1.24.2 pandas-1.5.3 python-dateutil-2.8.2 pytz-2022.7.1 six-1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze\nnumpy==1.24.2\npandas==1.5.3\npython-dateutil==2.8.2\npytz==2022.7.1\nsix==1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze > requirements.txt\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → tree -L 2\n.\n├── requirements.txt\n└── venv\n    ├── bin\n    ├── include\n    ├── lib\n    └── pyvenv.cfg\n\n4 directories, 2 files\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → deactivate\n\npy-3.10.9 tidyverse in ~/venv\n○ →"
  },
  {
    "objectID": "hf.html#환경-설정",
    "href": "hf.html#환경-설정",
    "title": "chatGPT",
    "section": "환경 설정",
    "text": "환경 설정\n파이썬 가상환경을 준비하고 transformers 및 연관 패키지를 설치한다.\n\n코드library(reticulate)\n\nuse_python(\"~/venv/venv/bin/python\")\nreticulate::py_config()\nreticulate::py_available()\n\nreticulate::py_install(\"transformers\", pip = TRUE)\nreticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)"
  },
  {
    "objectID": "hf.html#감정-분류",
    "href": "hf.html#감정-분류",
    "title": "chatGPT",
    "section": "\n3.1 감정 분류",
    "text": "3.1 감정 분류\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n코드library(reticulate)\nlibrary(tidyverse)\n\nuse_python(\"~/venv/venv/bin/python\")\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf.html#ner",
    "href": "hf.html#ner",
    "title": "chatGPT",
    "section": "\n3.2 NER",
    "text": "3.2 NER\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n코드# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf.html#질의응답",
    "href": "hf.html#질의응답",
    "title": "chatGPT",
    "section": "\n3.3 질의응답",
    "text": "3.3 질의응답\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n코드# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf.html#요약",
    "href": "hf.html#요약",
    "title": "chatGPT",
    "section": "\n3.4 요약",
    "text": "3.4 요약\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n코드summarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf.html#번역",
    "href": "hf.html#번역",
    "title": "chatGPT",
    "section": "\n3.5 번역",
    "text": "3.5 번역\nLanguage Technology Research Group at the University of Helsinki 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n코드# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\""
  },
  {
    "objectID": "hf.html#텍스트-생성",
    "href": "hf.html#텍스트-생성",
    "title": "chatGPT",
    "section": "\n3.6 텍스트 생성",
    "text": "3.6 텍스트 생성\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가 반응을 자동생성시켜 답신을 작성할 수 있다.\n\n코드generator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. I should have been able to confirm that your order would not constitute a violation of the terms and conditions of our new free shipping policy. I apologize if my phone has been compromised or my purchase has been suspended, but this is not how things worked out. Thanks so much. Thanks again. Best,\n#> \n#> John."
  },
  {
    "objectID": "hf.html#참고문헌",
    "href": "hf.html#참고문헌",
    "title": "chatGPT",
    "section": "\n3.7 참고문헌",
    "text": "3.7 참고문헌\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "hf_windows.html",
    "href": "hf_windows.html",
    "title": "chatGPT",
    "section": "",
    "text": "reticulate, “Installing Python Packages”\n\n\n생성\n환경 확인\n사용시작\n\n\n\nreticulate 패키지 conda_create() 함수로 새로운 환경을 생성한다.\n\n코드library(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n\n\n\n\nreticulate::py_available() 명령어로 파이썬 환경을 활용가능한지 확인하고 reticulate::py_config() 상세한 위치를 파악한다.\n\n코드library(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n\n\n\n\nuse_python() 함수로 파이썬 위치를 특정하고 관련 패키지 설치를 시작한다. 준비된 파이썬 가상환경에 transformers 및 연관 패키지를 설치한다.\n\n코드\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)"
  },
  {
    "objectID": "hf_windows.html#감정-분류",
    "href": "hf_windows.html#감정-분류",
    "title": "chatGPT",
    "section": "\n2.1 감정 분류",
    "text": "2.1 감정 분류\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n코드library(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf_windows.html#ner",
    "href": "hf_windows.html#ner",
    "title": "chatGPT",
    "section": "\n2.2 NER",
    "text": "2.2 NER\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n코드# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf_windows.html#질의응답",
    "href": "hf_windows.html#질의응답",
    "title": "chatGPT",
    "section": "\n2.3 질의응답",
    "text": "2.3 질의응답\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n코드# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf_windows.html#요약",
    "href": "hf_windows.html#요약",
    "title": "chatGPT",
    "section": "\n2.4 요약",
    "text": "2.4 요약\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n코드summarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf_windows.html#번역",
    "href": "hf_windows.html#번역",
    "title": "chatGPT",
    "section": "\n2.5 번역",
    "text": "2.5 번역\nLanguage Technology Research Group at the University of Helsinki 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n코드# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\""
  },
  {
    "objectID": "hf_windows.html#텍스트-생성",
    "href": "hf_windows.html#텍스트-생성",
    "title": "chatGPT",
    "section": "\n2.6 텍스트 생성",
    "text": "2.6 텍스트 생성\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가 반응을 자동생성시켜 답신을 작성할 수 있다.\n\n코드generator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you"
  },
  {
    "objectID": "hf_windows.html#참고문헌",
    "href": "hf_windows.html#참고문헌",
    "title": "chatGPT",
    "section": "\n2.7 참고문헌",
    "text": "2.7 참고문헌\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  }
]