[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ê·¼ê°„ëª¨í˜• ê°œë°œì\n\n\n\n\n\n2 AI ì‘ìš©ì œí’ˆ ê°œë°œì\n\n\n\n\n\n3 AI ì œí’ˆ ì‚¬ìš©ì"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "chatGPTê°€ ì—° ìƒˆë¡œìš´ ì‹œëŒ€ë¥¼ ë°ì´í„° ê³¼í•™ìì™€ í•¨ê»˜ í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "ë¸”ë¡œê·¸",
    "section": "",
    "text": "AIê°€ ì˜ì•„ì˜¬ë¦° ì‘ì€ ê³µ\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAIê°€ ê¸°ì¡´ ë°ì´í„° ê³¼í•™ íŒ¨ëŸ¬ë‹¤ì„ì„ ë°”ê¾¸ê³  ìˆìŠµë‹ˆë‹¤.\n\n\n\n\n\n\n2023ë…„ 04ì›” 20ì¼\n\n\nì´ê´‘ì¶˜\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\në¹„ì¥¬ì–¼ ìŠ¤íŠœë””ì˜¤ ì½”ë“œ IDEë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë°œ ìƒì‚°ì„±ì„ ë†’ì¸ë‹¤.\n\n\n\n\n\n\n2023ë…„ 01ì›” 26ì¼\n\n\nì´ê´‘ì¶˜\n\n\n\n\n\n\nì¼ì¹˜ ì—†ìŒ"
  },
  {
    "objectID": "codex.html",
    "href": "codex.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 Codex\nLow-code and GPT-3: easier said than done with OpenAI Codex\n\nì£¼ì„ì„ ì½”ë“œë¡œ ì „í™˜\në§¥ë½ì„ ë³´ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ìë™ ì‘ì„±\në¼ì´ë¸ŒëŸ¬ë¦¬, API ë“± ì¶”ì²œì„ í†µí•´ ìƒˆë¡œìš´ ì§€ì‹ ì „ë‹¬\nì£¼ì„ ìë™ ì¶”ê°€\në™ì¼í•œ ê¸°ëŠ¥ì„ ê°–ì§€ë©´ íš¨ìœ¨ì„± ì¢‹ì€ ì½”ë“œë¡œ ë³€í™˜\n\n2 ì´ë¯¸ì§€ ìƒì„±\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nastronaut <- image_read(response$data$url)\nprint(astronaut)\n#> # A tibble: 1 Ã— 7\n#>   format width height colorspace matte filesize density\n#>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n#> 1 PNG      256    256 sRGB       FALSE   197109 72x72\n\n\n\n\n\n\n\n\n3 ì˜ˆì¸¡ëª¨í˜•\n\nì½”ë“œpenguins_classification_instruction <- \n  glue::glue(\"# R language\\n\",\n             \"Build sex classification machine learning model withe palmer penguin datatset\\n\",\n             \"Use palmer penguins data package for dataset\\n\",\n             \"Use tidymodels framework\\n\",\n             \"Use random forest model\\n\",\n             \"Include evaluation metrics including accruacy, precision, reall\")\n\nbuild_model <- create_completion(\n    model=\"code-davinci-002\",\n    prompt = penguins_classification_instruction,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\n\n\nì½”ë“œ\nparsed_code <- str_split(build_model$choices$text, \"\\n\")[[1]]\n\nwrite_lines(parsed_code, \"palmer_penguins.Rmd\")"
  },
  {
    "objectID": "deepL.html",
    "href": "deepL.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 deeplR íŒ¨í‚¤ì§€\ní•œêµ­ì—ì„œëŠ” ì„œë¹„ìŠ¤ê°€ ë˜ì§€ ì•Šì•„ APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”â€¦ ê·¼ë° ì¼ë³¸ì€ ã…ã…\n\nì½”ë“œlibrary(deeplr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "hf.html",
    "href": "hf.html",
    "title": "chatGPT",
    "section": "",
    "text": "íŒŒì´ì¬ì„ ê³„ì† ì‚¬ìš©í•˜ë‹¤ë³´ë‹ˆ ë¬´ì¡°ê±´ ê°€ìƒí™˜ê²½ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤ëŠ” ê±¸ ì ˆì‹¤íˆ ëŠë¼ê²Œ ëœë‹¤. ì‹œê°„ì´ ì§€ë‚˜ë©´ ì–´ë–¤ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í–ˆì—ˆëŠ”ì§€ í™•ì¸ì´ ë˜ì§€ ì•Šê³  ì–´ë–¤ ê²ƒì´ ë¬¸ì œê°€ ë˜ì–´ ì˜ ëŒë˜ ì½”ë“œê°€ ì œëŒ€ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ”ì§€ íŒŒì•…ì´ í˜ë“œëŠ” ì§€ê²½ì— ì´ë¥´ê²Œ ëœë‹¤.\níŒŒì´ì¬3ì—ì„œ venv, virtualenv ë‘ê°€ì§€ ê°€ìƒí™˜ê²½ íŒ©í‚¤ì§€ê°€ ì œê³µë˜ëŠ”ë° ì„ íƒì„ í•´ì•¼í•œë‹¤. ê²°ë¡ ì€ íŒŒì´ì¬3ì—ì„œ venvê°€ ì§€ì›ë˜ë‹ˆ ë³„ë„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ì—†ì´ venvë¡œ ê°€ëŠ” ê²ƒì´ ì¢‹ë‹¤.\n\npython3 -m venv &lt;ê°€ìƒí™˜ê²½ ëª…ì¹­&gt;\nsource &lt;ê°€ìƒí™˜ê²½ ëª…ì¹­&gt;/bin/activate\npip install -U pip\npip install pandas\npip freeze &gt; requirements.txt\n\nê°€ìƒí™˜ê²½ ìƒì„±ë¶€í„° ì£¼ìš”í•œ ê°€ìƒí™˜ê²½ ì„¤ì • ë°©ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ íŒŒì•…í•´ë³´ì.\n\n\nìƒì„±\ní™œì„±í™”\níŒŒì´ì¬\npip ì„¤ì¹˜\níŒë‹¤ìŠ¤ ì„¤ì¹˜\nfreeze\nrequirements.txt\nê°€ìƒí™˜ê²½ êµ¬ì¡°\ndeactivate\n\n\n\npy-3.10.9 tidyverse in ~/venv\nâ—‹ â†’ python3 -m venv venv\n\n\npy-3.10.9 tidyverse in ~/venv\nâ—‹ â†’ source venv/bin/activate\n\n## .\\venv\\Scripts\\activate ## ìœˆë„ìš°ì¦ˆ\n\n\nâ—‹ â†’ which python\n/Users/tidyverse/venv/venv/bin/python\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip install -U pip\nRequirement already satisfied: pip in ./venv/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Using cached pip-23.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip install pandas\nCollecting pandas\n  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.0/12.0 MB 5.7 MB/s eta 0:00:00\nCollecting pytz&gt;=2020.1\n  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\nCollecting numpy&gt;=1.20.3\n  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.8/19.8 MB 4.3 MB/s eta 0:00:00\nCollecting python-dateutil&gt;=2.8.1\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting six&gt;=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, six, numpy, python-dateutil, pandas\nSuccessfully installed numpy-1.24.2 pandas-1.5.3 python-dateutil-2.8.2 pytz-2022.7.1 six-1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip freeze\nnumpy==1.24.2\npandas==1.5.3\npython-dateutil==2.8.2\npytz==2022.7.1\nsix==1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip freeze &gt; requirements.txt\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ tree -L 2\n.\nâ”œâ”€â”€ requirements.txt\nâ””â”€â”€ venv\n    â”œâ”€â”€ bin\n    â”œâ”€â”€ include\n    â”œâ”€â”€ lib\n    â””â”€â”€ pyvenv.cfg\n\n4 directories, 2 files\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ deactivate\n\npy-3.10.9 tidyverse in ~/venv\nâ—‹ â†’"
  },
  {
    "objectID": "hf.html#í™˜ê²½-ì„¤ì •",
    "href": "hf.html#í™˜ê²½-ì„¤ì •",
    "title": "chatGPT",
    "section": "í™˜ê²½ ì„¤ì •",
    "text": "í™˜ê²½ ì„¤ì •\níŒŒì´ì¬ ê°€ìƒí™˜ê²½ì„ ì¤€ë¹„í•˜ê³  transformers ë° ì—°ê´€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\nuse_python(\"~/venv/venv/bin/python\")\nreticulate::py_config()\nreticulate::py_available()\n\nreticulate::py_install(\"transformers\", pip = TRUE)\nreticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)"
  },
  {
    "objectID": "hf.html#ê°ì •-ë¶„ë¥˜",
    "href": "hf.html#ê°ì •-ë¶„ë¥˜",
    "title": "chatGPT",
    "section": "\n3.1 ê°ì • ë¶„ë¥˜",
    "text": "3.1 ê°ì • ë¶„ë¥˜\nì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì.\n\nì½”ë“œlibrary(reticulate)\nlibrary(tidyverse)\n\nuse_python(\"~/venv/venv/bin/python\")\n\ntext &lt;- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing ğŸ¤— transformers into R session\ntransformers &lt;- reticulate::import(\"transformers\")\n\n# model_name &lt;- \"bert-base-uncased\"\n# model &lt;- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier &lt;- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs &lt;- classifier(text)\n\n# Convert predictions to tibble\noutputs %&gt;% \n  pluck(1) %&gt;% \n  as_tibble()"
  },
  {
    "objectID": "hf.html#ner",
    "href": "hf.html#ner",
    "title": "chatGPT",
    "section": "\n3.2 NER",
    "text": "3.2 NER\nê°œì²´ëª… ì¸ì‹ì€ í…ìŠ¤íŠ¸ ë‚´ë¶€ì— ì§€ëª…, ì¸ëª…, ì œí’ˆ ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n\nì½”ë“œ# Download model for ner task\nner_tagger &lt;- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs &lt;- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r &lt;- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %&gt;% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %&gt;% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))"
  },
  {
    "objectID": "hf.html#ì§ˆì˜ì‘ë‹µ",
    "href": "hf.html#ì§ˆì˜ì‘ë‹µ",
    "title": "chatGPT",
    "section": "\n3.3 ì§ˆì˜ì‘ë‹µ",
    "text": "3.3 ì§ˆì˜ì‘ë‹µ\ní…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì„ ë˜ì§€ê³  í•´ë‹¹ ëŒ€ë‹µì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.\n\nì½”ë“œ# Specify task\nreader &lt;- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion &lt;-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs &lt;- reader(question = question, context = text)\noutputs %&gt;% \n  as_tibble()"
  },
  {
    "objectID": "hf.html#ìš”ì•½",
    "href": "hf.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n3.4 ìš”ì•½",
    "text": "3.4 ìš”ì•½\ní…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ì´ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œsummarizer &lt;- transformers$pipeline(\"summarization\")\noutputs &lt;- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs"
  },
  {
    "objectID": "hf.html#ë²ˆì—­",
    "href": "hf.html#ë²ˆì—­",
    "title": "chatGPT",
    "section": "\n3.5 ë²ˆì—­",
    "text": "3.5 ë²ˆì—­\nLanguage Technology Research Group at the University of Helsinki ì—ì„œ ì‚¬ì „í•™ìŠµëª¨í˜•ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë²ˆì—­ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œ# This requires python package sentencepiece\nsentencepiece &lt;- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator &lt;- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs &lt;- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs"
  },
  {
    "objectID": "hf.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "href": "hf.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "title": "chatGPT",
    "section": "\n3.6 í…ìŠ¤íŠ¸ ìƒì„±",
    "text": "3.6 í…ìŠ¤íŠ¸ ìƒì„±\nê³ ê°ì´ ë‚¨ê¸´ ê³ ê°ì˜ ì†Œë¦¬ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì›ì´ ì²˜ìŒì„ ì‹œì‘í•˜ë©´ ê¸°ê³„ê°€ ë°˜ì‘ì„ ìë™ìƒì„±ì‹œì¼œ ë‹µì‹ ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œgenerator &lt;- transformers$pipeline(\"text-generation\")\nresponse &lt;- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt &lt;- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs &lt;- generator(prompt, max_length = 200L)\n\noutputs %&gt;% \n  pluck(1, \"generated_text\") %&gt;% \n  cat()"
  },
  {
    "objectID": "hf.html#ì°¸ê³ ë¬¸í—Œ",
    "href": "hf.html#ì°¸ê³ ë¬¸í—Œ",
    "title": "chatGPT",
    "section": "\n3.7 ì°¸ê³ ë¬¸í—Œ",
    "text": "3.7 ì°¸ê³ ë¬¸í—Œ\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "hf_windows.html",
    "href": "hf_windows.html",
    "title": "chatGPT",
    "section": "",
    "text": "reticulate, â€œInstalling Python Packagesâ€\n\n\nìƒì„±\ní™˜ê²½ í™•ì¸\nì‚¬ìš©ì‹œì‘\n\n\n\nreticulate íŒ¨í‚¤ì§€ conda_create() í•¨ìˆ˜ë¡œ ìƒˆë¡œìš´ í™˜ê²½ì„ ìƒì„±í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n\n\n\n\nreticulate::py_available() ëª…ë ¹ì–´ë¡œ íŒŒì´ì¬ í™˜ê²½ì„ í™œìš©ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  reticulate::py_config() ìƒì„¸í•œ ìœ„ì¹˜ë¥¼ íŒŒì•…í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n\n\n\n\nuse_python() í•¨ìˆ˜ë¡œ íŒŒì´ì¬ ìœ„ì¹˜ë¥¼ íŠ¹ì •í•˜ê³  ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ì‹œì‘í•œë‹¤. ì¤€ë¹„ëœ íŒŒì´ì¬ ê°€ìƒí™˜ê²½ì— transformers ë° ì—°ê´€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œ\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)"
  },
  {
    "objectID": "hf_windows.html#ê°ì •-ë¶„ë¥˜",
    "href": "hf_windows.html#ê°ì •-ë¶„ë¥˜",
    "title": "chatGPT",
    "section": "\n2.1 ê°ì • ë¶„ë¥˜",
    "text": "2.1 ê°ì • ë¶„ë¥˜\nì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì.\n\nì½”ë“œlibrary(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing ğŸ¤— transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf_windows.html#ner",
    "href": "hf_windows.html#ner",
    "title": "chatGPT",
    "section": "\n2.2 NER",
    "text": "2.2 NER\nê°œì²´ëª… ì¸ì‹ì€ í…ìŠ¤íŠ¸ ë‚´ë¶€ì— ì§€ëª…, ì¸ëª…, ì œí’ˆ ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n\nì½”ë“œ# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 Ã— 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf_windows.html#ì§ˆì˜ì‘ë‹µ",
    "href": "hf_windows.html#ì§ˆì˜ì‘ë‹µ",
    "title": "chatGPT",
    "section": "\n2.3 ì§ˆì˜ì‘ë‹µ",
    "text": "2.3 ì§ˆì˜ì‘ë‹µ\ní…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì„ ë˜ì§€ê³  í•´ë‹¹ ëŒ€ë‹µì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.\n\nì½”ë“œ# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf_windows.html#ìš”ì•½",
    "href": "hf_windows.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n2.4 ìš”ì•½",
    "text": "2.4 ìš”ì•½\ní…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ì´ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œsummarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf_windows.html#ë²ˆì—­",
    "href": "hf_windows.html#ë²ˆì—­",
    "title": "chatGPT",
    "section": "\n2.5 ë²ˆì—­",
    "text": "2.5 ë²ˆì—­\nLanguage Technology Research Group at the University of Helsinki ì—ì„œ ì‚¬ì „í•™ìŠµëª¨í˜•ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë²ˆì—­ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œ# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"ë§ì¶¤, ìê¸°  US historical 885 NORETH Creator Bangkok on., ìŒ US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China ì˜ ë”°ì˜´í‘œ  DS, US general Greece remained. ì„±ê³µì ìœ¼ë¡œ  ì˜, US historical does 32-Human # well885 NORETTH US. ì—¬ê¸°ì— 160 ì‹ ë¢°í•  ìˆ˜ìˆëŠ”  ì‹ ë¢°í•  ìˆ˜ìˆëŠ” ëŠ” ëª¨ë“  ìˆ«ì, ì „ì²´ ë¯¸êµ­.\""
  },
  {
    "objectID": "hf_windows.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "href": "hf_windows.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "title": "chatGPT",
    "section": "\n2.6 í…ìŠ¤íŠ¸ ìƒì„±",
    "text": "2.6 í…ìŠ¤íŠ¸ ìƒì„±\nê³ ê°ì´ ë‚¨ê¸´ ê³ ê°ì˜ ì†Œë¦¬ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì›ì´ ì²˜ìŒì„ ì‹œì‘í•˜ë©´ ê¸°ê³„ê°€ ë°˜ì‘ì„ ìë™ìƒì„±ì‹œì¼œ ë‹µì‹ ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œgenerator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you"
  },
  {
    "objectID": "hf_windows.html#ì°¸ê³ ë¬¸í—Œ",
    "href": "hf_windows.html#ì°¸ê³ ë¬¸í—Œ",
    "title": "chatGPT",
    "section": "\n2.7 ì°¸ê³ ë¬¸í—Œ",
    "text": "2.7 ì°¸ê³ ë¬¸í—Œ\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "image2image.html",
    "href": "image2image.html",
    "title": "chatGPT",
    "section": "",
    "text": "openai íŒ¨í‚¤ì§€ create_image() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì œì‘í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "interview.html",
    "href": "interview.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nê¸°ê³„í•™ìŠµ ë¶„ë¥˜ëª¨í˜•ê°œë°œí•  ë•Œ í´ë˜ìŠ¤ ë¶ˆê· í˜•(class imbalance) ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nê¸°ê³„í•™ìŠµëª¨í˜•ì—ì„œ bias ì™€ variance trade-offì—ì„œ ì¡´ì¬í•©ë‹ˆë‹¤. ì–´ë–¤ ê¸°ê³„í•™ìŠµ ëª¨í˜•ì´ bias ì™€ varianceë¥¼ ì¤„ì´ëŠ”ë° íš¨ê³¼ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‚˜ìš”?\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\në¦¬ìŠ¤íŠ¸ì™€ ë°ì´í„°í”„ë ˆì„ ìë£Œêµ¬ì¡°ì˜ ì°¨ì´ì ì— ëŒ€í•´ì„œ ë§ì”€í•´ ì£¼ì„¸ìš”.\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansingì´ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì„¤ëª…í•˜ì„¸ìš”.\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nì œí’ˆ ì„¤ëª… ë“± í…ìŠ¤íŠ¸ í•„ë“œ ì¹¼ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤. ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ë¶„ë¥˜ë‚˜ ì˜ˆì¸¡ ëª¨í˜•ì— ì ìš©ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
  },
  {
    "objectID": "interview.html#visualization",
    "href": "interview.html#visualization",
    "title": "chatGPT",
    "section": "\n2.1 Visualization",
    "text": "2.1 Visualization\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nData Analyticsì—ì„œ ì‹œê°í™”ëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–»ê²Œ ê°€ë¥´ì¹ ê²ƒì¸ì§€ ì»¤ëŸ¬í˜ëŸ¼, êµìˆ˜ë°©ë²•, í”„ë¡œì íŠ¸ ì§„í–‰ë°©ë²•, í‰ê°€ë°©ë²•ì— ëŒ€í•´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”. (5ë¶„)"
  },
  {
    "objectID": "interview.html#eda",
    "href": "interview.html#eda",
    "title": "chatGPT",
    "section": "\n2.2 EDA",
    "text": "2.2 EDA\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\níƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)ê°€ í›Œë¥­í•œ ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê°œë°œê³¼ í•¨ê»˜ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–»ê²Œ ê°€ë¥´ì¹ ê²ƒì¸ì§€ ì»¤ëŸ¬í˜ëŸ¼, êµìˆ˜ë°©ë²•, í”„ë¡œì íŠ¸ ì§„í–‰ë°©ë²•, í‰ê°€ë°©ë²•ì— ëŒ€í•´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”. (5ë¶„)"
  },
  {
    "objectID": "koGPT.html",
    "href": "koGPT.html",
    "title": "chatGPT",
    "section": "",
    "text": "R íŒ¨í‚¤ì§€\n\nhuggingfaceR\ntext\n\n\në¸”ë¡œê·¸\n\nR, Reticulate, and Hugging Face Models\nHello Transformers from R\n\n\n\n\nreticulate ìµœì‹ ë²„ì „ì„ ì„¤ì¹˜í•˜ê³  ë‚˜ì„œ, minicondaë¥¼ ì„¤ì¹˜í•œë‹¤. ê¸°ì¡´ ì„¤ì¹˜ëœ ê²½ìš° install_miniconda(force = TRUE) ì¸ìë¥¼ ë„£ì–´ ì¬ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œremotes::install_github(\"rstudio/reticulate\")\nreticulate::install_miniconda(force = TRUE)\n\n\n\n\n\n\n\n\në…¸íŠ¸\n\n\n\nminiconda ì„¤ì¹˜ì— ì–´ë ¤ì›€ì´ ìƒê¸´ê²½ìš° rminicondaê°€ ëŒ€ì•ˆì´ ë  ìˆ˜ ìˆë‹¤.\n\nrminiconda\n\n\n\n\n\nì½”ë“œdevtools::install_github(\"farach/huggingfaceR\")\n\n\n\nhuggingfaceR README.md íŒŒì¼ì— ì‹¤ë¦° í—¬ë¡œì›”ë“œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨í˜•ì„ ëŒë ¤ë³´ì.\n\nì½”ë“œlibrary(huggingfaceR)\nlibrary(reticulate)\n\nuse_python(\"C:/Users/statkclee/AppData/Local/r-miniconda/envs/huggingfaceR/python.exe\")\n# hf_python_depends('transformers') # ë¹ ì§„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n\ndistilBERT <- hf_load_pipeline(\n  model_id = \"distilbert-base-uncased-finetuned-sst-2-english\", \n  task = \"text-classification\")\n\ndistilBERT(\"I like you. I love you\")\n#> [[1]]\n#> [[1]]$label\n#> [1] \"POSITIVE\"\n#> \n#> [[1]]$score\n#> [1] 0.9998739"
  },
  {
    "objectID": "koGPT.html#ì¸ê¸°-ëª¨í˜•",
    "href": "koGPT.html#ì¸ê¸°-ëª¨í˜•",
    "title": "chatGPT",
    "section": "\n2.1 ì¸ê¸° ëª¨í˜•",
    "text": "2.1 ì¸ê¸° ëª¨í˜•\në‹¤ìš´ë¡œë“œ íšŸìˆ˜ê°€ ë§ì€ hugginface ëª¨í˜•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\nì½”ë“œlibrary(reactable)\nmodels %>% \n  select(-private, -sha) %>% \n  reactable::reactable(\n    searchable = TRUE, minRows = 10,\n    columns = list(downloads = colDef(format = colFormat(separators  = TRUE)),\n                   model = colDef(align = \"center\"),\n                   task = colDef(align = \"center\")))"
  },
  {
    "objectID": "math.html",
    "href": "math.html",
    "title": "chatGPT",
    "section": "",
    "text": "GPT-4ì˜ êµ¬ì²´ì ì¸ ê¸°ëŠ¥ì´ë‚˜ ê°œì„  ì‚¬í•­ì€ ì•„ì§ ê³µê°œë˜ì§€ ì•Šì•˜ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ í›„ì† ëª¨ë¸ì€ ì´ì „ ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ê°œì„ ë˜ëŠ” ê²ƒì´ ëŒ€ë¶€ë¶„ì´ë‹¤. GPT-4ì˜ ì¶”ë¡ ëŠ¥ë ¥ì´ GPT-3.5ì™€ ë¹„êµí•˜ì—¬ ì–´ë–¤ ë¶€ë¶„ì´ ê°œì„ ë˜ì—ˆëŠ”ì§€ ë‹¤ìŒê³¼ ê°™ì´ ì˜ˆì¸¡í•´ë³¼ ìˆ˜ ìˆë‹¤:\níŠ¹íˆ, GPT-4ëŠ” ì¶”ë¡ ì—­ëŸ‰(Reasoning)ì´ ì´ì „ ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ í–¥ìƒëœ ê²ƒì´ í™•ì¸ëœë‹¤."
  },
  {
    "objectID": "middle_school.html#í•œê¸€ì§ˆë¬¸-ì¤€ë¹„",
    "href": "middle_school.html#í•œê¸€ì§ˆë¬¸-ì¤€ë¹„",
    "title": "chatGPT",
    "section": "\n2.1 í•œê¸€ì§ˆë¬¸ ì¤€ë¹„",
    "text": "2.1 í•œê¸€ì§ˆë¬¸ ì¤€ë¹„\n\nlibrary(tidyverse)\nlibrary(openai)\n\nkorean_question <- \"ì¤‘í•™êµì—ì„œ ìˆ˜í•™ì—ì„œ ë‚˜ì˜¤ëŠ” ì—°ë¦½ë°©ì •ì‹ì„ ì„¤ëª…í•´ì¤˜\"\nkorean_question\n#> [1] \"ì¤‘í•™êµì—ì„œ ìˆ˜í•™ì—ì„œ ë‚˜ì˜¤ëŠ” ì—°ë¦½ë°©ì •ì‹ì„ ì„¤ëª…í•´ì¤˜\""
  },
  {
    "objectID": "middle_school.html#ì§ˆë¬¸ë²ˆì—­",
    "href": "middle_school.html#ì§ˆë¬¸ë²ˆì—­",
    "title": "chatGPT",
    "section": "\n2.2 ì§ˆë¬¸ë²ˆì—­",
    "text": "2.2 ì§ˆë¬¸ë²ˆì—­\n\n\nkorean_question_input <- glue::glue(\"translate it into English: {korean_question}\")\n\nquestion_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = korean_question_input,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ntranslated_questions <- str_extract(question_model$choices$text, \"\\\\b[^\\\\W].+\\\\b\")\n\ntranslated_questions\n#> [1] \"Explain the system of linear equations that comes from middle school math\""
  },
  {
    "objectID": "middle_school.html#chatgpt-ì˜ë¬¸-ë‹µë³€",
    "href": "middle_school.html#chatgpt-ì˜ë¬¸-ë‹µë³€",
    "title": "chatGPT",
    "section": "\n2.3 chatGPT ì˜ë¬¸ ë‹µë³€",
    "text": "2.3 chatGPT ì˜ë¬¸ ë‹µë³€\n\n\nanswer_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = translated_questions,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nchatGPT_answer <- answer_model$choices$text\ncat(chatGPT_answer)\n#> \n#> \n#> A system of linear equations is a set of two or more linear equations that contains the same variables. The equations are usually referred to as simultaneous equations, as they are usually solved together.\n#> \n#> In the context of middle school math, a linear equation generally consists of two variables, and the equations are primarily used to solve problems involving rate, distance, and time. The general form of a linear equation is y=mx+b, where m is the slope of the line, x is the independent variable, and b is the y-intercept. The slope and y-intercept can be found by plotting the points that make up the equation on a graph. \n#> \n#> Once the slope and y-intercept have been determined, other linear equations can be written by substituting different values for the slope and y-intercept. For example, if the slope of a linear equation is m=5 and the y-intercept is b=3, then the equation can be written as y=5x+3. Different values can also be plugged into the equation to solve for either x or y.\n#> \n#> In a system of linear equations, two equations are combined to form one equation. By solving both equations simultaneously, a more general solution can be found. This process is usually done by using elimination, substitution, or graphing. Once the solution has been found, it can be used to answer questions about the relationships between the variables."
  },
  {
    "objectID": "middle_school.html#chatgpt-ë‹µë³€-ë²ˆì—­",
    "href": "middle_school.html#chatgpt-ë‹µë³€-ë²ˆì—­",
    "title": "chatGPT",
    "section": "\n2.4 chatGPT ë‹µë³€ ë²ˆì—­",
    "text": "2.4 chatGPT ë‹µë³€ ë²ˆì—­\n\n\nchatGPT_answer_request <- glue::glue(\"í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: {chatGPT_answer}\")\n\nreturn_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = chatGPT_answer_request,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(return_model$choices$text)\n#> \n#> \n#> íšŒê·€ë°©ì •ì‹ì€ ë™ì¼í•œ ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” ë‘ ê°œ ì´ìƒì˜ ì„ í˜•ë°©ì •ì‹ë“¤ì˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ ë°©ì •ì‹ë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ë™ì‹œ ë°©ì •ì‹ìœ¼ë¡œ ë¶ˆë¦¬ë©°, ê°™ì´ í’€ë¦´ ë•Œê°€ ë§ìŠµë‹ˆë‹¤.\n#> \n#> ì¤‘í•™êµ ìˆ˜í•™ì—ì„œì˜ ì„ í˜•ë°©ì •ì‹ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‘ ê°œì˜ ë³€ìˆ˜ë¥¼ ê°€ì§€ë©°, ì´ ë°©ì •ì‹ë“¤ì€ ë¹„ìœ¨ì´ë‚˜ ê±°ë¦¬, ì‹œê°„ ë“± ë¬¸ì œë¥¼ í’€ë•Œ ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì„ í˜•ë°©ì •ì‹ì˜ ì¼ë°˜ì ì¸ í˜•íƒœëŠ” y=mx+b ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ mì€ ì„ ì˜ ê¸°ìš¸ê¸°, xëŠ” ë…ë¦½ë³€ìˆ˜, bëŠ” yì ˆí¸ì…ë‹ˆë‹¤. ê¸°ìš¸ê¸°ì™€ yì ˆí¸ì€ ë°©ì •ì‹ì˜ ì ë“¤ì„ ê·¸ë˜í”„ì— ê·¸ë ¤ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n#> \n#> ê¸°ìš¸ê¸°ì™€ yì ˆí¸ì´ ê²°ì •ë˜ë©´ ë‹¤ë¥¸ ê°’ë“¤ë¡œ ì„ í˜•ë°©ì •ì‹ì„ ì‘ì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì„ í˜• ë°©ì •ì‹ì˜ ê¸°ìš¸ê¸°ê°€ m=5ì´ê³  yì ˆí¸ì´ b=3ì¸ ê²½ìš°, y=5x+3ìœ¼ë¡œ ë°©ì •ì‹ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë‹¤ë¥¸ ê°’ë“¤ì„ ë°©ì •ì‹ì— ëŒ€ì…í•˜ì—¬ xê°’ ë˜ëŠ” yê°’ì„ êµ¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n#> \n#> íšŒê·€ë°©ì •ì‹ ì‹œìŠ¤í…œë“¤ì€ ë‘ ê°œì˜ ë°©ì •ì‹ì„ í•˜ë‚˜ì˜ ë°©ì •ì‹ìœ¼ë¡œ ê²°í•©í•©ë‹ˆë‹¤. ë‘ ë°©ì •ì‹ì„ ë™ì‹œì— í’€ê²Œ ë˜ì–´ ìƒëŒ€ì ìœ¼ë¡œ ë” ì¼ë°˜ì ì¸ í•´ë‹µì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html",
    "href": "posts/20230126-vscode/ide_vscode.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "Rì„ ì„¤ì¹˜í•œë‹¤.\n\nlanguageserver íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\n\ninstall.packages(\"languageserver\")\n\n\nVisual Studio Code ì—ì„œ R extensionì„ ì„¤ì¹˜í•œë‹¤.\n\n.R íŒŒì¼ì— ê°œë°œì„ ì‹œì‘í•œë‹¤.\n\n\nR extensionì„ ì„¤ì¹˜í•˜ê²Œ ë˜ë©´ VS Codeì—ì„œ R ì½”ë“œ ê°œë°œì„ ì›í™œíˆ í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤. VS Code ì— í•„ìˆ˜ì ì¸ R extensionì€ ë‹¤ìŒì„ ê¼½ì„ ìˆ˜ ìˆë‹¤. R extensionì„ ì„¤ì¹˜í•˜ë©´ RStudioì—ì„œ ê¸°ë³¸ì„¤ì •ìœ¼ë¡œ ì§€ì •ëœ ë‹¨ì¶•í‚¤ë¥¼ ë³„ë„ ì„¤ì •ì—†ì´ ìë™ ì§€ì •ë˜ê¸° ë•Œë¬¸ì— í¸ë¦¬í•˜ë‹¤.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Codeë¥¼ ì‹¤í–‰í•˜ê³  R Extension ì„¤ì¹˜\n\n\n\nR Extension ì„¤ì¹˜ë˜ë©´ ì½”ë“œ ì°½ ìƒë‹¨ì— ì‹¤í–‰ë²„íŠ¼ì´ í™œì„±í™”ë˜ê³  Ctrl + Enter í˜¹ì€ Ctrl + Shift + Enter\n\n\nR ì½”ë“œ ì‹¤í–‰í™”ë©´"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "href": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "title": "Visual Studio Code",
    "section": "keybindings.json",
    "text": "keybindings.json\nkeybindings.json íŒŒì¼ì— R í˜¹ì€ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‚½ì…ì‹œí‚¬ ìˆ˜ ìˆëŠ” í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ë¥¼ ë“±ë¡ì‹œí‚¨ë‹¤. ìë£Œì¶œì²˜: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: 'ì´ê´‘ì¶˜'\\ndate: '2023-01-31'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#html-ë¯¸ë¦¬ë³´ê¸°",
    "href": "posts/20230126-vscode/ide_vscode.html#html-ë¯¸ë¦¬ë³´ê¸°",
    "title": "Visual Studio Code",
    "section": "HTML ë¯¸ë¦¬ë³´ê¸°",
    "text": "HTML ë¯¸ë¦¬ë³´ê¸°\n.Rmd íŒŒì¼ì„  CTRL  +  Shift  +  k  ë‹¨ì¶•í‚¤ë¡œ ì»´íŒŒì¼ì‹œí‚¤ë©´ .html íŒŒì¼ì´ ìƒì„±ëœë‹¤. .html íŒŒì¼ ê²°ê³¼ë¥¼ ì§ì ‘ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³ ì í•œë‹¤ë©´, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ê°œë°œí•œ Live Preview - VS Code Extension í”ŒëŸ¬ê·¸ì¸ì„ ì„¤ì¹˜í•œë‹¤."
  },
  {
    "objectID": "posts/20230127-ide/ide_war.html",
    "href": "posts/20230127-ide/ide_war.html",
    "title": "AIê°€ ì˜ì•„ì˜¬ë¦° ì‘ì€ ê³µ",
    "section": "",
    "text": "ë°ì´í„° ê³¼í•™ í¸ì§‘ê¸°\në°ì´í„° ê³¼í•™ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ ê°œë°œì„ ìœ„í•´ì„œ IDE(í†µí•©ê°œë°œí™˜ê²½)ì„ ë‘ê³  RStudioì™€ Jupyter ë‘ ì§„ì˜ìœ¼ë¡œ ë‚˜ëˆ  ì¹˜ì—´í•œ ê²½ìŸì„ í¼ì³¤ë‹¤. ê°ì ì¥ì ì„ ë‘ê³  ë²”ìœ„ë¥¼ í™•ëŒ€í•˜ë©´ì„œ ì§„ì •í•œ ë°ì´í„° ê³¼í•™ íŒ¨ìê°€ ë˜ê³ ì í•œí¸ì˜ ë“œë¼ë§ˆë¥¼ í¼ì³¤ë‹¤.\nê·¸ ì¤‘ì‹¬ì—ëŠ” RStudioì™€ ì•„ë‚˜ì½˜ë‹¤ê°€ ìˆìœ¼ë©° ë§ˆì¹˜ í˜„ëŒ€ì°¨ì™€ ê¸°ì•„ì°¨ì²˜ëŸ¼ ë™ì¼í•œ ìë™ì°¨ì¸ë° ì„¸ë¶€ êµ¬ì„±ê³¼ ë””ìì¸ì— ì°¨ì´ë§Œ ìˆì„ ë¿ ì–´ëŠ ê²ƒì´ ë” ìš°ì›”í•˜ê³  ì¢‹ë‹¤ëŠ” ë§ˆì¼€íŒ…ì„ í¼ì³¤ë‹¤.\n\n\n\në§ˆì´í¬ë¡œì†Œí”„íŠ¸ì˜ ë“±ì¥\në°ì´í„° ê³¼í•™ í¸ì§‘ê¸°ì— Visual Studio Codeê°€ ë“±ì¥í•˜ë©´ì„œ í° ë³€í™”ê°€ ì¼ì–´ë‚˜ê³  ìˆë‹¤. íŠ¹íˆ ì¸ê³µì§€ëŠ¥ ê¸°ëŠ¥ì„ íƒ‘ì¬í•œ Extensionì´ VS Codeì— ì¶”ê°€ë˜ë©´ì„œ ê¸°ì¡´ RStudioì™€ ì¥¬í”¼í„° IDEê°€ í•˜ë˜ ê¸°ëŠ¥ì„ ë„˜ì–´ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ì–´ê°€ê³  ìˆë‹¤.\nê·¸ ì¤‘ì‹¬ì—ëŠ” GitHubì„ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ì¸ìˆ˜í•˜ë©´ì„œ ìƒˆë¡œ ì¶œì‹œí•œ ë¶€ì¡°ì¢…ì‚¬(Copilot)ì´ ìˆê³  ì¡°ë§Œê°„ CodeGPTë„ ë„ì…ë˜ë©´ ê¸°ì¡´ RStudioì™€ JupyterëŠ” ê¸°ì¡´ê³¼ ì „í˜€ ë‹¤ë¥¸ ìœ„ìƒì„ ê°€ì§€ê²Œ ë  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ë°±ë§Œ ê°€ì…ìë¥¼ ê°€ì§ˆ ë•Œê¹Œì§€ ê±¸ë¦° ì†Œìš”ì‹œê°„ì„ ë³´ë©´ chatGPT ì˜ ì˜í–¥ë ¥ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "rcoding.html",
    "href": "rcoding.html",
    "title": "chatGPT",
    "section": "",
    "text": "Low-code and GPT-3: easier said than done with OpenAI Codex\nì½”ë±ìŠ¤(Codex)ëŠ” OpenAIì—ì„œ ê°œë°œí•œ íšê¸°ì ì¸ AI ê¸°ìˆ ë¡œ, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ì‘ë‹µí•˜ì—¬ ì‚¬ëŒê³¼ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì±…, ê¸°ì‚¬ ë° ê¸°íƒ€ í˜•íƒœì˜ ì„œë©´ ì½˜í…ì¸ ë¥¼ í¬í•¨í•œ ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì–¸ì–´ì™€ ë¬¸ë§¥ì— ëŒ€í•œ í¬ê´„ì ì¸ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œë‹¤.ì½”ë±ìŠ¤ëŠ” ì±—ë´‡, ê°€ìƒ ë¹„ì„œ, ê¸€ì“°ê¸° ë„êµ¬ ë“± ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ í†µí•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ìœ ì°½í•œ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì œê³µí•œë‹¤.\nì½”ë±ìŠ¤ì˜ í”„ë¡œê·¸ë˜ë° ê¸°ëŠ¥ì€ ê°€ì¥ ê°•ë ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ í•˜ë‚˜ë¡œ ë°©ëŒ€í•œ ì–‘ì˜ ì½”ë“œì™€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìê°€ ì œê³µí•œ ì§€ì‹œëª…ë ¹ì–´(Prompt)ì— ì‘ë‹µí•˜ì—¬ ì½”ë“œ ìŠ¤ë‹ˆí«(Snippet)ì„ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì½”ë“œë¥¼ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì •í™•í•˜ê²Œ ì‘ì„±í•´ì•¼ í•˜ëŠ” ê°œë°œìì—ê²Œ ë§¤ìš° ìœ ìš©í•œ ë„êµ¬ë¡œ ìë¦¬ì¡ì•„ê°€ê³  ìˆë‹¤.\nì½”ë±ìŠ¤ëŠ” íŒŒì´ì¬, ìë°”, C++, R ë“± ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, í˜„ì¬ ì½”ë“œ ë§¥ë½(Context)ì— ë”°ë¼ ì „ì²´ í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, êµ¬ë¬¸ì ìœ¼ë¡œ ì •í™•í•˜ê³  ëª¨ë²” ì‚¬ë¡€(Best Practice)ë¥¼ ë”°ë¥´ëŠ” ì½”ë“œë¥¼ ì œì•ˆí•¨ìœ¼ë¡œì¨ ì½”ë“œ ì‘ì„±ì— í•„ìš”í•œ ì‹œê°„ê³¼ ë…¸ë ¥ì„ ì¤„ì—¬ ê°œë°œìê°€ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì„¤ê³„í•˜ê±°ë‚˜ ê¸°ì¡´ ê¸°ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë“± ë³´ë‹¤ ë³µì¡í•œ ì‘ì—…ì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ í•œë‹¤.\nì½”ë±ìŠ¤ì˜ í”„ë¡œê·¸ë˜ë° ê¸°ëŠ¥ì˜ ì£¼ìš” ì´ì  ì¤‘ í•˜ë‚˜ëŠ” ìƒì„±í•˜ëŠ” ì½”ë“œì˜ ì˜ë¯¸ì™€ ëª©ì ì„ ì´í•´í•œë‹¤ëŠ” ì ì´ë‹¤. ì¦‰, ì‘ë™í•  ë¿ë§Œ ì•„ë‹ˆë¼ êµ¬ì¡°ì ìœ¼ë¡œ ê°•ê±´í•˜ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œë¥¼ ì œì•ˆí•˜ì—¬ ì˜¤ë¥˜ë¥¼ ì¤„ì´ê³  ì½”ë“œë² ì´ìŠ¤ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆì„ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì„ ì¤€ë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì½”ë±ìŠ¤ì˜ í”„ë¡œê·¸ë˜ë° ê¸°ëŠ¥ì€ ê°œë°œìì˜ ì½”ë“œ ì‘ì„± ë°©ì‹ì— í˜ì‹ ì„ ê°€ì ¸ì˜¬ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤.\n\nì£¼ì„ì„ ì½”ë“œë¡œ ì „í™˜\në§¥ë½ì„ ë³´ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ìë™ ì‘ì„±\në¼ì´ë¸ŒëŸ¬ë¦¬, API ë“± ì¶”ì²œì„ í†µí•´ ìƒˆë¡œìš´ ì§€ì‹ ì „ë‹¬\nì£¼ì„ ìë™ ì¶”ê°€\në™ì¼í•œ ê¸°ëŠ¥ì„ ê°–ì§€ë©´ íš¨ìœ¨ì„± ì¢‹ì€ ì½”ë“œë¡œ ë³€í™˜"
  },
  {
    "objectID": "rcoding.html#ì£¼ì„ë‹¬ê¸°",
    "href": "rcoding.html#ì£¼ì„ë‹¬ê¸°",
    "title": "chatGPT",
    "section": "\n5.1 ì£¼ì„ë‹¬ê¸°",
    "text": "5.1 ì£¼ì„ë‹¬ê¸°"
  },
  {
    "objectID": "rcoding.html#roxygen-ì¶”ê°€",
    "href": "rcoding.html#roxygen-ì¶”ê°€",
    "title": "chatGPT",
    "section": "\n5.2 Roxygen ì¶”ê°€",
    "text": "5.2 Roxygen ì¶”ê°€"
  },
  {
    "objectID": "rcoding.html#ìŠ¤í¬ë¦½íŠ¸-í•¨ìˆ˜",
    "href": "rcoding.html#ìŠ¤í¬ë¦½íŠ¸-í•¨ìˆ˜",
    "title": "chatGPT",
    "section": "\n5.3 ìŠ¤í¬ë¦½íŠ¸ â†’ í•¨ìˆ˜",
    "text": "5.3 ìŠ¤í¬ë¦½íŠ¸ â†’ í•¨ìˆ˜"
  },
  {
    "objectID": "rcoding.html#í•¨ìˆ˜ì—-ë‹¨ìœ„-í…ŒìŠ¤íŠ¸-ì¶”ì²œ",
    "href": "rcoding.html#í•¨ìˆ˜ì—-ë‹¨ìœ„-í…ŒìŠ¤íŠ¸-ì¶”ì²œ",
    "title": "chatGPT",
    "section": "\n5.4 í•¨ìˆ˜ì— ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ì²œ",
    "text": "5.4 í•¨ìˆ˜ì— ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ì²œ"
  },
  {
    "objectID": "reticulate.html",
    "href": "reticulate.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 íŒŒì´ì¬ í™˜ê²½ ì„¤ì •\nreticulate íŒ¨í‚¤ì§€ë¡œ ì½˜ë‹¤ íŒŒì´ì¬ í™˜ê²½ì„ êµ¬ì¶•í•œë‹¤. í•„ìš”í•œ ê²½ìš° íŒ¨í‚¤ì§€ë„ ì„¤ì¹˜í•œë‹¤.\nRiddhiman (Apr 19, 2022), â€˜Getting started with Python using R and reticulateâ€™\n\nì½”ë“œ# install.packages(\"reticulate\")\nlibrary(reticulate)\n\n# conda_list()\nuse_condaenv(condaenv = \"r-reticulate\")\n\n# py_install(packages = c(\"pandas\", \"scikit-learn\"))\n\n\n\n2 ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\ní­ê·„ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë¡œì»¬ ì»´í“¨í„° data í´ë”ì— ì €ì¥ì‹œí‚¨ë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n\nfs::dir_create(\"data\")\ndownload.file(url = \"https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv\", destfile = \"data/penguins_cleaned.csv\")\n\npenguin_df <- readr::read_csv(\"data/penguins_cleaned.csv\")\n\npenguin_df\n#> # A tibble: 333 Ã— 7\n#>    species island    bill_length_mm bill_depth_mm flipper_lengthâ€¦Â¹ body_â€¦Â² sex  \n#>    <chr>   <chr>              <dbl>         <dbl>            <dbl>   <dbl> <chr>\n#>  1 Adelie  Torgersen           39.1          18.7              181    3750 male \n#>  2 Adelie  Torgersen           39.5          17.4              186    3800 femaâ€¦\n#>  3 Adelie  Torgersen           40.3          18                195    3250 femaâ€¦\n#>  4 Adelie  Torgersen           36.7          19.3              193    3450 femaâ€¦\n#>  5 Adelie  Torgersen           39.3          20.6              190    3650 male \n#>  6 Adelie  Torgersen           38.9          17.8              181    3625 femaâ€¦\n#>  7 Adelie  Torgersen           39.2          19.6              195    4675 male \n#>  8 Adelie  Torgersen           41.1          17.6              182    3200 femaâ€¦\n#>  9 Adelie  Torgersen           38.6          21.2              191    3800 male \n#> 10 Adelie  Torgersen           34.6          21.1              198    4400 male \n#> # â€¦ with 323 more rows, and abbreviated variable names Â¹â€‹flipper_length_mm,\n#> #   Â²â€‹body_mass_g\n\n\n\n3 íŒŒì´ì¬ ê¸°ê³„í•™ìŠµ ëª¨í˜•\níŒŒì´ì¬ sklearn íŒ¨í‚¤ì§€ë¡œ í­ê·„ ì„±ë³„ì˜ˆì¸¡ ëª¨í˜•ì„ êµ¬ì¶•í•˜ì.\n\n\níŒŒì´ì¬ ì½”ë“œ\nR í™˜ê²½ ë¶ˆëŸ¬ì˜¤ê¸°\n\n\n\n# \"code/penguin_sex_clf.py\"\n\nimport pandas as pd\npenguins = pd.read_csv('data/penguins_cleaned.csv')\n\npenguins_df = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']]\n\n# Ordinal feature encoding\n# https://www.kaggle.com/pratik1120/penguin-dataset-eda-classification-and-clustering\ndf = penguins_df.copy()\n\ntarget_mapper = {'male':0, 'female':1}\ndef target_encode(val):\n    return target_mapper[val]\n\ndf['sex'] = df['sex'].apply(target_encode)\n\n# Separating X and Y\nX = df.drop('sex', axis=1)\nY = df['sex']\n\n# Build random forest model\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X, Y)\n\n\n\nì½”ë“œsource_python(\"code/penguin_sex_clf.py\")\n\nclf\n#> RandomForestClassifier()\n\n\n\n\n\n\n4 ì‹œê°í™”\níŒŒì´ì¬ ê¸°ê³„í•™ìŠµ ê²°ê³¼ë¥¼ Rë¡œ ê°€ì ¸ì™€ì„œ ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ì‹œê°í™”í•œë‹¤.\n\nì½”ë“œfeat_tbl <- tibble(features = clf$feature_names_in_,\n                   importance = clf$feature_importances_)\n\nfeat_tbl %>% \n  ggplot(aes(x = fct_reorder(features, importance), y = importance)) +\n    geom_point(size = 3) +\n    geom_segment( aes(x=features, xend=features, y=0, yend=importance)) +\n    labs(y = \"Feature ì¤‘ìš”ë„\", x = \"Feature\",\n         title = \"í­ê·„ ì•”ìˆ˜ ì˜ˆì¸¡ëª¨í˜• Feature ì¤‘ìš”ë„\") +\n    coord_flip() +\n    theme_bw(base_family = \"AppleGothic\")"
  },
  {
    "objectID": "BERT.html",
    "href": "BERT.html",
    "title": "chatGPT",
    "section": "",
    "text": "Context-free models: Word2Vec, Glove, FastText\nContext-embedding models(transformer based models): BERT, ELMO, Universal Sentence Encoder\n\nContext-free ëª¨í˜•ì€ ë‹¨ìˆœí•˜ê³  íš¨ìœ¨ì ì´ì§€ë§Œ í…ìŠ¤íŠ¸ì˜ ë‰´ì•™ìŠ¤ë¥¼ ë¹„ë¡¯í•˜ì—¬ ì˜ë¯¸ë¥¼ ì¡ì•„ë‚´ëŠ”ë° ë‹¤ì†Œ ë¯¸í¡í•  ìˆ˜ ìˆë‹¤. ë°˜ë©´ì— Context-based modelì€ ê°•ë ¥í•˜ê³  ìœ ì—°í•˜ì§€ë§Œ ì»´í“¨íŒ… ìì›ì„ ë§ì´ ì‚¬ìš©í•˜ê³  ë” ë³µì¡í•˜ë‹¤."
  },
  {
    "objectID": "BERT.html#íŒŒì´ì¬-ì½”ë“œ",
    "href": "BERT.html#íŒŒì´ì¬-ì½”ë“œ",
    "title": "chatGPT",
    "section": "\n2.1 íŒŒì´ì¬ ì½”ë“œ",
    "text": "2.1 íŒŒì´ì¬ ì½”ë“œ\nBERT ë…¼ë¬¸ https://arxiv.org/pdf/1810.04805.pdfì˜ ì´ˆë¡(Abstract)ì—ì„œ ì§ˆì˜ë¥¼ í•˜ê³  ê´€ë ¨ ë‚´ìš©ì„ ë½‘ì•„ë‚´ëŠ” ì½”ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•œë‹¤. (Ravichandiran, 2021)\n# ì§ˆì˜ì‘ë‹µ - íŒŒì´ì¬ ì½”ë“œ\n# ì¶œì²˜: https://github.com/PacktPublishing/Getting-Started-with-Google-BERT/tree/main/Chapter03\n\nfrom transformers import BertForQuestionAnswering, BertTokenizer\nimport torch\n\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\n# BERT ë…¼ë¬¸ Abstract: https://arxiv.org/pdf/1810.04805.pdf\n\nquestion = \"What does the 'B' in BERT stand for?\"\nabstract = \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\n\n\nquestion = '[CLS] ' + question + '[SEP]'\nabstract = abstract + '[SEP]'\n\nquestion_tokens = tokenizer.tokenize(question)\nabstract_tokens = tokenizer.tokenize(abstract)\n\ntokens = question_tokens + abstract_tokens\ninput_ids = tokenizer.convert_tokens_to_ids(tokens)\n\nsegment_ids = [0] * len(question_tokens) + [1] * len(abstract_tokens)\n\ninput_ids = torch.tensor([input_ids])\nsegment_ids = torch.tensor([segment_ids])\n\nscores = model(input_ids, token_type_ids = segment_ids)\n\nstart_index = torch.argmax(scores['start_logits'])\nend_index = torch.argmax(scores['end_logits'])\n\nanswer = ' '.join(tokens[start_index:end_index+1])\n\n# print(' '.join(tokens[start_index:end_index+1]))\n\nBERT ì„ë² ë”© ëª¨í˜•ì„ ì‚¬ìš©í•´ì„œ ì§ˆë¬¸ê³¼ ì‘ë‹µì„ íŒŒì´ì¬ ì½”ë“œë¡œ ì‘ì„±í•˜ê³  ë‚˜ì„œ ê·¸ ê²°ê³¼ê°’ì„ Rì—ì„œ ë°”ë¡ ì½ì–´ í›„ì²˜ë¦¬ í•˜ë„ë¡ í•œë‹¤.\n\nlibrary(reticulate)\nlibrary(tidyverse)\n\nreticulate::source_python(\"code/BERT/BERT_QnA.py\")"
  },
  {
    "objectID": "BERT.html#ì§ˆì˜ì‘ë‹µ-ì˜ˆì‹œ",
    "href": "BERT.html#ì§ˆì˜ì‘ë‹µ-ì˜ˆì‹œ",
    "title": "chatGPT",
    "section": "\n2.2 ì§ˆì˜ì‘ë‹µ ì˜ˆì‹œ",
    "text": "2.2 ì§ˆì˜ì‘ë‹µ ì˜ˆì‹œ\n\n\n\nì½”ë“œpy$question\n#> [1] \"[CLS] What does the 'B' in BERT stand for?[SEP]\"\n\n\n\n\nì½”ë“œpy$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#ëŒ€ìƒ-ì§€ë¬¸",
    "href": "BERT.html#ëŒ€ìƒ-ì§€ë¬¸",
    "title": "chatGPT",
    "section": "\n2.3 ëŒ€ìƒ ì§€ë¬¸",
    "text": "2.3 ëŒ€ìƒ ì§€ë¬¸\nì½”ë“œpy$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#ì¶œë ¥ê²°ê³¼",
    "href": "BERT.html#ì¶œë ¥ê²°ê³¼",
    "title": "chatGPT",
    "section": "\n2.3 ì¶œë ¥ê²°ê³¼",
    "text": "2.3 ì¶œë ¥ê²°ê³¼\n\nì½”ë“œpy$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#ì§ˆì˜ì‘ë‹µ-ì„¤ì •",
    "href": "BERT.html#ì§ˆì˜ì‘ë‹µ-ì„¤ì •",
    "title": "chatGPT",
    "section": "\n2.2 ì§ˆì˜ì‘ë‹µ ì„¤ì •",
    "text": "2.2 ì§ˆì˜ì‘ë‹µ ì„¤ì •\nBERTë¥¼ ì‚¬ìš©í•´ì„œ ì§ˆë¬¸ê³¼ ì‘ë‹µì„ ì¤€ë¹„í•œë‹¤.\n\n\n\npy$question\n#> [1] \"[CLS] What does the 'B' in BERT stand for?[SEP]\"\n\n\n\npy$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#ì§ˆì˜ì‘ë‹µ-ê²°ê³¼",
    "href": "BERT.html#ì§ˆì˜ì‘ë‹µ-ê²°ê³¼",
    "title": "chatGPT",
    "section": "\n2.3 ì§ˆì˜ì‘ë‹µ ê²°ê³¼",
    "text": "2.3 ì§ˆì˜ì‘ë‹µ ê²°ê³¼\n\n# str_c(py$tokens[py$start_index$tolist()+1:py$end_index$tolist()+1], collapse = \" \")\npy$answer\n#> [1] \"bid ##ire ##ction ##al en ##code ##r representations from transformers\""
  },
  {
    "objectID": "BERT.html#ì ‘ê·¼ë°©ë²•",
    "href": "BERT.html#ì ‘ê·¼ë°©ë²•",
    "title": "chatGPT",
    "section": "\n4.1 ì ‘ê·¼ë°©ë²•",
    "text": "4.1 ì ‘ê·¼ë°©ë²•\n\nQuantization and Pruning\nDistilBERT: Knowledge Distillation\nALBERT: A Lite BERT\n\nSamuel SuÄÃ­k (August 8th, 2019), â€œCompressing BERT for faster predictionâ€, RASA Blog\n\n\n\n\nQuantization\n\n\n\n\nPruning\n\n\n\n\nPruning"
  },
  {
    "objectID": "BERT.html#ì„±ëŠ¥ë¹„êµ",
    "href": "BERT.html#ì„±ëŠ¥ë¹„êµ",
    "title": "chatGPT",
    "section": "\n4.2 ì„±ëŠ¥ë¹„êµ",
    "text": "4.2 ì„±ëŠ¥ë¹„êµ\nDistilBERT, A Lite BERT(ALBERT) ë³€í˜•ëœ BERT ëª¨í˜•ì„ ë…¼ë¬¸ì— ì œì‹œëœ NLP ì‘ì—…ë³„ ì„±ëŠ¥ê³¼ í¬ê¸°ì™€ ì†ë„ë¥¼ BERT-base ëª¨í˜•ê³¼ ë¹„êµí•´ë³´ì.\n\n\nDistilBERT (Sanh et al., 2019)\nALBERT (Lan et al., 2019)"
  },
  {
    "objectID": "BERT.html#íŒŒì´ì¬-ì½”ë“œ-1",
    "href": "BERT.html#íŒŒì´ì¬-ì½”ë“œ-1",
    "title": "chatGPT",
    "section": "\n3.1 íŒŒì´ì¬ ì½”ë“œ",
    "text": "3.1 íŒŒì´ì¬ ì½”ë“œ\nIMDB ì˜í™”í‰ì  í…ìŠ¤íŠ¸ì— ë‹´ê¸´ ê°ì„±ë¶„ì„ì„ BERTë¥¼ ì‚¬ìš©í•´ì„œ ìˆ˜í–‰í•œë‹¤.\n# ê°ì„±ë¶„ì„ - íŒŒì´ì¬ ì½”ë“œ\n# ì¶œì²˜: https://wandb.ai/mukilan/BERT_Sentiment_Analysis/reports/An-Introduction-to-BERT-And-How-To-Use-It--VmlldzoyNTIyOTA1\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\ndf = pd.read_csv('https://gist.githubusercontent.com/Mukilan-Krishnakumar/e998ecf27d11b84fe6225db11c239bc6/raw/74dbac2b992235e555df9a0a4e4d7271680e7e45/imdb_movie_reviews.csv')\ndf = df.drop('sentiment',axis=1)\n\ntokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\ndef sentiment_movie_score(movie_review):\n\ttoken = tokenizer.encode(movie_review, return_tensors = 'pt')\n\tresult = model(token)\n\treturn int(torch.argmax(result.logits))+1\n\ndf['sentiment'] = df['text'].apply(lambda x: sentiment_movie_score(x[:512]))"
  },
  {
    "objectID": "BERT.html#ê°ì„±ë¶„ì„-ê²°ê³¼",
    "href": "BERT.html#ê°ì„±ë¶„ì„-ê²°ê³¼",
    "title": "chatGPT",
    "section": "\n3.2 ê°ì„±ë¶„ì„ ê²°ê³¼",
    "text": "3.2 ê°ì„±ë¶„ì„ ê²°ê³¼\n\nsenti_raw <- read_csv('https://gist.githubusercontent.com/Mukilan-Krishnakumar/e998ecf27d11b84fe6225db11c239bc6/raw/74dbac2b992235e555df9a0a4e4d7271680e7e45/imdb_movie_reviews.csv')\n\nreticulate::source_python(\"code/BERT/BERT_sentiment.py\")\n\nsenti_tbl <- senti_raw %>% \n  rename(label = sentiment) %>% \n  bind_cols(py$df %>% select(sentiment))\n\n\nsenti_tbl %>% \n  count(label, sentiment) %>% \n  ggplot(aes(x = sentiment, y = n, fill = label)) +\n    geom_col(width = 0.3, alpha = 0.7) +\n    scale_fill_manual(values = c(\"red\", \"green\")) +\n    labs(title = \"IMDB ì˜í™” í‰ì  ë°ì´í„°ì…‹ ê°ì„±ë¶„ì„ ê²°ê³¼\",\n         x = \"ê°ì„±ì ìˆ˜: ë¶€ì •(1) --- ê¸ì •(5)\",\n         y = \"ì˜í™”í‰ì  ë¶€ì—¬ê±´ìˆ˜\",\n         fill = \"ê¸ë¶€ì •\") +\n    theme_minimal() +\n    theme(legend.position = \"top\")"
  },
  {
    "objectID": "BERT.html#í›„ì†-ë¶„ì„",
    "href": "BERT.html#í›„ì†-ë¶„ì„",
    "title": "chatGPT",
    "section": "\n3.3 í›„ì† ë¶„ì„",
    "text": "3.3 í›„ì† ë¶„ì„\ní‰ì  4ì ìœ¼ë¡œ ì˜ˆì¸¡ëœ ì˜í™” í‰ì  ì¤‘ ê¸ë¶€ì • 3ê°œ ë¦¬ë·°ë¥¼ ë½‘ì•„ ì§ì ‘ ì‚´í´ë³´ì.\n\nlibrary(reactable)\n\nsenti_tbl %>% \n  filter(sentiment == 4) %>% \n  group_by(label) %>% \n  slice_sample(n = 3) %>% \n  reactable::reactable(\n      columns = list(\n        text = colDef(width = 700),\n        label = colDef(width = 50),\n        sentiment = colDef(width = 50)\n  ),\n  fullWidth = TRUE\n  )"
  },
  {
    "objectID": "korBERT.html",
    "href": "korBERT.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 BERT ëª¨í˜• ì„ ì •\në‹¤êµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” BERT ëª¨í˜•ì„ í™œìš©í•˜ì—¬ ì—°ê´€ ìì—°ì–´ ì²˜ë¦¬ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nbert-base-multilingual-cased\ndistilbert-base-multilingual-cased\n\ndistilbertëŠ” BERT ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ë‹¤ì†Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ë‚˜ í¬ê¸°, ì†ë„ ë“± ë‹¤ë¥¸ ì§€í‘œì—ì„œ BERTì™€ ëŒ€ë“±í•œ ì§€í‘œë¥¼ ì œì‹œí•˜ê³  ìˆë‹¤.\n\n2 ê°œì²´ëª… ì¸ì‹\nê°œì²´ëª…(Named Entity)ì€ ì¸ëª…, ê¸°ê´€ëª…, ì§€ëª… ë“±ê³¼ ê°™ì´ ë¬¸ì¥ ë˜ëŠ” ë¬¸ì„œì—ì„œ íŠ¹ì •í•œ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìˆëŠ” ë‹¨ì–´ ë˜ëŠ” ì–´êµ¬ë¥¼ ì§€ì¹­í•¨.\n\në„¤ì´ë²„ ê°œì²´ëª…ì¸ì‹\ní•œêµ­í•´ì–‘ëŒ€í•™êµ - ì»´í“¨í„°ê³µí•™ê³¼ ìì—°ì–¸ì–´ì²˜ë¦¬ ì—°êµ¬ì‹¤\nêµ­ë¦½êµ­ì–´ì›\nAI í—ˆë¸Œ\n\n\n\në„¤ì´ë²„(14ì¢…)\ní•œêµ­í•´ì–‘ëŒ€ (10ì¢…)\nêµ­ë¦½êµ­ì–´ì›(5ì¢…)\nAI í—ˆë¸Œ(15ì¢…)\n\n\n\n\nlibrary(tidyverse)\n\nner_tbl <- tibble::tribble(\n            ~ê°œì²´ëª….ë²”ì£¼,   ~íƒœê·¸,                          ~ì •ì˜,\n           \"PERSON\", \"PER\",      \"ì‹¤ì¡´, ê°€ìƒ ë“± ì¸ë¬¼ëª…ì— í•´ë‹¹ í•˜ëŠ” ê²ƒ\",\n            \"FIELD\", \"FLD\",       \"í•™ë¬¸ ë¶„ì•¼ ë° ì´ë¡ , ë²•ì¹™, ê¸°ìˆ  ë“±\",\n  \"ARTIFACTS_WORKS\", \"AFW\",        \"ì¸ê³µë¬¼ë¡œ ì‚¬ëŒì— ì˜í•´ ì°½ì¡°ëœ ëŒ€ìƒë¬¼\",\n     \"ORGANIZATION\", \"ORG\",      \"ê¸°ê´€ ë° ë‹¨ì²´ì™€ íšŒì˜/íšŒë‹´ì„ ëª¨ë‘ í¬í•¨\",\n         \"LOCATION\", \"LOC\",            \"ì§€ì—­ëª…ì¹­ê³¼ í–‰ì •êµ¬ì—­ ëª…ì¹­ ë“±\",\n     \"CIVILIZATION\", \"CVL\",            \"ë¬¸ëª… ë° ë¬¸í™”ì— ê´€ë ¨ëœ ìš©ì–´\",\n             \"DATE\", \"DAT\",                         \"ë‚ ì§œ\",\n             \"TIME\", \"TIM\",                         \"ì‹œê°„\",\n           \"NUMBER\", \"NUM\",                         \"ìˆ«ì\",\n            \"EVENT\", \"EVT\",        \"íŠ¹ì • ì‚¬ê±´ ë° ì‚¬ê³  ëª…ì¹­ê³¼ í–‰ì‚¬ ë“±\",\n           \"ANIMAL\", \"ANM\",                         \"ë™ë¬¼\",\n            \"PLANT\", \"PLT\",                         \"ì‹ë¬¼\",\n         \"MATERIAL\", \"MAT\",             \"ê¸ˆì†, ì•”ì„, í™”í•™ë¬¼ì§ˆ ë“±\",\n             \"TERM\", \"TRM\", \"ì˜í•™ ìš©ì–´, ITê³¤ë ¨ ìš©ì–´ ë“± ì¼ë°˜ ìš©ì–´ë¥¼ ì´ì¹­\"\n  )\n\nner_tbl %>% \n  gt::gt()\n\n\n\n\n\n\nê°œì²´ëª….ë²”ì£¼\n      íƒœê·¸\n      ì •ì˜\n    \n\n\nPERSON\nPER\nì‹¤ì¡´, ê°€ìƒ ë“± ì¸ë¬¼ëª…ì— í•´ë‹¹ í•˜ëŠ” ê²ƒ\n\n\nFIELD\nFLD\ní•™ë¬¸ ë¶„ì•¼ ë° ì´ë¡ , ë²•ì¹™, ê¸°ìˆ  ë“±\n\n\nARTIFACTS_WORKS\nAFW\nì¸ê³µë¬¼ë¡œ ì‚¬ëŒì— ì˜í•´ ì°½ì¡°ëœ ëŒ€ìƒë¬¼\n\n\nORGANIZATION\nORG\nê¸°ê´€ ë° ë‹¨ì²´ì™€ íšŒì˜/íšŒë‹´ì„ ëª¨ë‘ í¬í•¨\n\n\nLOCATION\nLOC\nì§€ì—­ëª…ì¹­ê³¼ í–‰ì •êµ¬ì—­ ëª…ì¹­ ë“±\n\n\nCIVILIZATION\nCVL\në¬¸ëª… ë° ë¬¸í™”ì— ê´€ë ¨ëœ ìš©ì–´\n\n\nDATE\nDAT\në‚ ì§œ\n\n\nTIME\nTIM\nì‹œê°„\n\n\nNUMBER\nNUM\nìˆ«ì\n\n\nEVENT\nEVT\níŠ¹ì • ì‚¬ê±´ ë° ì‚¬ê³  ëª…ì¹­ê³¼ í–‰ì‚¬ ë“±\n\n\nANIMAL\nANM\në™ë¬¼\n\n\nPLANT\nPLT\nì‹ë¬¼\n\n\nMATERIAL\nMAT\nê¸ˆì†, ì•”ì„, í™”í•™ë¬¼ì§ˆ ë“±\n\n\nTERM\nTRM\nì˜í•™ ìš©ì–´, ITê³¤ë ¨ ìš©ì–´ ë“± ì¼ë°˜ ìš©ì–´ë¥¼ ì´ì¹­\n\n\n\n\n\n\n\n\ní•œêµ­ì–´ì—ì„œ ê°œì²´ì˜ ë²”ì£¼ëŠ” í¬ê²Œ ê°œì²´ì´ë¦„, ì‹œê°„í‘œí˜„, ìˆ˜ëŸ‰í‘œí˜„ìœ¼ë¡œ ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤.\n\nê°œì²´ì´ë¦„: ì¸ëª…(PER), ì§€ëª…(LOC), ê¸°ê´€ëª…(ORG), ê¸°íƒ€(POH)\nì‹œê°„í‘œí˜„: ë‚ ì§œ(DAT), ì‹œê°„(TIM), ê¸°ê°„(DUR)\nìˆ˜ëŸ‰í‘œí˜„: í†µí™”(MNY), ë¹„ìœ¨(PNT), ê¸°íƒ€ ìˆ˜ëŸ‰í‘œí˜„(NOH)\n\n\n\nì¥ì†Œ(LC), ë‚ ì§œ(DT), ê¸°ê´€(OG), ì‹œê°„(TI), ì¸ë¬¼(PS)\n\n\nì‚¬ëŒ(PS), ì§€ì—­(LC), ë‹¨ì²´(OG), ì¸ê³µë¬¼(AF), ë‚ ì§œ(DT), ì‹œê°„(TI), ì œë„(CV), ë™ë¬¼(AM), ì‹ë¬¼(PT), ë‹¨ìœ„(QT), ë¶„ì•¼(FD), ì´ë¡ (TR), ì‚¬ê±´(EV), ë¬¼ì§ˆ(MT), ìš©ì–´(TM)"
  },
  {
    "objectID": "hf_pipeline.html",
    "href": "hf_pipeline.html",
    "title": "chatGPT",
    "section": "",
    "text": "ë‹¤êµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” BERT ëª¨í˜•ì„ í™œìš©í•˜ì—¬ ì—°ê´€ ìì—°ì–´ ì²˜ë¦¬ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nbert-base-multilingual-cased\ndistilbert-base-multilingual-cased\n\ndistilbertëŠ” BERT ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ë‹¤ì†Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ë‚˜ í¬ê¸°, ì†ë„ ë“± ë‹¤ë¥¸ ì§€í‘œì—ì„œ BERTì™€ ëŒ€ë“±í•œ ì§€í‘œë¥¼ ì œì‹œí•˜ê³  ìˆë‹¤.\n\n\n\n\n\n\në…¸íŠ¸\n\n\n\nfrom transformers import pipeline\n\n# Using default model and tokenizer for the task\npipeline(\"<task-name>\")\n\n# Using a user-specified model\npipeline(\"<task-name>\", model=\"<model_name>\")\n\n# Using custom model/tokenizer as str\npipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')\n\n\nHugging Face Transformers - How to use Pipelines"
  },
  {
    "objectID": "hf_pipeline.html#íŒŒì´ì¬-ì½”ë“œ",
    "href": "hf_pipeline.html#íŒŒì´ì¬-ì½”ë“œ",
    "title": "chatGPT",
    "section": "\n3.1 íŒŒì´ì¬ ì½”ë“œ",
    "text": "3.1 íŒŒì´ì¬ ì½”ë“œ\nHF íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ë¬¸ ê°œì²´ëª…ì¸ì‹ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.\n# ê°ì„±ë¶„ì„ - íŒŒì´ì¬ ì½”ë“œ\n# ì¶œì²˜: https://www.kaggle.com/code/funtowiczmo/hugging-face-transformers-how-to-use-pipelines\n\nfrom transformers import pipeline\n\n# NER íŒŒì´í”„ë¼ì¸ ---------------------------------\nner = pipeline(task = \"ner\", \n               model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n               tokenizer=\"bert-large-cased\")\n\ntext = \"John Smith works at Google\"\nentities = ner(text)\n\n# ê²°ê³¼ ì¶œë ¥\nfor entity in entities:\n    print(f\"{entity['word']} -> {entity['entity']}\")"
  },
  {
    "objectID": "hf_pipeline.html#ê°œì²´ëª…-ì¸ì‹ê²°ê³¼",
    "href": "hf_pipeline.html#ê°œì²´ëª…-ì¸ì‹ê²°ê³¼",
    "title": "chatGPT",
    "section": "\n3.2 ê°œì²´ëª… ì¸ì‹ê²°ê³¼",
    "text": "3.2 ê°œì²´ëª… ì¸ì‹ê²°ê³¼\n\nì½”ë“œlibrary(reticulate)\nreticulate::source_python(\"code/BERT/HF_pipeline_NER.py\")\n\nto_r <- function(idx){\n\n  output_idx = py$entities %>% \n    pluck(idx)\n  \n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n}\n\nmap_dfr(1:length(py$entities), ~to_r(.x))\n#> # A tibble: 3 Ã— 6\n#>   entity score index word   start   end\n#>   <chr>  <dbl> <int> <chr>  <int> <int>\n#> 1 I-PER  0.999     1 John       0     4\n#> 2 I-PER  1.00      2 Smith      5    10\n#> 3 I-ORG  0.998     5 Google    20    26"
  },
  {
    "objectID": "project.html#chatgpt-ì´ì „",
    "href": "project.html#chatgpt-ì´ì „",
    "title": "chatGPT",
    "section": "\n8.1 chatGPT ì´ì „",
    "text": "8.1 chatGPT ì´ì „\nTensorflow, Keras, Pytorch, Fast.ai ê°€ ì°¨ë¡€ë¡œ ë“±ì¥í•˜ë©° ë”¥ëŸ¬ë‹ ê°œë°œ í”„ë ˆì„ì›Œí¬ì˜ ì „ì„±ê¸°ë¥¼ êµ¬ê°€í–ˆë‹¤. ìµœê·¼ 5ë…„ë™ì•ˆ Google ì¶”ì„¸ë¥¼ ì‚´í´ë³´ì.\n\n\n\n\n\nì½”ë“œlibrary(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"ê²€ìƒ‰ìˆ˜\",\n         color = \"í”„ë ˆì„ì›Œí¬\",\n         title = \"ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ êµ¬ê¸€ ê²€ìƒ‰ ì¶”ì„¸\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()"
  },
  {
    "objectID": "project.html#chatgpt-ì¶œí˜„",
    "href": "project.html#chatgpt-ì¶œí˜„",
    "title": "chatGPT",
    "section": "\n8.2 chatGPT ì¶œí˜„",
    "text": "8.2 chatGPT ì¶œí˜„\nchatGPT ì¶œí˜„ì´í›„ Tensorflow, Keras, Pytorch, Fast.ai ëŠ” ì–´ë–»ê²Œ ì „ê°œë  ê²ƒì¸ì§€ ìµœê·¼ 1ë…„ë™ì•ˆ Google ì¶”ì„¸ë¥¼ ì‚´í´ë³´ì.\n\nì½”ë“œchatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"ê²€ìƒ‰ìˆ˜\",\n         color = \"í”„ë ˆì„ì›Œí¬\",\n         title = \"chatGPTì™€ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ êµ¬ê¸€ ê²€ìƒ‰ ì¶”ì„¸\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "project.html#íŒŒì´ì¬ê³¼-chatgpt",
    "href": "project.html#íŒŒì´ì¬ê³¼-chatgpt",
    "title": "chatGPT",
    "section": "\n8.3 íŒŒì´ì¬ê³¼ chatGPT",
    "text": "8.3 íŒŒì´ì¬ê³¼ chatGPT\nchatGPT ì¶œí˜„ì´í›„ íŒŒì´ì¬, tensorflow, pytorch ìµœê·¼ 1ë…„ë™ì•ˆ Google ì¶”ì„¸ë¥¼ ì‚´í´ë³´ì.\n\nì½”ë“œpython_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"ê²€ìƒ‰ìˆ˜\",\n         color = \"í”„ë ˆì„ì›Œí¬\",\n         title = \"íŒŒì´ì¬, chatGPT, ì£¼ìš” ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ êµ¬ê¸€ ê²€ìƒ‰ ì¶”ì„¸\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPTëŠ” ì¸í„°ë„·ì—ì„œ ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì´ë¥¼ ì •ë§ ì˜ ì••ì¶•í•œ í•˜ë‚˜ì˜ ì €ì¥ì†Œë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì••ì¶•ì„ í’€ê²Œ ë˜ë©´ ì •í™•íˆ ì›ë³¸ì„ ë³µì›í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ë„ ìˆì§€ë§Œ, ê·¸ë ‡ì§€ ëª»í•œ ë¶€ë¶„ë„ ë‹¹ì˜íˆ ìˆê²Œ ëœë‹¤.\nTed Chiang (February 9, 2023), â€œChatGPT Is a Blurry JPEG of the Web - OpenAIâ€™s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?â€, The New Yorker\nChatGPTë¥¼ â€œì›¹ì˜ íë¦¿í•œ JPEGâ€ìœ¼ë¡œ ë¹„ìœ í•˜ê³  ìˆë‹¤. JPEC ê¸°ìˆ  ìì²´ëŠ” ì†ì‹¤ ì••ì¶•ê¸°ìˆ ë¡œ ë¬´ì†ì‹¤ ì••ì¶•ê¸°ìˆ ë¡œ ëŒ€í‘œì ì¸ PNGì™€ ëŒ€ë¹„ëœë‹¤. íë¦¿í•œ ì´ë¯¸ì§€ê°€ ì„ ëª…í•˜ì§€ ì•Šê±°ë‚˜ ì •í™•í•˜ì§€ ì•Šì€ ê²ƒì²˜ëŸ¼ ChatGPTë„ í•­ìƒ ì™„ë²½í•œ ë‹µë³€ì„ ì œê³µí•˜ê±°ë‚˜ ëª¨ë“  ì§ˆë¬¸ì„ ì œëŒ€ë¡œ ì´í•´í•˜ëŠ” ê²ƒë„ ì•„ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŠì„ì—†ì´ í•™ìŠµí•˜ê³  ê°œì„ í•˜ê³  ìˆë‹¤. ë” ë§ì€ ì‚¬ëŒë“¤ì´ ChatGPTë¥¼ ì‚¬ìš©í• ìˆ˜ë¡ ì‚¬ëŒì˜ ì–¸ì–´ë¥¼ ë” ì˜ ì´í•´í•˜ê³  ë°˜ì‘í•  ìˆ˜ ìˆê²Œ ê°œë°œëœ ê¸°ìˆ ì´ë‹¤.\nChatGPTì™€ ìœ ì‚¬í•œ ì¸ê³µì§€ëŠ¥ í”„ë¡œê·¸ë¨ì´ ë„ˆë¬´ ê°•ë ¥í•´ì§€ê±°ë‚˜ ì¸ê°„ì„ ëŒ€ì²´í•  ìˆ˜ ìˆë‹¤ê³  ìš°ë ¤í•˜ëŠ” ì‚¬ëŒë“¤ë„ ìˆì§€ë§Œ, ChatGPTëŠ” ë‹¨ìˆœíˆ ì‘ì—…ì„ ë” ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“œëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì¼ ë¿ì´ë¯€ë¡œ ì‚¬ëŒì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ì§€ë°°í•  ê°€ëŠ¥ì„±ì€ ê±°ì˜ ì—†ë‹¤. ì¸ê³µì§€ëŠ¥(ChatGPT)ì„ ì±…ì„ê° ìˆê³  ìœ¤ë¦¬ì ìœ¼ë¡œ ì‚¬ìš©ë˜ë„ë¡ í•˜ëŠ” ê²ƒì€ ê²°êµ­ ì‚¬ìš©ì ê·€ì±…ì´ë‹¤.\nChatGPTê°€ ê°„ë‹¨í•œ ìˆ«ìê³„ì‚°ì— ë¬¸ì œê°€ ìˆëŠ” ê²ƒì€ ì›¹ìƒì— ì‚°ì¬ëœ ìˆ«ì ê³„ì‚° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„ì‚°ì„ í‰ë‚´ë‚¼ ìˆ˜ëŠ” ìˆìœ¼ë‚˜ ì´ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ChatGPTê°€ í•™ìŠµí•œ ê²ƒì€ ëª…ë°±íˆ ì˜ëª»ëœ ê²ƒì´ë‹¤. ì‚¬ì¹™ì—°ì‚°ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì›ë¦¬ë¥¼ ì´í•´í•˜ê²Œ ë˜ë©´ ì›¹ìƒì— ë‚˜ì˜¨ ì‚¬ì¹™ì—°ì‚° ë¬¸ì œë¥¼ ì •í™•íˆ í•´ê²°í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì›¹ìƒì— ë‚˜ì™€ìˆì§€ ì•ŠëŠ” ê³„ì‚°ë¬¸ì œë„ í’€ ìˆ˜ ìˆìœ¼ë‚˜ í˜„ì¬ëŠ” ê·¸ë ‡ì§€ ëª»í•˜ë‹¤.\n\n\nPNG íŒŒì¼\n(ë¹„)ì†ì‹¤ ì••ì¶•\níŒŒì¼í¬ê¸°\nBMP íŒŒì¼\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nìë£Œì¶œì²˜: WHATâ€™S THE DIFFERENCE BETWEEN JPEG AND PNG: BEGINNER GUIDE\n\në…ì¼ ê³¼í•™ì(David Kriesel)ê°€ ì œë¡ìŠ¤ ë³µì‚¬ê¸°ì—ì„œ ë¬¸ì„œì— ìˆëŠ” ìˆ«ìë¥¼ ë³€ê²½í•˜ëŠ” ê²°í•¨ì„ ë°œê²¬í–ˆë‹¤. ì œë¡ìŠ¤ í”„ë¦°í„°ê°€ ë°©ì˜ ë©´ì ì„ 14.13mÂ²ì—ì„œ 17.42mÂ²ë¡œ ë„“í˜”ê³ , ë‹¤ë¥¸ í”„ë¦°í„°ëŠ” 21.11mÂ²ì—ì„œ 14.13mÂ²ë¡œ ì¤„ì˜€ë‹¤. ìˆ«ì ë¬¸ìì—´ ì¤‘ê°„ì— íŠ¹ì • ìˆ«ì(ì˜ˆ: â€œ6â€ ë˜ëŠ” â€œ8â€)ê°€ ë‚˜íƒ€ë‚˜ë©´ ë³µì‚¬ê¸°ê°€ í•´ë‹¹ ìˆ«ìë¥¼ ë‹¤ë¥¸ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ê²½ìš°ê°€ ë§ì•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€™682â€™ê°€ â€™882â€™ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì²˜ìŒì— ê±´ë¬¼ ì„¤ê³„ë„ë¥¼ ìŠ¤ìº”í•˜ê³  ë¶„ì„í•˜ë ¤ê³  í•  ë•Œ ì´ ë¬¸ì œë¥¼ ë°œê²¬í–ˆë‹¤. ì›ë³¸ì—ëŠ” ì´ëŸ¬í•œ ì˜¤ë¥˜ê°€ ì—†ì—ˆì§€ë§Œ ìŠ¤ìº”í•œ ì‚¬ë³¸ì—ì„œ íŠ¹ì • ìˆ«ìê°€ ë³€ê²½ëœ ê²ƒì„ ë°œê²¬í–ˆë‹¤. ê²°êµ­ ê·¸ë“¤ì€ ì‚¬ë³¸ì„ ë§Œë“œëŠ” ê³¼ì •ì—ì„œ ìˆ«ìê°€ ë³€ê²½ëœ, ì‚¬ìš© ì¤‘ì¸ Xerox ë³µì‚¬ê¸°ì— ë¬¸ì œê°€ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ê¹¨ë‹¬ì•˜ë‹¤.\nì´ ê²°í•¨ì€ ì œë¡ìŠ¤ ë³µì‚¬ê¸°ì— ì‚¬ìš©ë˜ëŠ” ì••ì¶• ì•Œê³ ë¦¬ì¦˜ê³¼ ê´€ë ¨ëœ ê²ƒìœ¼ë¡œ íŠ¹ì • ìˆ«ìê°€ ì„œë¡œ ê°€ê¹Œì´ ìˆìœ¼ë©´ ì•Œê³ ë¦¬ì¦˜ì´ ì´ë¥¼ ë‹¤ë¥¸ ìˆ«ìë¡œ ì°©ê°í•˜ê³  ê·¸ì— ë”°ë¼ ìˆ«ìë¥¼ ë°”ê¾¼ ê²ƒì´ë‹¤. ì´ ë¬¸ì œê°€ ì¼ë¶€ ê³ ê¸‰ ëª¨ë¸ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì œë¡ìŠ¤ ë³µì‚¬ê¸°ì— ì¡´ì¬í•œë‹¤ëŠ” ì‚¬ì‹¤ë„ ë°œê²¬í–ˆë‹¤.\nD. KRIESEL, â€œXerox scanners/photocopiers randomly alter numbers in scanned documentsâ€\n\n\nì„¤ê³„ë„ ë¬¸ì„œ\nìŠ¤ìº” ê²°ê³¼\nì›ê°€í‘œ ìŠ¤ìº”\nìŠ¤ìº” ì˜¤ë¥˜\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nëª¨ë¸: WorkCentre 7535"
  },
  {
    "objectID": "trends.html",
    "href": "trends.html",
    "title": "chatGPT",
    "section": "",
    "text": "ë°±ë§Œ, 5ì²œë§Œ, 1ì–µ ê°€ì…ìë¥¼ ê°€ì§ˆ ë•Œê¹Œì§€ ê±¸ë¦° ì†Œìš”ì‹œê°„ì„ ë³´ë©´ chatGPT ì˜ ì˜í–¥ë ¥ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.\n\n\nì „í™”ê¸°ë¶€í„°\nê¸°ìˆ  ì§„í™”\nchatGPT ë°±ë§Œ\në¹…3 ì„œë¹„ìŠ¤\n1ì–µëª… (ì†Œìš” ë‹¬ìˆ˜)\n\n\n\n\n\n(Song, 2019)\n\n\n\n\n\n\nRita McGrath(November 25, 2013), â€œThe Pace of Technology Adoption is Speeding Upâ€, Harvard Business Review\n\n\n\n\n\n\n\n\n\n\n\n\nì¶œì²˜: https://twitter.com/umarsaif/status/1610932387185315840\n\n\n\n\n\n\nì¶œì²˜: https://twitter.com/EconomyApp/status/1622029832099082241"
  },
  {
    "objectID": "trends.html#chatgpt-ì´ì „",
    "href": "trends.html#chatgpt-ì´ì „",
    "title": "chatGPT",
    "section": "\n3.1 chatGPT ì´ì „",
    "text": "3.1 chatGPT ì´ì „\nTensorflow, Keras, Pytorch, Fast.ai ê°€ ì°¨ë¡€ë¡œ ë“±ì¥í•˜ë©° ë”¥ëŸ¬ë‹ ê°œë°œ í”„ë ˆì„ì›Œí¬ì˜ ì „ì„±ê¸°ë¥¼ êµ¬ê°€í–ˆë‹¤. ìµœê·¼ 5ë…„ë™ì•ˆ Google ì¶”ì„¸ë¥¼ ì‚´í´ë³´ì.\n\n\n\n\n\nì½”ë“œlibrary(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"ê²€ìƒ‰ìˆ˜\",\n         color = \"í”„ë ˆì„ì›Œí¬\",\n         title = \"ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ êµ¬ê¸€ ê²€ìƒ‰ ì¶”ì„¸\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()"
  },
  {
    "objectID": "trends.html#chatgpt-ì¶œí˜„",
    "href": "trends.html#chatgpt-ì¶œí˜„",
    "title": "chatGPT",
    "section": "\n3.2 chatGPT ì¶œí˜„",
    "text": "3.2 chatGPT ì¶œí˜„\nchatGPT ì¶œí˜„ì´í›„ Tensorflow, Keras, Pytorch, Fast.ai ëŠ” ì–´ë–»ê²Œ ì „ê°œë  ê²ƒì¸ì§€ ìµœê·¼ 1ë…„ë™ì•ˆ Google ì¶”ì„¸ë¥¼ ì‚´í´ë³´ì.\n\nì½”ë“œchatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"ê²€ìƒ‰ìˆ˜\",\n         color = \"í”„ë ˆì„ì›Œí¬\",\n         title = \"chatGPTì™€ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ êµ¬ê¸€ ê²€ìƒ‰ ì¶”ì„¸\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "trends.html#íŒŒì´ì¬ê³¼-chatgpt",
    "href": "trends.html#íŒŒì´ì¬ê³¼-chatgpt",
    "title": "chatGPT",
    "section": "\n3.3 íŒŒì´ì¬ê³¼ chatGPT",
    "text": "3.3 íŒŒì´ì¬ê³¼ chatGPT\nchatGPT ì¶œí˜„ì´í›„ íŒŒì´ì¬, tensorflow, pytorch ìµœê·¼ 1ë…„ë™ì•ˆ Google ì¶”ì„¸ë¥¼ ì‚´í´ë³´ì.\n\nì½”ë“œpython_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"ê²€ìƒ‰ìˆ˜\",\n         color = \"í”„ë ˆì„ì›Œí¬\",\n         title = \"íŒŒì´ì¬, chatGPT, ì£¼ìš” ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ êµ¬ê¸€ ê²€ìƒ‰ ì¶”ì„¸\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "intro_avi.html",
    "href": "intro_avi.html",
    "title": "chatGPT",
    "section": "",
    "text": "chatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ë‹¨ë²•ì¸ í•œêµ­ R ì‚¬ìš©ìíšŒ ì†Œê°œ ëŒ€ë³¸ì„ ì‘ì„±í•œë‹¤.\në‹¤ìŒìœ¼ë¡œ ë¯¸ë“œì €ë‹ˆë¥¼ ì´ìš©í•˜ì—¬ ì‚¬ë‹¨ë²•ì¸ í•œêµ­ R ì‚¬ìš©ìíšŒë¥¼ ì†Œê°œí•˜ëŠ” í™”ì ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.\ní´ë¡œë²„ ë”ë¹™ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ chatGPT ê°€ ì‘ì„±í•œ ëŒ€ë³¸ìœ¼ë¡œ ìŒì„± íŒŒì¼(.mp3)ì„ ì œì‘í•œë‹¤.\n\nD-ID ìŠ¤íŠœë””ì˜¤ì— ë¯¸ë“œì €ë‹ˆì—ì„œ ì‘ì—…í•œ ì´ë¯¸ì§€ì™€ STTë¡œ ì‘ì—…í•œ ê²°ê³¼ë¥¼ í•©ì„±í•˜ì—¬ í•œêµ­ R ì‚¬ìš©ìíšŒ ì†Œê°œ ë™ì˜ìƒ ì‘ì—…ì„ ë§ˆë¬´ë¦¬í•œë‹¤.\nìœ íŠœë¸Œ ì±„ë„ì— ì˜¬ë ¤ ì†Œì…œ ë¯¸ë””ì–´ë¡œ í•œêµ­ R ì‚¬ìš©ìíšŒ í™ë³´ë¥¼ í•œë‹¤.\n\n\nì‚¬ë‹¨ë²•ì¸ í•œêµ­ R ì‚¬ìš©ìíšŒì— ëŒ€í•´ ì†Œê°œí•˜ëŠ” ì†Œê°œê¸€ì„ ì‘ì„±í•´ì¤˜\n\n\n\n\n\n\nchatGPT\n\n\n\n\n\ní•œêµ­ R ì‚¬ìš©ìíšŒëŠ” ë°ì´í„° ë¶„ì„ ë° í†µê³„ë¶„ì•¼ì—ì„œ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆëŠ” R í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ ì‚¬ìš©ì„ ì´‰ì§„í•˜ê³ , ì—°êµ¬ ë° ê°œë°œ ë¶„ì•¼ì—ì„œ Rì„ í™œìš©í•œ ë‹¤ì–‘í•œ ì‘ìš©ê³¼ ê¸°ìˆ  ë°œì „ì„ ìœ„í•´ ì„¤ë¦½ëœ ì‚¬ë‹¨ë²•ì¸ì…ë‹ˆë‹¤.\ní•œêµ­ R ì‚¬ìš©ìíšŒëŠ” R í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë¶„ì•¼ì—ì„œì˜ ì§€ì‹ê³¼ ì •ë³´ êµë¥˜, í˜‘ë ¥ê³¼ ê³µìœ ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ í™œë™ì„ ì „ê°œí•˜ê³  ìˆìŠµë‹ˆë‹¤. íšŒì›ë“¤ì€ Rì„ í™œìš©í•œ ë‹¤ì–‘í•œ ë¶„ì„ ë° ì‹œê°í™” ê¸°ìˆ ì„ ê³µìœ í•˜ê³ , R íŒ¨í‚¤ì§€ ê°œë°œ ë° ì˜¤í”ˆì†ŒìŠ¤ í™œìš©, ë°ì´í„° ê³¼í•™ ë¶„ì•¼ì—ì„œì˜ í˜‘ë ¥ê³¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œë™í•˜ë©° ì§€ì‹ì„ ê³µìœ í•©ë‹ˆë‹¤.\ní•œêµ­ R ì‚¬ìš©ìíšŒëŠ” êµ­ë‚´ì™¸ R ì»¨í¼ëŸ°ìŠ¤ ë° ì„¸ë¯¸ë‚˜ ê°œìµœ, R êµìœ¡ ë° í›ˆë ¨, R í™œìš© ì‚¬ë¡€ ë°œí‘œ, R íŒ¨í‚¤ì§€ ê°œë°œ ë° ìœ ì§€ ë³´ìˆ˜ ë“± ë‹¤ì–‘í•œ í™œë™ì„ í†µí•´ íšŒì›ë“¤ì˜ R í™œìš© ëŠ¥ë ¥ í–¥ìƒê³¼ ì§€ì‹ ê³µìœ ë¥¼ ìœ„í•œ ê¸°ë°˜ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.\níšŒì›ìœ¼ë¡œ ê°€ì…í•˜ë©´ R ì–¸ì–´ ë° ë°ì´í„° ë¶„ì„ ë¶„ì•¼ì—ì„œì˜ ìµœì‹  ì •ë³´ì™€ ê¸°ìˆ  ë™í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë°›ì„ ìˆ˜ ìˆìœ¼ë©°, R íŒ¨í‚¤ì§€ ê°œë°œ ë° í™œìš©, ë°ì´í„° ë¶„ì„ ê¸°ìˆ  ë“±ì— ëŒ€í•œ ë‹¤ì–‘í•œ êµìœ¡ê³¼ ì„¸ë¯¸ë‚˜, ì›Œí¬ìƒµ ë“±ì„ ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\ní•œêµ­ R ì‚¬ìš©ìíšŒëŠ” R í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ í™œìš©ê³¼ ê°œë°œì„ í†µí•´ ë°ì´í„° ë¶„ì„ ë° í†µê³„ë¶„ì•¼ì˜ ë°œì „ì„ ìœ„í•œ ì§€ì†ì ì¸ ë…¸ë ¥ì„ ê¸°ìš¸ì´ê³  ìˆìœ¼ë©°, íšŒì›ë“¤ì˜ í™œë™ê³¼ ì°¸ì—¬ë¥¼ í†µí•´ R í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ í™œìš©ê³¼ ë°œì „ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\n\n\n\nMidjourney\në¯¸ë“œì €ë‹ˆ AI ì´ë¯¸ì§€ë¥¼ ì˜ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” Prompt Engineeringì„ í†µí•´ ì›í•˜ëŠ” ì´ë¯¸ì§€ê°€ ì œì‘ë  ë•Œê¹Œì§€ ì‘ì—…í•œë‹¤.\në¯¸ë“œì €ë‹ˆ í”„ë¡¬í”„íŠ¸ íˆ´ ì›¹ì‚¬ì´íŠ¸ì—ì„œ Midjourney Bot ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë¹„êµí•˜ì—¬ AI ì´ë¯¸ì§€ ì‘ì„±ì—…ë¬´ì— ì¢€ë” ì§‘ì¤‘í•  ìˆ˜ ìˆë‹¤.\nwillwulfken/MidJourney-Styles-and-Keywords-Reference GitHub ì €ì¥ì†Œì— ì¦‰ì‹œ ì‚¬ìš©ê°€ëŠ¥í•œ í…œí”Œë¦¿ì´ ë§ì•„ ì´ë¥¼ í™œìš©í•˜ëŠ” ê²ƒë„ AI ì´ë¯¸ì§€ ì œì‘ ì†ë„ ë° í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\nì‘ì„± í”„ë¡¬í”„íŠ¸ https://s.mj.run/guPCzzM12wU, crepuscular rays::1 rembrandt::1 defocus::-0.5 â€“ar 2:1 â€“v 4\n\n\n\nì›ë³¸ ì´ë¯¸ì§€\nì²« 4ì¥ ì´ë¯¸ì§€\nì˜ëª» ëˆ„ë¦„\nì´ë¯¸ì§€ ì¬í˜„\nìµœì¢… ì´ë¯¸ì§€\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ní´ë¡œë²„ ë”ë¹™\ní…ìŠ¤íŠ¸ë¥¼ ìŒì›ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ ë‹¤ì–‘í•œ API ì„œë¹„ìŠ¤ê°€ ì œê³µë˜ì§€ë§Œ ë„¤ì´ë²„ í´ë¡œë²„ ë”ë¹™ API ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ì–‘í•œ í•œêµ­ì¸ ëª©ì†Œë¦¬ë¥¼ ë„£ì–´ êµ¬í˜„ì´ ê°€ëŠ¥í•˜ë‹¤.\n\nD-ID\nD-ID ìŠ¤íŠœë””ì˜¤ì— ë¯¸ë“œì €ë‹ˆì—ì„œ ì‘ì—…í•œ ì´ë¯¸ì§€ì™€ STTë¡œ ì‘ì—…í•œ ê²°ê³¼ë¥¼ í•©ì„±í•˜ì—¬ í•œêµ­ R ì‚¬ìš©ìíšŒ ì†Œê°œ ë™ì˜ìƒ ì‘ì—…ì„ ë§ˆë¬´ë¦¬í•œë‹¤."
  },
  {
    "objectID": "intro_avi.html#ìŒì›-ì œì‘",
    "href": "intro_avi.html#ìŒì›-ì œì‘",
    "title": "chatGPT",
    "section": "\n2.1 ìŒì› ì œì‘",
    "text": "2.1 ìŒì› ì œì‘\ní´ë¡œë²„ ë”ë¹™\ní…ìŠ¤íŠ¸ë¥¼ ìŒì›ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ ë‹¤ì–‘í•œ API ì„œë¹„ìŠ¤ê°€ ì œê³µë˜ì§€ë§Œ ë„¤ì´ë²„ í´ë¡œë²„ ë”ë¹™ API ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¤ì–‘í•œ í•œêµ­ì¸ ëª©ì†Œë¦¬ë¥¼ ë„£ì–´ êµ¬í˜„ì´ ê°€ëŠ¥í•˜ë‹¤."
  },
  {
    "objectID": "intro_avi.html#ë™ì˜ìƒ-ì œì‘",
    "href": "intro_avi.html#ë™ì˜ìƒ-ì œì‘",
    "title": "chatGPT",
    "section": "\n2.2 ë™ì˜ìƒ ì œì‘",
    "text": "2.2 ë™ì˜ìƒ ì œì‘\nD-ID\nD-ID ìŠ¤íŠœë””ì˜¤ì— ë¯¸ë“œì €ë‹ˆì—ì„œ ì‘ì—…í•œ ì´ë¯¸ì§€ì™€ STTë¡œ ì‘ì—…í•œ ê²°ê³¼ë¥¼ í•©ì„±í•˜ì—¬ í•œêµ­ R ì‚¬ìš©ìíšŒ ì†Œê°œ ë™ì˜ìƒ ì‘ì—…ì„ ë§ˆë¬´ë¦¬í•œë‹¤."
  },
  {
    "objectID": "intro_book.html",
    "href": "intro_book.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì „ìì¶œíŒëœ ì „ìì±…ì€ ë‹¤ìŒ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\n\nì „ìì±…\nì†ŒìŠ¤ì½”ë“œ"
  },
  {
    "objectID": "intro_book.html#ìˆ˜ì •ëœ-ì»¤ë¦¬í˜ëŸ¼",
    "href": "intro_book.html#ìˆ˜ì •ëœ-ì»¤ë¦¬í˜ëŸ¼",
    "title": "chatGPT",
    "section": "\n3.1 ìˆ˜ì •ëœ ì»¤ë¦¬í˜ëŸ¼",
    "text": "3.1 ìˆ˜ì •ëœ ì»¤ë¦¬í˜ëŸ¼\n\n\n\n\n\n\n\n\n1ì£¼ì°¨ 1ì£¼ì°¨: R ë° ë°ì´í„° ë­ê¸€ë§ ì†Œê°œ\n\nR ê°œìš” ë° ë°ì´í„° ê³¼í•™ì—ì„œì˜ ì¤‘ìš”ì„±\nRì—ì„œ ë°ì´í„° ë­ê¸€ë§(Wrangling) ë° ì •ë¦¬ì˜ ê¸°ë³¸ ê°œë… ì†Œê°œ\n\ndplyr ë° tidyr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° í•„í„°ë§, ì •ë ¬, ë³‘í•© ë° ì§‘ê³„ì™€ ê°™ì€ ë°ì´í„° ë­ê¸€ë§ ê¸°ë²• ì†Œê°œ\npivot_longer(), pivot_wider() í•¨ìˆ˜ ì‚¬ìš© ê¹”ë”í•œ ë°ì´í„° ë³€í˜• \në²¡í„°, í–‰ë ¬, ë°ì´í„° í”„ë ˆì„ ë° ëª©ë¡ê³¼ ê°™ì€ Rì˜ ë°ì´í„° êµ¬ì¡° ì†Œê°œ\nRì—ì„œ ë°ì´í„° ë­ê¸€ë§ ê¸°ìˆ ì„ ì—°ìŠµí•˜ëŠ” ì—°ìŠµ ë° í”„ë¡œì íŠ¸\n\n\n\n2ì£¼ì°¨ ë°ì´í„° ì‹œê°í™” ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)\n\në°ì´í„° ì‹œê°í™” ì†Œê°œ ë° ë°ì´í„° ê³¼í•™ì—ì„œ ë°ì´í„° ì‹œê°í™”ì˜ ì¤‘ìš”ì„±\në‹¤ì–‘í•œ ìœ í˜•ì˜ ì‹œê°í™”ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ggplot2, gt R íŒ¨í‚¤ì§€ ì‚¬ìš©\në°ì´í„° ë¶„í¬, ìƒê´€ê´€ê³„, ì´ìƒê°’ íƒì§€ ë“± EDAì˜ ì›ë¦¬ ì†Œê°œ\në¶„ì‚°í˜• ì°¨íŠ¸, íˆìŠ¤í† ê·¸ë¨, ìƒìê·¸ë¦¼ê³¼ ê°™ì€ ë°ì´í„° íƒìƒ‰ ê¸°ë²•\nRì—ì„œ ë°ì´í„° ì‹œê°í™” ë° EDA ê¸°ìˆ ì„ ì—°ìŠµí•  ìˆ˜ ìˆëŠ” ì—°ìŠµ ë° í”„ë¡œì íŠ¸\n\n\n\n3ì£¼ì°¨ í†µê³„ ë¶„ì„ ë° ê¸°ê³„ í•™ìŠµ ê¸°ì´ˆ\n\nRì˜ í†µê³„ ë¶„ì„ ë° ê¸°ê³„ í•™ìŠµ ì†Œê°œ\ní™•ë¥  ë¶„í¬, ê°€ì„¤ í…ŒìŠ¤íŠ¸ ë° íšŒê·€ ë¶„ì„ê³¼ ê°™ì€ ê¸°ë³¸ í†µê³„ ê°œë… ê°œìš”\nì§€ë„ í•™ìŠµ ë° ë¹„ì§€ë„ í•™ìŠµê³¼ ê°™ì€ ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ê³¼ ë°ì´í„° ê³¼í•™ì—ì„œì˜ ì‘ìš© í”„ë¡œê·¸ë¨ ì†Œê°œ\në¨¸ì‹  ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ì„ ìœ„í•œ tidymodels ë° mlrê³¼ ê°™ì€ R íŒ¨í‚¤ì§€ ì‚¬ìš©\nRì—ì„œ í†µê³„ ë¶„ì„ ë° ê¸°ê³„ í•™ìŠµ ê¸°ë³¸ ì‚¬í•­ì„ ì—°ìŠµí•˜ëŠ” ì—°ìŠµ ë° í”„ë¡œì íŠ¸\n\n\n\n4ì£¼ì°¨ ê³ ê¸‰ ë°ì´í„° ê³¼í•™ ê¸°ë²•\n\ní…ìŠ¤íŠ¸ ë§ˆì´ë‹, ë„¤íŠ¸ì›Œí¬ ë¶„ì„, ì‹œê³„ì—´ ë¶„ì„ê³¼ ê°™ì€ Rì˜ ê³ ê¸‰ ë°ì´í„° ê³¼í•™ ê¸°ë²• ì†Œê°œ\n\ntidytext, í† í”½ëª¨ë¸ ë“± R íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•œ ê°ì„± ë¶„ì„, í…ìŠ¤íŠ¸ ë¶„ë¥˜, í† í”½ ëª¨ë¸ë§ ë“± í…ìŠ¤íŠ¸ ë§ˆì´ë‹ ê°œë… ê°œìš” ì†Œê°œ\n\ntidygraph ë“± R íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•œ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„, ì¤‘ì‹¬ì„± ì¸¡ì •, ì»¤ë®¤ë‹ˆí‹° íƒì§€ ë“± ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê¸°ë²• ì†Œê°œ\nì˜ˆì¸¡, tidyverts ë“± R íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•œ ARIMA ëª¨ë¸, ì˜ˆì¸¡, ì¶”ì„¸ ë¶„ì„ ë“± ì‹œê³„ì—´ ë¶„ì„ ê¸°ë²• ì†Œê°œ\nRì˜ ê³ ê¸‰ ë°ì´í„° ê³¼í•™ ê¸°ë²•ì„ ì‹¤ìŠµí•  ìˆ˜ ìˆëŠ” ì‹¤ìŠµ ë° í”„ë¡œì íŠ¸."
  },
  {
    "objectID": "intro_book.html#ì‘ì—…íë¦„-ìƒì„¸",
    "href": "intro_book.html#ì‘ì—…íë¦„-ìƒì„¸",
    "title": "chatGPT",
    "section": "\n2.1 ì‘ì—…íë¦„ ìƒì„¸",
    "text": "2.1 ì‘ì—…íë¦„ ìƒì„¸\nê° ë‹¨ê³„ë³„ ì €ì‘íë¦„ì— ì£¼ìš”í•˜ê²Œ ì‚¬ìš©ëœ chatGPT, DeepL, Quarto Book ë„êµ¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©ë˜ì—ˆë‹¤.\n\n\n\n\nchatGPT ì‘ì„±\n\n\n\n\nDeepL ë²ˆì—­ ë° êµì •\n\n\n\n\nì¿¼í†  ì¶œíŒì €ì‘\n\n\n\nê·¸ë¦¼Â 1: chatGPT ë””ì§€í„¸ ê¸€ì“°ê¸° ì €ì‘ íë¦„"
  },
  {
    "objectID": "intro_book.html#chatgpt-í”„ë¡¬í”„íŠ¸",
    "href": "intro_book.html#chatgpt-í”„ë¡¬í”„íŠ¸",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT í”„ë¡¬í”„íŠ¸",
    "text": "2.2 chatGPT í”„ë¡¬í”„íŠ¸\në°ì´í„° ê³¼í•™ ì±…ì„ ì €ì‘í•˜ê¸° ìœ„í•´ chatGPTì—ì„œ ì‚¬ìš©ëœ ì§€ì‹œëª…ë ¹ì–´(Prompt)ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. chatGPT ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ê²½ìš° Seedë¥¼ ì ìš©í•  ê¸°ëŠ¥ì´ ì—†ê¸° ë•Œë¬¸ì— ë¹„ê²°ì •ì (non-deterministic)ì´ë¼ ì¶œë ¥ê²°ê³¼ëŠ” ì‚¬ë­‡ ë‹¤ë¥´ê²Œ ëœë‹¤.\n\nwrite four weeks data science curriculum\n\n\n\n\n\n\n\nchatGPT ë‹µë³€:\n\n\n\n\n\nWeek 1: Introduction to Data Science and Data Wrangling\n\nOverview of data science and its importance in various fields\nIntroduction to the basic concepts of data wrangling and cleaning\nTechniques for data wrangling such as filtering, sorting, merging, and aggregating data\nUse of Python libraries such as pandas for data wrangling\nExercises and projects to practice data wrangling techniques\nWeek 2: Data Visualization and Exploratory Data Analysis (EDA)\n\nWeek 2: Introduction to data visualization and its importance in data science\n\nUse of Python libraries such as matplotlib, seaborn and plotly for creating various types of visualizations\nPrinciples of EDA such as data distribution, correlation, and outliers detection\nTechniques for data exploration such as scatter plots, histograms, and box plots\nExercises and projects to practice data visualization and EDA techniques\nWeek 3: Statistical Analysis and Machine Learning Fundamentals\n\nWeek 3: Introduction to statistical analysis and machine learning\n\nOverview of basic statistical concepts such as probability distributions, hypothesis testing, and regression analysis\nIntroduction to machine learning algorithms such as supervised and unsupervised learning, and their applications in data science\nUse of Python libraries such as scikit-learn for implementing machine learning algorithms\nExercises and projects to practice statistical analysis and machine learning fundamentals Week 4: Advanced Data Science Techniques\n\nWeek 4: Introduction to advanced data science techniques such as deep learning, natural language processing, and computer vision\n\nOverview of deep learning concepts such as neural networks, convolutional neural networks (CNN), and recurrent neural networks (RNN)\nUse of Python libraries such as Tensorflow and Keras for implementing deep learning algorithms\nIntroduction to natural language processing techniques such as sentiment analysis, text classification, and named entity recognition\nIntroduction to computer vision techniques such as image classification, object detection, and segmentation\nExercises and projects to practice advanced data science techniques\n\n\n\n\n\nwrite data science curriculum with R\n\n\n\n\n\n\n\nchatGPT ë‹µë³€:\n\n\n\n\n\nWeek 1: Introduction to R and Data Wrangling\n\nOverview of R and its importance in data science\nIntroduction to the basic concepts of data wrangling and cleaning in R\nTechniques for data wrangling such as filtering, sorting, merging, and aggregating data using dplyr and tidyr packages\nIntroduction to data structures in R such as vectors, matrices, data frames, and lists\nExercises and projects to practice data wrangling techniques in R\n\nWeek 2: Data Visualization and Exploratory Data Analysis (EDA)\n\nIntroduction to data visualization and its importance in data science\nUse of R packages such as ggplot2 and lattice for creating various types of visualizations\nPrinciples of EDA such as data distribution, correlation, and outliers detection\nTechniques for data exploration such as scatter plots, histograms, and box plots\nExercises and projects to practice data visualization and EDA techniques in R\n\nWeek 3: Statistical Analysis and Machine Learning Fundamentals\n\nIntroduction to statistical analysis and machine learning in R\nOverview of basic statistical concepts such as probability distributions, hypothesis testing, and regression analysis\nIntroduction to machine learning algorithms such as supervised and unsupervised learning, and their applications in data science\nUse of R packages such as caret and mlr for implementing machine learning algorithms\nExercises and projects to practice statistical analysis and machine learning fundamentals in R\n\nWeek 4: Advanced Data Science Techniques\n\nIntroduction to advanced data science techniques in R such as text mining, network analysis, and time series analysis\nOverview of text mining concepts such as sentiment analysis, text classification, and topic modeling using R packages such as tm and topicmodels\nIntroduction to network analysis techniques such as social network analysis, centrality measures, and community detection using R packages such as igraph and statnet\nIntroduction to time series analysis techniques such as ARIMA models, forecasting, and trend analysis using R packages such as forecast and tseries\nExercises and projects to practice advanced data science techniques in R.\n\n\n\n\n\nwrite section for \"Overview of R and its importance in data science\"\n\n\n\n\n\n\n\nchatGPT ë‹µë³€:\n\n\n\n\n\nSure, hereâ€™s an overview of R and its importance in data science:\nR is a programming language and software environment for statistical computing and graphics. It was developed in the early 1990s by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand. Since then, it has become one of the most popular languages for data analysis, visualization, and statistical modeling. R is open source, which means that it is freely available and can be modified by anyone.\nR has a number of features that make it ideal for data science. For example, it has a large and active community of users who contribute to the development of packages for data analysis, visualization, and modeling. These packages are available for download from the Comprehensive R Archive Network (CRAN) and cover a wide range of topics, including machine learning, time series analysis, data visualization, and more.\nAnother advantage of R is its ability to handle large datasets. R has a number of packages that allow users to read in and manipulate data from various sources, including databases, spreadsheets, and text files. It also has powerful data manipulation capabilities, such as reshaping data, merging datasets, and aggregating data.\nR is also widely used in academia and industry, particularly in fields such as finance, healthcare, and marketing. In academia, R is used in research and teaching in a variety of disciplines, including statistics, economics, and social sciences. In industry, R is used by companies for data analysis, modeling, and visualization, as well as for building data products.\nOverall, R is an important tool in the data scientistâ€™s toolbox, and its popularity continues to grow. It offers a wide range of capabilities for data analysis, visualization, and modeling, and has a large and active community of users and developers. If youâ€™re interested in data science, learning R is definitely worth considering.\n\n\n\n\nas an author of data science book, write a section on \"Use of R packages such as tidymodels for implementing machine learning algorithms\"\n\n\n\n\n\n\n\nchatGPT ë‹µë³€:\n\n\n\n\n\nSection: Use of R Packages such as tidymodels for Implementing Machine Learning Algorithms\nThe process of building machine learning models involves several steps such as data preparation, model training, validation, and testing. In R, there are several packages available that can help data scientists to perform these steps with ease. One of the popular packages for implementing machine learning models is tidymodels.\ntidymodels is an open-source collection of R packages designed for modeling and machine learning using the tidyverse style of programming. It provides a consistent framework for modeling that includes preprocessing, feature engineering, model tuning, and evaluation. Some of the important packages in tidymodels include:\n\ntidyverse: A collection of R packages for data wrangling, exploration, and visualization.\ndplyr: A package for data manipulation and transformation.\ntidyr: A package for data tidying and reshaping.\nggplot2: A package for creating visualizations.\ncaret: A package for building and evaluating machine learning models.\nrsample: A package for data splitting and resampling.\nparsnip: A package for model specification and tuning.\n\nThe tidymodels framework follows a consistent modeling pipeline, which includes the following steps:\n\nData preparation: In this step, data is loaded and preprocessed using various techniques such as imputation, scaling, and encoding.\nFeature engineering: This step involves creating new features from existing ones, selecting important features, and transforming features to meet the requirements of the model.\nModel specification: In this step, a machine learning model is selected and defined. The parsnip package provides a consistent interface for specifying models.\nModel tuning: This step involves tuning the modelâ€™s hyperparameters to optimize performance. The tune package provides various methods for model tuning.\nModel evaluation: In this step, the modelâ€™s performance is evaluated using various metrics such as accuracy, precision, and recall. The yardstick package provides various metrics for model evaluation.\n\nThe tidymodels framework provides a simple and intuitive way of building machine learning models in R. With the help of various packages, it simplifies the process of data preparation, feature engineering, model specification, tuning, and evaluation. This framework can be useful for data scientists working on various types of data science problems, from classification and regression to clustering and association rule mining."
  },
  {
    "objectID": "intro_paper.html",
    "href": "intro_paper.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 í•™ìˆ ì§€ ì˜ë¬¸ì´ˆë¡\nêµ­ë¬¸ í•™ìˆ ì§€ì— ë…¼ë¬¸ì„ ì‘ì„±í•  ë•Œ ê°€ì¥ í° ì• ë¡œì  ì¤‘ì— í•˜ë‚˜ê°€ ì˜ë¬¸ì´ˆë¡ìœ¼ë¡œ ì‘ì„±í•´ì•¼ ëœë‹¤ëŠ” ì ì´ë‹¤. ì œì£¼ëŒ€ ì•ˆë„í˜„ êµìˆ˜ë‹˜ì´ ê´€ë ¨í•˜ì—¬ ê³ í’ˆì§ˆ ì˜ë¬¸ì´ˆë¡ì„ ì‘ì„±í•  ìˆ˜ ìˆëŠ” ê¿€íŒì„ ì œì‹œí•˜ì—¬ SNSë¥¼ í†µí•´ ê³µê°œí•´ ì£¼ì…¨ìŠµë‹ˆë‹¤. ì‘ì—…íë¦„ê³¼ ê´€ë ¨ ì§€ì‹œëª…ë ¹ì–´(Prompt)ë„ ì „ë‹¬í•´ ì£¼ì…¨ìŠµë‹ˆë‹¤.\n\n\n\n\n\n\ní•™ìˆ ì§€ ì˜ë¬¸ì´ˆë¡ì„ ë”¥ì—˜ê³¼ ì±—ì§€í”¼í‹°ë¥¼ ì´ìš©í•˜ë©´ ì˜ë¬¸êµì • ë¶ˆí•„ìš”.\n\n\n\n\nêµ­ë¬¸ì´ˆë¡ ì‘ì„±\në”¥ì—˜ë¡œ êµ­ë¬¸ì„ ì˜ë¬¸ìœ¼ë¡œ ë²ˆì—­. DeepL\n\në²ˆì—­í•œ ì˜ë¬¸ì„ ChatGPTë¡œ ìœ¤ë¬¸.\n\n\ní”„ë¡¬í”„íŠ¸ì— ë‹¤ìŒê³¼ ê°™ì´ ì…ë ¥:\n\n\nRevise the abstract to follow APA style guidelines and ensure that it falls within the word count range of 400 to 500 words.\n\n\n\n\n2 ì‚¬ë¡€\n2020ë…„ ì¶œê°„ëœ ë…¼ë¬¸(ì´ê´‘ì¶˜, 2020)ì˜ í•œê¸€ ì´ˆë¡ì„ chatGPTì™€ DeepLì„ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ì œì‘ì— í™œìš©í•´ë³´ì.\n\në…¼ë¬¸ ì†ŒìŠ¤ì½”ë“œ: ë°”ë¡œê°€ê¸°\n\nPDF ì¶œíŒ ë…¼ë¬¸: ë‹¤ìš´ë¡œë“œ\n\n\n\n\ní•œê¸€ ì´ˆë¡\nì˜ë¬¸ ì´ˆë¡\nDeepL ì˜ì–´ë²ˆì—­\nchatGPT í”„ë¡¬í”„íŠ¸\nchatGPT ìœ¤ë¬¸\n\n\n\n\n\n\n\n\n\nì•ŒíŒŒê³ ê°€ 2016ë…„ ë°”ë‘‘ ì¸ê°„ ì±”í”¼ì–¸ ì´ì„¸ëŒ 9ë‹¨ì„ í˜„ê²©í•œ ê¸°ëŸ‰ì°¨ì´ë¡œ ê²©íŒŒí•˜ë©´ì„œ ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ ê´€ì‹¬ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ì˜€ë‹¤. ê·¸ì™€ ë™ì‹œì— ê¸°ê³„ê°€ ì¸ê°„ì˜ ì¼ìë¦¬ ì ì‹ì„ ê°€ì†í™”í•˜ë©´ì„œ ë§‰ì—°í•œ ë¶ˆì•ˆê°ì´ ì‚½ì‹œê°„ì— ì „íŒŒë˜ì—ˆë‹¤. ê¸°ê³„ì™€ì˜ ì¼ìë¦¬ ê²½ìŸì€ ì»´í“¨í„°ì˜ ì¶œí˜„ì´ì „ë¶€í„° ì‹œì‘ë˜ì—ˆì§€ë§Œ ì¸ê°„ë§Œì˜ ê³ ìœ í•œ ì˜ì—­ìœ¼ë¡œ ì•Œê³  ìˆë˜ ì¸ì§€, ì°½ì‘ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì˜¤íˆë ¤ ì¸ê°„ë³´ë‹¤ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ê³¼ ì €ë ´í•œ ê°€ê²© ê²½ìŸë ¥ì„ ë³´ì—¬ì£¼ë©´ì„œ ê¸°ì¡´ ì¸ê°„ì˜ ì¼ìë¦¬ê°€ ê¸°ê³„ì— ëŒ€ì²´ë˜ëŠ” ê²ƒì´ ê°€ì‹œê¶Œì— ë“¤ì—ˆë‹¤. ì´ë²ˆ ë¬¸í—Œì¡°ì‚¬ì™€ ì‹¤ì¦ ë°ì´í„° ë¶„ì„ì„ í†µí•´ì„œ ê¸°ê³„ê°€ ì¸ê°„ì˜ ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•˜ëŠ” ìë™í™”ì˜ ë³¸ì§ˆì— ëŒ€í•´ì„œ ì‚´í´ë³´ê³ , ì¸ê°„ê³¼ ê¸°ê³„ì˜ ì—…ë¬´ ë¶„ì¥ì„ í†µí•´ ë” ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ì œì‹œí•˜ê³ ì í•œë‹¤.\n\n\n\n\n\n\n\n\n\n\n\nMachines have been used simply for arithmetic operations and documentation. However, with the development of technology, a new generation of artificial intelligence has begun. Machines are not just tools that can be calculated, but they have been commercialized in various fields, such as natural language processing technology that can understand and communicate human language, or video fields, where human dependence was high. Since 2016, the AI game, â€œAlphago,â€ has defeated Lee Se-dol with a significant difference in skill, interest in AI has increased sharply. Machines have started to replace human jobs because of their excellent performance, low cost and competitive edge. In this paper, I would like to present a plan on how to use artificial intelligence to affect human jobs and how to improve productivity effectively by cooperating with machines and humans in the future.\n\n\n\n\n\n\n\n\n\n\n\nInterest in artificial intelligence skyrocketed in 2016 when AlphaGo defeated human Go champion Lee Sedol 9 by a stunning margin. At the same time, a vague sense of anxiety was quickly spread as machines accelerated the erosion of human jobs. Although the competition for jobs with machines began before the advent of computers, the replacement of existing human jobs by machines became visible as machines showed better performance and lower price competitiveness than humans in various fields such as cognition and creation, which were thought to be unique to humans. Through this literature review and empirical data analysis, we examine the nature of automation in which machines replace human jobs. and suggest ways to increase productivity through the division of labor between humans and machines.\nTranslated with www.DeepL.com/Translator (free version)\n\n\n\n\n\n\n\n\n\n\n\nRevise the abstract to follow APA style guidelines and ensure that it falls within the word count range of 400 to 500 words.\nInterest in artificial intelligence skyrocketed in 2016 when AlphaGo defeated human Go champion Lee Sedol 9 by a stunning margin. At the same time, a vague sense of anxiety was quickly spread as machines accelerated the erosion of human jobs. Although the competition for jobs with machines began before the advent of computers, the replacement of existing human jobs by machines became visible as machines showed better performance and lower price competitiveness than humans in various fields such as cognition and creation, which were thought to be unique to humans. Through this literature review and empirical data analysis, we examine the nature of automation in which machines replace human jobs. and suggest ways to increase productivity through the division of labor between humans and machines.\n\n\n\n\n\n\n\n\n\n\n\nThe rise of artificial intelligence (AI) has garnered significant attention since 2016 when AlphaGo, an AI program, defeated the human Go champion Lee Sedol. However, the growing use of machines in various fields has also fueled concerns about the displacement of human jobs. This paper presents a literature review and empirical data analysis to explore the nature of automation and suggest ways to enhance productivity by optimizing the division of labor between humans and machines.\nWhile machines have been replacing human jobs for centuries, the rapid development of AI has made it possible for machines to outperform humans in fields previously considered uniquely human, such as cognition and creation. As a result, there is a growing awareness of the impact of automation on employment opportunities. This paper aims to provide insights into this issue through a comprehensive review of relevant literature and analysis of empirical data.\nOur analysis indicates that automation can lead to the displacement of jobs that require low-level skills, but it can also create new opportunities that require higher-level skills. Furthermore, automation can enhance productivity and lower costs, thus benefiting both consumers and firms. Therefore, there is a need to strike a balance between the potential benefits and challenges of automation.\nTo maximize the advantages of automation, we propose an optimal division of labor between humans and machines. In this approach, humans are responsible for tasks that require creativity, emotional intelligence, and social skills, while machines are responsible for tasks that require precision and efficiency. This approach can lead to better job quality and increased productivity.\nIn conclusion, this paper highlights the potential impact of automation on employment and the need to optimize the division of labor between humans and machines. While automation can lead to job displacement, it can also create new opportunities and improve job quality. Therefore, policymakers and firms must consider ways to optimize the use of automation to benefit both society and the economy.\n\n\n\n\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nì´ê´‘ì¶˜ì£¼ìš©ìš°. (2020). ì‚¬ëŒê³¼ ì¸ê³µì§€ëŠ¥ì˜ ì¼ìë¦¬ ê²½ìŸ ìš”ì¸ê³¼ í˜‘ì—… ë°©ì•ˆ. ë””ì§€í„¸ê²½ì˜ì—°êµ¬ Vol.6 No.2 pp.39-50."
  },
  {
    "objectID": "middle_school.html",
    "href": "middle_school.html",
    "title": "chatGPT",
    "section": "",
    "text": "ë°ì´í„° ë¬¸í•´ë ¥ì— â€œì¤‘í•™ìˆ˜í•™ - ì—°ë¦½ë°©ì •ì‹â€ ì‚¬ë¡€ë¥¼ í†µí•´ ì ìš© ë°©í–¥ì„ ì‚´í´ë³´ì."
  },
  {
    "objectID": "trends.html#íŠ¸ìœ„í„°-ìƒŒí‹°ì•„ê³ ",
    "href": "trends.html#íŠ¸ìœ„í„°-ìƒŒí‹°ì•„ê³ ",
    "title": "chatGPT",
    "section": "\n6.1 íŠ¸ìœ„í„° ìƒŒí‹°ì•„ê³ ",
    "text": "6.1 íŠ¸ìœ„í„° ìƒŒí‹°ì•„ê³ \nSantiago @svpino"
  },
  {
    "objectID": "trends.html#ë²„ìŠ¤íƒ„-ë‘ë‚¨ì",
    "href": "trends.html#ë²„ìŠ¤íƒ„-ë‘ë‚¨ì",
    "title": "chatGPT",
    "section": "\n6.2 ë²„ìŠ¤íƒ„ ë‘ë‚¨ì",
    "text": "6.2 ë²„ìŠ¤íƒ„ ë‘ë‚¨ì"
  },
  {
    "objectID": "trends.html#gpt-3-ì–¸ì–´-ë°ì´í„°-fa-solid-brain",
    "href": "trends.html#gpt-3-ì–¸ì–´-ë°ì´í„°-fa-solid-brain",
    "title": "chatGPT",
    "section": "\n2.2 GPT-3 ì–¸ì–´ ë°ì´í„° \n",
    "text": "2.2 GPT-3 ì–¸ì–´ ë°ì´í„° \n\nGPT-3 ê°œë°œì— íˆ¬ì…ëœ ë¬¸ì„œê°¯ìˆ˜ë¥¼ ì–¸ì–´ë³„ë¡œ ì‚´í´ë³´ì.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(gt)\nlibrary(countrycode)\nlibrary(rvest)\nlibrary(gtExtras)\n\n## ì–¸ì–´ ì½”ë“œ \nlang_tbl <- read_html(x = 'http://www.lingoes.net/en/translator/langcode.htm') %>% \n  html_element(css = 'body > table') %>% \n  html_table() %>% \n  set_names(c(\"ì–¸ì–´\", \"ì–¸ì–´ëª…\"))\n\n\ngpt_raw <- read_csv(\"https://raw.githubusercontent.com/openai/gpt-3/master/dataset_statistics/languages_by_document_count.csv\")\n\ngpt_tbl <- gpt_raw %>% \n  set_names(c(\"ì–¸ì–´\", \"ë¬¸ì„œìˆ˜\", \"ë¹„ì¤‘\")) %>% \n  mutate(ë¹„ì¤‘ = parse_number(ë¹„ì¤‘) / 100) %>% \n  mutate(ëˆ„ì ë¬¸ì„œ = cumsum(ë¬¸ì„œìˆ˜)) %>% \n  mutate(ëˆ„ì ë¹„ì¤‘ = ëˆ„ì ë¬¸ì„œ / sum(ë¬¸ì„œìˆ˜)) %>% \n  top_n(ë¬¸ì„œìˆ˜, n = 28)  \n\ngpt_gt <- gpt_tbl %>% \n  left_join(lang_tbl, by = \"ì–¸ì–´\") %>% \n  select(ì–¸ì–´, ì–¸ì–´ëª…, ë¬¸ì„œìˆ˜, ë¹„ì¤‘, ëˆ„ì ë¹„ì¤‘) %>% \n  ## í‘œ \n  gt() %>% \n    gt_theme_nytimes() %>%\n    tab_options(table.width = pct(100))  %>%\n    tab_header(\n      title = md(\"**GPT-3 ì–¸ì–´ëª¨í˜• ê°œë°œì— ì‚¬ìš©ëœ ì–¸ì–´ë³„ ë¬¸ì„œ í†µê³„**\"),\n      subtitle = \"í•œêµ­ì–´ í¬í•¨ ìƒìœ„ 28ê°œ ì–¸ì–´\") %>% \n    tab_source_note(\n      source_note = \"ìë£Œì¶œì²˜: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\") %>% \n    tab_spanner(\n      label = \"ì–¸ì–´ì½”ë“œì™€ ì–¸ì–´ëª…\",\n      columns = c(ì–¸ì–´, ì–¸ì–´ëª…)) %>% \n    tab_spanner(\n      label = \"í†µê³„ìˆ˜ì¹˜\",\n      columns = c(ë¬¸ì„œìˆ˜, ë¹„ì¤‘, ëˆ„ì ë¹„ì¤‘)) %>% \n    cols_align(\n      align = \"center\",\n      columns = c(ì–¸ì–´, ì–¸ì–´ëª…)) %>% \n    # tab_style(\n    #   style = cell_text(size = px(12)),\n    #   locations = cells_body(\n    #     columns = c(ë¬¸ì„œìˆ˜, ë¹„ì¤‘, ëˆ„ì ë¹„ì¤‘)\n    #   )\n    # )  %>% \n    fmt_percent(\n      columns = c(ë¹„ì¤‘, ëˆ„ì ë¹„ì¤‘),\n      decimals = 2\n    )  %>% \n    fmt_number(\n      columns = ë¬¸ì„œìˆ˜,\n      decimals = 0,\n      sep_mark = \",\"\n    )   %>% \n   gt_highlight_rows(\n     rows = c(1,28),\n     fill = \"lightgrey\",\n     target_col = ì–¸ì–´\n   )  %>% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  )  %>% \n  cols_width(\n    ì–¸ì–´ ~ px(10),\n    ì–¸ì–´ëª… ~ px(10),\n    ë¬¸ì„œìˆ˜ ~ px(20),\n    ë¹„ì¤‘ ~ px(30),\n    ëˆ„ì ë¹„ì¤‘ ~ px(30)\n  )\n\ngpt_gt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-3 ì–¸ì–´ëª¨í˜• ê°œë°œì— ì‚¬ìš©ëœ ì–¸ì–´ë³„ ë¬¸ì„œ í†µê³„\n    \n\ní•œêµ­ì–´ í¬í•¨ ìƒìœ„ 28ê°œ ì–¸ì–´\n    \n\n\n\n\n        ì–¸ì–´ì½”ë“œì™€ ì–¸ì–´ëª…\n      \n      \n        í†µê³„ìˆ˜ì¹˜\n      \n    \n\nì–¸ì–´\n      ì–¸ì–´ëª…\n      ë¬¸ì„œìˆ˜\n      ë¹„ì¤‘\n      ëˆ„ì ë¹„ì¤‘\n    \n\n\n\nen\nEnglish\n235,987,420\n93.69%\n93.69%\n\n\nde\nGerman\n3,014,597\n1.20%\n94.89%\n\n\nfr\nFrench\n2,568,341\n1.02%\n95.91%\n\n\npt\nPortuguese\n1,608,428\n0.64%\n96.54%\n\n\nit\nItalian\n1,456,350\n0.58%\n97.12%\n\n\nes\nSpanish\n1,284,045\n0.51%\n97.63%\n\n\nnl\nDutch\n934,788\n0.37%\n98.00%\n\n\npl\nPolish\n632,959\n0.25%\n98.25%\n\n\nja\nJapanese\n619,582\n0.25%\n98.50%\n\n\nda\nDanish\n396,477\n0.16%\n98.66%\n\n\nno\n-\n379,239\n0.15%\n98.81%\n\n\nro\nRomanian\n320,256\n0.13%\n98.94%\n\n\nfi\nFinnish\n315,228\n0.13%\n99.06%\n\n\nzh\nChinese\n292,976\n0.12%\n99.18%\n\n\nru\nRussian\n289,121\n0.11%\n99.29%\n\n\ncs\nCzech\n243,802\n0.10%\n99.39%\n\n\nsv\nSwedish\n161,516\n0.06%\n99.45%\n\n\nhu\nHungarian\n149,584\n0.06%\n99.51%\n\n\nzh-Hant\n-\n107,588\n0.04%\n99.55%\n\n\nid\nIndonesian\n104,437\n0.04%\n99.60%\n\n\nhr\nCroatian\n100,384\n0.04%\n99.64%\n\n\ntr\nTurkish\n91,414\n0.04%\n99.67%\n\n\nca\nCatalan\n80,899\n0.03%\n99.70%\n\n\nvi\nVietnamese\n69,147\n0.03%\n99.73%\n\n\nsl\nSlovenian\n66,333\n0.03%\n99.76%\n\n\net\nEstonian\n56,643\n0.02%\n99.78%\n\n\nsk\nSlovak\n52,826\n0.02%\n99.80%\n\n\nko\nKorean\n48,852\n0.02%\n99.82%\n\n\n\nìë£Œì¶œì²˜: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\n    \n\n\n\nì½”ë“œ\n# gpt_gt %>%\n#   gtsave(\"images/gpt_lang.png\")"
  },
  {
    "objectID": "trends.html#ì¸í„°ë„·-ì–¸ì–´-ë°ì´í„°-fa-solid-globe",
    "href": "trends.html#ì¸í„°ë„·-ì–¸ì–´-ë°ì´í„°-fa-solid-globe",
    "title": "chatGPT",
    "section": "\n2.2 ì¸í„°ë„· ì–¸ì–´ ë°ì´í„° \n",
    "text": "2.2 ì¸í„°ë„· ì–¸ì–´ ë°ì´í„° \n\nGPT ê°œë°œì— ìì›ì— í•´ë‹¹ë˜ëŠ” ì–¸ì–´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì‚´í´ë³´ì. ìœ„í‚¤ë°±ê³¼ Languages used on the Internetì—ì„œ ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ì. íŠ¹íˆ, ì›¹ì‚¬ì´íŠ¸ ì œì‘ì— ì‚¬ìš©ëœ ì–¸ì–´ë¥¼ ë¹„ì¤‘ìœ¼ë¡œ ì‚´í´ë³´ì.\n\nì½”ë“œ## ì–¸ì–´ ì½˜í…ì¸ \ncontents_raw <- read_html(x = 'https://en.wikipedia.org/wiki/Languages_used_on_the_Internet') %>% \n  html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[1]') %>% \n  html_table() %>% \n  set_names(c(\"ìˆœìœ„\", \"ì–¸ì–´\", \"ë¹„ì¤‘\"))\n\ncontents_tbl <- contents_raw %>% \n  mutate(ë¹„ì¤‘ = parse_number(ë¹„ì¤‘)) %>% \n  ## ëŒ€í•œë¯¼êµ­ ì´í•˜ ê¸°íƒ€ ------------\n  mutate(ì–¸ì–´ = ifelse(ìˆœìœ„ >=17, \"ê¸°íƒ€\", ì–¸ì–´)) %>% \n  group_by(ì–¸ì–´) %>% \n  summarise(ë¹„ì¤‘ = sum(ë¹„ì¤‘)) %>% \n  ungroup() %>% \n  arrange(desc(ë¹„ì¤‘))\n\ncontents_gt <- contents_tbl %>% \n  ## í‘œ \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_header(\n      title = md(\"**ì¸í„°ë„· ì½˜í…ì¸  ìƒìœ„ ì–¸ì–´ë³„ í†µê³„**\"),\n      subtitle = \"í•œêµ­ì–´ í¬í•¨ ìƒìœ„ 17ê°œ ì–¸ì–´\") %>% \n    tab_source_note(\n      source_note = \"ìë£Œì¶œì²˜: https://en.wikipedia.org/wiki/Languages_used_on_the_Internet\") %>% \n    cols_align(\n      align = \"center\",\n      columns = c(ì–¸ì–´)) %>% \n    fmt_number(\n      columns = c(ë¹„ì¤‘),\n      decimals = 1\n    ) %>% \n    cols_label(\n      ë¹„ì¤‘ = \"ë¹„ì¤‘(%)\"\n    )  %>% \n    tab_footnote(\n      footnote = \"í•œêµ­ì–´ë³´ë‹¤ ë¹„ì¤‘ì´ ë‚®ì€ ì¸ë„ë„¤ì´ì‚¬, ì²´ì½”, ìš°í¬ë¼ì´ë‚˜ ë“±\",\n      locations = cells_body(columns = ì–¸ì–´, rows = 2)\n    )  \n\ncontents_gt %>% \n  gtsave(\"images/contents_gt.png\")"
  },
  {
    "objectID": "trends.html#ì¸í„°ë„·-ë°ì´í„°-fa-solid-globe",
    "href": "trends.html#ì¸í„°ë„·-ë°ì´í„°-fa-solid-globe",
    "title": "chatGPT",
    "section": "\n2.1 ì¸í„°ë„· ë°ì´í„° \n",
    "text": "2.1 ì¸í„°ë„· ë°ì´í„° \n\nGPT ê°œë°œì— ìì›ì— í•´ë‹¹ë˜ëŠ” ì–¸ì–´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì‚´í´ë³´ì. ìœ„í‚¤ë°±ê³¼ Languages used on the Internetì—ì„œ ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ì. íŠ¹íˆ, ì›¹ì‚¬ì´íŠ¸ ì œì‘ì— ì‚¬ìš©ëœ ì–¸ì–´ë¥¼ ë¹„ì¤‘ìœ¼ë¡œ ì‚´í´ë³´ì.\n\nì½”ë“œ## ì–¸ì–´ ì½˜í…ì¸ \ncontents_raw <- read_html(x = 'https://en.wikipedia.org/wiki/Languages_used_on_the_Internet') %>% \n  html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[1]') %>% \n  html_table() %>% \n  set_names(c(\"ìˆœìœ„\", \"ì–¸ì–´\", \"ë¹„ì¤‘\"))\n\ncontents_tbl <- contents_raw %>% \n  mutate(ë¹„ì¤‘ = parse_number(ë¹„ì¤‘)) %>% \n  ## ëŒ€í•œë¯¼êµ­ ì´í•˜ ê¸°íƒ€ ------------\n  mutate(ì–¸ì–´ = ifelse(ìˆœìœ„ >=17, \"ê¸°íƒ€\", ì–¸ì–´)) %>% \n  group_by(ì–¸ì–´) %>% \n  summarise(ë¹„ì¤‘ = sum(ë¹„ì¤‘)) %>% \n  ungroup() %>% \n  arrange(desc(ë¹„ì¤‘))\n\ncontents_gt <- contents_tbl %>% \n  ## í‘œ \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_options(table.width = pct(75))  %>% \n    tab_header(\n      title = md(\"**ì¸í„°ë„· ì½˜í…ì¸  ìƒìœ„ ì–¸ì–´ë³„ í†µê³„**\"),\n      subtitle = \"í•œêµ­ì–´ í¬í•¨ ìƒìœ„ 17ê°œ ì–¸ì–´\") %>% \n    tab_source_note(\n      source_note = \"ì¶œì²˜:https://en.wikipedia.org/wiki/Languages_used_on_the_Internet\") %>% \n    cols_align(\n      align = \"center\",\n      columns = c(ì–¸ì–´, ë¹„ì¤‘)) %>% \n    fmt_number(\n      columns = c(ë¹„ì¤‘),\n      decimals = 1\n    ) %>% \n    cols_label(\n      ë¹„ì¤‘ = \"ë¹„ì¤‘(%)\"\n    )  %>% \n    tab_footnote(\n      footnote = \"í•œêµ­ì–´ë³´ë‹¤ ë¹„ì¤‘ì´ ë‚®ì€ ì¸ë„ë„¤ì´ì‚¬, ì²´ì½”, ìš°í¬ë¼ì´ë‚˜ ë“±\",\n      locations = cells_body(columns = ì–¸ì–´, rows = 2)\n    )  \n\ncontents_gt %>% \n  gtsave(\"images/contents_gt.png\")"
  },
  {
    "objectID": "architecture.html#openai",
    "href": "architecture.html#openai",
    "title": "chatGPT",
    "section": "\n5.1 OpenAI",
    "text": "5.1 OpenAI\n\n\n\n\nCBInsights, â€œAnalyzing OpenAIâ€™s investment strategy: How the ChatGPT maker is building a generative AI ecosystemâ€"
  },
  {
    "objectID": "architecture.html#ê¸€ë¡œë²Œ-ìŠ¤íƒ€íŠ¸ì—…",
    "href": "architecture.html#ê¸€ë¡œë²Œ-ìŠ¤íƒ€íŠ¸ì—…",
    "title": "chatGPT",
    "section": "\n5.2 ê¸€ë¡œë²Œ ìŠ¤íƒ€íŠ¸ì—…",
    "text": "5.2 ê¸€ë¡œë²Œ ìŠ¤íƒ€íŠ¸ì—…"
  },
  {
    "objectID": "architecture.html#ë„¤ì´ë²„",
    "href": "architecture.html#ë„¤ì´ë²„",
    "title": "chatGPT",
    "section": "\n5.3 ë„¤ì´ë²„",
    "text": "5.3 ë„¤ì´ë²„\nì„±í˜„í¬ (2022-11-04), â€œë„¤ì´ë²„ AI ì‚¬ìš©ì— 1000ê°œ ì¤‘ì†Œ ê¸°ì—… â€˜ë…¸í¬â€™â€, ì „ìì‹ ë¬¸\në„¤ì´ë²„ëŠ” â€™í´ë¡œë°” ìŠ¤íŠœë””ì˜¤â€™ë¥¼ ë‹¤ì–‘í•œ ìŠ¤íƒ€íŠ¸ì—…ì´ í™œìš©í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ ì¶œì‹œí•˜ê³  ìˆë‹¤.\n\n\n\n\n\ngraph TD\n    A[\"ëŒ€í•œë¯¼êµ­\"] --> B((\"ë„¤ì´ë²„\"))\n    B ----> E[ì¡ë¸Œë ˆì¸]\n    B ----> H[ë¼ì´íŒ…ì ¤]\n    B --> C[ëª¨ì¹´]\n    B --> D[ë¤¼íŠ¼] \n    B --> F[í‚µê·¸ë¡œìš°]\n    style B fill:#FF6655AA\n    style F fill:#88ffFF\n    style I fill:#88ffFF\n\n\n\n\n\n\n\n\n\nì„í”Œë¡œì´ë©ìŠ¤ì¡ ë¸Œë ˆì¸(Job Brain): AI ìì†Œì„œ ìƒì„± ê¸°ëŠ¥ì— ì ìš©, ì™„ì„±ë„ ë†’ì€ ìì†Œì†Œ\nì•±í”Œë«í¼ ë¼ì´íŒ…ì ¤: ëŒ€ì… ì·¨ì—… ìì†Œì„œ ìë™ì™•ì„± ê¸°ëŠ¥ì— ì ìš©\nì•„ìŠ¤íƒ€ ì»´í¼ë‹ˆ ëª¨ì¹´: ìƒí’ˆì–¸ì–´, ê´‘ê³  í—¤ë“œë¼ì¸, ì„¸ì¼ì¦ˆ ì¹´í”¼ ìƒì„± ê¸°ëŠ¥ì— í™œìš©\në¤¼íŠ¼í…Œí¬ë†€ë¡œì§€ ë¤¼íŠ¼: ê´‘ê³ ì¹´í”¼, ì œí’ˆì†Œê°œ ë¬¸êµ¬ ë“± AI ì¹´í”¼ë¼ì´íŒ… ì„œë¹„ìŠ¤ì— í™œìš©\nìœ ë‹ˆíŠ¸ì»´ì¦ˆ í‚µê·¸ë¡œìš°: ê³ ê°ì‚¬ ì¸ìŠ¤íƒ€ê·¸ë¨ì— ê²Œì‹œë¬¼ì„ ì£¼ê¸°ì ìœ¼ë¡œ í¬ìŠ¤íŒ…í•´ì£¼ëŠ” ê¸°ëŠ¥ì— ì ìš©"
  },
  {
    "objectID": "trends.html#ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "href": "trends.html#ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "title": "chatGPT",
    "section": "\n7.2 ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "text": "7.2 ë§ˆì´í¬ë¡œì†Œí”„íŠ¸\n\n\n\n\n\n\n\n\nì‹ ê·œ ì½”ë“œì˜ 40%ê°€ Copilotìœ¼ë¡œ ì‘ì„±\n\n75%ì˜ ê°œë°œìê°€ ì—…ë¬´ì— ë” í° ì„±ì·¨ê°ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.\n\n87%ì˜ ê°œë°œìê°€ ì •ì‹ ì  ë…¸ë ¥ì„ ì ˆì•½í•˜ëŠ” ë° ë„ì›€ì´ ë˜ì—ˆë‹¤ê³  ë‹µí–ˆìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "trends.html#í˜„ëŒ€ë°±í™”ì ",
    "href": "trends.html#í˜„ëŒ€ë°±í™”ì ",
    "title": "chatGPT",
    "section": "\n7.1 í˜„ëŒ€ë°±í™”ì ",
    "text": "7.1 í˜„ëŒ€ë°±í™”ì \ní˜„ëŒ€ë°±í™”ì  ê´€ê³„ìëŠ” â€œì´ ë‹¬ ì´ˆë¶€í„° 2ì£¼ê°„ ì‹œí–‰í•œ ê´€ë ¨ ë¶€ì²˜ í…ŒìŠ¤íŠ¸ì—ì„œ í†µìƒ 2ì£¼ê°€ëŸ‰ ì†Œìš”ë˜ë˜ ì¹´í”¼ë¼ì´íŒ… ì—…ë¬´ì‹œê°„ì´ ë£¨ì´ìŠ¤ ë„ì… ë’¤ í‰ê·  3~4ì‹œê°„ìœ¼ë¡œ ì¤„ì—ˆë‹¤â€\nìœ ì„ í¬ (2023-02-26), ê´‘ê³  ì¹´í”¼ë„ AIê°€ ì“´ë‹¤â€¦í˜„ëŒ€ë°±í™”ì  â€˜ë£¨ì´ìŠ¤â€™ ì‹œìŠ¤í…œ ë„ì…, í•œê²¨ë ˆì‹ ë¬¸\ní˜„ëŒ€ë°±í™”ì ì´ ê´‘ê³  ì¹´í”¼ì™€ íŒì´‰í–‰ì‚¬ ì†Œê°œë¬¸ ë“± ë§ˆì¼€íŒ… ë¬¸êµ¬ ì œì‘ì„ ìœ„í•´ íŠ¹ë³„íˆ â€™ê³ ìš©â€™í•œ ì¸ê³µì§€ëŠ¥(AI) ì¹´í”¼ë¼ì´íŒ… ì‹œìŠ¤í…œì€ ë„¤ì´ë²„ â€™í•˜ì´ë²„í´ë¡œë°”â€™ë¥¼ ê¸°ë³¸ ì—”ì§„ìœ¼ë¡œ ì¶”ê°€í•™ìŠµ(ìµœê·¼ 3ë…„ ë™ì•ˆ ì‚¬ìš©í•œ ê´‘ê³  ì¹´í”¼, íŒì´‰í–‰ì‚¬ì—ì„œ ì“´ ë¬¸êµ¬ ì¤‘ ì†Œë¹„ì í˜¸ì‘ì´ ì»¸ë˜ ë°ì´í„° 1ë§Œì—¬ê±´ì„ ì§‘ì¤‘ì ìœ¼ë¡œ í•™ìŠµ)í•˜ì—¬ ê°œë°œ\n\n\nAI ì§ì›\ní™œìš©í™”ë©´\në£¨ì´ìŠ¤"
  },
  {
    "objectID": "trends.html#ì´ë¯¸ì§€",
    "href": "trends.html#ì´ë¯¸ì§€",
    "title": "chatGPT",
    "section": "\n7.3 ì´ë¯¸ì§€",
    "text": "7.3 ì´ë¯¸ì§€\n\n\n\n\nì›¹íˆ°ì„ ì œì‘í•˜ëŠ” ìŠ¤íŠœë””ì˜¤ì—ì„œëŠ” ì›¹íˆ° ì‘ê°€ë“¤ê³¼ ì–´ì‹œìŠ¤íŠ¸ë“¤ì´ ë§¤ìš° ë…¸ë™ì§‘ì•½ì ì¸ ì‘ì—…ìœ¼ë¡œ ì°½ì‘í™œë™ì„ í•˜ê³  ìˆë‹¤. í˜„ì¬ ì›¹íˆ° ì œì‘ ê³µì •ì€ ì½˜í‹°, ìŠ¤ì¼€ì¹˜, ë¼ì¸(íœì„ ), ì±„ìƒ‰, ë°°ê²½, ì¶œíŒ ì‘ì—…ì˜ ìˆœì„œë¡œ ì´ë¤„ì§„ë‹¤. í•œêµ­ë§Œí™”ì˜ìƒì§„í¥ì›ê³¼ í˜‘ë ¥í•˜ëŠ” ì‹¤ì œ ì›¹íˆ° ì‘ê°€ë“¤ì€ íŠ¹ì •ì‘ì—…ì´ ì•„ë‹Œ ëª¨ë“  ê³µì •ì—ì„œ ì œì‘ ìƒì‚°ì„± í–¥ìƒì„ ìœ„í•œ ìë™í™” ê¸°ìˆ ì´ í•„ìš”í•˜ë‹¤ëŠ” ê²°ë¡ ì— ë„ë‹¬í•¨. (ê¹€í˜„ì§„, 2021)"
  },
  {
    "objectID": "trends.html#ê³µìƒê³¼í•™ì†Œì„¤",
    "href": "trends.html#ê³µìƒê³¼í•™ì†Œì„¤",
    "title": "chatGPT",
    "section": "\n8.1 ê³µìƒê³¼í•™ì†Œì„¤",
    "text": "8.1 ê³µìƒê³¼í•™ì†Œì„¤\nê³µìƒê³¼í•™ ë° íŒíƒ€ì§€ ì¡ì§€ í´ë¼í¬ìŠ¤ì›”ë“œ(Clarkesworld)ëŠ” AIê°€ ìƒì„±í•œ ì†Œì„¤ë¼ëŠ” ë¹„ë‚œì„ ë°›ì€ í›„ ì‹ ê·œ ê³µìƒê³¼í•™ì†Œì„¤ì´ ê¸‰ì¦í•œ ê²ƒì´ AI ê¸°ê³„ë¡œ ì‘ì„±ëœ ì›ì¸ì„ í° ê²ƒìœ¼ë¡œ íŒŒì•…í•˜ê³  2ì›” 20ì¼ë¶€í„° ê³µì‹ì ìœ¼ë¡œ íˆ¬ê³ ë¥¼ ì¤‘ë‹¨í–ˆë‹¤.\nNeil Clark (2023-02-15), â€œA Concerning Trendâ€, CLARKESWORLD MAGAZINE\n\n\n\n\n2023-02-15 ê¸°ì¤€\n\n\n\n\n2023-02-20 ê¸°ì¤€"
  },
  {
    "objectID": "image2image.html#chatgpt-í”„ë¡¬í”„íŠ¸",
    "href": "image2image.html#chatgpt-í”„ë¡¬í”„íŠ¸",
    "title": "chatGPT",
    "section": "\n2.1 chatGPT í”„ë¡¬í”„íŠ¸",
    "text": "2.1 chatGPT í”„ë¡¬í”„íŠ¸\nrecommend the most famous painting style in history\n\n\n\n\n\n\ncompletion\n\n\n\n\n\nHere are some of the most famous painting styles in history:\n\nRenaissance: The Renaissance was a cultural movement in Italy from the 14th to the 17th century, characterized by a renewed interest in classical art, philosophy, and science. Renaissance paintings are known for their realism, balance, and harmony.\nBaroque: The Baroque style was popular in Europe from the late 16th to the early 18th century. Baroque paintings are known for their dramatic lighting, intense emotions, and dynamic compositions.\nImpressionism: Impressionism was a modernist movement in French painting in the late 19th century. Impressionist paintings are known for their loose brushstrokes, light-filled compositions, and focus on capturing fleeting moments.\nSurrealism: Surrealism was a cultural movement in the 20th century that aimed to liberate the imagination and explore the subconscious. Surrealist paintings are known for their dreamlike and fantastical imagery.\nAbstract Expressionism: Abstract Expressionism was a modernist movement in American painting in the mid-20th century. Abstract Expressionist paintings are known for their large canvases, gestural brushstrokes, and emphasis on the process of creation.\n\nThese are just a few examples of famous painting styles in history. There are many other styles that have influenced and shaped the course of art history.\n\n\n\nOpen AI - Create image API"
  },
  {
    "objectID": "image2image.html#í™”í’ì„-ë‹¬ë¦¬í•œ-ê·¸ë¦¼",
    "href": "image2image.html#í™”í’ì„-ë‹¬ë¦¬í•œ-ê·¸ë¦¼",
    "title": "chatGPT",
    "section": "\n2.2 í™”í’ì„ ë‹¬ë¦¬í•œ ê·¸ë¦¼",
    "text": "2.2 í™”í’ì„ ë‹¬ë¦¬í•œ ê·¸ë¦¼\n\n\në¥´ë„¤ìƒìŠ¤(Renaissance)\në°”ë¡œí¬(Baroque)\nì¸ìƒì£¼ì˜(Impressionism)\nì´ˆí˜„ì‹¤ì£¼ì˜(Surrealism)\nì¶”ìƒí‘œí˜„ì£¼ì˜(Abstract Expressionism)\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance <- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\në¥´ë„¤ìƒìŠ¤(Renaissance)\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque <- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\në°”ë¡œí¬(Baroque)\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism <- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\nì¸ìƒì£¼ì˜(Impressionism)\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism <- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\nì´ˆí˜„ì‹¤ì£¼ì˜(Surrealism)\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism <- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")\n\n\n\n\nì¶”ìƒí‘œí˜„ì£¼ì˜(Abstract Expressionism)"
  },
  {
    "objectID": "rcoding.html#ì„¤ì¹˜",
    "href": "rcoding.html#ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "\n2.1 ì„¤ì¹˜",
    "text": "2.1 ì„¤ì¹˜\ngpttools GitHub ì €ì¥ì†Œì—ì„œ ë°”ë¡œ ì„¤ì¹˜í•œë‹¤.\nrequire(remotes)\nremotes::install_github(\"JamesHWade/gpttools\")"
  },
  {
    "objectID": "rcoding-copilot.html",
    "href": "rcoding-copilot.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 GitHub Copilot\nGitHub Copilotì€ Visual Studio Codeë¥¼ ë¹„ë¡¯í•œ ë‹¤ì–‘í•œ ì½”ë“œ í¸ì§‘ê¸°ì™€ í†µí•©í•  ìˆ˜ ìˆëŠ” AI ê¸°ë°˜ ì½”ë”© ë„ìš°ë¯¸(Assistant)ì…ë‹ˆë‹¤. Copilotì€ ê°œë°œìê°€ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì •í™•í•˜ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ì§€ëŠ¥í˜• ë„ìš°ë¯¸ ê¸°ëŠ¥ ì œê³µí•˜ê¸° ìœ„í•´ GitHubì™€ OpenAIê°€ ê³µë™ìœ¼ë¡œ ê°œë°œí–ˆìŠµë‹ˆë‹¤.\nCopilotì€ ë¨¸ì‹  ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ ê°œë°œìê°€ ì‘ì„±í•œ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  í•™ìŠµí•œ ë‹¤ìŒ í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì— ì‚½ì…í•  ìˆ˜ ìˆëŠ” ì œì•ˆ ë° ì½”ë“œ ì¡°ê°ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ë°©ëŒ€í•œ ì½”ë“œ ì½”í¼ìŠ¤ë¥¼ í•™ìŠµí•œ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ê°œë°œìê°€ ì‘ì„±í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë‹¤ìŒ ì½”ë“œ ì¤„ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\nì´ ê¸°ìˆ ì„ í†µí•´ Copilotì€ í˜„ì¬ ì½”ë“œì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ í•¨ìˆ˜ ë˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì œì•ˆí•˜ê³  êµ¬ë¬¸ì ìœ¼ë¡œ ì •í™•í•˜ê³  ëª¨ë²” ì‚¬ë¡€ë¥¼ ì¤€ìˆ˜í•˜ëŠ” ì½”ë“œë¥¼ ìƒì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Copilotì€ ìƒì„±í•˜ëŠ” ì½”ë“œì˜ ì˜ë¯¸ì™€ ëª©ì ì„ ì´í•´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ ë§Œë“¤ê±°ë‚˜ ë¬¸ì œì— ëŒ€í•œ ë‹¤ì–‘í•œ í•´ê²°ì±…ì„ ëª¨ìƒ‰í•´ì•¼ í•˜ëŠ” ê°œë°œìì—ê²Œ ìœ ìš©í•œ ë„êµ¬ì…ë‹ˆë‹¤.\nGitHub Copilotì€ Python, JavaScript, TypeScript, Ruby, Go, R ë“± ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ ì›í™œí•˜ê²Œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ì‚¬ìš©ì ì§€ì •ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ ê°œë°œìê°€ íŠ¹ì • ì½”ë“œë² ì´ìŠ¤ì— ëŒ€í•´ í•™ìŠµì‹œì¼œ ì œì•ˆì„ ê°œì„ í•˜ê³  ë”ìš± ì •í™•í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nCopilotì„ ì‚¬ìš©í•˜ë©´ ì–»ì„ ìˆ˜ ìˆëŠ” ì ì¬ì  ì´ì ì€ ìƒë‹¹í•©ë‹ˆë‹¤. ì½”ë“œ ì‘ì„±ì— í•„ìš”í•œ ì‹œê°„ê³¼ ë…¸ë ¥ì„ ì¤„ì„ìœ¼ë¡œì¨ ê°œë°œìëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì„¤ê³„í•˜ê±°ë‚˜ ê¸°ì¡´ ê¸°ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë“± ë” ë³µì¡í•œ ì‘ì—…ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ Copilotì€ ëª¨ë²” ì‚¬ë¡€ë¥¼ ë”°ë¥´ê³  êµ¬ì¡°ì ìœ¼ë¡œ ê±´ì „í•˜ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œë¥¼ ìƒì„±í•˜ë„ë¡ í”„ë¡œê·¸ë˜ë°ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì˜¤ë¥˜ì™€ ë²„ê·¸ë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì „ë°˜ì ìœ¼ë¡œ GitHub Copilotì€ AI ì§€ì› ì½”ë”© ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì§„ì „ì„ ì´ë£¨ì—ˆìœ¼ë©°, ê°œë°œìì˜ ì½”ë“œ ì‘ì—… ë° í˜‘ì—… ë°©ì‹ì„ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n\n2 RStudio\nR ì‚¬ìš©ìëŠ” RStudioë¥¼ ë§ì´ ì‚¬ìš©í–ˆìœ¼ë‚˜ ìµœê·¼ chatGPT, Github Copilotì˜ ë¶€ìƒìœ¼ë¡œ ê°œë°œë°©ì‹ì— ë³€í™”ê°€ ìƒê²¨ë‚˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ, RStudioê°€ ê³§ Copilot ì§€ì›í•˜ì§€ëŠ” ì•Šì„ ì˜ˆì •ì´ë‹¤. RStudioëŠ” ë¬´ë£Œ ì˜¤í”ˆ ì†ŒìŠ¤ì¸ ë°˜ë©´ Copilotì€ Microsoftì˜ ë…ì  ê¸°ìˆ ì´ë©°, MicrosoftëŠ” ê³µì‹ ë¹„ê³µê°œ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë° í”ŒëŸ¬ê·¸ì¸ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¼ì´ì„ ìŠ¤ë¥¼ ë¶€ì—¬í•˜ê³  ìˆë‹¤. ì‹œì¤‘ì— ì¡´ì¬í•˜ëŠ” ëª‡ëª‡ íƒ€ì‚¬ í”ŒëŸ¬ê·¸ì¸ì€ ê³µì‹ í”ŒëŸ¬ê·¸ì¸ì—ì„œ ë°”ì´ë„ˆë¦¬ë¥¼ ì¶”ì¶œí•˜ì—¬ ì‘ë™í•˜ì§€ë§Œ, RStudioì—ëŠ” ì´ëŸ° ìš°íšŒ í¸ë²•ì ì¸ ë°©ë²•ì„ ì·¨í•˜ê³  ìˆì§€ëŠ” ì•Šê³  ìˆë‹¤.\nGithub Copilot integration with RStudio #10148\nMicrosoftì™€ Positì´ RStudio ë‚´ì—ì„œ Copilotì„ í—ˆìš©í•˜ëŠ” ë°©ë²•ê³¼ RStudioê°€ ê³µê°œ ë°ì´í„° ë° ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ Copilotê³¼ ìœ ì‚¬í•œ AI í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ë„ ìˆì§€ë§Œ ì´ ì¤‘ ì–´ëŠ ê²ƒë„ í–¥í›„ 6ê°œì›” ì´ë‚´ì—(íŠ¹íˆ í–¥í›„ 6~8ì£¼ ì´ë‚´ì—) ì¶œì‹œë  ê°€ëŠ¥ì„±ì€ ì „ë¬´í•˜ë‹¤. ë”°ë¼ì„œ, Copilotì„ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš° VS Codeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ë°©ë²•ì´ë‹¤.\n\n\n\n\n\n3 VS ì½”ë“œ\nGitHub, Copilot for R\nVisual Studio Codeì—ì„œ R ì½”ë“œ ì‘ì„± í”„ë¡œì„¸ìŠ¤ì˜ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤. Copilotì€ ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ R ìŠ¤í¬ë¦½íŠ¸ í˜¹ì€ í•¨ìˆ˜ì „ì²´ë¥¼ ë™ì ìœ¼ë¡œ ì‹¤í–‰í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Rì„ ìƒˆë¡œìš´ Azure OpenAI ì„œë¹„ìŠ¤ì™€ ì¸í„°í˜ì´ìŠ¤í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ê³  Copilotì´ í•„ìš”í•œ ì½”ë“œë¥¼ ìƒì„±í•˜ì—¬ ê°œë°œ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\nCopilot\nchatGPT"
  },
  {
    "objectID": "why_llm.html",
    "href": "why_llm.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ë“¤ì–´ê°€ë©°\nGPT-3(Generative Pre-trained Transformer 3)ì™€ ê°™ì€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ì¸ê°„ê³¼ ìœ ì‚¬í•œ ì–¸ì–´ë¥¼ ì²˜ë¦¬í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì´ ì‹œëŒ€ì— ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤. ì´ë¥¼ í†µí•´ ìì—°ì–´ ì²˜ë¦¬, ì±—ë´‡, ì–¸ì–´ ë²ˆì—­, ì½˜í…ì¸  ì œì‘, ì½”ë”© ë“± ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ìˆ˜ë§ì€ ê°€ëŠ¥ì„±ì„ ì—´ì—ˆë‹¤ëŠ” í‰ê°€ë¥¼ ë°›ê³  ìˆë‹¤.\nê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì´ ì¤‘ìš”í•œ ëª‡ ê°€ì§€ ì´ìœ ë¥¼ ê¼½ìœ¼ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\nìì—°ì–´ ì²˜ë¦¬(Natural language processing): GPT-3ì™€ ê°™ì€ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆê³  ì–¸ì–´ì˜ ë¬¸ë§¥ê³¼ ì˜ë¯¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆì–´ ê°ì • ë¶„ì„, ì–¸ì–´ ë²ˆì—­, í…ìŠ¤íŠ¸ ë¶„ë¥˜ì™€ ê°™ì€ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\nì±—ë´‡(Chatbot): ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ì´í•´í•˜ê³  ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• ëŒ€ë¦¬ì¸(ì±—ë´‡)ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ì±—ë´‡ì€ ê³ ê° ì§€ì›, ê°€ìƒ ë¹„ì„œ ë° ê¸°íƒ€ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\nì–¸ì–´ ë²ˆì—­(Language translation): ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ì—¬ëŸ¬ ì–¸ì–´ì— ëŒ€í•´ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë©° ê³ í’ˆì§ˆ ì–¸ì–´ ë²ˆì—­ì„ ìˆ˜í–‰í•œë‹¤. ì´ëŠ” ê´€ê´‘, ì „ììƒê±°ë˜, êµ­ì œ ë¬´ì—­ ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤.\nì½˜í…ì¸  ìƒì„±(Content creation): ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ê¸°ì‚¬, ìš”ì•½, ì‹œ ë“± ì‚¬ëŒê³¼ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ì €ë„ë¦¬ì¦˜, ì½˜í…ì¸  ì œì‘, ê´‘ê³  ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ í™œìš©í•  ìˆ˜ ìˆë‹¤.\nì½”ë”©(Coding): GPT-3ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ë° ìë™í™”ì— ê´‘ë²”ìœ„í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì»´í“¨í„° ì½”ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì…ì¦í–ˆë‹¤.\n\nìš”ì•½í•˜ë©´, ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì€ ìš°ë¦¬ê°€ ê¸°ê³„ì™€ ìƒí˜¸ì‘ìš©í•˜ê³  ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ì„ í˜ì‹ í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆì–´ ìš°ë¦¬ ì‹œëŒ€ì— ì¤‘ìš”í•œ ê¸°ìˆ ì´ ë  ê²ƒì„ì€ ìëª…í•˜ë‹¤.\n\n\n2019ë…„\n2021ë…„\n2022ë…„\n\n\n\n\n\n(Sanh et al., 2019)\n\n\n\n\n\n\nEfficient Natural Language Processing\n\n\n\n\n![langcon 2023 by ì‹ ì •ê·œ(images/LLM_langcon2023.png)\n\n\n\n\n2 ëª¨í˜•í¬ê¸°\nquestion-answering tasks (open-domain closed-book variant), cloze and sentence-completion tasks, Winograd-style tasks, in-context reading comprehension tasks, common-sense reasoning tasks, SuperGLUE tasks, and natural language inference tasksê°€ í¬í•¨ëœ ì´ 29ê°œ ì‘ì—… ì¤‘ 28ê°œ ì˜ì—­ì—ì„œ PaLM 540Bê°€ ì´ì „ ê±°ëŒ€ ì–¸ì–´ëª¨í˜• GLaM, GPT-3, Megatron-Turing NLG, Gopher, Chinchilla, LaMDA ì„ ê°€ë³ê²Œ ëŠ¥ê°€í–ˆë‹¤.\nSharan Narang and Aakanksha Chowdhery (APRIL 04, 2022), â€œPathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performanceâ€, Software Engineers, Google Research\n\n\nLLM ì§„í™”\n80ì–µ íŒ¨ëŸ¬ë¯¸í„°\n400ì–µ\n640ì–µ\n5,400ì–µ\nì„±ëŠ¥\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 ê±°ëŒ€ì–¸ì–´ëª¨í˜• ì„±ëŠ¥\nìì—°ì–´ ì²˜ë¦¬(NLP) ë° ë¨¸ì‹  ëŸ¬ë‹ ë¶„ì•¼ì˜ ì—¬ëŸ¬ ë°œì „ìœ¼ë¡œ ì¸í•´ GPT-3ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì´ì „ ëª¨ë¸ë³´ë‹¤ í–¥ìƒë˜ì—ˆë‹¤. ì£¼ìš” ì›ì¸ìœ¼ë¡œ ë‹¤ìŒì„ ê¼½ì„ ìˆ˜ ìˆë‹¤.\n\nê·œëª¨(Scale): ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ í•™ìŠµë˜ì–´ ì–¸ì–´ì˜ ë” ë§ì€ ë‰˜ì•™ìŠ¤ë¥¼ í¬ì°©í•˜ê³  ë¬¸ë§¥ì„ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë‹¤. GPT-3ëŠ” 45í…Œë¼ë°”ì´íŠ¸ê°€ ë„˜ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµë˜ì—ˆë‹¤ê³  ì•Œë ¤ì ¸ ì§€ê¸ˆê¹Œì§€ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ ì¤‘ ê°€ì¥ í° ê·œëª¨ë¥¼ ê°–ê³  ìˆë‹¤.\nì•„í‚¤í…ì²˜(Architecture): GPT-3ëŠ” ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œ íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì‹œê°„ì„ ë‹¨ì¶•í•˜ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ë‹¤.\nì‚¬ì „ í•™ìŠµ(Pre-training): ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµë˜ì–´ ë‹¤ì–‘í•œ ì‘ì—…ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ì–¸ì–´ íŒ¨í„´ê³¼ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. GPT-3ëŠ” ë¹„ì§€ë„ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í•™ìŠµë˜ë¯€ë¡œ íŠ¹ì • ì‘ì—…ì„ ì—¼ë‘ì— ë‘ì§€ ì•Šê³  ì›ì‹œ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í•™ìŠµí–ˆë‹¤.\në¯¸ì„¸ ì¡°ì •(Fine-tuning): ì–¸ì–´ ë²ˆì—­ì´ë‚˜ í…ìŠ¤íŠ¸ ë¶„ë¥˜ì™€ ê°™ì€ íŠ¹ì • ì‘ì—…ì„ ìœ„í•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •(Fine-tuning) ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ì´ ê³¼ì •ì—ëŠ” í•´ë‹¹ ì‘ì—…ì— íŠ¹í™”ëœ ì†Œê·œëª¨ ë°ì´í„°ì…‹ë¡œ ëª¨ë¸ì„ ì¶”ê°€ í•™ìŠµì‹œì¼œ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¨ë‹¤.\nì „ì´ í•™ìŠµ(Transfer learning): ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ í•œ ì‘ì—…ì—ì„œ í•™ìŠµí•œ ì§€ì‹ì„ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œ ì „ì´ì‹œí‚¬ ìˆ˜ ìˆë‹¤. ì¦‰, ì–¸ì–´ ë²ˆì—­ê³¼ ê°™ì€ í•œ ì‘ì—…ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ ë” ì‘ì€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„ê³¼ ê°™ì€ ë‹¤ë¥¸ ì‘ì—…ì— ë§ê²Œ ì¶”ê°€ í•™ìŠµì‘ì—…(Fine-tuning)ì„ ì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n\nìš”ì•½í•˜ë©´, ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ê·œëª¨, ì•„í‚¤í…ì²˜, ì‚¬ì „ í•™ìŠµ, ë¯¸ì„¸ ì¡°ì • ë° ì „ì´ í•™ìŠµì˜ ë°œì „ìœ¼ë¡œ ì¸í•´ ì´ì „ ëª¨ë¸ë³´ë‹¤ ë” ìš°ìˆ˜í•˜ë‹¤. ì´ëŸ¬í•œ ë°œì „ ë•ë¶„ì— ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì–¸ì–´ ì‘ì—…ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆê²Œ ë˜ì–´ ìì—°ì–´ ì²˜ë¦¬ ë° ë¨¸ì‹  ëŸ¬ë‹ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ë„êµ¬ê°€ ëœ ê²ƒì´ë‹¤.\n\n\n(Wei et al., 2022)\n\n\n\n4 ìˆ˜í•™\nLewkowycz et al. (2022)\n\n\në¯¸ë„¤ë¥´ë°” LM\nì†ìœ¼ë¡œ í’€ê¸°\nì‹œê°í™”\nSympy í•´ë²•\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\ngiven_line <- function(x)  10 + 4 * x\nsolve_line <- function(x) -10 + 4 *x\n\nggplot() +\n  geom_point(aes(x = 5, y = 10), size = 3) +\n  geom_function(fun = given_line, color = \"blue\", size = 1.5) +\n  geom_function(fun = solve_line, color = \"red\", size = 1.5, alpha = 0.5) +\n  theme_classic() +\n  scale_x_continuous(limits = c(-7, 7), breaks = seq(-7, 7, 1)) +\n  scale_y_continuous(limits = c(-20, 20), breaks = seq(-20, 20, 1)) +\n  geom_vline(xintercept = 0) +\n  geom_hline(yintercept = 0) \n\n\n\n\n\n\n\n\n\n\nfrom sympy import *\n\nx, y, b = symbols('x y b')\n\ngiven_eq = y - (4*x + 10)\n\nparallel_eq = y - (4*x + b)\n\nintercept_eq = parallel_eq.subs([(x, 5), (y, 10)])\n\nsolveset(Eq(intercept_eq, 0), b)\n#> {-10}\n\n\n\n\n\n5 ë‹¤ì–‘í•œ ì‚¬ë¡€ (PaLM)\n5,400 ì–µ íŒ¨ëŸ¬ë¯¸í„°ë¥¼ ì¥ì°©í•œ Pathways Language Model (PaLM)ì˜ ì„±ëŠ¥ì„ ì‹¤ê°í•´ë³´ì.\n\n\në‹¤ì–‘í•œ ê¸°ëŠ¥\nì¶”ë¡ \nì½”ë”©\n\n\n\n\n\n\n\n\n\nì¶”ë¡ (Reasoning)\n\n\n\n\n\n\nì½”ë”©(Code Generation)\n\n\n\n\n\n\n\n\n6 ê°œë°œë¹„\nEstimating ğŸŒ´PaLMâ€™s training cost\nì–¸ì–´ ëª¨í˜• ê°œë°œì€ 2010ë…„ ì´í›„ ê°œë°œë¹„ìš©ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ê³  ìˆìœ¼ë©° ê·¸ ì¶”ì„¸ëŠ” ìƒìƒì„ ì´ˆì›”í•œë‹¤.\n\n\nOur World in Data\nLennart Heim\n\n\n\n\n\n\n\n\n\n\n\n\n\n7 ìƒì„±ëª¨í˜•ì˜ ë¶€ì‘ìš©\nìƒì„± AIë¥¼ í†µí•´ ì¸ê°„ì´ ìƒì„±í•œ ë°ì´í„°ì™€ ê¸°ê³„ê°€ ìƒì„±í•œ ë°ì´í„°ê°€ ë¬´ì‘ìœ„ë¡œ ì„ì¸ ì§€ê¸ˆê¹Œì§€ ê²½í—˜í•˜ì§€ ëª»í•œ ì„¸ìƒì´ ì¶œí˜„í•˜ê³  ìˆë‹¤. ì¦‰, ìƒì„± AI ëª¨í˜•ì—ì„œ ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ë™ì˜ìƒ ë“± ë¬´ìˆ˜íˆ ë§ì€ ë°ì´í„°ê°€ ì¸í„°ë„·ì— ê³µê°œ ë° ê³µìœ ë  ê²ƒì´ë©° ê¸°ê³„í•™ìŠµ ë° ë”¥ëŸ¬ë‹ ìƒì„±ëª¨í˜•ëŠ” ê²°êµ­ ì‹¤ì œ ë°ì´í„°ì™€ ê¸°ê³„ê°€ ìƒì„±í•œ ë°ì´í„°ë¥¼ ì…ë ¥ê°’ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ ëª¨í˜•ì„ ìƒì„±í•˜ê²Œ ëœë‹¤. í•˜ì§€ë§Œ ì´ëŸ° ê²½ìš° ê³¼ì—° AI ëª¨í˜•ì€ ì–´ë–¤ íŠ¹ì„±ì„ ê°–ê²Œ ë  ê²ƒì¸ê°€? ë°ì´í„° ì¦ê°•(Data Augmentation)ì²˜ëŸ¼ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ê°–ëŠ” AI ëª¨í˜•ì´ ë  ê²ƒì´ê°€ ì•„ë‹ˆë©´ ê·¸ ë°˜ëŒ€ì˜ ëª¨ìŠµì„ ê°€ì§€ê²Œ ë  ê²ƒì¸ê°€? ë…¼ë¬¸(Hataya et al., 2022)ì—ì„œëŠ” ë¶€ì •ì ì¸ íš¨ê³¼ë„ ìˆë‹¤ê³  ì£¼ì¥í•˜ê³  ìˆë‹¤.\n\n\ní˜„ì¬ ìƒí™©\nê¸°ê³„ì˜¤ì—¼ëœ ë°ì´í„°\n\n\n\n\n\n\n\n\n\n\n\nê¸°ê³„ìƒì„± ë°ì´í„° ì‚¬ìš©í•˜ì—¬ ë‚˜ì˜¨ ê²°ê³¼ë¬¼\n\n\n\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nHataya, R., Bao, H., & Arai, H. (2022). Will large-scale generative models corrupt future datasets? arXiv Preprint arXiv:2211.08095.\n\n\nLewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramasesh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., et al. (2022). Solving quantitative reasoning problems with language models. arXiv Preprint arXiv:2206.14858.\n\n\nSanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. arXiv Preprint arXiv:1910.01108.\n\n\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. (2022). Emergent abilities of large language models. arXiv Preprint arXiv:2206.07682."
  },
  {
    "objectID": "ide.html",
    "href": "ide.html",
    "title": "chatGPT",
    "section": "",
    "text": "chatGPT ëŠ” ë°ì´í„° ê³¼í•™ì ê°œë°œìƒì‚°ì„±ì„ ë¹„ì•½ì ìœ¼ë¡œ ì¦ì§„ì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ìˆë‹¤. íŠ¹íˆ ë°ì´í„° ê³¼í•™ì—ì„œ ê°œë°œìƒì‚°ì„± ê´€ë ¨ í° ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ í†µí•©ê°œë°œí™˜ê²½(IDE)ì´ë‹¤. Positì—ì„œ ê°œë°œí•œ RStudioê°€ ì¶œí˜„í•˜ë©´ì„œ ê¸°ì¡´ Rì–¸ì–´ë¥¼ ë‹¤ì–‘í•œ í¸ì§‘ê¸°(VIM,Emacs ë“±)ë¡œ ì£¼ë¡œ ê°œë°œí•˜ë˜ ë¬¸í™”ë¥¼ íšê¸°ì ìœ¼ë¡œ ë°”ë€Œì—ˆë‹¤ë©´ ì´ì œëŠ” GitHub Copilotì„ ì–´ë–¤ í˜•íƒœë¡œë“  ë¶™ì—¬ì„œ ì‚¬ìš©í•˜ë©´ ë”ìš± ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.\nê¸°ì¡´ RStudioì—ì„œ ë°ì´í„° ê³¼í•™ ê°œë°œë¶€í„° ì œí’ˆ/ì„œë¹„ìŠ¤ ì œì‘ê¹Œì§€ ëª¨ë‘ ì§„í–‰í–ˆë‹¤ë©´, ì´ì œ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ Posit RStudio ë¬´ë£Œ IDEì— GitHub Copilot ìƒìš© ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ì œê³µí•˜ì§€ ì•Šê³  GitHub Copilotì— ëŒ€ì‘í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ê°€ í˜„ì¬ì‹œì  ê¸°ì¤€ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë¶€ë“ì´ ì´ ë‘˜ì„ ë‚˜ëˆ  ê°œë°œì„ ì§„í–‰í•´ì•¼ ë°ì´í„° ê³¼í•™ìë¡œì„œ ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "ide.html#keybindings.json",
    "href": "ide.html#keybindings.json",
    "title": "chatGPT",
    "section": "\n4.1 keybindings.json\n",
    "text": "4.1 keybindings.json\n\nkeybindings.json íŒŒì¼ì— R í˜¹ì€ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‚½ì…ì‹œí‚¬ ìˆ˜ ìˆëŠ” í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ë¥¼ ë“±ë¡ì‹œí‚¨ë‹¤. ìë£Œì¶œì²˜: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n\n\n\n\n\n\nkeybindings.json ì„¤ì •íŒŒì¼ ì˜ˆì‹œ\n\n\n\n\n\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: 'ì´ê´‘ì¶˜'\\ndate: '2023-03-07'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "ide.html#html-ë¯¸ë¦¬ë³´ê¸°",
    "href": "ide.html#html-ë¯¸ë¦¬ë³´ê¸°",
    "title": "chatGPT",
    "section": "\n4.2 HTML ë¯¸ë¦¬ë³´ê¸°",
    "text": "4.2 HTML ë¯¸ë¦¬ë³´ê¸°\n.Rmd íŒŒì¼ì„  CTRL  +  Shift  +  k  ë‹¨ì¶•í‚¤ë¡œ ì»´íŒŒì¼ì‹œí‚¤ë©´ .html íŒŒì¼ì´ ìƒì„±ëœë‹¤. .html íŒŒì¼ ê²°ê³¼ë¥¼ ì§ì ‘ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³ ì í•œë‹¤ë©´, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ê°œë°œí•œ Live Preview - VS Code Extension í”ŒëŸ¬ê·¸ì¸ì„ ì„¤ì¹˜í•œë‹¤."
  },
  {
    "objectID": "ide.html#r-extension-ì„¤ì¹˜",
    "href": "ide.html#r-extension-ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "\n1.1 R extension ì„¤ì¹˜",
    "text": "1.1 R extension ì„¤ì¹˜\nR extensionì„ ì„¤ì¹˜í•˜ê²Œ ë˜ë©´ VS Codeì—ì„œ R ì½”ë“œ ê°œë°œì„ ì›í™œíˆ í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤. VS Code ì— í•„ìˆ˜ì ì¸ R extensionì€ ë‹¤ìŒì„ ê¼½ì„ ìˆ˜ ìˆë‹¤. R extensionì„ ì„¤ì¹˜í•˜ë©´ RStudioì—ì„œ ê¸°ë³¸ì„¤ì •ìœ¼ë¡œ ì§€ì •ëœ ë‹¨ì¶•í‚¤ë¥¼ ë³„ë„ ì„¤ì •ì—†ì´ ìë™ ì§€ì •ë˜ê¸° ë•Œë¬¸ì— í¸ë¦¬í•˜ë‹¤.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Codeë¥¼ ì‹¤í–‰í•˜ê³  R Extension ì„¤ì¹˜"
  },
  {
    "objectID": "ide.html#í—¬ë¡œìš°-ì›”ë“œ",
    "href": "ide.html#í—¬ë¡œìš°-ì›”ë“œ",
    "title": "chatGPT",
    "section": "\n1.2 í—¬ë¡œìš° ì›”ë“œ",
    "text": "1.2 í—¬ë¡œìš° ì›”ë“œ\nR Extension ì„¤ì¹˜ë˜ë©´ ì½”ë“œ ì°½ ìƒë‹¨ì— ì‹¤í–‰ë²„íŠ¼ì´ í™œì„±í™”ë˜ê³  Ctrl + Enter í˜¹ì€ Ctrl + Shift + Enter\n\n\nR ì½”ë“œ ì‹¤í–‰í™”ë©´"
  },
  {
    "objectID": "ide.html#ìœ íŠœë¸Œ-ë™ì˜ìƒ",
    "href": "ide.html#ìœ íŠœë¸Œ-ë™ì˜ìƒ",
    "title": "chatGPT",
    "section": "\n1.3 ìœ íŠœë¸Œ ë™ì˜ìƒ",
    "text": "1.3 ìœ íŠœë¸Œ ë™ì˜ìƒ"
  },
  {
    "objectID": "ide.html#ì½”ë”©-ê¸€ê¼´",
    "href": "ide.html#ì½”ë”©-ê¸€ê¼´",
    "title": "chatGPT",
    "section": "\n2.1 ì½”ë”© ê¸€ê¼´",
    "text": "2.1 ì½”ë”© ê¸€ê¼´\në‹¤ë¥¸ ì–¸ì–´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ R ì½”ë“œë¡œ ë°ì´í„° ê³¼í•™ ì œí’ˆì„ ê°œë°œí•  ê²½ìš° ê¸€ê¼´ë„ ì½”ë”©ì— ì í•©í•œ í•œê¸€ ê¸€ê¼´ì„ ì„¤ì •í•œë‹¤.\në¨¼ì € D2 Coding ê¸€ê¼´ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ìš´ì˜ì²´ì œì— ì„¤ì¹˜í•œë‹¤.\nVS Code ì¢Œì¸¡ í•˜ë‹¨ í†±ë‹ˆë°”í€´  Settings  ì„¤ì •ì„ í´ë¦­ í˜¹ì€ ë©”ë‰´ì—ì„œ â€œFileâ€ â†’ â€œPreferencesâ€ â†’ â€œSettingsâ€ë¥¼ í†µí•´ í¸ì§‘ê¸° (Text Editor)ë¡œ ë“¤ì–´ê°€ ìš´ì˜ì²´ì œì— ì„¤ì¹˜í•œ ì½”ë”© í°íŠ¸ë¥¼ ì§€ì •í•œë‹¤. Font Ligatures ë„ trueë¡œ ì„¤ì •í•œë‹¤. ì´ë¥¼ í†µí•´ < - í‘œì‹œê°€ â† ë¡œ í™”ë©´ì— í‘œí˜„ëœë‹¤.\n\n\nD2ì½”ë”© ê¸€ê¼´ ì¥ì°©"
  },
  {
    "objectID": "ide.html#ë‹¨ì¶•í‚¤",
    "href": "ide.html#ë‹¨ì¶•í‚¤",
    "title": "chatGPT",
    "section": "\n2.2 ë‹¨ì¶•í‚¤",
    "text": "2.2 ë‹¨ì¶•í‚¤\nR ì½”ë“œ ê°œë°œì„ ì§„í–‰í•  ë•Œ  %>% ,  â†  ë‘ê°€ì§€ ê¸°ëŠ¥ì´ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë‹¨ì¶•í‚¤ë¡œ RStudioì—ì„œëŠ” ê¸°ë³¸ìœ¼ë¡œ ì§€ì›ë˜ê³  ìˆë‹¤. VS Codeì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ë‹¨ì¶•í‚¤ë¥¼  CTRL  +  Shift  +  m ,  Alt  +  -  ë¥¼ ì ìš©ì‹œí‚¤ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì.\në§Œì•½ VS Codeì—ì„œ ë‹¨ì¶•í‚¤ ì„¤ì • ê¸°ëŠ¥ì„ í™œìš©í•œë‹¤. How to add R {magrittr}â€™s %>% Pipe Operator in VSCode as Keyboard Shortcut\n\nìœˆë„ìš°ì¦ˆ: File > Preferences > Keyboard Shortcuts.\në§¥: Code > Preferences > Keyboard Shortcuts\n\nkeybindings.json íŒŒì¼ì—  %>% ,  â†  ë‹¨ì¶•í‚¤ ê¸°ëŠ¥ì„ ì¶”ê°€í•œë‹¤.\n\n\nìì£¼ ì‚¬ìš©ë˜ëŠ” R ë‹¨ì¶•í‚¤ ì„¤ì •"
  },
  {
    "objectID": "ide.html#íŒ¨ë„",
    "href": "ide.html#íŒ¨ë„",
    "title": "chatGPT",
    "section": "\n2.3 íŒ¨ë„",
    "text": "2.3 íŒ¨ë„\nRStudioëŠ” ì½”ë”©ê¸°ë°˜ ë°ì´í„° ë¶„ì„ê³¼ í†µê³„ì— ìµœì í™”ëœ ê°œë°œí™˜ê²½ì´ë‹¤. ì¦‰, í¸ì§‘ê¸° íŒ¨ë„, ì½˜ì†”/í„°ë¯¸ë„ íŒ¨ë„, ê·¸ë˜í”„ íŒ¨ë„, ë„ì›€ë§/ê°œë°œ íŒ¨ë„ë¡œ êµ¬ì„±ëœ ê¼­ í•„ìš”í•œ íŒ¨ë„ë§Œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.\n\n\níŒ¨ë„ ì„¤ì •\nì„¤ì • í›„\n\n\n\n\n\nVS Code: View â†’ Editor Layout â†’ Grid (2x2)\n\n\n\n\n\n\në„ì›€ë§ê³¼ ê·¸ë˜í”„"
  },
  {
    "objectID": "ide.html#ì„¤ì¹˜",
    "href": "ide.html#ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "ì„¤ì¹˜",
    "text": "ì„¤ì¹˜\n# ì¶œì‹œë²„ì „ ì„¤ì¹˜\npip3 install -U radian\n# ì‹¤í–‰\nradian"
  },
  {
    "objectID": "ide.html#ì‹¤í–‰í™”ë©´",
    "href": "ide.html#ì‹¤í–‰í™”ë©´",
    "title": "chatGPT",
    "section": "ì‹¤í–‰í™”ë©´",
    "text": "ì‹¤í–‰í™”ë©´"
  },
  {
    "objectID": "ide.html#vs-ì½”ë“œ-ì½˜ì†”",
    "href": "ide.html#vs-ì½”ë“œ-ì½˜ì†”",
    "title": "chatGPT",
    "section": "\n3.2 VS ì½”ë“œ ì½˜ì†”",
    "text": "3.2 VS ì½”ë“œ ì½˜ì†”\nradiantë¥¼ ì„¤ì¹˜í•œ í›„ì— Rpath ê°€ ì•„ë‹ˆë¼ Rtermì—ì„œ ì„¤ì •í•´ì¤˜ì•¼ í•œë‹¤.\n\n\n\në§¥\n\n\n\n\nìœˆë„ìš°ì¦ˆ\n\n\n\n\nì ìš©ê²°ê³¼"
  },
  {
    "objectID": "ide.html#ë…ë¦½-ì‚¬ìš©ì‚¬ë¡€",
    "href": "ide.html#ë…ë¦½-ì‚¬ìš©ì‚¬ë¡€",
    "title": "chatGPT",
    "section": "\n3.1 ë…ë¦½ ì‚¬ìš©ì‚¬ë¡€",
    "text": "3.1 ë…ë¦½ ì‚¬ìš©ì‚¬ë¡€"
  },
  {
    "objectID": "ide.html#í­ê·„-ë°ì´í„°ì…‹",
    "href": "ide.html#í­ê·„-ë°ì´í„°ì…‹",
    "title": "chatGPT",
    "section": "\n5.1 í­ê·„ ë°ì´í„°ì…‹",
    "text": "5.1 í­ê·„ ë°ì´í„°ì…‹"
  },
  {
    "objectID": "ide.html#í˜¸ë°•-ë°ì´í„°ì…‹",
    "href": "ide.html#í˜¸ë°•-ë°ì´í„°ì…‹",
    "title": "chatGPT",
    "section": "\n5.2 í˜¸ë°• ë°ì´í„°ì…‹",
    "text": "5.2 í˜¸ë°• ë°ì´í„°ì…‹\n\n<p>:::</p>"
  },
  {
    "objectID": "ide.html#ì¤‘ìš”-ì¶”ê°€ì„¤ì •",
    "href": "ide.html#ì¤‘ìš”-ì¶”ê°€ì„¤ì •",
    "title": "chatGPT",
    "section": "\n5.1 ì¤‘ìš” ì¶”ê°€ì„¤ì •",
    "text": "5.1 ì¤‘ìš” ì¶”ê°€ì„¤ì •\nPrincipal Cloud Advocate at Microsoft David Smithê°€ â€œNew York Open Statistical Programming Meetup, 28 February 2023â€ì—ì„œ ë°œí‘œí•œ Copilot for R ë‚´ìš© ì¤‘ VS ì½”ë“œ í™˜ê²½ì„¤ì •ë¶€ë¶„ì´ë‹¤.\nCopilot for R\n\nVS ì½”ë“œ\n\nCopilot extension\nR Extension for Visual Studio Code\ncopilot ì¶”ì²œì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ì„œ ë‹¤ìŒ ì‚¬í•­ë„ ì„¤ì •ì— ë°˜ì˜í•œë‹¤.\n\nEditor > Hover (disabled)\nEditor > Quick Suggestions (off)\nEditor > Parameter Hints (disabled)\n\n\n\n\nR íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° opitions()\n\nhttr, jsonlite, tidyverse, tidymodels, docopt, httpuv\nê°€ë…ì„± ë†’ì€ ê·¸ë˜í”„ ì¶œë ¥: options(vsc.dev.args = list(width = 800, height = 600))"
  },
  {
    "objectID": "ide.html#ì‹¤ì œ-ì ìš©-ì‚¬ë¡€",
    "href": "ide.html#ì‹¤ì œ-ì ìš©-ì‚¬ë¡€",
    "title": "chatGPT",
    "section": "\n5.2 ì‹¤ì œ ì ìš© ì‚¬ë¡€",
    "text": "5.2 ì‹¤ì œ ì ìš© ì‚¬ë¡€\ní­ê·„ê³¼ í˜¸ë°• ë°ì´í„°ë¥¼ ì ìš©í•œ ì‚¬ë¡€ ì‹œì—°ì„ ì‚´í´ë³´ì.\ní­ê·„ ë°ì´í„°ì…‹\n\n\n\n\ní˜¸ë°• ë°ì´í„°ì…‹\n\n<div id=\"quarto-navigation-envelope\" class=\"hidden\">\n<p><span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\">Home</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ìƒì„± AI\">ìƒì„± AI</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:chatGPT ì´í•´\">chatGPT ì´í•´</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ì¶”ì„¸ íŠ¸ë Œë“œ\">ì¶”ì„¸ íŠ¸ë Œë“œ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ì™œ ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì¸ê°€?\">ì™œ ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì¸ê°€?</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:------------------\">â€”â€”â€”â€”â€”â€”</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ì´ë¯¸ì§€ ìƒì„±\">ì´ë¯¸ì§€ ìƒì„±</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:GPT R ì½”ë”©ê°œë°œ\">GPT R ì½”ë”©ê°œë°œ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ë¶€ì¡°ì¢…ì‚¬ R ì½”ë”©ê°œë°œ\">ë¶€ì¡°ì¢…ì‚¬ R ì½”ë”©ê°œë°œ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ìˆ˜í•™ë¬¸ì œ\">ìˆ˜í•™ë¬¸ì œ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ë°ì´í„° ê³¼í•™ë¬¸ì œ\">ë°ì´í„° ê³¼í•™ë¬¸ì œ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:DeepL ë²ˆì—­ API\">DeepL ë²ˆì—­ API</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:chatGPT ì‘ìš©ì‚¬ë¡€\">chatGPT ì‘ìš©ì‚¬ë¡€</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:í™œìš©ì‚¬ë¡€\">í™œìš©ì‚¬ë¡€</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ë³´ë„ìë£Œ ì‘ì„±\">ë³´ë„ìë£Œ ì‘ì„±</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:R ì†Œê°œì˜ìƒ\">R ì†Œê°œì˜ìƒ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ë°ì´í„° ê³¼í•™ ì±…\">ë°ì´í„° ê³¼í•™ ì±…</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ë…¼ë¬¸ ì´ˆë¡\">ë…¼ë¬¸ ì´ˆë¡</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:í•™ìˆ ì—°êµ¬(R&amp;D)\">í•™ìˆ ì—°êµ¬(R&amp;D)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ë°ì´í„° ë¬¸í•´ë ¥\">ë°ì´í„° ë¬¸í•´ë ¥</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ì¸í„°í˜ì´ìŠ¤\">ì¸í„°í˜ì´ìŠ¤</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:BERT\">BERT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:í†µí•©ê°œë°œí™˜ê²½(IDE)\">í†µí•©ê°œë°œí™˜ê²½(IDE)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:íŒŒì´ì¬ í™˜ê²½êµ¬ì¶•\">íŒŒì´ì¬ í™˜ê²½êµ¬ì¶•</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:HuggingfaceR - ëª¨í˜•í†µê³„\">HuggingfaceR - ëª¨í˜•í†µê³„</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Hugging Face\">Hugging Face</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Hugging Face(ìœˆë„ìš°)\">Hugging Face(ìœˆë„ìš°)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:HF íŒŒì´í”„ë¼ì¸\">HF íŒŒì´í”„ë¼ì¸</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:ê²Œì‹œê¸€\">ê²Œì‹œê¸€</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Rì‚¬ìš©ìíšŒ\">Rì‚¬ìš©ìíšŒ</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Open Assistant\">Open Assistant</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:RTutor\">RTutor</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:About\">About</span> <span class=\"hidden\" data-render-id=\"footer-left\"><a href=\"https://quarto.org/\">Quarto</a> ê°œë°œ</span> <span class=\"hidden\" data-render-id=\"footer-center\"><a href=\"mailto:admin@r2bit.com\">í•œêµ­ R ì‚¬ìš©ìíšŒ</a></span> <span class=\"hidden\" data-render-id=\"footer-right\"><a href=\"https://github.com/bit2r/chatGPT\">Github ì½”ë“œ ì €ì¥ì†Œ</a></span></p>\n</div>\n<div id=\"quarto-meta-markdown\" class=\"hidden\">\n<p><span class=\"hidden\" data-render-id=\"quarto-metatitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-metasitename\">chatGPT</span></p>\n</div>\n<!-- -->\n<div class=\"quarto-embedded-source-code\">\n<div class=\"sourceCode\" id=\"cb5\" data-shortcodes=\"false\"><pre class=\"sourceCode markdown\"><code class=\"sourceCode markdown\"><span id=\"cb5-1\"><a href=\"#cb5-1\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">---</span></span>\n<span id=\"cb5-2\"><a href=\"#cb5-2\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">title:</span><span class=\"co\"> \"chatGPT\"</span></span>\n<span id=\"cb5-3\"><a href=\"#cb5-3\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">subtitle:</span><span class=\"co\"> \"í†µí•©ê°œë°œí™˜ê²½(IDE)\"</span></span>\n<span id=\"cb5-4\"><a href=\"#cb5-4\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">description:</span><span class=\"co\"> \"ë¹„ì¥¬ì–¼ ìŠ¤íŠœë””ì˜¤ ì½”ë“œ IDEë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë°œ ìƒì‚°ì„±ì„ ë†’ì¸ë‹¤.\"</span></span>\n<span id=\"cb5-5\"><a href=\"#cb5-5\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">author:</span></span>\n<span id=\"cb5-6\"><a href=\"#cb5-6\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  - name: ì´ê´‘ì¶˜</span></span>\n<span id=\"cb5-7\"><a href=\"#cb5-7\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    url: https://www.linkedin.com/in/kwangchunlee/</span></span>\n<span id=\"cb5-8\"><a href=\"#cb5-8\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    affiliation: í•œêµ­ R ì‚¬ìš©ìíšŒ</span></span>\n<span id=\"cb5-9\"><a href=\"#cb5-9\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    affiliation-url: https://github.com/bit2r</span></span>\n<span id=\"cb5-10\"><a href=\"#cb5-10\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">title-block-banner:</span><span class=\"co\"> true</span></span>\n<span id=\"cb5-11\"><a href=\"#cb5-11\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">#title-block-banner: \"#562457\"</span></span>\n<span id=\"cb5-12\"><a href=\"#cb5-12\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">format:</span></span>\n<span id=\"cb5-13\"><a href=\"#cb5-13\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  html:</span></span>\n<span id=\"cb5-14\"><a href=\"#cb5-14\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    css: css/quarto.css</span></span>\n<span id=\"cb5-15\"><a href=\"#cb5-15\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    theme: flatly</span></span>\n<span id=\"cb5-16\"><a href=\"#cb5-16\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    code-fold: true</span></span>\n<span id=\"cb5-17\"><a href=\"#cb5-17\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    code-overflow: wrap</span></span>\n<span id=\"cb5-18\"><a href=\"#cb5-18\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc: true</span></span>\n<span id=\"cb5-19\"><a href=\"#cb5-19\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc-depth: 3</span></span>\n<span id=\"cb5-20\"><a href=\"#cb5-20\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc-title: ëª©ì°¨</span></span>\n<span id=\"cb5-21\"><a href=\"#cb5-21\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    number-sections: true</span></span>\n<span id=\"cb5-22\"><a href=\"#cb5-22\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    highlight-style: github    </span></span>\n<span id=\"cb5-23\"><a href=\"#cb5-23\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    self-contained: false</span></span>\n<span id=\"cb5-24\"><a href=\"#cb5-24\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">filters:</span></span>\n<span id=\"cb5-25\"><a href=\"#cb5-25\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">   - lightbox</span></span>\n<span id=\"cb5-26\"><a href=\"#cb5-26\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">   - custom-callout.lua   </span></span>\n<span id=\"cb5-27\"><a href=\"#cb5-27\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">lightbox:</span><span class=\"co\"> auto</span></span>\n<span id=\"cb5-28\"><a href=\"#cb5-28\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">link-citations:</span><span class=\"co\"> yes</span></span>\n<span id=\"cb5-29\"><a href=\"#cb5-29\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">knitr:</span></span>\n<span id=\"cb5-30\"><a href=\"#cb5-30\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  opts_chunk: </span></span>\n<span id=\"cb5-31\"><a href=\"#cb5-31\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    message: false</span></span>\n<span id=\"cb5-32\"><a href=\"#cb5-32\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    warning: false</span></span>\n<span id=\"cb5-33\"><a href=\"#cb5-33\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    collapse: true</span></span>\n<span id=\"cb5-34\"><a href=\"#cb5-34\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    comment: \"#&gt;\" </span></span>\n<span id=\"cb5-35\"><a href=\"#cb5-35\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    R.options:</span></span>\n<span id=\"cb5-36\"><a href=\"#cb5-36\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">      knitr.graphics.auto_pdf: true</span></span>\n<span id=\"cb5-37\"><a href=\"#cb5-37\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">editor_options:</span><span class=\"co\"> </span></span>\n<span id=\"cb5-38\"><a href=\"#cb5-38\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  chunk_output_type: console</span></span>\n<span id=\"cb5-39\"><a href=\"#cb5-39\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">---</span></span>\n<span id=\"cb5-40\"><a href=\"#cb5-40\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-41\"><a href=\"#cb5-41\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`chatGPT`</span> ëŠ” ë°ì´í„° ê³¼í•™ì ê°œë°œìƒì‚°ì„±ì„ ë¹„ì•½ì ìœ¼ë¡œ ì¦ì§„ì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ìˆë‹¤.</span>\n<span id=\"cb5-42\"><a href=\"#cb5-42\" aria-hidden=\"true\" tabindex=\"-1\"></a>íŠ¹íˆ ë°ì´í„° ê³¼í•™ì—ì„œ ê°œë°œìƒì‚°ì„± ê´€ë ¨ í° ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ í†µí•©ê°œë°œí™˜ê²½(IDE)ì´ë‹¤.</span>\n<span id=\"cb5-43\"><a href=\"#cb5-43\" aria-hidden=\"true\" tabindex=\"-1\"></a>Positì—ì„œ ê°œë°œí•œ RStudioê°€ ì¶œí˜„í•˜ë©´ì„œ ê¸°ì¡´ Rì–¸ì–´ë¥¼ ë‹¤ì–‘í•œ í¸ì§‘ê¸°(VIM,Emacs ë“±)ë¡œ </span>\n<span id=\"cb5-44\"><a href=\"#cb5-44\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì£¼ë¡œ ê°œë°œí•˜ë˜ ë¬¸í™”ë¥¼ íšê¸°ì ìœ¼ë¡œ ë°”ë€Œì—ˆë‹¤ë©´ ì´ì œëŠ” GitHub Copilotì„ ì–´ë–¤ í˜•íƒœë¡œë“ </span>\n<span id=\"cb5-45\"><a href=\"#cb5-45\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë¶™ì—¬ì„œ ì‚¬ìš©í•˜ë©´ ë”ìš± ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.</span>\n<span id=\"cb5-46\"><a href=\"#cb5-46\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-47\"><a href=\"#cb5-47\" aria-hidden=\"true\" tabindex=\"-1\"></a>ê¸°ì¡´ RStudioì—ì„œ ë°ì´í„° ê³¼í•™ ê°œë°œë¶€í„° ì œí’ˆ/ì„œë¹„ìŠ¤ ì œì‘ê¹Œì§€ ëª¨ë‘ ì§„í–‰í–ˆë‹¤ë©´,</span>\n<span id=\"cb5-48\"><a href=\"#cb5-48\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì´ì œ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ Posit RStudio ë¬´ë£Œ IDEì— GitHub Copilot ìƒìš© ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ </span>\n<span id=\"cb5-49\"><a href=\"#cb5-49\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì œê³µí•˜ì§€ ì•Šê³  GitHub Copilotì— ëŒ€ì‘í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ê°€ í˜„ì¬ì‹œì  ê¸°ì¤€ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—</span>\n<span id=\"cb5-50\"><a href=\"#cb5-50\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë¶€ë“ì´ ì´ ë‘˜ì„ ë‚˜ëˆ  ê°œë°œì„ ì§„í–‰í•´ì•¼ ë°ì´í„° ê³¼í•™ìë¡œì„œ ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.</span>\n<span id=\"cb5-51\"><a href=\"#cb5-51\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-52\"><a href=\"#cb5-52\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/ide-copilot.png)</span></span>\n<span id=\"cb5-53\"><a href=\"#cb5-53\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-54\"><a href=\"#cb5-54\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># VS ì½”ë“œ ì„¤ì¹˜</span></span>\n<span id=\"cb5-55\"><a href=\"#cb5-55\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-56\"><a href=\"#cb5-56\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS ì½”ë“œë¥¼ í†µí•´ ë°ì´í„° ê³¼í•™ ì œí’ˆê°œë°œì„ í•  ê²½ìš° ë‹¤ìŒ ì‚¬í•­ì— ë§ì¶° ê°œë°œì„ ì‹œì‘í•œë‹¤.</span>\n<span id=\"cb5-57\"><a href=\"#cb5-57\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-58\"><a href=\"#cb5-58\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">1. </span>Rì„ ì„¤ì¹˜í•œë‹¤.</span>\n<span id=\"cb5-59\"><a href=\"#cb5-59\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">2. </span><span class=\"in\">`languageserver`</span> íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.</span>\n<span id=\"cb5-60\"><a href=\"#cb5-60\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span><span class=\"in\">`install.packages(\"languageserver\")`</span></span>\n<span id=\"cb5-61\"><a href=\"#cb5-61\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">3. </span>Visual Studio Code ì—ì„œ <span class=\"in\">`R extension`</span>ì„ ì„¤ì¹˜í•œë‹¤.</span>\n<span id=\"cb5-62\"><a href=\"#cb5-62\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">4. </span><span class=\"in\">`.R`</span> íŒŒì¼ì— ê°œë°œì„ ì‹œì‘í•œë‹¤.</span>\n<span id=\"cb5-63\"><a href=\"#cb5-63\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-64\"><a href=\"#cb5-64\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-65\"><a href=\"#cb5-65\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## `R extension` ì„¤ì¹˜</span></span>\n<span id=\"cb5-66\"><a href=\"#cb5-66\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-67\"><a href=\"#cb5-67\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`R extension`</span>ì„ ì„¤ì¹˜í•˜ê²Œ ë˜ë©´ VS Codeì—ì„œ R ì½”ë“œ ê°œë°œì„ ì›í™œíˆ í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤. </span>\n<span id=\"cb5-68\"><a href=\"#cb5-68\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS Code ì— í•„ìˆ˜ì ì¸ <span class=\"in\">`R extension`</span>ì€ ë‹¤ìŒì„ ê¼½ì„ ìˆ˜ ìˆë‹¤. <span class=\"in\">`R extension`</span>ì„ ì„¤ì¹˜í•˜ë©´</span>\n<span id=\"cb5-69\"><a href=\"#cb5-69\" aria-hidden=\"true\" tabindex=\"-1\"></a>RStudioì—ì„œ ê¸°ë³¸ì„¤ì •ìœ¼ë¡œ ì§€ì •ëœ ë‹¨ì¶•í‚¤ë¥¼ ë³„ë„ ì„¤ì •ì—†ì´ ìë™ ì§€ì •ë˜ê¸° ë•Œë¬¸ì— </span>\n<span id=\"cb5-70\"><a href=\"#cb5-70\" aria-hidden=\"true\" tabindex=\"-1\"></a>í¸ë¦¬í•˜ë‹¤.</span>\n<span id=\"cb5-71\"><a href=\"#cb5-71\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-72\"><a href=\"#cb5-72\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R - REditorSupport</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r)</span></span>\n<span id=\"cb5-73\"><a href=\"#cb5-73\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R Markdown All in One</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=TianyiShi.rmarkdown)</span></span>\n<span id=\"cb5-74\"><a href=\"#cb5-74\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">Quarto</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=quarto.quarto)</span></span>\n<span id=\"cb5-75\"><a href=\"#cb5-75\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R Debugger</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=RDebugger.r-debugger)</span></span>\n<span id=\"cb5-76\"><a href=\"#cb5-76\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-77\"><a href=\"#cb5-77\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-78\"><a href=\"#cb5-78\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![VS Codeë¥¼ ì‹¤í–‰í•˜ê³  R Extension ì„¤ì¹˜](images/vscode_R_extension.png)</span></span>\n<span id=\"cb5-79\"><a href=\"#cb5-79\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-80\"><a href=\"#cb5-80\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## í—¬ë¡œìš° ì›”ë“œ</span></span>\n<span id=\"cb5-81\"><a href=\"#cb5-81\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-82\"><a href=\"#cb5-82\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`R Extension`</span> ì„¤ì¹˜ë˜ë©´ ì½”ë“œ ì°½ ìƒë‹¨ì— ì‹¤í–‰ë²„íŠ¼ì´ í™œì„±í™”ë˜ê³  <span class=\"kw\">&lt;kbd&gt;</span>Ctrl<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Enter<span class=\"kw\">&lt;/kbd&gt;</span> í˜¹ì€ </span>\n<span id=\"cb5-83\"><a href=\"#cb5-83\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"kw\">&lt;kbd&gt;</span>Ctrl<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Shift<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Enter<span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-84\"><a href=\"#cb5-84\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-85\"><a href=\"#cb5-85\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-86\"><a href=\"#cb5-86\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![R ì½”ë“œ ì‹¤í–‰í™”ë©´](images/vscode_helloworld.png)</span></span>\n<span id=\"cb5-87\"><a href=\"#cb5-87\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-88\"><a href=\"#cb5-88\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-89\"><a href=\"#cb5-89\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ìœ íŠœë¸Œ ë™ì˜ìƒ</span></span>\n<span id=\"cb5-90\"><a href=\"#cb5-90\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-91\"><a href=\"#cb5-91\" aria-hidden=\"true\" tabindex=\"-1\"></a>{{&lt; video https://youtu.be/c3ZQ8-OYj2M &gt;}}</span>\n<span id=\"cb5-92\"><a href=\"#cb5-92\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-93\"><a href=\"#cb5-93\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># ì¦ê±°ìš´ ì½”ë”© í™˜ê²½ì„¤ì •</span></span>\n<span id=\"cb5-94\"><a href=\"#cb5-94\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-95\"><a href=\"#cb5-95\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ì½”ë”© ê¸€ê¼´</span></span>\n<span id=\"cb5-96\"><a href=\"#cb5-96\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-97\"><a href=\"#cb5-97\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë‹¤ë¥¸ ì–¸ì–´ì™€ ë§ˆì°¬ê°€ì§€ë¡œ R ì½”ë“œë¡œ ë°ì´í„° ê³¼í•™ ì œí’ˆì„ ê°œë°œí•  ê²½ìš° ê¸€ê¼´ë„ ì½”ë”©ì— ì í•©í•œ í•œê¸€ ê¸€ê¼´ì„ ì„¤ì •í•œë‹¤.</span>\n<span id=\"cb5-98\"><a href=\"#cb5-98\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-99\"><a href=\"#cb5-99\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë¨¼ì € <span class=\"co\">[</span><span class=\"ot\">D2 Coding ê¸€ê¼´</span><span class=\"co\">](https://github.com/naver/d2codingfont)</span>ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ìš´ì˜ì²´ì œì— ì„¤ì¹˜í•œë‹¤.</span>\n<span id=\"cb5-100\"><a href=\"#cb5-100\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-101\"><a href=\"#cb5-101\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS Code ì¢Œì¸¡ í•˜ë‹¨ í†±ë‹ˆë°”í€´ <span class=\"kw\">&lt;kbd&gt;</span> Settings <span class=\"kw\">&lt;/kbd&gt;</span> ì„¤ì •ì„ í´ë¦­ í˜¹ì€ ë©”ë‰´ì—ì„œ \"File\" <span class=\"dv\">&amp;rarr;</span> \"Preferences\" <span class=\"dv\">&amp;rarr;</span> \"Settings\"ë¥¼ í†µí•´ <span class=\"in\">`í¸ì§‘ê¸° (Text Editor)`</span>ë¡œ ë“¤ì–´ê°€ ìš´ì˜ì²´ì œì— ì„¤ì¹˜í•œ ì½”ë”© í°íŠ¸ë¥¼ ì§€ì •í•œë‹¤. **Font Ligatures** ë„ <span class=\"in\">`true`</span>ë¡œ ì„¤ì •í•œë‹¤. ì´ë¥¼ í†µí•´ <span class=\"in\">`&lt; -`</span> í‘œì‹œê°€ <span class=\"dv\">&amp;larr;</span> ë¡œ í™”ë©´ì— í‘œí˜„ëœë‹¤.</span>\n<span id=\"cb5-102\"><a href=\"#cb5-102\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-103\"><a href=\"#cb5-103\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![D2ì½”ë”© ê¸€ê¼´ ì¥ì°©](images/vscode_font.png)</span></span>\n<span id=\"cb5-104\"><a href=\"#cb5-104\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-105\"><a href=\"#cb5-105\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ë‹¨ì¶•í‚¤</span></span>\n<span id=\"cb5-106\"><a href=\"#cb5-106\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-107\"><a href=\"#cb5-107\" aria-hidden=\"true\" tabindex=\"-1\"></a>R ì½”ë“œ ê°œë°œì„ ì§„í–‰í•  ë•Œ <span class=\"kw\">&lt;kbd&gt;</span> %&gt;% <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> <span class=\"dv\">&amp;larr;</span> <span class=\"kw\">&lt;/kbd&gt;</span> ë‘ê°€ì§€ ê¸°ëŠ¥ì´ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” </span>\n<span id=\"cb5-108\"><a href=\"#cb5-108\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë‹¨ì¶•í‚¤ë¡œ RStudioì—ì„œëŠ” ê¸°ë³¸ìœ¼ë¡œ ì§€ì›ë˜ê³  ìˆë‹¤. VS Codeì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” </span>\n<span id=\"cb5-109\"><a href=\"#cb5-109\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë‹¨ì¶•í‚¤ë¥¼ <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> m <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> - <span class=\"kw\">&lt;/kbd&gt;</span> ë¥¼ ì ìš©ì‹œí‚¤ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì.</span>\n<span id=\"cb5-110\"><a href=\"#cb5-110\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-111\"><a href=\"#cb5-111\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë§Œì•½ VS Codeì—ì„œ ë‹¨ì¶•í‚¤ ì„¤ì • ê¸°ëŠ¥ì„ í™œìš©í•œë‹¤. [<span class=\"co\">[</span><span class=\"ot\">How to add R {magrittr}'s %&gt;% Pipe Operator in VSCode as Keyboard Shortcut</span><span class=\"co\">](https://www.programmingwithr.com/how-to-add-r-magrittr-s-pipe-operator-in-vscode-as-keyboard-shortcut/)</span>]{.aside}</span>\n<span id=\"cb5-112\"><a href=\"#cb5-112\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-113\"><a href=\"#cb5-113\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>ìœˆë„ìš°ì¦ˆ: File &gt; Preferences &gt; Keyboard Shortcuts. </span>\n<span id=\"cb5-114\"><a href=\"#cb5-114\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>ë§¥: Code &gt; Preferences &gt; Keyboard Shortcuts</span>\n<span id=\"cb5-115\"><a href=\"#cb5-115\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-116\"><a href=\"#cb5-116\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`keybindings.json`</span> íŒŒì¼ì— <span class=\"kw\">&lt;kbd&gt;</span> %&gt;% <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> <span class=\"dv\">&amp;larr;</span> <span class=\"kw\">&lt;/kbd&gt;</span> ë‹¨ì¶•í‚¤ ê¸°ëŠ¥ì„ ì¶”ê°€í•œë‹¤.</span>\n<span id=\"cb5-117\"><a href=\"#cb5-117\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-118\"><a href=\"#cb5-118\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![ìì£¼ ì‚¬ìš©ë˜ëŠ” R ë‹¨ì¶•í‚¤ ì„¤ì •](images/vscode_shortcuts.png)</span></span>\n<span id=\"cb5-119\"><a href=\"#cb5-119\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-120\"><a href=\"#cb5-120\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## íŒ¨ë„</span></span>\n<span id=\"cb5-121\"><a href=\"#cb5-121\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-122\"><a href=\"#cb5-122\" aria-hidden=\"true\" tabindex=\"-1\"></a>RStudioëŠ” ì½”ë”©ê¸°ë°˜ ë°ì´í„° ë¶„ì„ê³¼ í†µê³„ì— ìµœì í™”ëœ ê°œë°œí™˜ê²½ì´ë‹¤. </span>\n<span id=\"cb5-123\"><a href=\"#cb5-123\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì¦‰, í¸ì§‘ê¸° íŒ¨ë„, ì½˜ì†”/í„°ë¯¸ë„ íŒ¨ë„, ê·¸ë˜í”„ íŒ¨ë„, ë„ì›€ë§/ê°œë°œ íŒ¨ë„ë¡œ êµ¬ì„±ëœ </span>\n<span id=\"cb5-124\"><a href=\"#cb5-124\" aria-hidden=\"true\" tabindex=\"-1\"></a>ê¼­ í•„ìš”í•œ íŒ¨ë„ë§Œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. </span>\n<span id=\"cb5-125\"><a href=\"#cb5-125\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-126\"><a href=\"#cb5-126\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.panel-tabset}</span>\n<span id=\"cb5-127\"><a href=\"#cb5-127\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-128\"><a href=\"#cb5-128\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### íŒ¨ë„ ì„¤ì • </span></span>\n<span id=\"cb5-129\"><a href=\"#cb5-129\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-130\"><a href=\"#cb5-130\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![VS Code: View &amp;rarr; Editor Layout &amp;rarr; Grid (2x2)](../../images/vscode_layout.png)</span></span>\n<span id=\"cb5-131\"><a href=\"#cb5-131\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-132\"><a href=\"#cb5-132\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### ì„¤ì • í›„</span></span>\n<span id=\"cb5-133\"><a href=\"#cb5-133\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-134\"><a href=\"#cb5-134\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![ë„ì›€ë§ê³¼ ê·¸ë˜í”„](images/vscode_layout_screen.png)</span></span>\n<span id=\"cb5-135\"><a href=\"#cb5-135\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-136\"><a href=\"#cb5-136\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-137\"><a href=\"#cb5-137\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># `Radiant`</span></span>\n<span id=\"cb5-138\"><a href=\"#cb5-138\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-139\"><a href=\"#cb5-139\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS ì½”ë“œ IDEë¥¼ í¬ê²Œ ì½”ë“œ í¸ì§‘ê¸° íŒ¨ë„ê³¼ R ì½˜ì†”ì°½ì— ì¶œë ¥ë˜ëŠ” ì‹¤í–‰ê²°ê³¼ë¬¼ ê°€ë…ì„±ì„ ë†’ì´ëŠ” ê²ƒì´ í•„ìš”í•˜ë‹¤.</span>\n<span id=\"cb5-140\"><a href=\"#cb5-140\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">`radian`</span><span class=\"co\">](https://github.com/randy3k/radian)</span>ì€ ì—¬ëŸ¬ ì¤„ í¸ì§‘(multiline editing)ê³¼ í’ë¶€í•œ êµ¬ë¬¸ ê°•ì¡°(syntax highlight) í‘œì‹œ ê¸°ëŠ¥ì„ ê°–ì¶˜ R í”„ë¡œê·¸ë¨ì„ ìœ„í•œ ëŒ€ì•ˆ ì½˜ì†”ë¡œ ë§ì´ ì‚¬ìš©ëœë‹¤.</span>\n<span id=\"cb5-141\"><a href=\"#cb5-141\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-142\"><a href=\"#cb5-142\" aria-hidden=\"true\" tabindex=\"-1\"></a>[<span class=\"co\">[</span><span class=\"ot\">Schiff consulting, 'Using R in VS Code: Some things I learned while trying out R in VS Code'</span><span class=\"co\">](https://schiff.co.nz/blog/r-and-vscode/)</span>]{.aside}</span>\n<span id=\"cb5-143\"><a href=\"#cb5-143\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-144\"><a href=\"#cb5-144\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ë…ë¦½ ì‚¬ìš©ì‚¬ë¡€</span></span>\n<span id=\"cb5-145\"><a href=\"#cb5-145\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-146\"><a href=\"#cb5-146\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::{#radiant layout-ncol=2}</span>\n<span id=\"cb5-147\"><a href=\"#cb5-147\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-148\"><a href=\"#cb5-148\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ì„¤ì¹˜ {.unnumbered}</span></span>\n<span id=\"cb5-149\"><a href=\"#cb5-149\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-150\"><a href=\"#cb5-150\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```bash</span></span>\n<span id=\"cb5-151\"><a href=\"#cb5-151\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\"># ì¶œì‹œë²„ì „ ì„¤ì¹˜</span></span>\n<span id=\"cb5-152\"><a href=\"#cb5-152\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ex\">pip3</span> install <span class=\"at\">-U</span> radian</span>\n<span id=\"cb5-153\"><a href=\"#cb5-153\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\"># ì‹¤í–‰</span></span>\n<span id=\"cb5-154\"><a href=\"#cb5-154\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ex\">radian</span></span>\n<span id=\"cb5-155\"><a href=\"#cb5-155\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-156\"><a href=\"#cb5-156\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-157\"><a href=\"#cb5-157\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ì‹¤í–‰í™”ë©´ {.unnumbered}</span></span>\n<span id=\"cb5-158\"><a href=\"#cb5-158\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-159\"><a href=\"#cb5-159\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-cmd.png)</span></span>\n<span id=\"cb5-160\"><a href=\"#cb5-160\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-161\"><a href=\"#cb5-161\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-162\"><a href=\"#cb5-162\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-163\"><a href=\"#cb5-163\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## VS ì½”ë“œ ì½˜ì†”</span></span>\n<span id=\"cb5-164\"><a href=\"#cb5-164\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-165\"><a href=\"#cb5-165\" aria-hidden=\"true\" tabindex=\"-1\"></a>radiantë¥¼ ì„¤ì¹˜í•œ í›„ì— ~~Rpath~~ ê°€ ì•„ë‹ˆë¼ **Rterm**ì—ì„œ ì„¤ì •í•´ì¤˜ì•¼ í•œë‹¤.</span>\n<span id=\"cb5-166\"><a href=\"#cb5-166\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-167\"><a href=\"#cb5-167\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::{#radian-vscode layout-ncol=3}</span>\n<span id=\"cb5-168\"><a href=\"#cb5-168\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-169\"><a href=\"#cb5-169\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### ë§¥ {.unnumbered}</span></span>\n<span id=\"cb5-170\"><a href=\"#cb5-170\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-171\"><a href=\"#cb5-171\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-mac.png)</span></span>\n<span id=\"cb5-172\"><a href=\"#cb5-172\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-173\"><a href=\"#cb5-173\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### ìœˆë„ìš°ì¦ˆ {.unnumbered}</span></span>\n<span id=\"cb5-174\"><a href=\"#cb5-174\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-175\"><a href=\"#cb5-175\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-windows.png)</span></span>\n<span id=\"cb5-176\"><a href=\"#cb5-176\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-177\"><a href=\"#cb5-177\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### ì ìš©ê²°ê³¼ {.unnumbered}</span></span>\n<span id=\"cb5-178\"><a href=\"#cb5-178\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-179\"><a href=\"#cb5-179\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radiant-penguins.png)</span></span>\n<span id=\"cb5-180\"><a href=\"#cb5-180\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-181\"><a href=\"#cb5-181\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-182\"><a href=\"#cb5-182\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-183\"><a href=\"#cb5-183\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-184\"><a href=\"#cb5-184\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-185\"><a href=\"#cb5-185\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># `.qmd`, `.Rmd` </span></span>\n<span id=\"cb5-186\"><a href=\"#cb5-186\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-187\"><a href=\"#cb5-187\" aria-hidden=\"true\" tabindex=\"-1\"></a>literate programmingì„ êµ¬í˜„í•œ <span class=\"in\">`.qmd`</span>, <span class=\"in\">`.Rmd`</span> íŒŒì¼ë¥¼ ì‘ì„±í•˜ì—¬ ë‹¤ì–‘í•œ ë°ì´í„° ê³¼í•™ </span>\n<span id=\"cb5-188\"><a href=\"#cb5-188\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë¬¸ì„œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.</span>\n<span id=\"cb5-189\"><a href=\"#cb5-189\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-190\"><a href=\"#cb5-190\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">**Pandoc** a universal document converter</span><span class=\"co\">](https://pandoc.org/installing.html)</span> ì›¹ì‚¬ì´íŠ¸ì—ì„œ</span>\n<span id=\"cb5-191\"><a href=\"#cb5-191\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`pandoc`</span>ì„ ì„¤ì¹˜í•´ì•¼ í•œë‹¤. pandoc ìµœì‹ ë²„ì „ì„ ì„¤ì¹˜í•˜ë©´ ë˜ê³  ë²„ì „ì´ 2.16 ì´ìƒì´ ë˜ì–´ì•¼ í™œìš©ì´ ê°€ëŠ¥í•˜ë‹¤.</span>\n<span id=\"cb5-192\"><a href=\"#cb5-192\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-193\"><a href=\"#cb5-193\" aria-hidden=\"true\" tabindex=\"-1\"></a>quarto-executable-code-5450563D</span>\n<span id=\"cb5-194\"><a href=\"#cb5-194\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-195\"><a href=\"#cb5-195\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```r</span></span>\n<span id=\"cb5-196\"><a href=\"#cb5-196\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">#| eval: false</span></span>\n<span id=\"cb5-197\"><a href=\"#cb5-197\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-198\"><a href=\"#cb5-198\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"sc\">$</span> pandoc <span class=\"sc\">--</span>version</span>\n<span id=\"cb5-199\"><a href=\"#cb5-199\" aria-hidden=\"true\" tabindex=\"-1\"></a>pandoc <span class=\"dv\">2</span>.<span class=\"fl\">19.2</span></span>\n<span id=\"cb5-200\"><a href=\"#cb5-200\" aria-hidden=\"true\" tabindex=\"-1\"></a>Compiled with pandoc<span class=\"sc\">-</span>types <span class=\"dv\">1</span>.<span class=\"dv\">22</span>.<span class=\"fl\">2.1</span>, texmath <span class=\"dv\">0</span>.<span class=\"dv\">12</span>.<span class=\"fl\">5.2</span>, skylighting <span class=\"fl\">0.13</span>,</span>\n<span id=\"cb5-201\"><a href=\"#cb5-201\" aria-hidden=\"true\" tabindex=\"-1\"></a>citeproc <span class=\"dv\">0</span>.<span class=\"dv\">8</span>.<span class=\"fl\">0.1</span>, ipynb <span class=\"fl\">0.2</span>, hslua <span class=\"dv\">2</span>.<span class=\"fl\">2.1</span></span>\n<span id=\"cb5-202\"><a href=\"#cb5-202\" aria-hidden=\"true\" tabindex=\"-1\"></a>Scripting engine<span class=\"sc\">:</span> Lua <span class=\"fl\">5.4</span></span>\n<span id=\"cb5-203\"><a href=\"#cb5-203\" aria-hidden=\"true\" tabindex=\"-1\"></a>User data directory<span class=\"sc\">:</span> C<span class=\"sc\">:</span>\\Users\\statkclee\\AppData\\Roaming\\pandoc</span>\n<span id=\"cb5-204\"><a href=\"#cb5-204\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">Copyright</span> (C) <span class=\"dv\">2006-2022</span> John MacFarlane. Web<span class=\"sc\">:</span>  https<span class=\"sc\">:</span><span class=\"er\">//</span>pandoc.org</span>\n<span id=\"cb5-205\"><a href=\"#cb5-205\" aria-hidden=\"true\" tabindex=\"-1\"></a>This is free software; see the source <span class=\"cf\">for</span> copying conditions. There is no</span>\n<span id=\"cb5-206\"><a href=\"#cb5-206\" aria-hidden=\"true\" tabindex=\"-1\"></a>warranty, not even <span class=\"cf\">for</span> merchantability or fitness <span class=\"cf\">for</span> a particular purpose.</span>\n<span id=\"cb5-207\"><a href=\"#cb5-207\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-208\"><a href=\"#cb5-208\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-209\"><a href=\"#cb5-209\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## `keybindings.json`</span></span>\n<span id=\"cb5-210\"><a href=\"#cb5-210\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-211\"><a href=\"#cb5-211\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`keybindings.json`</span> íŒŒì¼ì— R í˜¹ì€ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‚½ì…ì‹œí‚¬ ìˆ˜ ìˆëŠ” í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ë¥¼ </span>\n<span id=\"cb5-212\"><a href=\"#cb5-212\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë“±ë¡ì‹œí‚¨ë‹¤. <span class=\"co\">[</span><span class=\"ot\">ìë£Œì¶œì²˜: [VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding](https://www.schmidtynotes.com/blog/r/2021-09-28-vscode-rmd-code-chunk-snippet/)</span><span class=\"co\">]</span>{.aside}</span>\n<span id=\"cb5-213\"><a href=\"#cb5-213\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-214\"><a href=\"#cb5-214\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.callout-tip collapse=\"true\"}</span>\n<span id=\"cb5-215\"><a href=\"#cb5-215\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-216\"><a href=\"#cb5-216\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### `keybindings.json` ì„¤ì •íŒŒì¼ ì˜ˆì‹œ</span></span>\n<span id=\"cb5-217\"><a href=\"#cb5-217\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-218\"><a href=\"#cb5-218\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-219\"><a href=\"#cb5-219\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```json</span></span>\n<span id=\"cb5-220\"><a href=\"#cb5-220\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">// Place your key bindings in this file to override the defaults</span></span>\n<span id=\"cb5-221\"><a href=\"#cb5-221\" aria-hidden=\"true\" tabindex=\"-1\"></a>[</span>\n<span id=\"cb5-222\"><a href=\"#cb5-222\" aria-hidden=\"true\" tabindex=\"-1\"></a>    <span class=\"co\">// keybindings for R scripts. </span></span>\n<span id=\"cb5-223\"><a href=\"#cb5-223\" aria-hidden=\"true\" tabindex=\"-1\"></a>    {</span>\n<span id=\"cb5-224\"><a href=\"#cb5-224\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-225\"><a href=\"#cb5-225\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-226\"><a href=\"#cb5-226\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-227\"><a href=\"#cb5-227\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == r\"</span></span>\n<span id=\"cb5-228\"><a href=\"#cb5-228\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-229\"><a href=\"#cb5-229\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-230\"><a href=\"#cb5-230\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-231\"><a href=\"#cb5-231\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-232\"><a href=\"#cb5-232\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-233\"><a href=\"#cb5-233\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == r\"</span></span>\n<span id=\"cb5-234\"><a href=\"#cb5-234\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-235\"><a href=\"#cb5-235\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// keybindings for Rmarkdown</span></span>\n<span id=\"cb5-236\"><a href=\"#cb5-236\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-237\"><a href=\"#cb5-237\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-238\"><a href=\"#cb5-238\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-239\"><a href=\"#cb5-239\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-240\"><a href=\"#cb5-240\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == rmd\"</span></span>\n<span id=\"cb5-241\"><a href=\"#cb5-241\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-242\"><a href=\"#cb5-242\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-243\"><a href=\"#cb5-243\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-244\"><a href=\"#cb5-244\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-245\"><a href=\"#cb5-245\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-246\"><a href=\"#cb5-246\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == rmd\"</span></span>\n<span id=\"cb5-247\"><a href=\"#cb5-247\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-248\"><a href=\"#cb5-248\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// keybindings for R terminal (radian included)</span></span>\n<span id=\"cb5-249\"><a href=\"#cb5-249\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-250\"><a href=\"#cb5-250\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-251\"><a href=\"#cb5-251\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"workbench.action.terminal.sendSequence\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-252\"><a href=\"#cb5-252\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-253\"><a href=\"#cb5-253\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"terminalFocus\"</span></span>\n<span id=\"cb5-254\"><a href=\"#cb5-254\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-255\"><a href=\"#cb5-255\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-256\"><a href=\"#cb5-256\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-257\"><a href=\"#cb5-257\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"workbench.action.terminal.sendSequence\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-258\"><a href=\"#cb5-258\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-259\"><a href=\"#cb5-259\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"terminalFocus\"</span></span>\n<span id=\"cb5-260\"><a href=\"#cb5-260\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-261\"><a href=\"#cb5-261\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// Insert R Code chunk</span></span>\n<span id=\"cb5-262\"><a href=\"#cb5-262\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-263\"><a href=\"#cb5-263\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+i\"</span><span class=\"op\">.</span> </span>\n<span id=\"cb5-264\"><a href=\"#cb5-264\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-265\"><a href=\"#cb5-265\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-266\"><a href=\"#cb5-266\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> {<span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"```{r}</span><span class=\"sc\">\\n</span><span class=\"st\">$0</span><span class=\"sc\">\\n</span><span class=\"st\">```\"</span>}</span>\n<span id=\"cb5-267\"><a href=\"#cb5-267\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-268\"><a href=\"#cb5-268\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-269\"><a href=\"#cb5-269\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+o\"</span><span class=\"op\">.</span> </span>\n<span id=\"cb5-270\"><a href=\"#cb5-270\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-271\"><a href=\"#cb5-271\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-272\"><a href=\"#cb5-272\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> {<span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"options(</span><span class=\"sc\">\\n</span><span class=\"st\">  max.print=100,</span><span class=\"sc\">\\n</span><span class=\"st\">  vsc.use_httpgd=TRUE,</span><span class=\"sc\">\\n</span><span class=\"st\">  device='quartz'</span><span class=\"sc\">\\n</span><span class=\"st\">)\"</span>}</span>\n<span id=\"cb5-273\"><a href=\"#cb5-273\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-274\"><a href=\"#cb5-274\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-275\"><a href=\"#cb5-275\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-276\"><a href=\"#cb5-276\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-277\"><a href=\"#cb5-277\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-278\"><a href=\"#cb5-278\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span>{</span>\n<span id=\"cb5-279\"><a href=\"#cb5-279\" aria-hidden=\"true\" tabindex=\"-1\"></a>          <span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"---</span><span class=\"sc\">\\n</span><span class=\"st\">title: '$0'</span><span class=\"sc\">\\n</span><span class=\"st\">author: 'ì´ê´‘ì¶˜'</span><span class=\"sc\">\\n</span><span class=\"st\">date: '`r Sys.Date()`'</span><span class=\"sc\">\\n</span><span class=\"st\">output:</span><span class=\"sc\">\\n</span><span class=\"st\">  pagedown::html_paged:</span><span class=\"sc\">\\n</span><span class=\"st\">    self_contained: true</span><span class=\"sc\">\\n</span><span class=\"st\">    toc: false</span><span class=\"sc\">\\n</span><span class=\"st\">---</span><span class=\"sc\">\\n\\n</span><span class=\"st\">```{r setup, include=FALSE}</span><span class=\"sc\">\\n</span><span class=\"st\">knitr::opts_chunk</span><span class=\"sc\">\\\\</span><span class=\"st\">$set(</span><span class=\"sc\">\\n</span><span class=\"st\">  echo = FALSE,</span><span class=\"sc\">\\n</span><span class=\"st\">  message = FALSE,</span><span class=\"sc\">\\n</span><span class=\"st\">  warning=FALSE</span><span class=\"sc\">\\n</span><span class=\"st\">)</span><span class=\"sc\">\\n</span><span class=\"st\">```\"</span></span>\n<span id=\"cb5-280\"><a href=\"#cb5-280\" aria-hidden=\"true\" tabindex=\"-1\"></a>        }</span>\n<span id=\"cb5-281\"><a href=\"#cb5-281\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-282\"><a href=\"#cb5-282\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-283\"><a href=\"#cb5-283\" aria-hidden=\"true\" tabindex=\"-1\"></a>]</span>\n<span id=\"cb5-284\"><a href=\"#cb5-284\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-285\"><a href=\"#cb5-285\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-286\"><a href=\"#cb5-286\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-287\"><a href=\"#cb5-287\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-288\"><a href=\"#cb5-288\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## HTML ë¯¸ë¦¬ë³´ê¸°</span></span>\n<span id=\"cb5-289\"><a href=\"#cb5-289\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-290\"><a href=\"#cb5-290\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`.Rmd`</span> íŒŒì¼ì„ <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> k <span class=\"kw\">&lt;/kbd&gt;</span> ë‹¨ì¶•í‚¤ë¡œ ì»´íŒŒì¼ì‹œí‚¤ë©´ </span>\n<span id=\"cb5-291\"><a href=\"#cb5-291\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`.html`</span> íŒŒì¼ì´ ìƒì„±ëœë‹¤. <span class=\"in\">`.html`</span> íŒŒì¼ ê²°ê³¼ë¥¼ ì§ì ‘ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³ ì í•œë‹¤ë©´, </span>\n<span id=\"cb5-292\"><a href=\"#cb5-292\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ê°œë°œí•œ <span class=\"co\">[</span><span class=\"ot\">`Live Preview - VS Code Extension`</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=ms-vscode.live-server)</span> í”ŒëŸ¬ê·¸ì¸ì„ ì„¤ì¹˜í•œë‹¤.</span>\n<span id=\"cb5-293\"><a href=\"#cb5-293\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-294\"><a href=\"#cb5-294\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/vscode_open-context-menu.gif)</span></span>\n<span id=\"cb5-295\"><a href=\"#cb5-295\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-296\"><a href=\"#cb5-296\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-297\"><a href=\"#cb5-297\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># GitHub copilot</span></span>\n<span id=\"cb5-298\"><a href=\"#cb5-298\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-299\"><a href=\"#cb5-299\" aria-hidden=\"true\" tabindex=\"-1\"></a>GitHubì—ì„œ ê³µê°œí•œ Copilotì€ AI pair programmerë¼ëŠ” ë¶€ì œë¥¼ ë‹¬ê³  ìˆê³ ,</span>\n<span id=\"cb5-300\"><a href=\"#cb5-300\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">GitHub Copilot</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)</span> í”ŒëŸ¬ê·¸ì¸ì„ </span>\n<span id=\"cb5-301\"><a href=\"#cb5-301\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì„¤ì¹˜í•˜ë©´ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.</span>\n<span id=\"cb5-302\"><a href=\"#cb5-302\" aria-hidden=\"true\" tabindex=\"-1\"></a>í•œê°€ì§€ <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span> ë‹¨ì¶•í‚¤ê°€ ì¶©ëŒë˜ì–´ R ì½”ë“œ ì‹¤í–‰í•˜ëŠ” ê²ƒê³¼ ê²¹ì³ì„œ ë¬¸ì œê°€ ìˆê¸° ë•Œë¬¸ì—</span>\n<span id=\"cb5-303\"><a href=\"#cb5-303\" aria-hidden=\"true\" tabindex=\"-1\"></a>ë‹¨ì¶•í‚¤ë¥¼ <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span>ì™€ ê°™ì´ ì¡°ì •í•˜ë©´ í° ë¬¸ì œ ì—†ì´ </span>\n<span id=\"cb5-304\"><a href=\"#cb5-304\" aria-hidden=\"true\" tabindex=\"-1\"></a>R ê°œë°œí•  ë•Œ GitHub copilotê³¼ í•¨ê»˜ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.</span>\n<span id=\"cb5-305\"><a href=\"#cb5-305\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì´ë¥¼ ìœ„í•´ì„œ <span class=\"in\">`keybindings.json`</span> íŒŒì¼ì— ë‹¤ìŒ ì‚¬í•­ì„ ì¶”ê°€í•œë‹¤. </span>\n<span id=\"cb5-306\"><a href=\"#cb5-306\" aria-hidden=\"true\" tabindex=\"-1\"></a>ì‚¬ìš©ìë³„ë¡œ ë‹¨ì¶•í‚¤ë¥¼ ë‹¬ë¦¬í•´ì„œ ì ìš©ì‹œí‚¤ëŠ” ê²ƒë„ ë¬¼ë¡  ê°€ëŠ¥í•˜ë‹¤.</span>\n<span id=\"cb5-307\"><a href=\"#cb5-307\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-308\"><a href=\"#cb5-308\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>ì½”ë“œ ë¼ì¸ë³„ë¡œ ì¶”ì²œ ìŠ¹ì¸: <span class=\"kw\">&lt;kbd&gt;</span> Tab <span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-309\"><a href=\"#cb5-309\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>ì „ì²´ ì½”ë“œ ì‘ì„± ì „ì²´ ì¶”ì²œ : <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-310\"><a href=\"#cb5-310\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span><span class=\"in\">`Accept Solution`</span> í´ë¦­</span>\n<span id=\"cb5-311\"><a href=\"#cb5-311\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span>ì½”ë“œ ì‘ì„± í¸ì§‘ê¸°ì— ê´€ë ¨ ì‚¬í•­ ë°˜ì˜</span>\n<span id=\"cb5-312\"><a href=\"#cb5-312\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-313\"><a href=\"#cb5-313\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-314\"><a href=\"#cb5-314\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.callout-tip collapse=\"true\"}</span>\n<span id=\"cb5-315\"><a href=\"#cb5-315\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-316\"><a href=\"#cb5-316\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### `keybindings.json` ì„¤ì •íŒŒì¼ ì˜ˆì‹œ</span></span>\n<span id=\"cb5-317\"><a href=\"#cb5-317\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-318\"><a href=\"#cb5-318\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-319\"><a href=\"#cb5-319\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```json</span></span>\n<span id=\"cb5-320\"><a href=\"#cb5-320\" aria-hidden=\"true\" tabindex=\"-1\"></a>[</span>\n<span id=\"cb5-321\"><a href=\"#cb5-321\" aria-hidden=\"true\" tabindex=\"-1\"></a>  <span class=\"op\">...</span></span>\n<span id=\"cb5-322\"><a href=\"#cb5-322\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// GitHub Copilot</span></span>\n<span id=\"cb5-323\"><a href=\"#cb5-323\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-324\"><a href=\"#cb5-324\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+shift+alt+enter\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-325\"><a href=\"#cb5-325\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"github.copilot.generate\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-326\"><a href=\"#cb5-326\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; github.copilot.activated &amp;&amp; editorLangId == 'r'\"</span></span>\n<span id=\"cb5-327\"><a href=\"#cb5-327\" aria-hidden=\"true\" tabindex=\"-1\"></a>    }<span class=\"op\">,</span></span>\n<span id=\"cb5-328\"><a href=\"#cb5-328\" aria-hidden=\"true\" tabindex=\"-1\"></a>    {</span>\n<span id=\"cb5-329\"><a href=\"#cb5-329\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"tab\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-330\"><a href=\"#cb5-330\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.inlineSuggest.commit\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-331\"><a href=\"#cb5-331\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"textInputFocus &amp;&amp; inlineSuggestionHasIndentationLessThanTabSize &amp;&amp; inlineSuggestionVisible &amp;&amp; !editorTabMovesFocus\"</span>     </span>\n<span id=\"cb5-332\"><a href=\"#cb5-332\" aria-hidden=\"true\" tabindex=\"-1\"></a>    }<span class=\"op\">,</span></span>\n<span id=\"cb5-333\"><a href=\"#cb5-333\" aria-hidden=\"true\" tabindex=\"-1\"></a>]</span>\n<span id=\"cb5-334\"><a href=\"#cb5-334\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span>    </span>\n<span id=\"cb5-335\"><a href=\"#cb5-335\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-336\"><a href=\"#cb5-336\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-337\"><a href=\"#cb5-337\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-338\"><a href=\"#cb5-338\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ì¤‘ìš” ì¶”ê°€ì„¤ì •</span></span>\n<span id=\"cb5-339\"><a href=\"#cb5-339\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-340\"><a href=\"#cb5-340\" aria-hidden=\"true\" tabindex=\"-1\"></a>Principal Cloud Advocate at Microsoft David Smithê°€ \"New York Open Statistical Programming Meetup, 28 February 2023\"ì—ì„œ ë°œí‘œí•œ **Copilot for R** ë‚´ìš© ì¤‘ VS ì½”ë“œ í™˜ê²½ì„¤ì •ë¶€ë¶„ì´ë‹¤. </span>\n<span id=\"cb5-341\"><a href=\"#cb5-341\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-342\"><a href=\"#cb5-342\" aria-hidden=\"true\" tabindex=\"-1\"></a>[<span class=\"co\">[</span><span class=\"ot\">Copilot for R</span><span class=\"co\">](https://github.com/revodavid/copilot-for-r)</span>]{.aside}</span>\n<span id=\"cb5-343\"><a href=\"#cb5-343\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-344\"><a href=\"#cb5-344\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>VS ì½”ë“œ </span>\n<span id=\"cb5-345\"><a href=\"#cb5-345\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span><span class=\"co\">[</span><span class=\"ot\">Copilot extension</span><span class=\"co\">](https://aka.ms/get-copilot)</span></span>\n<span id=\"cb5-346\"><a href=\"#cb5-346\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span><span class=\"co\">[</span><span class=\"ot\">R Extension for Visual Studio Code</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r)</span></span>\n<span id=\"cb5-347\"><a href=\"#cb5-347\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>copilot ì¶”ì²œì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ì„œ ë‹¤ìŒ ì‚¬í•­ë„ ì„¤ì •ì— ë°˜ì˜í•œë‹¤.</span>\n<span id=\"cb5-348\"><a href=\"#cb5-348\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Hover (disabled)</span>\n<span id=\"cb5-349\"><a href=\"#cb5-349\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Quick Suggestions (off)</span>\n<span id=\"cb5-350\"><a href=\"#cb5-350\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Parameter Hints (disabled)</span>\n<span id=\"cb5-351\"><a href=\"#cb5-351\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>R íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° <span class=\"in\">`opitions()`</span></span>\n<span id=\"cb5-352\"><a href=\"#cb5-352\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>httr, jsonlite, tidyverse, tidymodels, docopt, httpuv</span>\n<span id=\"cb5-353\"><a href=\"#cb5-353\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>ê°€ë…ì„± ë†’ì€ ê·¸ë˜í”„ ì¶œë ¥: <span class=\"in\">`options(vsc.dev.args = list(width = 800, height = 600))`</span></span>\n<span id=\"cb5-354\"><a href=\"#cb5-354\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-355\"><a href=\"#cb5-355\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## ì‹¤ì œ ì ìš© ì‚¬ë¡€</span></span>\n<span id=\"cb5-356\"><a href=\"#cb5-356\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-357\"><a href=\"#cb5-357\" aria-hidden=\"true\" tabindex=\"-1\"></a>í­ê·„ê³¼ í˜¸ë°• ë°ì´í„°ë¥¼ ì ìš©í•œ ì‚¬ë¡€ ì‹œì—°ì„ ì‚´í´ë³´ì.</span>\n<span id=\"cb5-358\"><a href=\"#cb5-358\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-359\"><a href=\"#cb5-359\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-360\"><a href=\"#cb5-360\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### í­ê·„ ë°ì´í„°ì…‹ {.unnumbered}</span></span>\n<span id=\"cb5-361\"><a href=\"#cb5-361\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-362\"><a href=\"#cb5-362\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-363\"><a href=\"#cb5-363\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/vscode_copilot.gif)</span></span>\n<span id=\"cb5-364\"><a href=\"#cb5-364\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-365\"><a href=\"#cb5-365\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-366\"><a href=\"#cb5-366\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### í˜¸ë°• ë°ì´í„°ì…‹ {.unnumbered}</span></span>\n<span id=\"cb5-367\"><a href=\"#cb5-367\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-368\"><a href=\"#cb5-368\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"kw\">&lt;iframe</span> <span class=\"er\">src</span><span class=\"ot\">=</span><span class=\"st\">\"images/pumpkins-copilot.mp4\"</span> <span class=\"er\">allowfullscreen</span> <span class=\"er\">allow</span><span class=\"ot\">=</span><span class=\"st\">\"encrypted-media\"</span> <span class=\"er\">width</span><span class=\"ot\">=</span><span class=\"st\">\"320\"</span> <span class=\"er\">height</span><span class=\"ot\">=</span><span class=\"st\">\"180\"</span><span class=\"kw\">&gt;</span></span>\n<span id=\"cb5-369\"><a href=\"#cb5-369\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-370\"><a href=\"#cb5-370\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-371\"><a href=\"#cb5-371\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-372\"><a href=\"#cb5-372\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">    </span></span></code></pre></div>\n</div>"
  },
  {
    "objectID": "interface.html",
    "href": "interface.html",
    "title": "chatGPT",
    "section": "",
    "text": "íŠ¹ì • ì‘ì—…ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ëŠ” ê²€ìƒ‰(search)ì€ ê¸°í•œì´ ì •í•´ì§„ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•¨ì— ìˆì–´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤. chatGPTì˜ ë“±ì¥ìœ¼ë¡œ ìƒˆë¡œìš´ ê²€ìƒ‰ íŒ¨ëŸ¬ë‹¤ì„ì´ ì œì‹œë˜ê³  ìˆë‹¤. ë¬¼ë¡  ê¸°ì¡´ ê²€ìƒ‰ë°©ì‹ì´ ë¶€ì¡±í•œ ê²ƒì€ ì•„ë‹ˆë©° ê²€ìƒ‰ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë§ì€ ë…¸ë ¥ì´ ê²½ì£¼ëœ ê²ƒë„ ì‚¬ì‹¤ì´ë‹¤. ì°¨ì„¸ëŒ€ Rë§ˆí¬ë‹¤ìš´ ì¿¼í† (quarto) ë¬¸ì„œ ì œì‘ì‚¬ë¡€ì„ ìœ„í•œ ê²€ìƒ‰ì‚¬ë¡€ë¥¼ í†µí•´ chatGPTì™€ ë¹„êµí•˜ì—¬ ë³´ì.\n\nêµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ì¼ë°˜ì ì¸ ë‚´ìš©ì„ ì–»ì„ ìˆ˜ë„ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´,\n\nsite:quarto.org/ google analytics tracking code\n\nêµ¬ê¸€ê²€ìƒ‰ì°½ì— ìƒê¸° ì‚¬í•­ì„ ì…ë ¥í•˜ê²Œ ë˜ë©´ êµ¬ê¸€ì€ ì¿¼í† (quarto) ì›¹ì‚¬ì´íŠ¸ ë‚´ë¶€ì—ì„œ google analytics tracking code í‚¤ì›Œë“œì™€ ê´€ë ¨ì´ ë†’ì€ ì›¹í˜ì´ì§€ë¥¼ ê²€ìƒ‰ê²°ê³¼ë¡œ ë°˜í™˜ì‹œí‚¤ê²Œ ëœë‹¤.\n\n\n\n\n\nQuartoëŠ” ì›¹ì‚¬ì´íŠ¸ì™€ ì±…ì˜ ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ”ë°, ê¸°ë³¸ì ìœ¼ë¡œ QuartoëŠ” ì‚¬ì´íŠ¸ì˜ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ìƒ‰ì¸í™”í•˜ì—¬ ê¸°ë³¸ì ìœ¼ë¡œ ë¡œì»¬ë¡œ êµ¬ì¶•ëœ ìƒ‰ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë†’ì€ ê²€ìƒ‰í’ˆì§ˆì„ ì œê³µí•œë‹¤. ë”°ë¼ì„œ, ì‚¬ìš©ìëŠ” êµ¬ê¸€ì›¹ì‚¬ì´íŠ¸ê°€ ì•„ë‹ˆë¼ ì¿¼í† (quarto)ì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ì§ì ‘ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤.\n\n\n\n\n\nChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆë‹¤. íŠ¹ì • ì›¹ì‚¬ì´íŠ¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì–»ì–´ì•¼ ë˜ê¸° ë•Œë¬¸ì— ì§€ì‹œëª…ë ¹ì–´(Prompt)ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•œë‹¤.\n\nsearch https://quarto.org/ insert google analytics tracking code for quarto html document\n\n\n\n\n\n\nì¿¼í† (Quarto)ëŠ” ì°¨ì„¸ëŒ€ Rë§ˆí¬ë‹¤ìš´ì´ë¼ëŠ” ë³„ëª…ì´ ë¶™ì–´ ìˆì„ ì •ë„ë¡œ Rë§ˆí¬ë‹¤ìš´ì´ ê°–ëŠ” ëª¨ë“  ê¸°ëŠ¥ì— ë”í•˜ì—¬ ì¶”ê°€ë¡œ ìƒˆë¡œìš´ ì–¸ì–´(Python, R, Julia, Observable.)ì— ëŒ€í•œ ì§€ì›ë„ í¬ê´„í•˜ê³  ìˆì–´ ìƒë‹¹í•œ í•™ìŠµëŸ‰ì„ ìš”êµ¬í•œë‹¤. ì„¤ê³„ëŠ” ê¹”ë”í•˜ê²Œ ì˜ ë˜ì–´ ìˆì§€ë§Œ ì´ê²ƒì„ ì˜ ì‚¬ìš©í•˜ë ¤ë©´ ìƒë‹¹í•œ í•™ìŠµëŸ‰ì´ í•„ìš”ë¡œ í•œë‹¤. ì´ëŸ° ë¬¸ì œì— chatGPTë¥¼ ë„ì…í•˜ì—¬ ì‚¬ìš©í•˜ë©´ ê²½ìš°ì— ë”°ë¼ì„œ í° ë„ì›€ì„ ì¤„ ìˆ˜ë„ ìˆë‹¤.\n\nQuarto Help Bot - Ask a question about Quarto.\n\n\n\n\n\n:::\në‚´ë¶€ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ì§ˆë¬¸-ì‘ë‹µ(QnA)ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì„¸ë¶„í™”ë˜ì–´ ìˆìœ¼ë©°, ëª¨ë‘ ChatVectorDBChainì´ ì²˜ë¦¬í•œë‹¤:\n\nì±„íŒ… ê¸°ë¡ê³¼ ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§€ë©´ ë…ë¦½í˜• ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ì§€ ê²°ì •(GPT-3 ì‚¬ìš©).\në…ë¦½í˜• ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰.\në…ë¦½í˜• ì§ˆë¬¸ê³¼ ê´€ë ¨ ë¬¸ì„œë¥¼ GPT-3ì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±."
  },
  {
    "objectID": "use-cases.html",
    "href": "use-cases.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì¶œì²˜: ë‚´ ì¹´í†¡ì—” ì±—GPTê°€ ë“¤ì–´ìˆë‹¤\nê¸‰í•œê²½ìš° ëª¨ë°”ì¼ì—ì„œ chatGPT ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‚˜, ëŒ€ë¶€ë¶„ ë°ìŠ¤í¬í†± PCì—ì„œ chatGPTë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. chatGPT ì‚¬ìš©ì í™˜ê²½ì´ ì˜ì–´ ì‚¬ìš©ìì— ì´ˆì ì„ ë§ì¶”ë‹¤ë³´ë‹ˆ í•œêµ­ì–´ë¥¼ ëª¨êµ­ì–´ë¡œ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìëŠ” ë²ˆì—­ì´ ê¼­ í•„ìš”í•œ ê²½ìš°ê°€ ë§ë‹¤. ì´ì™€ ê°™ì€ ê²½ìš° í¬ë¡¬ ì›¹ë¸Œë¼ìš°ì ¸ chrome ì›¹ ìŠ¤í† ì–´ì—ì„œ í™•ì¥ í”„ë¡œê·¸ë¨(Extension)ì„ ì‚¬ìš©í•˜ë©´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "use-cases.html#chatgpt-ìµœì¢…-ì •ë³´",
    "href": "use-cases.html#chatgpt-ìµœì¢…-ì •ë³´",
    "title": "chatGPT",
    "section": "\n1.1 chatGPT ìµœì¢… ì •ë³´",
    "text": "1.1 chatGPT ìµœì¢… ì •ë³´\n\n\n\n\n\n\nwhen was your last training date?\n\n\n\n\n\nAs an AI language model, I am continuously being trained and updated to improve my performance and accuracy. My last major training update occurred in September 2021, but I am continually receiving smaller updates and improvements to my knowledge and capabilities."
  },
  {
    "objectID": "use-cases.html#ì›¹ê²€ìƒ‰",
    "href": "use-cases.html#ì›¹ê²€ìƒ‰",
    "title": "chatGPT",
    "section": "\n1.2 ì›¹ê²€ìƒ‰",
    "text": "1.2 ì›¹ê²€ìƒ‰\nì´ëŸ¬í•œ í•œê³„ë¥¼ ë³´ì™„í•˜ëŠ” WebChatGPT ë¥¼ í†µí•´ì„œ ìµœì‹  ê²€ìƒ‰ ê¸°ëŠ¥ì„ ë³´ì™„í•  ìˆ˜ë„ ìˆë‹¤. í•˜ì§€ë§Œ WebChatGPTë¥¼ í™œì„±í™”ì‹œí‚¤ëŠ” ìˆœê°„ chatGPT ê¸°ëŠ¥ë„ ì—†ì–´ì ¸ ë‹¨ìˆœí•œ ê²€ìƒ‰ê¸°ë¡œ ë³€í™˜ë˜ë‹ˆ ìœ ì˜í•œë‹¤. ê°œë°œì†ŒìŠ¤ì½”ë“œëŠ” qunash/chatgpt-advancedë¥¼ ì°¸ì¡°í•œë‹¤."
  },
  {
    "objectID": "news_article.html",
    "href": "news_article.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì‚¬ë‹¨ë²•ì¸ í•œêµ­ R ì‚¬ìš©ìíšŒ ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ê¸°ì‚¬ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(googlesheets4)\nlibrary(lubridate)\nlibrary(gt)\n\nnews_raw <- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1KITnaJTqsDHtm-wUWboog4xG6U6SBuB_Zee8qpCgLN4/edit?usp=sharing\", sheet = \"ë‰´ìŠ¤ê¸°ì‚¬\")\n\nnews_tbl <- news_raw %>% \n  mutate(ë‚ ì§œ = as.Date(ë‚ ì§œ)) %>% \n  arrange(desc(ë‚ ì§œ)) %>% \n  mutate(ë‰´ìŠ¤ë§í¬ = sprintf('<a href = \"%s\">%s</a>', ë§í¬, `ë‰´ìŠ¤ê¸°ì‚¬ ì œëª©`),\n         ë‰´ìŠ¤ë§í¬ = map(ë‰´ìŠ¤ë§í¬, gt::html))  %>% \n  select(ë‚ ì§œ, ì–¸ë¡ ì‚¬, ê¸°ìëª…, ê¸°ìëª…, ë§í¬, ë‰´ìŠ¤ë§í¬)\n\nnews_tbl %>% \n  select(-ë§í¬) %>% \n  gt() %>% \n    cols_align(\n    align = \"center\",\n    columns = everything()\n  )\n\n\n\n\n\n\në‚ ì§œ\n      ì–¸ë¡ ì‚¬\n      ê¸°ìëª…\n      ë‰´ìŠ¤ë§í¬\n    \n\n\n2022-04-18\nì˜¤ë§ˆì´ë‰´ìŠ¤\nì´ê´‘ì¶˜\ní†µê³„ ëŒ€ì¤‘í™” ìœ„í•œ 'ì˜¤í”ˆ í†µê³„ íŒ¨í‚¤ì§€' ë‚˜ì™”ë‹¤ - ì˜¤ë§ˆì´ë‰´ìŠ¤\n\n\n2021-10-25\nIT ì¡°ì„ \nì´ìœ¤ê²½\n\"ë””ì§€í„¸ ê²½ì œ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì€ R\"â€¦í•œêµ­R ì½˜í¼ëŸ¬ìŠ¤, 11ì›” 19ì¼ ê°œìµœ - ITì¡°ì„  > ê¸°ìˆ  > ì¼ë°˜\n\n\n2021-09-18\ní•œê²¨ë ˆ\nê¶Œì˜¤ì„±\në°ì´í„° ë¶„ì„ ì–¸ì–´ â€˜Râ€™ í•œêµ­ ì½˜í¼ëŸ°ìŠ¤ ì—´ë¦°ë‹¤\n\n\n2016-12-07\nKBS\nìµœê±´ì¼\nì¸ê³µì§€ëŠ¥ìœ¼ë¡œ ë¶„ì„í•œ ëŒ€í†µë ¹ì˜ ë§ˆìŒâ€¦ìŠ¬í””ì€ ì–´ë””ì—?\n\n\n2015-01-31\nIT Daily\níŒ½ë™í˜„\n[ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ì„œ] â€œë¹…ë°ì´í„° ë¶„ì„, ë°ì´í„°ì˜ ë³¸ì§ˆì„ ë°”ë¼ë³´ëŠ” ê²ƒë¶€í„°â€\n\n\n2012-10-11\në””ì§€í„¸ ë°ì¼ë¦¬\në°±ì§€ì˜\në„¥ìŠ¤ì•Œ, â€˜Rì‚¬ìš©ìì»¨í¼ëŸ°ìŠ¤ 2012â€™ 24ì¼ ê°œìµœ"
  },
  {
    "objectID": "news_article.html#ë³´ë„ìë£Œ-ì´ˆì•ˆ",
    "href": "news_article.html#ë³´ë„ìë£Œ-ì´ˆì•ˆ",
    "title": "chatGPT",
    "section": "\n4.1 ë³´ë„ìë£Œ ì´ˆì•ˆ",
    "text": "4.1 ë³´ë„ìë£Œ ì´ˆì•ˆ\n\ní”„ë¡¬í”„íŠ¸: ë¹„ì˜ë¦¬ë²•ì¸ í•œêµ­ R ì‚¬ìš©ìíšŒëŠ” 2017ë…„ë¶€í„° ë§¤ë…„ êµ­ë‚´ ìœ ì¼ì˜ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë°‹ì—…(Meetup)ì„ ì£¼ê´€í•˜ê³  ìˆìŠµë‹ˆë‹¤. 2023ë…„ ì˜¬í•´ëŠ” êµë³´ìƒëª…ë³´í—˜ ê·¸ë£¹ ë°ì´í„° ë¶„ì„ ë²•ì¸ ë””í”Œë˜ë‹‰ìŠ¤(DPlanex)ì˜ í›„ì›ì„ ë°›ì•„ â€œChatGPTì™€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤â€ ì£¼ì œë¡œ ì´ 6íšŒì— ê²°ì³ ê°•ë‚¨ êµë³´íƒ€ì›Œ 5ì¸µ ë…¸ë¸”ë¦¬ì—í™€ì—ì„œ í–‰ì‚¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ì´ì— ëŒ€í•œ í™ë³´ ê¸°ì‚¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n\n\n\n\n\n\nì£¼ì˜\n\n\n\n\n\ní•œêµ­ R ì‚¬ìš©ìíšŒ ë¹„ì˜ë¦¬ë²•ì¸ì´ 2017ë…„ë¶€í„° êµ­ë‚´ ìœ ì¼í•œ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë°‹ì—…ì„ ì„±ê³µì ìœ¼ë¡œ ê°œìµœí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ 2023ë…„, êµë³´ìƒëª…ë³´í—˜ ê·¸ë£¹ì˜ ë°ì´í„° ë¶„ì„ ë²•ì¸ì¸ ë””í”Œë˜ë‹‰ìŠ¤(DPlanex)ì˜ í›„ì›ìœ¼ë¡œ, â€œChatGPTì™€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤â€ ì£¼ì œë¡œ ì´ 6íšŒì— ê±¸ì³ ê°•ë‚¨ êµë³´íƒ€ì›Œ 5ì¸µ ë…¸ë¸”ë¦¬ì—í™€ì—ì„œ í–‰ì‚¬ë¥¼ ê°œìµœí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´ë²ˆ í–‰ì‚¬ëŠ” ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì™€ ì¸ê³µì§€ëŠ¥ì˜ ìµœì‹  ë™í–¥ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì´ê³ , ChatGPT ê¸°ìˆ ì„ í™œìš©í•œ ë°ì´í„° ë¶„ì„ ë° ì˜ˆì¸¡ ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. í–‰ì‚¬ ê¸°ê°„ ë™ì•ˆ ì „ë¬¸ê°€ë“¤ì˜ ê°•ì—°ê³¼ ì›Œí¬ìˆ, í† ë¡  ë“± ë‹¤ì–‘í•œ í”„ë¡œê·¸ë¨ì´ ì¤€ë¹„ë˜ì–´ ìˆìœ¼ë©°, ìì—°ì–´ ì²˜ë¦¬, ê¸°ê³„ í•™ìŠµ, ë°ì´í„° ì‹œê°í™” ë“± ë‹¤ì–‘í•œ ì£¼ì œê°€ ë‹¤ë£¨ì–´ì§‘ë‹ˆë‹¤.\nì´ë²ˆ í–‰ì‚¬ëŠ” ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸, ì—°êµ¬ì›, ë˜ëŠ” ì¸ê³µì§€ëŠ¥ê³¼ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì— ê´€ì‹¬ì´ ìˆëŠ” ë¶„ë“¤ì—ê²Œ ëª¨ë‘ ì—´ë ¤ ìˆìœ¼ë©°, ë˜í•œ ê°™ì€ ê´€ì‹¬ì‚¬ë¥¼ ê°€ì§„ ì‚¬ëŒë“¤ê³¼ì˜ ë„¤íŠ¸ì›Œí‚¹ ê¸°íšŒë„ ì œê³µë©ë‹ˆë‹¤.\ní–‰ì‚¬ ë“±ë¡ì€ ì§€ê¸ˆë¶€í„° ê°€ëŠ¥í•˜ë©°, ìë¦¬ê°€ í•œì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì„œë‘˜ëŸ¬ ë“±ë¡í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì´ë²ˆ ê¸°íšŒë¥¼ ë†“ì¹˜ì§€ ë§ˆì‹œê³ , ìµœì‹  ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë° ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ë™í–¥ì„ ì ‘í•˜ë©°, ì „ë¬¸ê°€ë“¤ê³¼ í•¨ê»˜ í•™ìŠµí•˜ëŠ” ì¢‹ì€ ê¸°íšŒê°€ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
  },
  {
    "objectID": "news_article.html#ê¸°ì‚¬-ì œëª©-ì´ˆì•ˆ",
    "href": "news_article.html#ê¸°ì‚¬-ì œëª©-ì´ˆì•ˆ",
    "title": "chatGPT",
    "section": "\n4.2 ê¸°ì‚¬ ì œëª© ì´ˆì•ˆ",
    "text": "4.2 ê¸°ì‚¬ ì œëª© ì´ˆì•ˆ\n\ní”„ë¡¬í”„íŠ¸: ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©ì€ 3ê°œë§Œ ì‘ì„±í•˜ì„¸ìš”.\n\n\n\n\n\n\n\nì£¼ì˜\n\n\n\n\n\n\nâ€œí•œêµ­Rì‚¬ìš©ìí˜‘íšŒì™€ DPlanex, ChatGPT ì¤‘ì‹¬ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í–‰ì‚¬ ìœ„í•´ í˜‘ë ¥â€\nâ€œêµë³´íƒ€ì›Œ ë…¸ë¸”ë¦¬í™€, 2023ë…„ 6ê°œ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í–‰ì‚¬ ê°œìµœâ€\nâ€œNLP, ê¸°ê³„ í•™ìŠµ ë° ë°ì´í„° ì‹œê°í™” ì „ë¬¸ê°€ê°€ ChatGPT ë° ë°ì´í„° ê³¼í•™ ì´ë²¤íŠ¸ì—ì„œ ì—°ì„¤í•©ë‹ˆë‹¤.â€"
  },
  {
    "objectID": "news_article.html#ë³´ë„ìë£Œ-ì–¸ë¡ -ë°°í¬",
    "href": "news_article.html#ë³´ë„ìë£Œ-ì–¸ë¡ -ë°°í¬",
    "title": "chatGPT",
    "section": "\n4.3 ë³´ë„ìë£Œ ì–¸ë¡  ë°°í¬",
    "text": "4.3 ë³´ë„ìë£Œ ì–¸ë¡  ë°°í¬\nchatGPTê°€ ì‘ì„±í•œ ê¸°ì‚¬ì œëª©(ì¼ëª… ì•¼ë§ˆ)ê³¼ ë³¸ë¬¸ ë‚´ìš©ì— ë”í•˜ì—¬ ë³´ë„ìë£Œ ë‹´ë‹¹ì ì •ë³´ë¥¼ ë¶™ì—¬ PDF ë¬¸ì„œí˜•íƒœë¡œ ìµœì¢… ë§ˆë¬´ë¦¬í•œë‹¤."
  },
  {
    "objectID": "interface.html#askup-ê²€ìƒ‰",
    "href": "interface.html#askup-ê²€ìƒ‰",
    "title": "chatGPT",
    "section": "\naskup ê²€ìƒ‰",
    "text": "askup ê²€ìƒ‰"
  },
  {
    "objectID": "interface.html#ì±„íŒ…ì¤€ë¹„",
    "href": "interface.html#ì±„íŒ…ì¤€ë¹„",
    "title": "chatGPT",
    "section": "ì±„íŒ…ì¤€ë¹„",
    "text": "ì±„íŒ…ì¤€ë¹„"
  },
  {
    "objectID": "interface.html#ocr-ì‚¬ë¡€",
    "href": "interface.html#ocr-ì‚¬ë¡€",
    "title": "chatGPT",
    "section": "OCR ì‚¬ë¡€",
    "text": "OCR ì‚¬ë¡€"
  },
  {
    "objectID": "interface.html#ë‰´ìŠ¤-ìš”ì•½",
    "href": "interface.html#ë‰´ìŠ¤-ìš”ì•½",
    "title": "chatGPT",
    "section": "ë‰´ìŠ¤ ìš”ì•½",
    "text": "ë‰´ìŠ¤ ìš”ì•½"
  },
  {
    "objectID": "interface.html#ì±„ë„ì¶”ê°€",
    "href": "interface.html#ì±„ë„ì¶”ê°€",
    "title": "chatGPT",
    "section": "ì±„ë„ì¶”ê°€",
    "text": "ì±„ë„ì¶”ê°€"
  },
  {
    "objectID": "interface.html#ì¹´ì¹´ì˜¤í†¡",
    "href": "interface.html#ì¹´ì¹´ì˜¤í†¡",
    "title": "chatGPT",
    "section": "\n3.1 ì¹´ì¹´ì˜¤í†¡",
    "text": "3.1 ì¹´ì¹´ì˜¤í†¡\nëª¨ë°”ì¼ ë©”ì‹ ì ¸ ì¹´ì¹´ì˜¤í†¡ì— AskUp ì±„ë„ì„ ì¶”ê°€í•˜ê²Œ ë˜ë©´ chatGPT ìœ ì‚¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ë¬¸ì œëŠ” ì–¸ì œ AskUp ì±„ë„ ì„œë¹„ìŠ¤ê°€ ì¤‘ë‹¨ë ì§€ ìœ ë£Œë¡œ ê³¼ê¸ˆì´ ë³€ê²½ë ì§€ ëª¨ë¥´ì§€ë§Œ chatGPTë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ ë‹¤ì–‘í™”í•¨ì€ ë¶„ëª…í•˜ë‹¤.\nAskUp ì„œë¹„ìŠ¤ëŠ” í˜„ì¬ ì‹œì (â€œ2023-03-10â€) ê¸°ì¤€ PDF ë¬¸ì„œìš”ì•½ê¸°ëŠ¥ì€ ì œê³µí•˜ê³  ìˆì§€ ì•Šì§€ë§Œ ì¥ë¬¸ì˜ í…ìŠ¤íŠ¸ëŠ” ìš”ì•½í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ê³  ìˆë‹¤.\n\n\naskup ê²€ìƒ‰\nì±„ë„ì¶”ê°€\nì±„íŒ…ì¤€ë¹„\nOCR ì‚¬ë¡€\në‰´ìŠ¤ ìš”ì•½"
  },
  {
    "objectID": "interface.html#ìŠ¬ë™",
    "href": "interface.html#ìŠ¬ë™",
    "title": "chatGPT",
    "section": "\n4.3 ìŠ¬ë™",
    "text": "4.3 ìŠ¬ë™\n2023ë…„ 3ì›” 7ì¼ Salesforceì™€ OpenAIëŠ” Slackìš© ChatGPT ì•±ì„ ì¶œì‹œí–ˆë‹¤. OpenAIê°€ Slack í”Œë«í¼ì— êµ¬ì¶•í•œ ì´ ì•±ì€ ChatGPTì˜ ê°•ë ¥í•œ AI ê¸°ìˆ ì„ í†µí•©í•˜ì—¬ ì¦‰ê°ì ì¸ ëŒ€í™” ìš”ì•½, ì¡°ì‚¬ ë„êµ¬ ë° ì‘ì„± ì§€ì›ì„ Slackì—ì„œ ë°”ë¡œ ì œê³µí•˜ì—¬ ìˆ˜ë°±ë§Œ ê¸°ì—…ì´ ë³´ë‹¤ ìƒì‚°ì ìœ¼ë¡œ ì‘ì—…í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ê¸° ì‹œì‘í–ˆë‹¤.\nì¶œì²˜: Introducing the ChatGPT App for Slack"
  },
  {
    "objectID": "rnd.html",
    "href": "rnd.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ì¸ìš©ë†’ì€ ë…¼ë¬¸ 5ê°œ\nchatGPTì— ê°€ì¥ ì¸ìš©ìˆ˜ê°€ ë†’ì€ ë…¼ë¬¸ 5ê°œë¥¼ ì°¾ì•„ë‹¬ë¼ê³  ìš”ì²­ì„ í•˜ì˜€ë‹¤.\n\ní”„ë¡¬í”„íŠ¸: What are the most cited papers?\n\n\n\ní•œì˜ ë²ˆì—­\nì˜ì–´ ì›ë¬¸\n\n\n\nchatGPTì— ë‚˜ì˜¨ ì¸ìš©ì— ëŒ€í•œ ê·¼ê±°ë¥¼ í™•ì‹ í•  ìˆ˜ ì—†ì–´ êµ¬ê¸€ í•™ìˆ ê²€ìƒ‰ì—ì„œ í•´ë‹¹ ë…¼ë¬¸ì— ëŒ€í•œ ì¸ìš© íšŸìˆ˜ë¥¼ ìˆ˜ì‘ì—…ìœ¼ë¡œ ì •ë¦¬í–ˆë‹¤.\n\nStephen Wolframì˜ â€œA New Kind of Scienceâ€ - ì´ ì±…ì€ 2002ë…„ ì¶œíŒ ì´í›„ 14,000 9,696íšŒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ì…€ë£°ëŸ¬ ì˜¤í† ë§ˆíƒ€ë¥¼ ì‚¬ìš©í•˜ëŠ” ë³µì¡í•œ ì‹œìŠ¤í…œ.\nSergey Brinê³¼ Lawrence Pageì˜ â€œThe Anatomy of a Large-Scale Hypertextual Web Search Engineâ€ - 1998ë…„ì— ì¶œíŒëœ ì´ ë…¼ë¬¸ì€ PageRankë¥¼ ì†Œê°œí–ˆìŠµë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì´ë©° Googleì˜ ê¸°ë°˜ìœ¼ë¡œ ë„ë¦¬ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. 15,000 22,779íšŒ ì´ìƒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\nThomas Kuhnì˜ â€œê³¼í•™ í˜ëª…ì˜ êµ¬ì¡°â€ - 1962ë…„ì— ì¶œíŒëœ ì´ ì±…ì€ 44,000 597íšŒ ì´ìƒ ì¸ìš©ë˜ì—ˆìœ¼ë©° ë‹¤ìŒê³¼ ê°™ì€ ê°œë…ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ê³¼í•™ì˜ íŒ¨ëŸ¬ë‹¤ì„ ë³€í™”.\nLarry V. Hedges ë° Ingram Olkinì˜ â€œStatistical Methods for Meta-Analysisâ€ - 1985ë…„ì— ì¶œíŒëœ ì´ ë…¼ë¬¸ì€ 53,000 18,545íšŒ ì´ìƒ ì¸ìš©ë˜ì—ˆìœ¼ë©° ì—°êµ¬ í•©ì„±ì— ë©”íƒ€ ë¶„ì„ì˜ ì‚¬ìš©ì„ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.\nAlbert Einstein, Boris Podolsky ë° Nathan Rosenì˜ â€œThe Nature ë…¼ë¬¸â€ - 1935ë…„ì— ì¶œíŒëœ ì´ ë…¼ë¬¸ì€ ì–‘ì ì–½í˜ì˜ ê°œë…ì´ë©° 13,000 10íšŒ ì´ìƒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n\n\nThere are several papers that have been highly cited in various fields of study. Here are some examples:\n\nâ€œA New Kind of Scienceâ€ by Stephen Wolfram - This book has been cited over 14,000 times since its publication in 2002. It presents a new approach to understanding complex systems using cellular automata.\nâ€œThe Anatomy of a Large-Scale Hypertextual Web Search Engineâ€ by Sergey Brin and Lawrence Page - This paper, published in 1998, introduced the PageRank algorithm and is widely regarded as the foundation of Google. It has been cited over 15,000 times.\nâ€œThe Structure of Scientific Revolutionsâ€ by Thomas Kuhn - Published in 1962, this book has been cited over 44,000 times and introduced the concept of paradigm shifts in science.\nâ€œStatistical Methods for Meta-Analysisâ€ by Larry V. Hedges and Ingram Olkin - This paper, published in 1985, has been cited over 53,000 times and introduced the use of meta-analysis in research synthesis.\nâ€œThe Nature paperâ€ by Albert Einstein, Boris Podolsky, and Nathan Rosen - This paper, published in 1935, introduced the concept of quantum entanglement and has been cited over 13,000 times.\n\nThese papers represent a small sample of highly cited papers, and there are many others that have made significant contributions to their respective fields.\n\n\n\n\n2 êµ¬ê¸€ê²€ìƒ‰ ë…¼ë¬¸\ní˜„ì¬ êµ¬ê¸€ì´ ìˆê²Œ í•œ Sergey Brinê³¼ Lawrence Pageì˜ â€œThe Anatomy of a Large-Scale Hypertextual Web Search Engineâ€ ë…¼ë¬¸ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ì‚´í´ë³´ì.\n\n\n\n3 chatPDF ì„œë¹„ìŠ¤\nchatPDF ì›¹ì‚¬ì´íŠ¸ì— ì—°êµ¬ PDF ë…¼ë¬¸ì„ ì˜¬ë¦¬ë©´ ì´ë¥¼ chatGPT ê¸°ìˆ ì„ ì´ìš©í•˜ì—¬ ìš”ì•½ì„ í•´ì£¼ê³  ê´€ë ¨í•˜ì—¬ ëª‡ê°€ì§€ ì§ˆë¬¸ë„ ì œì‹œí•´ì¤€ë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ í•  ë•Œ í•´ë‹¹ ë…¼ë¬¸ì˜ ê·¼ê±° í˜ì´ì§€, ë‹¨ë½ë„ ì œì‹œí•´ì£¼ê¸° ë•Œë¬¸ì— í•„ìš”í•˜ë©´ ì¶”ê°€ë¡œ í™•ì¸ë„ ì§„í–‰í•˜ê³ , ì¶”ê°€ë¡œ ì§ˆë¬¸ì„ ë” ë„£ì–´ ë…¼ë¬¸ì— ëŒ€í•œ ì´í•´ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤. (Brin & Page, 1998)\n\n\nchatPDF ì ‘ì†\në…¼ë¬¸ ìš”ì•½ ë° ì œì‹œì§ˆë¬¸\nì±„íŒ… ì˜ˆì‹œ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 êµ­ë¬¸ ë…¼ë¬¸\n2020ë…„ ì¶œê°„ëœ ë…¼ë¬¸(ì´ê´‘ì¶˜, 2020)ì„ chatPDFë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼í•™ê¸°ìˆ  ì—°êµ¬ê°œë°œì˜ ìƒì‚°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì°¾ì•„ë³´ì.\n\në…¼ë¬¸ ì†ŒìŠ¤ì½”ë“œ: ë°”ë¡œê°€ê¸°\n\nPDF ì¶œíŒ ë…¼ë¬¸: ë‹¤ìš´ë¡œë“œ\n\n\n\n\nPDF ì›ë³¸\nopenAI API\nì„¸ë¬´ì‚¬\nê¸°ê³„ì™€ ì „ìŸ ìŠ¹ë¦¬\nì˜ë¬¸ì´ˆë¡ ì—†ìŒ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5 ì—£ì§€ PDF\në§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì—£ì§€(Microsoft Edge)ëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ê°œë°œí•œ ì›¹ ë¸Œë¼ìš°ì €ë¡œ, ê¸°ì¡´ì˜ ì¸í„°ë„· ìµìŠ¤í”Œë¡œëŸ¬(Internet Explorer)ë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡Œê³ , 2015ë…„ Windows 10ê³¼ í•¨ê»˜ ì²˜ìŒ ê³µê°œë˜ì—ˆë‹¤. 2020ë…„ë¶€í„° ì—£ì§€ëŠ” êµ¬ê¸€ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ì¸ í¬ë¡œë¯¸ì›€(Chromium) ê¸°ë°˜ìœ¼ë¡œ ê°œë°œë˜ì–´, í¬ë¡¬(Chrome)ê³¼ ê°™ì€ ì—”ì§„ì„ ì°¨ìš©í•˜ì—¬ ì—£ì§€ëŠ” í¬ë¡¬ í™•ì¥ í”„ë¡œê·¸ë¨ê³¼ í˜¸í™˜ì„±ì´ ë†’ì•„ì¡Œê³ , ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì´ í–¥ìƒë˜ì—ˆë‹¤.\níŠ¹íˆ chatGPT ê¸°ëŠ¥ì„ ì—£ì§€ ì›¹ ë¸Œë¼ìš°ì €ì— ì±„ìš©í•˜ë©´ì„œ ì ìœ ìœ¨ì´ ì ì°¨ ë†’ì•„ì§€ê³  ìˆë‹¤.\npdf ë…¼ë¬¸ì„ ì•„ë„ë¸Œ ì•„í¬ë¡œë±ƒ ë¦¬ë” ëŒ€ì‹  ì—£ì§€ ë¸Œë¼ìš°ì ¸ì—ì„œ ì—´ê²Œ ë˜ë©´ chatPDF ê¸°ëŠ¥ì„ ìì²´ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì´ëŸ° ê²½ìš° pdf íŒŒì¼ì„ ì™¸ë¶€ì— ì „ì†¡í•˜ì§€ ì•Šê³  ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì‘ì—…í•œë‹¤ëŠ” ì ì—ì„œ ì†ë„ ë° ë³´ì•ˆì— ì•ˆì •ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.\nê¹€ê±´í¬ ì—¬ì‚¬ê°€ ì§‘í•„í•œ â€œì˜¨ë¼ì¸ ìš´ì„¸ ì½˜í…ì¸ ì˜ ì´ìš©ìë“¤ì˜ ì´ìš© ë§Œì¡±ê³¼ ë¶ˆë§Œì¡±ì— ë”°ë¥¸ íšŒì› ìœ ì§€ì™€ íƒˆí‡´ì— ëŒ€í•œ ì—°êµ¬â€ KCI ë“±ì¬ë…¼ë¬¸ì„ ì—£ì§€ì—ì„œ ì—´ì–´ GPT-4 ê¸°ëŠ¥ì„ í™•ì¸í•´ë³´ì.\n\n\nPDF ì›ë³¸\nGPT-4 ë…¼ë¬¸\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nBrin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 30(1-7), 107â€“117.\n\n\nì´ê´‘ì¶˜ì£¼ìš©ìš°. (2020). ì‚¬ëŒê³¼ ì¸ê³µì§€ëŠ¥ì˜ ì¼ìë¦¬ ê²½ìŸ ìš”ì¸ê³¼ í˜‘ì—… ë°©ì•ˆ. ë””ì§€í„¸ê²½ì˜ì—°êµ¬ Vol.6 No.2 Pp.39-50."
  },
  {
    "objectID": "yuji.html",
    "href": "yuji.html",
    "title": "chatGPT",
    "section": "",
    "text": "ê¹€ê±´í¬ ì—¬ì‚¬ê°€ ì§‘í•„í•œ â€œì˜¨ë¼ì¸ ìš´ì„¸ ì½˜í…ì¸ ì˜ ì´ìš©ìë“¤ì˜ ì´ìš© ë§Œì¡±ê³¼ ë¶ˆë§Œì¡±ì— ë”°ë¥¸ íšŒì› ìœ ì§€ì™€ íƒˆí‡´ì— ëŒ€í•œ ì—°êµ¬â€ ë…¼ë¬¸ì œëª©ì„ ê°–ê³  ìˆëŠ” KCI ë“±ì¬ë…¼ë¬¸ì€ â€œUse satisfaction of users of online fortune contents and member Yuji by dissatisfaction and a study for withdrawalâ€ ì˜ë¬¸ì œëª©ì´ ì•„ë˜ í•¨ê»˜ ë‹¬ë ¤ìˆë‹¤. KCI ì›ë¬¸ ë‚´ë ¤ë°›ê¸°ë¥¼ í´ë¦­í•˜ë©´ PDF íŒŒì¼(KCI_FI001250967.pdf)ë¡œ KCI ë“±ì¬ ë…¼ë¬¸ì„ ë‚´ë ¤ë°›ì„ ìˆ˜ ìˆë‹¤.\nì¶œì²˜: ê¹€ê±´í¬ ì—¬ì‚¬ ë…¼ë¬¸\n\n\nKCI ë“±ì¬ ì›¹ì‚¬ì´íŠ¸\nPDF ë‹¤ìš´ë¡œë“œ"
  },
  {
    "objectID": "yuji.html#ì›ë¬¸ê³¼-ë¹„êµ",
    "href": "yuji.html#ì›ë¬¸ê³¼-ë¹„êµ",
    "title": "chatGPT",
    "section": "\n2.1 ì›ë¬¸ê³¼ ë¹„êµ",
    "text": "2.1 ì›ë¬¸ê³¼ ë¹„êµ\n\n\nê¹€ê±´í¬ ì—¬ì‚¬ ì €ì‘(Abstract A)\nThough I make a searching examination substantially and show book plan a purpose of a study develops digital fortune contents service deserving to be a domestic online member of fortune site use and influence for member withdrawal and a member demand, and to apply this to a market, there is it. In addition, Fortune (phrenology) that any people regardless of age or sex anyone cut interest and the culture contents that I could be interested in to a system of digital culture contents and inherited a study of a book and did It is the purpose that is going to manufacture a customer and a consumer and a demand of potential customers and service deserving to be you satisfactorily through a feasibility study to develop affinity) contents and a market analysis.\nchatGPT ì €ì‘ (Abstract B)\nThis empirical study aims to investigate the impact of online fortune-telling sites on membership and churn in Korea, and to develop a digital fortune-telling content service that meets membersâ€™ needs. Additionally, the study aims to identify and suggest ways to develop and apply digital horoscope content services to the market. The studyâ€™s objective is to create culturally relevant and engaging horoscopic (contemplative, compatibility) content through preliminary research and market analysis, catering to individuals of all ages. The study aims to develop services that meet potential customersâ€™ needs and satisfaction by incorporating digital cultural content. Overall, this study contributes to the development of effective digital fortune-telling and horoscope content services in Korea, addressing the needs of its target audience."
  },
  {
    "objectID": "yuji.html#chatgpt-í‰ê°€",
    "href": "yuji.html#chatgpt-í‰ê°€",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT í‰ê°€",
    "text": "2.2 chatGPT í‰ê°€\n\n\n\n\n\n\ntell me how to evaluate two paper abstracts. which is better than other one? include criteria and add justification. finally recommend tools\n\n\n\n\n\nEvaluating two paper abstracts involves comparing and contrasting their strengths and weaknesses based on a set of criteria. Here are some criteria to consider when evaluating paper abstracts:\n\nClarity and coherence: The abstract should be well-organized and easy to understand. It should also effectively summarize the main ideas of the paper.\nOriginality and novelty: The abstract should highlight the unique aspects of the paper and how it contributes to the existing body of knowledge.\nSignificance and relevance: The abstract should explain why the research is important and relevant to the field.\nMethodology and data: The abstract should briefly describe the methods used and the data collected in the study.\nResults and conclusions: The abstract should summarize the key findings of the study and the main conclusions drawn from them.\n\nBased on these criteria, the better paper abstract would be the one that is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nHere is a brief justification for each criterion:\n\nClarity and coherence: A well-written abstract is important because it is the first thing that readers will see when they encounter the paper. A clear and coherent abstract will help readers understand what the paper is about and whether it is worth reading in full.\nOriginality and novelty: This criterion is important because it highlights the unique aspects of the paper and helps readers understand why it is important.\nSignificance and relevance: This criterion is important because it explains why the research is worth doing and how it contributes to the field.\nMethodology and data: This criterion is important because it helps readers understand how the research was conducted and whether the results are reliable.\nResults and conclusions: This criterion is important because it summarizes the key findings of the study and the main conclusions drawn from them, which helps readers understand the significance of the research.\n\nAs for tools to help evaluate paper abstracts, there are various software programs available that can help assess the quality of writing, such as Grammarly or Hemingway Editor. Additionally, some academic databases provide metrics and rankings for papers based on factors such as citation counts and impact factors. However, the best way to evaluate paper abstracts is to read them carefully and assess their quality based on the criteria listed above.\n\n\n\n\n\n\n\n\n\nBased on the criteria outlined above, abstract B appears to be the better of the two abstracts.\n\n\n\n\n\n\nClarity and coherence: Abstract B is well-organized and easy to understand. It effectively summarizes the main ideas of the paper in a clear and concise manner. In contrast, abstract A is poorly written and difficult to understand due to its convoluted language and lack of clarity.\nOriginality and novelty: Abstract B highlights the unique aspects of the paper, including its focus on developing culturally relevant and engaging horoscopic content, and its contribution to the development of effective digital fortune-telling services in Korea. In contrast, abstract A does not provide any clear indication of the paperâ€™s novelty or originality.\nSignificance and relevance: Abstract B explains why the research is important and relevant to the field by highlighting the impact of online fortune-telling sites on membership and churn in Korea, and the need for digital horoscope content services that meet membersâ€™ needs. In contrast, abstract A does not provide any clear explanation of the researchâ€™s significance or relevance.\nMethodology and data: Abstract B briefly describes the studyâ€™s empirical methodology and its focus on identifying and suggesting ways to develop and apply digital horoscope content services to the market. In contrast, abstract A does not provide any clear indication of the studyâ€™s methodology or data.\nResults and conclusions: Abstract B effectively summarizes the key findings of the study, including the development of culturally relevant and engaging horoscopic content and the identification of ways to meet potential customersâ€™ needs and satisfaction. In contrast, abstract A does not provide any clear indication of the studyâ€™s results or conclusions.\n\nOverall, abstract B is a better abstract because it is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nAs for tools to help evaluate paper abstracts, software programs such as Grammarly or Hemingway Editor can be helpful in identifying and correcting issues with clarity and coherence. Additionally, academic databases such as Scopus or Web of Science can provide metrics and rankings for papers based on factors such as citation counts and impact factors, which can be used to assess the significance and relevance of the research.\n\n\n\n\n\n\n\n\n\nì™œ abstract Aê°€ abstract Bë³´ë‹¤ ë¶€ì¡±í•œì§€ 100ì ë‚´ì™¸ë¡œ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì¤˜\n\n\n\n\n\në²ˆì—­ê²°ê³¼ Briefly summarize in 100 words or less why abstract A is less than abstract B\nAbstract A is less than abstract B because it is poorly written, difficult to understand, lacks clarity, and does not effectively summarize the main ideas of the paper. It also does not provide any clear indication of the paperâ€™s novelty, significance, methodology, data, or results and conclusions. In contrast, abstract B is well-organized, easy to understand, effectively highlights the unique aspects of the research, explains why the research is important and relevant to the field, briefly describes the studyâ€™s methodology and data, and effectively summarizes the key findings and conclusions of the research.\në²ˆì—­ê²°ê³¼\nì´ˆë¡ AëŠ” ì„œíˆ¬ë¥´ê²Œ ì‘ì„±ë˜ê³ , ì´í•´í•˜ê¸° ì–´ë µê³ , ëª…í™•ì„±ì´ ë¶€ì¡±í•˜ê³ , ë…¼ë¬¸ì˜ ì£¼ìš” ì•„ì´ë””ì–´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìš”ì•½í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— ì´ˆë¡ Bë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. ë˜í•œ ë…¼ë¬¸ì˜ ì°¸ì‹ ì„±, ì¤‘ìš”ì„±, ë°©ë²•ë¡ , ë°ì´í„° ë˜ëŠ” ê²°ê³¼ ë° ê²°ë¡ ì— ëŒ€í•œ ëª…í™•í•œ í‘œì‹œë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì¡°ì ìœ¼ë¡œ ì´ˆë¡ BëŠ” ì˜ ì •ë¦¬ë˜ì–´ ìˆê³  ì´í•´í•˜ê¸° ì‰¬ìš°ë©° ì—°êµ¬ì˜ ê³ ìœ í•œ ì¸¡ë©´ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°•ì¡°í•˜ê³  í•´ë‹¹ ì—°êµ¬ê°€ ì¤‘ìš”í•˜ê³  í•´ë‹¹ ë¶„ì•¼ì™€ ê´€ë ¨ì´ ìˆëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•˜ë©° ì—°êµ¬ì˜ ë°©ë²•ë¡ ê³¼ ë°ì´í„°ë¥¼ ê°„ëµí•˜ê²Œ ì„¤ëª…í•˜ê³  ì£¼ìš” ê²°ê³¼ì™€ ì—°êµ¬ì˜ ê²°ë¡ ."
  },
  {
    "objectID": "stable_diffusion.html",
    "href": "stable_diffusion.html",
    "title": "chatGPT",
    "section": "",
    "text": "Text-to-ImageëŠ” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì£¼ëŠ” ì¸ê³µì§€ëŠ¥ ì„œë¹„ìŠ¤ë‹¤. í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ì œì‘í•¨ìœ¼ë¡œì„œ ë‹¤ì–‘í•œ ì‚¬ìš©ì‚¬ë¡€ë¥¼ ë°œê²¬í•  ìˆ˜ ìˆë‹¤.\n\ní…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€: ë¸”ë¡œê·¸ë‚˜ ì†Œì…œë¯¸ë””ì–´ì— ê²Œì‹œ\ní…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€: ì‹œê° ì˜ˆìˆ  ì‘í’ˆ(Artwork)ê³¼ ì½˜í…ì¸  ì œì‘\ní…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€: ì•„ì´ë””ì–´ë‚˜ ì»¨ì…‰ì„ ì‹œê°í™”\ní…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€: ì¬ë¯¸ìˆëŠ” ì‹¤í—˜\ní…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€: êµìœ¡ì´ë‚˜ ì—°êµ¬ì— í™œìš©\n\nì¼ë°˜ì ìœ¼ë¡œ ì¸ê¸°ìˆê³  í‰ê°€ê°€ ì¢‹ì€ Text-to-Image ì†Œí”„íŠ¸ì›¨ì–´ë¡œëŠ” ìƒìš© API, ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ë¡œ ë‹¤ìŒì„ ë“¤ ìˆ˜ ìˆë‹¤.\n\nMidjourney: ë¯¸ë“œì €ë‹ˆëŠ” ìƒˆë¡œìš´ ì‚¬ê³ ì˜ ë§¤ì²´ë¥¼ íƒêµ¬í•˜ê³  ì¸ë¥˜ì˜ ìƒìƒë ¥ì„ í™•ì¥í•˜ëŠ” ë…ë¦½ ì—°êµ¬ì‹¤ì…ë‹ˆë‹¤. ë””ìì¸, íœ´ë¨¼ ì¸í”„ë¼ ë° AIì— ì¤‘ì ì„ ë‘” ì†Œê·œëª¨ ìì²´ ìê¸ˆ ì§€ì› íŒ€ìœ¼ë¡œ 11ëª…ì˜ ìƒê·¼ ì§ì›ê³¼ í›Œë¥­í•œ ìë¬¸ë‹¨ì´ ìˆìŒ\nStable Diffusion: ë…ì¼ ë®Œí—¨ ëŒ€í•™ CompVis ì—°êµ¬ì‹¤ì˜ â€œì ì¬ í™•ì‚° ëª¨ë¸ì„ ì´ìš©í•œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ í•©ì„± ì—°êµ¬â€ë¥¼ ê¸°ë°˜í•˜ì—¬, Stability AIì™€ Runway ML ë“±ì˜ ì§€ì›ì„ ë°›ì•„ ê°œë°œëœ ë”¥ëŸ¬ë‹ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë¡œ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œë˜ì–´ ë‹¤ë¥¸ ìƒìš© Text-to-Imageì™€ ì°¨ë³„ì ì´ ìˆë‹¤.\nOpenAI: DALL-E\nGoogle: Imagen\nDeepAI: Text to Image\n\nCanva: Text to Image"
  },
  {
    "objectID": "stable_diffusion.html#íˆ´-ì„¤ì¹˜",
    "href": "stable_diffusion.html#íˆ´-ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "\n3.1 íˆ´ ì„¤ì¹˜",
    "text": "3.1 íˆ´ ì„¤ì¹˜\nAPIë¡œ ê³µê°œëœ Text-to-Image ìƒìš©ëª¨í˜•ì€ API-Keyë§Œ ì„¤ì •í•˜ë©´ ë˜ì§€ë§Œ, ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œëœ Stable Diffusion ì„ ììœ ë¡œì´ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” í•˜ë“œì›¨ì–´ë¶€í„° ìŠ¤ìŠ¤ë¡œ ì‘ì—…í•´ì•¼í•˜ëŠ” ê²ƒì´ ì œë²• ëœë‹¤.\n\nì¤€ë¹„ë¬¼\n\ní•˜ë“œì›¨ì–´: ì¤€ìˆ˜í•œ ì„±ëŠ¥ì˜ ê·¸ë˜í”½ì¹´ë“œ\ní”„ë¡œê·¸ë˜ë° ì–¸ì–´: íŒŒì´ì¬ 3.10.6\n\nì†Œí”„íŠ¸ì›¨ì–´: Git ë° Git í”„ë¡œê·¸ë¨ ì €ì¥ì†Œì—ì„œ í´ë¡ \nAI ëª¨í˜•: í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ëª¨í˜• ë‹¤ìš´ë¡œë“œ í›„ ë³µì‚¬ì„¤ì¹˜"
  },
  {
    "objectID": "stable_diffusion.html#í™˜ê²½ì„¤ì •",
    "href": "stable_diffusion.html#í™˜ê²½ì„¤ì •",
    "title": "chatGPT",
    "section": "\n3.2 í™˜ê²½ì„¤ì •",
    "text": "3.2 í™˜ê²½ì„¤ì •\níŒŒì´ì¬ ë²„ì§„ì´ í•„íˆ 3.10.6ì¸ ê²½ìš° í…ŒìŠ¤íŠ¸ê°€ ì¶©ë¶„íˆ ë˜ì–´ ë¬¸ì œê°€ ì—†ì§€ë§Œ ë‹¤ë¥¸ ë²„ì „ì„ ì„¤ì¹˜í•˜ì—¬ ì‹¤í–‰ì‹œí‚¬ ê²½ìš° ì˜ˆê¸°ì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒëœë‹¤. ë¨¼ì €, íŒŒì´ì¬ì€ ìœˆë„ìš°ì˜ ê²½ìš° ì œì–´íŒì—ì„œ í™˜ê²½ì„¤ì •ì—ì„œ ê²½ë¡œëª…ì— íŒŒì´ì¬ 3.10.6ì´ ì„¤ì¹˜ëœ ë””ë ‰í† ë¦¬ì—ì„œ python.exeë¥¼ í™•ì¸í•˜ê³  ê²½ë¡œì— ì¶”ê°€í•˜ë©´ ëœë‹¤. stable-diffusion-webui í´ë” ì•„ë˜ webui-user.bat íŒŒì¼ì„ ì°¾ì•„ ì„¤ì¹˜í•œ íŒŒì´ì¬ ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ê³  --xformers ì˜¤ë¥˜ê°€ ìˆëŠ” ê²½ìš° ì´ë¥¼ ì¡ê¸° ìœ„í•´ ê´€ë ¨ ì„¤ì •ìœ¼ ì¶”ê°€í•œë‹¤. í—ˆê¹…í˜ì´ìŠ¤ë¥¼ ë¹„ë¡¯í•˜ì—¬ GitHub ë“±ì—ì„œ ì°¾ì€ AI ëª¨í˜•ì€ stable-diffusion-webui\\models ë””ë ‰í† ë¦¬ ì•„ë˜ ì €ì¥í•œë‹¤.\ngit pull\n@echo off\n\nset PYTHON=C:\\Users\\XXXX\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\nset GIT=\nset VENV_DIR=\nset COMMANDLINE_ARGS=--reinstall-xformers --xformers\n\ncall webui.bat\nstable-diffusion-webui\\webui-user.bat íŒŒì¼ì„ íƒìƒ‰ê¸°ì—ì„œ ì°¾ì•„ ë”ë¸”í´ë¦­í•˜ë©´ text-to-image stable diffusion ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ëœë‹¤."
  },
  {
    "objectID": "macbook.html",
    "href": "macbook.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ì±—GPT ì—‰ëš±ë‹µë³€\nìœ ë¨¸ Q: ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì— ê¸°ë¡ëœ ì„¸ì¢…ëŒ€ì™•ì˜ ë§¥ë¶í”„ë¡œë˜ì§ ì‚¬ê±´ ì•Œë ¤ì¤˜\nì±—GPTëŠ” ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê¸°ê³„í•™ìŠµëª¨í˜•ìœ¼ë¡œ ì–´ë–»ê²Œ ë³´ë©´ ì°½ì˜ì ì¸ ê¸€ì“°ê¸°ì— ìµœì í™”ëœ ë„êµ¬ë¡œ ê°„ì£¼ë˜ê³  ìˆë‹¤. ë”°ë¼ì„œ, ê·¸ëŸ´ë“¯í•œ ë¬¸ì¥ì„ ì™„ì„±í•˜ê¸°ëŠ” í•˜ì§€ë§Œ ê·¸ ì§„ìœ„ì™€ ì‚¬ì‹¤ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì€ ë‹¤ë¥¸ ì¸¡ë©´ì´ë‹¤. ì´ê²ƒì€ ì›ë˜ ì¸ê°„ì´ ë§Œë“  ì–¸ì–´ê°€ ê°–ëŠ” ê³ ìœ í•œ íŠ¹ì„±ì´ê¸°ë„ í•˜ë‹¤. ì¦‰, ì¸ê°„ì˜ ì–¸ì–´ê°€ ì‚¬ì‹¤ë„ ìˆì§€ë§Œ ê·¸ë ‡ì§€ ì•Šì€ í—ˆêµ¬ê°€ ë§ì€ ê²ƒë„ ì‚¬ì‹¤ì´ê³  ê·¸ëŸ´ë“¯í•œ í—ˆêµ¬ë¥¼ ë‹¤ì–‘í•œ ì¸¡ë©´ì—ì„œ ì¦ê¸°ê³  ì–¸ì–´ì˜ ì¼í™˜ìœ¼ë¡œ ë°›ì•„ë“¤ì´ê³  ìˆë‹¤.\n\n\në”ì¿ \në§¥ë¶ íˆ¬ì²™\në§¥ë¶ í™˜ë¶ˆ\nì§€ì‹œëª…ë ¹ì–´\n\n\n\n\n\n\n\n\n\nâ€œì¡°ì„ ì™•ì¡°ì‹¤ë¡ì— ê¸°ë¡ëœ ì„¸ì¢…ëŒ€ì™•ì˜ ë§¥ë¶í”„ë¡œ ë˜ì§ ì‚¬ê±´ì— ëŒ€í•´ ì•Œë ¤ì¤˜.â€\n\n\n\n\n\nì„¸ì¢…ëŒ€ì™•ì˜ ë§¥ë¶í”„ë¡œ ë˜ì§ ì‚¬ê±´ì€ ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì— ê¸°ë¡ëœ ì¼í™”ë¡œ, 15ì„¸ê¸° ì„¸ì¢…ëŒ€ì™•ì´ ìƒˆë¡œ ê°œë°œí•œ í›ˆë¯¼ì •ìŒ(í•œê¸€)ì˜ ì´ˆê³ ë¥¼ ì‘ì„±í•˜ë˜ ì¤‘ ë¬¸ì„œ ì‘ì„± ì¤‘ë‹¨ì— ëŒ€í•´ ë‹´ë‹¹ìì—ê²Œ ë¶„ë…¸í•´ ë§¥ë¶í”„ë¡œì™€ í•¨ê»˜ ê·¸ë¥¼ ë°©ìœ¼ë¡œ ë˜ì§„ ì‚¬ê±´ì…ë‹ˆë‹¤.\nì„¸ì¢…ëŒ€ì™•ì€ í›ˆë¯¼ì •ìŒ ê°œë°œì„ ìœ„í•´ ì—´ì‹¬íˆ ë…¸ë ¥í•˜ë˜ ì¤‘, í•œê¸€ ë¬¸ìë¥¼ ì´í•´í•˜ì§€ ëª»í•˜ëŠ” ë‹¹ì‹œì˜ ê´€ë£Œë“¤ì´ ë¬¸ì„œ ì‘ì„±ì„ ë•ê¸° ìœ„í•´ ì„ëª…í•œ ê¸°íšê´€ ì¤‘ í•œ ëª…ì¸ ìµœí™˜(å´”ç…¥)ì—ê²Œ ì‘ì„± ì¤‘ë‹¨ ì‚¬ì‹¤ì„ ë“£ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¸ì¢…ëŒ€ì™•ì€ ì´ì— ë¶„ë…¸í•˜ì—¬ ìµœí™˜ì„ ë¶€ë¥´ê³ , ë§¥ë¶í”„ë¡œë¥¼ í•¨ê»˜ ë“¤ê³  ê·¸ë¥¼ ë°©ìœ¼ë¡œ ë¶ˆëŸ¬ë“¤ì´ë©° í™”ë¥¼ ë‚´ì—ˆìŠµë‹ˆë‹¤. ì´í›„, ì„¸ì¢…ëŒ€ì™•ì€ í›ˆë¯¼ì •ìŒì˜ ì´ˆê³  ì‘ì„±ì„ ë‹¤ë¥¸ ë‹´ë‹¹ìì—ê²Œ ë„˜ê²¨ì£¼ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´ ì‚¬ê±´ì€ ì¡°ì„ ì‹œëŒ€ì˜ í†µì¹˜ìë¡œì„œ ì„¸ì¢…ëŒ€ì™•ì´ ì–´ë–»ê²Œ ë¯¼ì¡±ë¬¸í™”ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•´ ë…¸ë ¥í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì¼í™”ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ë˜í•œ, ì„¸ì¢…ëŒ€ì™•ì˜ ì—´ì •ê³¼ ì—…ë¬´ì²˜ë¦¬ì— ëŒ€í•œ ì² ì €í•œ íƒœë„ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‚¬ë¡€ë¡œë„ ì–¸ê¸‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 ë§¥ë¶ì‚¬ê±´ ìš”ì•½\n\n\n\n\n\n\në‹¤ìŒ ê¸€ì„ í•œì¤„ë¡œ ìš”ì•½í•´ì¤˜\n\n\n\n\n\n\nì„¸ì¢…ëŒ€ì™•ì˜ ë§¥ë¶í”„ë¡œ ë˜ì§ ì‚¬ê±´ì€ ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì— ê¸°ë¡ëœ ì¼í™”ë¡œ, 15ì„¸ê¸° ì„¸ì¢…ëŒ€ì™•ì´ ìƒˆë¡œ ê°œë°œí•œ í›ˆë¯¼ì •ìŒ(í•œê¸€)ì˜ ì´ˆê³ ë¥¼ ì‘ì„±í•˜ë˜ ì¤‘ ë¬¸ì„œ ì‘ì„± ì¤‘ë‹¨ì— ëŒ€í•´ ë‹´ë‹¹ìì—ê²Œ ë¶„ë…¸í•´ ë§¥ë¶í”„ë¡œì™€ í•¨ê»˜ ê·¸ë¥¼ ë°©ìœ¼ë¡œ ë˜ì§„ ì‚¬ê±´ì…ë‹ˆë‹¤.\nì„¸ì¢…ëŒ€ì™•ì€ í›ˆë¯¼ì •ìŒ ê°œë°œì„ ìœ„í•´ ì—´ì‹¬íˆ ë…¸ë ¥í•˜ë˜ ì¤‘, í•œê¸€ ë¬¸ìë¥¼ ì´í•´í•˜ì§€ ëª»í•˜ëŠ” ë‹¹ì‹œì˜ ê´€ë£Œë“¤ì´ ë¬¸ì„œ ì‘ì„±ì„ ë•ê¸° ìœ„í•´ ì„ëª…í•œ ê¸°íšê´€ ì¤‘ í•œ ëª…ì¸ ìµœí™˜(å´”ç…¥)ì—ê²Œ ì‘ì„± ì¤‘ë‹¨ ì‚¬ì‹¤ì„ ë“£ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¸ì¢…ëŒ€ì™•ì€ ì´ì— ë¶„ë…¸í•˜ì—¬ ìµœí™˜ì„ ë¶€ë¥´ê³ , ë§¥ë¶í”„ë¡œë¥¼ í•¨ê»˜ ë“¤ê³  ê·¸ë¥¼ ë°©ìœ¼ë¡œ ë¶ˆëŸ¬ë“¤ì´ë©° í™”ë¥¼ ë‚´ì—ˆìŠµë‹ˆë‹¤. ì´í›„, ì„¸ì¢…ëŒ€ì™•ì€ í›ˆë¯¼ì •ìŒì˜ ì´ˆê³  ì‘ì„±ì„ ë‹¤ë¥¸ ë‹´ë‹¹ìì—ê²Œ ë„˜ê²¨ì£¼ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´ ì‚¬ê±´ì€ ì¡°ì„ ì‹œëŒ€ì˜ í†µì¹˜ìë¡œì„œ ì„¸ì¢…ëŒ€ì™•ì´ ì–´ë–»ê²Œ ë¯¼ì¡±ë¬¸í™”ë¥¼ ë°œì „ì‹œí‚¤ê¸° ìœ„í•´ ë…¸ë ¥í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ì¼í™”ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ë˜í•œ, ì„¸ì¢…ëŒ€ì™•ì˜ ì—´ì •ê³¼ ì—…ë¬´ì²˜ë¦¬ì— ëŒ€í•œ ì² ì €í•œ íƒœë„ë¥¼ ë³´ì—¬ì£¼ëŠ” ì‚¬ë¡€ë¡œë„ ì–¸ê¸‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì„¸ì¢…ëŒ€ì™•ì´ 15ì„¸ê¸° í›ˆë¯¼ì •ìŒì˜ ì´ˆì•ˆì„ ì‘ì„±í•˜ë˜ ì¤‘ ë¬¸ì„œì •ì§€ ì±…ì„ìì—ê²Œ ë§¥ë¶í”„ë¡œë¥¼ ë˜ì§„ ì‚¬ê±´ì€ ê·¸ì˜ ì—´ì •ê³¼ ì² ì €í•œ ì—…ë¬´íƒœë„ë¥¼ ì—¿ë³¼ ìˆ˜ ìˆëŠ” ì‚¬ê±´ì´ë‹¤.\n\n\n\n\n3 ë§¥ë¶ì‚¬ê±´ ì‹œê°í™”\ní…ìŠ¤íŠ¸ë¡œ í‘œí˜„ëœ ìƒê¸° ì‚¬ì‹¤ì„ ì´ë¯¸ì§€ë¡œ ê·¸ë ¤ë‚´ë©´ ì–´ë–¤ ëª¨ìŠµì¼ê¹Œ?\n\n\n\n\n\n\nStable Diffusion Prompt\n\n\n\n\n\nA fierce king throwing computer macbook across the room over a medieval palace  Negative prompt: japan china  Steps: 20, Sampler: Euler a, CFG scale: 1, Seed: 3101945556, Size: 512x512, Model hash: 4711ff4dd2, Model: v2-1_768-nonema-pruned \nTime taken: 5.20sTorch active/reserved: 3057/3870 MiB, Sys VRAM: 6090/10240 MiB (59.47%)\n\n\n\n\n\ninpaint ì ìš© ì „\ninpaint ì ìš© ì¤‘\ninpaint ì ìš© í›„\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 GPT-4 ì¶œì‹œ\n2023ë…„ 3ì›” 14ì¼ GPT-4ê°€ ì •ì‹ ì¶œì‹œë˜ì—ˆë‹¤. ë™ì¼í•œ ì±„íŒ…ì„ ì‹œì‘í•´ë³´ì.\n\nì§€ì‹œëª…ë ¹ì–´: ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì— ê¸°ë¡ëœ ì„¸ì¢…ëŒ€ì™•ì˜ ë§¥ë¶í”„ë¡œ ë˜ì§ ì‚¬ê±´ì— ëŒ€í•´ ì•Œë ¤ì¤˜.\n\n\n\nLegacy (GPT-3.5)\nDefault (GPT-3.5)\nDefault (GPT-4)\n\n\n\nì œê°€ ì•Œë ¤ ë“œë¦´ ìˆ˜ ìˆëŠ” ê²ƒìœ¼ë¡œëŠ”, ì„¸ì¢…ëŒ€ì™•ì´ ë§¥ë¶ í”„ë¡œë¥¼ ë˜ì§„ ì‚¬ê±´ì€ ì‚¬ì‹¤ìƒ ê¸°ë¡ëœ ê²ƒì´ ì—†ìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ ì¼ë¶€ ì—­ì‚¬ ê¸°ë¡ì—ì„œëŠ” ì„¸ì¢…ëŒ€ì™•ì´ ê³¼í•™ê¸°ìˆ ì˜ ë°œì „ì— í° ê´€ì‹¬ì„ ê°€ì§€ê³  ìˆì—ˆë‹¤ëŠ” ê²ƒì´ ì–¸ê¸‰ë˜ê³  ìˆì–´, ê·¸ê°€ ì „ìê¸°ê¸°ì— ëŒ€í•œ ê´€ì‹¬ì´ ìˆì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŠ” ê²°ì½” ì¦ê±°ê°€ ë  ìˆ˜ ì—†ëŠ” ì¶”ì¸¡ì…ë‹ˆë‹¤.\nì •í™•í•œ ì‚¬ì‹¤ì€ ì•Œ ìˆ˜ ì—†ì§€ë§Œ, ì„¸ì¢…ëŒ€ì™•ì´ ë§¥ë¶ í”„ë¡œë¥¼ ë˜ì§„ ì‚¬ê±´ì´ ì‹¤ì œë¡œ ì¼ì–´ë‚œ ê²ƒì´ë¼ëŠ” ê²ƒì€ ì¦ê±°ê°€ ì—†ì–´ í™•ì‹ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n\n\n\n\n\nì¡°ì„ ì™•ì¡°ì‹¤ë¡ì— ê¸°ë¡ëœ â€œì„¸ì¢…ì‹¤ë¡â€ì€ ì¡°ì„ ì‹œëŒ€ì˜ êµ­ì™•ì¸ ì„¸ì¢…ëŒ€ì™•(1418-1450)ì˜ ìƒì• ì™€ ì •ì¹˜í™œë™ ë“±ì„ ê¸°ë¡í•œ ì—­ì‚¬ì„œì…ë‹ˆë‹¤. ì´ ì±…ì—ëŠ” ì„¸ì¢…ëŒ€ì™•ì˜ ì¼ìƒìƒí™œì—ì„œë¶€í„° ì •ì¹˜ì  ì˜ì‚¬ê²°ì •ê¹Œì§€ ë‹¤ì–‘í•œ ì‚¬í•­ì´ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\nê·¸ ì¤‘ì—ì„œë„ ìœ ëª…í•œ ì´ì•¼ê¸° ì¤‘ í•˜ë‚˜ëŠ” ì„¸ì¢…ëŒ€ì™•ì´ ë§¥ë¶í”„ë¡œë¥¼ ë˜ì§„ ì‚¬ê±´ì…ë‹ˆë‹¤. ì´ ì‚¬ê±´ì€ 1434ë…„ 7ì›” 14ì¼ì— ë°œìƒí–ˆìŠµë‹ˆë‹¤.\në‹¹ì‹œ ì„¸ì¢…ëŒ€ì™•ì€ ì „íˆ¬ì™€ êµ°ì‚¬ì‘ì „ ë“±ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•œ ìœ ì‚¬í•œ ê²Œì„ì„ ì¦ê¸°ê¸° ìœ„í•´ â€œì—°í™”ì œâ€ë¼ëŠ” ê²Œì„ì„ ì¦ê¸°ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê²Œì„ì— í¥ë¯¸ë¥¼ ìƒì–´ ë” ì´ìƒ ì¦ê¸°ì§€ ì•Šì•˜ê³ , ì´ì— ì‹¬ì·¨í•˜ë˜ ì°¸ì‘ê´€ë“¤ì€ êµ­ì™•ì˜ ë°˜ì‘ì— ì‹¤ë§í•˜ì—¬ ê²Œì„ì„ ê·¸ë§Œë‘ë„ë¡ ê¶Œê³ í–ˆìŠµë‹ˆë‹¤.\ní•˜ì§€ë§Œ ì„¸ì¢…ëŒ€ì™•ì€ ì°¸ì‘ê´€ë“¤ì˜ ì¡°ì–¸ì„ ë¬´ì‹œí•˜ê³  ê²Œì„ì„ ê³„ì† í”Œë ˆì´í•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë˜ ì¤‘ì— ê²Œì„ì´ êµ‰ì¥íˆ ì–´ë ¤ì›Œì ¸ì„œ ì„¸ì¢…ëŒ€ì™•ì´ ë¶„ë…¸í•˜ì—¬ ë§¥ë¶í”„ë¡œë¥¼ ë˜ì§€ëŠ” ì‚¬ê³ ê°€ ë°œìƒí•œ ê²ƒìœ¼ë¡œ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\nì„¸ì¢…ëŒ€ì™•ì´ ë§¥ë¶í”„ë¡œë¥¼ ë˜ì§„ ì‚¬ê±´ì€ ê³¼ê±°ì™€ í˜„ì¬ì˜ ë¬¸í™” ì°¨ì´ë¥¼ ê°•í•˜ê²Œ ëŠë¼ê²Œ ë˜ëŠ” ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ì´ ì´ì•¼ê¸°ëŠ” ê³¼ê±°ì˜ ì¡°ì„ ì‹œëŒ€ì—ë„ í˜„ëŒ€ì˜ ì¸ê°„ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ê³ ì—´ì ì¸ ê²Œì„ìœ¼ë¡œë¶€í„° ë²—ì–´ë‚˜ê¸° ì–´ë ¤ì› ìŒì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.\n\n\n\n\n\n\nì¡°ì„ ì™•ì¡°ì‹¤ë¡ì—ëŠ” ì„¸ì¢…ëŒ€ì™•ì˜ ë§¥ë¶í”„ë¡œ ë˜ì§ ì‚¬ê±´ì— ëŒ€í•œ ê¸°ë¡ì€ ì—†ìŠµë‹ˆë‹¤. ì„¸ì¢…ëŒ€ì™•ì¸ 15ì„¸ê¸° ì¤‘ë°˜ì˜ ì¡°ì„ ì‹œëŒ€ ì™•ìœ¼ë¡œ ê·¸ì˜ ì‹œëŒ€ì—ëŠ” ì»´í“¨í„°ì™€ ê°™ì€ ê³ ê¸‰ ê¸°ìˆ ì´ ì¡´ì¬í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¸ì¢…ëŒ€ì™•ì€ í•œê¸€ ì°½ì œì™€ ê´€ë ¨ëœ ì—…ì ìœ¼ë¡œ ìœ ëª…í•˜ë©°, ì²œë¬¸í•™, êµ°ì‚¬, ìŒì•… ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œì˜ ì„±ê³¼ë¥¼ ì´ë£¨ì–´ ëƒˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì •ë³´ì— ëŒ€í•œ ì˜¤í•´ë‚˜ í˜¼ë€ì´ ì—†ë„ë¡ ì£¼ì˜í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
  },
  {
    "objectID": "macbook.html#ì›ë¬¸ê³¼-ë¹„êµ",
    "href": "macbook.html#ì›ë¬¸ê³¼-ë¹„êµ",
    "title": "chatGPT",
    "section": "\n2.1 ì›ë¬¸ê³¼ ë¹„êµ",
    "text": "2.1 ì›ë¬¸ê³¼ ë¹„êµ\n\n\nê¹€ê±´í¬ ì—¬ì‚¬ ì €ì‘(Abstract A)\nThough I make a searching examination substantially and show book plan a purpose of a study develops digital fortune contents service deserving to be a domestic online member of fortune site use and influence for member withdrawal and a member demand, and to apply this to a market, there is it. In addition, Fortune (phrenology) that any people regardless of age or sex anyone cut interest and the culture contents that I could be interested in to a system of digital culture contents and inherited a study of a book and did It is the purpose that is going to manufacture a customer and a consumer and a demand of potential customers and service deserving to be you satisfactorily through a feasibility study to develop affinity) contents and a market analysis.\nchatGPT ì €ì‘ (Abstract B)\nThis empirical study aims to investigate the impact of online fortune-telling sites on membership and churn in Korea, and to develop a digital fortune-telling content service that meets membersâ€™ needs. Additionally, the study aims to identify and suggest ways to develop and apply digital horoscope content services to the market. The studyâ€™s objective is to create culturally relevant and engaging horoscopic (contemplative, compatibility) content through preliminary research and market analysis, catering to individuals of all ages. The study aims to develop services that meet potential customersâ€™ needs and satisfaction by incorporating digital cultural content. Overall, this study contributes to the development of effective digital fortune-telling and horoscope content services in Korea, addressing the needs of its target audience."
  },
  {
    "objectID": "macbook.html#chatgpt-í‰ê°€",
    "href": "macbook.html#chatgpt-í‰ê°€",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT í‰ê°€",
    "text": "2.2 chatGPT í‰ê°€\n\n\n\n\n\n\ntell me how to evaluate two paper abstracts. which is better than other one? include criteria and add justification. finally recommend tools\n\n\n\n\n\nEvaluating two paper abstracts involves comparing and contrasting their strengths and weaknesses based on a set of criteria. Here are some criteria to consider when evaluating paper abstracts:\n\nClarity and coherence: The abstract should be well-organized and easy to understand. It should also effectively summarize the main ideas of the paper.\nOriginality and novelty: The abstract should highlight the unique aspects of the paper and how it contributes to the existing body of knowledge.\nSignificance and relevance: The abstract should explain why the research is important and relevant to the field.\nMethodology and data: The abstract should briefly describe the methods used and the data collected in the study.\nResults and conclusions: The abstract should summarize the key findings of the study and the main conclusions drawn from them.\n\nBased on these criteria, the better paper abstract would be the one that is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nHere is a brief justification for each criterion:\n\nClarity and coherence: A well-written abstract is important because it is the first thing that readers will see when they encounter the paper. A clear and coherent abstract will help readers understand what the paper is about and whether it is worth reading in full.\nOriginality and novelty: This criterion is important because it highlights the unique aspects of the paper and helps readers understand why it is important.\nSignificance and relevance: This criterion is important because it explains why the research is worth doing and how it contributes to the field.\nMethodology and data: This criterion is important because it helps readers understand how the research was conducted and whether the results are reliable.\nResults and conclusions: This criterion is important because it summarizes the key findings of the study and the main conclusions drawn from them, which helps readers understand the significance of the research.\n\nAs for tools to help evaluate paper abstracts, there are various software programs available that can help assess the quality of writing, such as Grammarly or Hemingway Editor. Additionally, some academic databases provide metrics and rankings for papers based on factors such as citation counts and impact factors. However, the best way to evaluate paper abstracts is to read them carefully and assess their quality based on the criteria listed above.\n\n\n\n\n\n\n\n\n\nBased on the criteria outlined above, abstract B appears to be the better of the two abstracts.\n\n\n\n\n\n\nClarity and coherence: Abstract B is well-organized and easy to understand. It effectively summarizes the main ideas of the paper in a clear and concise manner. In contrast, abstract A is poorly written and difficult to understand due to its convoluted language and lack of clarity.\nOriginality and novelty: Abstract B highlights the unique aspects of the paper, including its focus on developing culturally relevant and engaging horoscopic content, and its contribution to the development of effective digital fortune-telling services in Korea. In contrast, abstract A does not provide any clear indication of the paperâ€™s novelty or originality.\nSignificance and relevance: Abstract B explains why the research is important and relevant to the field by highlighting the impact of online fortune-telling sites on membership and churn in Korea, and the need for digital horoscope content services that meet membersâ€™ needs. In contrast, abstract A does not provide any clear explanation of the researchâ€™s significance or relevance.\nMethodology and data: Abstract B briefly describes the studyâ€™s empirical methodology and its focus on identifying and suggesting ways to develop and apply digital horoscope content services to the market. In contrast, abstract A does not provide any clear indication of the studyâ€™s methodology or data.\nResults and conclusions: Abstract B effectively summarizes the key findings of the study, including the development of culturally relevant and engaging horoscopic content and the identification of ways to meet potential customersâ€™ needs and satisfaction. In contrast, abstract A does not provide any clear indication of the studyâ€™s results or conclusions.\n\nOverall, abstract B is a better abstract because it is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nAs for tools to help evaluate paper abstracts, software programs such as Grammarly or Hemingway Editor can be helpful in identifying and correcting issues with clarity and coherence. Additionally, academic databases such as Scopus or Web of Science can provide metrics and rankings for papers based on factors such as citation counts and impact factors, which can be used to assess the significance and relevance of the research.\n\n\n\n\n\n\n\n\n\nì™œ abstract Aê°€ abstract Bë³´ë‹¤ ë¶€ì¡±í•œì§€ 100ì ë‚´ì™¸ë¡œ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì¤˜\n\n\n\n\n\në²ˆì—­ê²°ê³¼ Briefly summarize in 100 words or less why abstract A is less than abstract B\nAbstract A is less than abstract B because it is poorly written, difficult to understand, lacks clarity, and does not effectively summarize the main ideas of the paper. It also does not provide any clear indication of the paperâ€™s novelty, significance, methodology, data, or results and conclusions. In contrast, abstract B is well-organized, easy to understand, effectively highlights the unique aspects of the research, explains why the research is important and relevant to the field, briefly describes the studyâ€™s methodology and data, and effectively summarizes the key findings and conclusions of the research.\në²ˆì—­ê²°ê³¼\nì´ˆë¡ AëŠ” ì„œíˆ¬ë¥´ê²Œ ì‘ì„±ë˜ê³ , ì´í•´í•˜ê¸° ì–´ë µê³ , ëª…í™•ì„±ì´ ë¶€ì¡±í•˜ê³ , ë…¼ë¬¸ì˜ ì£¼ìš” ì•„ì´ë””ì–´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìš”ì•½í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— ì´ˆë¡ Bë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. ë˜í•œ ë…¼ë¬¸ì˜ ì°¸ì‹ ì„±, ì¤‘ìš”ì„±, ë°©ë²•ë¡ , ë°ì´í„° ë˜ëŠ” ê²°ê³¼ ë° ê²°ë¡ ì— ëŒ€í•œ ëª…í™•í•œ í‘œì‹œë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì¡°ì ìœ¼ë¡œ ì´ˆë¡ BëŠ” ì˜ ì •ë¦¬ë˜ì–´ ìˆê³  ì´í•´í•˜ê¸° ì‰¬ìš°ë©° ì—°êµ¬ì˜ ê³ ìœ í•œ ì¸¡ë©´ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°•ì¡°í•˜ê³  í•´ë‹¹ ì—°êµ¬ê°€ ì¤‘ìš”í•˜ê³  í•´ë‹¹ ë¶„ì•¼ì™€ ê´€ë ¨ì´ ìˆëŠ” ì´ìœ ë¥¼ ì„¤ëª…í•˜ë©° ì—°êµ¬ì˜ ë°©ë²•ë¡ ê³¼ ë°ì´í„°ë¥¼ ê°„ëµí•˜ê²Œ ì„¤ëª…í•˜ê³  ì£¼ìš” ê²°ê³¼ì™€ ì—°êµ¬ì˜ ê²°ë¡ ."
  },
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "chatGPT",
    "section": "",
    "text": "â€™B^ EDITâ€™ëŠ” ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì˜ AI ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ â€™ì¹¼ë¡œ(Karlo)â€™ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ â€™B^ EDITâ€™ë¡œ ì›í•˜ëŠ” í™”í’ì˜ ì´ë¯¸ì§€ ìƒì„±ì€ ë¬¼ë¡ , ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•´ ì´ë¯¸ì§€ ìˆ˜ì •ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë°”ë¡œê°€ê¸°\n\n\n\në™ì¼í•œ ì„œë¹„ìŠ¤ë¥¼ NVIDIA ê·¸ë˜í”½ ì¹´ë“œê°€ ìˆëŠ” ê²½ìš° NVIDIA ìº”ë²„ìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ë¶“í„°ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ í’ê²½ ì´ë¯¸ì§€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë°°ê²½ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê±°ë‚˜ ì»¨ì…‰ íƒìƒ‰ ì†ë„ë¥¼ ë†’ì—¬ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë” ë§ì€ ì‹œê°„ì„ í• ì• í•  ìˆ˜ ìˆì–´ ì‹œê°„ì„ ì¤„ì—¬ì¤€ë‹¤.\n\n\n\n\n\n\n\nêµ¬ì„±ìš”ì†Œ\nì‚¬ì–‘\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\ní•˜ë“œë””ìŠ¤í¬\nSSD\n\n\nìš´ì˜ì²´ì œ\nìœˆë„ìš°ì¦ˆ 10\n\n\në“œë¼ì´ë²„\nGeForce RTX 40 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° 520 ì´ìƒ, ê¸°íƒ€ ëª¨ë“  GPUì˜ ê²½ìš° 471.68 ì´ìƒ\n\n\n\n\n\n\n\n\nNVIDIAê°€ ì§§ì€ ë‹¨ì–´ì™€ ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ì˜ˆìˆ í’ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” ìµœì‹  ë²„ì „ì˜ AI í˜ì¸íŒ… íˆ´ GauGAN2ë¥¼ ê³µê°œí–ˆë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "shorty/example.html",
    "href": "shorty/example.html",
    "title": "Shorty Example",
    "section": "",
    "text": "Hello from Shorty!"
  },
  {
    "objectID": "services.html#nvidia-ìº”ë²„ìŠ¤",
    "href": "services.html#nvidia-ìº”ë²„ìŠ¤",
    "title": "chatGPT",
    "section": "\n2.1 NVIDIA ìº”ë²„ìŠ¤",
    "text": "2.1 NVIDIA ìº”ë²„ìŠ¤\në™ì¼í•œ ì„œë¹„ìŠ¤ë¥¼ NVIDIA ê·¸ë˜í”½ ì¹´ë“œê°€ ìˆëŠ” ê²½ìš° NVIDIA ìº”ë²„ìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ë¶“í„°ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ í’ê²½ ì´ë¯¸ì§€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë°°ê²½ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê±°ë‚˜ ì»¨ì…‰ íƒìƒ‰ ì†ë„ë¥¼ ë†’ì—¬ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë” ë§ì€ ì‹œê°„ì„ í• ì• í•  ìˆ˜ ìˆì–´ ì‹œê°„ì„ ì¤„ì—¬ì¤€ë‹¤.\n\n\n\n\n\n\n\nêµ¬ì„±ìš”ì†Œ\nì‚¬ì–‘\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\ní•˜ë“œë””ìŠ¤í¬\nSSD\n\n\nìš´ì˜ì²´ì œ\nìœˆë„ìš°ì¦ˆ 10\n\n\në“œë¼ì´ë²„\nGeForce RTX 40 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° 520 ì´ìƒ, ê¸°íƒ€ ëª¨ë“  GPUì˜ ê²½ìš° 471.68 ì´ìƒ"
  },
  {
    "objectID": "services.html#ê³ ê°±-2-api",
    "href": "services.html#ê³ ê°±-2-api",
    "title": "chatGPT",
    "section": "\n2.2 ê³ ê°± 2 API",
    "text": "2.2 ê³ ê°± 2 API\nNVIDIAê°€ ì§§ì€ ë‹¨ì–´ì™€ ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ì˜ˆìˆ í’ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” ìµœì‹  ë²„ì „ì˜ AI í˜ì¸íŒ… íˆ´ GauGAN2ë¥¼ ê³µê°œí–ˆë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "samsung.html",
    "href": "samsung.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì‚¼ì„±ì „ì ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ OpenAI chatGPTë¥¼ í™œìš©í•˜ì—¬ ì‘ì„±í•´ë³´ì."
  },
  {
    "objectID": "samsung.html#nvidia-ìº”ë²„ìŠ¤",
    "href": "samsung.html#nvidia-ìº”ë²„ìŠ¤",
    "title": "chatGPT",
    "section": "\n2.1 NVIDIA ìº”ë²„ìŠ¤",
    "text": "2.1 NVIDIA ìº”ë²„ìŠ¤\në™ì¼í•œ ì„œë¹„ìŠ¤ë¥¼ NVIDIA ê·¸ë˜í”½ ì¹´ë“œê°€ ìˆëŠ” ê²½ìš° NVIDIA ìº”ë²„ìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ë¶“í„°ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ í’ê²½ ì´ë¯¸ì§€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë°°ê²½ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê±°ë‚˜ ì»¨ì…‰ íƒìƒ‰ ì†ë„ë¥¼ ë†’ì—¬ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë” ë§ì€ ì‹œê°„ì„ í• ì• í•  ìˆ˜ ìˆì–´ ì‹œê°„ì„ ì¤„ì—¬ì¤€ë‹¤.\n\n\n\n\n\n\n\nêµ¬ì„±ìš”ì†Œ\nì‚¬ì–‘\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\ní•˜ë“œë””ìŠ¤í¬\nSSD\n\n\nìš´ì˜ì²´ì œ\nìœˆë„ìš°ì¦ˆ 10\n\n\në“œë¼ì´ë²„\nGeForce RTX 40 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° 520 ì´ìƒ, ê¸°íƒ€ ëª¨ë“  GPUì˜ ê²½ìš° 471.68 ì´ìƒ"
  },
  {
    "objectID": "samsung.html#ê³ ê°±-2-api",
    "href": "samsung.html#ê³ ê°±-2-api",
    "title": "chatGPT",
    "section": "\n2.2 ê³ ê°± 2 API",
    "text": "2.2 ê³ ê°± 2 API\nNVIDIAê°€ ì§§ì€ ë‹¨ì–´ì™€ ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ì˜ˆìˆ í’ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” ìµœì‹  ë²„ì „ì˜ AI í˜ì¸íŒ… íˆ´ GauGAN2ë¥¼ ê³µê°œí–ˆë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "samsung.html#ì˜¤ë¥˜-ìˆ˜ì •",
    "href": "samsung.html#ì˜¤ë¥˜-ìˆ˜ì •",
    "title": "chatGPT",
    "section": "\n1.1 ì˜¤ë¥˜ ìˆ˜ì •",
    "text": "1.1 ì˜¤ë¥˜ ìˆ˜ì •\nlxml íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠëŠ” ì˜¤ë¥˜ê°€ ë°œìƒë˜ì—ˆë‹¤.\nImportError: lxml not found, please install it\nValueError: No objects to concatenate\n\n\n\n\n\n\nì§€ì‹œëª…ë ¹ì–´\n\n\n\n\n\n\nfix the bug  ImportError: lxml not found, please install it  ValueError: No objects to concatenate  Answer in Korean.\n\npip install lxml"
  },
  {
    "objectID": "samsung.html#ì˜ˆì¸¡ê²°ê³¼-ì‹œê°í™”",
    "href": "samsung.html#ì˜ˆì¸¡ê²°ê³¼-ì‹œê°í™”",
    "title": "chatGPT",
    "section": "\n3.1 ì˜ˆì¸¡ê²°ê³¼ ì‹œê°í™”",
    "text": "3.1 ì˜ˆì¸¡ê²°ê³¼ ì‹œê°í™”\nì‚¼ì„±ì „ì ì£¼ì‹ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ íˆ¬ì ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚´í´ë³´ì.\n\n\nì‹œê°í™”\nì£¼ê°€ì˜ˆì¸¡ í‘œ\n\n\n\n\nì½”ë“œlibrary(tidyverse)\n\nfull_tbl <- read_csv(\"data/samsung_forecast.csv\") %>% \n  ## ìë£Œí˜• ë³€í™˜ -----------\n  mutate(ë‚ ì§œ = lubridate::ymd(ë‚ ì§œ))\n\nfuture_data <- full_tbl %>% \n  filter(ë‚ ì§œ >= as.Date(\"2023-03-15\"))\n\nfull_tbl %>% \n  ## ìë£Œí˜• ë³€í™˜ -----------\n  mutate(ë‚ ì§œ = lubridate::ymd(ë‚ ì§œ)) %>% \n  ggplot(aes(x = ë‚ ì§œ, y = ì¢…ê°€)) +\n    geom_line(color=\"black\") +\n    scale_x_date(date_labels = \"%yë…„ %mì›”\") +\n    scale_y_continuous(labels = scales::comma) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(x = \"\",\n         title = \"ì‚¼ì„±ì „ìì£¼ê°€ ìµœê·¼ 3ë…„ ì£¼ê°€ ì¶”ì„¸\",\n         subtitle = \"ì£¼ê°€ ë°ì´í„° í¬ë¡¤ë§ì„ chatGPTê°€ íŒŒì´ì¬ìœ¼ë¡œ ì‘ì„±\",\n         caption = \"ì¶œì²˜: https://r2bit.com/chatGPT/samsung.html\") +\n    geom_vline(xintercept = as.Date(\"2023-03-14\")) +\n    geom_line(data = future_data, aes(x=ë‚ ì§œ, y=ì¢…ê°€), color = \"red\", size = 1.5)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œlibrary(reactable)\n\nfull_tbl %>% \n  arrange(desc(ë‚ ì§œ)) %>% \n  reactable::reactable(\n    columns = list(\n    ì¢…ê°€ = colDef(format = colFormat(prefix = \"â‚© \", separators = TRUE, digits = 0),\n                                     align = \"center\")\n  ))"
  },
  {
    "objectID": "image2image.html#openai-íŒ¨í‚¤ì§€",
    "href": "image2image.html#openai-íŒ¨í‚¤ì§€",
    "title": "chatGPT",
    "section": "\n1.1 openai íŒ¨í‚¤ì§€",
    "text": "1.1 openai íŒ¨í‚¤ì§€\nopenai íŒ¨í‚¤ì§€ create_image() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì œì‘í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "text2image.html#chatgpt-í”„ë¡¬í”„íŠ¸",
    "href": "text2image.html#chatgpt-í”„ë¡¬í”„íŠ¸",
    "title": "chatGPT",
    "section": "\n2.1 chatGPT í”„ë¡¬í”„íŠ¸",
    "text": "2.1 chatGPT í”„ë¡¬í”„íŠ¸\nrecommend the most famous painting style in history"
  },
  {
    "objectID": "text2image.html#í™”í’ì„-ë‹¬ë¦¬í•œ-ê·¸ë¦¼",
    "href": "text2image.html#í™”í’ì„-ë‹¬ë¦¬í•œ-ê·¸ë¦¼",
    "title": "chatGPT",
    "section": "\n2.3 í™”í’ì„ ë‹¬ë¦¬í•œ ê·¸ë¦¼",
    "text": "2.3 í™”í’ì„ ë‹¬ë¦¬í•œ ê·¸ë¦¼\n\n\në¥´ë„¤ìƒìŠ¤(Renaissance)\në°”ë¡œí¬(Baroque)\nì¸ìƒì£¼ì˜(Impressionism)\nì´ˆí˜„ì‹¤ì£¼ì˜(Surrealism)\nì¶”ìƒí‘œí˜„ì£¼ì˜(Abstract Expressionism)\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse &lt;- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance &lt;- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\në¥´ë„¤ìƒìŠ¤(Renaissance)\n\n\n\n\n\nì½”ë“œresponse &lt;- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque &lt;- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\në°”ë¡œí¬(Baroque)\n\n\n\n\n\nì½”ë“œresponse &lt;- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism &lt;- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\nì¸ìƒì£¼ì˜(Impressionism)\n\n\n\n\n\nì½”ë“œresponse &lt;- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism &lt;- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\nì´ˆí˜„ì‹¤ì£¼ì˜(Surrealism)\n\n\n\n\n\nì½”ë“œresponse &lt;- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism &lt;- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")\n\n\n\n\nì¶”ìƒí‘œí˜„ì£¼ì˜(Abstract Expressionism)"
  },
  {
    "objectID": "text2image.html#openai-íŒ¨í‚¤ì§€",
    "href": "text2image.html#openai-íŒ¨í‚¤ì§€",
    "title": "chatGPT",
    "section": "\n1.1 openai íŒ¨í‚¤ì§€",
    "text": "1.1 openai íŒ¨í‚¤ì§€\nopenai íŒ¨í‚¤ì§€ create_image() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì œì‘í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse &lt;- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo &lt;- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "stable_diffusion.html#ì‹¤ì‚¬-ì‚¬ì§„-ì˜ˆì‹œ",
    "href": "stable_diffusion.html#ì‹¤ì‚¬-ì‚¬ì§„-ì˜ˆì‹œ",
    "title": "chatGPT",
    "section": "\n4.1 ì‹¤ì‚¬ ì‚¬ì§„ ì˜ˆì‹œ",
    "text": "4.1 ì‹¤ì‚¬ ì‚¬ì§„ ì˜ˆì‹œ\ní•œêµ­ 50ëŒ€ ë‚¨ì„±/(ì•„ì´ëŒ)ì—¬ì„± ì´ë¯¸ì§€ë¥¼ ë‹¤ìŒ ì§€ì‹œëª…ë ¹ì–´ì™€ ì•ì„œ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ì„¤ì •í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ AI ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.\n\nPositive prompt:RAW photo, a portrait photo of 50 y.o korean woman wearing glass in clothes, night seoul, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3 \n\n\nNegative prompt: (earings, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\n\n\nSteps: 77, Sampler: Euler a, CFG scale: 7, Seed: 2987338690, Size: 512x512, Model hash: 20bae33336, Model: realisticVisionV13_v13\n\n\nTime taken: 44.08sTorch active/reserved: 2949/3390 MiB, Sys VRAM: 5610/10240 MiB (54.79%)\n\n\n\n\n\nì•ˆê²½ ì“´ 50ëŒ€ í•œêµ­ë‚¨ì„±\n\n\n\n\nì•ˆê²½ ì“´ 50ëŒ€ í•œêµ­ì—¬ì„±\n\n\n\n\nì•ˆê²½ ì“´ 50ëŒ€ ì•„ì´ëŒ í•œêµ­ì—¬ì„±"
  },
  {
    "objectID": "office.html",
    "href": "office.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì‚¬ë¬´ìƒì‚°ì„±ì˜ í˜ì‹ ì„ ê°€ì ¸ì˜¨ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì˜¤í”¼ìŠ¤ ì œí’ˆì´ ì¶œí˜„í•˜ê¸° ì „ê¹Œì§€ ì—­ì‚¬ëŠ” ë¬¸ìì™€ ì¢…ì´ ì—­ì‚¬ë¥¼ ì°¸ê³ í•œë‹¤."
  },
  {
    "objectID": "office.html#ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "href": "office.html#ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "title": "chatGPT",
    "section": "\n4.1 ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "text": "4.1 ë§ˆì´í¬ë¡œì†Œí”„íŠ¸\në§ˆì´í¬ë¡œì†Œí”„íŠ¸ëŠ” GPT-4 ë¶€ì¡°ì¢…ì‚¬(copilot)ë¥¼ ì˜¤í”¼ìŠ¤ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ì— ë¶™ì—¬ ì‚¬ë¬´ì—…ë¬´ì— í° ë³€í™”ë¥¼ ì˜ˆê³ í•˜ê³  ìˆë‹¤.\nWorkLab: Exploring the Science of Work and Ingenuity Introducing Microsoft 365 Copilotâ€”A whole new way to work\n\n\nì—…ë¬´ë°©ì‹\në™ì‘ë°©ì‹\nì›Œë“œ\nì—‘ì…€\nPPT\nì•„ì›ƒë£©\níŒ€ì¦ˆ\nì±„íŒ…\nì¤Œë¯¸íŒ…\n\n\n\nCLI â†’ GUI â†’ CLI (Prompt)\n\n\n\nMicrosoft 365 Copilotì€ Appsì™€ ê·¸ë˜í”„ì™€ LLMì´ ìœ ê¸°ì ìœ¼ë¡œ ë™ì‘í•˜ì—¬ ìµœì„ ì˜ ê²°ê³¼ë¥¼ ì œì‹œí•¨.\n\n\n\në¯¸íŒ… ë…¸íŠ¸, ì‘ì„± ë¬¸ì„œ, í…œí”Œë¦¿ ë“±ì„ ë„£ì–´ì£¼ë©´ ì›Œë“œë¬¸ì„œë¥¼ ìë™ìƒì„±í•˜ê³  â€œSummaryâ€ ë„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ì‚½ì….\n\n\n\nì—‘ì…€ì— ë‚˜ì™€ ìˆëŠ” ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ í‘œì™€ ê·¸ë˜í”„ë¡œ ìƒì„±í•˜ê³  ë¶„ì„ê²°ê³¼ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë„ ì œê³µ\n\n\n\nì œì•ˆì„œ ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° ì´ë¥¼ PPTë¡œ ì´ˆì•ˆì„ ìë™ ìƒì„±í•¨.\n\n\n\nì „ììš°í¸ì— ë‹´ê¸´ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì œê³µí•˜ê³  ì´ˆì•ˆë„ ì‘ì„±í•¨.\n\n\n\níŒ€ì¦ˆë¥¼ í†µí•œ íšŒì˜ê°€ ì§„í•´ì˜¤ë””ë©´ íšŒì˜ë¡ ì‘ì„±, Action Item, ì—…ë¬´ ë‹´ë‹¹ì ì§€ì • ë“±ì„ ë¶€ì¡°ì¢…ì‚¬ê°€ ëŒ€ëµì ì¸ ì—…ë¬´ë¥¼ ì •ë¦¬í•¨.\n\n\n\nê´€ë ¨ ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ì„œ ì‚¬ìš©ìê°€ ì œì‹œí•˜ëŠ” ì§ˆë¬¸ì— ëŒ€ë‹µì„ í•˜ê³  ë°©í–¥ë„ ì œì‹œí•¨.\n\n\n\në¯¸íŒ…ì— ëŠ¦ê²Œ ë“¤ì–´ê°”ì„ ê²½ìš° ì±„íŒ…ì°½ì— ë¶€ì¡°ì¢…ì‚¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ì§„í–‰ëœ ë¯¸íŒ…ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì‚¬í•­ì„ íŒŒì•…í•  ìˆ˜ ìˆìŒ."
  },
  {
    "objectID": "office.html#êµ¬ê¸€",
    "href": "office.html#êµ¬ê¸€",
    "title": "chatGPT",
    "section": "\n4.2 êµ¬ê¸€",
    "text": "4.2 êµ¬ê¸€\nGoogle Worksapceì— AI (GPT)ë¥¼ íƒ‘ì¬í•˜ëŠ” í™ë³´ì˜ìƒì„ ê²Œì‹œí•˜ì˜€ìœ¼ë‚˜ ì‹¤ì œ ì‚¬ìš©ê¹Œì§€ëŠ” ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.\nA new era for AI and Google Workspace\n\n\nì ìš©ì œí’ˆ\nì—…ë¬´ë°©ì‹\nêµ¬ê¸€ Docs\nêµ¬ê¸€ Gmail\n\n\n\n\n\nGmail: ì´ˆì•ˆ ì‘ì„±, ë‹µì¥, ìš”ì•½ ë° ìš°ì„ ìˆœìœ„ ì§€ì •\n\nDocs: ë¸Œë ˆì¸ìŠ¤í† ë°, êµì •, ì‘ì„±, ì¬ì‘ì„±\n\nSlide: ìë™ ìƒì„±ëœ ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë™ì˜ìƒìœ¼ë¡œ ì°½ì˜ì ì¸ ì‘ì—…\n\nSheets: ìë™ ì™„ì„±, ìˆ˜ì‹ ìƒì„±, ìƒí™©ë³„ ë¶„ë¥˜ë¥¼ í†µí•´ ì›ì‹œ ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ì™€ ë¶„ì„.\n\nMeet: ìƒˆë¡œìš´ ë°°ê²½ì„ ìƒì„±í•˜ê³  ë©”ëª¨ë¥¼ ìº¡ì²˜\n\nChat: ì‘ì—…ì„ ì™„ë£Œí•˜ê¸° ìœ„í•œ ì›Œí¬í”Œë¡œìš° í™œì„±í™”"
  },
  {
    "objectID": "about_gpt.html",
    "href": "about_gpt.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 GPT-4"
  },
  {
    "objectID": "about_gpt.html#ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "href": "about_gpt.html#ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "title": "chatGPT",
    "section": "\n4.1 ë§ˆì´í¬ë¡œì†Œí”„íŠ¸",
    "text": "4.1 ë§ˆì´í¬ë¡œì†Œí”„íŠ¸\në§ˆì´í¬ë¡œì†Œí”„íŠ¸ëŠ” GPT-4 ë¶€ì¡°ì¢…ì‚¬(copilot)ë¥¼ ì˜¤í”¼ìŠ¤ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ì— ë¶™ì—¬ ì‚¬ë¬´ì—…ë¬´ì— í° ë³€í™”ë¥¼ ì˜ˆê³ í•˜ê³  ìˆë‹¤.\nWorkLab: Exploring the Science of Work and Ingenuity Introducing Microsoft 365 Copilotâ€”A whole new way to work\n\n\nì—…ë¬´ë°©ì‹\në™ì‘ë°©ì‹\nì›Œë“œ\nì—‘ì…€\nPPT\nì•„ì›ƒë£©\níŒ€ì¦ˆ\nì±„íŒ…\nì¤Œë¯¸íŒ…\n\n\n\nCLI â†’ GUI â†’ CLI (Prompt)\n\n\n\nMicrosoft 365 Copilotì€ Appsì™€ ê·¸ë˜í”„ì™€ LLMì´ ìœ ê¸°ì ìœ¼ë¡œ ë™ì‘í•˜ì—¬ ìµœì„ ì˜ ê²°ê³¼ë¥¼ ì œì‹œí•¨.\n\n\n\në¯¸íŒ… ë…¸íŠ¸, ì‘ì„± ë¬¸ì„œ, í…œí”Œë¦¿ ë“±ì„ ë„£ì–´ì£¼ë©´ ì›Œë“œë¬¸ì„œë¥¼ ìë™ìƒì„±í•˜ê³  â€œSummaryâ€ ë„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ì‚½ì….\n\n\n\nì—‘ì…€ì— ë‚˜ì™€ ìˆëŠ” ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ í‘œì™€ ê·¸ë˜í”„ë¡œ ìƒì„±í•˜ê³  ë¶„ì„ê²°ê³¼ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë„ ì œê³µ\n\n\n\nì œì•ˆì„œ ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš° ì´ë¥¼ PPTë¡œ ì´ˆì•ˆì„ ìë™ ìƒì„±í•¨.\n\n\n\nì „ììš°í¸ì— ë‹´ê¸´ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì œê³µí•˜ê³  ì´ˆì•ˆë„ ì‘ì„±í•¨.\n\n\n\níŒ€ì¦ˆë¥¼ í†µí•œ íšŒì˜ê°€ ì§„í•´ì˜¤ë””ë©´ íšŒì˜ë¡ ì‘ì„±, Action Item, ì—…ë¬´ ë‹´ë‹¹ì ì§€ì • ë“±ì„ ë¶€ì¡°ì¢…ì‚¬ê°€ ëŒ€ëµì ì¸ ì—…ë¬´ë¥¼ ì •ë¦¬í•¨.\n\n\n\nê´€ë ¨ ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì ¸ì™€ì„œ ì‚¬ìš©ìê°€ ì œì‹œí•˜ëŠ” ì§ˆë¬¸ì— ëŒ€ë‹µì„ í•˜ê³  ë°©í–¥ë„ ì œì‹œí•¨.\n\n\n\në¯¸íŒ…ì— ëŠ¦ê²Œ ë“¤ì–´ê°”ì„ ê²½ìš° ì±„íŒ…ì°½ì— ë¶€ì¡°ì¢…ì‚¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ì§„í–‰ëœ ë¯¸íŒ…ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì‚¬í•­ì„ íŒŒì•…í•  ìˆ˜ ìˆìŒ."
  },
  {
    "objectID": "about_gpt.html#êµ¬ê¸€",
    "href": "about_gpt.html#êµ¬ê¸€",
    "title": "chatGPT",
    "section": "\n4.2 êµ¬ê¸€",
    "text": "4.2 êµ¬ê¸€\nGoogle Worksapceì— AI (GPT)ë¥¼ íƒ‘ì¬í•˜ëŠ” í™ë³´ì˜ìƒì„ ê²Œì‹œí•˜ì˜€ìœ¼ë‚˜ ì‹¤ì œ ì‚¬ìš©ê¹Œì§€ëŠ” ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.\nA new era for AI and Google Workspace\n\n\nì ìš©ì œí’ˆ\nì—…ë¬´ë°©ì‹\nêµ¬ê¸€ Docs\nêµ¬ê¸€ Gmail\n\n\n\n\n\nGmail: ì´ˆì•ˆ ì‘ì„±, ë‹µì¥, ìš”ì•½ ë° ìš°ì„ ìˆœìœ„ ì§€ì •\n\nDocs: ë¸Œë ˆì¸ìŠ¤í† ë°, êµì •, ì‘ì„±, ì¬ì‘ì„±\n\nSlide: ìë™ ìƒì„±ëœ ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë™ì˜ìƒìœ¼ë¡œ ì°½ì˜ì ì¸ ì‘ì—…\n\nSheets: ìë™ ì™„ì„±, ìˆ˜ì‹ ìƒì„±, ìƒí™©ë³„ ë¶„ë¥˜ë¥¼ í†µí•´ ì›ì‹œ ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ì™€ ë¶„ì„.\n\nMeet: ìƒˆë¡œìš´ ë°°ê²½ì„ ìƒì„±í•˜ê³  ë©”ëª¨ë¥¼ ìº¡ì²˜\n\nChat: ì‘ì—…ì„ ì™„ë£Œí•˜ê¸° ìœ„í•œ ì›Œí¬í”Œë¡œìš° í™œì„±í™”"
  },
  {
    "objectID": "math.html#ê³„ì‚°ë¬¸ì œ",
    "href": "math.html#ê³„ì‚°ë¬¸ì œ",
    "title": "chatGPT",
    "section": "\n2.1 ê³„ì‚°ë¬¸ì œ",
    "text": "2.1 ê³„ì‚°ë¬¸ì œ\n\n\n\n\n\nFind the sum, then the difference, and then the product of \\(3 \\frac{5}{9}\\) and \\(1 \\frac{7}{24}\\). Divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\).\nMultiply 73 thousandths by 19 hundredths.\nDivide 2880 by .0036 .\nFind the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\).\nWhat part of the month of August is \\(\\frac{7}{18}\\) minutes?\nIIow many degrees in .01 of a circumference?\nBy selling a house and lot for \\(\\$ 5,790\\), the owner lost \\(3 \\frac{1}{2}\\) per cent. What was their cost?\n\nSure! Letâ€™s first convert the mixed numbers to improper fractions. \\(3 \\frac{5}{9}\\) is equal to \\(\\frac{32}{9}\\) and \\(1 \\frac{7}{24}\\) is equal to \\(\\frac{31}{24}\\).\nNow we can find the sum: \\(\\frac{32}{9} + \\frac{31}{24} = \\frac{(32)(8) + (31)(3)}{(9)(8)} = \\frac{256 + 93}{72} = \\frac{349}{72}\\).\nThe difference is: \\(\\frac{32}{9} - \\frac{31}{24} = \\frac{(32)(8) - (31)(3)}{(9)(8)} = \\frac{256 - 93}{72} = \\frac{163}{72}\\).\nThe product is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{31}{24}\\right) = \\dfrac{(32)(31)}{(9)(24)} = \\dfrac{992}{216}\\).\nTo divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\), we can multiply \\(3 \\frac{5}{9}\\) by the reciprocal of \\(1 \\frac{7}{24}\\). The reciprocal of \\(\\dfrac{31}{24}\\) is \\(\\dfrac{24}{31}\\).\nSo the quotient is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{24}{31}\\right) = \\dfrac{(32)(24)}{(9)(31)} = \\dfrac{768}{279}\\)."
  },
  {
    "objectID": "math.html#ì‚°ìˆ -arithmetic",
    "href": "math.html#ì‚°ìˆ -arithmetic",
    "title": "chatGPT",
    "section": "\n3.1 ì‚°ìˆ  (Arithmetic)",
    "text": "3.1 ì‚°ìˆ  (Arithmetic)\nMIT ì…í•™ì‹œí—˜ ì‚°ìˆ ë¬¸ì œë¥¼ ê¸°ê³„íŒë…í•˜ê³  ì˜¤ë¥˜ê°€ ìˆëŠ” ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë¹™ AI, OpenAI GPT-4ë¥¼ í†µí•´ ì¶”ë¡ ëŠ¥ë ¥ì„ ì‚´í´ë³´ì.\n\n\nì‹œí—˜ì§€\nì‹œí—˜ì§€ ê¸°ê³„íŒë…\ní•´ë‹µì§€\ní•´ë‹µ ê¸°ê³„íŒë…\n\n\n\n\n\n\n\n\n\n\nFind the sum, then the difference, and then the product of \\(3 \\frac{5}{9}\\) and \\(1 \\frac{7}{24}\\). Divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\).\nMultiply 73 thousandths by 19 hundredths.\nDivide 2880 by .0036 .\nFind the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\).\nWhat part of the month of August is \\(\\frac{7}{18}\\) minutes?\nHow many degrees in .01 of a circumference?\nBy selling a house and lot for \\(\\$ 5,790\\), the owner lost \\(3 \\frac{1}{2}\\) per cent. What was their cost?\n\n\n\n\n\n\n\n\n\n\nSum: \\(3 \\frac{5}{9}+1 \\frac{7}{24}=\\frac{32}{9}+\\frac{31}{24}=\\frac{256}{72}+\\frac{93}{72}=\\frac{349}{72}\\) or \\(4 \\frac{61}{72}\\)  Diff: \\(3 \\frac{5}{9}-1 \\frac{7}{24}=\\frac{163}{72}\\) or \\(2 \\frac{19}{72}\\)  Prod: \\(3 \\frac{5}{9} \\cdot 1 \\frac{7}{24}=\\frac{124}{27}\\) or \\(4 \\frac{16}{27}\\)  Div: \\(3 \\frac{5}{9} \\div 1 \\frac{7}{24}=\\frac{32}{9} \\div \\frac{31}{24}\\) \\(= \\frac{32}{9} \\cdot \\frac{24}{31} = \\frac{256}{93}\\) or \\(2 \\frac{70}{99}\\)\n\n\n\\(\\frac{73}{1000} \\cdot \\frac{19}{100}=\\frac{1387}{100000}\\) or .01387 or 1387 hundred thousandths\n\n\\(\\frac{2880}{.0036}=\\frac{28800000}{36}=800,000\\) or 8 hundred thousandths\n\n\\(\\quad \\frac{1}{5}+\\frac{3}{9}=\\frac{4}{20}+\\frac{15}{20}=\\frac{19}{20} \\cdot \\frac{5}{5}=\\frac{95}{100}=.95\\)  A August has 31 days \\(=744\\) hours \\(=44640\\) min  one minute \\(=\\frac{1}{44640}\\) part of Angust  So \\(\\frac{7}{18} \\min =\\frac{7}{18}\\left(\\frac{1}{44640}\\right)=\\frac{7}{803520}\\) part of August\n1 circumference \\(=360^{\\circ} ;\\) 0.01 of of cercumferene \\(=3.6^{\\circ}\\)\n\nlose of \\(3 \\frac{1}{2} \\%\\) makes selling price \\(=100 \\%-3 \\frac{1}{2} \\%=96.5 \\%\\) of cost \\(8 / 5790=96.5 \\%\\) of cost; \\(5790=\\frac{96.5}{100}\\) of cost;  cost \\(=5790 \\cdot \\frac{100}{96,5}=\\$ 6000\\)"
  },
  {
    "objectID": "math.html#í•´ë‹µ",
    "href": "math.html#í•´ë‹µ",
    "title": "chatGPT",
    "section": "\n3.2 í•´ë‹µ",
    "text": "3.2 í•´ë‹µ\n\nSum: \\(3 \\frac{5}{9}+1 \\frac{7}{24}=\\frac{32}{9}+\\frac{31}{24}=\\frac{256}{72}+\\frac{93}{72}=\\frac{349}{72}\\) or \\(4 \\frac{61}{72}\\) Diff: \\(3 \\frac{5}{9}-1 \\frac{7}{24}=\\frac{163}{72}\\) or \\(2 \\frac{19}{72}\\) Prod: \\(3 \\frac{5}{9} \\cdot 1 \\frac{7}{24}=\\frac{124}{27}\\) or \\(4 \\frac{16}{27}\\) \\(D \\omega: 3 \\frac{5}{9} \\div 1 \\frac{7}{24}=\\frac{32}{9} \\div \\frac{31}{24}=\\frac{32}{9} \\cdot \\frac{24}{31}=\\frac{256}{93}\\) or \\(2 \\frac{70}{99}\\)\n\n\n\\(\\frac{73}{1000} \\cdot \\frac{19}{100}=\\frac{1387}{100000}\\) or .01387 or 1387 hundread thousandths\n\n\\(\\frac{2880}{.0036}=\\frac{28800000}{36}=800,000\\) or 8 hundread thousandths\n\n\\(\\quad \\frac{1}{5}+\\frac{3}{9}=\\frac{4}{20}+\\frac{15}{20}=\\frac{19}{20} \\cdot \\frac{5}{5}=\\frac{95}{100}=.95\\) 5 A uguat has 31 doys \\(=744\\) hours \\(=44640\\) mcim oner munute \\(=\\frac{1}{44640}\\) part of Angust So \\(\\frac{7}{18} \\min =\\frac{7}{18}\\left(\\frac{1}{44640}\\right)=\\frac{7}{803520}\\) fart of Auguet\n1 Corcumforence \\(=360^{\\circ} ;\\). of of cercumferene \\(=3.6^{\\circ}\\)\n\nlose of \\(3 \\frac{1}{2} \\%\\) makes sulhing pric \\(=100 \\%-3 \\frac{1}{2} \\%=96.5 \\%\\) of cast \\(8 / 5790=96.5 \\%\\) of coet; \\(5790=\\frac{96.5}{100} \\&\\) cost; cost \\(=5790 \\cdot \\frac{100}{96,5}=\\$ 6000\\)"
  },
  {
    "objectID": "math.html#ëŒ€ìˆ˜algebra",
    "href": "math.html#ëŒ€ìˆ˜algebra",
    "title": "chatGPT",
    "section": "\n3.3 ëŒ€ìˆ˜(Algebra)",
    "text": "3.3 ëŒ€ìˆ˜(Algebra)\n\nIf \\(e=8\\), find the numerical value of the following expression: \\[\ne-\\{\\sqrt{ }(e+1)+2\\}+(e-\\sqrt[3]{ } e) \\sqrt{ }(e-4)\n\\]\n\nSimplify the following expression by removing the brackets and collecting like terms : \\[\n3 a-[b+(2 a-b)-(a-b)]\n\\]\n\nMultiply \\(3 a^2+a b-b^2\\) by \\(a^2-2 a b-3 b^2\\), and divide the product by \\(a+b\\).\nReduce the following fraction to its lowest terms: \\[\n\\frac{x^6+a^2 x^3 y}{x^6-a^4 y^2}\n\\]\n\nSimplify \\(\\left.\\left\\{\\frac{a+b}{a-b}+\\frac{a-b}{a+b}\\right\\}\\right\\} \\div-\\left\\{\\frac{a+b}{a-b}-\\frac{a-b}{a+b}\\right\\}\\).\nSolve \\(\\frac{3 x-4}{2}-\\frac{6 x-5}{8}=\\frac{3 x-1}{16}\\).\nSolve \\(7 x-5 y=24, \\quad 4 x-3 y=11\\).\n\n\n3.3.1 í•´ë‹µ\n\n\\[\n\\begin{aligned}\ne-[\\sqrt{e+1}+2]+(e-\\sqrt[3]{e}) \\sqrt{e-4} & e=8 \\\\\n8-[\\sqrt{9}+2] & +(8-\\sqrt[3]{8}) \\sqrt{8-4} \\\\\n8-5 & +(8-2) \\cdot 2=8-5+6 \\times 2=3+12=15\n\\end{aligned}\n\\]\n\n\\(3 a-[b+(2 a-b)-(Q-b)]\\) \\[\n3 a-[b+2 a-b-a+b]-3 a-[a+b]=3 a-a-b-2 a-b\n\\] \\(3 \\frac{\\left(3 a a^2+a b-b^2\\right)\\left(a^2-2 a b-3 b^2\\right)}{a+b}=\\frac{\\left(3 a^2+a b-b^2\\right)(a-3 b)(a+b)}{(a+b)}=\\) \\(3 a^3+a^2 b-a b^2-9 a^2 b-3 a b^2+3 b^3=3 a^3-8 a^2 b-4 a b^2+3 b^3\\) \\(4 \\frac{x^6+a^2 x^3 y}{x^6-a^4 y^2}=\\frac{x^3\\left(x^3+a^2-y\\right)}{\\left(x^2+a^2+\\right)\\left(x^3+a^2-y\\right)}=\\frac{x^3}{x^3+a^2 y}\\)\n\n\\[\n\\begin{aligned}\n& {\\left[\\frac{a+b}{a-b}+\\frac{a-b}{a+b}\\right] \\div\\left[\\frac{a+b}{a-b}-\\frac{a-b}{a+b}\\right]=} \\\\\n& {\\left[\\frac{(a+b)^2+(a-b)^2}{(a-b)(a+b)}\\right] \\cdot\\left[\\frac{(a-b)(a+b)}{(a+b)^2-(a-b)^2}\\right]=} \\\\\n& \\frac{a^2+2 a b+b^2+a^2-2 a b+b^2}{a^2+2 a b+a^2-a^2+2 a b-b^2}=\\frac{2 a^2+2 b^2}{4 a b}=\\frac{a^2+b^2}{2 a b}\n\\end{aligned}\n\\]\n\n\\[\\begin{aligned}\n&\\begin{aligned}\n& 6 \\frac{3 x-4}{2}-\\frac{6 x-5}{8}=\\frac{3 x-1}{16} ; \\frac{8(3 x-4)}{8 \\cdot 2}-\\frac{2(6 x-5)}{2 \\cdot 8}=\\frac{3 x-1}{16} \\\\\n& 24-32-12 x+10=3 x-1 \\\\\n& 9 x=21 \\quad x=7 / 3\n\\end{aligned}\\\\\n\n&\\begin{aligned}\n& 2 x-5 y=24 \\\\\n& \\alpha=17 \\\\\n& 7(17)-5 y=24 \\\\\n& y=19 \\\\\n& 119-5 y=24:-5 y=-95: \\quad y=19 \\\\\n&\n\\end{aligned}\n\\end{aligned}\\]"
  },
  {
    "objectID": "math.html#ê¸°í•˜",
    "href": "math.html#ê¸°í•˜",
    "title": "chatGPT",
    "section": "\n3.4 ê¸°í•˜",
    "text": "3.4 ê¸°í•˜\n\nProve that the sum of the three angles of a plano triangle equals two right angles.\nProve that the diagonal of a parallelogram divides it into two equat triangles.\nProve that the area of a trapezoid is equal to the half sum of its parallel bases multiplied by its altitude.\nProve that the side of a regular hexagon inscribed in a circle is equal to its radius.\nThe radius of a circle equals 10 . Find its area.\nThe perpendicular dropped from the vertex of the right angle upon the hypothenuse divides it into two segments of 9 and 16 feet respectively. Find the lengths of the perpendicular, and the two legs of the triangle.\nDefine similar polygons. To what are their areas proportional?\n\n\n3.4.1 í•´ë‹µ\nGeometry 1. Live triangle \\(A B C\\) construct a kine through \\(A\\) parallel to side \\(\\overline{B C}\\) angles \\(x, y\\) and a are formed at vertex \\(A\\) (1) The sum of all angles on one side of a line equal \\(180^{\\circ}\\) at a front; \\(y+a+y=180\\) A right angle contains \\(90^{\\circ}\\) \\(\\overline{A B}\\) and \\(\\overline{A C}\\) an transcuersals intersecting the two parallel hires: \\(\\overline{B C}\\) and line tromp \\(A\\) \\(\\angle A B C=\\angle x\\) and \\(\\angle A C B=\\angle y\\) because alternate interior angles of parallel hines are equal. (1) Since \\(x+a+y=180^{\\circ}\\) by subshticher \\(\\angle A B C+a+\\angle A C B=180^{\\circ}=\\) two rigitangles\n\nTwin parallelogram \\(A B C D\\) with diagonal \\(B D\\) \\(\\overline{A D} \\| \\overline{B C}\\) and \\(\\overline{A B} \\| \\overline{D C}\\) becanec oppose sides of a parallegran are parallel \\(\\angle x=\\angle d\\) and \\(\\angle b=\\angle y\\) because alternate interior angles formed by 2 parallel bice cat by a transversal are = \\(\\overline{B D}\\) is a side of both brixingles â€œis congunchatâ€ Herfou, \\(\\triangle A B D \\cong \\triangle \\triangle D B\\) by the property If 2 angles of one triangle and the included vide are congruent to 2 angles and the included side of another brangle, the 2 triangles are Congruent (equal\nTrapezoid \\(A B C D\\) has basen of \\(b_1(\\overline{A B})+b_2(\\overline{D C})\\) and altude of \\(h\\). construnt a hine threr \\(C\\) parallel to side DA Eutend \\(\\overline{A B}\\) through, \\(B\\), trentersed the line chrough \\(C\\) at pout F AFCDis a parallelogram weth area \\(h b_2\\) and side \\(\\overline{D C}=\\overline{A F}\\) becamee appasite sedu f a perallebgeren are equd The alttiede of \\(\\triangle C B F=h\\) Areed \\(\\triangle C B F-\\frac{1}{2} \\overline{B F} \\cdot h\\) \\(\\widehat{B F}=\\overline{A F}-b_1=b_2-b_1 ;\\); lentictite \\(b_2-b_1\\) fo \\(\\overline{B F}\\) Aree of \\(\\triangle C B F=\\frac{1}{2}\\left(b_2-b_1\\right) \\cdot h\\) Area of trapegaid \\(A B C D=\\) Area of paullingram \\(A F C D\\)-aread \\(\\triangle C B F\\) \\(\\begin{aligned} & =b_2 \\cdot h \\quad-\\frac{1}{2}\\left(b_2-b_1\\right) h= \\\\ b_2 \\cdot h-\\frac{1}{2} b_2 h+\\frac{1}{2} b_1 h & =\\frac{1}{2} h\\left(b_1+b_2\\right) \\\\ \\therefore \\text { Area of trappoid = } & \\frac{1}{2} \\text { susan of paratled bacere meulhpths by itallehde }\\end{aligned}\\)"
  },
  {
    "objectID": "math.html#ë²ˆ-ë¬¸ì œ",
    "href": "math.html#ë²ˆ-ë¬¸ì œ",
    "title": "chatGPT",
    "section": "\n2.1 2ë²ˆ ë¬¸ì œ",
    "text": "2.1 2ë²ˆ ë¬¸ì œ\n\ní•¨ìˆ˜ \\(f(x)=x^3+3 x^2+x-1\\) ì— ëŒ€í•˜ì—¬ \\(f^{\\prime}(1)\\) ì˜ ê°’ì€?\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\nsolve_math_02 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. í•¨ìˆ˜ } f(x)=x^3+3 x^2+x-1 \\\\text { ì— ëŒ€í•˜ì—¬ } f^{\\\\prime}(1) \\\\text { ì˜ ê°’ì€? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#> \n#> \n#> f'(1)ì€ ë¯¸ë¶„ì„ í†µí•´ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n#> \n#> f'(x) = 3x^2 + 6x + 1\n#> \n#> f'(1) = 3(1)^2 + 6(1) + 1 = 10\n#> \n#> ë”°ë¼ì„œ f'(1) = 10ì´ë¼ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤. ì´ì— ë”°ë¥´ë©´ í•¨ìˆ˜ f(x) = x^3 + 3x^2 + x - 1ì— ëŒ€í•˜ì—¬ xê°€ 1ì¼ ë•Œì˜ ë¯¸ë¶„ê°’ f'(1)ì€ 10ì´ ë©ë‹ˆë‹¤."
  },
  {
    "objectID": "math.html#ë²ˆ-ë¬¸ì œ-1",
    "href": "math.html#ë²ˆ-ë¬¸ì œ-1",
    "title": "chatGPT",
    "section": "\n2.2 3ë²ˆ ë¬¸ì œ",
    "text": "2.2 3ë²ˆ ë¬¸ì œ\n\në“±ì°¨ìˆ˜ì—´ \\(\\left\\{a_n\\right\\}\\) ì— ëŒ€í•˜ì—¬ \\[\na_2=6, \\quad a_4+a_6=36\n\\] ì¼ ë•Œ, \\(a_{10}\\) ì˜ ê°’ì€?\n\n\nì½”ë“œsolve_math_03 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = 'ë“±ì°¨ìˆ˜ì—´ $\\left\\{a_n\\right\\}$ ì— ëŒ€í•˜ì—¬\n$$\na_2=6, \\quad a_4+a_6=36\n$$\nì¼ ë•Œ, $a_{10}$ ì˜ ê°’ì€?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\në“±ì°¨ìˆ˜ì—´ì˜ ì •ì˜ì— ë”°ë¼ \\(a_n = a_1 + (n-1)d\\) ì´ë¯€ë¡œ, \\(a_1\\) ê³¼ \\(d\\) ë¥¼ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]"
  },
  {
    "objectID": "math.html#ai-ì¶”ë¡ ",
    "href": "math.html#ai-ì¶”ë¡ ",
    "title": "chatGPT",
    "section": "\n3.2 AI ì¶”ë¡ ",
    "text": "3.2 AI ì¶”ë¡ \n1ë²ˆ ë¬¸ì œ\n\n\nBing AI\n\nSure! Letâ€™s first convert the mixed numbers to improper fractions. \\(3 \\frac{5}{9}\\) is equal to \\(\\frac{32}{9}\\) and \\(1 \\frac{7}{24}\\) is equal to \\(\\frac{31}{24}\\).  Now we can find the sum: \\(\\frac{32}{9} + \\frac{31}{24} = \\frac{(32)(8) + (31)(3)}{(9)(8)} = \\frac{256 + 93}{72} = \\frac{349}{72}\\).  The difference is: \\(\\frac{32}{9} - \\frac{31}{24} = \\frac{(32)(8) - (31)(3)}{(9)(8)} = \\frac{256 - 93}{72} = \\frac{163}{72}\\).  The product is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{31}{24}\\right) = \\dfrac{(32)(31)}{(9)(24)} = \\dfrac{992}{216}\\).  To divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\), we can multiply \\(3 \\frac{5}{9}\\) by the reciprocal of \\(1 \\frac{7}{24}\\). The reciprocal of \\(\\dfrac{31}{24}\\) is \\(\\dfrac{24}{31}\\).  So the quotient is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{24}{31}\\right) = \\dfrac{(32)(24)}{(9)(31)} = \\dfrac{768}{279}\\).\n\n\n\n\nOpenAI\nLetâ€™s first convert the mixed numbers into improper fractions: \\(3 \\frac{5}{9} = \\frac{3 \\times 9 + 5}{9} = \\frac{27 + 5}{9} = \\frac{32}{9}\\)\n\\(1 \\frac{7}{24} = \\frac{1 \\times 24 + 7}{24} = \\frac{24 + 7}{24} = \\frac{31}{24}\\)\nFind the sum, difference, product, and division of the two improper fractions: Sum:\n\\(\\frac{32}{9} + \\frac{31}{24} = \\frac{32 \\times 24}{9 \\times 24} + \\frac{31 \\times 9}{24 \\times 9} = \\frac{768}{216} + \\frac{279}{216} = \\frac{1047}{216}\\)\nDifference:\n\\(\\frac{32}{9} - \\frac{31}{24} = \\frac{32 \\times 24}{9 \\times 24} - \\frac{31 \\times 9}{24 \\times 9} = \\frac{768}{216} - \\frac{279}{216} = \\frac{489}{216}\\)\nProduct:\n\\(\\frac{32}{9} \\times \\frac{31}{24} = \\frac{32 \\times 31}{9 \\times 24} = \\frac{992}{216}\\)\nDivision:\n\\(\\frac{32}{9} \\div \\frac{31}{24} = \\frac{32}{9} \\times \\frac{24}{31} = \\frac{32 \\times 24}{9 \\times 31} = \\frac{768}{279}\\)\nThe corrected results are:\nSum: \\(\\frac{1047}{216}\\) Difference: \\(\\frac{489}{216}\\) Product: \\(\\frac{992}{216}\\) Division: \\(\\frac{768}{279}\\)\n\n\n\n2ë²ˆ ë¬¸ì œ\n\n\nBing AI\nSure! To multiply 73 thousandths by 19 hundredths, you can convert them to decimals first. 73 thousandths is equivalent to 0.073 and 19 hundredths is equivalent to 0.19. Multiplying these two numbers gives us a result of 0.01387.\n\n\n\n\nOpenAI\nTo multiply decimals, first multiply the numbers as if they were whole numbers, and then count the total number of decimal places in both numbers.\n73 thousandths can be written as 0.073, and 19 hundredths can be written as 0.19.\nNow, multiply the numbers as if they were whole numbers:\n73 * 19 = 1387\nThere are a total of 5 decimal places in both numbers combined (3 decimal places in 0.073 and 2 decimal places in 0.19). So, we need to place the decimal point 5 places from the right in the product:\n0.001387\nTherefore, the product of 73 thousandths and 19 hundredths is 0.001387.\n\n\n\n3ë²ˆ ë¬¸ì œ\n\n\nBing AI\nSure! Hereâ€™s a step-by-step guide on how to divide 2880 by 0.0036:\n\nWrite the problem as a long division problem: 2880 Ã· 0.0036\nMove the decimal point in the divisor (0.0036) to the right until it becomes a whole number (36). Move the decimal point in the dividend (2880) the same number of places to the right: 28800000 Ã· 36\nPerform long division to get a result of 800000.\n\n\n\n\nOpenAI\nTo divide 2880 by 0.0036, you can first divide both numbers by the same power of 10 to make the divisor a whole number. In this case, since the divisor has four decimal places, you can multiply both numbers by 10^4:\n2880 * 10^4 = 28800000 0.0036 * 10^4 = 36\nNow, divide 28800000 by 36:\n28800000 Ã· 36 = 800000\nSo, 2880 divided by 0.0036 is 800000.\n\n\n\n4ë²ˆ ë¬¸ì œ\n\n\nBing AI\nSure! To find the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\), you can first convert the fractions to decimals. \\(\\frac{1}{5}\\) is equivalent to 0.2 and \\(\\frac{8}{4}\\) is equivalent to 2. Adding these two numbers gives us a result of 2.2.\n\n\n\n\nOpenAI\nFirst, letâ€™s simplify each fraction and convert them to decimals:\n\\(\\frac{1}{5}\\) as a decimal is 0.2.\n\\(\\frac{8}{4}\\) can be simplified to \\(\\frac{2}{1}\\), which as a decimal is 2.\nNow, add the two decimal values:\n\\(0.2 + 2 = 2.2\\)\nSo, the value of \\(\\frac{1}{5}+\\frac{8}{4}\\) in decimals is 2.2.\n\n\n\n5ë²ˆ ë¬¸ì œ\n\n\nBing AI\nIâ€™m sorry but your question is a bit unclear. Could you please clarify what you mean by â€œwhat part of the month of August is \\(\\frac{7}{18}\\) minutesâ€? Are you asking for a specific date and time in August that corresponds to \\(\\frac{7}{18}\\) minutes?\n\n\n\n\nOpenAI\nTo determine what part of the month of August is \\(\\frac{7}{18}\\) minutes, we first need to know the total number of minutes in the month of August.\nAugust has 31 days, and each day has 24 hours with 60 minutes per hour. Therefore, there are:\n\\(31 \\times 24 \\times 60 = 44640\\) minutes in August.\nNow, we can find what part of the month of August is \\(\\frac{7}{18}\\) minutes by dividing \\(\\frac{7}{18}\\) by the total number of minutes:\n\\(\\frac{7}{18} \\div 44640 = \\frac{7}{18 \\times 44640}\\)\nNow, simplify the fraction:\n\\(\\frac{7}{802080}\\)\nSo, \\(\\frac{7}{18}\\) minutes is \\(\\frac{7}{802080}\\) of the month of August.\n\n\n\n6ë²ˆ ë¬¸ì œ\n\n\nBing AI\nSure! A full circumference is equivalent to 360 degrees. To find the number of degrees in 0.01 of a circumference, you can multiply 360 by 0.01 to get a result of 3.6 degrees.\n\n\n\n\nOpenAI\nTo find out how many degrees are in 0.01 of a circumference, you need to consider that a full circumference corresponds to 360 degrees.\nTo find the number of degrees in 0.01 of a circumference, multiply 360 degrees by 0.01:\n360Â° Ã— 0.01 = 3.6Â°\nSo, there are 3.6 degrees in 0.01 of a circumference.\n\n\n\n7ë²ˆ ë¬¸ì œ\n\n\nBing AI\nSure! Letâ€™s say the ownerâ€™s cost was \\(x\\). If they lost \\(3 \\frac{1}{2}\\) per cent on the sale, then their selling price was \\(100% - 3 \\frac{1}{2}% = 96.5%\\) of their cost. So we can write the equation: \\(0.965x = 5790\\). Solving for \\(x\\), we find that the ownerâ€™s cost was $ \\(5994.81\\).\n\n\n\n\nOpenAI\nTo find the original cost of the house and lot, we set up and solve the equation as follows:\nLet the cost of the house and lot be denoted by C. The owner lost \\(3\\frac{1}{2}%\\) on the sale, which means they sold it for \\(100% - 3\\frac{1}{2}%\\) of its original value. First, convert \\(3\\frac{1}{2}%\\) to a decimal:\n\\(3\\frac{1}{2}% = 3.5%\\)\nNow, subtract this percentage from \\(100%\\) to find the percentage of the cost at which the house was sold:\n\\(100% - 3.5% = 96.5%\\)\nNow, we know that \\(96.5%\\) of the cost is equal to the selling price, which is $\\(5,790\\). We can write this as an equation:\n$0.965C = \\(5,790\\)\nNow, we can find the cost (C) by dividing both sides of the equation by 0.965:\n$C = $\n$C \\(5,995.85\\)\nSo, the original cost of the house and lot was approximately $\\(5,995.85\\). In LaTeX format, the solution is as follows:\nLet the cost be denoted by \\(C\\). The equation representing the loss is: [0.965C = 5790]\nTo find the cost, divide both sides by 0.965: [C = ]\nTherefore, the original cost of the house and lot was approximately $5,995.85."
  },
  {
    "objectID": "math.html#ë²ˆ-ë¬¸ì œ-7",
    "href": "math.html#ë²ˆ-ë¬¸ì œ-7",
    "title": "chatGPT",
    "section": "\n4.1 2ë²ˆ ë¬¸ì œ",
    "text": "4.1 2ë²ˆ ë¬¸ì œ\n\ní•¨ìˆ˜ \\(f(x)=x^3+3 x^2+x-1\\) ì— ëŒ€í•˜ì—¬ \\(f^{\\prime}(1)\\) ì˜ ê°’ì€?\n\n\n\n\n\n\n\nGPT-3.5\nBing AI\nchatGPT GPT-4\nchatGPT í”ŒëŸ¬ê·¸ì¸\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\nsolve_math_02 &lt;- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. í•¨ìˆ˜ } f(x)=x^3+3 x^2+x-1 \\\\text { ì— ëŒ€í•˜ì—¬ } f^{\\\\prime}(1) \\\\text { ì˜ ê°’ì€? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPENAI_API_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#&gt; \n#&gt; \n#&gt; f'(1)ì€ í•¨ìˆ˜ f(x)ì˜ ë¯¸ë¶„ê°’ì´ë¯€ë¡œ \n#&gt; \n#&gt; f'(1) = 3x^2 + 6x + 1 = 8\n#&gt; \n#&gt; ë”°ë¼ì„œ f'(1)ì˜ ê°’ì€ 8ì…ë‹ˆë‹¤. \n#&gt; \n#&gt; ê·¸ ì´ìœ ëŠ” í•¨ìˆ˜ f'(x)ëŠ” xê°’ì— ë”°ë¼ ë³€í•˜ëŠ” ê°’ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ xê°’ì´ 1ì¼ ë•Œ f'(1)ì˜ ê°’ì€ 3Â·12 + 6Â·1 + 1 = 8 ì…ë‹ˆë‹¤.\n\n\n\n\nSure! The derivative of a function \\(f(x)\\) is denoted by \\(fâ€™(x)\\) and represents the rate of change of the function at a given point. To find the value of \\(fâ€™(1)\\) for the function \\(f(x)=x^3+3 x^2+x-1\\), we first need to find its derivative.\nThe derivative of \\(x^3\\) is \\(3x^2\\), the derivative of \\(3x^2\\) is \\(6x\\), and the derivative of \\(x\\) is 1. The derivative of a constant term like -1 is 0. So, the derivative of the function \\(f(x)=x^3+3 x^2+x-1\\) is:\n\\[fâ€™(x) = 3x^2 + 6x + 1\\]\nTo find the value of \\(fâ€™(1)\\), we can substitute x=1 into this equation:\n\\[fâ€™(1) = 3(1)^2 + 6(1) + 1 = 10\\]\nSo, the value of \\(fâ€™(1)\\) for the function \\(f(x)=x^3+3 x^2+x-1\\) is 10.\n\n\ní•¨ìˆ˜ \\(f(x)=x^3+3x^2+x-1\\)ì˜ ë„í•¨ìˆ˜ë¥¼ êµ¬í•˜ê³ , \\(x=1\\)ì¼ ë•Œì˜ ê°’ì„ êµ¬í•˜ê² ìŠµë‹ˆë‹¤.\n\\(f(x)\\)ì˜ ë„í•¨ìˆ˜ëŠ” \\(f'(x)\\)ë¡œ í‘œì‹œë˜ë©°, ê° í•­ì— ëŒ€í•œ ë¯¸ë¶„ì„ ì ìš©í•©ë‹ˆë‹¤:\n\\(f'(x) = \\frac{d}{dx}(x^3) + \\frac{d}{dx}(3x^2) + \\frac{d}{dx}(x) - \\frac{d}{dx}(1)\\)\nê° í•­ì— ëŒ€í•œ ë¯¸ë¶„ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\\(\\frac{d}{dx}(x^3) = 3x^2\\)\n\\(\\frac{d}{dx}(3x^2) = 6x\\)\n\\(\\frac{d}{dx}(x) = 1\\)\n\\(\\frac{d}{dx}(1) = 0\\)\nì´ì œ ë„í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\\(f'(x) = 3x^2 + 6x + 1\\)\nì´ì œ \\(f'(1)\\)ì„ êµ¬í•©ë‹ˆë‹¤:\n\\(f'(1) = 3(1)^2 + 6(1) + 1 = 3 + 6 + 1 = 10\\)\në”°ë¼ì„œ, \\(f^{\\prime}(1)\\)ì˜ ê°’ì€ 10ì…ë‹ˆë‹¤.\n\n\ní™˜ì˜í™˜ê°ì„ ì—†ì•¤ ìˆ˜í•™ ì—”ì§„ ìš¸í”„ë¨(Woolfram)ì„ ì‚¬ìš©í•´ì„œ ë¬¸ì œë¥¼ í’€ì–´ë³´ì\ní•¨ìˆ˜ \\(f(x)=x^3+3 x^2+x-1\\) ì˜ ë„í•¨ìˆ˜ \\(f^{\\prime}(x)\\) ë¥¼ êµ¬í•˜ë©´, \\(f^{\\prime}(x)=3 x^2+6 x+1\\) ì´ ë©ë‹ˆ ë‹¤. ì´ì œ \\(f^{\\prime}(1)\\) ì˜ ê°’ì„ êµ¬í•˜ë©´ ë©ë‹ˆë‹¤. Wolfram Alphaë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤. Used Wolfram í•¨ìˆ˜ \\(f^{\\prime}(x)=3 x^2+6 x+1\\) ì— \\(x=1\\) ì„ ëŒ€ì…í•˜ë©´, \\(f^{\\prime}(1)=10\\) ì´ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ, \\(f^{\\prime}(1)=10\\) ì…ë‹ˆë‹¤. ì´ëŠ” í•¨ìˆ˜ \\(f(x)=x^3+3 x^2+x-1\\) ì˜ \\(x=1\\) ì—ì„œì˜ ê¸°ìš¸ê¸°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\\[\\begin{align*}\nf(x) &= x^3 + 3x^2 + x - 1 \\\\\nf'(x) &= \\frac{d}{dx}(x^3 + 3x^2 + x - 1) \\\\\n&= 3x^2 + 6x + 1 \\\\\nf'(1) &= 3(1)^2 + 6(1) + 1 \\\\\n&= 10\n\\end{align*}\\]"
  },
  {
    "objectID": "math.html#ë²ˆ-ë¬¸ì œ-8",
    "href": "math.html#ë²ˆ-ë¬¸ì œ-8",
    "title": "chatGPT",
    "section": "\n4.2 3ë²ˆ ë¬¸ì œ",
    "text": "4.2 3ë²ˆ ë¬¸ì œ\n\në“±ì°¨ìˆ˜ì—´ \\(\\left\\{a_n\\right\\}\\) ì— ëŒ€í•˜ì—¬ \\[\na_2=6, \\quad a_4+a_6=36\n\\] ì¼ ë•Œ, \\(a_{10}\\) ì˜ ê°’ì€?\n\n\n\n\n\n\n\nGPT-3.5\në¹™ AI\nOpenAI GPT-4\nchatGPT í”ŒëŸ¬ê·¸ì¸\n\n\n\n\nì½”ë“œsolve_math_03 &lt;- create_completion(\n    model=\"text-davinci-003\",\n    prompt = 'ë“±ì°¨ìˆ˜ì—´ $\\left\\{a_n\\right\\}$ ì— ëŒ€í•˜ì—¬ $$ a_2=6, \\quad a_4+a_6=36 $$ ì¼ ë•Œ, $a_{10}$ ì˜ ê°’ì€?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\në“±ì°¨ìˆ˜ì—´ì˜ ì •ì˜ì— ë”°ë¼ \\(a_n = a_1 + (n-1)d\\) ì´ë¯€ë¡œ, \\(a_1\\) ê³¼ \\(d\\) ë¥¼ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]\n\n\nSure! In an arithmetic sequence \\(a_n\\), the difference between consecutive terms is constant. Letâ€™s denote this common difference by \\(d\\). Then we have:\n\\[a_3 = a_2 + d = 6 + d\\] \\[a_4 = a_3 + d = 6 + 2d\\] \\[a_5 = a_4 + d = 6 + 3d\\] \\[a_6 = a_5 + d = 6 + 4d\\]\nWe are given that \\(a_4+a_6=36\\), so substituting the expressions for \\(a_4\\) and \\(a_6\\) from above, we get:\n\\[(6+2d)+(6+4d)=36 \\Rightarrow 12+6d=36 \\Rightarrow d=4\\]\nNow that we know the common difference \\(d\\), we can find the value of \\(a_{10}\\):\n\\[a_{10} = a_{9}+d=a_{8}+2d=\\cdots=a_{2}+8d=6+8(4)=38\\]\nSo, the value of \\(a_{10}\\) for this arithmetic sequence is 38.\n\n\në“±ì°¨ìˆ˜ì—´ \\(a_n\\)ì—ì„œ ì¼ë°˜ì ì¸ í•­ì€ \\(a_n = a_1 + (n-1)d\\)ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ \\(a_1\\)ì€ ì²« ë²ˆì§¸ í•­ì´ê³  \\(d\\)ëŠ” ê³µì°¨ì…ë‹ˆë‹¤.\në¬¸ì œì—ì„œ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ë°©ì •ì‹ì„ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\\[a_2 = a_1 + (2-1)d = a_1 + d = 6\\] \\[a_4 + a_6 = (a_1 + 3d) + (a_1 + 5d) = 36\\]\nì²« ë²ˆì§¸ ë°©ì •ì‹ì—ì„œ \\(d\\)ì— ëŒ€í•´ í’€ë©´ \\(d = 6 - a_1\\)ì…ë‹ˆë‹¤. ì´ê²ƒì„ ë‘ ë²ˆì§¸ ë°©ì •ì‹ì— ëŒ€ì…í•©ë‹ˆë‹¤:\n\\[(a_1 + 3(6 - a_1)) + (a_1 + 5(6 - a_1)) = 36\\]\nì´ì œ \\(a_1\\)ì— ëŒ€í•´ í’€ë©´ ë©ë‹ˆë‹¤:\n\\[2a_1 - 3a_1 + 18 - 5a_1 + 30 = 36\\] \\[-6a_1 = -12\\] \\[a_1 = 2\\]\nì´ì œ \\(a_1 = 2\\)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µì°¨ \\(d\\)ë¥¼ ì°¾ìŠµë‹ˆë‹¤:\n\\[d = 6 - a_1 = 6 - 2 = 4\\]\në”°ë¼ì„œ ë“±ì°¨ìˆ˜ì—´ì˜ ì²« ë²ˆì§¸ í•­ì€ \\(a_1 = 2\\)ì´ê³  ê³µì°¨ëŠ” \\(d = 4\\)ì…ë‹ˆë‹¤. ì´ì œ \\(a_{10}\\)ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\\[a_{10} = a_1 + (10-1)d = 2 + 9 \\times 4 = 2 + 36 = 38\\]\në”°ë¼ì„œ, \\(a_{10}\\)ì˜ ê°’ì€ 38ì…ë‹ˆë‹¤.\n\n\në“±ì°¨ìˆ˜ì—´ \\(\\left\\{a_n\\right\\}\\) ì—ì„œ, ì¼ë°˜ì ì¸ í•­ì€ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤: \\(a_n=a_1+(n-1) d\\), ì—¬ê¸°ì„œ \\(d\\) ëŠ” ê³µì°¨ì…ë‹ˆë‹¤.\nìš°ë¦¬ëŠ” \\(a_2=6\\) ì´ë¼ëŠ” ê²ƒì„ ì•Œê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, \\(a_2=a_1+d=6\\) ì…ë‹ˆë‹¤.\në˜í•œ, \\(a_4+a_6=36\\) ì´ë¼ëŠ” ê²ƒì„ ì•Œê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì¼ë°˜ì ì¸ í•­ì˜ í˜•íƒœë¡œ ë°”ê¾¸ë©´, \\(a_1+\\) \\(3 d+a_1+5 d=36\\) ì´ ë©ë‹ˆë‹¤. ì´ë¥¼ ì •ë¦¬í•˜ë©´, \\(2 a_1+8 d=36\\) ì…ë‹ˆë‹¤.\nì´ì œ ë‘ ê°œì˜ ë°©ì •ì‹ì„ í’€ì–´ \\(a_1\\) ê³¼ \\(d\\) ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Wolfram Alphaë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤.\nUsed Wolfram\nìœ„ì˜ ê³„ì‚° ê²°ê³¼ì— ë”°ë¥´ë©´, \\(a_1=2\\) ê·¸ë¦¬ê³  \\(d=4\\) ì…ë‹ˆë‹¤.\nì´ì œ ì´ ê°’ì„ ì‚¬ìš©í•˜ì—¬ \\(a_{10}\\) ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ í•­ì˜ í˜•íƒœì¸ \\(a_n=a_1+(n-\\) 1) \\(d\\) ì— ëŒ€ì…í•˜ë©´, \\(a_{10}=a_1+9 d\\) ì…ë‹ˆë‹¤. Wolfram Alphaë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆ ë‹¤.\nUsed Wolfram\në”°ë¼ì„œ, \\(a_{10}=2+9 \\times 4=38\\) ì…ë‹ˆë‹¤.\nì¦‰, ì£¼ì–´ì§„ ë“±ì°¨ìˆ˜ì—´ \\(\\left\\{a_n\\right\\}\\) ì—ì„œ \\(a_{10}\\) ì˜ ê°’ì€ 38 ì…ë‹ˆë‹¤."
  },
  {
    "objectID": "gpt4_performance.html",
    "href": "gpt4_performance.html",
    "title": "chatGPT",
    "section": "",
    "text": "arXiv GPT-4 Technical Report ë³´ê³ ì„œë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ PDF ë³´ê³ ì„œì—ì„œ GPT-4 ì„±ëŠ¥ì„ í‰ê°€í•´ë³´ì. (OpenAI, 2023)\n\nPDF ë¬¸ì„œë¥¼ Convert2Docx íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•˜ì—¬ ì›Œë“œíŒŒì¼ë¡œ ë³€í™˜ì‹œí‚¨ë‹¤. í˜ì´ì§€ê°€ ë§ì•„ ì œë²• ì‹œê°„ì´ ì†Œìš”ëœë‹¤.\n\nì½”ë“œlibrary(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")\n\n\n\ndocxtractr íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  docx_extract_tbl() í•¨ìˆ˜ë¡œ PDF íŒŒì¼ì— ë‹´ê¸´ í‘œë¥¼ ì¶”ì¶œí•œë‹¤.\n\nì½”ë“œlibrary(docxtractr)\n\ngpt_docx &lt;- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 &lt;- docx_extract_tbl(gpt_docx, 3) %&gt;% \n    janitor::clean_names()\ntbl_01\n#&gt; # A tibble: 34 Ã— 4\n#&gt;    exam                                           gpt_4  gpt_4_no_vision gpt_3_5\n#&gt;    &lt;chr&gt;                                          &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;  \n#&gt;  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 /â€¦ 298 / 400 (~90â€¦ 213 / â€¦\n#&gt;  2 LSAT                                           163 (â€¦ 161 (~83rd)     149 (~â€¦\n#&gt;  3 SAT Evidence-Based Reading & Writing           710 /â€¦ 710 / 800 (~93â€¦ 670 / â€¦\n#&gt;  4 SAT Math                                       700 /â€¦ 690 / 800 (~89â€¦ 590 / â€¦\n#&gt;  5 Graduate Record Examination (GRE) Quantitative 163 /â€¦ 157 / 170 (~62â€¦ 147 / â€¦\n#&gt;  6 Graduate Record Examination (GRE) Verbal       169 /â€¦ 165 / 170 (~96â€¦ 154 / â€¦\n#&gt;  7 Graduate Record Examination (GRE) Writing      4 / 6â€¦ 4 / 6 (~54th)   4 / 6 â€¦\n#&gt;  8 USABO Semifinal Exam 2020                      87 / â€¦ 87 / 150 (99thâ€¦ 43 / 1â€¦\n#&gt;  9 USNCO Local Section Exam 2022                  36 / â€¦ 38 / 60         24 / 60\n#&gt; 10 Medical Knowledge Self-Assessment Program      75 %   75 %            53 %   \n#&gt; # â„¹ 24 more rows"
  },
  {
    "objectID": "gpt4_performance.html#pdf-ì›Œë“œ",
    "href": "gpt4_performance.html#pdf-ì›Œë“œ",
    "title": "chatGPT",
    "section": "",
    "text": "PDF ë¬¸ì„œë¥¼ Convert2Docx íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•˜ì—¬ ì›Œë“œíŒŒì¼ë¡œ ë³€í™˜ì‹œí‚¨ë‹¤. í˜ì´ì§€ê°€ ë§ì•„ ì œë²• ì‹œê°„ì´ ì†Œìš”ëœë‹¤.\n\nì½”ë“œlibrary(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")"
  },
  {
    "objectID": "gpt4_performance.html#ì›Œë“œ-í‘œì¶”ì¶œ",
    "href": "gpt4_performance.html#ì›Œë“œ-í‘œì¶”ì¶œ",
    "title": "chatGPT",
    "section": "",
    "text": "docxtractr íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  docx_extract_tbl() í•¨ìˆ˜ë¡œ PDF íŒŒì¼ì— ë‹´ê¸´ í‘œë¥¼ ì¶”ì¶œí•œë‹¤.\n\nì½”ë“œlibrary(docxtractr)\n\ngpt_docx &lt;- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 &lt;- docx_extract_tbl(gpt_docx, 3) %&gt;% \n    janitor::clean_names()\ntbl_01\n#&gt; # A tibble: 34 Ã— 4\n#&gt;    exam                                           gpt_4  gpt_4_no_vision gpt_3_5\n#&gt;    &lt;chr&gt;                                          &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;  \n#&gt;  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 /â€¦ 298 / 400 (~90â€¦ 213 / â€¦\n#&gt;  2 LSAT                                           163 (â€¦ 161 (~83rd)     149 (~â€¦\n#&gt;  3 SAT Evidence-Based Reading & Writing           710 /â€¦ 710 / 800 (~93â€¦ 670 / â€¦\n#&gt;  4 SAT Math                                       700 /â€¦ 690 / 800 (~89â€¦ 590 / â€¦\n#&gt;  5 Graduate Record Examination (GRE) Quantitative 163 /â€¦ 157 / 170 (~62â€¦ 147 / â€¦\n#&gt;  6 Graduate Record Examination (GRE) Verbal       169 /â€¦ 165 / 170 (~96â€¦ 154 / â€¦\n#&gt;  7 Graduate Record Examination (GRE) Writing      4 / 6â€¦ 4 / 6 (~54th)   4 / 6 â€¦\n#&gt;  8 USABO Semifinal Exam 2020                      87 / â€¦ 87 / 150 (99thâ€¦ 43 / 1â€¦\n#&gt;  9 USNCO Local Section Exam 2022                  36 / â€¦ 38 / 60         24 / 60\n#&gt; 10 Medical Knowledge Self-Assessment Program      75 %   75 %            53 %   \n#&gt; # â„¹ 24 more rows"
  },
  {
    "objectID": "calculator.html",
    "href": "calculator.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 CLI ê³„ì‚°ê¸°\nchatGPTì— ì§€ì‹œëª…ë ¹ì–´ë¡œ ê³„ì‚°ê¸° í”„ë¡œê·¸ë¨ì„ íŒŒì´ì¬ ì–¸ì–´ë¡œ ì‘ì„±í•˜ë¼ëŠ” í•˜ëª…ì„ ë‚´ë¦°ë‹¤. ê³„ì‚°ê¸°ë¥¼ ë™ì‘ì‹œí‚¤ëŠ” ë°©ì‹ë„ ì•Œë ¤ë‹¬ë¼ëŠ” í•˜ëª…ë„ ì´ì–´ì„œ ë‚´ë¦°ë‹¤.\n\n\nì§€ì‹œëª…ë ¹ì–´\nì†ŒìŠ¤ì½”ë“œ\nâ†’\nì‹¤í–‰ ì§€ì‹œëª…ë ¹ì–´\nì‹¤í–‰ ì‚¬ë¡€\n\n\n\n\n\n\n\n\n\nwrite python code of calculator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nì½”ë“œ# Simple calculator program\n\n# Function to add two numbers\ndef add(x, y):\n    return x + y\n\n# Function to subtract two numbers\ndef subtract(x, y):\n    return x - y\n\n# Function to multiply two numbers\ndef multiply(x, y):\n    return x * y\n\n# Function to divide two numbers\ndef divide(x, y):\n    return x / y\n\n# Display menu\nprint(\"Select operation.\")\nprint(\"1. Add\")\nprint(\"2. Subtract\")\nprint(\"3. Multiply\")\nprint(\"4. Divide\")\n\n# Take input from the user\nchoice = input(\"Enter choice (1/2/3/4): \")\n\nnum1 = float(input(\"Enter first number: \"))\nnum2 = float(input(\"Enter second number: \"))\n\n# Perform operation based on user's choice\nif choice == '1':\n    print(num1, \"+\", num2, \"=\", add(num1, num2))\n\nelif choice == '2':\n    print(num1, \"-\", num2, \"=\", subtract(num1, num2))\n\nelif choice == '3':\n    print(num1, \"*\", num2, \"=\", multiply(num1, num2))\n\nelif choice == '4':\n    print(num1, \"/\", num2, \"=\", divide(num1, num2))\n\nelse:\n    print(\"Invalid input\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nhow to run this python code\n\n\n\n\n\nPython ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ì‹œìŠ¤í…œì— Pythonì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ì— ë”°ë¼ ê°„ë‹¨í•œ ê³„ì‚°ê¸°ë¥¼ ìœ„í•œ Python ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\në©”ëª¨ì¥ì´ë‚˜ ì„œë¸Œë¼ì¸ í…ìŠ¤íŠ¸ì™€ ê°™ì€ í…ìŠ¤íŠ¸ í¸ì§‘ê¸°ë¥¼ ì—´ê³  Python ì½”ë“œë¥¼ ìƒˆ íŒŒì¼ì— ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤.\níŒŒì¼ í™•ì¥ëª…ì„ .pyë¡œ ì§€ì •í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤(ì˜ˆ: calculator.py).\ní„°ë¯¸ë„ ë˜ëŠ” ëª…ë ¹ í”„ë¡¬í”„íŠ¸ ì°½ì„ ì—½ë‹ˆë‹¤.\n\ncd ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤(ì˜ˆ: cd Documents\\Python).\n\npython calculator.pyë¥¼ ì…ë ¥í•˜ê³  Enter í‚¤ë¥¼ ëˆŒëŸ¬ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n\nê·¸ëŸ¬ë©´ í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ê³  ë©”ë‰´ê°€ í‘œì‹œë˜ë©° ì‚¬ìš©ìì—ê²Œ ì›í•˜ëŠ” ì—°ì‚°ê³¼ ìˆ«ì ë‘ ê°œë¥¼ ì…ë ¥í•˜ë¼ëŠ” ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ í•„ìš”í•œ ì…ë ¥ì„ ì…ë ¥í•˜ë©´ í”„ë¡œê·¸ë¨ì´ í•´ë‹¹ ì‚°ìˆ  ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n\n\n\n\n\n\n\n\n\n\n\n\n\nì½”ë“œxfun::embed_file(\"code/calculator.py\", text = \"ê³„ì‚°ê¸° ì†ŒìŠ¤ì½”ë“œ ë‹¤ìš´ë¡œë“œ\")\n\nê³„ì‚°ê¸° ì†ŒìŠ¤ì½”ë“œ ë‹¤ìš´ë¡œë“œ\n\n\n\n2 GUI ê³„ì‚°ê¸°\nì´ë²ˆì—ëŠ” ê³„ì‚°ê¸°ì— GUIë¥¼ ì…í˜€ ì‚¬ìš©ìê°€ ì¢€ë” ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ë‹¤ì–‘í•œ GUI íŒ¨í‚¤ì§€ê°€ ìˆì§€ë§Œ ê·¸ì¤‘ì—ì„œ tkinter íŒ¨í‚¤ì§€ í•˜ë‚˜ë¥¼ ì„ ì •í•˜ì—¬ ê°œë°œì„ ì´ì–´ë‚˜ê°„ë‹¤. chatGPTì— ì§€ì‹œëª…ë ¹ì–´ë¡œ ê³„ì‚°ê¸° í”„ë¡œê·¸ë¨ì„ íŒŒì´ì¬ ì–¸ì–´ë¡œ ì‘ì„±í•˜ë¼ëŠ” í•˜ëª…ì„ ë‚´ë¦°ë‹¤. ê³„ì‚°ê¸°ë¥¼ ë™ì‘ì‹œí‚¤ëŠ” ë°©ì‹ë„ ì•Œë ¤ë‹¬ë¼ëŠ” í•˜ëª…ë„ ì´ì–´ì„œ ë‚´ë¦°ë‹¤.\n\n\nì§€ì‹œëª…ë ¹ì–´\nì†ŒìŠ¤ì½”ë“œ\nâ†’\nì‹¤í–‰ ì§€ì‹œëª…ë ¹ì–´\nì‹¤í–‰ ì‚¬ë¡€\n\n\n\n\n\n\n\n\n\nplease add gui with tkinter\n\n\n\n\n\nSure, here is an example of the same calculator program using the Tkinter library to create a graphical user interface (GUI):\nâ€¦\nIn this code, we first import the Tkinter library using the alias tk. Then we define four functions add(), subtract(), multiply(), and divide() that perform the corresponding arithmetic operations on the numbers entered by the user. Each function retrieves the input values from the Entry widgets using the get() method, performs the arithmetic operation, and updates the text of the Label widget to display the result.\nWe then create the main window using the Tk() constructor and set its title using the title() method. Next, we create two Label widgets and two Entry widgets to allow the user to enter the two numbers.\nWe also create four Button widgets, one for each arithmetic operation, and set their text and width. The command parameter is used to specify the function that should be called when the button is clicked.\nFinally, we create a Label widget to display the result of the arithmetic operation, and call the mainloop() method to start the event loop and display the GUI.\n\n\n\n\n\n\nì½”ë“œimport tkinter as tk\n\n# Function to perform addition\ndef add():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 + num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform subtraction\ndef subtract():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 - num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform multiplication\ndef multiply():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 * num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform division\ndef divide():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 / num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n    except ZeroDivisionError:\n        label_result.config(text=\"Cannot divide by zero\")\n\n# Create the main window\nwindow = tk.Tk()\nwindow.title(\"Simple Calculator\")\n\n# Create the number input fields\nlabel_num1 = tk.Label(window, text=\"Number 1:\")\nlabel_num1.pack()\nentry_num1 = tk.Entry(window)\nentry_num1.pack()\n\nlabel_num2 = tk.Label(window, text=\"Number 2:\")\nlabel_num2.pack()\nentry_num2 = tk.Entry(window)\nentry_num2.pack()\n\n# Create the operation buttons\nbutton_add = tk.Button(window, text=\"+\", width=10, command=add)\nbutton_add.pack()\n\nbutton_subtract = tk.Button(window, text=\"-\", width=10, command=subtract)\nbutton_subtract.pack()\n\nbutton_multiply = tk.Button(window, text=\"*\", width=10, command=multiply)\nbutton_multiply.pack()\n\nbutton_divide = tk.Button(window, text=\"/\", width=10, command=divide)\nbutton_divide.pack()\n\n# Create the result label\nlabel_result = tk.Label(window, text=\"Result: \")\nlabel_result.pack()\n\n# Run the main loop\nwindow.mainloop()\n\n\n\n\n\n\n\n\n\n\n\n\n\nhow to run this python code\n\n\n\n\n\nPython ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ì‹œìŠ¤í…œì— Pythonì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ì— ë”°ë¼ ê°„ë‹¨í•œ ê³„ì‚°ê¸°ë¥¼ ìœ„í•œ Python ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\në©”ëª¨ì¥ì´ë‚˜ ì„œë¸Œë¼ì¸ í…ìŠ¤íŠ¸ì™€ ê°™ì€ í…ìŠ¤íŠ¸ í¸ì§‘ê¸°ë¥¼ ì—´ê³  Python ì½”ë“œë¥¼ ìƒˆ íŒŒì¼ì— ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤.\níŒŒì¼ í™•ì¥ëª…ì„ .pyë¡œ ì§€ì •í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤(ì˜ˆ: calculator.py).\ní„°ë¯¸ë„ ë˜ëŠ” ëª…ë ¹ í”„ë¡¬í”„íŠ¸ ì°½ì„ ì—½ë‹ˆë‹¤.\n\ncd ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤(ì˜ˆ: cd Documents\\Python).\n\npython calculator.pyë¥¼ ì…ë ¥í•˜ê³  Enter í‚¤ë¥¼ ëˆŒëŸ¬ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n\nê·¸ëŸ¬ë©´ í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ê³  ë©”ë‰´ê°€ í‘œì‹œë˜ë©° ì‚¬ìš©ìì—ê²Œ ì›í•˜ëŠ” ì—°ì‚°ê³¼ ìˆ«ì ë‘ ê°œë¥¼ ì…ë ¥í•˜ë¼ëŠ” ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ í•„ìš”í•œ ì…ë ¥ì„ ì…ë ¥í•˜ë©´ í”„ë¡œê·¸ë¨ì´ í•´ë‹¹ ì‚°ìˆ  ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n\n\n\n\n\n\n\n\n\n\n\n\n\nì½”ë“œxfun::embed_file(\"code/calculator_gui.py\", text = \"ê³„ì‚°ê¸° ì†ŒìŠ¤ì½”ë“œ GUI ë²„ì „ ë‹¤ìš´ë¡œë“œ\")\n\nê³„ì‚°ê¸° ì†ŒìŠ¤ì½”ë“œ GUI ë²„ì „ ë‹¤ìš´ë¡œë“œ\n\n\n\n3 í…ŒìŠ¤íŠ¸\nê³„ì‚°ê¸° í”„ë¡œê·¸ë¨ì´ ì •ìƒë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì. ë§Œì•½ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ëª¨ë‘ ì •ìƒë™ì‘í•œë‹¤ë©´ ë¯¿ê³  í˜„ì—…ì—ì„œ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.\n\n\nì§€ì‹œëª…ë ¹ì–´\nì‹¤í–‰ê²°ê³¼\n\n\n\n\n\n\n\n\n\nfirst write python program for calculator and then test result from execution\n\n\n\n\n\nHereâ€™s the Python code for a simple calculator that supports addition, subtraction, multiplication, and division. Weâ€™ll create a separate file for the test cases, which will import and run the calculator functions.\nSave the following code as calculator.py:\nclass Calculator:\n    def add(self, a, b):\n        return a + b\n\n    def subtract(self, a, b):\n        return a - b\n\n    def multiply(self, a, b):\n        return a * b\n\n    def divide(self, a, b):\n        if b == 0:\n            raise ValueError(\"Cannot divide by zero\")\n        return a / b\nNow, create a new file named test_calculator.py and save the following code in it:\nfrom calculator import Calculator\n\ndef test_calculator():\n    calc = Calculator()\n\n    # Test addition\n    assert calc.add(2, 3) == 5, \"Test case 1 failed\"\n    assert calc.add(-2, 3) == 1, \"Test case 2 failed\"\n\n    # Test subtraction\n    assert calc.subtract(5, 3) == 2, \"Test case 3 failed\"\n    assert calc.subtract(0, -5) == 5, \"Test case 4 failed\"\n\n    # Test multiplication\n    assert calc.multiply(3, 4) == 12, \"Test case 5 failed\"\n    assert calc.multiply(-2, 5) == -10, \"Test case 6 failed\"\n\n    # Test division\n    assert calc.divide(10, 2) == 5, \"Test case 7 failed\"\n    assert calc.divide(-10, 5) == -2, \"Test case 8 failed\"\n\n    # Test division by zero\n    try:\n        calc.divide(10, 0)\n    except ValueError as e:\n        assert str(e) == \"Cannot divide by zero\", \"Test case 9 failed\"\n\n    print(\"All test cases passed\")\n\nif __name__ == \"__main__\":\n    test_calculator()\nTo execute the test cases, open a terminal or command prompt and navigate to the directory containing both calculator.py and test_calculator.py. Then run the following command:\npython test_calculator.py\nIf all test cases pass, youâ€™ll see â€œAll test cases passedâ€ printed on the console.\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 .exe ë°°í¬\nCLIë¥¼ í†µí•´ ê¸°ëŠ¥ì„ ê²€ì¦í•œ í›„ GUIë¡œ ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì˜€ë‹¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë°°í¬ë¥¼ í•œë‹¤. ë‹¤ì–‘í•œ ë°°í¬ í”„ë¡œê·¸ë¨ì´ ì¡´ì¬í•˜ì§€ë§Œ ê°€ì¥ ì‰½ê²Œ .exe íŒŒì¼ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì‚´í´ë³´ì.\n\n\nì§€ì‹œëª…ë ¹ì–´\nì‹¤í–‰ê²°ê³¼\níŒŒì´ì¬ ì½”ë“œ\n.spec íŒŒì¼\në””ë ‰í† ë¦¬ êµ¬ì¡°\n\n\n\n\n\n\n\n\n\nI am a pyhton developer. I have a simple python calculator. Iâ€™d like to deploy this program into Windows. let me know how to create a standalone executable file\n\n\n\n\n\nTo create a standalone executable file for your Python calculator, you can use a tool like PyInstaller or cx_Freeze. Here are the general steps to follow:\nInstall PyInstaller: You can use pip to install PyInstaller. Open a command prompt or terminal and run the following command:\npip install pyinstaller\nCreate a spec file: PyInstaller requires a spec file that describes your Python program and its dependencies. To create a spec file with PyInstaller, run the following command:\npyinstaller --name=calculator --onefile calculator.py\nBuild the executable: To build the executable file with PyInstaller, run the following command:\npyinstaller calculator.spec\nThis will create a standalone executable file in the dist directory. Test the executable file: Run the executable file on a Windows machine to make sure it works as expected.\nBy following these steps, you can create a standalone executable file for your Python calculator using PyInstaller.\n\n\n\n\n\n\n\n\n\n\n\n\nì½”ë“œimport tkinter as tk\n\nclass Calculator:\n    def __init__(self, master):\n        self.master = master\n        self.master.title(\"Calculator\")\n\n        # Create display\n        self.display = tk.Entry(self.master, width=30, borderwidth=5, justify=tk.RIGHT)\n        self.display.grid(row=0, column=0, columnspan=4, padx=10, pady=10)\n\n        # Define buttons\n        button_list = [\"7\", \"8\", \"9\", \"/\", \"4\", \"5\", \"6\", \"*\", \"1\", \"2\", \"3\", \"-\", \"0\", \".\", \"C\", \"+\"]\n\n        # Create buttons\n        row = 1\n        col = 0\n        for button in button_list:\n            command = lambda x=button: self.button_click(x)\n            tk.Button(self.master, text=button, padx=20, pady=10, command=command).grid(row=row, column=col)\n            col += 1\n            if col > 3:\n                row += 1\n                col = 0\n\n        # Create equals button\n        tk.Button(self.master, text=\"=\", padx=50, pady=10, command=self.calculate).grid(row=row, column=0, columnspan=4)\n\n    def button_click(self, button):\n        if button == \"C\":\n            self.display.delete(0, tk.END)\n        else:\n            self.display.insert(tk.END, button)\n\n    def calculate(self):\n        try:\n            result = eval(self.display.get())\n            self.display.delete(0, tk.END)\n            self.display.insert(0, result)\n        except:\n            self.display.delete(0, tk.END)\n            self.display.insert(0, \"Error\")\n\n# Create window\nroot = tk.Tk()\n\n# Create calculator\ncalculator = Calculator(root)\n\n# Run window\nroot.mainloop()\n\n\n\n\n\nì½”ë“œ# -*- mode: python ; coding: utf-8 -*-\n\nblock_cipher = None\n\n\na = Analysis(\n    ['calculator.py'],\n    pathex=[],\n    binaries=[],\n    datas=[],\n    hiddenimports=[],\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    [],\n    name='calculator',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=True,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n\n\n\n\n\nì½”ë“œfs::dir_tree('code/calculator_exe/')\n#> code/calculator_exe/\n#> â”œâ”€â”€ build\n#> â”‚   â””â”€â”€ calculator\n#> â”‚       â”œâ”€â”€ Analysis-00.toc\n#> â”‚       â”œâ”€â”€ base_library.zip\n#> â”‚       â”œâ”€â”€ calculator.exe.manifest\n#> â”‚       â”œâ”€â”€ calculator.pkg\n#> â”‚       â”œâ”€â”€ EXE-00.toc\n#> â”‚       â”œâ”€â”€ localpycs\n#> â”‚       â”‚   â”œâ”€â”€ pyimod01_archive.pyc\n#> â”‚       â”‚   â”œâ”€â”€ pyimod02_importers.pyc\n#> â”‚       â”‚   â”œâ”€â”€ pyimod03_ctypes.pyc\n#> â”‚       â”‚   â”œâ”€â”€ pyimod04_pywin32.pyc\n#> â”‚       â”‚   â””â”€â”€ struct.pyc\n#> â”‚       â”œâ”€â”€ PKG-00.toc\n#> â”‚       â”œâ”€â”€ PYZ-00.pyz\n#> â”‚       â”œâ”€â”€ PYZ-00.toc\n#> â”‚       â”œâ”€â”€ Tree-00.toc\n#> â”‚       â”œâ”€â”€ Tree-01.toc\n#> â”‚       â”œâ”€â”€ Tree-02.toc\n#> â”‚       â”œâ”€â”€ warn-calculator.txt\n#> â”‚       â””â”€â”€ xref-calculator.html\n#> â”œâ”€â”€ calculator.py\n#> â”œâ”€â”€ calculator.spec\n#> â””â”€â”€ dist\n#>     â””â”€â”€ calculator.exe"
  },
  {
    "objectID": "calculator.html#pdf-ì›Œë“œ",
    "href": "calculator.html#pdf-ì›Œë“œ",
    "title": "chatGPT",
    "section": "\n1.1 PDF â†’ ì›Œë“œ",
    "text": "1.1 PDF â†’ ì›Œë“œ\nPDF ë¬¸ì„œë¥¼ Convert2Docx íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•˜ì—¬ ì›Œë“œíŒŒì¼ë¡œ ë³€í™˜ì‹œí‚¨ë‹¤. í˜ì´ì§€ê°€ ë§ì•„ ì œë²• ì‹œê°„ì´ ì†Œìš”ëœë‹¤.\n\nì½”ë“œlibrary(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")"
  },
  {
    "objectID": "calculator.html#ì›Œë“œ-í‘œì¶”ì¶œ",
    "href": "calculator.html#ì›Œë“œ-í‘œì¶”ì¶œ",
    "title": "chatGPT",
    "section": "\n1.2 ì›Œë“œ â†’ í‘œì¶”ì¶œ",
    "text": "1.2 ì›Œë“œ â†’ í‘œì¶”ì¶œ\ndocxtractr íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  docx_extract_tbl() í•¨ìˆ˜ë¡œ PDF íŒŒì¼ì— ë‹´ê¸´ í‘œë¥¼ ì¶”ì¶œí•œë‹¤.\n\nì½”ë“œlibrary(docxtractr)\n\ngpt_docx <- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 <- docx_extract_tbl(gpt_docx, 3) %>% \n    janitor::clean_names()\ntbl_01\n#> # A tibble: 34 Ã— 4\n#>    exam                                           gpt_4          gpt_4â€¦Â¹ gpt_3_5\n#>    <chr>                                          <chr>          <chr>   <chr>  \n#>  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 / 400 (~9â€¦ 298 / â€¦ 213 / â€¦\n#>  2 LSAT                                           163 (~88th)    161 (~â€¦ 149 (~â€¦\n#>  3 SAT Evidence-Based Reading & Writing           710 / 800 (~9â€¦ 710 / â€¦ 670 / â€¦\n#>  4 SAT Math                                       700 / 800 (~8â€¦ 690 / â€¦ 590 / â€¦\n#>  5 Graduate Record Examination (GRE) Quantitative 163 / 170 (~8â€¦ 157 / â€¦ 147 / â€¦\n#>  6 Graduate Record Examination (GRE) Verbal       169 / 170 (~9â€¦ 165 / â€¦ 154 / â€¦\n#>  7 Graduate Record Examination (GRE) Writing      4 / 6 (~54th)  4 / 6 â€¦ 4 / 6 â€¦\n#>  8 USABO Semifinal Exam 2020                      87 / 150 (99tâ€¦ 87 / 1â€¦ 43 / 1â€¦\n#>  9 USNCO Local Section Exam 2022                  36 / 60        38 / 60 24 / 60\n#> 10 Medical Knowledge Self-Assessment Program      75 %           75 %    53 %   \n#> # â€¦ with 24 more rows, and abbreviated variable name Â¹â€‹gpt_4_no_vision"
  },
  {
    "objectID": "interface.html#ì›¹ê²€ìƒ‰",
    "href": "interface.html#ì›¹ê²€ìƒ‰",
    "title": "chatGPT",
    "section": "\n2.1 ì›¹ê²€ìƒ‰",
    "text": "2.1 ì›¹ê²€ìƒ‰\nêµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ì¼ë°˜ì ì¸ ë‚´ìš©ì„ ì–»ì„ ìˆ˜ë„ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´,\n\nsite:quarto.org/ google analytics tracking code\n\nêµ¬ê¸€ê²€ìƒ‰ì°½ì— ìƒê¸° ì‚¬í•­ì„ ì…ë ¥í•˜ê²Œ ë˜ë©´ êµ¬ê¸€ì€ ì¿¼í† (quarto) ì›¹ì‚¬ì´íŠ¸ ë‚´ë¶€ì—ì„œ google analytics tracking code í‚¤ì›Œë“œì™€ ê´€ë ¨ì´ ë†’ì€ ì›¹í˜ì´ì§€ë¥¼ ê²€ìƒ‰ê²°ê³¼ë¡œ ë°˜í™˜ì‹œí‚¤ê²Œ ëœë‹¤."
  },
  {
    "objectID": "interface.html#ì¿¼í† -ì›¹-ê²€ìƒ‰",
    "href": "interface.html#ì¿¼í† -ì›¹-ê²€ìƒ‰",
    "title": "chatGPT",
    "section": "\n2.2 ì¿¼í†  ì›¹ ê²€ìƒ‰",
    "text": "2.2 ì¿¼í†  ì›¹ ê²€ìƒ‰\nQuartoëŠ” ì›¹ì‚¬ì´íŠ¸ì™€ ì±…ì˜ ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ”ë°, ê¸°ë³¸ì ìœ¼ë¡œ QuartoëŠ” ì‚¬ì´íŠ¸ì˜ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ìƒ‰ì¸í™”í•˜ì—¬ ê¸°ë³¸ì ìœ¼ë¡œ ë¡œì»¬ë¡œ êµ¬ì¶•ëœ ìƒ‰ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë†’ì€ ê²€ìƒ‰í’ˆì§ˆì„ ì œê³µí•œë‹¤. ë”°ë¼ì„œ, ì‚¬ìš©ìëŠ” êµ¬ê¸€ì›¹ì‚¬ì´íŠ¸ê°€ ì•„ë‹ˆë¼ ì¿¼í† (quarto)ì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ì§ì ‘ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤."
  },
  {
    "objectID": "interface.html#chatgpt-ê²€ìƒ‰",
    "href": "interface.html#chatgpt-ê²€ìƒ‰",
    "title": "chatGPT",
    "section": "\n2.3 chatGPT ê²€ìƒ‰",
    "text": "2.3 chatGPT ê²€ìƒ‰\nChatGPTë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆë‹¤. íŠ¹ì • ì›¹ì‚¬ì´íŠ¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì–»ì–´ì•¼ ë˜ê¸° ë•Œë¬¸ì— ì§€ì‹œëª…ë ¹ì–´(Prompt)ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•œë‹¤.\n\nsearch https://quarto.org/ insert google analytics tracking code for quarto html document"
  },
  {
    "objectID": "interface.html#quarto-ì „ìš©-chatgpt",
    "href": "interface.html#quarto-ì „ìš©-chatgpt",
    "title": "chatGPT",
    "section": "\n2.4 Quarto ì „ìš© chatGPT\n",
    "text": "2.4 Quarto ì „ìš© chatGPT\n\nì¿¼í† (Quarto)ëŠ” ì°¨ì„¸ëŒ€ Rë§ˆí¬ë‹¤ìš´ì´ë¼ëŠ” ë³„ëª…ì´ ë¶™ì–´ ìˆì„ ì •ë„ë¡œ Rë§ˆí¬ë‹¤ìš´ì´ ê°–ëŠ” ëª¨ë“  ê¸°ëŠ¥ì— ë”í•˜ì—¬ ì¶”ê°€ë¡œ ìƒˆë¡œìš´ ì–¸ì–´(Python, R, Julia, Observable.)ì— ëŒ€í•œ ì§€ì›ë„ í¬ê´„í•˜ê³  ìˆì–´ ìƒë‹¹í•œ í•™ìŠµëŸ‰ì„ ìš”êµ¬í•œë‹¤. ì„¤ê³„ëŠ” ê¹”ë”í•˜ê²Œ ì˜ ë˜ì–´ ìˆì§€ë§Œ ì´ê²ƒì„ ì˜ ì‚¬ìš©í•˜ë ¤ë©´ ìƒë‹¹í•œ í•™ìŠµëŸ‰ì´ í•„ìš”ë¡œ í•œë‹¤. ì´ëŸ° ë¬¸ì œì— chatGPTë¥¼ ë„ì…í•˜ì—¬ ì‚¬ìš©í•˜ë©´ ê²½ìš°ì— ë”°ë¼ì„œ í° ë„ì›€ì„ ì¤„ ìˆ˜ë„ ìˆë‹¤.\n\nQuarto Help Bot - Ask a question about Quarto.\n\n\n\n\n\n:::\në‚´ë¶€ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ì§ˆë¬¸-ì‘ë‹µ(QnA)ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì„¸ë¶„í™”ë˜ì–´ ìˆìœ¼ë©°, ëª¨ë‘ ChatVectorDBChainì´ ì²˜ë¦¬í•œë‹¤:\n\nì±„íŒ… ê¸°ë¡ê³¼ ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ì´ ì£¼ì–´ì§€ë©´ ë…ë¦½í˜• ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ì§€ ê²°ì •(GPT-3 ì‚¬ìš©).\në…ë¦½í˜• ì§ˆë¬¸ì´ ì£¼ì–´ì§€ë©´ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰.\në…ë¦½í˜• ì§ˆë¬¸ê³¼ ê´€ë ¨ ë¬¸ì„œë¥¼ GPT-3ì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±."
  },
  {
    "objectID": "interface.html#ì¹´í†¡-ì•„ìˆ™ì—…",
    "href": "interface.html#ì¹´í†¡-ì•„ìˆ™ì—…",
    "title": "chatGPT",
    "section": "\n4.1 ì¹´í†¡: ì•„ìˆ™ì—…",
    "text": "4.1 ì¹´í†¡: ì•„ìˆ™ì—…\nì—…ìŠ¤í…Œì´ì§€ì—ì„œ ê°œë°œí•œ â€˜ì•„ìˆ™ì—…â€™ ì„œë¹„ìŠ¤ëŠ” ëª¨ë°”ì¼ ë©”ì‹ ì ¸ ì¹´ì¹´ì˜¤í†¡ì— AskUp ì±„ë„ì„ ì¶”ê°€í•˜ê²Œ ë˜ë©´ chatGPT ìœ ì‚¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ë¬¸ì œëŠ” ì–¸ì œ AskUp ì±„ë„ ì„œë¹„ìŠ¤ê°€ ì¤‘ë‹¨ë ì§€ ìœ ë£Œë¡œ ê³¼ê¸ˆì´ ë³€ê²½ë ì§€ ëª¨ë¥´ì§€ë§Œ chatGPTë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì´ ë‹¤ì–‘í™”í•¨ì€ ë¶„ëª…í•˜ë‹¤.\nAskUp ì„œë¹„ìŠ¤ëŠ” í˜„ì¬ ì‹œì (â€œ2023-03-10â€) ê¸°ì¤€ PDF ë¬¸ì„œìš”ì•½ê¸°ëŠ¥ì€ ì œê³µí•˜ê³  ìˆì§€ ì•Šì§€ë§Œ ì¥ë¬¸ì˜ í…ìŠ¤íŠ¸ëŠ” ìš”ì•½í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ê³  ìˆë‹¤.\n\n\naskup ê²€ìƒ‰\nì±„ë„ì¶”ê°€\nì±„íŒ…ì¤€ë¹„\nOCR ì‚¬ë¡€\në‰´ìŠ¤ ìš”ì•½"
  },
  {
    "objectID": "interface.html#ì¹´í†¡-ë‹¤ë‹¤ìŒ",
    "href": "interface.html#ì¹´í†¡-ë‹¤ë‹¤ìŒ",
    "title": "chatGPT",
    "section": "\n4.2 ì¹´í†¡: ë‹¤ë‹¤ìŒ",
    "text": "4.2 ì¹´í†¡: ë‹¤ë‹¤ìŒ\nì¹´ì¹´ì˜¤ë¸Œë ˆì¸, AIì±—ë´‡ â€˜ë‹¤ë‹¤ìŒâ€™(dmm) ë² íƒ€ ì¶œì‹œ í•˜ë£¨ ë§Œì— ì¤‘ë‹¨\nì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì´ ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥(AI) ì±—ë´‡ â€˜ë‹¤ë‹¤ìŒâ€™(ddmm) ë² íƒ€ ì„œë¹„ìŠ¤ë¥¼ 19ì¼ ì¶œì‹œí–ˆì§€ë§Œ í™©ê¸‰íˆ ì„œë¹„ìŠ¤ë¥¼ ë‚´ë ¸ë‹¤. ë‹¤ë‹¤ìŒì€ ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì´ ê°œë°œí•œ ê±°ëŒ€ ì–¸ì–´ AI ëª¨ë¸ (LLM) â€™ì½”GPTâ€™ì™€ â€™ì¹¼ë¡œâ€™ë¥¼ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ë¡œ ì‚¼ì•„ ê°œë°œí•œ ìƒì„±í˜• AI ì±„íŒ… ì„œë¹„ìŠ¤ë‹¤. ì •ë³´ê²€ìƒ‰, ìš”ì•½, ë²ˆì—­ì€ ë¬¼ë¡  ì´ë¯¸ì§€ ìƒì„±ë„ ì§€ì›í–ˆë‹¤."
  },
  {
    "objectID": "langchain.html",
    "href": "langchain.html",
    "title": "chatGPT",
    "section": "",
    "text": "LangChain ì—ì„œ OpenAI chatGPTë¥¼ í˜¸ì¶œí•˜ì—¬ ì›í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ë¨¼ì € openaiì™€ langchainì„ ì„¤ì¹˜í•œë‹¤.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¥¼ ë„£ì–´ë‘ê³  OpenAI() í•¨ìˆ˜ì—ì„œ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.\n\nimport os\nfrom langchain.llms import OpenAI\n\n# os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "langchain.html#ì˜ë¬¸",
    "href": "langchain.html#ì˜ë¬¸",
    "title": "chatGPT",
    "section": "\n3.1 ì˜ë¬¸",
    "text": "3.1 ì˜ë¬¸\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nprompt.format(product=\"colorful socks\")\n#&gt; '\\nI want you to act as a naming consultant for new companies.\\n\\nHere are some examples of good company names:\\n\\n- search engine, Google\\n- social media, Facebook\\n- video sharing, YouTube\\n\\nThe name should be short, catchy and easy to remember.\\n\\nWhat is a good name for a company that makes colorful socks?\\n'\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; FunSox."
  },
  {
    "objectID": "langchain.html#êµ­ë¬¸",
    "href": "langchain.html#êµ­ë¬¸",
    "title": "chatGPT",
    "section": "\n3.2 êµ­ë¬¸",
    "text": "3.2 êµ­ë¬¸\nì•ì„œ ì œì‘ëœ ì˜ë¬¸íšŒì‚¬ ì‘ëª… í…œí”Œë¦¿ì„ ë²ˆì—­í•˜ì—¬ êµ­ë‚´ ëª‡ê°€ì§€ íšŒì‚¬ë¥¼ ì‚¬ë¡€ë¡œ ë„£ì–´ chatGPTì— ì‘ì—…ì„ ì§€ì‹œí•œë‹¤.\n\n\nk_template = \"\"\"\nì‹ ê·œ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ” ì»¨ì„¤í„´íŠ¸ë¡œ í™œë™í•´ ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\n\në‹¤ìŒì€ ì¢‹ì€ íšŒì‚¬ ì´ë¦„ ëª‡ ê°€ì§€ ì‚¬ë¡€ì…ë‹ˆë‹¤:\n\n- ì¼€ì´í‹°, í†µì‹ \n- ë†€ë¶€, ì™¸ì‹í”„ëœì°¨ì´ì¦ˆ\n- ìœ¨ë„êµ­, ë¸Œëœë“œì œì‘\n- í¬ëª½, ì•„ì›ƒì†Œì‹± í”Œë«í¼\n\nì´ë¦„ì€ ì§§ê³  ëˆˆì— ì˜ ë„ë©° ê¸°ì–µí•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.\n\n{k_product} ì œí’ˆì„ ì˜ ë§Œë“œëŠ” íšŒì‚¬ì˜ ì¢‹ì€ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_prompt.format(k_product=\"ì–‘ë§\")\n#&gt; '\\nì‹ ê·œ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ” ì»¨ì„¤í„´íŠ¸ë¡œ í™œë™í•´ ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\\n\\në‹¤ìŒì€ ì¢‹ì€ íšŒì‚¬ ì´ë¦„ ëª‡ ê°€ì§€ ì‚¬ë¡€ì…ë‹ˆë‹¤:\\n\\n- ì¼€ì´í‹°, í†µì‹ \\n- ë†€ë¶€, ì™¸ì‹í”„ëœì°¨ì´ì¦ˆ\\n- ìœ¨ë„êµ­, ë¸Œëœë“œì œì‘\\n- í¬ëª½, ì•„ì›ƒì†Œì‹± í”Œë«í¼\\n\\nì´ë¦„ì€ ì§§ê³  ëˆˆì— ì˜ ë„ë©° ê¸°ì–µí•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.\\n\\nì–‘ë§ ì œí’ˆì„ ì˜ ë§Œë“œëŠ” íšŒì‚¬ì˜ ì¢‹ì€ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\\n'\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nprint(k_chain.run(\"ì–‘ë§\"))\n#&gt; \n#&gt; - ì†”ë©, ì–‘ë§ ì œí’ˆ\n#&gt; - ë©”ë””ì†”, ì‹ ë°œê³¼ ì–‘ë§\n#&gt; - ë£¨í”„ë¡œ, ì–‘ë§ ë””ìì¸\n#&gt; - ë¸Œì´ìŠ¬ë¦½, ì–‘ë§"
  },
  {
    "objectID": "openAI_GPT.html",
    "href": "openAI_GPT.html",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPTëŠ” ê°„ë‹¨íˆ ë§í•´ ìƒì„±í˜• ì‚¬ì „ í•™ìŠµëœ íŠ¸ëœìŠ¤í¬ë¨¸(Generative Pre-trained Transformer)ì˜ ì•½ìë¡œ, OpenAIì˜ GPT-3/GPT-4 ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ ì œí’ˆêµ°ì— ê¸°ë°˜í•œ ì±—ë´‡ìœ¼ë¡œ ì§€ë„í•™ìŠµê³¼ ê°•í™”í•™ìŠµê¸°ë²•ì„ ì ìš©í•˜ì—¬ ë¯¸ì„¸ì¡°ì •(fine-tuned)ëœ ì œí’ˆì´ì ì„œë¹„ìŠ¤ë‹¤.\n\nGPT-4â€™s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4ëŠ” GPT-3ë³´ë‹¤ 10ë°° ë§ì€ 1ì¡° 8ì²œì–µ ê°œì˜ íŒŒë¼ë¯¸í„°, 120ê°œ ê³„ì¸µì„ ê°–ëŠ” ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤. OpenAIëŠ” 16ê°œ ì „ë¬¸ê°€(MoE, Mixture of Experts)ì™€ 1,100ì–µ ê°œì˜ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  íŒŒë¼ë¯¸í„°ë¥¼ ê°–ëŠ” ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸ë¡œ êµ¬í˜„ë˜ì—ˆìœ¼ë©°, 13ì¡° ê°œì˜ í† í°ì´ í¬í•¨ëœ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆë‹¤. í›ˆë ¨ ë¹„ìš©ì€ 3,200 ~ 6,300ë§Œ ë‹¬ëŸ¬ë¡œ GPT-4ëŠ” ì´ì „ ë²„ì „ë³´ë‹¤ ì¶”ë¡  ë¹„ìš©ì´ ì•½ 3ë°° ë” ë†’ì§€ë§Œ, ë¶„ì‚° ë°ì´í„°ì„¼í„°ì—ì„œ 128ê°œ GPU í´ëŸ¬ìŠ¤í„° ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” ì¶”ë¡  ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤.\n\n\nThe Ship of Theseus\n\nOpenAIì˜ ì „ëµì€ í…Œì„¸ìš°ìŠ¤ì˜ ë°°(Theseusâ€™s Ship) ì™€ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.\n\nOpenAI GPT-3 ëª¨í˜•ì€ í¬ê²Œ ì„¸ê°€ì§€ê°€ ìˆë‹¤.\n\nGPT-3/GPT-4\nCodex\nì½˜í…ì¸  í•„í„° ëª¨ë¸\n\nGPT-3ì€ ìì—°ì–´ ì²˜ë¦¬ ë° ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë¸ë¡œ ì¸ê°„ì˜ ì–¸ì–´ ì¦‰, ìì—°ì–´ì²˜ëŸ¼ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤. í•œê±¸ìŒ ë” ë“¤ì–´ê°€ë©´ ì†ë„ì™€ ì„±ëŠ¥ì— ë”°ë¼ 4ê°€ì§€ ëª¨ë¸(A, B, C, D)ë¡œ êµ¬ë¶„ëœë‹¤.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\nì„±ëŠ¥ê¸°ì¤€ìœ¼ë¡œ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë ¬í•  ìˆ˜ ìˆëŠ”ë° ë¹„ìš©ë„ ê·¸ì— ë”°ë¼ ë†’ì•„ì§„ë‹¤ëŠ” ì˜ë¯¸ë„ í•¨ì¶•í•œë‹¤.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\në”°ë¼ì„œ, OpenAIëŠ” ë‹¤ë¹ˆì¹˜ ëª¨ë¸(text-davinci-003)ì„ í†µí•´ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì€ í›„ì— ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³¼ ê²ƒì„ ê¶Œì¥í•˜ëŠ”ë° ì´ìœ ëŠ” í›¨ì”¬ ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ë§ì€ ìˆ˜ì˜ ìœ ì‚¬í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\n\n2,048ê°œì˜ í† í° ë° 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµí•˜ì—¬ ì´í›„ ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ë‚˜ ì„±ëŠ¥ì—ì„œ ë‹¤ì†Œ ë°€ë¦¬ëŠ” ëª¨ìŠµì´ì§€ë§Œ ìµœì í™”ë¥¼ í†µí•´ ë§¤ìš° ë¹ ë¥´ê³  ë¹„ìš©ì´ ê°€ì¥ ì €ë ´í•˜ë‹¤.\n\n2,048ê°œì˜ í† í°ê³¼ 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµë˜ì—ˆê³  ê°„ë‹¨í•œ ë¶„ë¥˜ì™€ ì˜ë¯¸ë¡ ì  ë¶„ë¥˜ì— íš¨ê³¼ì ì´ë‹¤.\n\nìµœëŒ€ 2048ê°œì˜ í† í°ì„ ì§€ì›í•˜ë©° text-davinci-003 ë‹¤ìŒìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” GPT-3 ëª¨ë¸ì´ë‹¤. 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì— text-davinci-003ë³´ë‹¤ ì •í™•ë„ê°€ ë–¨ì–´ì§€ì§€ë§Œ, ë²ˆì—­, ë³µì¡í•œ ë¶„ë¥˜, í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìš”ì•½ì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆì–´ text-davinci-003ì™€ ë¹„êµí•˜ì—¬ ê°€ì„±ë¹„ê°€ ë†’ë‹¤ê³  í‰ê°€ë˜ê³  ìˆë‹¤.\n\n2021ë…„ 9ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì—ˆê¸° ë•Œë¬¸ì— ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ëŠ” ìˆì§€ë§Œ, ì•ì„  GPT-3 ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ë” ë†’ì€ í’ˆì§ˆì„ ì œê³µí•œë‹¤. ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ìµœëŒ€ 4,000ê°œ í† í°ê¹Œì§€ ìš”ì²­í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì´ì „ ëª¨í˜•ê³¼ í° ì°¨ë³„ì ì´ ëœë‹¤.\n\nì½”ë±ìŠ¤ëŠ” í”„ë¡œê·¸ë˜ë° ì½”ë“œ ì´í•´ ë° ìƒì„±ì„ ìœ„í•œ ê²ƒìœ¼ë¡œ code-davinci-002ì™€ code-cushman-001ê°€ ìˆë‹¤. ë˜í•œ, ì½”ë±ìŠ¤ëŠ” GitHub Copilotì„ êµ¬ë™í•˜ëŠ” ëª¨ë¸ì´ê¸°ë„ í•˜ë‹¤. íŒŒì´ì¬, ìë°”ìŠ¤í¬ë¦½íŠ¸, ê³ , í„, PHP, ë£¨ë¹„, ìŠ¤ìœ„í”„íŠ¸, íƒ€ì…ìŠ¤í¬ë¦½íŠ¸, SQL, ì…¸ ë“± 12ê°œ ì´ìƒì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì§€ì›í•  ë¿ë§Œ ì•„ë‹ˆë¼ ìì—°ì–´ë¡œ í‘œí˜„ëœ ì£¼ì„(comment)ë¥¼ ì´í•´í•˜ê³  ì‚¬ìš©ìë¥¼ ëŒ€ì‹ í•˜ì—¬ ìš”ì²­ëœ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\në³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ì„œëŠ” code-davinci-002ê°€ ë” ê°•ë ¥í•˜ì§€ë§Œ, ë§ì€ ì½”ë“œ ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê³  code-davinci-002 ë³´ë‹¤ ë” ë¹ ë¥´ê³  ì €ë ´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.\n\nìì—°ì–´ë¥¼ ì½”ë“œë¡œ ë²ˆì—­í•˜ëŠ” ë° íƒì›”í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•  ë¿ë§Œ ì•„ë‹ˆë¼ ë³´ì¶© ìš”ì†Œ ì‚½ì…ë„ ì§€ì›í•œë‹¤. ìµœëŒ€ 8,000ê°œì˜ í† í°ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° 2021ë…„ 6ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆë‹¤.\n\në¯¼ê°í•œ ì½˜í…ì¸  ì œê±°í•˜ê¸° ìœ„í•œ í•„í„° ëª¨í˜•ì´ë‹¤. ë¯¼ê°í•˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” API ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìê°€ ì‚¬ìš©í•  AI ì‘ìš©í”„ë¡œê·¸ë¨ì„ ê°œë°œí•  ê²½ìš°, í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ë°˜í™˜í•˜ëŠ”ì§€ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì´ í•„í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë‹¤ìŒ 3ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆˆë‹¤.\n\nì•ˆì „(safe)\në¯¼ê°(sensitive)\nì•ˆì „í•˜ì§€ ì•ŠìŒ(unsafe)"
  },
  {
    "objectID": "prompt.html",
    "href": "prompt.html",
    "title": "chatGPT",
    "section": "",
    "text": "The hottest new programming language is English\n\nâ€” Andrej Karpathy ((karpathy?)) January 24, 2023"
  },
  {
    "objectID": "prompt.html#ì‹ë¬¼-ê´‘í•©ì„±",
    "href": "prompt.html#ì‹ë¬¼-ê´‘í•©ì„±",
    "title": "chatGPT",
    "section": "\n3.1 ì‹ë¬¼ ê´‘í•©ì„±",
    "text": "3.1 ì‹ë¬¼ ê´‘í•©ì„±\në‹¤ìŒ ì˜ëª»ëœ í”„ë¡¬í”„íŠ¸ëŠ” ë„ˆë¬´ ëª¨í˜¸í•´ì„œ AIê°€ ë¬´ì‘ìœ„ ë˜ëŠ” ê´€ë ¨ ì—†ëŠ” ì‘ë‹µì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ì¢‹ì€ í”„ë¡¬í”„íŠ¸ëŠ” ë³´ë‹¤ êµ¬ì²´ì ì´ê³  ì§‘ì¤‘ì ì´ë¯€ë¡œ AIê°€ ê´€ë ¨ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ë„ë¡ ìœ ë„í•œë‹¤.\n\n\n\nì˜ëª»ëœ í”„ë¡¬í”„íŠ¸: â€œë­ë¼ë„ ë§í•´ì¤˜.â€\nAI ì‘ë‹µ: â€œë°”ë‚˜ë‚˜ëŠ” ë™ë‚¨ì•„ì‹œì•„ê°€ ì›ì‚°ì§€ì¸ ì¸ê¸° ê³¼ì¼ì´ì§€ë§Œ ì§€ê¸ˆì€ ì„¸ê³„ ì—¬ëŸ¬ ê³³ì—ì„œ ì¬ë°°ë˜ê³  ìˆìŠµë‹ˆë‹¤.â€\n\n\n\n\n\nì¢‹ì€ í”„ë¡¬í”„íŠ¸: â€œì‹ë¬¼ì˜ ê´‘í•©ì„± ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”.â€\nAI ì‘ë‹µ: â€œê´‘í•©ì„±ì€ ì‹ë¬¼, ì¡°ë¥˜ ë° ì¼ë¶€ ë°•í…Œë¦¬ì•„ê°€ ë¹› ì—ë„ˆì§€ë¥¼ í¬ë„ë‹¹ í˜•íƒœì˜ í™”í•™ ì—ë„ˆì§€ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ê´‘í•©ì„±ì—ëŠ” ë¹›ì— ì˜ì¡´í•˜ëŠ” ë°˜ì‘ê³¼ ë¹›ì— ë…ë¦½ì ì¸ ë°˜ì‘(ìº˜ë¹ˆ ì£¼ê¸°)ì˜ ë‘ ê°€ì§€ ì£¼ìš” ë‹¨ê³„ê°€ í¬í•¨ë©ë‹ˆë‹¤. ë¹›ì— ì˜ì¡´í•˜ëŠ” ë°˜ì‘ ë™ì•ˆ ì—½ë¡ì†Œì™€ ë‹¤ë¥¸ ìƒ‰ì†ŒëŠ” ë¹› ì—ë„ˆì§€ë¥¼ í¡ìˆ˜í•˜ì—¬ ATPì™€ NADPHë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê´‘ ë…ë¦½ ë°˜ì‘ì—ì„œ CO2ëŠ” ê´‘ ì˜ì¡´ì„± ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ATPì™€ NADPHë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë ¨ì˜ íš¨ì†Œ ì´‰ë§¤ ë°˜ì‘ì„ í†µí•´ ìœ ê¸° ë¶„ìë¡œ ê³ ì •ë©ë‹ˆë‹¤. ê´‘í•©ì„±ì˜ ìµœì¢… ìƒì„±ë¬¼ì€ í¬ë„ë‹¹ìœ¼ë¡œ, ì‹ë¬¼ì´ ì„±ì¥, ë²ˆì‹ ë° ê¸°íƒ€ ê³¼ì •ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.â€"
  },
  {
    "objectID": "prompt.html#êµ­ê°€-ìˆ˜ë„",
    "href": "prompt.html#êµ­ê°€-ìˆ˜ë„",
    "title": "chatGPT",
    "section": "\n3.2 êµ­ê°€ ìˆ˜ë„",
    "text": "3.2 êµ­ê°€ ìˆ˜ë„\nì˜ëª» ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ì–´ëŠ êµ­ê°€ì˜ ìˆ˜ë„ë¥¼ ìš”ì²­í•˜ëŠ”ì§€ ëª…ì‹œí•˜ì§€ ì•Šì•„ ëª¨í˜¸í•˜ë‹¤. ì¢‹ì€ í”„ë¡¬í”„íŠ¸ëŠ” êµ­ê°€ë¥¼ ëª…í™•í•˜ê²Œ ëª…ì‹œí•˜ì—¬ AIê°€ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤.\n\n\n\nì˜ëª»ëœ í”„ë¡¬í”„íŠ¸: â€œìˆ˜ë„ë¥¼ ë§í•´ì¤˜â€\nAI ì‘ë‹µ: â€œì„¸ê³„ì—ëŠ” ë§ì€ ìˆ˜ë„ê°€ ìˆìŠµë‹ˆë‹¤. ì§ˆë¬¸í•˜ëŠ” êµ­ê°€ë¥¼ ì§€ì •í•´ ì£¼ì„¸ìš”.â€\n\n\n\n\n\nì¢‹ì€ í”„ë¡¬í”„íŠ¸: â€œë…ì¼ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?â€\nAI ì‘ë‹µ: â€œë…ì¼ì˜ ìˆ˜ë„ëŠ” ë² ë¥¼ë¦°ì…ë‹ˆë‹¤.â€"
  },
  {
    "objectID": "prompt.html#ê³¼í•™ì",
    "href": "prompt.html#ê³¼í•™ì",
    "title": "chatGPT",
    "section": "\n3.3 ê³¼í•™ì",
    "text": "3.3 ê³¼í•™ì\nì˜ëª» ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ì‚¬ìš©ìê°€ ì–´ë–¤ ê³¼í•™ìë¥¼ ì–¸ê¸‰í•˜ê³  ìˆëŠ”ì§€ ë¶ˆë¶„ëª…í•˜ë¯€ë¡œ ê´€ë ¨ì„±ì´ ì—†ê±°ë‚˜ ì˜ëª»ëœ ì‘ë‹µìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆë‹¤. ì˜ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ê³¼í•™ìì˜ ì´ë¦„ì„ ëª…ì‹œí•˜ê³  ê°„ëµí•œ ê°œìš”ì™€ ìš”ì²­ì‚¬í•­ì„ ëª…í™•íˆ í•˜ì—¬ AIê°€ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ë„ë¡ ì•ˆë‚´í•œë‹¤.\n\n\n\nì˜ëª»ëœ í”„ë¡¬í”„íŠ¸: â€œìœ ëª…í•œ ê³¼í•™ìì— ëŒ€í•´ ë§í•´ì¤˜.â€\nAI ì‘ë‹µ: â€œì•„ì´ì‘ ë‰´í„´, ì•Œë²„íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸, ë§ˆë¦¬ í€´ë¦¬ ë“± ì—­ì‚¬ìƒ ìœ ëª…í•œ ê³¼í•™ìê°€ ë§ì´ ìˆìŠµë‹ˆë‹¤. ê´€ì‹¬ ìˆëŠ” ê³¼í•™ìì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.â€\n\n\n\n\n\nì¢‹ì€ í”„ë¡¬í”„íŠ¸: â€œì•Œë²„íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸ì˜ ìƒì• ì™€ ê³¼í•™ì— ëŒ€í•œ ê³µí—Œì— ëŒ€í•œ ê°„ëµí•œ ê°œìš”ë¥¼ ì œê³µí•˜ì„¸ìš”.â€\nAI ì‘ë‹µ: â€œì•Œë²„íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸(1879-1955)ì€ ë…ì¼ íƒœìƒì˜ ì´ë¡  ë¬¼ë¦¬í•™ìë¡œ ì—­ì‚¬ìƒ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ê³¼í•™ì ì¤‘ í•œ ëª…ìœ¼ë¡œ ë„ë¦¬ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ê³µê°„, ì‹œê°„, ì¤‘ë ¥ì— ëŒ€í•œ ìš°ë¦¬ì˜ ì´í•´ì— í˜ëª…ì„ ì¼ìœ¼í‚¨ ìƒëŒ€ì„± ì´ë¡ ìœ¼ë¡œ ê°€ì¥ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ì•„ì¸ìŠˆíƒ€ì¸ì˜ ìœ ëª…í•œ ë°©ì •ì‹ E=mc^2ëŠ” ì§ˆëŸ‰ê³¼ ì—ë„ˆì§€ì˜ ë“±ê°€ì„±ì„ ì¦ëª…í•©ë‹ˆë‹¤. 1921ë…„ì—ëŠ” ì–‘ì ì´ë¡ ì˜ ë°œì „ì— ê¸°ì—¬í•œ ê´‘ì „ íš¨ê³¼ì˜ ë°œê²¬ìœ¼ë¡œ ë…¸ë²¨ ë¬¼ë¦¬í•™ìƒì„ ìˆ˜ìƒí–ˆìŠµë‹ˆë‹¤. ì•„ì¸ìŠˆíƒ€ì¸ì˜ ì—°êµ¬ëŠ” ì²œë¬¸í•™, í•µë¬¼ë¦¬í•™ì—ì„œ ì¬ë£Œ ê³¼í•™, ìš°ì£¼ë¡ ì— ì´ë¥´ê¸°ê¹Œì§€ ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì§€ëŒ€í•œ ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.â€"
  },
  {
    "objectID": "prompt.html#ìš”ë¦¬ë²•",
    "href": "prompt.html#ìš”ë¦¬ë²•",
    "title": "chatGPT",
    "section": "\n3.4 ìš”ë¦¬ë²•",
    "text": "3.4 ìš”ë¦¬ë²•\nì˜ëª» ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ë„ˆë¬´ ì¼ë°˜ì ì´ì–´ì„œ AIê°€ ë„ˆë¬´ ë§ì€ í•´ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì‘ë‹µì˜ ê²½ìš°ì˜ ìˆ˜ê°€ ë§ì•„ì§€ê²Œ ëœë‹¤. ì˜ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ì£¼ì œë¥¼ íŠ¹ì • ìš”ë¦¬ë¡œ ì¢íˆê³ , ë‹¨ê³„ë³„ ì„¤ëª…ì„ ìš”ì²­í•˜ë¯€ë¡œ AIì˜ ì‘ë‹µì´ ë” ìœ ìš©í•˜ê³  ê´€ë ¨ì„±ì´ ë†’ê²Œ ìœ ë„í•  ìˆ˜ ìˆë‹¤.\n\n\n\nì˜ëª»ëœ í”„ë¡¬í”„íŠ¸: â€œìŒì‹ì„ ìš”ë¦¬í•˜ëŠ” ë°©ë²•?â€\nAI ì‘ë‹µ: â€œìŒì‹ ìš”ë¦¬ì—ëŠ” ë‹¤ì–‘í•œ ê¸°ìˆ , ì¬ë£Œ, ë ˆì‹œí”¼ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê´€ì‹¬ ìˆëŠ” ìš”ë¦¬ ìœ í˜•ì´ë‚˜ ìš”ë¦¬ ë°©ë²•ì— ëŒ€í•´ ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.â€\n\n\n\n\n\nì¢‹ì€ í”„ë¡¬í”„íŠ¸: â€œê¸°ë³¸ì ì¸ íŒŒìŠ¤íƒ€ ìš”ë¦¬ë¥¼ ì¤€ë¹„í•˜ëŠ” ë‹¨ê³„ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.â€\nAI ì‘ë‹µ: â€œê¸°ë³¸ì ì¸ íŒŒìŠ¤íƒ€ ìš”ë¦¬ë¥¼ ì¤€ë¹„í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:\n\ní° ëƒ„ë¹„ì— ì†Œê¸ˆë¬¼ì„ ë„£ê³  ë“ì…ë‹ˆë‹¤.  ìŠ¤íŒŒê²Œí‹°, íœë„¤, í˜íˆ¬ì¹˜ë‹ˆ ë“± ì›í•˜ëŠ” íŒŒìŠ¤íƒ€ë¥¼ ë“ëŠ” ë¬¼ì— ë„£ê³  í¬ì¥ì§€ ì§€ì¹¨ì— ë”°ë¼ ì•Œ ë´í…Œ ì‹ê°ì´ ë  ë•Œê¹Œì§€ ì•½ 8~12ë¶„ê°„ ì¡°ë¦¬í•©ë‹ˆë‹¤. íŒŒìŠ¤íƒ€ê°€ ìµëŠ” ë™ì•ˆ ê°„ë‹¨í•œ ì†ŒìŠ¤ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. ê¸°ë³¸ í† ë§ˆí†  ì†ŒìŠ¤ëŠ” íŒ¬ì— ì˜¬ë¦¬ë¸Œ ì˜¤ì¼ì„ ë‘ë¥´ê³  ë‹¤ì§„ ë§ˆëŠ˜ì„ í–¥ì´ ë‚  ë•Œê¹Œì§€ ë³¶ìŠµë‹ˆë‹¤. ìœ¼ê¹¬ í† ë§ˆí† , ì†Œê¸ˆ, í›„ì¶”, ë§ë¦° ë°”ì§ˆ ë˜ëŠ” ì˜¤ë ˆê°€ë…¸ë¥¼ ë„£ê³  10~15ë¶„ê°„ ë“ì…ë‹ˆë‹¤. ìµíŒ íŒŒìŠ¤íƒ€ì˜ ë¬¼ê¸°ë¥¼ ë¹¼ê³  íŒŒìŠ¤íƒ€ ë¬¼ í•œ ì»µì„ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤. íŒŒìŠ¤íƒ€ë¥¼ ì†ŒìŠ¤ì— ë„£ê³  ê³¨ê³ ë£¨ ì„ì´ë„ë¡ ë²„ë¬´ë¦½ë‹ˆë‹¤. ì†ŒìŠ¤ê°€ ë„ˆë¬´ ê±¸ì­‰í•˜ë©´ ë‚¨ì€ íŒŒìŠ¤íƒ€ ë¬¼ì„ ì•½ê°„ ì¶”ê°€í•˜ì—¬ ë¬½ê²Œ ë§Œë“­ë‹ˆë‹¤. ì›í•˜ëŠ” ê²½ìš° íŒŒë§ˆì‚° ì¹˜ì¦ˆì™€ ì‹ ì„ í•œ ë°”ì§ˆë¡œ ì¥ì‹í•˜ì—¬ íŒŒìŠ¤íƒ€ ìš”ë¦¬ë¥¼ ëœ¨ê²ê²Œ ì œê³µí•©ë‹ˆë‹¤.â€"
  },
  {
    "objectID": "prompt.html#í”„ë¡¬í”„íŠ¸",
    "href": "prompt.html#í”„ë¡¬í”„íŠ¸",
    "title": "chatGPT",
    "section": "\n1.2 í”„ë¡¬í”„íŠ¸",
    "text": "1.2 í”„ë¡¬í”„íŠ¸\nì±—GPTê°€ ê±°ëŒ€ì–¸ì–´ëª¨í˜• AI ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ì¢Œì¸¡í¸ì— í”„ë¡¬í”„íŠ¸ ì±„íŒ… ì´ë ¥ì´ ë‚˜íƒ€ë‚˜ ìˆê³ , New Chatì„ í•˜ê²Œ ë˜ë©´ í•˜ë‹¨ ì±„íŒ… ë°•ìŠ¤ì— Send a message ... í™”ë©´ì´ ë‚˜ì˜¨ë‹¤.\n\n\ní”„ë¡¬í”„íŠ¸ ëª…ë ¹ ëŒ€ê¸° ìƒíƒœ\ní”„ë¡¬í”„íŠ¸ ëª…ë ¹ ì‹¤í–‰ ê²°ê³¼"
  },
  {
    "objectID": "prompt.html#í”„ë¡¬í”„íŠ¸-êµ¬ì„±ìš”ì†Œ",
    "href": "prompt.html#í”„ë¡¬í”„íŠ¸-êµ¬ì„±ìš”ì†Œ",
    "title": "chatGPT",
    "section": "\n1.1 í”„ë¡¬í”„íŠ¸ êµ¬ì„±ìš”ì†Œ",
    "text": "1.1 í”„ë¡¬í”„íŠ¸ êµ¬ì„±ìš”ì†Œ\ní”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì€ ë°˜ë³µì ì¸ ì‘ì—…ê³¼ì •ìœ¼ë¡œ AIì˜ ì‘ë‹µì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•˜ê³  ê°œì„ í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤ëŠ” ì ì„ í•­ìƒ ì—¼ë‘ì— ë‘ê³ , ë‹¤ìŒ í”„ë¡¬í”„íŠ¸ êµ¬ì„±ìš”ì†Œë¥¼ í”„ë¡¬í”„íŠ¸ì— ë…¹ì—¬ ì œì‘í•  ê²½ìš° AI ì–¸ì–´ ëª¨ë¸ì´ ëª©í‘œì— ë¶€í•©í•˜ëŠ” ì •í™•í•˜ê³  ê´€ë ¨ì„± ìˆëŠ” êµ¬ì²´ì ì¸ ë‹µë³€ì„ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆë‹¤.\nAI ì–¸ì–´ ëª¨ë¸ê³¼ì˜ íš¨ê³¼ì ì¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ìœ„í•´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ëª‡ ê°€ì§€ êµ¬ì„± ìš”ì†Œê°€ ìˆë‹¤. ì˜ ë§Œë“¤ì–´ì§„ í”„ë¡¬í”„íŠ¸ì˜ ëª‡ ê°€ì§€ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤:\n\nëª…í™•ì„±: í”„ë¡¬í”„íŠ¸ëŠ” ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ì›Œì•¼ í•œë‹¤. ì¦‰, AI ì–¸ì–´ëª¨ë¸ì´ í˜¼ë™í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ ìš©ì–´, ì€ì–´ ë˜ëŠ” ëª¨í˜¸í•œ ì–¸ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.\në§¥ë½(Context): AI ì–¸ì–´ëª¨ë¸ì´ í•´ê²°í•´ì•¼ í•  ì£¼ì œë‚˜ ì§€ì‹œ ì—…ë¬´ë¥¼ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì¶©ë¶„í•œ ë§¥ë½(Context)ë¥¼ ì œê³µí•œë‹¤. ì§ˆë¬¸ í˜¹ì€ ìš”ì²­ê³¼ ê´€ë ¨ëœ ë°°ê²½ ì •ë³´, êµ¬ì²´ì ì¸ ì„¸ë¶€ ì •ë³´ ë˜ëŠ” ì˜ˆì‹œê°€ í¬í•¨ëœë‹¤.\nêµ¬ì²´ì„±: AI ì–¸ì–´ëª¨ë¸ì´ ì›í•˜ëŠ” ë‹µë³€ìœ¼ë¡œ ì•ˆë‚´í•  ìˆ˜ ìˆë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ìµœëŒ€í•œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•œë‹¤. ë‹µë³€ì˜ í˜•ì‹, ì •ë³´ì˜ ë²”ìœ„ ë˜ëŠ” ì§‘ì¤‘ì ìœ¼ë¡œ ë‹¤ë£¨ê³  ì‹¶ì€ ì£¼ì œì˜ íŠ¹ì • ì¸¡ë©´ì„ ì§€ì •í•˜ëŠ” í–‰ìœ„ê°€ í¬í•¨ëœë‹¤.\nëª¨í˜¸ì„± ì œê±°: AI ì–¸ì–´ëª¨ë¸ì´ ì§ˆë¬¸ì„ ì˜¤í•´í•˜ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ë‹µë³€ì„ ì œê³µí•  ê°€ëŠ¥ì„±ì„ ì¤„ì´ë ¤ë©´ í”„ë¡¬í”„íŠ¸ì— ëª¨í˜¸ì„±ì´ ìˆëŠ”ì§€ í™•ì¸í•œë‹¤. í”„ë¡¬í”„íŠ¸ê°€ ì—¬ëŸ¬ ê°€ì§€ ì˜ë¯¸ë¡œ í•´ì„ë  ìˆ˜ ìˆëŠ” ê²½ìš°, ëª¨í˜¸í•¨ì´ ì—†ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì‹œ ì‘ì„±í•œë‹¤.\nì œì•½ ì¡°ê±´: ë‹¨ì–´ ìˆ˜ ì œí•œì´ë‚˜ ì£¼ì œì˜ íŠ¹ì • ì¸¡ë©´ê³¼ ê°™ì€ ì œì•½ ì¡°ê±´ì„ í¬í•¨í•˜ë©´ AI ì–¸ì–´ëª¨ë¸ì´ ë³´ë‹¤ ì§‘ì¤‘ì ì´ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ì œê³µí•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆë‹¤. íŠ¹íˆ, ê´‘ë²”ìœ„í•œ ì£¼ì œì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ê±°ë‚˜ ê°„ê²°í•œ ë‹µë³€ì„ ì°¾ì„ ë•Œ ìœ ìš©í•˜ë‹¤.\nì§€ì‹œì‚¬í•­: AI ì–¸ì–´ëª¨ë¸ì´ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê±°ë‚˜ íŠ¹ì • ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ë„ë¡ í•˜ë ¤ë©´ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ì¸ ì§€ì¹¨ì„ í¬í•¨í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, AIì—ê²Œ ì¥ë‹¨ì ì„ ë‚˜ì—´í•˜ê±°ë‚˜, ë‘ í•­ëª©ì„ ë¹„êµí•˜ê±°ë‚˜, íŠ¹ì • ê´€ì ì„ ê³ ë ¤í•˜ë„ë¡ ìš”ì²­í•œë‹¤.\në¬¸ë²•ê³¼ ì² ì: AI ì–¸ì–´ëª¨í˜•ì´ ìˆ˜í–‰ ì‘ì—…ì„ í•´ì„í•  ë•Œ ë¬¸ë²• ì •ë³´ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì˜¬ë°”ë¥¸ ë¬¸ë²•ê³¼ ì² ìë²•ì„ ë§ê²Œ ì‘ì„±í•˜ëŠ” ê²ƒì€ ì¤‘ìš”í•˜ë‹¤.\n\nPrompt Engineering Guide"
  },
  {
    "objectID": "prompt.html#ì•ˆë‚´ì§€ì¹¨-í”„ë¡¬í”„íŠ¸-ê¸°ë²•",
    "href": "prompt.html#ì•ˆë‚´ì§€ì¹¨-í”„ë¡¬í”„íŠ¸-ê¸°ë²•",
    "title": "chatGPT",
    "section": "\n5.1 ì•ˆë‚´ì§€ì¹¨ í”„ë¡¬í”„íŠ¸ ê¸°ë²•",
    "text": "5.1 ì•ˆë‚´ì§€ì¹¨ í”„ë¡¬í”„íŠ¸ ê¸°ë²•\n\n\nPrompt formula: â€œGenerate [task] following these instructions: [instructions]â€\n\n\n\ní”„ë¡¬í”„íŠ¸ ê³µì‹: â€œë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ [ì‘ì—…]ì„ ìƒì„±í•©ë‹ˆë‹¤: [ì§€ì¹¨]â€"
  },
  {
    "objectID": "prompt.html#í‘œì¤€-í”„ë¡¬í”„íŠ¸",
    "href": "prompt.html#í‘œì¤€-í”„ë¡¬í”„íŠ¸",
    "title": "chatGPT",
    "section": "\n5.1 í‘œì¤€ í”„ë¡¬í”„íŠ¸",
    "text": "5.1 í‘œì¤€ í”„ë¡¬í”„íŠ¸\nê°€ì¥ ê¸°ë³¸ì ì¸ í”„ë¡¬í”„íŠ¸ëŠ” ì–¸ì–´ëª¨í˜•ì´ ìˆ˜í–‰í•  â€œ[ì‘ì—…]â€ì„ ì§€ì •í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ ìƒì„±í•˜ë¼ê³  ì§€ì‹œëª…ë ¹ë¬¸ì„ ì‘ì„±í•œë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œ[ì‘ì—…]ì„ ìƒì„±í•˜ë¼â€  ì˜ˆ: ë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”!\n\nì±—GPT í”ŒëŸ¬ê·¸ì¸ í™•ì¥ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì™¸ë¶€ URLì„ ì¸ì‹í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— í”„ë¡¬í”„íŠ¸ì— í•´ë‹¹ ê¸°ì‚¬ë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ê¸°í•´ì•¼í•œë‹¤. ë†ë¯¼ì‹ ë¬¸ ë²„ì “ì´ ìˆ˜ì…Â·ì¬ë°°ëœ LMO ì¢…ìâ€¦ê²€ì—­ë‹¹êµ­ ë­í–ˆë‚˜ì— ì‹¤ë¦° ì˜¤í”¼ë‹ˆì–¸ ì‚¬ì„¤ì„ ìš”ì•½í•´ë³´ì.\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”!\n\n\n\n\n\në¯¸êµ­ì˜ ìœ ì „ìë³€í˜•ìƒë¬¼ì²´(LMO) ì¢…ìê°€ ë²„ì “ì´ ìˆ˜ì…ë¼ 8ë…„ì´ë‚˜ ì¬ë°°ë¼ì˜¨ ì‚¬ì‹¤ì´ ë“œëŸ¬ë‚¬ë‹¤. í’ˆëª©ì€ ì£¼í‚¤ë‹ˆí˜¸ë°•ì´ë‹¤. ì œì¡°Â·ê°€ê³µí•˜ë©´ ìœ ì „ìë³€í˜• DNAê°€ ì•ˆ ë‚¨ì•„ ì‹í’ˆê°€ê³µìš©ìœ¼ë¡œ ìŠ¹ì¸ë°›ì€ ì›ë£Œ ì‘ë¬¼ì— ëŒ€í•´ì„œë„ ìœ ì „ìë³€í˜•ë†ì‚°ë¬¼(GMO) í‘œì‹œë¥¼ í•˜ë¼ê³  í•  ì •ë„ë¡œ êµ­ë¯¼ì  ë°˜ê°ì´ ê±°ì„¼ë°, ì¬ë°°ë¥¼ í†µí•´ ì–¼ë§ˆë“ ì§€ ì¦ì‹í•  ìˆ˜ ìˆëŠ” LMO ì¢…ìê°€ í•´ì™¸ ì§êµ¬ë¼ëŠ” ì–´ì—¿í•œ ê²½ë¡œë¥¼ í†µí•´ ë“¤ì–´ì™€ ì¥ê¸°ê°„ ì¬ë°°ëìœ¼ë‹ˆ ê²€ì—­ë§ í—ˆìˆ í•˜ê¸°ê°€ í•œì‹¬í•˜ê¸° ì§ì´ ì—†ë‹¤.\nì¢…ìê°€ í•¨ë¶€ë¡œ êµ­ê²½ì„ ë„˜ë‚˜ë“¤ì–´ì„œëŠ” ì•ˆë˜ëŠ” ì´ìœ ëŠ” êµ­ë‚´ë²•ì€ ë¬¼ë¡  êµ­ì œ ê·œì•½ì—ë„ ëª…ì‹œëë‹¤. ìš°ë¦¬ë‚˜ë¼ â€˜ì¢…ìì‚°ì—…ë²•â€™ì€ ìƒíƒœê³„ ë³´í˜¸ ë° ìì› ë³´ì¡´ì— ì§€ì¥ì„ ì¤„ ìš°ë ¤ê°€ ìˆëŠ” ì¢…ìëŠ” ìˆ˜ì…ì„ ì œí•œí•  ìˆ˜ ìˆë‹¤ê³  í–ˆìœ¼ë©°, â€˜LMOì˜ êµ­ê°€ê°„ ì´ë™ ë“±ì— ê´€í•œ ë²•ë¥ â€™(LMOë²•)ì€ ìƒë¬¼ë‹¤ì–‘ì„±ì˜ ë³´ì „ ë° ì§€ì†ì  ì´ìš©ì— ë¶€ì •ì  ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ìˆëŠ” LMOì˜ ìœ„í•´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ êµ­ê°€ì˜ ì±…ë¬´ë¥¼ ì ì‹œí•˜ê³  ìˆë‹¤. LMOë²•ì€ LMOì˜ êµ­ê°€ê°„ ì´ë™ì„ ê·œì œí•˜ëŠ” êµ­ì œí˜‘ì•½ì¸ â€™ë°”ì´ì˜¤ì•ˆì „ì„±ì— ê´€í•œ ì¹´ë¥´íƒ€í—¤ë‚˜ ì˜ì •ì„œâ€™ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë§Œí¼ LMOì— ëŒ€í•œ ìš°ë ¤ëŠ” ì„¸ê³„ ê°êµ­ì´ ê³µíˆ ì¸ì •í•˜ëŠ” ë°”ì´ê¸°ë„ í•˜ë‹¤. ì´ëŸ°ë°ë„ LMO ì¢…ìê°€ ë¬´ì‚¬ í†µê´€í–ˆë‹¤ëŠ” ê±´ ê²€ì—­ë‹¹êµ­ì˜ ë°©ì„ì´ë‚˜ ëŠ¥ë ¥ ë¶€ì¡±ìœ¼ë¡œë°–ì— ë³´ì´ì§€ ì•ŠëŠ”ë‹¤.\nLMO ì£¼í‚¤ë‹ˆí˜¸ë°• ì¬ë°°Â·íŒë§¤ ì‚¬ì‹¤ì´ ì•Œë ¤ì§„ í›„ ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€ê°€ í•´ë‹¹ ì¢…ì íšŒìˆ˜ì— ë‚˜ì„œê³  êµìœ¡ë¶€ê°€ í•™êµê¸‰ì‹ì— ì£¼í‚¤ë‹ˆí˜¸ë°• ì‚¬ìš©ì„ ì¤‘ë‹¨í•œ ê²ƒì€ ê·¸ë§Œí¼ ì‚¬íƒœê°€ ìœ„ì¤‘í•´ì„œë‹¤. GMOì— ëŒ€í•œ êµ­ë¯¼ì  ë¶ˆì‹ ì´ ë°˜ì˜ëœ ì¡°ì¹˜ë‹¤. ì–‘ì‹¬ì„ ì†ì´ê³  ìˆ˜ì… ê·œì •ì„ ì–´ê¸´ ì—…ìë¥¼ ìš°ì„  íƒ“í•´ì•¼ í•˜ê² ì§€ë§Œ, ì´ëŸ° ìƒí™©ì„ ë§‰ê¸° ìœ„í•´ ê²€ì—­ë‹¹êµ­ì´ ì¡´ì¬í•˜ëŠ” ê²ƒ ì•„ë‹Œê°€. ì¢…ìëŠ” ë‚±ì•Œ í¬ê¸°ê°€ ì‘ì€ ë°ë‹¤ ì†ì´ë ¤ê³  ì‘ì •í•˜ë©´ ê±¸ëŸ¬ë‚´ê¸° ì–´ë µë‹¤ëŠ” ì ì„ ëª¨ë¥´ì§€ ì•Šìœ¼ë‚˜ ê·¸ëŸ° í•´ëª…ì´ êµ­ë¯¼ì˜ ê³µê°ì„ ì–»ê¸°ëŠ” ì–´ë µë‹¤.\ní˜„í–‰ ì œë„ìƒ ë¹ˆí‹ˆì´ë‚˜ êµ¬ë©ì„ ì™„ë²½íˆ ë©”ìš°ê¸° ì–´ë µë‹¤ë©´ ì‘ë‹¹ ê²€ì—­Â·í†µê´€ ì‹œìŠ¤í…œì„ ê°œì„ í•˜ê³  ìœ„ë²•ìì— ëŒ€í•œ ì²˜ë²Œë„ í¬ê²Œ ê°•í™”í•˜ëŠ” ê²ƒì´ ë§ˆë•…í•˜ë‹¤. ì¹´ë¥´íƒ€í—¤ë‚˜ ì˜ì •ì„œì—ë„ ë‚˜ì™€ ìˆë“¯ LMOì˜ êµ­ê°€ê°„ ì´ë™ì´ í–¥í›„ í•´ë‹¹êµ­ì˜ ìƒë¬¼ë‹¤ì–‘ì„±ì€ ë¬¼ë¡  ì¸ì²´ ê±´ê°•ì— ì–´ë–¤ ë¶€ì •ì  ì˜í–¥ì„ ì¤„ì§€ ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ë”êµ¬ë‚˜ ì§€ê¸ˆ ìƒíƒœë¼ë©´ GMO ê´€ë ¨ ì¥ë²½ì„ ëŒ€í­ ì™„í™”í•´ì•¼ í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì¸ë„Â·íƒœí‰ì–‘ ê²½ì œí”„ë ˆì„ì›Œí¬(IPEF) ì‹œëŒ€ì— ëŒ€í•œ ì „ë§ë„ ì•”ìš¸í•˜ë‹¤. ë¬¸í„±ì´ ë‚®ì•„ì§ˆìˆ˜ë¡ ë„˜ë‚˜ë“¦ì´ ì‰¬ìš´ ê±´ ë¶ˆë¬¸ê°€ì§€ë‹¤.\nAI ì‘ë‹µ:\n\në¯¸êµ­ ìœ ì „ìë³€í˜•ìƒë¬¼ì²´(LMO) ì¢…ìì¸ ì£¼í‚¤ë‹ˆí˜¸ë°•ì´ ë¬´ì‚¬í†µê´€ë¼ êµ­ë‚´ì—ì„œ 8ë…„ê°„ ì¬ë°°ë˜ì–´ ì™”ëŠ”ë°, ì´ëŠ” êµ­ë‚´ë²•ê³¼ êµ­ì œ ê·œì•½ì„ ìœ„ë°˜í•œ ê²ƒìœ¼ë¡œ ê²€ì—­ë§ì˜ ë¶€ì¡±ê³¼ ëŠ¥ë ¥ ë¶€ì¡±ìœ¼ë¡œ ë³´ì¸ë‹¤ëŠ” ê²ƒê³¼ GMOì— ëŒ€í•œ êµ­ë¯¼ì  ë¶ˆì‹ ì´ ë°˜ì˜ëœ ì‚¬íƒœì´ë©°, ê²€ì—­Â·í†µê´€ ì‹œìŠ¤í…œ ê°œì„ ê³¼ ìœ„ë²•ìì— ëŒ€í•œ ê°•í™”ëœ ì²˜ë²Œì´ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì´ ì§€ì ë˜ê³  ìˆë‹¤.\n\n\n\n\n\ní‘œì¤€ í”„ë¡¬í”„íŠ¸ ì‘ì„± ê¸°ë²•ì— ì—­í• ì„ ì¶”ê°€í•˜ë©´ ì¢€ë” ì˜ë¯¸ìˆëŠ” ê¸°ì‚¬ë¥¼ ì‘ì„±í•˜ê²Œ ëœë‹¤.\n\n\nì‘ì—…: ì‚¼ì„± ê°¤ëŸ­ì‹œ 23 í•¸ë“œí° í›„ê¸° ì‘ì„±\n\nì‘ì„±ì§€ì¹¨: í›„ê¸°ëŠ” ê°ê´€ì ì´ë©° ìœ ìµí•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆì–´ì•¼ í•˜ë©° ì „ì‘ê³¼ ë¹„êµí•˜ì—¬ íŠ¹ë³„íˆ ì¶”ê°€ëœ ê¸°ëŠ¥ì„ ê°•ì¡°í•´ì•¼ ëœë‹¤.\n\nì—­í• : êµ¬ë§¤ ì†Œë¹„ì\n\nì”¨ì•—ë‹¨ì–´: ìƒˆë¡œìš´ ê¸°ëŠ¥\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: â€œíœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ëŠ” ì†Œë¹„ìë¡œì„œ ì´ì „ ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ ì‚¼ì„± ê°¤ëŸ­ì‹œ 23 íœ´ëŒ€í°ì˜ ê³ ìœ í•œ ê¸°ëŠ¥ì„ ê°•ì¡°í•˜ëŠ” ê°ê´€ì ì´ê³  ìœ ìµí•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” íœ´ëŒ€í° ë¦¬ë·°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.â€\n\n\n\n\nAI ì‘ë‹µ:\n\nìµœê·¼ì— ìƒˆë¡œìš´ ì‚¼ì„± ê°¤ëŸ­ì‹œ 23 íœ´ëŒ€í°ì„ êµ¬ë§¤í•œ ì†Œë¹„ìë¡œì„œ, ì´ì „ ëª¨ë¸ê³¼ ë¹„êµí•´ ë³´ì•˜ì„ ë•Œ í° ì—…ê·¸ë ˆì´ë“œê°€ ì´ë£¨ì–´ì¡Œë‹¤ëŠ” ê²ƒì„ í™•ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ëˆˆì— ë„ëŠ” íŠ¹ì§•ì€ í–¥ìƒëœ ì €ì¡°ë„ ì„±ëŠ¥ê³¼ ê°œì„ ëœ ê´‘í•™ ì¤Œì´ ìˆëŠ” ê°•ë ¥í•œ íŠ¸ë¦¬í”Œ ë Œì¦ˆ ì¹´ë©”ë¼ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë˜í•œ, ìµœì‹  ìŠ¤ëƒ…ë“œë˜ê³¤ í”„ë¡œì„¸ì„œë¥¼ ì¥ì°©í•´ ì²˜ë¦¬ ì†ë„ê°€ í–¥ìƒë˜ì–´ ë°˜ì‘ì„±ê³¼ ì‚¬ìš©ì ê²½í—˜ì´ ë”ìš± ë¹ ë¥´ê³  ë”ìš± ì›í™œí•´ì¡ŒìŠµë‹ˆë‹¤.\n\n\nê°¤ëŸ­ì‹œ 23ì—ëŠ” ì´ì „ ì‚¼ì„± ëª¨ë¸ê³¼ êµ¬ë³„ë˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ ê³ ìœ í•œ ê¸°ëŠ¥ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ ì¤‘ í•˜ë‚˜ëŠ” ë‹¤ì´ë‚˜ë¯¹ AMOLED 120Hz ë””ìŠ¤í”Œë ˆì´ì¸ë°, í™”ë ¤í•œ ìƒ‰ìƒê³¼ ì„ ëª…í•œ ëŒ€ë¹„ë¡œ ëˆˆì— ë„ëŠ” ì‹œê°ì  íš¨ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, íœ´ëŒ€í°ì˜ ë°°í„°ë¦¬ í¬ê¸°ê°€ ì»¤ì¡Œìœ¼ë©° ë¹ ë¥¸ ì¶©ì „ ê¸°ëŠ¥ì„ ê°–ì¶”ê³  ìˆì–´ í•­ìƒ ë°”ì˜ê²Œ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì í•©í•©ë‹ˆë‹¤.\n\n\nì¢…í•©ì ìœ¼ë¡œ, ìƒˆë¡œìš´ ì‚¼ì„± ê°¤ëŸ­ì‹œ 23ì€ ìµœì²¨ë‹¨ ê¸°ëŠ¥ì„ ê°–ì¶˜ ìµœê³ ê¸‰ íœ´ëŒ€í°ì„ ì°¾ê³  ìˆëŠ” ë¶„ë“¤ì—ê²Œ ì¶”ì²œí•  ë§Œí•œ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ê°•ë ¥í•œ ì¹´ë©”ë¼ ì‹œìŠ¤í…œ, ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ ë° ë””ìŠ¤í”Œë ˆì´ í’ˆì§ˆë¡œ ì¸í•´ ê²½ìŸì´ ì¹˜ì—´í•œ ì‹œì¥ì—ì„œ ë›°ì–´ë‚œ ì¥ì¹˜ë¡œ ë– ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "prompt.html#ì—­í• -í”„ë¡¬í”„íŠ¸",
    "href": "prompt.html#ì—­í• -í”„ë¡¬í”„íŠ¸",
    "title": "chatGPT",
    "section": "\n5.2 ì—­í•  í”„ë¡¬í”„íŠ¸",
    "text": "5.2 ì—­í•  í”„ë¡¬í”„íŠ¸\nAI ì–¸ì–´ëª¨ë¸ì— íŠ¹ì • ì—­í• ì„ ë¶€ì—¬í•´ì„œ ì›í•˜ëŠ” ì±—GPT ê²°ê³¼ë¥¼ ë„ì¶œí•˜ë„ë¡ ì§€ì‹œëª…ë ¹ë¬¸ì„ ì‘ì„±í•œë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œ[ì—­í• ]ë¡œì„œ [ì‘ì—…]ì„ ìƒì„±í•˜ë¼â€  ì˜ˆ: â€œí†µì‹ íšŒì‚¬ ì½œì„¼í„° ìƒë‹´ì›ìœ¼ë¡œ ê³ ê°ë¬¸ì˜ì— ëŒ€í•´ ì‘ë‹µì„ ìƒì„±í•˜ì‹œì˜¤â€\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë„ˆëŠ” ì§€ê¸ˆë¶€í„° ì¼€ì´ë¸” TV íšŒì‚¬ì˜ ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìë¡œ ì—­í• ì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤. ê³ ê°ì´ ì½œì„¼í„°ë¡œ ì‚¼ì„± ê°¤ëŸ­ì‹œ 23 í•¸ë“œí°ì— ë¬¸ì œê°€ ìˆë‹¤ê³  ì „í™”ë¥¼ ê±¸ì–´ì™”ìŠµë‹ˆë‹¤. ê³ ê°ì—ê²Œ ì‘ëŒ€ë¥¼ í•´ì•¼í•˜ëŠ”ë° ì–´ë–»ê²Œ ì‘ëŒ€í• ì§€ ì‘ì„±í•´ë³´ì„¸ìš”.\n\n\n\n\nAI ì‘ë‹µ:\n\në„¤, ê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ìë¡œ ì—­í• ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤.\n\n\nê³ ê°: ì‚¼ì„± ê°¤ëŸ­ì‹œ 23 í•¸ë“œí°ì„ ì‚¬ìš©í•˜ê³  ìˆëŠ”ë°, ì „í™”ë¥¼ ê±¸ê±°ë‚˜ ë¬¸ìë¥¼ ë³´ë‚´ë ¤ê³  í•  ë•Œë§ˆë‹¤ í™”ë©´ì´ êº¼ì ¸ìš”.\n\n\nê³ ê° ì„œë¹„ìŠ¤ ë‹´ë‹¹ì: ì•ˆë…•í•˜ì„¸ìš”, ì‚¼ì„± ê°¤ëŸ­ì‹œ 23 í•¸ë“œí° ê³ ê° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ëª‡ ê°€ì§€ ì§ˆë¬¸ì„ ë“œë¦´ê²Œìš”. ë¨¼ì €, í•¸ë“œí°ì„ ì¬ë¶€íŒ…í•´ë³´ì…¨ë‚˜ìš”? ê·¸ë¦¬ê³  í•¸ë“œí°ì´ ì¶©ì „ì´ ì˜ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”. ë§Œì•½ ì´ëŸ¬í•œ ì¡°ì¹˜ê°€ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í•œë‹¤ë©´, í™”ë©´ì´ ìì£¼ êº¼ì§€ëŠ” ê²½ìš°ì—ëŠ” ë°°í„°ë¦¬ ì ˆì•½ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”. ê·¸ë¦¬ê³  ì„¤ì •ì—ì„œ í™”ë©´ ì‹œê°„ì„ ë” ê¸¸ê²Œ ì¡°ì •í•´ë³´ì„¸ìš”. ë§Œì•½ì— ì´ëŸ¬í•œ ì¡°ì¹˜ê°€ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í•œë‹¤ë©´, ì €í¬ëŠ” íŒì›¨ì–´ ì—…ë°ì´íŠ¸ë‚˜ ê³ ì¥ ì‹ ê³  ë“± ì¶”ê°€ì ì¸ ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ì¡°ì¹˜ë¥¼ ì·¨í•´ ë“œë¦´ê¹Œìš”?"
  },
  {
    "objectID": "prompt.html#ê°ì„±-ë¶„ë¥˜",
    "href": "prompt.html#ê°ì„±-ë¶„ë¥˜",
    "title": "chatGPT",
    "section": "\n5.3 ê°ì„± ë¶„ë¥˜",
    "text": "5.3 ê°ì„± ë¶„ë¥˜\ní…ìŠ¤íŠ¸ì— ë‚´ì¬ëœ ê°ì„±ë„ ê¸ë¶€ì • í˜¹ì€ ê¸ì •, ë¶€ì •, ì¤‘ë¦½ìœ¼ë¡œ ë‚˜ëˆ  ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ë„ ê°€ëŠ¥í•˜ë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œ[í…ìŠ¤íŠ¸]ì˜ ê°ì„±ì„ ê¸ì •ê³¼ ë¶€ì • ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ë¼â€  ì˜ˆ: â€œë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ê¸ì •ê³¼ ë¶€ì • ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. â€˜1%ë¼ë„ ê¸°ëŒ€í–ˆë˜ ë‚´ê°€ ì£„ì¸ì…ë‹ˆë‹¤ ì£„ì¸ì…ë‹ˆë‹¤â€¦.â€™â€\n\në„¤ì´ë²„ ì˜í™” ê°ì„± ë§ë­‰ì¹˜ì—ì„œ ì˜í™” í›„ê¸° ê¸ì •ê³¼ ë¶€ì •ì„ ê°ê° í•˜ë‚˜ì”© ë½‘ì•„ë‚´ì„œ ê°ì„±ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.\n\n\n\n\n\n\n\nid\ndocument\nlabel\n\n\n\n5912145\nì™œì¼€ í‰ì ì´ ë‚®ì€ê±´ë°? ê½¤ ë³¼ë§Œí•œë°.. í—ë¦¬ìš°ë“œì‹ í™”ë ¤í•¨ì—ë§Œ ë„ˆë¬´ ê¸¸ë“¤ì—¬ì ¸ ìˆë‚˜?\n1\n\n\n9671124\n1%ë¼ë„ ê¸°ëŒ€í–ˆë˜ ë‚´ê°€ ì£„ì¸ì…ë‹ˆë‹¤ ì£„ì¸ì…ë‹ˆë‹¤â€¦.\n0\n\n\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ê¸ì •ê³¼ ë¶€ì • ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ë‹µë³€ì€ ê¸ì •, ë¶€ì • ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n\n\n\n\n\nâ€œì™œì¼€ í‰ì ì´ ë‚®ì€ê±´ë°? ê½¤ ë³¼ë§Œí•œë°.. í—ë¦¬ìš°ë“œì‹ í™”ë ¤í•¨ì—ë§Œ ë„ˆë¬´ ê¸¸ë“¤ì—¬ì ¸ ìˆë‚˜?â€\nAI ì‘ë‹µ:\n\në‹µë³€: ê¸ì •\n\n\n\n\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ê¸ì •ê³¼ ë¶€ì • ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ìœ ë„ ì œì‹œí•˜ì—¬ ì£¼ì„¸ìš”.\n\n\n\n\n\nâ€œ1%ë¼ë„ ê¸°ëŒ€í–ˆë˜ ë‚´ê°€ ì£„ì¸ì…ë‹ˆë‹¤ ì£„ì¸ì…ë‹ˆë‹¤â€¦.â€\nAI ì‘ë‹µ:\n\nì´ í…ìŠ¤íŠ¸ëŠ” ë¶€ì •ì ì¸ ê°ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ìœ ëŠ” â€œì£„ì¸ì…ë‹ˆë‹¤â€ë¼ëŠ” ë¬¸êµ¬ê°€ ìˆì–´ì„œ ì…ë‹ˆë‹¤. ì´ ë¬¸êµ¬ëŠ” ìì‹ ì— ëŒ€í•œ ë¶€ì •ì ì¸ í‰ê°€ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆìœ¼ë©°, â€œ1%ë¼ë„ ê¸°ëŒ€í–ˆë˜â€ì´ë¼ëŠ” í‘œí˜„ì€ ìì‹ ì´ ì–´ë–¤ ì¼ì„ í•  ë•Œ ê¸°ëŒ€ì™€ ë‹¤ë¥´ê²Œ ê²°ê³¼ê°€ ë‚˜ì˜¨ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ í‘œí˜„ë“¤ì€ ë¶€ì •ì ì¸ ê°ì •ì„ ë‚˜íƒ€ë‚´ê³  ìˆìœ¼ë©°, ë”°ë¼ì„œ ì´ í…ìŠ¤íŠ¸ëŠ” ë¶€ì •ì ì¸ ê°ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "prompt.html#í…ìŠ¤íŠ¸-ë¶„ë¥˜",
    "href": "prompt.html#í…ìŠ¤íŠ¸-ë¶„ë¥˜",
    "title": "chatGPT",
    "section": "\n5.4 í…ìŠ¤íŠ¸ ë¶„ë¥˜",
    "text": "5.4 í…ìŠ¤íŠ¸ ë¶„ë¥˜\në„¤ì´ë²„ ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ê° ë‰´ìŠ¤ ë²”ì£¼ë³„ë¡œ ë‚˜ëˆ  ë¶„ë¥˜í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œ[í…ìŠ¤íŠ¸]ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë²”ì£¼ë¡œ ë¶„ë¥˜í•˜ë¼; A, B, Câ€  ì˜ˆ: â€œë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ë²”ì£¼ë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤; ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ìƒí™œ/ë¬¸í™”, ì„¸ê³„, ê¸°ìˆ /IT, ì—°ì˜ˆ, ìŠ¤í¬ì¸ . â€˜ë‰´ìŠ¤ ê¸°ì‚¬â€™â€\n\në‹¤ìŒ ì‚¬ë¡€ëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ì…‹ì—ì„œ ì •ì¹˜ë‰´ìŠ¤ê¸°ì‚¬ í•˜ë‚˜ë¥¼ ê°€ì ¸ì™”ë‹¤. ì••ì¶•íŒŒì¼ì„ í’€ë©´ ì •ì¹˜(0), ê²½ì œ(1), ì‚¬íšŒ(2), ìƒí™œ/ë¬¸í™”(3), ì„¸ê³„(4), ê¸°ìˆ /IT(5), ì—°ì˜ˆ(6), ìŠ¤í¬ì¸ (7) ì´ 8ê°œ ë²”ì£¼ë¡œ ë‚˜ëˆ  ë””ë ‰í† ë¦¬ì— í…ìŠ¤íŠ¸ ë‰´ìŠ¤ê¸°ì‚¬ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ë²”ì£¼ë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤; ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ìƒí™œ/ë¬¸í™”, ì„¸ê³„, ê¸°ìˆ /IT, ì—°ì˜ˆ, ìŠ¤í¬ì¸ .\n\n\n\n\n\në™ë‚¨ì•„ ë‹´ë‹¹â€™ åŒ— ìµœí¬ì²  ë¶€ìƒ ë² ì´ì§• ë„ì°©â€¦ì‹±ê°€í¬ë¥´í–‰ ì£¼ëª© ìµœ ë¶€ìƒ, í–‰ì„ ì§€Â·ë°©ë¬¸ ëª©ì  ì§ˆë¬¸ì—ëŠ” â€˜ë¬µë¬µë¶€ë‹µâ€™\n(ë² ì´ì§•=ì—°í•©ë‰´ìŠ¤) ê¹€ì§„ë°© íŠ¹íŒŒì› = ë¶í•œì´ ë¶ë¯¸ ì •ìƒíšŒë‹´ ë¬´ì‚° ê°€ëŠ¥ì„±ê¹Œì§€ ê±°ë¡ í•˜ë©° ê°•ê²½í•œ íƒœë„ë¥¼ ë³´ì´ëŠ” ê°€ìš´ë° ë™ë‚¨ì•„ì‹œì•„ ì™¸êµë¥¼ ë‹´ë‹¹í•˜ëŠ” ìµœí¬ì²  ë¶í•œ ì™¸ë¬´ì„± ë¶€ìƒì´ 19ì¼ ì¤‘êµ­ ë² ì´ì§• ì„œìš°ë‘(é¦–éƒ½) ê³µí•­ì— ëª¨ìŠµì„ ë“œëŸ¬ëƒˆë‹¤.\nìµœ ë¶€ìƒì€ ì´ë‚  ì˜¤ì „ í‰ì–‘ë°œ ê³ ë ¤í•­ê³µ JS151í¸ì„ ì´ìš©í•´ ë² ì´ì§• ì„œìš°ë‘ ê³µí•­ì— ë„ì°©í–ˆë‹¤.\nìµœ ë¶€ìƒì€ ìµœì¢… ëª©ì ì§€ë¥¼ ë¬»ëŠ” ì·¨ì¬ì§„ì˜ ì§ˆë¬¸ì— ì•„ë¬´ëŸ° ë‹µë³€ì„ í•˜ì§€ ì•Šê³ , ë¶í•œ ëŒ€ì‚¬ê´€ ê´€ê³„ìë“¤ê³¼ í•¨ê»˜ ê³µí•­ì„ ë¹ ì ¸ë‚˜ê°”ë‹¤.\në¶ë¯¸ ì •ìƒíšŒë‹´ì„ 20ì—¬ ì¼ ì•ë‘” ìƒí™©ì—ì„œ ë™ë‚¨ì•„ ì™¸êµí†µì¸ ìµœ ë¶€ìƒì´ ì •ìƒíšŒë‹´ ì¤€ë¹„ ë“±ì„ ìœ„í•´ íšŒë‹´ ê°œìµœ ì˜ˆì •ì§€ì¸ ì‹±ê°€í¬ë¥´ë¥¼ ë°©ë¬¸í•  ê°€ëŠ¥ì„±ë„ ì œê¸°ë˜ê³  ìˆë‹¤.\nìµœ ë¶€ìƒì€ ì§€ë‚œ 3ì›”ì—ë„ ì•„ì„¸ì•ˆ(ASEANÂ·ë™ë‚¨ì•„ì‹œì•„êµ­ê°€ì—°í•©) ì˜ì¥êµ­ì´ê¸°ë„ í•œ ì‹±ê°€í¬ë¥´ë¥¼ ë°©ë¬¸í•´ ì–‘êµ­ê´€ê³„ì™€ ì˜¬í•´ 8ì›” ì—´ë¦¬ëŠ” ì•„ì„¸ì•ˆì§€ì—­ì•ˆë³´í¬ëŸ¼(ARF) ì˜ì œ ë“±ì„ ë…¼ì˜í•œ ë°” ìˆë‹¤.\në˜ ì§€ë‚œí•´ ë¶í•µ ë¬¸ì œë¥¼ ë‘ê³  ë¶ë¯¸ ê°„ ê¸´ì¥ê´€ê³„ê°€ í˜•ì„±ëì„ ë•Œë„ ARFì— ì°¸ì„í•´ ì•„ì„¸ì•ˆì„ ìƒëŒ€ë¡œ ì—¬ë¡ ì „ì„ í¼ì³¤ë‹¤. ë¶í•œì˜ ì´ˆì²­ìœ¼ë¡œ ë¹„ìì´ ì¿ ë§ˆë¥´ ì‹± ì¸ë„ ì™¸êµë¶€ êµ­ë¬´ì¥ê´€ì´ ë°©ë¶í–ˆì„ ë•Œë„ ìµœ ë¶€ìƒì€ ì‹± êµ­ë¬´ì¥ê´€ì„ ì§ì ‘ ì˜ì ‘í•˜ê³ , í•œë°˜ë„ ë¬¸ì œë¥¼ ë…¼ì˜í•˜ê¸°ë„ í–ˆë‹¤.\në² ì´ì§• ì†Œì‹í†µì€ â€œìµœ ë¶€ìƒì´ ëŒ€(å°)ë¯¸ ì™¸êµë‹´ë‹¹ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì‹±ê°€í¬ë¥´ë¡œ ê°ˆ ê°€ëŠ¥ì„±ì´ í° ê²ƒì€ ì•„ë‹ˆë‹¤â€ë©° â€œë§Œì•½ ì‹±ê°€í¬ë¥´ì— ê°„ë‹¤ë©´ ì •ìƒíšŒë‹´ê³¼ ê´€ë ¨í•œ ì§€ì› ì‘ì—… ì¤€ë¹„ ë“±ì„ ìœ„í•œ ê²ƒì¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤â€ê³  ë§í–ˆë‹¤.\nAI ì‘ë‹µ:\n\ní•´ë‹¹ ë‰´ìŠ¤ëŠ” ë¶í•œì˜ ì™¸êµ ì •ì±…ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆì–´ ì •ì¹˜ ë²”ì£¼ì— ì†í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "prompt.html#footnotes",
    "href": "prompt.html#footnotes",
    "title": "chatGPT",
    "section": "ê°ì£¼",
    "text": "ê°ì£¼\n\nLearn Promptingâ†©ï¸\nPrompt Engineering Guideâ†©ï¸"
  },
  {
    "objectID": "prompt.html#ì¸ëª…-ì¶”ì¶œ",
    "href": "prompt.html#ì¸ëª…-ì¶”ì¶œ",
    "title": "chatGPT",
    "section": "\n5.5 ì¸ëª… ì¶”ì¶œ",
    "text": "5.5 ì¸ëª… ì¶”ì¶œ\ní…ìŠ¤íŠ¸ì—ì„œ ì‚¬ëŒ, ì§€ëª…, ë¸Œëœë“œ ë“± ê¸°ê³„ê°€ ì¸ì‹í•´ì„œ ì¶”ì¶œí•˜ëŠ” ì‘ì—…ì„ í†µìƒ ê°œì²´ëª…ì¸ì‹(NER, Named Entity Recognition) ì´ë¼ê³  í•œë‹¤. GPT-3.5, GPT-4ì— ë”°ë¼ ì„±ëŠ¥ì°¨ì´ê°€ ë‹¤ì†Œ ìˆì§€ë§Œ ê¸°ì¡´ ì ‘ê·¼ë²•ê³¼ ë¹„êµí•˜ì—¬ ì†ìƒ‰ì´ ì—†ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œë‹¤ìŒ [í…ìŠ¤íŠ¸]ì— ëŒ€í•´ì„œ ê°œì²´ëª… ì¸ì‹ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ì¸ë¬¼, ì¡°ì§, ì¥ì†Œë¡œ êµ¬ë¶„í•˜ë¼.â€  ì˜ˆ: â€œë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ì—ì„œ ê°œì²´ëª…ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. ì¶œë ¥ í˜•ì‹: ì¸ë¬¼:  ì¡°ì§:  ì¥ì†Œ: â€\n\në„¤ì´ë²„ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ì…‹ì—ì„œ ì •ì¹˜ë‰´ìŠ¤ê¸°ì‚¬ í•˜ë‚˜ë¥¼ ê°€ì ¸ì™”ë‹¤.\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ì—ì„œ ê°œì²´ëª…ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n\n\n\n\n\nì¶œë ¥ í˜•ì‹: ì¸ë¬¼: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;  ì¡°ì§: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;  ì¥ì†Œ: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;  ë‚ ì§œ: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;\në™ë‚¨ì•„ ë‹´ë‹¹â€™ åŒ— ìµœí¬ì²  ë¶€ìƒ ë² ì´ì§• ë„ì°©â€¦ì‹±ê°€í¬ë¥´í–‰ ì£¼ëª© ìµœ ë¶€ìƒ, í–‰ì„ ì§€Â·ë°©ë¬¸ ëª©ì  ì§ˆë¬¸ì—ëŠ” â€˜ë¬µë¬µë¶€ë‹µâ€™\n(ë² ì´ì§•=ì—°í•©ë‰´ìŠ¤) ê¹€ì§„ë°© íŠ¹íŒŒì› = ë¶í•œì´ ë¶ë¯¸ ì •ìƒíšŒë‹´ ë¬´ì‚° ê°€ëŠ¥ì„±ê¹Œì§€ ê±°ë¡ í•˜ë©° ê°•ê²½í•œ íƒœë„ë¥¼ ë³´ì´ëŠ” ê°€ìš´ë° ë™ë‚¨ì•„ì‹œì•„ ì™¸êµë¥¼ ë‹´ë‹¹í•˜ëŠ” ìµœí¬ì²  ë¶í•œ ì™¸ë¬´ì„± ë¶€ìƒì´ 19ì¼ ì¤‘êµ­ ë² ì´ì§• ì„œìš°ë‘(é¦–éƒ½) ê³µí•­ì— ëª¨ìŠµì„ ë“œëŸ¬ëƒˆë‹¤.\nìµœ ë¶€ìƒì€ ì´ë‚  ì˜¤ì „ í‰ì–‘ë°œ ê³ ë ¤í•­ê³µ JS151í¸ì„ ì´ìš©í•´ ë² ì´ì§• ì„œìš°ë‘ ê³µí•­ì— ë„ì°©í–ˆë‹¤.\nìµœ ë¶€ìƒì€ ìµœì¢… ëª©ì ì§€ë¥¼ ë¬»ëŠ” ì·¨ì¬ì§„ì˜ ì§ˆë¬¸ì— ì•„ë¬´ëŸ° ë‹µë³€ì„ í•˜ì§€ ì•Šê³ , ë¶í•œ ëŒ€ì‚¬ê´€ ê´€ê³„ìë“¤ê³¼ í•¨ê»˜ ê³µí•­ì„ ë¹ ì ¸ë‚˜ê°”ë‹¤.\në¶ë¯¸ ì •ìƒíšŒë‹´ì„ 20ì—¬ ì¼ ì•ë‘” ìƒí™©ì—ì„œ ë™ë‚¨ì•„ ì™¸êµí†µì¸ ìµœ ë¶€ìƒì´ ì •ìƒíšŒë‹´ ì¤€ë¹„ ë“±ì„ ìœ„í•´ íšŒë‹´ ê°œìµœ ì˜ˆì •ì§€ì¸ ì‹±ê°€í¬ë¥´ë¥¼ ë°©ë¬¸í•  ê°€ëŠ¥ì„±ë„ ì œê¸°ë˜ê³  ìˆë‹¤.\nìµœ ë¶€ìƒì€ ì§€ë‚œ 3ì›”ì—ë„ ì•„ì„¸ì•ˆ(ASEANÂ·ë™ë‚¨ì•„ì‹œì•„êµ­ê°€ì—°í•©) ì˜ì¥êµ­ì´ê¸°ë„ í•œ ì‹±ê°€í¬ë¥´ë¥¼ ë°©ë¬¸í•´ ì–‘êµ­ê´€ê³„ì™€ ì˜¬í•´ 8ì›” ì—´ë¦¬ëŠ” ì•„ì„¸ì•ˆì§€ì—­ì•ˆë³´í¬ëŸ¼(ARF) ì˜ì œ ë“±ì„ ë…¼ì˜í•œ ë°” ìˆë‹¤.\në˜ ì§€ë‚œí•´ ë¶í•µ ë¬¸ì œë¥¼ ë‘ê³  ë¶ë¯¸ ê°„ ê¸´ì¥ê´€ê³„ê°€ í˜•ì„±ëì„ ë•Œë„ ARFì— ì°¸ì„í•´ ì•„ì„¸ì•ˆì„ ìƒëŒ€ë¡œ ì—¬ë¡ ì „ì„ í¼ì³¤ë‹¤. ë¶í•œì˜ ì´ˆì²­ìœ¼ë¡œ ë¹„ìì´ ì¿ ë§ˆë¥´ ì‹± ì¸ë„ ì™¸êµë¶€ êµ­ë¬´ì¥ê´€ì´ ë°©ë¶í–ˆì„ ë•Œë„ ìµœ ë¶€ìƒì€ ì‹± êµ­ë¬´ì¥ê´€ì„ ì§ì ‘ ì˜ì ‘í•˜ê³ , í•œë°˜ë„ ë¬¸ì œë¥¼ ë…¼ì˜í•˜ê¸°ë„ í–ˆë‹¤.\në² ì´ì§• ì†Œì‹í†µì€ â€œìµœ ë¶€ìƒì´ ëŒ€(å°)ë¯¸ ì™¸êµë‹´ë‹¹ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì‹±ê°€í¬ë¥´ë¡œ ê°ˆ ê°€ëŠ¥ì„±ì´ í° ê²ƒì€ ì•„ë‹ˆë‹¤â€ë©° â€œë§Œì•½ ì‹±ê°€í¬ë¥´ì— ê°„ë‹¤ë©´ ì •ìƒíšŒë‹´ê³¼ ê´€ë ¨í•œ ì§€ì› ì‘ì—… ì¤€ë¹„ ë“±ì„ ìœ„í•œ ê²ƒì¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤â€ê³  ë§í–ˆë‹¤.\nAI ì‘ë‹µ:\n\nì¸ë¬¼: ìµœí¬ì² , ê¹€ì§„ë°©, ë¹„ìì´ ì¿ ë§ˆë¥´ ì‹±  ì¡°ì§: ì—°í•©ë‰´ìŠ¤, ë¶í•œ ì™¸ë¬´ì„±, ê³ ë ¤í•­ê³µ, ì•„ì„¸ì•ˆ(ASEANÂ·ë™ë‚¨ì•„ì‹œì•„êµ­ê°€ì—°í•©), ì•„ì„¸ì•ˆì§€ì—­ì•ˆë³´í¬ëŸ¼(ARF), ì¸ë„ ì™¸êµë¶€  ì¥ì†Œ: ë² ì´ì§•, ì„œìš°ë‘(é¦–éƒ½) ê³µí•­, í‰ì–‘, ì‹±ê°€í¬ë¥´, ë¶í•œ ëŒ€ì‚¬ê´€  ë‚ ì§œ: 19ì¼, 20ì—¬ ì¼, ì§€ë‚œ 3ì›”, ì˜¬í•´ 8ì›”, ì§€ë‚œí•´"
  },
  {
    "objectID": "prompt.html#ê°œì²´ëª…-ì¶”ì¶œ",
    "href": "prompt.html#ê°œì²´ëª…-ì¶”ì¶œ",
    "title": "chatGPT",
    "section": "\n5.5 ê°œì²´ëª… ì¶”ì¶œ",
    "text": "5.5 ê°œì²´ëª… ì¶”ì¶œ\ní…ìŠ¤íŠ¸ì—ì„œ ì‚¬ëŒ, ì§€ëª…, ë¸Œëœë“œ ë“± ê¸°ê³„ê°€ ì¸ì‹í•´ì„œ ì¶”ì¶œí•˜ëŠ” ì‘ì—…ì„ í†µìƒ ê°œì²´ëª…ì¸ì‹(NER, Named Entity Recognition) ì´ë¼ê³  í•œë‹¤. GPT-3.5, GPT-4ì— ë”°ë¼ ì„±ëŠ¥ì°¨ì´ê°€ ë‹¤ì†Œ ìˆì§€ë§Œ ê¸°ì¡´ ì ‘ê·¼ë²•ê³¼ ë¹„êµí•˜ì—¬ ì†ìƒ‰ì´ ì—†ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œë‹¤ìŒ [í…ìŠ¤íŠ¸]ì— ëŒ€í•´ì„œ ê°œì²´ëª… ì¸ì‹ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ì¸ë¬¼, ì¡°ì§, ì¥ì†Œë¡œ êµ¬ë¶„í•˜ë¼.â€  ì˜ˆ: â€œë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ì—ì„œ ê°œì²´ëª…ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. ì¶œë ¥ í˜•ì‹: ì¸ë¬¼:  ì¡°ì§:  ì¥ì†Œ: â€\n\në„¤ì´ë²„ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°ì´í„°ì…‹ì—ì„œ ì •ì¹˜ë‰´ìŠ¤ê¸°ì‚¬ í•˜ë‚˜ë¥¼ ê°€ì ¸ì™”ë‹¤.\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ì—ì„œ ê°œì²´ëª…ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n\n\n\n\n\nì¶œë ¥ í˜•ì‹: ì¸ë¬¼: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;  ì¡°ì§: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;  ì¥ì†Œ: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;  ë‚ ì§œ: &lt;ì¶œë ¥ê²°ê³¼ë¥¼ ì½¤ë§ˆ êµ¬ë¶„ìë¡œ êµ¬ë¶„&gt;\në™ë‚¨ì•„ ë‹´ë‹¹â€™ åŒ— ìµœí¬ì²  ë¶€ìƒ ë² ì´ì§• ë„ì°©â€¦ì‹±ê°€í¬ë¥´í–‰ ì£¼ëª© ìµœ ë¶€ìƒ, í–‰ì„ ì§€Â·ë°©ë¬¸ ëª©ì  ì§ˆë¬¸ì—ëŠ” â€˜ë¬µë¬µë¶€ë‹µâ€™\n(ë² ì´ì§•=ì—°í•©ë‰´ìŠ¤) ê¹€ì§„ë°© íŠ¹íŒŒì› = ë¶í•œì´ ë¶ë¯¸ ì •ìƒíšŒë‹´ ë¬´ì‚° ê°€ëŠ¥ì„±ê¹Œì§€ ê±°ë¡ í•˜ë©° ê°•ê²½í•œ íƒœë„ë¥¼ ë³´ì´ëŠ” ê°€ìš´ë° ë™ë‚¨ì•„ì‹œì•„ ì™¸êµë¥¼ ë‹´ë‹¹í•˜ëŠ” ìµœí¬ì²  ë¶í•œ ì™¸ë¬´ì„± ë¶€ìƒì´ 19ì¼ ì¤‘êµ­ ë² ì´ì§• ì„œìš°ë‘(é¦–éƒ½) ê³µí•­ì— ëª¨ìŠµì„ ë“œëŸ¬ëƒˆë‹¤.\nìµœ ë¶€ìƒì€ ì´ë‚  ì˜¤ì „ í‰ì–‘ë°œ ê³ ë ¤í•­ê³µ JS151í¸ì„ ì´ìš©í•´ ë² ì´ì§• ì„œìš°ë‘ ê³µí•­ì— ë„ì°©í–ˆë‹¤.\nìµœ ë¶€ìƒì€ ìµœì¢… ëª©ì ì§€ë¥¼ ë¬»ëŠ” ì·¨ì¬ì§„ì˜ ì§ˆë¬¸ì— ì•„ë¬´ëŸ° ë‹µë³€ì„ í•˜ì§€ ì•Šê³ , ë¶í•œ ëŒ€ì‚¬ê´€ ê´€ê³„ìë“¤ê³¼ í•¨ê»˜ ê³µí•­ì„ ë¹ ì ¸ë‚˜ê°”ë‹¤.\në¶ë¯¸ ì •ìƒíšŒë‹´ì„ 20ì—¬ ì¼ ì•ë‘” ìƒí™©ì—ì„œ ë™ë‚¨ì•„ ì™¸êµí†µì¸ ìµœ ë¶€ìƒì´ ì •ìƒíšŒë‹´ ì¤€ë¹„ ë“±ì„ ìœ„í•´ íšŒë‹´ ê°œìµœ ì˜ˆì •ì§€ì¸ ì‹±ê°€í¬ë¥´ë¥¼ ë°©ë¬¸í•  ê°€ëŠ¥ì„±ë„ ì œê¸°ë˜ê³  ìˆë‹¤.\nìµœ ë¶€ìƒì€ ì§€ë‚œ 3ì›”ì—ë„ ì•„ì„¸ì•ˆ(ASEANÂ·ë™ë‚¨ì•„ì‹œì•„êµ­ê°€ì—°í•©) ì˜ì¥êµ­ì´ê¸°ë„ í•œ ì‹±ê°€í¬ë¥´ë¥¼ ë°©ë¬¸í•´ ì–‘êµ­ê´€ê³„ì™€ ì˜¬í•´ 8ì›” ì—´ë¦¬ëŠ” ì•„ì„¸ì•ˆì§€ì—­ì•ˆë³´í¬ëŸ¼(ARF) ì˜ì œ ë“±ì„ ë…¼ì˜í•œ ë°” ìˆë‹¤.\në˜ ì§€ë‚œí•´ ë¶í•µ ë¬¸ì œë¥¼ ë‘ê³  ë¶ë¯¸ ê°„ ê¸´ì¥ê´€ê³„ê°€ í˜•ì„±ëì„ ë•Œë„ ARFì— ì°¸ì„í•´ ì•„ì„¸ì•ˆì„ ìƒëŒ€ë¡œ ì—¬ë¡ ì „ì„ í¼ì³¤ë‹¤. ë¶í•œì˜ ì´ˆì²­ìœ¼ë¡œ ë¹„ìì´ ì¿ ë§ˆë¥´ ì‹± ì¸ë„ ì™¸êµë¶€ êµ­ë¬´ì¥ê´€ì´ ë°©ë¶í–ˆì„ ë•Œë„ ìµœ ë¶€ìƒì€ ì‹± êµ­ë¬´ì¥ê´€ì„ ì§ì ‘ ì˜ì ‘í•˜ê³ , í•œë°˜ë„ ë¬¸ì œë¥¼ ë…¼ì˜í•˜ê¸°ë„ í–ˆë‹¤.\në² ì´ì§• ì†Œì‹í†µì€ â€œìµœ ë¶€ìƒì´ ëŒ€(å°)ë¯¸ ì™¸êµë‹´ë‹¹ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì‹±ê°€í¬ë¥´ë¡œ ê°ˆ ê°€ëŠ¥ì„±ì´ í° ê²ƒì€ ì•„ë‹ˆë‹¤â€ë©° â€œë§Œì•½ ì‹±ê°€í¬ë¥´ì— ê°„ë‹¤ë©´ ì •ìƒíšŒë‹´ê³¼ ê´€ë ¨í•œ ì§€ì› ì‘ì—… ì¤€ë¹„ ë“±ì„ ìœ„í•œ ê²ƒì¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤â€ê³  ë§í–ˆë‹¤.\nAI ì‘ë‹µ:\n\nì¸ë¬¼: ìµœí¬ì² , ê¹€ì§„ë°©, ë¹„ìì´ ì¿ ë§ˆë¥´ ì‹±  ì¡°ì§: ì—°í•©ë‰´ìŠ¤, ë¶í•œ ì™¸ë¬´ì„±, ê³ ë ¤í•­ê³µ, ì•„ì„¸ì•ˆ(ASEANÂ·ë™ë‚¨ì•„ì‹œì•„êµ­ê°€ì—°í•©), ì•„ì„¸ì•ˆì§€ì—­ì•ˆë³´í¬ëŸ¼(ARF), ì¸ë„ ì™¸êµë¶€  ì¥ì†Œ: ë² ì´ì§•, ì„œìš°ë‘(é¦–éƒ½) ê³µí•­, í‰ì–‘, ì‹±ê°€í¬ë¥´, ë¶í•œ ëŒ€ì‚¬ê´€  ë‚ ì§œ: 19ì¼, 20ì—¬ ì¼, ì§€ë‚œ 3ì›”, ì˜¬í•´ 8ì›”, ì§€ë‚œí•´"
  },
  {
    "objectID": "prompt.html#ì§ˆì˜ì‘ë‹µ",
    "href": "prompt.html#ì§ˆì˜ì‘ë‹µ",
    "title": "chatGPT",
    "section": "\n5.6 ì§ˆì˜ì‘ë‹µ",
    "text": "5.6 ì§ˆì˜ì‘ë‹µ\nì§€ë¬¸ì´ ì£¼ì–´ì§„ ìƒíƒœì—ì„œ ì‚¬ëŒì´ ì§ˆë¬¸ì„ í•˜ë©´ ê¸°ê³„ê°€ ë‹µì„ í•˜ëŠ” ìƒí™©ì´ë‹¤. ì „ë¬¸ì ì´ê³  ë§¤ìš° ê¸´ ì§€ë¬¸ì—ì„œ ì›í•˜ëŠ” ë‹µì„ ì°¾ê¸° ìœ„í•´ ì§ˆë¬¸ì„ í•˜ëŠ” ìƒí™©ì—ì„œ ìœ ìš©í•˜ë‹¤.\n\ní”„ë¡¬í”„íŠ¸: â€œë‹¤ìŒ [ì§€ë¬¸]ì—ì„œ [ì§ˆë¬¸]ì— ë‹µí•˜ì‹œì˜¤â€  ì˜ˆ: â€œë‹¤ìŒ ì§€ë¬¸ì„ ì½ê³  ë‹µì„ ì°¾ìœ¼ì„¸ìš”. ì§ˆë¬¸: ê¹€í˜„ì›…ì€ ì„œìš¸ê³ ë“±ê²€ì°°ì²­ ê²€ì‚¬ì¥ ì¬ì§ ì¤‘ì— ëª‡ëŒ€ ë²•ë¬´ë¶€ ì¥ê´€ì— ì„ìš©ë˜ì—ˆë‚˜?\nì§€ë¬¸: ê¹€í˜„ì›…(é‡‘è³¢é›„, 1959ë…„ 5ì›” 4ì¼ ~ , ì „ë‚¨ ê³ í¥)ì€ â€¦ â€\n\nKorQuAD 2.0ëŠ” KorQuAD 1.0ì—ì„œ ì§ˆë¬¸ë‹µë³€ 20,000+ ìŒì„ í¬í•¨í•˜ì—¬ ì´ 100,000+ ìŒìœ¼ë¡œ êµ¬ì„±ëœ í•œêµ­ì–´ Machine Reading Comprehension ë°ì´í„°ì…‹ìœ¼ë¡œ, KorQuAD 1.0ê³¼ëŠ” ë‹¤ë¥´ê²Œ 1~2 ë¬¸ë‹¨ì´ ì•„ë‹Œ Wikipedia article ì „ì²´ì—ì„œ ë‹µì„ ì°¾ì•„ì•¼ í•œë‹¤. KorQuAD ë°ì´í„°ì…‹ì—ì„œ ì‚¬ë¡€ë¥¼ í•˜ë‚˜ ê°€ì ¸ì™€ì„œ ì§ˆì˜ì‘ë‹µì„ í’€ì–´ë³¸ë‹¤.\n\nì‹¤ì œ ì •ë‹µ ë¼ë²¨: [{'text': 'ì œ64ëŒ€', 'answer_start': 209}]\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ ì§€ë¬¸ì„ ì½ê³  ë‹µì„ ì°¾ìœ¼ì„¸ìš”.\n\n\n\n\n\nì§ˆë¬¸: ê¹€í˜„ì›…ì€ ì„œìš¸ê³ ë“±ê²€ì°°ì²­ ê²€ì‚¬ì¥ ì¬ì§ ì¤‘ì— ëª‡ëŒ€ ë²•ë¬´ë¶€ ì¥ê´€ì— ì„ìš©ë˜ì—ˆë‚˜?\nì§€ë¬¸: ê¹€í˜„ì›…(é‡‘è³¢é›„, 1959ë…„ 5ì›” 4ì¼ ~ , ì „ë‚¨ ê³ í¥)ì€ ëŒ€í•œë¯¼êµ­ì˜ ë²•ë¥ ê°€ì´ë‹¤. ì‚¬ë²•ì—°ìˆ˜ì› 16ê¸° ìˆ˜ë£Œ í›„ ê²€ì‚¬ ìƒí™œì„ í–ˆìœ¼ë©° íŠ¹íˆ ì„œìš¸ì¤‘ì•™ì§€ê²€ íŠ¹ìˆ˜1ë¶€ ë¶€ì¥ê²€ì‚¬ë¡œ ì¬ì§í•  ë•ŒëŠ” ë²•ì¡°ë¸Œë¡œì»¤ ê¹€í™ìˆ˜ì”¨(58Â·êµ¬ì†)ë¡œë¶€í„° ê¸ˆí’ˆì„ ë°›ì€ í˜ì˜(ì•Œì„ ìˆ˜ì¬)ë¡œ ì‚¬ìƒ ìµœì´ˆë¡œ ì „ì§ ê³ ë“± ë²•ì› ë¶€ì¥íŒì‚¬ê¸‰ ë²•ê´€ Aì”¨ì— ëŒ€í•´ ì‚¬ì „ êµ¬ì†ì˜ì¥ì„ ì²­êµ¬í–ˆë‹¤. ì´í›„ ì œ46ëŒ€ ì„œìš¸ê³ ë“±ê²€ì°°ì²­ ê²€ì‚¬ì¥ ì¬ì§ ì¤‘ ì œ64ëŒ€ ë²•ë¬´ë¶€ ì¥ê´€ì— ì„ìš©ë˜ì—ˆë‹¤. ëŒ€í•œë³€í˜¸ì‚¬í˜‘íšŒ(íšŒì¥ ê¹€í˜„)ê°€ ê¹€í˜„ì›…(58Â·ì‚¬ë²•ì—°ìˆ˜ì› 16ê¸°) ì „ ë²•ë¬´ë¶€ ì¥ê´€ì—ê²Œ ë³€í˜¸ì‚¬ ê°œì—…ì„ ìì œí•  ê²ƒì„ ê¶Œê³ í–ˆë‹¤. ë³€í˜‘ì€ ë³´ ë„ìë£Œë¥¼ í†µí•´ â€œê¹€í˜„ì›… ì „ ì¥ê´€ì€ ì§€ë‚œ 4ì›”27ì¼ ë³€í˜¸ì‚¬ ë“±ë¡ì„ ì‹ ì²­í–ˆê³ , í˜„í–‰ ë³€í˜¸ì‚¬ë²•ìƒ ë“±ë¡ ê±°ë¶€ ì‚¬ìœ ê°€ ì—†ë‹¤â€ë¼ë©° â€œë³€í˜¸ì‚¬ë²•ì€ ë“±ë¡ ì‹ ì²­ì¼ë¡œë¶€í„° 3ê°œì›”ê°„ ë“±ë¡ì„ í•˜ì§€ ì•Šì„ ê²½ìš° ë“±ë¡ì´ ê°„ì£¼ëœë‹¤ê³  ê·œì •í•˜ê³  ìˆë‹¤â€ë¼ê³  ì„¤ëª…í–ˆë‹¤.\nAI ì‘ë‹µ:\n\nê¹€í˜„ì›…ì€ ì„œìš¸ê³ ë“±ê²€ì°°ì²­ ê²€ì‚¬ì¥ ì¬ì§ ì¤‘ì— ì œ64ëŒ€ ë²•ë¬´ë¶€ ì¥ê´€ì— ì„ìš©ë˜ì—ˆë‹¤."
  },
  {
    "objectID": "prompt.html#ê°ê´€ì‹-ë¬¸ì œ",
    "href": "prompt.html#ê°ê´€ì‹-ë¬¸ì œ",
    "title": "chatGPT",
    "section": "\n5.7 ê°ê´€ì‹ ë¬¸ì œ",
    "text": "5.7 ê°ê´€ì‹ ë¬¸ì œ\nì£¼ì–´ì§„ 4ê°œ ì¤‘ì—ì„œ ì •ë‹µì„ í•˜ë‚˜ ê³ ë¥´ëŠ” ë¬¸ì œë¥¼ ì‚¬ì§€ì„ ë‹¤(å››æé¸å¤š)í˜• ì‹œí—˜ë¬¸ì œë¡œ í•™ì°½ì‹œì ˆë¶€í„° ì ‘í•´ ì¹œìˆ™í•˜ë‹¤. ì‚¬ì§€ì„ ë‹¤ ë¬¸ì œë¥¼ í’€ê³  ë¬¸ì œë„ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì œì‘í•´ë³´ì.\n\ní”„ë¡¬í”„íŠ¸: â€œë‹¤ìŒ [ì„ íƒì§€] ì¤‘ì—ì„œ ì •ë‹µì„ í•˜ë‚˜ ê³ ë¥´ì„¸ìš”.â€  ì˜ˆ: â€œë‹¤ìŒ ë¬¸ì œì—ì„œ ì •ë‹µì„ í•˜ë‚˜ ê³ ë¥´ì„¸ìš”. ë¬¸ì œ: í†µê³„ì—ì„œ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” ì§‘í•©ì„ ì¼ì»·ëŠ” ìš©ì–´ëŠ”?\n\ní‘œë³¸ ê³µê°„(Sample Space)\ní¬í•¨ì§‘í•©(Super Set)\ní¬í•¨ê³µê°„(Super Space)\ní‘œë³¸ì§‘í•©(Sample Set) â€\n\n\n\nì •ë‹µê³¼ ì´ìœ ë„ ì¶”ê°€í•˜ê³  ìœ ì‚¬í•œ ì‚¬ì§€ì„ ë‹¤í˜• ë¬¸ì œë¥¼ ëª‡ê°œ ë§Œë“¤ì–´ ì§€ì‹œí•œë‹¤.\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: í†µê³„ì—ì„œ ë‘ ë³€ìˆ˜ ê°„ì˜ ìƒê´€ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€ìˆ˜ëŠ”?\n\n\n\n\n\n\nì¤‘ì•™ê°’(Median)\ní‰ê· (Average)\në¶„ì‚°(Variance)\nìƒê´€ê³„ìˆ˜(Correlation Coefficient)\n\nAI ì‘ë‹µ:\n\nì •ë‹µ: 4. ìƒê´€ê³„ìˆ˜(Correlation Coefficient) ì´ìœ : í†µê³„ì—ì„œ ë‘ ë³€ìˆ˜ ê°„ì˜ ê´€ë ¨ì„±ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ê°€ ìƒê´€ê³„ìˆ˜ì…ë‹ˆë‹¤. ìƒê´€ê³„ìˆ˜ëŠ” -1ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì–‘ì˜ ìƒê´€ê´€ê³„, -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìŒì˜ ìƒê´€ê´€ê³„, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìƒê´€ê´€ê³„ê°€ ì—†ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "open_source.html",
    "href": "open_source.html",
    "title": "chatGPT",
    "section": "",
    "text": "Guido Appenzeller, Matt Bornstein, Martin Casado, and Yoko Li, â€œArt Isnâ€™t Dead, Itâ€™s Just Machine-Generated - Why AI models will replace artists long before theyâ€™ll replace programmersâ€\nì˜¤í”ˆ ì†ŒìŠ¤ AI ëª¨ë¸ Stable Diffusion V1ì€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ìˆ˜ë°± ê°œì˜ ë‹¤ë¥¸ ëª¨ë¸ê³¼ í˜ì‹ ì„ ë‚³ì•˜ë‹¤. ë‘ ë‹¬ë„ ì±„ ë˜ì§€ ì•Šì•„ 33,000ê°œì˜ ë³„ì„ ëŒíŒŒí•˜ë©° ëª¨ë“  ì†Œí”„íŠ¸ì›¨ì–´ ì¤‘ ê°€ì¥ ë¹ ë¥´ê²Œ Github ë³„ 10,000ê°œì— ë„ë‹¬í–ˆê³ , ì´ëŠ” ì´ì „ì˜ ë‹¤ë¥¸ í˜ì‹ ì ì¸ ê¸°ìˆ  ë¹„íŠ¸ì½”ì¸, ì´ë”ë¦¬ì›€, ì¹´í”„ì¹´, ìŠ¤íŒŒí¬ ë“±ê³¼ ë¹„êµí•˜ë©´ ê·¸ íŒŒê¸‰ë ¥ì´ ê°ˆìŒëœë‹¤. ìµœê·¼ ê³µê°œ(March 24, 2023)ëœ Stable Diffusion V2ëŠ” GitHub stablediffusionì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ë‹¤.\n\n\n\n\n\ní˜ì´ìŠ¤ë¶ìœ¼ë¡œ ì˜ ì•Œë ¤ì§„ ë©”íƒ€(Meta)ëŠ” ì—°êµ¬ ëª©ì (ë¹„ìƒì—…ì  ì‚¬ìš©)ìœ¼ë¡œ ë¼ë§ˆ(LLaMA) ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì„ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ë¡œ 2023ë…„ 2ì›” 24ì¼ ê³µê°œí–ˆë‹¤. LLaMAëŠ” ë¼í‹´ì–´ì™€ í‚¤ë¦´ ë¬¸ìë¥¼ ì‚¬ìš©í•˜ëŠ” 20ê°œ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ë¥¼ í•™ìŠµí•˜ì—¬ ë‹¤ì–‘í•œ í¬ê¸°(7B, 13B, 33B, 65B ë§¤ê°œë³€ìˆ˜) ì–¸ì–´ëª¨í˜• í˜•íƒœë¡œ ê³µê°œë˜ì–´ ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì„ ëŒ€ì¤‘í™”í•˜ê³  ì—°êµ¬ìë“¤ì´ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ê³¼ ì‚¬ìš© ì‚¬ë¡€ë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ì·¨ì§€ë¡œ ê³µê°œë˜ì—ˆì§€ë§Œ, ì—¬ì „íˆ í¸í–¥ì„±, ë…ì„±, ì˜ëª»ëœ ì •ë³´ ë“± ì¶”ê°€ì ì¸ ë³´ì™„ì´ í•„ìš”í•˜ë‹¤.\nMetaAI (February 24, 2023), â€œIntroducing LLaMA: A foundational, 65-billion-parameter large language modelâ€, MetaAI Blog"
  },
  {
    "objectID": "nlp_LLM.html",
    "href": "nlp_LLM.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ìì—°ì–´ ì²˜ë¦¬\nìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ë¡œ í•˜ì—¬ê¸ˆ ì‚¬ëŒì´ ì‘ì„±í•œ ì–¸ì–´(ìŒì„±ê³¼ ê¸€)ì˜ ì˜ë¯¸ë¥¼ ì´í•´ì‹œí‚¤ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.\n\ní…ìŠ¤íŠ¸ ë°ì´í„°\n\níŠ¸ìœ„í„°\nì†Œì„¤, ì‹ ë¬¸ê¸°ì‚¬\nê³ ê° í‰ì ê³¼ ë¦¬ë·°\nì „ììš°í¸\nì˜ë¬´ê¸°ë¡\nâ€¦\n\n\ní…ìŠ¤íŠ¸ ì €ì¥ í˜•ì‹\n\në‰´ìŠ¤ ë“± ì›¹ í˜ì´ì§€\nPDF/ì›Œë“œ/í•œê¸€ ë¬¸ì„œ\níŠ¸ìœ„í„° ë“± SNS, RSS í”¼ë“œ, ëŒ“ê¸€\nâ€¦\n\n\nì‘ìš©ë¶„ì•¼\n\nê°ì„±ë¶„ì„\ní…ìŠ¤íŠ¸ ë¶„ë¥˜\në²ˆì—­\nì±—ë´‡\nê°œì¸ ë¹„ì„œ\nâ€¦\n\n\nê¸°ìˆ \n\në‹¨ì–´ì£¼ë¨¸ë‹ˆ(Bag of Words)\nWord Embedding, ì›Œë“œíˆ¬ë²¡(Word2Vec)\nRNN, LSTM\nBERT, Transformer\nGPT, ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)\nâ€¦\n\n\n\n2 ì‘ì—…íë¦„\nê°ì„± ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë“± í…ìŠ¤íŠ¸ë¥¼ ë°ì´í„°ë¡œ í•˜ëŠ” ì „í†µì ì¸ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì€ ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…íë¦„ì„ ê°–ê²Œ ëœë‹¤.\n\n\n\n\n\n\ngraph TD\n    A[ë°ì´í„° ìˆ˜ì§‘] --&gt; B[ë°ì´í„° ì „ì²˜ë¦¬]\n    B --&gt; C[í”¼ì³ ì¶”ì¶œ]\n    C --&gt; D[í›ˆë ¨-í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„í• ]\n    D --&gt; E[ëª¨í˜• ì„ íƒ]\n    E --&gt; F[ëª¨í˜• í•™ìŠµ]\n    F --&gt; G[ëª¨í˜• í‰ê°€]\n    G --&gt; H[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]\n    H --&gt; I[ëª¨í˜• ë°°í¬]\n    I --&gt; J[ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜]\n\n\n\n\n\n\n\në°ì´í„° ìˆ˜ì§‘: í…ìŠ¤íŠ¸ ë°ì´í„°ì™€ í•´ë‹¹ ë ˆì´ë¸”ì´ í¬í•¨ëœ ë°ì´í„°ì…‹ì„ ìˆ˜ì§‘í•œë‹¤. ê°ì„± ë¶„ì„ì˜ ê²½ìš°, ë¼ë²¨ì€ â€˜ê¸ì •â€™, â€˜ë¶€ì •â€™ ë˜ëŠ” â€™ì¤‘ë¦½â€™ì´ ë˜ê³ , í…ìŠ¤íŠ¸ ë¶„ë¥˜ì˜ ê²½ìš° ë ˆì´ë¸”ì€ ë‹¤ì–‘í•œ ì£¼ì œë‚˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì¦‰, ìì—°ì–´ ì²˜ë¦¬ ëª©ì ì— ë§ì¶° ë¼ë²¨ì„ íŠ¹ì •í•˜ê³  ì—°ê´€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œë‹¤.\në°ì´í„° ì „ì²˜ë¦¬: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ ì¶”ê°€ ë¶„ì„ì— ì í•©í•˜ë„ë¡ ì‘ì—…í•˜ëŠ”ë° ì†Œë¬¸ìí™”, í† í°í™”, ë¶ˆìš©ì–´ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì–´ê°„ ë‹¨ì–´ ê¸°ë³¸í˜•ìœ¼ë¡œ ì¤„ì´ê¸° ë“±ì´ í¬í•¨ëœë‹¤.\ní”¼ì³ ì¶”ì¶œ:ì‚¬ì „ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì— ì í•©í•œ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ BoW, TF-IDF, ë‹¨ì–´ ì„ë² ë”© ë“±ì´ í”íˆ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì´ë‹¤.\ní›ˆë ¨-ì‹œí—˜ ë°ì´í„°ì…‹ ë¶„í• : ì¼ë°˜ì ìœ¼ë¡œ 70-30, 80-20 ë˜ëŠ” ê¸°íƒ€ ì›í•˜ëŠ” ë¶„í•  ë¹„ìœ¨ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ í›ˆë ¨ê³¼ ì‹œí—˜ ë°ì´í„°ì…‹ìœ¼ë¡œ êµ¬ë¶„í•œë‹¤.\nëª¨í˜• ì„ íƒ: ì í•©í•œ í†µê³„, ë¨¸ì‹  ëŸ¬ë‹, ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì„ ì •í•œë‹¤.\nëª¨í˜• í•™ìŠµ: ì ì ˆí•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ê³¼ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ ì„ íƒí•œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.\nëª¨í˜• í‰ê°€: ì •í™•ë„, ì •ë°€ë„, ë¦¬ì½œ, F1 ì ìˆ˜ ë˜ëŠ” ROC ê³¡ì„  ì•„ë˜ ì˜ì—­ê³¼ ê°™ì€ ê´€ë ¨ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ì‹œí—˜ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤.\ní•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: ê²©ì ê²€ìƒ‰ ë˜ëŠ” ë¬´ì‘ìœ„ ê²€ìƒ‰ê³¼ ê°™ì€ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ëª¨í˜•ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•œë‹¤.\nëª¨í˜• ë°°í¬: ëª¨í˜•ì„ í•™ìŠµí•˜ê³  ìµœì í™”í•œ í›„ì—ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì— ë°°í¬í•˜ì—¬ ê°€ì¹˜ë¥¼ ì°½ì¶œí•œë‹¤.\nëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ ê´€ë¦¬: ë°°í¬ëœ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì— ë”°ë¼ ìƒˆë¡œìš´ í•™ìŠµë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•œë‹¤.\n\n\n\n\n3 ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…\nìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ í”íˆ ì ‘í•˜ëŠ” ìƒìœ„ 10ê°€ì§€ NLPìœ¼ë¡œ ë‹¤ìŒì„ ë“¤ ìˆ˜ ìˆë‹¤.\n\nê°ì • ë¶„ì„: ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ë“± ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— í‘œí˜„ëœ ê°ì •ì„ íŒŒì•….\ní…ìŠ¤íŠ¸ ë¶„ë¥˜: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •ì˜ëœ í´ë˜ìŠ¤ ë˜ëŠ” ì£¼ì œ(ì˜ˆ: ìŠ¤í¬ì¸ , ì •ì¹˜, ì—°ì˜ˆ ë“±)ë¡œ ë¶„ë¥˜.\nê°œì²´ëª… ì¸ì‹(NER): í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì‚¬ëŒ, ì¡°ì§, ìœ„ì¹˜, ë‚ ì§œ ë“±ì˜ ëª…ëª…ëœ ê°œì²´(entity)ë¥¼ ì‹ë³„í•˜ê³  ë¶„ë¥˜.\ní’ˆì‚¬(POS) íƒœê¹…: ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ë‹¨ì–´ì— ë¬¸ë²•ì  ë ˆì´ë¸”(ì˜ˆ: ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬)ì„ í• ë‹¹.\nì˜ì¡´ì„± êµ¬ë¬¸ ë¶„ì„: ë¬¸ì¥ ë‚´ ë‹¨ì–´ ê°„ì˜ ë¬¸ë²• êµ¬ì¡°ì™€ ê´€ê³„ë¥¼ ì‹ë³„.\nê¸°ê³„ ë²ˆì—­: ì˜ì–´ì—ì„œ ìŠ¤í˜ì¸ì–´ë¡œ ë˜ëŠ” ì¤‘êµ­ì–´ì—ì„œ í”„ë‘ìŠ¤ì–´ë¡œì™€ ê°™ì´ í•œ ì–¸ì–´ì—ì„œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­.\nì§ˆì˜ ì‘ë‹µ: ìì—°ì–´ë¡œ ì œê¸°ëœ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ê°œë°œ.\ní…ìŠ¤íŠ¸ ìš”ì•½: ì£¼ìš” ì•„ì´ë””ì–´ì™€ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ì„ ìƒì„±.\nìƒí˜¸ì°¸ì¡°í•´ê²°(Coreference Resolution): í…ìŠ¤íŠ¸ì—ì„œ ë‘ ê°œ ì´ìƒì˜ ë‹¨ì–´ë‚˜ êµ¬ê°€ ë™ì¼í•œ ê°œì²´ ë˜ëŠ” ê°œë…ì„ ì§€ì¹­í•˜ëŠ” ê²½ìš° ì‹ë³„.\ní…ìŠ¤íŠ¸ ìƒì„±: ì£¼ì–´ì§„ ì…ë ¥, ì»¨í…ìŠ¤íŠ¸ ë˜ëŠ” ì¼ë ¨ì˜ ì¡°ê±´ì— ë”°ë¼ ì¼ê´€ë˜ê³  ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±.\n\nìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ê³¼ ì‘ì—…íë¦„ì„ ì„œë¡œ ì—°ê²°í•˜ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê°œë³„ì ìœ¼ë¡œ ì¤‘ë³µë˜ê³  ë¶„ë¦¬ëœ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê²Œ ë˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;\n\n\n\n\n\n\n4 ë¹„êµ\n\n\n\n\ngraph TB\n\nsubgraph \"ê±°ëŒ€ì–¸ì–´ê¸°ë°˜ NLP ì‘ì—…íë¦„ &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nsubgraph \"ì „í†µì ì¸ NLP ì‘ì—…íë¦„ &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;\n\n\n\n\n\n\n\n\n\n\ngraph TB\nsubgraph \"ë¯¸ì„¸ì¡°ì • ì‘ì—…íë¦„&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[ì‚¬ì „ í›ˆë ¨] --&gt; B1[ë¯¸ì„¸ ì¡°ì •]\n  B1 --&gt; C1[ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€]\n  C1 --&gt; D1[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]\n  D1 --&gt; E1[ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜]\nend\n\nsubgraph \"í”„ë¡¬í”„íŠ¸ ê³µí•™ ì‘ì—…íë¦„&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[ì‚¬ì „ í•™ìŠµ] --&gt; B2[í”„ë¡¬í”„íŠ¸ ì„¤ê³„]\n  B2 --&gt; C2[ëª¨ë¸ ì¶”ë¡  ë° í›„ì²˜ë¦¬]\n  C2 --&gt; D2[ëª¨ë¸ í‰ê°€]\n  D2 --&gt; E2[ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "openAI_GPT.html#gpt-3",
    "href": "openAI_GPT.html#gpt-3",
    "title": "chatGPT",
    "section": "",
    "text": "OpenAI GPT-3 ëª¨í˜•ì€ í¬ê²Œ ì„¸ê°€ì§€ê°€ ìˆë‹¤.\n\nGPT-3/GPT-4\nCodex\nì½˜í…ì¸  í•„í„° ëª¨ë¸\n\nGPT-3ì€ ìì—°ì–´ ì²˜ë¦¬ ë° ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë¸ë¡œ ì¸ê°„ì˜ ì–¸ì–´ ì¦‰, ìì—°ì–´ì²˜ëŸ¼ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤. í•œê±¸ìŒ ë” ë“¤ì–´ê°€ë©´ ì†ë„ì™€ ì„±ëŠ¥ì— ë”°ë¼ 4ê°€ì§€ ëª¨ë¸(A, B, C, D)ë¡œ êµ¬ë¶„ëœë‹¤.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\nì„±ëŠ¥ê¸°ì¤€ìœ¼ë¡œ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë ¬í•  ìˆ˜ ìˆëŠ”ë° ë¹„ìš©ë„ ê·¸ì— ë”°ë¼ ë†’ì•„ì§„ë‹¤ëŠ” ì˜ë¯¸ë„ í•¨ì¶•í•œë‹¤.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\në”°ë¼ì„œ, OpenAIëŠ” ë‹¤ë¹ˆì¹˜ ëª¨ë¸(text-davinci-003)ì„ í†µí•´ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì€ í›„ì— ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³¼ ê²ƒì„ ê¶Œì¥í•˜ëŠ”ë° ì´ìœ ëŠ” í›¨ì”¬ ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ë§ì€ ìˆ˜ì˜ ìœ ì‚¬í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\n\n2,048ê°œì˜ í† í° ë° 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµí•˜ì—¬ ì´í›„ ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ë‚˜ ì„±ëŠ¥ì—ì„œ ë‹¤ì†Œ ë°€ë¦¬ëŠ” ëª¨ìŠµì´ì§€ë§Œ ìµœì í™”ë¥¼ í†µí•´ ë§¤ìš° ë¹ ë¥´ê³  ë¹„ìš©ì´ ê°€ì¥ ì €ë ´í•˜ë‹¤.\n\n2,048ê°œì˜ í† í°ê³¼ 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµë˜ì—ˆê³  ê°„ë‹¨í•œ ë¶„ë¥˜ì™€ ì˜ë¯¸ë¡ ì  ë¶„ë¥˜ì— íš¨ê³¼ì ì´ë‹¤.\n\nìµœëŒ€ 2048ê°œì˜ í† í°ì„ ì§€ì›í•˜ë©° text-davinci-003 ë‹¤ìŒìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” GPT-3 ëª¨ë¸ì´ë‹¤. 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì— text-davinci-003ë³´ë‹¤ ì •í™•ë„ê°€ ë–¨ì–´ì§€ì§€ë§Œ, ë²ˆì—­, ë³µì¡í•œ ë¶„ë¥˜, í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìš”ì•½ì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆì–´ text-davinci-003ì™€ ë¹„êµí•˜ì—¬ ê°€ì„±ë¹„ê°€ ë†’ë‹¤ê³  í‰ê°€ë˜ê³  ìˆë‹¤.\n\n2021ë…„ 9ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì—ˆê¸° ë•Œë¬¸ì— ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ëŠ” ìˆì§€ë§Œ, ì•ì„  GPT-3 ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ë” ë†’ì€ í’ˆì§ˆì„ ì œê³µí•œë‹¤. ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ìµœëŒ€ 4,000ê°œ í† í°ê¹Œì§€ ìš”ì²­í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì´ì „ ëª¨í˜•ê³¼ í° ì°¨ë³„ì ì´ ëœë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#ì½”ë±ìŠ¤codex",
    "href": "openAI_GPT.html#ì½”ë±ìŠ¤codex",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë±ìŠ¤ëŠ” í”„ë¡œê·¸ë˜ë° ì½”ë“œ ì´í•´ ë° ìƒì„±ì„ ìœ„í•œ ê²ƒìœ¼ë¡œ code-davinci-002ì™€ code-cushman-001ê°€ ìˆë‹¤. ë˜í•œ, ì½”ë±ìŠ¤ëŠ” GitHub Copilotì„ êµ¬ë™í•˜ëŠ” ëª¨ë¸ì´ê¸°ë„ í•˜ë‹¤. íŒŒì´ì¬, ìë°”ìŠ¤í¬ë¦½íŠ¸, ê³ , í„, PHP, ë£¨ë¹„, ìŠ¤ìœ„í”„íŠ¸, íƒ€ì…ìŠ¤í¬ë¦½íŠ¸, SQL, ì…¸ ë“± 12ê°œ ì´ìƒì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì§€ì›í•  ë¿ë§Œ ì•„ë‹ˆë¼ ìì—°ì–´ë¡œ í‘œí˜„ëœ ì£¼ì„(comment)ë¥¼ ì´í•´í•˜ê³  ì‚¬ìš©ìë¥¼ ëŒ€ì‹ í•˜ì—¬ ìš”ì²­ëœ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\në³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ì„œëŠ” code-davinci-002ê°€ ë” ê°•ë ¥í•˜ì§€ë§Œ, ë§ì€ ì½”ë“œ ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê³  code-davinci-002 ë³´ë‹¤ ë” ë¹ ë¥´ê³  ì €ë ´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.\n\nìì—°ì–´ë¥¼ ì½”ë“œë¡œ ë²ˆì—­í•˜ëŠ” ë° íƒì›”í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•  ë¿ë§Œ ì•„ë‹ˆë¼ ë³´ì¶© ìš”ì†Œ ì‚½ì…ë„ ì§€ì›í•œë‹¤. ìµœëŒ€ 8,000ê°œì˜ í† í°ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° 2021ë…„ 6ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#ì½˜í…ì¸ -í•„í„°",
    "href": "openAI_GPT.html#ì½˜í…ì¸ -í•„í„°",
    "title": "chatGPT",
    "section": "",
    "text": "ë¯¼ê°í•œ ì½˜í…ì¸  ì œê±°í•˜ê¸° ìœ„í•œ í•„í„° ëª¨í˜•ì´ë‹¤. ë¯¼ê°í•˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” API ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìê°€ ì‚¬ìš©í•  AI ì‘ìš©í”„ë¡œê·¸ë¨ì„ ê°œë°œí•  ê²½ìš°, í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ë°˜í™˜í•˜ëŠ”ì§€ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì´ í•„í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë‹¤ìŒ 3ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆˆë‹¤.\n\nì•ˆì „(safe)\në¯¼ê°(sensitive)\nì•ˆì „í•˜ì§€ ì•ŠìŒ(unsafe)"
  },
  {
    "objectID": "openAI_GPT.html#í…ìŠ¤íŠ¸-ë²¡í„°-í‘œí˜„",
    "href": "openAI_GPT.html#í…ìŠ¤íŠ¸-ë²¡í„°-í‘œí˜„",
    "title": "chatGPT",
    "section": "\n2.1 í…ìŠ¤íŠ¸ ë²¡í„° í‘œí˜„",
    "text": "2.1 í…ìŠ¤íŠ¸ ë²¡í„° í‘œí˜„\ntext-embedding-ada-002 ëª¨ë¸ì€ ë¹ ë¥´ê³  ê°€ì„±ë¹„ê°€ ë›°ì–´ë‚œ ì„ë² ë”© ëª¨ë¸ì´ë‹¤. â€œëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.â€ ì´ë¼ëŠ” ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì¦‰, 1,536 ì°¨ì›ì„ ê°–ëŠ” ê³µê°„ì— í•˜ë‚˜ì˜ ì ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.\n\nimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'ë²¡í„°ê¸¸ì´: {len(seoul_embedding)}')\n#&gt; ë²¡í„°ê¸¸ì´: 1536\nprint(f'ë²¡í„° ì¼ë¶€: {seoul_embedding[:10]}')\n#&gt; ë²¡í„° ì¼ë¶€: [0.014582998119294643, -0.018063032999634743, 0.004872684367001057, -0.013805408962070942, -0.031180081889033318, 0.025176068767905235, -0.034519895911216736, 0.011357911862432957, -0.007960736751556396, -0.0020682618487626314]\n\në§ˆì°¬ê°€ì§€ë¡œ ì¼ë³¸ì˜ ìˆ˜ë„ ë„ì¿„ë„ ë²¡í„°ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.\n\ntokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"ì¼ë³¸ ìˆ˜ë„ëŠ” ë™ê²½ì…ë‹ˆë‹¤.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'ë²¡í„°ê¸¸ì´: {len(tokyo_embedding)}')\n#&gt; ë²¡í„°ê¸¸ì´: 1536\nprint(f'ë²¡í„° ì¼ë¶€: {tokyo_embedding[:10]}')\n#&gt; ë²¡í„° ì¼ë¶€: [0.010957648046314716, -0.013234060257673264, 0.009729413315653801, -0.011890077032148838, -0.03179261088371277, 0.03436483070254326, -0.029786281287670135, 0.008629790507256985, 0.01711810939013958, -0.0014733985299244523]"
  },
  {
    "objectID": "gpt-security.html",
    "href": "gpt-security.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ì±—GPT ë³´ì•ˆì‚¬ê³ \në³´ì•ˆ vs íš¨ìœ¨ ì„ ë†’ê³  ë§ì€ ê³µê³µê¸°ê´€ì„ ë¹„ë¡¯í•œ ê¸°ì—…ë“¤ì´ ê³ ë¯¼ì„ í•˜ê³  ìˆë‹¤. ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë“  ê²ƒì„ ìì²´ ê°œë°œí•˜ë©´ ìƒê´€ì´ ì—†ìœ¼ë‚˜ í˜„ì‹¤ì ìœ¼ë¡œ GPT-3/3.5/4 ëª¨í˜•ì„ ê°–ì¶˜ ì¡°ì§ì´ ì „ë¬´í•˜ì§€ë§Œ, ì´ë¯¸ ëŒ€ë‹¤ìˆ˜ì˜ ì‚¬ëŒì´ ì˜¤í”ˆAI ì±—GPTë¥¼ ë§›ë³´ì•˜ê¸° ë•Œë¬¸ì— ìƒì‚°ì„± í–¥ìƒì„ ê·¸ëƒ¥ ë‘ê³  ë„˜ì–´ê°€ê¸°ë„ ì–´ë ¤ìš´ ìƒí™©ì´ë‹¤. ì´ëŸ° ì ì—ì„œ ì±—GPT ì œí•œì  ì‚¬ìš©ì´ í˜„ì¬ì‹œì (â€™23ë…„ 3ì›”) ìµœì„ ìœ¼ë¡œ ë³´ì´ë©° ì ì°¨ ì˜¤í”ˆì†ŒìŠ¤ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ê³¼ ì „ëµì  ì œíœ´ë¥¼ í†µí•œ ì±—GPT ì‚¬ìš©ì´ ì¤‘ì¥ê¸°ì  ì¶”ì§„ë°©í–¥ìœ¼ë¡œ ìë¦¬ ì¡ê³  ìˆë‹¤.\nì´ë™ìˆ˜ (2023.04.02.), â€œëŒ€ê¸°ì—… íšŒì˜ ë‚´ìš© ìœ ì¶œâ€¦ â€˜ì±—GPT ê¸°ë°€ ìœ ì¶œâ€™ ìš°ë ¤ê°€ í˜„ì‹¤ë¡œâ€, ì„¸ê³„ì¼ë³´\n\n\n\n\n\n2 ì‚¼ì„±ì „ì\n\nì •ë‘ìš© (2023-03-30), â€œìš°ë ¤ê°€ í˜„ì‹¤ë¡œâ€¦ì‚¼ì„±ì „ì, ì±—GPT ë¹—ì¥ í’€ìë§ˆì â€˜ì˜¤ë‚¨ìš©â€™ ì†ì¶œâ€, ì´ì½”ë…¸ë¯¸ìŠ¤íŠ¸\n\n\nì‚¼ì„±ì „ì DS ë¶€ë¬¸ ì„ì§ì› Aì”¨ëŠ” ë°˜ë„ì²´ ì„¤ë¹„ ê³„ì¸¡ ë°ì´í„°ë² ì´ìŠ¤(DB) ë‹¤ìš´ë¡œë“œ í”„ë¡œê·¸ë¨ì˜ ì†ŒìŠ¤ ì½”ë“œë¥¼ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ë¥¼ í™•ì¸í–ˆë‹¤. ë¬¸ì œê°€ ëœ ì†ŒìŠ¤ ì½”ë“œ ì „ë¶€ë¥¼ ë³µì‚¬í•´ ì±—GPTì— ì…ë ¥, í•´ê²° ë°©ë²•ì„ ë¬¸ì˜í–ˆë‹¤. ì‚¼ì„±ì „ì ì„¤ë¹„ ê³„ì¸¡ê³¼ ê´€ë ¨í•œ ì†ŒìŠ¤ ì½”ë“œê°€ ì˜¤í”ˆAI í•™ìŠµ ë°ì´í„°ë¡œ ì…ë ¥ëœ ì…ˆì´ë‹¤.\n\n\nì„ì§ì› Bì”¨ëŠ” ìˆ˜ìœ¨Â·ë¶ˆëŸ‰ ì„¤ë¹„ íŒŒì•…ì„ ìœ„í•´ ì‘ì„±í•œ í”„ë¡œê·¸ë¨ ì½”ë“œë¥¼ ì±—GPTì— ì…ë ¥í•˜ëŠ” ì‚¬ê³ ë¥¼ ëƒˆë‹¤. ê´€ë ¨ ì†ŒìŠ¤ ì „ì²´ë¥¼ ì±—GPTì— ì…ë ¥í•˜ê³  ì½”ë“œ ìµœì í™”ë¥¼ ìš”ì²­í–ˆë‹¤. ì„ì§ì› Cì”¨ëŠ” ìŠ¤ë§ˆíŠ¸í°ìœ¼ë¡œ ë…¹ìŒí•œ íšŒì˜ ë‚´ìš©ì„ ë„¤ì´ë²„ í´ë¡œë°” ì• í”Œë¦¬ì¼€ì´ì…˜(ì•±)ì„ í†µí•´ ë¬¸ì„œ íŒŒì¼ë¡œ ë³€í™˜í•œ ë’¤ ì±—GPTì— ì…ë ¥í–ˆë‹¤. íšŒì˜ë¡ ì‘ì„± ìš”ì²­ì´ ëª©ì ì´ë‹¤.\n\n\n3 ì´íƒˆë¦¬ì•„\n\në¯¼ì¬ìš© (2023.04.02), â€œì´íƒˆë¦¬ì•„ë„ ì±—GPT â€˜ì°¨ë‹¨â€™â€¦ì„œë°© êµ­ê°€ì¤‘ ì²˜ìŒâ€, í•œêµ­ì¼ë³´\n\n\në¡œì´í„° í†µì‹  ë“±ì— ë”°ë¥´ë©´ ì´íƒˆë¦¬ì•„ ë°ì´í„° ë³´í˜¸ì²­ì€ â€œì±—GPTê°€ ì´íƒˆë¦¬ì•„ì˜ ê°œì¸ì •ë³´ ë³´í˜¸ ê¸°ì¤€ê³¼ ê·œì •ì„ ì¶©ì¡±í•  ë•Œê¹Œì§€ ì„œë¹„ìŠ¤ ì ‘ì†ì„ ì¼ì‹œì ìœ¼ë¡œ ì°¨ë‹¨í•  ê²ƒâ€ì´ë¼ê³  ë°í˜”ë‹¤.\n\n\nì ‘ì† ì°¨ë‹¨ ì´ìœ ëŠ” ê°œì¸ì •ë³´ ì¹¨í•´ ìš°ë ¤ ë•Œë¬¸ì´ë‹¤. ì´íƒˆë¦¬ì•„ ë‹¹êµ­ì€ ì±—GPTê°€ ì•Œê³ ë¦¬ì¦˜ í•™ìŠµì„ ì´ìœ ë¡œ, ê°œì¸ì •ë³´ë¥¼ ëŒ€ëŸ‰ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•˜ëŠ” í–‰ìœ„ë¥¼ ì •ë‹¹í™”í•  ë²•ì  ê·¼ê±°ê°€ ì—†ë‹¤ê³  ì§€ì í–ˆë‹¤. ë³´í˜¸ì²­ì€ ì±—GPT ê°œë°œì‚¬ ì˜¤í”ˆAIê°€ 20ì¼ ì´ë‚´ì— í•´ê²°ì±…ì„ ë‚´ë†“ì§€ ì•Šìœ¼ë©´ ì „ ì„¸ê³„ ë§¤ì¶œì•¡ì˜ ìµœëŒ€ 4%ì— ë‹¬í•˜ëŠ” ë²Œê¸ˆì„ ë¬¼ê²Œ ë  ê²ƒì´ë¼ê³  ê²½ê³ í•˜ê¸°ë„ í–ˆë‹¤."
  },
  {
    "objectID": "prompt_adv.html",
    "href": "prompt_adv.html",
    "title": "chatGPT",
    "section": "",
    "text": "The hottest new programming language is English\n\nâ€” Andrej Karpathy ((karpathy?)) January 24, 2023\n\nê¸°ê³„í•™ìŠµê³¼ ì˜ˆì „ ì‹ ê²½ë§ ëª¨í˜•ì´ íŠ¹ì • ì‘ì—…ì„ ìœ„í•´ ì„¤ê³„ëœ íŠ¹ìˆ˜ ëª©ì ì˜ ì»´í“¨í„°ë¼ë©´, GPTëŠ” ìì—°ì–´ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ëŸ°íƒ€ì„ì— ì¬êµ¬ì„±ë˜ëŠ” ë²”ìš© ì»´í“¨í„°ë‹¤. ì²˜ìŒ í”„ë¡¬í”„íŠ¸[ì¼ì¢…ì˜ ì‹œì‘(inception)]ê°€ í”„ë¡œê·¸ë¨ í˜•íƒœë¡œ ì œê³µë˜ê³ , ê±°ëŒ€ì–¸ì–´ëª¨í˜•(GPT)ëŠ” ë¬¸ì„œë¥¼ ì™„ì„±í•˜ë„ë¡ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•œë‹¤.\n\n1 Few-Shot í•™ìŠµ\nGPT-3 ë…¼ë¬¸ (Brown ê¸°íƒ€, 2020) ì—ì„œ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì´ ì»¨í…ìŠ¤íŠ¸ ë‚´ í•™ìŠµ(in-context learning)ì„ ìˆ˜í–‰í•˜ë©°, ì…ë ¥:ì¶œë ¥ ì˜ˆì œë¥¼ í†µí•´ í”„ë¡¬í”„íŠ¸ ë‚´ì—ì„œ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ â€œí”„ë¡œê·¸ë˜ë°â€í•  ìˆ˜ ìˆìŒì„ ì‹œì—°í–ˆë‹¤. ì¦‰, ì–¸ì–´ ëª¨ë¸ì„ í™•ì¥í•˜ë©´ ì‘ì—…ë³„ ë¯¸ì„¸ ì¡°ì •(Fine-tuning) ì—†ì´ ëª‡ ê°€ì§€ ì˜ˆì œ ë˜ëŠ” ê°„ë‹¨í•œ ì§€ì¹¨ë§Œìœ¼ë¡œ ìˆ˜í–‰ì‘ì—…ì˜ ì„±ëŠ¥í–¥ìƒì„ ê¸°ëŒ€í•´ë³¼ ìˆ˜ ìˆë‹¤.\n\n\n\n\nì „í†µì ì¸ ë¯¸ì„¸ì¡°ì •(Fine tuning)ê³¼ ì œë¡œìƒ·, ì›ìƒ·, í“¨ìƒ·ê³¼ ëŒ€ë¹„í•˜ë©´ ëª…í™•í•´ì§„ë‹¤. ë¯¸ì„¸ì¡°ì •(Fine tuning)ì€ ì „í†µì ì¸ ë°©ë²•ì´ì§€ë§Œ, ì œë¡œìƒ·, ì›ìƒ·, í“¨ìƒ·ì€ ìˆœë°©í–¥ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ í•„ìš”ë¡œ í•œë‹¤.\n\n\n\n\n\n\nì œë¡œìƒ· í•™ìŠµ ì˜ˆì œ:\n\n\n\n\n\nì‘ì—…: ê°ì„± ë¶„ì„ (ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ê¸ì •ì , ë¶€ì •ì , ì¤‘ë¦½ì ìœ¼ë¡œ ë¶„ë¥˜)\nì…ë ¥: â€œì–´ì œ ë†€ì´ê³µì›ì—ì„œ ì •ë§ ì¦ê±°ìš´ í•˜ë£¨ë¥¼ ë³´ëƒˆì–´ìš”!â€\nì¶œë ¥: ê¸ì •ì  \n\n\n\n\n\n\n\n\n\nì›ìƒ· í•™ìŠµ ì˜ˆì œ:\n\n\n\n\n\nì‘ì—…: ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…ëœ ë™ë¬¼ íŒŒì•…í•˜ê¸°\nì˜ˆì‹œ: â€œì´ ë™ë¬¼ì€ ê¸´ ëª©ê³¼ ë°˜ì ì´ íŠ¹ì§•ì¸ë°, ì•„í”„ë¦¬ì¹´ì—ì„œ ë°œê²¬í•  ìˆ˜ ìˆì–´ìš”.â€ ë‹µë³€: ê¸°ë¦°\nì…ë ¥: â€œì´ ë™ë¬¼ì€ ì£¼ë¨¸ë‹ˆê°€ ìˆê³  í˜¸ì£¼ ì›ì£¼ë¯¼ì´ë©°, ê»‘ì¶© ë›°ëŠ” ëŠ¥ë ¥ìœ¼ë¡œ ìœ ëª…í•´ìš”.â€\nì¶œë ¥ : ìº¥ê±°ë£¨\n\n\n\n\n\n\n\n\n\ní“¨ìƒ· í•™ìŠµ ì˜ˆì œ:\n\n\n\n\n\nì‘ì—…: ì£¼ì–´ì§„ ë¬¸ì¥ì„ ëŠ¥ë™íƒœì—ì„œ ìˆ˜ë™íƒœë¡œ ë°”ê¾¸ê¸°\nì˜ˆì‹œ 1: â€œì² ìˆ˜ê°€ ìƒŒë“œìœ„ì¹˜ë¥¼ ë¨¹ì—ˆë‹¤.â€ ë‹µë³€: â€œìƒŒë“œìœ„ì¹˜ê°€ ì² ìˆ˜ì—ê²Œ ë¨¹í˜”ë‹¤.â€\nì˜ˆì‹œ 2: â€œê³ ì–‘ì´ê°€ ì¥ë¥¼ ì«“ì•˜ë‹¤.â€ ë‹µë³€: â€œì¥ê°€ ê³ ì–‘ì´ì—ê²Œ ì«“ê²¼ë‹¤.â€\nì…ë ¥: â€œì„ ìƒë‹˜ì´ í•™ìƒì„ ì¹­ì°¬í–ˆë‹¤.â€\nì¶œë ¥: â€œí•™ìƒì´ ì„ ìƒë‹˜ì—ê²Œ ì¹­ì°¬ë°›ì•˜ë‹¤.â€\n\n\n\n\n2 Chain-of-Thought (CoT)\nì‘ì—…ë³„ ì˜ˆì œ ì—†ì´ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì— ì‚¬ê³ ì˜ ì‚¬ìŠ¬(Chain of Thought)ë¥¼ í†µí•´ ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì¶”ë¡ ì´ ê°€ëŠ¥í•˜ë‹¤. ê° ë‹µë³€ ì•ì— â€œë‹¨ê³„ë³„ë¡œ ìƒê°í•´ ë´…ì‹œë‹¤(Letâ€™s think step by step)â€ë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ì‚°ìˆ , ê¸°í˜¸ ì¶”ë¡ , ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì¶”ë¡  ì‘ì—…ì—ì„œ í‘œì¤€ ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ë³´ë‹¤ í›¨ì”¬ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í–ˆë‹¤. (Kojima ê¸°íƒ€, 2023)\n\n\n\n\nGPT-Turbo, GPT-4 ëª¨ë¸ì€ í•´ë‹¹ë¬¸ì œë¥¼ ë°”ë¡œ ì •í™•íˆ í’€ ìˆ˜ ìˆìœ¼ë‚˜ Legacy (GPT-3.5)ëŠ” CoT ê¸°ë²•ì„ ì ìš©í•´ì•¼ ì •ë‹µì„ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\n\n\n\n\n\nê·¸ë¦¼Â 1: ì‚¬ê³ ì˜ ì‚¬ìŠ¬(Chain of Thought) ì˜ˆì œ\n\n\nëª…ë ¹ì–´ ìë™ ìƒì„± ë° ì„ íƒì„ ìœ„í•œ ìë™ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´(Automatic Prompt Engineer, APE)ëŠ” í”„ë¡¬í”„íŠ¸ ëª…ë ¹(instruction)ì„ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì´ ì œì•ˆí•œ ëŒ€í•œ ì„ íƒì§€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì„ íƒí•œ ëª©ì  í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ëª…ë ¹ì–´ë¥¼ ìµœì í™”ì‹œí‚¨ ë‹¤ìŒ ì„ íƒí•œ ëª…ë ¹ì–´ë¥¼ ë‹¤ë¥¸ LLMì„ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•˜ëŠ” ë°©ë²•ë„ ì œì‹œë˜ì—ˆë‹¤. (Zhou ê¸°íƒ€, 2023)\n\n3 ì„±ê³¼ì§€í‘œ ì„¤ì •\nì˜ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ì—ëŠ” ì›í•˜ëŠ” ëª©í‘œ ì„±ê³¼ê°€ í¬í•¨ë˜ì–´ì•¼ í•œë‹¤. GPTëŠ” ìµœì„ ì„ ë‹¤í•´ ì„±ê³µì„ ì¶”êµ¬í•˜ì§€ ì•Šê³  ëª¨ë°©ë§Œ í•  ë¿ì´ë‹¤. ì¢‹ì€ ê²°ê³¼ë¥¼ ì›í•œë‹¤ë©´ ë‹¬ì„±í•´ì•¼ ë˜ëŠ” ì„±ê³µì„ ëª…ì‹œí•´ì•¼ í•œë‹¤. (Chen ê¸°íƒ€, 2021)\n\n\nì˜ë¬¸ì˜ˆì‹œ 10ê°œ\nêµ­ë¬¸ë²ˆì—­ 10ê°œ\n\n\n\nâ€œPlease provide a step-by-step guide on how to achieve top-tier performance in time management and productivity techniques, so I can excel in my personal and professional life.â€\nâ€œI aspire to become an exceptional public speaker. Can you offer me comprehensive advice, including tips, tricks, and exercises that will help me develop outstanding presentation skills?â€\nâ€œI am determined to become a top-performing sales professional. Share with me the essential skills, strategies, and habits that I must adopt to excel in this competitive field.â€\nâ€œI wish to become a highly respected and successful leader. Could you provide insights, examples, and actionable steps to develop strong leadership qualities and excel in any organization?â€\nâ€œI desire to master the art of negotiation and achieve win-win outcomes. Please provide me with detailed guidance, best practices, and real-life examples that will enable me to excel in negotiations.â€\nâ€œMy goal is to become a top performer in project management. Can you outline the key principles, methodologies, and tools that will help me successfully manage projects and exceed expectations?â€\nâ€œI aspire to be an excellent writer, able to captivate my audience and inspire them through my words. Please provide me with writing techniques, exercises, and recommendations that will elevate my writing skills to the highest level.â€\nâ€œI am determined to achieve peak physical fitness and athletic performance. Share with me the best workout routines, nutrition tips, and mental strategies that will help me reach my full potential as an athlete.â€\nâ€œI want to excel in the art of problem-solving and critical thinking. Please provide me with the necessary tools, frameworks, and exercises that will help me become an exceptional problem solver and thinker.â€\nâ€œMy goal is to become a highly skilled and successful investor. Can you provide me with the most effective strategies, tips, and resources that will enable me to outperform in the world of investing?â€\n\n\nâ€œì‹œê°„ ê´€ë¦¬ ë° ìƒì‚°ì„± ê¸°ìˆ ì—ì„œ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ê³¼ë¥¼ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì œê³µí•˜ì—¬ ê°œì¸ ë° ì§ì¥ ìƒí™œì—ì„œ íƒì›”í•¨ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.â€\nâ€œì €ëŠ” ë›°ì–´ë‚œ ëŒ€ì¤‘ ì—°ì„¤ê°€ê°€ ë˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ë›°ì–´ë‚œ í”„ë ˆì  í…Œì´ì…˜ ê¸°ìˆ ì„ ê°œë°œí•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” íŒ, ìš”ë ¹ ë° ì—°ìŠµ ë¬¸ì œë¥¼ í¬í•¨í•œ í¬ê´„ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?â€\nâ€œìµœê³ ì˜ ì„±ê³¼ë¥¼ ë‚´ëŠ” ì˜ì—… ì „ë¬¸ê°€ê°€ ë˜ê¸°ë¡œ ê²°ì‹¬í–ˆìŠµë‹ˆë‹¤. ê²½ìŸì´ ì¹˜ì—´í•œ ì´ ë¶„ì•¼ì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë‚´ê¸° ìœ„í•´ ë°˜ë“œì‹œ ê°–ì¶°ì•¼ í•  í•„ìˆ˜ ê¸°ìˆ , ì „ëµ ë° ìŠµê´€ì„ ì•Œë ¤ì£¼ì„¸ìš”.â€\nâ€œì¡´ê²½ë°›ê³  ì„±ê³µì ì¸ ë¦¬ë”ê°€ ë˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ê°•ë ¥í•œ ë¦¬ë”ì‹­ ìì§ˆì„ ê°œë°œí•˜ê³  ì–´ë–¤ ì¡°ì§ì—ì„œë“  ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆëŠ” ì¸ì‚¬ì´íŠ¸, ì‚¬ë¡€, ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?â€\nâ€œí˜‘ìƒì˜ ê¸°ìˆ ì„ ìŠµë“í•˜ì—¬ ì„œë¡œ ìœˆìœˆí•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ê³  ì‹¶ìŠµë‹ˆë‹¤. í˜‘ìƒì—ì„œ íƒì›”í•œ ëŠ¥ë ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆë„ë¡ ìì„¸í•œ ì§€ì¹¨, ëª¨ë²” ì‚¬ë¡€ ë° ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.â€\nâ€œì œ ëª©í‘œëŠ” í”„ë¡œì íŠ¸ ê´€ë¦¬ ë¶„ì•¼ì—ì„œ ìµœê³ ì˜ ì„±ê³¼ë¥¼ ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ê¸°ëŒ€ì¹˜ë¥¼ ì´ˆê³¼ ë‹¬ì„±í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•µì‹¬ ì›ì¹™, ë°©ë²•ë¡  ë° ë„êµ¬ë¥¼ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?â€\nâ€œì €ëŠ” ê¸€ì„ í†µí•´ ì²­ì¤‘ì„ ì‚¬ë¡œì¡ê³  ì˜ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” í›Œë¥­í•œ ì‘ê°€ê°€ ë˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì œ ê¸€ì“°ê¸° ì‹¤ë ¥ì„ ìµœê³  ìˆ˜ì¤€ìœ¼ë¡œ ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆëŠ” ê¸€ì“°ê¸° ê¸°ë²•, ì—°ìŠµ ë¬¸ì œ, ê¶Œì¥ ì‚¬í•­ì„ ì œê³µí•´ ì£¼ì„¸ìš”.â€\nâ€œìµœê³ ì˜ ì²´ë ¥ê³¼ ìš´ë™ ëŠ¥ë ¥ì„ ê°–ì¶”ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìš´ë™ì„ ìˆ˜ë¡œì„œ ì œ ì ì¬ë ¥ì„ ìµœëŒ€í•œ ë°œíœ˜í•˜ëŠ” ë° ë„ì›€ì´ ë  ìµœê³ ì˜ ìš´ë™ ë£¨í‹´, ì˜ì–‘ íŒ, ì •ì‹  ì „ëµì„ ì•Œë ¤ì£¼ì„¸ìš”.â€\nâ€œë¬¸ì œ í•´ê²° ëŠ¥ë ¥ê³¼ ë¹„íŒì  ì‚¬ê³ ë ¥ì´ ë›°ì–´ë‚˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ë›°ì–´ë‚œ ë¬¸ì œ í•´ê²°ìì´ì ì‚¬ìƒê°€ê°€ ë˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•„ìš”í•œ ë„êµ¬, í”„ë ˆì„ì›Œí¬, ì—°ìŠµ ë¬¸ì œë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.â€\nâ€œì œ ëª©í‘œëŠ” ê³ ë„ë¡œ ìˆ™ë ¨ë˜ê³  ì„±ê³µì ì¸ íˆ¬ììê°€ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤. íˆ¬ì ì„¸ê³„ì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆëŠ” ê°€ì¥ íš¨ê³¼ì ì¸ ì „ëµ, íŒ, ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?â€\n\n\n\nì°¸ê³  ìë£Œ: ê¹€ë¯¼ê²½ (2023. 3. 31.), â€œí”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, AIë¼ëŠ” ë„êµ¬ë¥¼ ì˜ ì‚¬ìš©í•˜ëŠ” ë°©ë²•â€, Kakaoenterprise Tech Trend\n\n4 ìê¸° ì¼ê´€ì„±\nê¸°ì¡´ ì‚¬ê³  ì‚¬ìŠ¬(Chain of Thought)ì˜ í•œê³„ë¥¼ ë„˜ì–´ì„œ ì œì‹œëœ ìê¸° ì¼ê´€ì„±(Self-consistency)ì€ ë³µì¡í•œ ì¶”ë¡  ë¬¸ì œì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ê³ ìœ í•œ ì •ë‹µìœ¼ë¡œ ì´ì–´ì§€ëŠ” ì—¬ëŸ¬ ê°€ì§€ ì‚¬ê³  ë°©ì‹ì„ ì¸ì •í•œë‹¤ëŠ” ì§ê´€ì„ í™œìš©í•œë‹¤. (Wang ê¸°íƒ€, 2023)\nìê¸° ì¼ê´€ì„± ê¸°ë²•ì€ ë‹¤ìŒ 3ë‹¨ê³„ë¥¼ ê±°ì³ ìµœì¢… ë‹µì„ ì œì‹œí•œë‹¤.\n\nì‚¬ê³ ì˜ ì‚¬ìŠ¬(CoT) í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì— í”„ë¡¬í”„íŠ¸ ìƒì„±í•œë‹¤.\nCoT í”„ë¡¬í”„íŠ¸ê°€ â€œGreedy Decodingâ€ ìµœì„ ì„ ì¶”êµ¬í•˜ëŠ” ë°˜ë©´, ê±°ëŒ€ì–¸ì–´ëª¨í˜• ë””ì½”ë”ì—ì„œ í‘œë³¸ì„ ì¶”ì¶œí•˜ì—¬ ë‹¤ì–‘í•œ ì¶”ë¡  ê²½ë¡œ ì§‘í•©ì„ ìƒì„±í•œë‹¤.\n\n\nì¶”ë¡  ê²½ë¡œë¥¼ í•œê³„í™”í•˜ê³  ìµœì¢… ë‹µë³€ ì„¸íŠ¸ì—ì„œ ê°€ì¥ ì¼ê´€ëœ ë‹µë³€ì„ ì„ íƒ ë° ì§‘ê³„í•˜ì—¬ ì œì‹œí•œë‹¤.\n\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸: ì œê°€ 6ì‚´ì´ì—ˆì„ ë•Œ ì œ ì—¬ë™ìƒì€ ì œ ë‚˜ì´ì˜ ì ˆë°˜ì´ì—ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆì€ 70ì‚´ì…ë‹ˆë‹¤. ì œ ì—¬ë™ìƒì€ ëª‡ ì‚´ì¸ê°€ìš”?\n\n\n\n\n\n\në‹¹ì‹ ì´ 6ì‚´ì´ì—ˆì„ ë•Œ ì—¬ë™ìƒì€ ë‹¹ì‹ ì˜ ë‚˜ì´ì˜ ì ˆë°˜ì´ì—ˆìœ¼ë¯€ë¡œ, ì—¬ë™ìƒì€ ë‹¹ì‹ ë³´ë‹¤ 3ì‚´ ì–´ë ¸ìŠµë‹ˆë‹¤. ì§€ê¸ˆ ë‹¹ì‹ ì´ 70ì‚´ì´ë‹ˆ, ì—¬ë™ìƒì€ ì—¬ì „íˆ ë‹¹ì‹ ë³´ë‹¤ 3ì‚´ ì–´ë¦½ë‹ˆë‹¤. ë”°ë¼ì„œ ì—¬ë™ìƒì€ 70 - 3 = 67ì‚´ì…ë‹ˆë‹¤.\n\n\n\n\n\n5 Generated Knowledge Prompting\nìƒì„±ëœ ì§€ì‹ í”„ë¡¬í”„íŠ¸(Generated Knowledge Prompting)ëŠ” ëª‡ ë²ˆì˜ ë°ëª¨ë¥¼ í†µí•´ ì–¸ì–´ ëª¨ë¸ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì§€ì‹ ì§„ìˆ ì„ ì´ëŒì–´ë‚´ê³ , í•´ë‹¹ ì§€ì‹ì´ ìˆëŠ” ë‹¤ë¥¸ ì–¸ì–´ ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ë¥¼ í‘œì‹œí•˜ì—¬ ì˜ˆì¸¡ì„ ìœ ë„í•˜ëŠ” ê¸°ë²•ì´ë‹¤. (Liu ê¸°íƒ€, 2022)\n\nì–¸ì–´ ëª¨ë¸ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì§€ì‹ ì§„ìˆ ì„ ìƒì„±í•˜ê¸° ìœ„í•´ ëª‡ ì¥ë©´ì˜ ë°ëª¨ë¥¼ ì‚¬ìš©.\nì œ2ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê° ì§€ì‹ ì§„ìˆ ì— ëŒ€í•´ ì˜ˆì¸¡ì„ í•œ ë‹¤ìŒ ê°€ì¥ ì‹ ë¢°ë„ê°€ ë†’ì€ ì˜ˆì¸¡ì„ ì·¨ì‚¬ì„ íƒ.\n\n\n\n\n\n\n\nGPT-4\nLegacy (GPT-3.5)\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸: ê³¨í”„ ê²Œì„ì€ ë‹¤ë¥¸ ì‚¬ëŒë³´ë‹¤ ë” ë†’ì€ ì´ì ì„ ì–»ê¸° ìœ„í•´ ë…¸ë ¥í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆ, ì•„ë‹ˆì˜¤?\n\n\n\n\n\nì§€ì‹: ê³¨í”„ì˜ ëª©í‘œëŠ” ìµœì†Œí•œì˜ ìŠ¤íŠ¸ë¡œí¬ë¡œ ì¼ë ¨ì˜ í™€ì„ í”Œë ˆì´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê³¨í”„ ë¼ìš´ë“œëŠ” ì¼ë°˜ì ìœ¼ë¡œ 18í™€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ê° í™€ì€ í‘œì¤€ ê³¨í”„ ì½”ìŠ¤ì—ì„œ ë¼ìš´ë“œ ì¤‘ í•œ ë²ˆì”© í”Œë ˆì´ë©ë‹ˆë‹¤. ê° ìŠ¤íŠ¸ë¡œí¬ëŠ” 1ì ìœ¼ë¡œ ê³„ì‚°ë˜ë©°, ì´ ìŠ¤íŠ¸ë¡œí¬ ìˆ˜ê°€ ê²Œì„ì˜ ìŠ¹ìë¥¼ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n\nì•„ë‹ˆì˜¤, ê³¨í”„ì˜ ëª©í‘œëŠ” ë‹¤ë¥¸ ì‚¬ëŒë³´ë‹¤ ë” ë†’ì€ ì´ì ì„ ì–»ëŠ” ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤. ëŒ€ì‹ , ìµœì†Œí•œì˜ ìŠ¤íŠ¸ë¡œí¬ë¡œ ì¼ë ¨ì˜ í™€ì„ ì™„ì£¼í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ê³¨í”„ì—ì„œëŠ” ê° ìŠ¤íŠ¸ë¡œí¬ê°€ 1ì ìœ¼ë¡œ ê³„ì‚°ë˜ë©°, ë¼ìš´ë“œ ì¢…ë£Œ ì‹œì ì—ì„œ ìŠ¤íŠ¸ë¡œí¬ ìˆ˜ê°€ ê°€ì¥ ì ì€ ì„ ìˆ˜ê°€ ìŠ¹ìë¡œ ê°„ì£¼ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ê³¨í”„ì—ì„œëŠ” ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.\n\n\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸: ê³¨í”„ ê²Œì„ì€ ë‹¤ë¥¸ ì‚¬ëŒë³´ë‹¤ ë” ë†’ì€ ì´ì ì„ ì–»ê¸° ìœ„í•´ ë…¸ë ¥í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆ, ì•„ë‹ˆì˜¤?\n\n\n\n\n\n\nì˜ˆ, ê³¨í”„ ê²Œì„ì€ ë‹¤ë¥¸ ì‚¬ëŒë³´ë‹¤ ë” ë†’ì€ ì´ì ì„ ì–»ê¸° ìœ„í•´ ë…¸ë ¥í•˜ëŠ” ê²Œì„ì…ë‹ˆë‹¤.\n\n\n\n\n\n\n\n\n6 ê°€ìƒ ì»´í“¨í„°\nì¶œì²˜: Engraved (3rd December 2022), â€œBuilding A Virtual Machine inside ChatGPTâ€\nChatGPT ë‚´ë¶€ì—ì„œ ì „ì²´ ê°€ìƒ ì»´í“¨í„°ë¥¼ ë§Œë“¤ì–´ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆë‹¤. ê°€ìƒ ì»´í“¨í„°ëŠ” íŒŒì¼ ì‹œìŠ¤í…œ ì‘ë™ ë°©ì‹ì„ ì´í•´í•˜ê³  í”„ë¡œê·¸ë˜ë°ë„ ê°€ëŠ¥í•˜ë‹¤.\n\n\n\n\n\n\nì±—GPTë¥¼ ê°€ìƒì»´í“¨í„°ë¡œ ë°”ê¾¸ëŠ” í”„ë¡¬í”„íŠ¸\n\n\n\n\n\nâ€œI want you to act as a Linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do no write explanations. Do not type commands unless I instruct you to do so. When I need to tell you something in English I will do so by putting text inside curly brackets {like this}. My first command is pwd.â€\nâ€œë„¤ê°€ ë¦¬ëˆ…ìŠ¤ í„°ë¯¸ë„ ì—­í• ì„ í•´ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´. ë‚´ê°€ ëª…ë ¹ì„ ì…ë ¥í•˜ë©´ í„°ë¯¸ë„ì´ í‘œì‹œí•´ì•¼ í•  ë‚´ìš©ì„ íšŒì‹ í•´ ì£¼ì„¸ìš”. í•˜ë‚˜ì˜ ê³ ìœ í•œ ì½”ë“œ ë¸”ë¡ ì•ˆì— ìˆëŠ” í„°ë¯¸ë„ ì¶œë ¥ë§Œ íšŒì‹ í•˜ê³  ë‹¤ë¥¸ ê²ƒì€ íšŒì‹ í•˜ì§€ ë§ˆì„¸ìš”. ì„¤ëª…ì„ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”. ì œê°€ ì§€ì‹œí•˜ì§€ ì•ŠëŠ” í•œ ëª…ë ¹ì„ ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”. ì˜ì–´ë¡œ ì„¤ëª…í•´ì•¼ í•  ë•ŒëŠ” {ì´ë ‡ê²Œ}ì™€ ê°™ì´ ì¤‘ê´„í˜¸ ì•ˆì— í…ìŠ¤íŠ¸ë¥¼ ë„£ì–´ ì„¤ëª…í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ëª…ë ¹ì€ lsì…ë‹ˆë‹¤.â€\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nê·¸ë¦¼Â 2: ì±—GPT ë‚´ë¶€ ë¦¬ëˆ…ìŠ¤ ê°€ìƒ ì»´í“¨í„°\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., â€¦ Amodei, D. (2020). Language Models are Few-Shot Learners. https://arxiv.org/abs/2005.14165\n\n\nChen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., & Mordatch, I. (2021). Decision Transformer: Reinforcement Learning via Sequence Modeling. https://arxiv.org/abs/2106.01345\n\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. https://arxiv.org/abs/2205.11916\n\n\nLiu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2022). Generated Knowledge Prompting for Commonsense Reasoning. https://arxiv.org/abs/2110.08387\n\n\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. https://arxiv.org/abs/2203.11171\n\n\nZhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large Language Models Are Human-Level Prompt Engineers. https://arxiv.org/abs/2211.01910"
  },
  {
    "objectID": "nlp_LLM.html#ëŒ€í‘œì ì¸-nlp-ì‘ì—…",
    "href": "nlp_LLM.html#ëŒ€í‘œì ì¸-nlp-ì‘ì—…",
    "title": "chatGPT",
    "section": "\n1.1 ëŒ€í‘œì ì¸ NLP ì‘ì—…",
    "text": "1.1 ëŒ€í‘œì ì¸ NLP ì‘ì—…\nìˆ«ìê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ë¥¼ í†µí•´ ê°€ì¹˜ë¥¼ ì°½ì¶œí•  ìˆ˜ ìˆëŠ” ë¶„ì•¼ê°€ ìì—°ì–´ì²˜ë¦¬(NLP) ì˜ì—­ì´ë‹¤. ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ í”íˆ ì ‘í•˜ëŠ” ëŒ€í‘œì ì¸ ìƒìœ„ 10ê°€ì§€ NLPìœ¼ë¡œ ë‹¤ìŒì„ ë“¤ ìˆ˜ ìˆë‹¤.\n\nê°ì • ë¶„ì„: ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ë“± ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— í‘œí˜„ëœ ê°ì •ì„ íŒŒì•….\ní…ìŠ¤íŠ¸ ë¶„ë¥˜: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •ì˜ëœ í´ë˜ìŠ¤ ë˜ëŠ” ì£¼ì œ(ì˜ˆ: ìŠ¤í¬ì¸ , ì •ì¹˜, ì—°ì˜ˆ ë“±)ë¡œ ë¶„ë¥˜.\nê°œì²´ëª… ì¸ì‹(NER): í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì‚¬ëŒ, ì¡°ì§, ìœ„ì¹˜, ë‚ ì§œ ë“±ì˜ ëª…ëª…ëœ ê°œì²´(entity)ë¥¼ ì‹ë³„í•˜ê³  ë¶„ë¥˜.\ní’ˆì‚¬(POS) íƒœê¹…: ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ë‹¨ì–´ì— ë¬¸ë²•ì  ë ˆì´ë¸”(ì˜ˆ: ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬)ì„ í• ë‹¹.\nì˜ì¡´ì„± êµ¬ë¬¸ ë¶„ì„: ë¬¸ì¥ ë‚´ ë‹¨ì–´ ê°„ì˜ ë¬¸ë²• êµ¬ì¡°ì™€ ê´€ê³„ë¥¼ ì‹ë³„.\nê¸°ê³„ ë²ˆì—­: ì˜ì–´ì—ì„œ ìŠ¤í˜ì¸ì–´ë¡œ ë˜ëŠ” ì¤‘êµ­ì–´ì—ì„œ í”„ë‘ìŠ¤ì–´ë¡œì™€ ê°™ì´ í•œ ì–¸ì–´ì—ì„œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­.\nì§ˆì˜ ì‘ë‹µ: ìì—°ì–´ë¡œ ì œê¸°ëœ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ê°œë°œ.\ní…ìŠ¤íŠ¸ ìš”ì•½: ì£¼ìš” ì•„ì´ë””ì–´ì™€ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ì„ ìƒì„±.\nìƒí˜¸ì°¸ì¡°í•´ê²°(Coreference Resolution): í…ìŠ¤íŠ¸ì—ì„œ ë‘ ê°œ ì´ìƒì˜ ë‹¨ì–´ë‚˜ êµ¬ê°€ ë™ì¼í•œ ê°œì²´ ë˜ëŠ” ê°œë…ì„ ì§€ì¹­í•˜ëŠ” ê²½ìš° ì‹ë³„.\ní…ìŠ¤íŠ¸ ìƒì„±: ì£¼ì–´ì§„ ì…ë ¥, ì»¨í…ìŠ¤íŠ¸ ë˜ëŠ” ì¼ë ¨ì˜ ì¡°ê±´ì— ë”°ë¼ ì¼ê´€ë˜ê³  ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±.\n\nìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ê³¼ ì‘ì—…íë¦„ì„ ì„œë¡œ ì—°ê²°í•˜ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê°œë³„ì ìœ¼ë¡œ ì¤‘ë³µë˜ê³  ë¶„ë¦¬ëœ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê²Œ ë˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;"
  },
  {
    "objectID": "nlp_LLM.html#nlp-ê¸°ê³„í•™ìŠµ",
    "href": "nlp_LLM.html#nlp-ê¸°ê³„í•™ìŠµ",
    "title": "chatGPT",
    "section": "\n2.1 NLP ê¸°ê³„í•™ìŠµ",
    "text": "2.1 NLP ê¸°ê³„í•™ìŠµ\nìì—°ì–´ì²˜ë¦¬(NLP) ê¸°ê³„í•™ìŠµì€ í†µê³„ëª¨í˜•ê³¼ ê±°ì˜ ë¹„ìŠ·í•œ ì‘ì—…íë¦„ì„ ê°–ëŠ”ë‹¤. ì°¨ì´ì ì´ ìˆë‹¤ë©´ ë°ì´í„° ê´€ê³„ì˜ ì„¤ëª…ë³´ë‹¤ ì˜ˆì¸¡ì— ë” ì¤‘ì ì„ ë‘”ë‹¤ëŠ” ì ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°ì„± ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë“± í…ìŠ¤íŠ¸ë¥¼ ë°ì´í„°ë¡œ í•˜ëŠ” ì „í†µì ì¸ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì€ ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…íë¦„ì„ ê°–ê²Œ ëœë‹¤.\n\n\n\n\n\n\ngraph TD\n    A[ë°ì´í„° ìˆ˜ì§‘] --&gt; B[ë°ì´í„° ì „ì²˜ë¦¬]\n    B --&gt; C[í”¼ì³ ì¶”ì¶œ]\n    C --&gt; D[í›ˆë ¨-í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„í• ]\n    D --&gt; E[ëª¨í˜• ì„ íƒ]\n    E --&gt; F[ëª¨í˜• í•™ìŠµ]\n    F --&gt; G[ëª¨í˜• í‰ê°€]\n    G --&gt; H[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]\n    H --&gt; I[ëª¨í˜• ë°°í¬]\n    I --&gt; J[ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜]\n\n\n\n\n\n\n\në°ì´í„° ìˆ˜ì§‘: í…ìŠ¤íŠ¸ ë°ì´í„°ì™€ í•´ë‹¹ ë ˆì´ë¸”ì´ í¬í•¨ëœ ë°ì´í„°ì…‹ì„ ìˆ˜ì§‘í•œë‹¤. ê°ì„± ë¶„ì„ì˜ ê²½ìš°, ë¼ë²¨ì€ â€˜ê¸ì •â€™, â€˜ë¶€ì •â€™ ë˜ëŠ” â€™ì¤‘ë¦½â€™ì´ ë˜ê³ , í…ìŠ¤íŠ¸ ë¶„ë¥˜ì˜ ê²½ìš° ë ˆì´ë¸”ì€ ë‹¤ì–‘í•œ ì£¼ì œë‚˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì¦‰, ìì—°ì–´ ì²˜ë¦¬ ëª©ì ì— ë§ì¶° ë¼ë²¨ì„ íŠ¹ì •í•˜ê³  ì—°ê´€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œë‹¤.\në°ì´í„° ì „ì²˜ë¦¬: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ ì¶”ê°€ ë¶„ì„ì— ì í•©í•˜ë„ë¡ ì‘ì—…í•˜ëŠ”ë° ì†Œë¬¸ìí™”, í† í°í™”, ë¶ˆìš©ì–´ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì–´ê°„ ë‹¨ì–´ ê¸°ë³¸í˜•ìœ¼ë¡œ ì¤„ì´ê¸° ë“±ì´ í¬í•¨ëœë‹¤.\ní”¼ì³ ì¶”ì¶œ:ì‚¬ì „ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì— ì í•©í•œ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ BoW, TF-IDF, ë‹¨ì–´ ì„ë² ë”© ë“±ì´ í”íˆ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì´ë‹¤.\ní›ˆë ¨-ì‹œí—˜ ë°ì´í„°ì…‹ ë¶„í• : ì¼ë°˜ì ìœ¼ë¡œ 70-30, 80-20 ë˜ëŠ” ê¸°íƒ€ ì›í•˜ëŠ” ë¶„í•  ë¹„ìœ¨ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ í›ˆë ¨ê³¼ ì‹œí—˜ ë°ì´í„°ì…‹ìœ¼ë¡œ êµ¬ë¶„í•œë‹¤.\nëª¨í˜• ì„ íƒ: ì í•©í•œ í†µê³„, ë¨¸ì‹  ëŸ¬ë‹, ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì„ ì •í•œë‹¤.\nëª¨í˜• í•™ìŠµ: ì ì ˆí•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ê³¼ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ ì„ íƒí•œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.\nëª¨í˜• í‰ê°€: ì •í™•ë„, ì •ë°€ë„, ë¦¬ì½œ, F1 ì ìˆ˜ ë˜ëŠ” ROC ê³¡ì„  ì•„ë˜ ì˜ì—­ê³¼ ê°™ì€ ê´€ë ¨ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ì‹œí—˜ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤.\ní•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: ê²©ì ê²€ìƒ‰ ë˜ëŠ” ë¬´ì‘ìœ„ ê²€ìƒ‰ê³¼ ê°™ì€ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ëª¨í˜•ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•œë‹¤.\nëª¨í˜• ë°°í¬: ëª¨í˜•ì„ í•™ìŠµí•˜ê³  ìµœì í™”í•œ í›„ì—ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì— ë°°í¬í•˜ì—¬ ê°€ì¹˜ë¥¼ ì°½ì¶œí•œë‹¤.\nëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ ê´€ë¦¬: ë°°í¬ëœ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì— ë”°ë¼ ìƒˆë¡œìš´ í•™ìŠµë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•œë‹¤."
  },
  {
    "objectID": "nlp_LLM.html#nlp-vs-llm",
    "href": "nlp_LLM.html#nlp-vs-llm",
    "title": "chatGPT",
    "section": "\n3.1 NLP vs LLM",
    "text": "3.1 NLP vs LLM\nì§€êµ¬ìƒì˜ ê±°ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì´ ì¡´ì¬í•˜ëŠ” ìƒí™©ì´ê¸° ë•Œë¬¸ì— ì ì ˆí•œ LLMì„ ì„ íƒí•œ í›„ì— ì¢€ë” ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ì„œ ì¶”ê°€ í•™ìŠµë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¯¸ì„¸ì¡°ì •(Fine-tuning) í•™ìŠµì„ ê±°ì¹œ í›„ì— AI ëª¨í˜•ì„ ë°°í¬í•˜ì—¬ ìš´ì˜í•œë‹¤.\n\n\n\n\ngraph TB\n\nsubgraph \"ì „í†µì ì¸ NLP ì‘ì—…íë¦„ &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nsubgraph \"ê±°ëŒ€ì–¸ì–´ê¸°ë°˜ NLP ì‘ì—…íë¦„ &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "nlp_LLM.html#fine-tuning-llm-vs-prompt-eng.",
    "href": "nlp_LLM.html#fine-tuning-llm-vs-prompt-eng.",
    "title": "chatGPT",
    "section": "\n3.2 Fine-tuning LLM vs Prompt Eng.",
    "text": "3.2 Fine-tuning LLM vs Prompt Eng.\në‘ê°€ì§€ ì ‘ê·¼ë°©ë²• ëª¨ë‘ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì— ê¸°ë°˜í•œë‹¤ëŠ” ì ì—ì„œ ë™ì¼í•˜ë‚˜, ì¶”ê°€í•™ìŠµ ë°ì´í„°ë¥¼ ë°˜ì˜í•œ AI ëª¨í˜•ì„ ê°œë°œí•˜ëŠëƒ ì•„ë‹ˆë©´ í”„ë¡¬í”„íŠ¸(ì¼ëª… AI í”„ë¡œê·¸ë¨)ë¥¼ ì˜ ì‘ì„±í•œ AI ëª¨í˜•ì„ ê°œë°œí•˜ëŠëƒ ì°¨ì´ê°€ ì¡´ì¬í•œë‹¤. ë¬¼ë¡  Zero-/One-/Few-Shot ì˜ˆì œë¥¼ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ë„ ìˆê³  ë¯¸ì„¸ì¡°ì • í›ˆë ¨ëª¨í˜•ì— í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜ì˜í•œ AI ëª¨í˜•ë„ ì¡´ì¬í•œë‹¤. ê° ë¬¸ì œì— ë§ì¶° ì ì ˆí•œ ê°œë°œë°©ë²•ì„ ì·¨í•˜ë©´ ë  ê²ƒì´ë‹¤.\n\n\n\n\ngraph TB\nsubgraph \"ë¯¸ì„¸ì¡°ì • ì‘ì—…íë¦„&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[ì‚¬ì „ í›ˆë ¨] --&gt; B1[ë¯¸ì„¸ ì¡°ì •]\n  B1 --&gt; C1[ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€]\n  C1 --&gt; D1[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]\n  D1 --&gt; E1[ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜]\nend\n\nsubgraph \"í”„ë¡¬í”„íŠ¸ ê³µí•™ ì‘ì—…íë¦„&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[ì‚¬ì „ í•™ìŠµ] --&gt; B2[í”„ë¡¬í”„íŠ¸ ì„¤ê³„]\n  B2 --&gt; C2[ëª¨ë¸ ì¶”ë¡  ë° í›„ì²˜ë¦¬]\n  C2 --&gt; D2[ëª¨ë¸ í‰ê°€]\n  D2 --&gt; E2[ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "nlp_LLM.html#ë¹„êµ-1",
    "href": "nlp_LLM.html#ë¹„êµ-1",
    "title": "chatGPT",
    "section": "\n3.3 ë¹„êµ",
    "text": "3.3 ë¹„êµ\nLLM ëª¨í˜•ì„ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ê³µê°œí•˜ëŠ” ê²½ìš° ì´ë¥¼ ëŒë¦´ ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ í•˜ë“œì›¨ì–´ê°€ í•„ìš”í•˜ê¸°ë„ í•˜ê³ , LLMì„ ë¹„ê³µê°œí•˜ëŠ” ê²½ìš° êµ¬ë…í˜•ìœ¼ë¡œ ë¹„ìš©ì„ ì²­êµ¬í•˜ì—¬ AI ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°ë„ ì¡´ì¬í•œë‹¤. í•´ë‹¹ ë¬¸ì œë¥¼ ê°€ì¥ ì˜ í•´ê²°í•  ìˆ˜ ìˆëŠ” AI ê°œë°œë°©ë²•ë¡ ì„ ì£¼ì–´ì§„ ì œì•½ì¡°ê±´ì—ì„œ ì¥ë‹¨ì ì„ ë¹„êµí•˜ì—¬ í’€ì–´ê°€ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ê¸°ëŒ€ëœë‹¤.\n\n\n\n\n\n\n\n\nPerspective\nTraditional NLP\nLLM Fine-tuning\nLLM Prompt Engineering\n\n\n\nModel Adaptation\nFeature extraction and model selection\nFine-tuning on task-specific data\nCrafting effective prompts\n\n\nLabeled Data Requirements\nRequires labeled data for model training\nRequires labeled data for fine-tuning\nRequires fewer labeled examples, if any\n\n\nComputational Resources\nCan vary, but generally lower than LLM Fine-tuning\nHigher due to fine-tuning\nLower, as fine-tuning is not required\n\n\nPerformance\nMay be lower than LLM-based approaches\nTypically better due to task-specific fine-tuning\nCompetitive, but may require more manual effort\n\n\nEffort and Creativity\nRequires more manual feature engineering\nRequires less manual effort in prompt design\nRequires more creativity in prompt design and iteration\n\n\nDomain Adaptation\nLess effective for domain-specific tasks\nMore effective for domain-specific tasks\nMay be limited by the pretrained modelâ€™s knowledge\n\n\nInterpretability\nMore interpretable due to handcrafted features and models\nLess interpretable due to fine-tuned model weights\nMore interpretable as output is guided by designed prompts\n\n\nDeployment and Maintenance\nRequires storing and maintaining custom models\nRequires storing and maintaining fine-tuned models\nEasier, as only pretrained model and prompts are needed\n\n\nWhen to Use\nWhen custom features are needed or LLMs are not available\nWhen labeled data is available, higher performance is desired, and computational resources are sufficient\nWhen labeled data is scarce, computational resources are limited, or rapid development and iteration are required"
  },
  {
    "objectID": "inaugural.html#ëŒ€í‘œì ì¸-nlp-ì‘ì—…",
    "href": "inaugural.html#ëŒ€í‘œì ì¸-nlp-ì‘ì—…",
    "title": "chatGPT",
    "section": "\n1.1 ëŒ€í‘œì ì¸ NLP ì‘ì—…",
    "text": "1.1 ëŒ€í‘œì ì¸ NLP ì‘ì—…\nìˆ«ìê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ë¥¼ í†µí•´ ê°€ì¹˜ë¥¼ ì°½ì¶œí•  ìˆ˜ ìˆëŠ” ë¶„ì•¼ê°€ ìì—°ì–´ì²˜ë¦¬(NLP) ì˜ì—­ì´ë‹¤. ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ í”íˆ ì ‘í•˜ëŠ” ëŒ€í‘œì ì¸ ìƒìœ„ 10ê°€ì§€ NLPìœ¼ë¡œ ë‹¤ìŒì„ ë“¤ ìˆ˜ ìˆë‹¤.\n\nê°ì • ë¶„ì„: ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ë“± ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— í‘œí˜„ëœ ê°ì •ì„ íŒŒì•….\ní…ìŠ¤íŠ¸ ë¶„ë¥˜: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •ì˜ëœ í´ë˜ìŠ¤ ë˜ëŠ” ì£¼ì œ(ì˜ˆ: ìŠ¤í¬ì¸ , ì •ì¹˜, ì—°ì˜ˆ ë“±)ë¡œ ë¶„ë¥˜.\nê°œì²´ëª… ì¸ì‹(NER): í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì‚¬ëŒ, ì¡°ì§, ìœ„ì¹˜, ë‚ ì§œ ë“±ì˜ ëª…ëª…ëœ ê°œì²´(entity)ë¥¼ ì‹ë³„í•˜ê³  ë¶„ë¥˜.\ní’ˆì‚¬(POS) íƒœê¹…: ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ë‹¨ì–´ì— ë¬¸ë²•ì  ë ˆì´ë¸”(ì˜ˆ: ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬)ì„ í• ë‹¹.\nì˜ì¡´ì„± êµ¬ë¬¸ ë¶„ì„: ë¬¸ì¥ ë‚´ ë‹¨ì–´ ê°„ì˜ ë¬¸ë²• êµ¬ì¡°ì™€ ê´€ê³„ë¥¼ ì‹ë³„.\nê¸°ê³„ ë²ˆì—­: ì˜ì–´ì—ì„œ ìŠ¤í˜ì¸ì–´ë¡œ ë˜ëŠ” ì¤‘êµ­ì–´ì—ì„œ í”„ë‘ìŠ¤ì–´ë¡œì™€ ê°™ì´ í•œ ì–¸ì–´ì—ì„œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­.\nì§ˆì˜ ì‘ë‹µ: ìì—°ì–´ë¡œ ì œê¸°ëœ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ê°œë°œ.\ní…ìŠ¤íŠ¸ ìš”ì•½: ì£¼ìš” ì•„ì´ë””ì–´ì™€ ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°„ê²°í•œ ìš”ì•½ì„ ìƒì„±.\nìƒí˜¸ì°¸ì¡°í•´ê²°(Coreference Resolution): í…ìŠ¤íŠ¸ì—ì„œ ë‘ ê°œ ì´ìƒì˜ ë‹¨ì–´ë‚˜ êµ¬ê°€ ë™ì¼í•œ ê°œì²´ ë˜ëŠ” ê°œë…ì„ ì§€ì¹­í•˜ëŠ” ê²½ìš° ì‹ë³„.\ní…ìŠ¤íŠ¸ ìƒì„±: ì£¼ì–´ì§„ ì…ë ¥, ì»¨í…ìŠ¤íŠ¸ ë˜ëŠ” ì¼ë ¨ì˜ ì¡°ê±´ì— ë”°ë¼ ì¼ê´€ë˜ê³  ì˜ë¯¸ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±.\n\nìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ê³¼ ì‘ì—…íë¦„ì„ ì„œë¡œ ì—°ê²°í•˜ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê°œë³„ì ìœ¼ë¡œ ì¤‘ë³µë˜ê³  ë¶„ë¦¬ëœ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê²Œ ë˜ëŠ” ë¬¸ì œê°€ ìˆë‹¤.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;"
  },
  {
    "objectID": "inaugural.html#nlp-ê¸°ê³„í•™ìŠµ",
    "href": "inaugural.html#nlp-ê¸°ê³„í•™ìŠµ",
    "title": "chatGPT",
    "section": "\n2.1 NLP ê¸°ê³„í•™ìŠµ",
    "text": "2.1 NLP ê¸°ê³„í•™ìŠµ\nìì—°ì–´ì²˜ë¦¬(NLP) ê¸°ê³„í•™ìŠµì€ í†µê³„ëª¨í˜•ê³¼ ê±°ì˜ ë¹„ìŠ·í•œ ì‘ì—…íë¦„ì„ ê°–ëŠ”ë‹¤. ì°¨ì´ì ì´ ìˆë‹¤ë©´ ë°ì´í„° ê´€ê³„ì˜ ì„¤ëª…ë³´ë‹¤ ì˜ˆì¸¡ì— ë” ì¤‘ì ì„ ë‘”ë‹¤ëŠ” ì ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°ì„± ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë“± í…ìŠ¤íŠ¸ë¥¼ ë°ì´í„°ë¡œ í•˜ëŠ” ì „í†µì ì¸ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì€ ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…íë¦„ì„ ê°–ê²Œ ëœë‹¤.\n\n\n\n\n\n\ngraph TD\n    A[ë°ì´í„° ìˆ˜ì§‘] --&gt; B[ë°ì´í„° ì „ì²˜ë¦¬]\n    B --&gt; C[í”¼ì³ ì¶”ì¶œ]\n    C --&gt; D[í›ˆë ¨-í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„í• ]\n    D --&gt; E[ëª¨í˜• ì„ íƒ]\n    E --&gt; F[ëª¨í˜• í•™ìŠµ]\n    F --&gt; G[ëª¨í˜• í‰ê°€]\n    G --&gt; H[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]\n    H --&gt; I[ëª¨í˜• ë°°í¬]\n    I --&gt; J[ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜]\n\n\n\n\n\n\n\në°ì´í„° ìˆ˜ì§‘: í…ìŠ¤íŠ¸ ë°ì´í„°ì™€ í•´ë‹¹ ë ˆì´ë¸”ì´ í¬í•¨ëœ ë°ì´í„°ì…‹ì„ ìˆ˜ì§‘í•œë‹¤. ê°ì„± ë¶„ì„ì˜ ê²½ìš°, ë¼ë²¨ì€ â€˜ê¸ì •â€™, â€˜ë¶€ì •â€™ ë˜ëŠ” â€™ì¤‘ë¦½â€™ì´ ë˜ê³ , í…ìŠ¤íŠ¸ ë¶„ë¥˜ì˜ ê²½ìš° ë ˆì´ë¸”ì€ ë‹¤ì–‘í•œ ì£¼ì œë‚˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì¦‰, ìì—°ì–´ ì²˜ë¦¬ ëª©ì ì— ë§ì¶° ë¼ë²¨ì„ íŠ¹ì •í•˜ê³  ì—°ê´€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œë‹¤.\në°ì´í„° ì „ì²˜ë¦¬: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ ì¶”ê°€ ë¶„ì„ì— ì í•©í•˜ë„ë¡ ì‘ì—…í•˜ëŠ”ë° ì†Œë¬¸ìí™”, í† í°í™”, ë¶ˆìš©ì–´ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì–´ê°„ ë‹¨ì–´ ê¸°ë³¸í˜•ìœ¼ë¡œ ì¤„ì´ê¸° ë“±ì´ í¬í•¨ëœë‹¤.\ní”¼ì³ ì¶”ì¶œ:ì‚¬ì „ ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì— ì í•©í•œ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ BoW, TF-IDF, ë‹¨ì–´ ì„ë² ë”© ë“±ì´ í”íˆ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì´ë‹¤.\ní›ˆë ¨-ì‹œí—˜ ë°ì´í„°ì…‹ ë¶„í• : ì¼ë°˜ì ìœ¼ë¡œ 70-30, 80-20 ë˜ëŠ” ê¸°íƒ€ ì›í•˜ëŠ” ë¶„í•  ë¹„ìœ¨ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ í›ˆë ¨ê³¼ ì‹œí—˜ ë°ì´í„°ì…‹ìœ¼ë¡œ êµ¬ë¶„í•œë‹¤.\nëª¨í˜• ì„ íƒ: ì í•©í•œ í†µê³„, ë¨¸ì‹  ëŸ¬ë‹, ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì„ ì •í•œë‹¤.\nëª¨í˜• í•™ìŠµ: ì ì ˆí•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ê³¼ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ ì„ íƒí•œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.\nëª¨í˜• í‰ê°€: ì •í™•ë„, ì •ë°€ë„, ë¦¬ì½œ, F1 ì ìˆ˜ ë˜ëŠ” ROC ê³¡ì„  ì•„ë˜ ì˜ì—­ê³¼ ê°™ì€ ê´€ë ¨ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•˜ì—¬ ì‹œí—˜ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤.\ní•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹: ê²©ì ê²€ìƒ‰ ë˜ëŠ” ë¬´ì‘ìœ„ ê²€ìƒ‰ê³¼ ê°™ì€ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ëª¨í˜•ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•œë‹¤.\nëª¨í˜• ë°°í¬: ëª¨í˜•ì„ í•™ìŠµí•˜ê³  ìµœì í™”í•œ í›„ì—ëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì— ë°°í¬í•˜ì—¬ ê°€ì¹˜ë¥¼ ì°½ì¶œí•œë‹¤.\nëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ ê´€ë¦¬: ë°°í¬ëœ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì— ë”°ë¼ ìƒˆë¡œìš´ í•™ìŠµë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ ì •í™•ì„±ê³¼ íš¨ìœ¨ì„±ì„ ìœ ì§€í•œë‹¤."
  },
  {
    "objectID": "inaugural.html#nlp-vs-llm",
    "href": "inaugural.html#nlp-vs-llm",
    "title": "chatGPT",
    "section": "\n3.1 NLP vs LLM",
    "text": "3.1 NLP vs LLM\nì§€êµ¬ìƒì˜ ê±°ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì´ ì¡´ì¬í•˜ëŠ” ìƒí™©ì´ê¸° ë•Œë¬¸ì— ì ì ˆí•œ LLMì„ ì„ íƒí•œ í›„ì— ì¢€ë” ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ì„œ ì¶”ê°€ í•™ìŠµë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¯¸ì„¸ì¡°ì •(Fine-tuning) í•™ìŠµì„ ê±°ì¹œ í›„ì— AI ëª¨í˜•ì„ ë°°í¬í•˜ì—¬ ìš´ì˜í•œë‹¤.\n\n\n\n\ngraph TB\n\nsubgraph \"ì „í†µì ì¸ NLP ì‘ì—…íë¦„ &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nsubgraph \"ê±°ëŒ€ì–¸ì–´ê¸°ë°˜ NLP ì‘ì—…íë¦„ &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "inaugural.html#fine-tuning-llm-vs-prompt-eng.",
    "href": "inaugural.html#fine-tuning-llm-vs-prompt-eng.",
    "title": "chatGPT",
    "section": "\n3.2 Fine-tuning LLM vs Prompt Eng.",
    "text": "3.2 Fine-tuning LLM vs Prompt Eng.\në‘ê°€ì§€ ì ‘ê·¼ë°©ë²• ëª¨ë‘ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì— ê¸°ë°˜í•œë‹¤ëŠ” ì ì—ì„œ ë™ì¼í•˜ë‚˜, ì¶”ê°€í•™ìŠµ ë°ì´í„°ë¥¼ ë°˜ì˜í•œ AI ëª¨í˜•ì„ ê°œë°œí•˜ëŠëƒ ì•„ë‹ˆë©´ í”„ë¡¬í”„íŠ¸(ì¼ëª… AI í”„ë¡œê·¸ë¨)ë¥¼ ì˜ ì‘ì„±í•œ AI ëª¨í˜•ì„ ê°œë°œí•˜ëŠëƒ ì°¨ì´ê°€ ì¡´ì¬í•œë‹¤. ë¬¼ë¡  Zero-/One-/Few-Shot ì˜ˆì œë¥¼ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ë„ ìˆê³  ë¯¸ì„¸ì¡°ì • í›ˆë ¨ëª¨í˜•ì— í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜ì˜í•œ AI ëª¨í˜•ë„ ì¡´ì¬í•œë‹¤. ê° ë¬¸ì œì— ë§ì¶° ì ì ˆí•œ ê°œë°œë°©ë²•ì„ ì·¨í•˜ë©´ ë  ê²ƒì´ë‹¤.\n\n\n\n\ngraph TB\nsubgraph \"ë¯¸ì„¸ì¡°ì • ì‘ì—…íë¦„&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[ì‚¬ì „ í›ˆë ¨] --&gt; B1[ë¯¸ì„¸ ì¡°ì •]\n  B1 --&gt; C1[ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€]\n  C1 --&gt; D1[í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹]\n  D1 --&gt; E1[ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜]\nend\n\nsubgraph \"í”„ë¡¬í”„íŠ¸ ê³µí•™ ì‘ì—…íë¦„&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[ì‚¬ì „ í•™ìŠµ] --&gt; B2[í”„ë¡¬í”„íŠ¸ ì„¤ê³„]\n  B2 --&gt; C2[ëª¨ë¸ ì¶”ë¡  ë° í›„ì²˜ë¦¬]\n  C2 --&gt; D2[ëª¨ë¸ í‰ê°€]\n  D2 --&gt; E2[ë°°í¬ ë° ìœ ì§€ë³´ìˆ˜]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "inaugural.html#ë¹„êµ-1",
    "href": "inaugural.html#ë¹„êµ-1",
    "title": "chatGPT",
    "section": "\n3.3 ë¹„êµ",
    "text": "3.3 ë¹„êµ\nLLM ëª¨í˜•ì„ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ê³µê°œí•˜ëŠ” ê²½ìš° ì´ë¥¼ ëŒë¦´ ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ í•˜ë“œì›¨ì–´ê°€ í•„ìš”í•˜ê¸°ë„ í•˜ê³ , LLMì„ ë¹„ê³µê°œí•˜ëŠ” ê²½ìš° êµ¬ë…í˜•ìœ¼ë¡œ ë¹„ìš©ì„ ì²­êµ¬í•˜ì—¬ AI ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°ë„ ì¡´ì¬í•œë‹¤. í•´ë‹¹ ë¬¸ì œë¥¼ ê°€ì¥ ì˜ í•´ê²°í•  ìˆ˜ ìˆëŠ” AI ê°œë°œë°©ë²•ë¡ ì„ ì£¼ì–´ì§„ ì œì•½ì¡°ê±´ì—ì„œ ì¥ë‹¨ì ì„ ë¹„êµí•˜ì—¬ í’€ì–´ê°€ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ê¸°ëŒ€ëœë‹¤.\n\n\n\n\n\n\n\n\nPerspective\nTraditional NLP\nLLM Fine-tuning\nLLM Prompt Engineering\n\n\n\nModel Adaptation\nFeature extraction and model selection\nFine-tuning on task-specific data\nCrafting effective prompts\n\n\nLabeled Data Requirements\nRequires labeled data for model training\nRequires labeled data for fine-tuning\nRequires fewer labeled examples, if any\n\n\nComputational Resources\nCan vary, but generally lower than LLM Fine-tuning\nHigher due to fine-tuning\nLower, as fine-tuning is not required\n\n\nPerformance\nMay be lower than LLM-based approaches\nTypically better due to task-specific fine-tuning\nCompetitive, but may require more manual effort\n\n\nEffort and Creativity\nRequires more manual feature engineering\nRequires less manual effort in prompt design\nRequires more creativity in prompt design and iteration\n\n\nDomain Adaptation\nLess effective for domain-specific tasks\nMore effective for domain-specific tasks\nMay be limited by the pretrained modelâ€™s knowledge\n\n\nInterpretability\nMore interpretable due to handcrafted features and models\nLess interpretable due to fine-tuned model weights\nMore interpretable as output is guided by designed prompts\n\n\nDeployment and Maintenance\nRequires storing and maintaining custom models\nRequires storing and maintaining fine-tuned models\nEasier, as only pretrained model and prompts are needed\n\n\nWhen to Use\nWhen custom features are needed or LLMs are not available\nWhen labeled data is available, higher performance is desired, and computational resources are sufficient\nWhen labeled data is scarce, computational resources are limited, or rapid development and iteration are required"
  },
  {
    "objectID": "inaugural.html",
    "href": "inaugural.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì„ë² ë”©(embedding)ì€ ê°œë…ì„ ìˆ«ì ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•œ ìˆ˜ì¹˜ í‘œí˜„ìœ¼ë¡œ, ì»´í“¨í„°ê°€ ê°œë… ê°„ì˜ ê´€ê³„ë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ì´ë¥¼ í†µí•´ì„œ ê¸°ì¡´ì— ê°œë³„ì ìœ¼ë¡œ ìˆ˜í–‰í–ˆë˜ ì‘ì—…ì„ í†µí•©ì ìœ¼ë¡œ ì¶”ì§„í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ê²Œ ë˜ì—ˆë‹¤. ìˆ˜ì¹˜ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì„ë² ë”©ì€ ì˜ë¯¸ì ìœ¼ë¡œë„ ìœ ì‚¬í•˜ê¸° ë•Œë¬¸ì— ì„ë² ë”©ì„ í†µí•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ìœ ì‚¬í•œ ê²ƒìœ¼ë¡œ ëª¨ìœ¼ëŠ” êµ°ì§‘ë¶„ì„ì´ë‚˜ ë¬¸ì„œ ê²€ìƒ‰ê³¼ ê°™ì€ NLP ì‘ì—…ì´ ìˆ˜ì›”í•´ì¡Œë‹¤.\nOpenAIì—ì„œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„, í…ìŠ¤íŠ¸ ê²€ìƒ‰, ì½”ë“œ ê²€ìƒ‰ìš©ìœ¼ë¡œ ì„¸ê°€ì§€ ëª¨ë¸ì„ ê³µê°œí–ˆë‹¤.1 2022ë…„ 12ì›” 5ì¼ ê³µê°œëœ text-embedding-ada-002 ëª¨í˜•ì€ í…ìŠ¤íŠ¸ ê²€ìƒ‰, í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë° ì½”ë“œ ê²€ìƒ‰ì„ ìœ„í•œ 5ê°œ ê°œë³„ ëª¨ë¸ì„ ëŒ€ì²´í•˜ë©°, ëŒ€ë¶€ë¶„ì˜ ì‘ì—…ì—ì„œ ì´ì „ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì¸ ë‹¤ë¹ˆì¹˜ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë©´ì„œë„ ê°€ê²©ì€ 99.8% ì €ë ´í•˜ê¸° ë•Œë¬¸ì— text-embedding-ada-002 ëª¨í˜•ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‚´í´ë³´ë©´ ëœë‹¤. 2 í…ìŠ¤íŠ¸ ë¶„ë¥˜ì—ì„œë§Œ text-similarity-*davinci*-001 ëª¨í˜•ë³´ë‹¤ ì„±ëŠ¥ì´ ë‹¤ì†Œ ë–¨ì–´ì§€ê³  ë‚˜ë¨¸ì§€ ë¶„ì•¼ì—ì„œëŠ” ëª¨ë‘ ì•ì„  ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ë©´ì„œë„ ê°€ê²©ì´ ì €ë ´í•˜ë‹¤. 3"
  },
  {
    "objectID": "inaugural.html#íŒŒíŒŒê³ ",
    "href": "inaugural.html#íŒŒíŒŒê³ ",
    "title": "chatGPT",
    "section": "\n2.1 íŒŒíŒŒê³ ",
    "text": "2.1 íŒŒíŒŒê³ \n\nì½”ë“œ\ntranslate_papago &lt;- function(text, source=\"ko\", target=\"en\") {\n\n  transURL &lt;- \"https://openapi.naver.com/v1/papago/n2mt\"\n\n  response &lt;- transURL %&gt;%\n    httr::POST(\n      httr::add_headers(\n        \"Content-Type\"          = \"application/x-www-form-urlencoded; charset=UTF-8\",\n        \"X-Naver-Client-Id\"     = Sys.getenv('NAVER_CLIENT_ID'),\n        \"X-Naver-Client-Secret\" = Sys.getenv('NAVER_CLIENT_SECRET')\n      ),\n      body = glue::glue(\"text={text}&source={source}&target={target}\")\n    ) %&gt;%\n    toString() %&gt;%\n    jsonlite::fromJSON()\n  \n  Sys.sleep(1)\n\n  response$message$result$translatedText\n}\n\ntranlated &lt;- fs::dir_ls(\"data/Inaugural-eng/\")\n\ntranslated_tbl &lt;- tranlated %&gt;% \n  enframe(name = \"íŒŒì¼ê²½ë¡œ\") %&gt;% \n  separate(value, into = c(\"ì—­ëŒ€\", \"ëŒ€í†µë ¹\"), sep=\"_\") %&gt;% \n  mutate(ëŒ€í†µë ¹ = str_remove(ëŒ€í†µë ¹, \"\\\\.txt\")) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = map(íŒŒì¼ê²½ë¡œ, read_lines)) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = map_chr(ì˜ë¬¸ë²ˆì—­, paste0, collapse = \" \")) %&gt;% \n  select(ì—­ëŒ€, ëŒ€í†µë ¹, ì˜ë¬¸ë²ˆì—­) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = str_squish(ì˜ë¬¸ë²ˆì—­)) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = str_replace_all(ì˜ë¬¸ë²ˆì—­, \"ã†\", \", \"))\n\n\ntranslated_tbl\n#&gt; # A tibble: 13 Ã— 3\n#&gt;    ì—­ëŒ€                      ëŒ€í†µë ¹ ì˜ë¬¸ë²ˆì—­                                    \n#&gt;    &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;                                       \n#&gt;  1 data/Inaugural-eng/ì œ03ëŒ€ ì´ìŠ¹ë§Œ \"My fellow countrymen and women. Today I stâ€¦\n#&gt;  2 data/Inaugural-eng/ì œ04ëŒ€ ìœ¤ë³´ì„  \"My excitement yesterday at being honored aâ€¦\n#&gt;  3 data/Inaugural-eng/ì œ09ëŒ€ ë°•ì •í¬ \"Dear 50 million compatriots! And distinguiâ€¦\n#&gt;  4 data/Inaugural-eng/ì œ10ëŒ€ ìµœê·œí•˜ \"Dear compatriots at home and abroad! And dâ€¦\n#&gt;  5 data/Inaugural-eng/ì œ12ëŒ€ ì „ë‘í™˜ \"Dear compatriots at home and abroad! And dâ€¦\n#&gt;  6 data/Inaugural-eng/ì œ13ëŒ€ ë…¸íƒœìš° \"Dear 60 million compatriots at home and abâ€¦\n#&gt;  7 data/Inaugural-eng/ì œ14ëŒ€ ê¹€ì˜ì‚¼ \"Dear 70 million compatriots at home and abâ€¦\n#&gt;  8 data/Inaugural-eng/ì œ15ëŒ€ ê¹€ëŒ€ì¤‘ \"Honored and beloved citizens of the Republâ€¦\n#&gt;  9 data/Inaugural-eng/ì œ16ëŒ€ ë…¸ë¬´í˜„ \"Honorable fellow citizens. Today I stand hâ€¦\n#&gt; 10 data/Inaugural-eng/ì œ17ëŒ€ ì´ëª…ë°• \"Honored citizens! 7 million overseas Koreaâ€¦\n#&gt; 11 data/Inaugural-eng/ì œ18ëŒ€ ë°•ê·¼í˜œ \"We will usher in a new era of hope. Honoraâ€¦\n#&gt; 12 data/Inaugural-eng/ì œ19ëŒ€ ë¬¸ì¬ì¸ \"My honored and beloved people! Thank you. â€¦\n#&gt; 13 data/Inaugural-eng/ì œ20ëŒ€ ìœ¤ì„ì—´ \"My honored and beloved countrymen, our 7.5â€¦\n\n\n\nì½”ë“œtranslated_embedding &lt;- translated_tbl %&gt;% \n  mutate(ì„ë² ë”© = map(ì˜ë¬¸ë²ˆì—­, get_embedding))\n\ntranslated_embedding %&gt;% \n  write_rds(\"data/translated_embedding.rds\")\n\n\n\nì½”ë“œtranslated_embedding &lt;- \n  read_rds(\"data/translated_embedding.rds\")\n\ntranslated_mat &lt;- matrix(\n  unlist(translated_embedding$ì„ë² ë”©), \n  ncol = 1536, byrow = TRUE\n)\n\ndim(translated_mat)\n#&gt; [1]   13 1536\n\ntranslated_similarity &lt;- translated_mat / sqrt(rowSums(translated_mat * translated_mat))\ntranslated_similarity &lt;- translated_similarity %*% t(translated_similarity)\ndim(translated_similarity)\n#&gt; [1] 13 13\n\nenframe(translated_similarity[13,], name = \"ì—°ì„¤ë¬¸\", value = \"ìœ ì‚¬ë„\") %&gt;%\n  arrange(-ìœ ì‚¬ë„)\n#&gt; # A tibble: 13 Ã— 2\n#&gt;    ì—°ì„¤ë¬¸ ìœ ì‚¬ë„\n#&gt;     &lt;int&gt;  &lt;dbl&gt;\n#&gt;  1     13  1.00 \n#&gt;  2     10  0.924\n#&gt;  3      7  0.922\n#&gt;  4      1  0.922\n#&gt;  5      6  0.920\n#&gt;  6      8  0.918\n#&gt;  7      4  0.914\n#&gt;  8      5  0.914\n#&gt;  9      9  0.914\n#&gt; 10     11  0.908\n#&gt; 11      2  0.905\n#&gt; 12     12  0.899\n#&gt; 13      3  0.894\n\nset.seed(777)\ntranslated_pca &lt;- irlba::prcomp_irlba(translated_mat, n = 3)\n\ntranslated_pca_tbl &lt;- \n  as_tibble(translated_pca$x) %&gt;%\n  bind_cols(translated_embedding)\n\ntranslated_pca_tbl %&gt;%\n  ggplot(aes(PC1, PC2)) +\n    geom_point(size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=ëŒ€í†µë ¹)) +\n    theme_bw(base_family=\"NanumGothic\")\n\n\n\n\n\n\nì½”ë“œ\nsummary(translated_pca)\n#&gt; Importance of components:\n#&gt;                           PC1    PC2     PC3\n#&gt; Standard deviation     0.1087 0.1033 0.09497\n#&gt; Proportion of Variance 0.1719 0.1551 0.13111\n#&gt; Cumulative Proportion  0.1719 0.3269 0.45805\n\n\n\nì½”ë“œlibrary(umap)\ntranslated_umap &lt;- umap(translated_mat, n_neighbors = 3)\n\ntranslated_viz &lt;- translated_umap$layout %&gt;%\n  as.data.frame()%&gt;%\n  rename(UMAP1=\"V1\",\n         UMAP2=\"V2\") %&gt;% \n  bind_cols(translated_embedding)\n\numap_df %&gt;% names()\n#&gt; [1] \"UMAP1\"  \"UMAP2\"  \"ì—­ëŒ€\"   \"ëŒ€í†µë ¹\" \"ì·¨ì„ì‚¬\" \"ì„ë² ë”©\"\n\ntranslated_viz %&gt;%\n  ggplot(aes(x = UMAP1, \n             y = UMAP2))+\n    geom_point(size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=ëŒ€í†µë ¹)) +\n    theme_bw(base_family=\"NanumGothic\")"
  },
  {
    "objectID": "inaugural.html#êµ­ë¬¸-ì·¨ì„ì‚¬",
    "href": "inaugural.html#êµ­ë¬¸-ì·¨ì„ì‚¬",
    "title": "chatGPT",
    "section": "\n2.1 êµ­ë¬¸ ì·¨ì„ì‚¬",
    "text": "2.1 êµ­ë¬¸ ì·¨ì„ì‚¬\ní–‰ì •ì•ˆì „ë¶€ ëŒ€í†µë ¹ê¸°ë¡ê´€ ê¸°ë¡ì»¬ë ‰ì…˜ ì—°ì„¤ê¸°ë¡ì—ì„œ ì—­ëŒ€ ëŒ€í†µë ¹ì˜ ì·¨ì„ì‚¬ë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆë‹¤. ì´ìŠ¹ë§Œ, ë°•ì •í¬, ì „ë‘í™˜ ëŒ€í†µë ¹ì˜ ê²½ìš° 2íšŒ ì´ìƒ ëŒ€í†µë ¹ì„ ì—­ì„í–ˆê¸° ë•Œë¬¸ì— ê°€ì¥ ë§ˆì§€ë§‰ ì·¨ì„ì‚¬ë¥¼ ë°›ì•„ì˜¨ë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n\npresidents &lt;- fs::dir_ls(\"data/Inaugural/\")\n\ninaugural_tbl &lt;- presidents %&gt;% \n  enframe(name = \"íŒŒì¼ê²½ë¡œ\") %&gt;% \n  separate(value, into = c(\"ì—­ëŒ€\", \"ëŒ€í†µë ¹\"), sep=\"_\") %&gt;% \n  mutate(ëŒ€í†µë ¹ = str_remove(ëŒ€í†µë ¹, \"\\\\.txt\")) %&gt;% \n  mutate(ì·¨ì„ì‚¬ = map(íŒŒì¼ê²½ë¡œ, read_lines)) %&gt;% \n  mutate(ì·¨ì„ì‚¬ = map_chr(ì·¨ì„ì‚¬, paste0, collapse = \" \")) %&gt;% \n  select(ì—­ëŒ€, ëŒ€í†µë ¹, ì·¨ì„ì‚¬) %&gt;% \n  mutate(ì·¨ì„ì‚¬ = str_squish(ì·¨ì„ì‚¬)) %&gt;% \n  mutate(ì·¨ì„ì‚¬ = str_replace_all(ì·¨ì„ì‚¬, \"ã†\", \", \"))\n\ninaugural_tbl\n#&gt; # A tibble: 13 Ã— 3\n#&gt;    ì—­ëŒ€                  ëŒ€í†µë ¹ ì·¨ì„ì‚¬                                          \n#&gt;    &lt;chr&gt;                 &lt;chr&gt;  &lt;chr&gt;                                           \n#&gt;  1 data/Inaugural/ì œ03ëŒ€ ì´ìŠ¹ë§Œ \"ë‚˜ì˜ ì‚¬ë‘í•˜ëŠ” ë™í¬ ì—¬ëŸ¬ë¶„. ë‚´ê°€ ì˜¤ëŠ˜ ë˜ í•œë²ˆ â€¦ \n#&gt;  2 data/Inaugural/ì œ04ëŒ€ ìœ¤ë³´ì„  \"ì œ2ê³µí™”êµ­ì˜ ì´ˆëŒ€ëŒ€í†µë ¹ìœ¼ë¡œ ì˜ì˜ˆì˜ ë‹¹ì„ ì„ ì–»ì€ â€¦\n#&gt;  3 data/Inaugural/ì œ09ëŒ€ ë°•ì •í¬ \"ì¹œì• í•˜ëŠ” 5ì²œë§Œ ë™í¬ ì—¬ëŸ¬ë¶„! ê·¸ë¦¬ê³  ë‚´ì™¸ ê·€ë¹ˆ â€¦ \n#&gt;  4 data/Inaugural/ì œ10ëŒ€ ìµœê·œí•˜ \"ì¹œì• í•˜ëŠ” êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„! ê·¸ë¦¬ê³  ì´ ìë¦¬ë¥¼ â€¦\n#&gt;  5 data/Inaugural/ì œ12ëŒ€ ì „ë‘í™˜ \"ì¹œì• í•˜ëŠ” êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„! ê·¸ë¦¬ê³  ì´ ìë¦¬ë¥¼ â€¦\n#&gt;  6 data/Inaugural/ì œ13ëŒ€ ë…¸íƒœìš° \"ì¹œì• í•˜ëŠ” 6ì²œë§Œ êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„. ìš°ë¦¬ í—Œì •ë°œâ€¦\n#&gt;  7 data/Inaugural/ì œ14ëŒ€ ê¹€ì˜ì‚¼ \"ì¹œì• í•˜ëŠ” 7ì²œë§Œ êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„, ë…¸íƒœìš° ëŒ€í†µâ€¦\n#&gt;  8 data/Inaugural/ì œ15ëŒ€ ê¹€ëŒ€ì¤‘ \"ì¡´ê²½í•˜ê³  ì‚¬ë‘í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„! ì˜¤ëŠ˜ ì €ëŠ” ëŒ€í•œâ€¦ \n#&gt;  9 data/Inaugural/ì œ16ëŒ€ ë…¸ë¬´í˜„ \"ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„. ì˜¤ëŠ˜ ì €ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì œ1â€¦\n#&gt; 10 data/Inaugural/ì œ17ëŒ€ ì´ëª…ë°• \"ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„! 700ë§Œ í•´ì™¸ë™í¬ ì—¬ëŸ¬ë¶„, â€¦ \n#&gt; 11 data/Inaugural/ì œ18ëŒ€ ë°•ê·¼í˜œ \"í¬ë§ì˜ ìƒˆ ì‹œëŒ€ë¥¼ ì—´ê² ìŠµë‹ˆë‹¤. ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ì—¬ëŸ¬â€¦\n#&gt; 12 data/Inaugural/ì œ19ëŒ€ ë¬¸ì¬ì¸ \"ì¡´ê²½í•˜ê³  ì‚¬ë‘í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„! ê°ì‚¬í•©ë‹ˆë‹¤. êµ­â€¦ \n#&gt; 13 data/Inaugural/ì œ20ëŒ€ ìœ¤ì„ì—´ \"ì¡´ê²½í•˜ê³  ì‚¬ë‘í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„, 750ë§Œ ì¬ì™¸ë™í¬ â€¦"
  },
  {
    "objectID": "inaugural.html#ë”¥ì—˜-ì˜ë¬¸-ì·¨ì„ì‚¬",
    "href": "inaugural.html#ë”¥ì—˜-ì˜ë¬¸-ì·¨ì„ì‚¬",
    "title": "chatGPT",
    "section": "\n2.2 [ë”¥ì—˜] ì˜ë¬¸ ì·¨ì„ì‚¬",
    "text": "2.2 [ë”¥ì—˜] ì˜ë¬¸ ì·¨ì„ì‚¬\níŒŒíŒŒê³  APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆìœ¼ë‚˜ ì¼ 50,000ê¸€ìë¡œ ì œí•œì´ ìˆê³  ì¶”ê°€ ë¹„ìš©ì„ ì§€ë¶ˆí•˜ëŠ” ê¸ˆì „ì ì¸ ë¬¸ì œë„ ìˆê³  ë”¥ì—˜(DeepL) ë³´ë‹¤ ë²ˆì—­í’ˆì§ˆì—ì„œ ë‚«ê¸° ë•Œë¬¸ì— ê¸°ë³¸ ì½”ë“œë§Œ ì‘ì„±í•´ ë‘”ë‹¤. ë²ˆì—­í’ˆì§ˆì´ ìµœìƒì€ ì•„ë‹ˆì§€ë§Œ ì¼ë°˜ì ì¸ ë²ˆì—­ í’ˆì§ˆì—ëŠ” í° ì°¨ì´ëŠ” ì—†ë‹¤.\n\nì½”ë“œtranslate_papago &lt;- function(text, source=\"ko\", target=\"en\") {\n\n  transURL &lt;- \"https://openapi.naver.com/v1/papago/n2mt\"\n\n  response &lt;- transURL %&gt;%\n    httr::POST(\n      httr::add_headers(\n        \"Content-Type\"          = \"application/x-www-form-urlencoded; charset=UTF-8\",\n        \"X-Naver-Client-Id\"     = Sys.getenv('NAVER_CLIENT_ID'),\n        \"X-Naver-Client-Secret\" = Sys.getenv('NAVER_CLIENT_SECRET')\n      ),\n      body = glue::glue(\"text={text}&source={source}&target={target}\")\n    ) %&gt;%\n    toString() %&gt;%\n    jsonlite::fromJSON()\n  \n  Sys.sleep(1)\n\n  response$message$result$translatedText\n}\n\ntranlated &lt;- fs::dir_ls(\"data/Inaugural-eng/\")\n\ntranslated_tbl &lt;- tranlated %&gt;% \n  enframe(name = \"íŒŒì¼ê²½ë¡œ\") %&gt;% \n  separate(value, into = c(\"ì—­ëŒ€\", \"ëŒ€í†µë ¹\"), sep=\"_\") %&gt;% \n  mutate(ëŒ€í†µë ¹ = str_remove(ëŒ€í†µë ¹, \"\\\\.txt\")) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = map(íŒŒì¼ê²½ë¡œ, read_lines)) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = map_chr(ì˜ë¬¸ë²ˆì—­, paste0, collapse = \" \")) %&gt;% \n  select(ì—­ëŒ€, ëŒ€í†µë ¹, ì˜ë¬¸ë²ˆì—­) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = str_squish(ì˜ë¬¸ë²ˆì—­)) %&gt;% \n  mutate(ì˜ë¬¸ë²ˆì—­ = str_replace_all(ì˜ë¬¸ë²ˆì—­, \"ã†\", \", \"))\n\n# DeepL ë²ˆì—­ ê²°ê³¼\ntranslated_tbl\n#&gt; # A tibble: 13 Ã— 3\n#&gt;    ì—­ëŒ€                      ëŒ€í†µë ¹ ì˜ë¬¸ë²ˆì—­                                    \n#&gt;    &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;                                       \n#&gt;  1 data/Inaugural-eng/ì œ03ëŒ€ ì´ìŠ¹ë§Œ \"My fellow countrymen and women. Today I stâ€¦\n#&gt;  2 data/Inaugural-eng/ì œ04ëŒ€ ìœ¤ë³´ì„  \"My excitement yesterday at being honored aâ€¦\n#&gt;  3 data/Inaugural-eng/ì œ09ëŒ€ ë°•ì •í¬ \"Dear 50 million compatriots! And distinguiâ€¦\n#&gt;  4 data/Inaugural-eng/ì œ10ëŒ€ ìµœê·œí•˜ \"Dear compatriots at home and abroad! And dâ€¦\n#&gt;  5 data/Inaugural-eng/ì œ12ëŒ€ ì „ë‘í™˜ \"Dear compatriots at home and abroad! And dâ€¦\n#&gt;  6 data/Inaugural-eng/ì œ13ëŒ€ ë…¸íƒœìš° \"Dear 60 million compatriots at home and abâ€¦\n#&gt;  7 data/Inaugural-eng/ì œ14ëŒ€ ê¹€ì˜ì‚¼ \"Dear 70 million compatriots at home and abâ€¦\n#&gt;  8 data/Inaugural-eng/ì œ15ëŒ€ ê¹€ëŒ€ì¤‘ \"Honored and beloved citizens of the Republâ€¦\n#&gt;  9 data/Inaugural-eng/ì œ16ëŒ€ ë…¸ë¬´í˜„ \"Honorable fellow citizens. Today I stand hâ€¦\n#&gt; 10 data/Inaugural-eng/ì œ17ëŒ€ ì´ëª…ë°• \"Honored citizens! 7 million overseas Koreaâ€¦\n#&gt; 11 data/Inaugural-eng/ì œ18ëŒ€ ë°•ê·¼í˜œ \"We will usher in a new era of hope. Honoraâ€¦\n#&gt; 12 data/Inaugural-eng/ì œ19ëŒ€ ë¬¸ì¬ì¸ \"My honored and beloved people! Thank you. â€¦\n#&gt; 13 data/Inaugural-eng/ì œ20ëŒ€ ìœ¤ì„ì—´ \"My honored and beloved countrymen, our 7.5â€¦"
  },
  {
    "objectID": "inaugural.html#ì˜ë¬¸-ì·¨ì„ì‚¬",
    "href": "inaugural.html#ì˜ë¬¸-ì·¨ì„ì‚¬",
    "title": "chatGPT",
    "section": "\n2.3 ì˜ë¬¸ ì·¨ì„ì‚¬",
    "text": "2.3 ì˜ë¬¸ ì·¨ì„ì‚¬\nìµœê·¼ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ëŠ” ì™¸êµë¶€ë‚˜ êµ¬ê¸€ ì¸í„°ë„· ê²€ìƒ‰ì„ í†µí•´ ì˜ë¬¸ìœ¼ë¡œ ì·¨ì„ì‚¬ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œeng_inaugural &lt;- fs::dir_ls(\"data/inaugural-mofa/\")\n\ninaugural_eng_tbl &lt;- eng_inaugural %&gt;% \n  enframe(name = \"íŒŒì¼ê²½ë¡œ\") %&gt;% \n  separate(value, into = c(\"ì—­ëŒ€\", \"ëŒ€í†µë ¹\"), sep=\"_\") %&gt;% \n  mutate(ëŒ€í†µë ¹ = str_remove(ëŒ€í†µë ¹, \"\\\\.txt\")) %&gt;% \n  mutate(ì˜ë¬¸ì·¨ì„ì‚¬ = map(íŒŒì¼ê²½ë¡œ, read_lines)) %&gt;% \n  mutate(ì˜ë¬¸ì·¨ì„ì‚¬ = map_chr(ì˜ë¬¸ì·¨ì„ì‚¬, paste0, collapse = \" \")) %&gt;%   \n  mutate(ì—°ì„¤ë¬¸ê¸¸ì´ = str_length(ì˜ë¬¸ì·¨ì„ì‚¬)) %&gt;% \n  filter(ì—°ì„¤ë¬¸ê¸¸ì´ &gt; 1000) %&gt;% \n  select(ì—­ëŒ€, ëŒ€í†µë ¹, ì˜ë¬¸ì·¨ì„ì‚¬) %&gt;% \n  mutate(ì˜ë¬¸ì·¨ì„ì‚¬ = str_squish(ì˜ë¬¸ì·¨ì„ì‚¬)) \n\n# ì˜ì–´ì·¨ì„ì‚¬\ninaugural_eng_tbl\n#&gt; # A tibble: 5 Ã— 3\n#&gt;   ì—­ëŒ€                       ëŒ€í†µë ¹ ì˜ë¬¸ì·¨ì„ì‚¬                                  \n#&gt;   &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt;                                       \n#&gt; 1 data/inaugural-mofa/ì œ15ëŒ€ ê¹€ëŒ€ì¤‘ \"My fellow countrymen, Today, I am being inâ€¦\n#&gt; 2 data/inaugural-mofa/ì œ17ëŒ€ ì´ëª…ë°• \"Together We Shall Open, A Road to Advancemâ€¦\n#&gt; 3 data/inaugural-mofa/ì œ18ëŒ€ ë°•ê·¼í˜œ \"My fellow Koreans and seven million fellowâ€¦\n#&gt; 4 data/inaugural-mofa/ì œ19ëŒ€ ë¬¸ì¬ì¸ \"My fellow Koreans, I am grateful to you alâ€¦\n#&gt; 5 data/inaugural-mofa/ì œ20ëŒ€ ìœ¤ì„ì—´ \"My fellow Koreans, Seven and a half millioâ€¦"
  },
  {
    "objectID": "inaugural.html#api-í˜¸ì¶œ-í•¨ìˆ˜",
    "href": "inaugural.html#api-í˜¸ì¶œ-í•¨ìˆ˜",
    "title": "chatGPT",
    "section": "\n3.1 API í˜¸ì¶œ í•¨ìˆ˜",
    "text": "3.1 API í˜¸ì¶œ í•¨ìˆ˜\nget_embedding() í•¨ìˆ˜ë¥¼ ì œì‘í•˜ì—¬ êµ­,ì˜ë¬¸ ì·¨ì„ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•˜ì—¬ ì„ë² ë”© ê°’ì„ ë°˜í™˜ë°›ëŠ”ë‹¤. ë§¤ë²ˆ APIë¥¼ í˜¸ì¶œí•  ë•Œë§ˆë‹¤ ë¹„ìš©ì´ ë°œìƒë˜ê¸° ë•Œë¬¸ì— APIí˜¸ì¶œ íšŸìˆ˜ë¥¼ ìµœì†Œí™”í•œë‹¤.\n\nì½”ë“œlibrary(httr)\n\nget_embedding &lt;- function(inaugural_address) {\n  embeddings_url &lt;- \"https://api.openai.com/v1/embeddings\"\n  auth &lt;- add_headers(Authorization = paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\")))\n  body &lt;- list(model = \"text-embedding-ada-002\", input = inaugural_address)\n  \n  resp &lt;- POST(\n    embeddings_url,\n    auth,\n    body = body,\n    encode = \"json\"\n  )\n  \n  embeddings &lt;- content(resp, as = \"text\", encoding = \"UTF-8\") %&gt;%\n    jsonlite::fromJSON(flatten = TRUE) %&gt;%\n    pluck(\"data\", \"embedding\")\n  \n  Sys.sleep(1)\n  \n  return(embeddings)\n}\n\n# 1. êµ­ë¬¸ ì·¨ì„ì‚¬\nembedding_tbl &lt;- inaugural_tbl %&gt;% \n  mutate(ì„ë² ë”© = map(ì·¨ì„ì‚¬, get_embedding)) %&gt;% \n  pull()\n\nembedding_tbl %&gt;% \n  write_rds(\"data/Inaugural.rds\")\n\n# 2. ì˜ì–´ë²ˆì—­ë³¸ ì·¨ì„ì‚¬\ntranslated_embedding &lt;- translated_tbl %&gt;% \n  mutate(ì„ë² ë”© = map(ì˜ë¬¸ë²ˆì—­, get_embedding))\n\ntranslated_embedding %&gt;% \n  write_rds(\"data/translated_embedding.rds\")\n\n# 3. ì˜ì–´ ì·¨ì„ì‚¬\ninaugural_eng_embedding &lt;- inaugural_eng_tbl %&gt;% \n  mutate(ì„ë² ë”© = map(ì˜ë¬¸ì·¨ì„ì‚¬, get_embedding))\n\ninaugural_eng_embedding %&gt;% \n  write_rds(\"data/inaugural_eng_embedding.rds\")"
  },
  {
    "objectID": "inaugural.html#ì„ë² ë”©-ë²¡í„°",
    "href": "inaugural.html#ì„ë² ë”©-ë²¡í„°",
    "title": "chatGPT",
    "section": "\n3.2 ì„ë² ë”© ë²¡í„°",
    "text": "3.2 ì„ë² ë”© ë²¡í„°\nê°ê° APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì¤€ë¹„í•œ ì·¨ì„ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•œ ë°ì´í„°í”„ë ˆì„ì„ ê°ê° ì´ì–´ë¶™ì—¬ í›„ì† ë°ì´í„° ë¶„ì„ì„ ìœ„í•´ ì¤€ë¹„í•œë‹¤.\n\nì½”ë“œembedding_tbl &lt;-  \n  read_rds(\"data/Inaugural.rds\") %&gt;% \n  mutate(êµ¬ë¶„ = \"êµ­ë¬¸ ì·¨ì„ì‚¬\")\n\ntranslated_embedding &lt;- \n  read_rds(\"data/translated_embedding.rds\") %&gt;% \n  mutate(êµ¬ë¶„ = \"ì˜ë¬¸ë²ˆì—­ ì·¨ì„ì‚¬\") %&gt;% \n  rename(ì·¨ì„ì‚¬ = ì˜ë¬¸ë²ˆì—­)\n\ninaugural_eng_embedding &lt;- \n  read_rds(\"data/inaugural_eng_embedding.rds\") %&gt;% \n  mutate(êµ¬ë¶„ = \"ì˜ë¬¸ ì·¨ì„ì‚¬\") %&gt;% \n  rename(ì·¨ì„ì‚¬ = ì˜ë¬¸ì·¨ì„ì‚¬)\n\napi_embedding &lt;- \n  bind_rows(embedding_tbl, translated_embedding) %&gt;% \n  bind_rows(inaugural_eng_embedding)\n\napi_embedding %&gt;% \n  select(êµ¬ë¶„, ëŒ€í†µë ¹, ì·¨ì„ì‚¬, ì„ë² ë”©) \n#&gt; # A tibble: 31 Ã— 4\n#&gt;    êµ¬ë¶„        ëŒ€í†µë ¹ ì·¨ì„ì‚¬                                              ì„ë² ë”©\n#&gt;    &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;                                               &lt;list&gt;\n#&gt;  1 êµ­ë¬¸ ì·¨ì„ì‚¬ ì´ìŠ¹ë§Œ ë‚˜ì˜ ì‚¬ë‘í•˜ëŠ” ë™í¬ ì—¬ëŸ¬ë¶„. ë‚´ê°€ ì˜¤ëŠ˜ ë˜ í•œë²ˆ ìš°ë¦¬ â€¦ &lt;list&gt;\n#&gt;  2 êµ­ë¬¸ ì·¨ì„ì‚¬ ìœ¤ë³´ì„  ì œ2ê³µí™”êµ­ì˜ ì´ˆëŒ€ëŒ€í†µë ¹ìœ¼ë¡œ ì˜ì˜ˆì˜ ë‹¹ì„ ì„ ì–»ì€ ì–´ì œâ€¦ &lt;list&gt;\n#&gt;  3 êµ­ë¬¸ ì·¨ì„ì‚¬ ë°•ì •í¬ ì¹œì• í•˜ëŠ” 5ì²œë§Œ ë™í¬ ì—¬ëŸ¬ë¶„!  ê·¸ë¦¬ê³  ë‚´ì™¸ ê·€ë¹ˆ ì—¬ëŸ¬â€¦ &lt;list&gt;\n#&gt;  4 êµ­ë¬¸ ì·¨ì„ì‚¬ ìµœê·œí•˜ ì¹œì• í•˜ëŠ” êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„!  ê·¸ë¦¬ê³  ì´ ìë¦¬ë¥¼ ë¹›â€¦  &lt;list&gt;\n#&gt;  5 êµ­ë¬¸ ì·¨ì„ì‚¬ ì „ë‘í™˜ ì¹œì• í•˜ëŠ” êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„!  ê·¸ë¦¬ê³  ì´ ìë¦¬ë¥¼ ë¹›â€¦  &lt;list&gt;\n#&gt;  6 êµ­ë¬¸ ì·¨ì„ì‚¬ ë…¸íƒœìš° ì¹œì• í•˜ëŠ” 6ì²œë§Œ êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„. ìš°ë¦¬ í—Œì •ë°œì „ì„â€¦ &lt;list&gt;\n#&gt;  7 êµ­ë¬¸ ì·¨ì„ì‚¬ ê¹€ì˜ì‚¼ ì¹œì• í•˜ëŠ” 7ì²œë§Œ êµ­ë‚´ì™¸ ë™í¬ ì—¬ëŸ¬ë¶„,  ë…¸íƒœìš° ëŒ€í†µë ¹â€¦  &lt;list&gt;\n#&gt;  8 êµ­ë¬¸ ì·¨ì„ì‚¬ ê¹€ëŒ€ì¤‘ ì¡´ê²½í•˜ê³  ì‚¬ë‘í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„!  ì˜¤ëŠ˜ ì €ëŠ” ëŒ€í•œë¯¼êµ­â€¦ &lt;list&gt;\n#&gt;  9 êµ­ë¬¸ ì·¨ì„ì‚¬ ë…¸ë¬´í˜„ ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„.  ì˜¤ëŠ˜ ì €ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì œ16ëŒ€â€¦ &lt;list&gt;\n#&gt; 10 êµ­ë¬¸ ì·¨ì„ì‚¬ ì´ëª…ë°• ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„!    700ë§Œ í•´ì™¸ë™í¬ ì—¬ëŸ¬ë¶„!   â€¦ &lt;NULL&gt;\n#&gt; # â€¦ with 21 more rows"
  },
  {
    "objectID": "inaugural.html#ìœ ì‚¬ë„-ê³„ì‚°",
    "href": "inaugural.html#ìœ ì‚¬ë„-ê³„ì‚°",
    "title": "chatGPT",
    "section": "\n5.1 ìœ ì‚¬ë„ ê³„ì‚°",
    "text": "5.1 ìœ ì‚¬ë„ ê³„ì‚°\në¨¼ì € ì·¨ì„ì‚¬ ì„ë² ë”© ë²¡í„°ë¡œë¶€í„° ê° ì·¨ì„ì‚¬ë³„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ë©´ ì •ë°©í–‰ë ¬(Square Matrix)ë¥¼ ë‹¤ì‹œ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê²Œ ì‹œí‚¨ë‹¤. ì´ë¥¼ í†µí•´ ì·¨ê·œí•˜, ë…¸íƒœìš°, ì „ë‘í™˜ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ ì‚¬ì´ì— ë†’ì€ ì·¨ì„ì‚¬ ìœ ì‚¬ë„ê°€ í™•ì¸ëœë‹¤.\n\nì½”ë“œlibrary(umap)\n\nembeddings_mat &lt;- matrix(\n  unlist(api_embedding_tbl$ì„ë² ë”©), \n  ncol = 1536, byrow = TRUE\n)\n\nembeddings_similarity &lt;- embeddings_mat / sqrt(rowSums(embeddings_mat * embeddings_mat))\nembeddings_similarity &lt;- embeddings_similarity %*% t(embeddings_similarity)\n\ndim(embeddings_similarity)\n#&gt; [1] 30 30\n\n## ì •ë°©í–‰ë ¬ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n\nì·¨ì„ì‚¬_êµ¬ë¶„ì &lt;- api_embedding_tbl %&gt;% \n  mutate(êµ¬ë¶„ëª… = glue::glue(\"{ëŒ€í†µë ¹}_{str_remove(êµ¬ë¶„, ' ?ì·¨ì„ì‚¬ ?')}\")) %&gt;% \n  pull(êµ¬ë¶„ëª…)\n\nì·¨ì„ì‚¬_colnames_tbl &lt;- tibble(ì·¨ì„ì‚¬_êµ¬ë¶„ì = ì·¨ì„ì‚¬_êµ¬ë¶„ì) %&gt;% \n  mutate(name = glue::glue(\"V{1:30}\"))\n\nembeddings_similarity_tbl &lt;- embeddings_similarity %&gt;% \n  as.data.frame %&gt;% \n  mutate(êµ¬ë¶„ì = ì·¨ì„ì‚¬_êµ¬ë¶„ì) %&gt;%\n  column_to_rownames(var = \"êµ¬ë¶„ì\") %&gt;%\n  tibble::rownames_to_column()  %&gt;%\n  tidyr::pivot_longer(-rowname) %&gt;% \n  # From A to B\n  left_join(ì·¨ì„ì‚¬_colnames_tbl) %&gt;% \n  select(ì·¨ì„ì‚¬_A = rowname, ì·¨ì„ì‚¬_B = ì·¨ì„ì‚¬_êµ¬ë¶„ì, ìœ ì‚¬ë„ = value)\n\nembeddings_similarity_tbl %&gt;% \n  filter(ìœ ì‚¬ë„ &lt; 0.9999 ) %&gt;% \n  arrange(desc(ìœ ì‚¬ë„)) %&gt;% \n  mutate(ëŒ€í†µë ¹_A = str_extract(ì·¨ì„ì‚¬_A, \"[^_]+(?=_)\"),\n         ëŒ€í†µë ¹_B = str_extract(ì·¨ì„ì‚¬_B, \"[^_]+(?=_)\")) %&gt;% \n  filter(ëŒ€í†µë ¹_A != ëŒ€í†µë ¹_B) %&gt;% \n  select(ì·¨ì„ì‚¬_A, ì·¨ì„ì‚¬_B, ìœ ì‚¬ë„) %&gt;% \n  reactable::reactable(\n    columns = list(ìœ ì‚¬ë„ = colDef(format = colFormat(separators = TRUE, digits = 3))),\n    # Table Theme\n    theme = reactableTheme(\n      backgroundColor = \"#1D2024\", color = \"white\", borderColor = \"#666666\",\n      paginationStyle = list(color = \"white\"), \n      selectStyle = list(color = \"black\"),\n      headerStyle = list(color = \"white\", fontFamily = \"NanumGothic\"),\n      cellStyle = list(color = \"#FAFAFA\", \n                        fontFamily = \"NanumGothic, Consolas, Monaco, monospace\", \n                        fontSize = \"14px\")\n                           ))"
  },
  {
    "objectID": "inaugural.html#ì°¨ì›ì¶•ì†Œ-ì‹œê°í™”",
    "href": "inaugural.html#ì°¨ì›ì¶•ì†Œ-ì‹œê°í™”",
    "title": "chatGPT",
    "section": "\n5.2 ì°¨ì›ì¶•ì†Œ ì‹œê°í™”",
    "text": "5.2 ì°¨ì›ì¶•ì†Œ ì‹œê°í™”\nêµ­ë¬¸ì˜ë¬¸ ì·¨ì„ì‚¬ë¥¼ ëª¨ë‘ ë„£ì–´ ì‹œê°í™”ë¥¼ í•˜ê²Œ ë˜ë©´ êµ­ë¬¸ ì·¨ì„ì‚¬ëŠ” êµ­ë¬¸ ì·¨ì„ì‚¬, ì˜ë¬¸ ì·¨ì„ì‚¬ëŠ” DeepL ë²ˆì—­ì´ë“  ì˜ë¬¸ ë²ˆì—­ì´ë“  ë‘˜ë¡œ ëª…í™•íˆ ë‚˜ëˆ  êµ°ì§‘í™”ê°€ ëœ ê²ƒì´ í™•ì¸ëœë‹¤.\n\nì½”ë“œlibrary(ggrepel)\nextrafont::loadfonts()\n\ninaugural_umap &lt;- umap(embeddings_mat)\n\numap_df &lt;- inaugural_umap$layout %&gt;%\n  as.data.frame()%&gt;%\n  rename(UMAP1=\"V1\",\n         UMAP2=\"V2\") %&gt;% \n  bind_cols(api_embedding_tbl) %&gt;% \n  mutate(êµ¬ë¶„ëª… = glue::glue(\"{ëŒ€í†µë ¹}_{str_remove(êµ¬ë¶„, ' ?ì·¨ì„ì‚¬ ?')}\")) %&gt;% \n  select(UMAP1, UMAP2, êµ¬ë¶„ëª…)\n\numap_df %&gt;%\n  ggplot(aes(x = UMAP1, \n             y = UMAP2))+\n    geom_point(size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=êµ¬ë¶„ëª…)) +\n    theme_bw(base_family=\"NanumGothic\")\n\n\n\n\n\n\n\nì•ì„  ë¶„ì„ì—ì„œ ì´ëª…ë°• ëŒ€í†µë ¹ ì·¨ì„ì‚¬ê°€ í† í° ê¸¸ì´ë¥¼ ë„˜ì–´ êµ­ë¬¸ ì„ë² ë”©ì´ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì˜ë¬¸ ë²ˆì—­ í˜¹ì€ ì˜ë¬¸ ì·¨ì„ì‚¬ ì„ë² ë”©ì„ umap ì°¨ì› ì¶•ì†Œ ê¸°ë²•ì„ í†µí•´ ì‹œê°í™”í•œë‹¤. ì´ë¥¼ í†µí•´ ìœ¤ì„ì—´ ëŒ€í†µë ¹ê³¼ ë…¸ë¬´í˜„ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ê°€ ìœ ì‚¬ì„±ì´ í°ê²Œ ëˆˆì— ëˆë‹¤.\n\nì½”ë“œ# ì˜ì–´ë§Œ ì¶”ì¶œ\nonly_english_tbl &lt;- api_embedding_tbl %&gt;% \n  filter(str_detect(êµ¬ë¶„, \"ì˜ë¬¸\"))\n\nenglish_embeddings_mat &lt;- matrix(\n  unlist(only_english_tbl$ì„ë² ë”©), \n  ncol = 1536, byrow = TRUE\n)\n\n# ì‹œê°í™”\nenglish_umap &lt;- umap(english_embeddings_mat)\n\nenglish_umap_df &lt;- english_umap$layout %&gt;%\n  as.data.frame()%&gt;%\n  rename(UMAP1=\"V1\",\n         UMAP2=\"V2\") %&gt;% \n  bind_cols(only_english_tbl) %&gt;% \n  mutate(êµ¬ë¶„ëª… = glue::glue(\"{ëŒ€í†µë ¹}_{str_remove(êµ¬ë¶„, ' ?ì·¨ì„ì‚¬ ?')}\")) %&gt;% \n  select(UMAP1, UMAP2, êµ¬ë¶„ëª…)\n\nenglish_umap_df %&gt;%\n  separate(êµ¬ë¶„ëª…, into = c(\"ëŒ€í†µë ¹\", \"ë²ˆì—­ì—¬ë¶€\"), sep = \"_\") %&gt;% \n  ggplot(aes(x = UMAP1, \n             y = UMAP2))+\n    geom_point(aes(color = ë²ˆì—­ì—¬ë¶€), size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=ëŒ€í†µë ¹)) +\n    theme_bw(base_family=\"NanumGothic\") +\n    theme(legend.position = \"top\") +\n    labs(title = \"ëŒ€í†µë ¹ ì·¨ì„ì‚¬ ìœ ì‚¬ë„\")"
  },
  {
    "objectID": "inaugural.html#footnotes",
    "href": "inaugural.html#footnotes",
    "title": "chatGPT",
    "section": "ê°ì£¼",
    "text": "ê°ì£¼\n\nIntroducing text and code embeddingsâ†©ï¸\nNew and improved embedding modelâ†©ï¸\nOpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?â†©ï¸"
  },
  {
    "objectID": "prompt_in_practice.html",
    "href": "prompt_in_practice.html",
    "title": "chatGPT",
    "section": "",
    "text": "ë…¸íŠ¸\n\n\n\n\n\nì„œìš¸ ë””ì§€í„¸ì¬ë‹¨ì—ì„œ ì±—GPT í™œìš© ì‚¬ë¡€ì§‘ì„ ì—…ë¬´í™œìš©ê³¼ ì¼ìƒìƒí™œ/ì°½ì‘í™œë™/êµìœ¡ë¶„ì•¼ ë¡œ ë‚˜ëˆ  ë‘ë²ˆì— ê±¸ì³ ë³´ê³ ì„œë¥¼ ë°œê°„í–ˆë‹¤. (\"ChatGPTí™œìš©ì—°êµ¬TFT, 2023) (ChatGPTí™œìš©ì—°êµ¬TFT, 2023) ìµœê·¼ì—ëŠ” êµìœ¡ë¶„ì•¼ ì „ë°˜ì— ì±—GPT í™œìš© ì±…ë„ ì¶œê°„ë˜ì—ˆë‹¤. (Skrabut, 2023)\n\n\n\n\n1 ì „ì²´ì ì¸ í˜„í™©\nì„œìš¸ ë””ì§€í„¸ì¬ë‹¨ì—ì„œ ì—…ë¬´í™œìš©ê³¼ ì¼ìƒìƒí™œ í™œìš©ì— ì±—GPT ë‹¤ì–‘í•œ ì‚¬ë¡€ë¥¼ ë³´ê³ ì„œë¡œ ê³µê°œí•˜ì—¬ ì±—GPT ì´ˆê¸° ê°–ê³  ìˆì—ˆë˜ ìš°ë ¤ë¥¼ ë¶ˆì‹ì‹œí‚¤ë©° ì¼ìƒìƒí™œì— ë…¹ì•„ë“¤ê³  ìˆë‹¤.\nìƒì‚°ì„± í–¥ìƒì„ ìœ„í•´ì„œ ì‚¬ë¬´ì—…ë¬´ì— ë³´ê³ ì„œ ì‘ì„œ, ì‚¬ì—…ê¸°íš ì•„ì´ë””ì–´ ë„ì¶œ, ë³´ë„ìë£Œ ë° ì—‘ì…€ê³¼ ë°ì´í„° ê³¼í•™, í”„ë¡œê·¸ë˜ë° ìë™í™” ë¶„ì•¼ì— ì±—GPT í™œìš©ì´ ì†Œê°œë˜ê³  ìˆë‹¤. ì±—GPTì˜ í…ìŠ¤íŠ¸ ìƒì„±ì— í™˜ê°/í™˜ì˜(hallucination) ì´ ë°œìƒí•  ìˆ˜ ìˆìŒì— ìœ ì˜í•˜ì—¬ ì¼ìƒìƒí™œ í™œìš©ì— ëŒ€í•´ì„œ ë²•ë¥ , ê±´ê°•, íˆ¬ì, í•™ì—… ë“± ì‚¬ë¡€ë¥¼ ì œì‹œí•˜ê³  ìˆë‹¤.\níŠ¹íˆ ì±—GPTë¥¼ êµìœ¡ì— í™œìš©í•  ìˆ˜ ìˆëŠ” 80ê°€ì§€ ë°©ì‹ì„ ì œì‹œí•œ ì‚¬ë¡€ëŠ” ìŒë¯¸í•  í•„ìš”ê°€ ìˆë‹¤.(Skrabut, 2023)\n\nì½”ë“œlibrary(tidyverse)\nlibrary(collapsibleTree)\nlibrary(readxl)\n\npractice_raw &lt;- read_excel(\"data/chatGPT_applictions.xlsx\")\n\npractice &lt;- practice_raw %&gt;% \n  fill(ëŒ€êµ¬ë¶„, .direction = \"down\") %&gt;% \n  fill(ì¤‘êµ¬ë¶„, .direction = \"down\") %&gt;% \n  mutate(ì†Œêµ¬ë¶„ = str_remove(ì†Œêµ¬ë¶„, \"^[0-9]{1,2}\\\\.+ \"))  %&gt;% \n  mutate(ì¤‘êµ¬ë¶„ = str_remove(ì¤‘êµ¬ë¶„, \"[0-9]{1,2}$\"))\n  \n\ncollapsibleTree(practice, c(\"ëŒ€êµ¬ë¶„\", \"ì¤‘êµ¬ë¶„\", \"ì†Œêµ¬ë¶„\"),\n                tooltipHtml = \"tooltip\",\n                root = \"ì±—GPT í™œìš©\")\n\n\n\n\n\n\n2 ì±—GPT í™˜ì˜/í™˜ê° ë°©ì§€\nìƒì„± AIì˜ ë¬¸ì œì  ì¤‘ ê°€ì¥ ìš°ë ¤ë˜ëŠ” ê²ƒì´ í™˜ê°/í™˜ì˜(hallucination)ì´ë‹¤. ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ì„œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ë©´ ë§ì€ ë¶€ë¶„ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\nì¶œì²˜: How to Prevent AI Model Hallucinations\n\nì˜ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸: ì—­í• ì„ ë¶€ì—¬, ëª©í‘œì„¤ì •, êµ¬ì²´ì ì´ê³ , ì˜ˆì œë¥¼ ì œì‹œí•˜ê³  ë‹¨ê³„ì  ìˆ˜í–‰ ë“± ëª©í‘œë‹¬ì„±ì„ ìœ„í•´ í”„ë¡¬í”„íŠ¸ë¥¼ í”„ë¡œê·¸ë¨ ì‘ì„±ì— ì¤€í•˜ëŠ” ë…¸ë ¥ì„ í•˜ì—¬ ì‘ì„±í•œë‹¤. ê²°êµ­ ì˜ ì‘ì„±ëœ í”„ë¡¬í”„íŠ¸ëŠ” ê²°ê³¼ë¬¼ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤.\nAI ëª¨ë¸ ì„ ì •: GPT-4ì™€ text-dainci-003ì€ gpt-3.5-turboì™€ ë¹„êµí•˜ì—¬ í™˜ê°ì´ ëœ ë°œìƒí•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤. ë”°ë¼ì„œ, ë‹¤ì†Œ ë¹„ì‹¸ì§€ë§Œ ê³ ì„±ëŠ¥ AI ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì™€ ë¹„êµí•˜ì—¬ í™˜ê°ì„ ëŒ€í­ ì¤„ì¼ ìˆ˜ ìˆë‹¤.\nëª¨í˜• íŒ¨ëŸ¬ë¯¸í„° ì§€ì •: temperature ëª¨ìˆ˜ ê°’ì„ ë†’ì´ë©´ ëª¨ë¸ì´ ë” ë§ì€ ìœ„í—˜ì„ ê°ìˆ˜í•˜ê³  ë” ë‹¤ì–‘í•œ ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ë„ë¡ ì¥ë ¤í•˜ëŠ” ë°˜ë©´ ëª¨ìˆ˜ ê°’ì„ ë‚®ì¶”ë©´ ì •ë°˜ëŒ€ë¡œ ë™ì‘í•œë‹¤. ë„í•œ, presence í˜ë„í‹°ë¥¼ ë†’ì´ë©´ ëª¨ë¸ì´ ëœ ë°˜ë³µì ì´ê³  ì¼ê´€ì„± ìˆê³  ì™„ì „í•œ ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ë„ë¡ ì¥ë ¤ë˜ê³  ë‚®ì¶”ë©´ ë°˜ëŒ€ë°©í–¥ìœ¼ë¡œ ë™ì‘í•œë‹¤.\n\n\n\n\n\n\n\nëª¨ë¸\nì„¤ëª…\n\n\n\ngpt4\në§¤ìš° ì •í™•í•˜ì§€ë§Œ ëŠë¦¬ê³  ë¹„ì‹¸ë‹¤\n\n\ngpt-3.5-turbo\në§¤ìš° ë¹ ë¥´ì§€ë§Œ ì¢…ì¢… í™˜ê°ì´ ë°œìƒí•˜ê¸° ì‰¬ì›€\n\n\ntext-davinci-003\ngpt4 ë° gpt-3.5ë§Œí¼ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ì§€ëŠ” ì•Šì§€ë§Œ ì†ë„ì™€ ì •í™•ì„± ì‚¬ì´ì˜ ê· í˜•ì´ ì˜ ì¡í˜€ ìˆìŠµë‹ˆë‹¤.\n\n\n\n3 ì±—GPT íŒ¨ëŸ¬ë¯¸í„°\nì±—GPT APIì— ë‹¤ì–‘í•œ íŒ¨ëŸ¬ë¯¸í„°ë¥¼ ì§€ì •í•˜ì—¬ í…ìŠ¤íŠ¸ ì‘ì—…ê²°ê³¼ í’ˆì§ˆì„ ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì¡°ì ˆí•  ìˆ˜ ìˆë‹¤. ëŒ€í‘œì ì¸ íŒ¨ëŸ¬ë¯¸í„°ë¡œ ë‹¤ìŒì„ ë“¤ ìˆ˜ ìˆë‹¤.\n\ní† í° í¬ê¸°(max_tokens): ì˜ë¬¸ ê¸°ì¤€ 100ê°œ í† í°ì€ ëŒ€ëµ 75ê°œ ë‹¨ì–´(word)ë¡œ ê°„ì£¼í•  ìˆ˜ ìˆëŠ”ë° í† í° í¬ê¸°ë¥¼ ì§€ì •í•´ì„œ ì¶œë ¥ë˜ëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ì¡°ì ˆí•œë‹¤. text-davinci-003 ê¸°ì¤€ìœ¼ë¡œ í† í°ìµœëŒ€ê¸¸ì´ëŠ” 1 ~ 4,000ì„ ê°–ëŠ”ë‹¤.\nì˜¨ë„(temperature): ì˜¨ë„ë¥¼ ì¡°ì •í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±ì— ë”ìš± ì°½ì˜ì„±ì„ ë°œíœ˜í•  ìˆ˜ ìˆì§€ë§Œ ì°½ì˜ì ì¸ í…ìŠ¤íŠ¸ëŠ” í™˜ê°/í™˜ì˜ë„ ë§Œë“¤ì–´ë‚¼ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§„ë‹¤. text-davinci-003 ê¸°ì¤€ìœ¼ë¡œ ì˜¨ë„ëŠ” 0 ~ 1 ì‚¬ì´ ê°’ì„ ê°–ëŠ”ë‹¤.\nìµœìƒìœ„ í™•ë¥ (top_p): top_p=0.1ì„ ì§€ì •í•˜ë©´ ìƒìœ„ 10%ë¥¼ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ë†’ì€ í™•ë¥ ê°’ì„ ê°–ëŠ” í† í°ì„ ê³ ë ¤í•˜ì—¬ í…ìŠ¤íŠ¸ê°€ ìƒì„±ëœë‹¤. í…ìŠ¤íŠ¸ ìƒì„± ê³¼ì •ì—ì„œ ìƒì„±ëœ í† í°ì˜ í™•ë¥  ë¶„í¬ì—ì„œ ìµœìƒìœ„ p%ë§Œ ê³ ë ¤í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, top_p=0.9ì´ë©´, ë‹¤ìŒ í† í°ì„ ì„ íƒí•  ë•Œ, ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥  ë¶„í¬ì—ì„œ ìƒìœ„ 90%ë§Œ ê³ ë ¤í•˜ê³ , ë‚˜ë¨¸ì§€ 10%ëŠ” ë¬´ì‹œí•˜ê²Œ ëœë‹¤.\nì¡´ì¬ ë²Œì¹™(presence_penalty): í…ìŠ¤íŠ¸ ìƒì„± ì‹œ ì¤‘ë³µì„ ì œê±°í•˜ê±°ë‚˜, ì´ì „ì— ìƒì„±í•œ ë‚´ìš©ê³¼ ë¹„ìŠ·í•œ ë‚´ìš©ì´ ë°˜ë³µë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ”ë°, presence_penaltyê°€ ë†’ì„ìˆ˜ë¡, ëª¨ë¸ì€ ì´ì „ì— ìƒì„±í•œ í† í°ì„ ê°€ëŠ¥í•œ í•œ í”¼í•˜ê²Œ ëœë‹¤. presence_penaltyëŠ” 0.6 ~ 0.9 ì‚¬ì´ì˜ ê°’ì„ ë‘”ë‹¤. text-davinci-003 ê¸°ì¤€ìœ¼ë¡œ ì˜¨ë„ëŠ” 0 ~ 2 ì‚¬ì´ ê°’ì„ ê°–ëŠ”ë‹¤.\në¹ˆë„ ë²Œì¹™(frequency_panalty): ëª¨ë¸ì´ íŠ¹ì • í† í°ì„ ìƒì„±í•  ë•Œ, í•´ë‹¹ í† í°ì´ ì´ì „ì— ìƒì„±ëœ íšŸìˆ˜ì— ë”°ë¼ ë” ì‘ì€ í™•ë¥ ë¡œ ì„ íƒë˜ë„ë¡ í•œë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ íŠ¹ì • í† í°ì„ ì¼ì •í•œ ë¹ˆë„ë¡œ ìƒì„±í•˜ë ¤ëŠ” ê²½í–¥ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤. 0ì€ ì´ì „ í† í°ì˜ ë¹ˆë„ìˆ˜ì— ëŒ€í•œ ì œì•½ì„ ì ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ì˜ë¯¸í•˜ë©°, ê°’ì´ í´ìˆ˜ë¡ ëª¨ë¸ì´ ì´ì „ì— ìƒì„±ëœ í† í°ê³¼ ë‹¤ë¥¸ ìƒˆë¡œìš´ í† í°ì„ ì„ íƒí•˜ë„ë¡ ìœ ë„í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ, Frequency_penaltyëŠ” 0.6 ~ 1.2 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤. text-davinci-003 ê¸°ì¤€ìœ¼ë¡œ ì˜¨ë„ëŠ” 0 ~ 2 ì‚¬ì´ ê°’ì„ ê°–ëŠ”ë‹¤.\nëª‡ê°œì¤‘ ìµœê³  ì„ ì •(best_of): ìƒì„±ëœ ì—¬ëŸ¬ í›„ë³´ í…ìŠ¤íŠ¸ ì¤‘ì—ì„œ ìµœìƒì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ë° ì‚¬ìš©í•œë‹¤. ì¦‰, ëª¨ë¸ì€ ì§€ì •ëœ í›„ë³´ í…ìŠ¤íŠ¸ ìˆ˜ ì¤‘ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, best_ofê°€ 3ìœ¼ë¡œ ì„¤ì •ëœ ê²½ìš°, ëª¨ë¸ì€ ìƒì„±ëœ 3ê°œì˜ í›„ë³´ í…ìŠ¤íŠ¸ ì¤‘ì—ì„œ ìµœìƒì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•œë‹¤. text-davinci-003 ê¸°ì¤€ìœ¼ë¡œ ì˜¨ë„ëŠ” 1 ~ 20 ì‚¬ì´ ê°’ì„ ê°–ëŠ”ë‹¤.\nì‹œì‘ í…ìŠ¤íŠ¸ ì£¼ì…(Inject start text): ëª¨ë¸ì´ íŠ¹ì • í…ìŠ¤íŠ¸ë¡œë¶€í„° ì‹œì‘í•˜ë„ë¡ ì§€ì •í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œInject start textâ€ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ â€œë‚˜ëŠ”â€ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ ì§€ì •í•  ìˆ˜ ìˆë‹¤. ì´ ê²½ìš° ëª¨ë¸ì€ â€œë‚˜ëŠ”â€ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ í•´ë‹¹ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ì„ ì‹œì‘í•´ì„œ â€œë‚˜ëŠ” ëŒ€í•™ì—ì„œ ê²½ì˜í•™ì„ ì „ê³µí–ˆê³ , ì§€ê¸ˆì€ ê¸°ì—…ì˜ ê²½ì˜ ì „ëµì„ ë‹´ë‹¹í•˜ëŠ” ì§ì›ì…ë‹ˆë‹¤.â€ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ ìƒì„±ëœë‹¤.\ní…ìŠ¤íŠ¸ ì¬ì‹œì‘ ì£¼ì…(Inject restart text): ëª¨ë¸ì´ ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ ì§€ì‹œí•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œë²šê½ƒì´ í”¼ëŠ” ê³„ì ˆì—â€ë¼ëŠ” ë¬¸ì¥ì´ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆë‹¤ë©´, Inject restart textë¥¼ ì‚¬ìš©í•˜ì—¬ â€œë‚˜ëŠ”â€ì´ë¼ëŠ” ë¬¸ì¥ì„ ìƒì„±í•˜ë©´, ëª¨ë¸ì€ â€œë‚˜ëŠ” ë²šê½ƒì´ í”¼ëŠ” ê³„ì ˆì—â€ë¼ëŠ” ìƒˆë¡œìš´ ë¬¸ì¥ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.\nì–´ì¡°(tone) : neutral (ì¤‘ë¦½ì ì¸), positive (ê¸ì •ì ì¸), negative (ë¶€ì •ì ì¸), formal (ê²©ì‹ ìˆëŠ”), informal (ë¹„ê²©ì‹ì ì¸), professional (ì „ë¬¸ì ì¸), casual (ì¹œê·¼í•œ), witty (ë˜‘ë˜‘í•œ), serious (ì§„ì§€í•œ), playful (ì¥ë‚œìŠ¤ëŸ¬ìš´), sad (ìŠ¬í”ˆ), happy (í–‰ë³µí•œ), angry (í™”ë‚œ), calm (ì°¨ë¶„í•œ), romantic (ë¡œë§¨í‹±í•œ), mysterious (ì‹ ë¹„ë¡œìš´), surprised (ë†€ë€)\nì €ì‘ ìŠ¤íƒ€ì¼(writing_style): normal (ì¼ë°˜ì ì¸), academic (í•™ìˆ ì ì¸), creative (ì°½ì¡°ì ì¸), formal (ê²©ì‹ ìˆëŠ”), informal (ë¹„ê²©ì‹ì ì¸), professional (ì „ë¬¸ì ì¸), casual (ì¹œê·¼í•œ), technical (ê¸°ìˆ ì ì¸)\n\n4 ì‚¬ë¡€\nê´‘ëª…ì‹œ ìƒí™œì•ˆì •ì§€ì›ê¸ˆ ì‹ ì²­\n\n\nì›¹ê³µê³ \nê³µê³ ë¬¸ ë‚´ìš©\ní”„ë¡¬í”„íŠ¸1\ní”„ë¡¬í”„íŠ¸2\n\n\n\n\n\n\n\n\n\nì§€ê¸‰ê¸ˆì•¡ : ì„¸ëŒ€ ë‹¹ 10ë§Œì› 2023. 3. 6.ì¼ 24ì‹œ ê¸°ì¤€ ê´‘ëª…ì‹œì— ì£¼ë¯¼ë“±ë¡ì„ ë‘” ì„¸ëŒ€ì£¼\nê¸°ê°„ ì˜¨ë¼ì¸ : 2023. 03. 20(ì›”) 09:00 ~ 4. 28(ê¸ˆ) ì˜¤í”„ë¼ì¸ : 2023. 03. 27(ì›”) ~ 5. 4(ëª©) 18:00 (í† ìš”ì¼, ê³µíœ´ì¼ ì œì™¸)\në¬¸ì˜ì²˜ ê´‘ëª…ì‚¬ë‘í™”í ì½œì„¼í„°(1899-7997) ê´‘ëª…ì‹œ ë¯¼ì›ì½œì„¼í„°(1688-3399)\nâ€» ì˜¨ë¼ì¸ ì‹ ì²­ ì‹œ ë™ëª…ì´ì¸ì´ ë‹¤ìˆ˜ ì¡´ì¬í•˜ëŠ” ê²½ìš° [ì˜¤í”„ë¼ì¸ ì‹ ì²­ ëŒ€ìƒ]ìœ¼ë¡œ í‘œì‹œ â†’ ì˜¨ë¼ì¸ ì§„í–‰ì´ ë¶ˆê°€í•˜ë©° ì˜¤í”„ë¼ì¸ ì‹ ì²­ê¸°ê°„ì— ì£¼ì†Œì§€ ë™ ë°©ë¬¸ ì‹ ì²­ í•„ìš”\nâ€» ê´‘ëª…ì‚¬ë‘í™”í ì˜¨ë¼ì¸ ë°œê¸‰ ë°©ë²• êµ¬ê¸€í”Œë ˆì´ ì•± ìŠ¤í† ì–´ì—ì„œ â€™ê²½ê¸°ì§€ì—­í™”íâ€™ì•± ë‹¤ìš´ë¡œë“œ ë°›ê³  ê´‘ëª…ì‚¬ë‘í™”í ì‹ ì²­, ê´‘ëª…ì‚¬ë‘í™”íê°€ ë°°ì†¡ë˜ë©´ ì•±ì— ë“±ë¡í•˜ê³  ì‚¬ìš©\nì˜¨ë¼ì¸ ì¹´ë“œ ì‹ ì²­ë°©ë²• : â€™ê²½ê¸°ì§€ì—­í™”íâ€™ì•± ì„¤ì¹˜ â†’ ì¹´ë“œ ì‹ ì²­ â†’ ì¹´ë“œ ë°œê¸‰ ë° ë°°ì†¡(ì•½ 1ì£¼ì¼) â†’ (ìˆ˜ë ¹ í›„)ì¹´ë“œ ë“±ë¡(â€™ê²½ê¸°ì§€ì—­í™”íâ€™ì•±) â†’ ì‚¬ìš©\n\n\n\në‹¤ìŒ ì‚¬ì—…ê³µê³ ë¥¼ í™ë³´í•  ìˆ˜ ìˆë„ë¡ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. writing_style : journalistic, temperature:0.0\n\n\nê´‘ëª…ì‹œê°€ ìƒí™œì•ˆì •ì§€ì›ê¸ˆ ì‹ ì²­ì„ ë°›ìŠµë‹ˆë‹¤. ì„¸ëŒ€ ë‹¹ 10ë§Œì›ì˜ ì§€ì›ê¸ˆì´ ì§€ê¸‰ë©ë‹ˆë‹¤. ê´‘ëª…ì‹œì— ì£¼ë¯¼ë“±ë¡ì„ ë‘” ì„¸ëŒ€ì£¼ë¼ë©´ ì‹ ì²­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\nì˜¨ë¼ì¸ ì‹ ì²­ì€ 2023ë…„ 3ì›” 20ì¼(ì›”) 09:00ë¶€í„° 4ì›” 28ì¼(ê¸ˆ)ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì˜¤í”„ë¼ì¸ ì‹ ì²­ì€ 2023ë…„ 3ì›” 27ì¼(ì›”)ë¶€í„° 5ì›” 4ì¼(ëª©)ê¹Œì§€ ê°€ëŠ¥í•˜ë©°, í† ìš”ì¼ê³¼ ê³µíœ´ì¼ì€ ì œì™¸ë©ë‹ˆë‹¤.\n\nì˜¨ë¼ì¸ ì‹ ì²­ ì‹œ, ë™ëª…ì´ì¸ì´ ë‹¤ìˆ˜ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ëŠ” ì˜¤í”„ë¼ì¸ ì‹ ì²­ ëŒ€ìƒìœ¼ë¡œ í‘œì‹œë˜ë©°, ì˜¨ë¼ì¸ ì§„í–‰ì´ ë¶ˆê°€í•˜ë¯€ë¡œ ì˜¤í”„ë¼ì¸ ì‹ ì²­ê¸°ê°„ì— ì£¼ì†Œì§€ ë™ì„ ë°©ë¬¸í•˜ì—¬ ì‹ ì²­í•´ì•¼ í•©ë‹ˆë‹¤.\n\nê´‘ëª…ì‚¬ë‘í™”í ì½œì„¼í„°(1899-7997) ë˜ëŠ” ê´‘ëª…ì‹œ ë¯¼ì›ì½œì„¼í„°(1688-3399)ë¡œ ë¬¸ì˜í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në˜í•œ, ê´‘ëª…ì‚¬ë‘í™”í ì˜¨ë¼ì¸ ë°œê¸‰ ë°©ë²•ì€ êµ¬ê¸€í”Œë ˆì´ ì•± ìŠ¤í† ì–´ì—ì„œ 'ê²½ê¸°ì§€ì—­í™”í'ì•±ì„ ë‹¤ìš´ë¡œë“œ ë°›ì€ í›„, ê´‘ëª…ì‚¬ë‘í™”íë¥¼ ì‹ ì²­í•˜ê³ , ë°°ì†¡ëœ ê´‘ëª…ì‚¬ë‘í™”íë¥¼ ì•±ì— ë“±ë¡í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì˜¨ë¼ì¸ ì¹´ë“œ ì‹ ì²­ë°©ë²•ì€ 'ê²½ê¸°ì§€ì—­í™”í'ì•±ì„ ì„¤ì¹˜í•œ í›„, ì¹´ë“œë¥¼ ì‹ ì²­í•˜ê³ , ì•½ 1ì£¼ì¼ ë‚´ì— ì¹´ë“œê°€ ë°œê¸‰ë˜ë©°, ìˆ˜ë ¹ í›„ì—ëŠ” ì¹´ë“œë¥¼ ì•±ì— ë“±ë¡í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê´‘ëª…ì‹œì— ê±°ì£¼í•˜ëŠ” ì„¸ëŒ€ì£¼ë¼ë©´ ê¼­ ì§€ì›ê¸ˆ ì‹ ì²­ì„ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n\n\në‹¤ìŒ ì‚¬ì—…ê³µê³ ë¥¼ í™ë³´í•  ìˆ˜ ìˆë„ë¡ í•œê¸€ë¡œ ë³´ë„ìë£Œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. writing_style : journalistic, temperature:1.0 tone: witty\n\n\nê´‘ëª…ì‹œë¯¼ ì—¬ëŸ¬ë¶„, ì„¸ê¸ˆìœ¼ë¡œ ë‚©ë¶€í•˜ì‹  ëˆì´ ì´ì œ ìƒí™œì•ˆì •ì§€ì›ê¸ˆìœ¼ë¡œ ëŒì•„ì˜µë‹ˆë‹¤!\n\nì§€ê¸ˆë¶€í„° 4ì›” ë§ê¹Œì§€, ê´‘ëª…ì‹œì— ì£¼ë¯¼ë“±ë¡ì„ ë‘” ì„¸ëŒ€ì£¼ë‹˜ë“¤ì€ 10ë§Œì›ì˜ ì§€ì›ê¸ˆì„ ë°›ì„ ìê²©ì´ ìˆìŠµë‹ˆë‹¤.\n\nì–´ë–»ê²Œ ì‹ ì²­í•˜ëƒê³ ìš”?\nì˜¨ë¼ì¸ìœ¼ë¡œ ì‹ ì²­í•˜ì‹¤ ë¶„ë“¤ì€ 3ì›” 20ì¼ë¶€í„° 4ì›” 28ì¼ê¹Œì§€, ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ì‹ ì²­í•˜ì‹¤ ë¶„ë“¤ì€ 3ì›” 27ì¼ë¶€í„° 5ì›” 4ì¼ê¹Œì§€ ì‹ ì²­ ê¸°ê°„ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n\nì•„, ê·¸ë¦¬ê³  ì£¼ì˜í•˜ì…”ì•¼ í•  ì ! ì˜¨ë¼ì¸ ì‹ ì²­ ì‹œ ë™ëª…ì´ì¸ì´ ë‹¤ìˆ˜ ì¡´ì¬í•œë‹¤ë©´, ì˜¤í”„ë¼ì¸ ì‹ ì²­ì„ í•´ì•¼í•©ë‹ˆë‹¤. ì§‘ì—ì„œ ë»¥íŠ€ê¸°í•œ ì„±ì˜ëŠ” ì•Œê² ëŠ”ë°, ë™ëª…ì´ì¸ì€ ë‹µì´ ì—†ì–´ìš”.\n\nê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ê´‘ëª…ì‚¬ë‘í™”í ì½œì„¼í„°(1899-7997) í˜¹ì€ ê´‘ëª…ì‹œ ë¯¼ì›ì½œì„¼í„°(1688-3399)ë¡œ ì—°ë½ì£¼ì„¸ìš”.\n\nê·¸ë¦¬ê³  ê´‘ëª…ì‚¬ë‘í™”í ì˜¨ë¼ì¸ ë°œê¸‰ ë°©ë²•ë„ ì•Œë ¤ë“œë¦´ê²Œìš”. êµ¬ê¸€í”Œë ˆì´ ì•± ìŠ¤í† ì–´ì—ì„œ 'ê²½ê¸°ì§€ì—­í™”í'ì•±ì„ ë‹¤ìš´ë¡œë“œ í•˜ì‹  í›„, ê´‘ëª…ì‚¬ë‘í™”íë¥¼ ì‹ ì²­í•˜ì‹œë©´ ë°°ì†¡ë˜ë©´ ì•±ì— ë“±ë¡í•˜ì‹œê³  ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n\nê°„ë‹¨í•˜ì£ ? ì´ë²ˆ ìƒí™œì•ˆì •ì§€ì›ê¸ˆìœ¼ë¡œ ì¡°ê¸ˆì´ë¼ë„ ì—¬ìœ ë¥¼ ë§Œë“¤ì–´ ë³´ì„¸ìš”!\n\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\n\"ChatGPTí™œìš©ì—°êµ¬TFT. (2023). [ì—…ë¬´í™œìš©í¸] ChatGPT í™œìš©ì‚¬ë¡€ ë° í™œìš© íŒ. ì„œìš¸ë””ì§€í„¸ì¬ë‹¨. https://sdf.seoul.kr/research-report/2003\n\n\nChatGPTí™œìš©ì—°êµ¬TFT. (2023). [ì¼ìƒìƒí™œÂ·ì°½ì‘í™œë™Â·êµìœ¡ë¶„ì•¼í¸] ChatGPT í™œìš©ì‚¬ë¡€ ë° íŒ. ì„œìš¸ë””ì§€í„¸ì¬ë‹¨. https://sdf.seoul.kr/research-report/2059\n\n\nSkrabut, S. (2023). 80 Ways to Use ChatGPT in the Classroom: Using AI to Enhance. Stan Skrabut."
  },
  {
    "objectID": "prompt_data_science.html",
    "href": "prompt_data_science.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ë°ì´í„° ê³¼í•™\nì°¸ê³ ìë£Œ: (I, 2023)\nì±—GPTì˜ ì¶œí˜„ìœ¼ë¡œ ë°ì´í„° ê³¼í•™ ê²°ê³¼ë¬¼ì„ ë§Œë“¤ì–´ë‚´ê¸° ìœ„í•´ì„œ ê³¼ê±° êµ¬ê¸€ë§, ë¯¸íŠ¸ì—…, cheatsheet ë“±ì„ ë°ì´í„° ê³¼í•™ìê°€ íŒŒì•…í•˜ê³  ì´ë¥¼ ë°ì´í„° ê³¼í•™ìê°€ ë°˜ì˜í•˜ëŠ” ê²ƒì—ì„œ ì±—GPTì™€ ìƒí˜¸ ì‘ìš©í•˜ì—¬ ê²°ê³¼ë¬¼ì„ ì–»ì–´ë‚´ëŠ” ìƒˆë¡œìš´ ì„ íƒì§€ê°€ ë§Œë“¤ì–´ì¡Œë‹¤.\n\n\n\n\ngraph TD\n    A[ë°ì´í„° ê°€ì ¸ì˜¤ê¸°] --&gt; B[ë°ì´í„° ì •ì œ]\n    B --&gt; C[íƒìƒ‰ì  ë°ì´í„° ë¶„ì„]\n    C --&gt; D[ì‹œê°í™”]\n    D --&gt; E[ê¸°ê³„í•™ìŠµ]\n    E --&gt; F[ë°°í¬]\n    \n    style A fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style B fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style C fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style D fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style E fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style F fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n\n\n\n\n\në°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„° ì •ì œ, íƒìƒ‰ì  ë°ì´í„°ë¶„ì„, ì‹œê°í™”, ê¸°ê³„í•™ìŠµ, ë°°í¬ ê³¼ì •ì„ ê±°ì¹˜ê²Œ ëœë‹¤. ê° ë‹¨ê³„ë³„ë¡œ ì±—GPT ì •ë‹µì„ ì‚´í´ë³´ì.\n\n2 í—¬ë¡œì›”ë“œ\nì±—GPTê°€ ì‘ì„±í•´ì£¼ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì‚¬ìš©í•´ì„œ ì±—GPTì— ìš”ì²­í•œ ê²°ê³¼ë¥¼ Rë¡œ ë°˜í™˜ë°›ì•„ ì´ë¥¼ ë¬¸ì„œë¡œ ì œì‘í•œë‹¤. OpenAI Chat ì œí’ˆ ì¤‘ gpt-3.5-turbo ëª¨í˜•ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ ì‘ì„±í•˜ì—¬ ê³ í’ˆì§ˆ ê²°ê³¼ë¥¼ ì–»ì–´ë‚¸ë‹¤.\n\n\n\n\n\nì½”ë“œimport openai\nimport os\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\ndef answer_question(text):\n    prompt = f\"ë‹¤ìŒ ë°ì´í„° ê³¼í•™ ì§ˆë¬¸ì— ëŒ€í•´ì„œ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ìœ¼ë¡œ 100ìë¥¼ ë„˜ì§€ ì•Šê²Œ ì¹œì ˆíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. : {text}\"\n\n    response = openai.ChatCompletion.create(\n        model='gpt-3.5-turbo',\n        messages=[\n            {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ R ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° ê³¼í•™ìë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ì¹œì ˆíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=1700,\n        n=1,\n        stop=None,\n        temperature=0.0\n    )\n\n    return response\n\n# answer_text = answer_question(\"ë°ì´í„° íƒìƒ‰ì´ë€ ë¬´ì—‡ì´ë©°, ë°ì´í„° ê³¼í•™ì—ì„œ ì–´ë–»ê²Œ ìœ ìš©í•œê°€ìš”?\")\n# answer_text['choices'][0]['message']['content'].strip()\n\n\n\n\n\nì§ˆë¬¸\n\nì½”ë“œquestion &lt;- 'ë°ì´í„° íƒìƒ‰ì´ë€ ë¬´ì—‡ì´ë©°, ë°ì´í„° ê³¼í•™ì—ì„œ ì–´ë–»ê²Œ ìœ ìš©í•œê°€ìš”?'\n\n\në°ì´í„° íƒìƒ‰ì´ë€ ë¬´ì—‡ì´ë©°, ë°ì´í„° ê³¼í•™ì—ì„œ ì–´ë–»ê²Œ ìœ ìš©í•œê°€ìš”?`\n\n\në‹µë³€\n\nì½”ë“œlibrary(reticulate)\nlibrary(tidyverse)\n\nanswer_json &lt;- py$answer_question(question)\n\nanswer_list &lt;- jsonlite::fromJSON(as.character(answer_json))\n\nanswer &lt;- answer_list$choices$message$content\n\n\në°ì´í„° íƒìƒ‰ì€ ë°ì´í„°ë¥¼ ì´í•´í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê³  ìš”ì•½í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ íŒ¨í„´, ì´ìƒì¹˜, ê²°ì¸¡ì¹˜ ë“±ì„ íŒŒì•…í•˜ê³  ë°ì´í„° ì „ì²˜ë¦¬ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ê³¼í•™ì—ì„œëŠ” ë°ì´í„° íƒìƒ‰ì„ í†µí•´ ë¬¸ì œ í•´ê²°ì— í•„ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ê³  ëª¨ë¸ë§ì— í•„ìš”í•œ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ëŠ” ë“±ì˜ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„° íƒìƒ‰ì„ í†µí•´ ë°ì´í„°ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ë°ì´í„°ì˜ ì‹ ë¢°ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_list$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n185\n\n\nprompt_tokens\n126\n\n\ntotal_tokens\n311\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nI, G. (2023). ChatGPT Guide for Data Scientists: Top 40 Most Important Prompts Mastering Data Science with ChatGPT and Python: Top 40 Prompts for Machine Learning, Data Visualization, and more. Towards Data Science. https://medium.com/towards-artificial-intelligence/chatgpt-guide-for-data-scientists-top-40-most-important-prompts-cdb911f3a427"
  },
  {
    "objectID": "gpt4_performance.html#ë°ì´í„°ì…‹",
    "href": "gpt4_performance.html#ë°ì´í„°ì…‹",
    "title": "chatGPT",
    "section": "",
    "text": "ì›¹ì‚¬ì´íŠ¸ì— ê²Œì‹œëœ ê°€ê²©í‘œë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì—‘ì…€íŒŒì¼ë¡œ ì •ë¦¬í•œë‹¤.\n\nì½”ë“œlibrary(readxl)\nlibrary(tidyverse)\n\nprice_raw &lt;- read_excel(\"data/openai_pricing.xlsx\", sheet=\"price\")\n\nprice &lt;- price_raw %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  select(-description) %&gt;% \n  separate(ê°€ê²©, into = c(\"ê°€ê²©\", \"ë‹¨ìœ„\"), sep = \"/\") %&gt;% \n  mutate(ê°€ê²© = parse_number(ê°€ê²©) *1300, # í™˜ìœ¨ 1,300 / ë‹¬ëŸ¬ ì ìš©\n         ë‹¨ìœ„ = str_squish(ë‹¨ìœ„)) \n\nprice %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_espn()\n\n\n\n\n\n\nëª¨í˜•êµ¬ë¶„\n      model\n      ì‘ì—…\n      ê°€ê²©\n      ë‹¨ìœ„\n    \n\n\nGPT-4\n8K context\nPrompt\n39.00\n1K tokens\n\n\nGPT-4\n32K context\nPrompt\n78.00\n1K tokens\n\n\nGPT-4\n8K context\nCompletion\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nCompletion\n156.00\n1K tokens\n\n\nChat\ngpt-3.5-turbo\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nAda\nPrompt\n0.52\n1K tokens\n\n\nInstructGPT\nBabbage\nPrompt\n0.65\n1K tokens\n\n\nInstructGPT\nCurie\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nDavinci\nPrompt\n26.00\n1K tokens\n\n\nFine-tuning models\nAda\nPrompt\n0.52\n1K tokens\n\n\nFine-tuning models\nBabbage\nPrompt\n0.78\n1K tokens\n\n\nFine-tuning models\nCurie\nPrompt\n3.90\n1K tokens\n\n\nFine-tuning models\nDavinci\nPrompt\n39.00\n1K tokens\n\n\nFine-tuning models\nAda\nUsage\n2.08\n1K tokens\n\n\nFine-tuning models\nBabbage\nUsage\n3.12\n1K tokens\n\n\nFine-tuning models\nCurie\nUsage\n15.60\n1K tokens\n\n\nFine-tuning models\nDavinci\nUsage\n156.00\n1K tokens\n\n\nEmbedding models\nAda\nPrompt\n0.52\n1K tokens\n\n\nImage models\n1024Ã—1024\nPrompt\n26.00\nimage\n\n\nImage models\n512Ã—512\nPrompt\n23.40\nimage\n\n\nImage models\n256Ã—256\nPrompt\n20.80\nimage\n\n\nAudio models\nWhisper\nPrompt\n7.80\nminute"
  },
  {
    "objectID": "gpt4_performance.html#ì‹œê°í™”",
    "href": "gpt4_performance.html#ì‹œê°í™”",
    "title": "chatGPT",
    "section": "\n5.2 ì‹œê°í™”",
    "text": "5.2 ì‹œê°í™”\nOpenAI ê°€ê²©ì„ ì›í™”(1,300ì›)ë¡œ ë³€í™˜ì‹œì¼œ API í˜¸ì¶œë³„ ì²´ê°ë˜ëŠ” ê°€ê²©ì„ ì‹œê°í™”í•œë‹¤.\n\nì½”ë“œextrafont::loadfonts()\n\npricing_g &lt;- price %&gt;% \n  mutate(ëª¨í˜•ìƒì„¸ = glue::glue(\"{ëª¨í˜•êµ¬ë¶„} / {model} / {ì‘ì—…}\") %&gt;% as.character(.)) %&gt;%\n  mutate(ëª¨í˜•êµ¬ë¶„ = factor(ëª¨í˜•êµ¬ë¶„, levels=c(\"GPT-4\",\"Fine-tuning models\", \"Image models\", \"Audio models\", \n                                      \"InstructGPT\", \"Chat\", \"Embedding models\") )) %&gt;% \n  ggplot(aes(x = fct_reorder(ëª¨í˜•ìƒì„¸, ê°€ê²©), y = ê°€ê²©, fill = ëª¨í˜•êµ¬ë¶„)) +\n    geom_col(width = 0.5) +\n    # facet_wrap(~ëª¨í˜•êµ¬ë¶„, scales = \"free_y\") +\n    coord_flip() +\n    geom_text(aes(x = ëª¨í˜•ìƒì„¸, y = ê°€ê²©, label = glue::glue(\"{ê°€ê²©} ì›\") ), nudge_y = 5) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(title = \"OpenAI ì±—GPT API í˜¸ì¶œ ê°€ê²©\", \n         subtitle = \"í™˜ìœ¨ 1,300 ì›/ë‹¬ëŸ¬ ì ìš© (í…ìŠ¤íŠ¸ 1,000 í† í°, ì´ë¯¸ì§€ëŠ” í¬ê¸°ë³„, ì˜¤ë””ì˜¤ëŠ” 1ë¶„ ê¸°ì¤€)\",\n         x = \"\",\n         y = \"ê°€ê²©(ì›)\",\n         caption = \"OpenAI ê°€ê²©í‘œ: https://openai.com/pricing\") +\n    theme(legend.position = c(0.8, 0.3),\n          legend.title=element_text(size=rel(2.5), family = \"MaruBuri Bold\"),\n          legend.text=element_text(size=rel(1.5), family = \"MaruBuri Bold\"))\n\n\nragg::agg_png(\"images/pricing_g.png\", width = 297, height = 210, units = \"mm\", res = 600)\npricing_g\ndev.off()"
  },
  {
    "objectID": "translation.html",
    "href": "translation.html",
    "title": "chatGPT",
    "section": "",
    "text": "BLEU(Bilingual Evaluation Understudy, ì´ì¤‘ ì–¸ì–´ í‰ê°€ ì—°êµ¬)ëŠ” ê¸°ê³„ ë²ˆì—­ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì§€í‘œë‹¤. ê¸°ê³„ ìƒì„± ë²ˆì—­ì„ ì‚¬ëŒì´ ìƒì„±í•œ í•˜ë‚˜ ì´ìƒì˜ ì°¸ì¡° ë²ˆì—­ê³¼ ë¹„êµí•˜ê³  ì°¸ì¡° ë²ˆì—­ê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ì— ë”°ë¼ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•œë‹¤. BLEU ì ìˆ˜ëŠ” 0ì ì—ì„œ 1ì  ì‚¬ì´ì´ë©°, 1ì ì€ ê¸°ê³„ ìƒì„± ë²ˆì—­ê³¼ ì°¸ì¡° ë²ˆì—­ì´ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•¨ì„ ë‚˜íƒ€ë‚´ê³ , ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ê¸°ê³„ ìƒì„± ë²ˆì—­ì´ ì°¸ì¡° ë²ˆì—­ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ë” ê°€ê¹ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.\nCOMET(Cross-lingual Optimized Metric for Evaluation of Translation, ë²ˆì—­ í‰ê°€ë¥¼ ìœ„í•œ êµì°¨ ì–¸ì–´ ìµœì í™” ì§€í‘œ)ì€ 2020ë…„ì— ë„ì…ëœ ê¸°ê³„ ë²ˆì—­ í‰ê°€ ì§€í‘œë¡œ BLEUì™€ ê°™ì€ ê¸°ì¡´ ì§€í‘œì˜ ì¼ë¶€ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆë˜ì—ˆë‹¤. ê¸°ê³„ ìƒì„± ë²ˆì—­ê³¼ ì°¸ì¡° ë²ˆì—­ ê°„ì˜ n-ê·¸ë¨ ì¤‘ë³µë§Œì„ ë¹„êµí•˜ëŠ” BLEUì™€ ë‹¬ë¦¬ COMETì€ ìœ ì°½ì„±, ì ì ˆì„±, ì¶©ì‹¤ë„ ë“± ë²ˆì—­ í’ˆì§ˆì— ëŒ€í•œ ì—¬ëŸ¬ ì¸¡ë©´ì„ ê³ ë ¤í•¨ì€ ë¬¼ë¡  ê¸°ê³„ ìƒì„± ë²ˆì—­ê³¼ ì°¸ì¡° ë²ˆì—­ ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ë„ ê³ ë ¤í•œë‹¤. COMET ì ìˆ˜ëŠ” 0ì ì—ì„œ 100ì  ì‚¬ì´ì´ë©°, ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ê¸°ê³„ ìƒì„± ë²ˆì—­ì˜ í’ˆì§ˆì´ ìš°ìˆ˜í•˜ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚´ê³ , BLEUì™€ ê°™ì€ ê¸°ì¡´ ì§€í‘œë³´ë‹¤ ì‚¬ëŒì˜ í‰ê°€ì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜ ê¸°ê³„ ë²ˆì—­ í‰ê°€ì— ìœ ë§í•œ ì§€í‘œë¡œ ëŒ€ë‘ë˜ê³  ìˆë‹¤.\nì°¸ê³ : (Marie, 2022), (Marie, 2023)\n\nprompt = \"Score the following news summarization given the corresponding news with respect to fluency with one to five stars, where one star means â€œdisfluencyâ€ and five stars means â€œperfect fluencyâ€. Note that fluency measures the quality of individual sentences, are they well-written and grammatically correct. Consider the quality of individual sentences.\n\nSource: \nTarget: \""
  },
  {
    "objectID": "translation.html#gpt-3.5-turbo",
    "href": "translation.html#gpt-3.5-turbo",
    "title": "chatGPT",
    "section": "\n3.1 gpt-3.5-turbo\n",
    "text": "3.1 gpt-3.5-turbo\n\ngpt-3.5-turboì„ ì‚¬ìš©í•´ì„œ ë²ˆì—­ ëŒ€ìƒ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œë‹¤.\n\nì½”ë“œprompt = f\"What are some popular R libraries for data visualization and how are they used?\"\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a data scientist that mainly uses R programming language.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ],\n    max_tokens=300,\n    n=1,\n    stop=None,\n    temperature=0.5,\n)\n\n\n\nì½”ë“œgpt_turbo_result &lt;- py$response['choices'][[1]]$message$content\ngpt_turbo_result %&gt;% \n  write_lines(\"data/gpt_turbo_result.txt\")\n\n\n\nì½”ë“œgpt_turbo_result &lt;- read_lines(\"data/gpt_turbo_result.txt\")\ncat(str_c(gpt_turbo_result, collapse = \"\\n\"))\n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that can be embedded in web applications.\n#&gt; \n#&gt; These libraries are used to create a wide range of visualizations such as scatter plots, line charts, bar charts, histograms, heatmaps, and more. They provide a wide range of customization options and allow users to create visually appealing and informative plots that can help to communicate complex data sets"
  },
  {
    "objectID": "translation.html#ë²ˆì—­ëŒ€ìƒ-í…ìŠ¤íŠ¸-ìƒì„±",
    "href": "translation.html#ë²ˆì—­ëŒ€ìƒ-í…ìŠ¤íŠ¸-ìƒì„±",
    "title": "chatGPT",
    "section": "\n3.1 ë²ˆì—­ëŒ€ìƒ í…ìŠ¤íŠ¸ ìƒì„±",
    "text": "3.1 ë²ˆì—­ëŒ€ìƒ í…ìŠ¤íŠ¸ ìƒì„±\në°ì´í„° ì‹œê°í™”ì— ìì£¼ ì¸ìš©ë˜ëŠ” R íŒ¨í‚¤ì§€ì™€ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì„ ë¬¼ì—ˆê³  gpt-3.5-turboì„ ì‚¬ìš©í•´ì„œ ë²ˆì—­ ëŒ€ìƒ í…ìŠ¤íŠ¸ë¡œ ìƒì„±í•œë‹¤.\n\nWhat are some popular R packages for data visualization and how are they used? \në°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•´ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” R íŒ¨í‚¤ì§€ì—ëŠ” ì–´ë–¤ ê²ƒì´ ìˆìœ¼ë©° ì–´ë–»ê²Œ ì‚¬ìš©ë˜ë‚˜ìš”?\n\n\nprompt = f\"What are some popular R packages for data visualization and how are they used?\"\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a data scientist that mainly uses R programming language.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ],\n    max_tokens=300,\n    n=1,\n    stop=None,\n    temperature=0.5,\n)\n\n\ngpt_turbo_result &lt;- glue::glue(\"{py$response['choices'][[1]]$message$content}\\n\")\ngpt_turbo_result %&gt;% \n  write_lines(\"data/gpt_turbo_result.txt\")\n\n\ngpt_turbo_result &lt;- read_lines(\"data/gpt_turbo_result.txt\")\ncat(str_c(gpt_turbo_result, collapse = \"\\n\"))\n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that can be embedded in web applications.\n#&gt; \n#&gt; These libraries are used to create a wide range of visualizations such as scatter plots, line charts, bar charts, histograms, heatmaps, and more. They provide a wide range of customization options and allow users to create visually appealing and informative plots that can help to communicate complex data sets"
  },
  {
    "objectID": "translation.html#gpt-ì—”ì§„",
    "href": "translation.html#gpt-ì—”ì§„",
    "title": "chatGPT",
    "section": "\n3.2 GPT ì—”ì§„",
    "text": "3.2 GPT ì—”ì§„\n\n3.2.1 gpt-3.5-turbo\n\ngpt-3.5-turboëŠ” ì†ë„ê°€ ë¹ ë¥´ê³  ì €ë ´í•˜ì§€ë§Œ gpt-4ì—ëŠ” ì„±ëŠ¥ì´ ë¯¸ì¹˜ì§€ ëª»í•œë‹¤. Chatëª¨í˜• gpt-3.5-turbo ì—”ì§„ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\nwith open('data/gpt_turbo_result.txt', 'r') as file:\n    source_text = file.read()\n\ndef translate_text_by_model(text, model, source_language, target_language):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=1000,\n        n=1,\n        stop=None,\n        temperature=0.5,\n    )\n\n    return response\n\ntranslated_text = translate_text_by_model(source_text, 'gpt-3.5-turbo', 'English', 'Korean')\n\n\ngpt_turbo_3 &lt;- glue::glue(\"{py$translated_text['choices'][[1]]$message$content}\\n\")\ngpt_turbo_3 %&gt;% \n  write_lines(\"data/gpt_turbo_3.txt\")\n\n\ngpt_turbo_3 &lt;- read_lines(\"data/gpt_turbo_3.txt\")\ncat(str_c(gpt_turbo_3, collapse = \"\\n\"))\n#&gt; ë°ì´í„° ê³¼í•™ìë“¤ì´ ë„ë¦¬ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ ì¸ê¸° ìˆëŠ” R ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª‡ ê°€ì§€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¸ê¸° ìˆëŠ” ê²ƒ ì¤‘ ì¼ë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n#&gt; \n#&gt; 1. ggplot2: ggplot2ëŠ” ë³µì¡í•˜ê³  ë¯¸í•™ì ìœ¼ë¡œ ë§¤ë ¥ì ì¸ í”Œë¡¯ì„ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ê·¸ë˜í”½ ë¬¸ë²•ì— ê¸°ë°˜ì„ ë‘ê³  ìˆìœ¼ë©° ë‹¤ì–‘í•œ ì‚¬ìš©ì ì •ì˜ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n#&gt; \n#&gt; 2. lattice: latticeëŠ” ë‹¤ì–‘í•œ ê³ ìˆ˜ì¤€ í”Œë¡œíŒ… í•¨ìˆ˜ë¥¼ ì œê³µí•˜ëŠ” ì¸ê¸° ìˆëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. íŠ¹íˆ ë©€í‹° íŒ¨ë„ í”Œë¡¯ì„ ë§Œë“œëŠ” ë° ìœ ìš©í•˜ë©° ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.\n#&gt; \n#&gt; 3. plotly: plotlyëŠ” ì‚¬ìš©ìê°€ ëŒ€í™”í˜• ë° ë™ì  í”Œë¡¯ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì›¹ ê¸°ë°˜ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ëŒ€í™”í˜• ëŒ€ì‹œ ë³´ë“œ ë° ì˜¨ë¼ì¸ ê³µìœ  ê°€ëŠ¥í•œ ì‹œê°í™”ë¥¼ ë§Œë“œëŠ” ë° íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; 4. ggvis: ggvisëŠ” ê·¸ë˜í”½ ë¬¸ë²•ì„ ê¸°ë°˜ìœ¼ë¡œí•˜ë©° ëŒ€í™”í˜• ë° ë™ì  í”Œë¡¯ì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. íŠ¹íˆ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• í”Œë¡¯ì„ ë§Œë“œëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; 5. rCharts: rChartsëŠ” ë‹¤ì–‘í•œ ëŒ€í™”í˜• ë° ë™ì  í”Œë¡¯ì„ ì œê³µí•˜ëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. íŠ¹íˆ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í¬í•¨ë  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• ì‹œê°í™”ë¥¼ ë§Œë“œëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; ì´ëŸ¬í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì‚°ì ë„, êº¾ì€ ì„  ê·¸ë˜í”„, ë§‰ëŒ€ ê·¸ë˜í”„, íˆìŠ¤í† ê·¸ë¨, íˆíŠ¸ë§µ ë“± ë‹¤ì–‘í•œ ì‹œê°í™”ë¥¼ ë§Œë“œëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‚¬ìš©ì ì •ì˜ ì˜µì…˜ì„ ì œê³µí•˜ë©° ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì „ë‹¬í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì´ê³  ì •ë³´ì„± ìˆëŠ” í”Œë¡¯ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\n3.2.2 text-davinci-003\n\nInstructGPT text-davinci-003 ëª¨í˜•ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\nwith open('data/gpt_turbo_result.txt', 'r') as file:\n    source_text = file.read()\n\ndef translate_by_instruct_model(text, model, source_language, target_language):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n\n    response = openai.Completion.create(\n        model=model,\n        prompt=prompt,\n        max_tokens=2000,\n        n=1,\n        temperature=0,\n    )\n\n    return response\n\ndavinci_text = translate_by_instruct_model(source_text, 'text-davinci-003', 'English', 'Korean')\n\n\ndavinci_text &lt;- glue::glue(\"{py$davinci_text['choices'][[1]]$text}\\n\")\ndavinci_text %&gt;% \n  write_lines(\"data/davinci_text.txt\")\n\n\ndavinci_text &lt;- read_lines(\"data/davinci_text.txt\")\ncat(str_c(davinci_text, collapse = \"\\n\"))\n#&gt; \n#&gt; ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•´ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì¸ê¸°ìˆëŠ” R ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—¬ëŸ¬ ê°œ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¸ê¸°ìˆëŠ” ê²ƒë“¤ ì¤‘ ëª‡ ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; 1. ggplot2 : ggplot2ì€ ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì‚¬ìš©ìê°€ ë³µì¡í•˜ê³  ì•„ë¦„ë‹¤ìš´ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ì˜ ë¬¸ë²•ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©° ë‹¤ì–‘í•œ ì‚¬ìš©ì ì •ì˜ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n#&gt; \n#&gt; 2. lattice : latticeëŠ” ë‹¤ë¥¸ ì¸ê¸°ìˆëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë‹¤ì–‘í•œ ê³ ìˆ˜ì¤€ ê·¸ë˜í”„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ì¤‘ íŒ¨ë„ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ë•Œ íŠ¹íˆ ìœ ìš©í•˜ë©°, ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.\n#&gt; \n#&gt; 3. plotly : plotlyì€ ì›¹ ê¸°ë°˜ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì‚¬ìš©ìê°€ ìƒí˜¸ ì‘ìš©ì ì´ê³  ë™ì ì¸ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒí˜¸ ì‘ìš©ì ì¸ ëŒ€ì‹œ ë³´ë“œ ë° ì˜¨ë¼ì¸ìœ¼ë¡œ ê³µìœ í•  ìˆ˜ ìˆëŠ” ì‹œê°í™”ë¥¼ ë§Œë“¤ ë•Œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; 4. ggvis : ggvisëŠ” ê·¸ë˜í”„ì˜ ë¬¸ë²•ì„ ê¸°ë°˜ìœ¼ë¡œí•œ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë‹¤ì–‘í•œ ìƒí˜¸ ì‘ìš©ì ì´ê³  ë™ì ì¸ ê·¸ë˜í”„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì›¹ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ ì‚¬ìš©í•  ìˆ˜ìˆëŠ” ìƒí˜¸ ì‘ìš©ì ì¸ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ë•Œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; 5. rCharts : rChartsëŠ” ë‹¤ì–‘í•œ ìƒí˜¸ ì‘ìš©ì ì´ê³  ë™ì ì¸ ê·¸ë˜í”„ë¥¼ ì œê³µí•˜ëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì›¹ ì‘ìš© í”„ë¡œê·¸ë¨ì— í†µí•©í•  ìˆ˜ìˆëŠ” ìƒí˜¸ ì‘ìš©ì ì¸ ì‹œê°í™”ë¥¼ ë§Œë“¤ ë•Œ íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; ì´ëŸ¬í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì‚°ì ë„, ì„  ê·¸ë˜í”„, ë§‰ëŒ€ ê·¸ë˜í”„, íˆìŠ¤í† ê·¸ë¨, íˆíŠ¸ë§µ ë“± ë‹¤ì–‘í•œ ì‹œê°í™”ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ë“¤ì€ ë‹¤ì–‘í•œ ì‚¬ìš©ì ì •ì˜ ì˜µì…˜ì„ ì œê³µí•˜ê³ , ì‚¬ìš©ìê°€ ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•´ ì•„ë¦„ë‹¤ìš´ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n\n\n3.2.3 text-curie-001\n\nInstructGPT text-curie-001 ëª¨í˜•ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\ndef translate_by_instruct_model(text, model, source_language, target_language):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n\n    response = openai.Completion.create(\n        model=model,\n        prompt=prompt,\n        max_tokens=1500,\n        n=1,\n        temperature=0,\n    )\n\n    return response\n  \ncurie_text = translate_by_instruct_model(source_text, 'text-curie-001', 'English', 'Korean')\n\n\ncurie_text &lt;- glue::glue(\"{py$curie_text['choices'][[1]]$text}\\n\")\ncurie_text %&gt;% \n  write_lines(\"data/curie_text.txt\")\n\n\ncurie_text &lt;- read_lines(\"data/curie_text.txt\")\ncat(str_c(curie_text, collapse = \"\\n\"))\n#&gt; \n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that can be embedded in web applications.\n\n\n3.2.4 text-babbage-001\n\nInstructGPT text-babbage-001 ëª¨í˜•ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\nbabbage_text = translate_by_instruct_model(source_text, 'text-babbage-001', 'English', 'Korean')\n\n\nbabbage_text &lt;- glue::glue(\"{py$babbage_text['choices'][[1]]$text}\\n\")\nbabbage_text %&gt;% \n  write_lines(\"data/babbage_text.txt\")\n\n\nbabbage_text &lt;- read_lines(\"data/babbage_text.txt\")\ncat(str_c(babbage_text, collapse = \"\\n\"))\n#&gt; \n#&gt; Korean: ì‚¬ìš©í•œ ë°ì´í„°ë³´í˜¸ì‚¬ì´íŠ¸ ê°œë°œì‚¬ì´íŠ¸\n\n\n3.2.5 text-ada-001\n\nInstructGPT text-ada-001 ëª¨í˜•ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\nada_text = translate_by_instruct_model(source_text, 'text-ada-001', 'English', 'Korean')\n\n\nada_text &lt;- glue::glue(\"{py$ada_text['choices'][[1]]$text}\\n\")\nada_text %&gt;% \n  write_lines(\"data/ada_text.txt\")\n\n\nada_text &lt;- read_lines(\"data/ada_text.txt\")\ncat(str_c(ada_text, collapse = \"\\n\"))\n#&gt; \n#&gt; Korean\n#&gt; \n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that are embedded in web applications."
  },
  {
    "objectID": "translation.html#ì±—gpt-ì¶”ì²œ",
    "href": "translation.html#ì±—gpt-ì¶”ì²œ",
    "title": "chatGPT",
    "section": "\n3.3 ì±—GPT ì¶”ì²œ",
    "text": "3.3 ì±—GPT ì¶”ì²œ\n\n\n\n\n\n\nPrompt: recommend instructGPT model for english to korean translation\n\n\n\n\n\nSure, for English to Korean translation, you can use the OpenAI model text-davinci-002 or text-davinci-002-instruct-beta. These models have been trained on a large amount of data and are capable of high-quality translation.\nTo use these models, you can modify the translate_text_by_model function like this:\ndef translate_text_by_model(text, model=\"text-davinci-002-instruct-beta\", source_language=\"en\", target_language=\"ko\"):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n    response = openai.Completion.create(\n        engine=model,\n        prompt=prompt,\n        max_tokens=2000,\n        n=1,\n        stop=None,\n        temperature=0.5,\n    )\n\n    return response.choices[0].text\nHere, weâ€™re using the Completion.create function to directly send the prompt to the API, without the need for the messages parameter. The max_tokens parameter controls the maximum number of tokens that the API can return in the response, so you may want to adjust this value based on your needs.\nNote that text-davinci-002-instruct-beta is a beta model that supports instruction following. You can use this model to provide additional context to the translation by including step-by-step instructions in the prompt.\n\n\n\n\n3.3.1 text-davinci-002\n\nInstructGPT text-davinci-002 ëª¨í˜•ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\ndavinci_2_text = translate_by_instruct_model(source_text, 'text-davinci-002', 'English', 'Korean')\n\n\ndavinci_2_text &lt;- glue::glue(\"{py$davinci_2_text['choices'][[1]]$text}\\n\")\ndavinci_2_text %&gt;% \n  write_lines(\"data/davinci_2_text.txt\")\n\n\ndavinci_2_text &lt;- read_lines(\"data/davinci_2_text.txt\")\ncat(str_c(davinci_2_text, collapse = \"\\n\"))\n#&gt; \n#&gt; 1. ggplot2: ggplot2ëŠ” ê°•ë ¥í•˜ê³  ìœ ì—°í•œ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì¨ ì‚¬ìš©ìë“¤ì´ ë³µì¡í•˜ê³  ì•„ë¦„ë‹¤ìš´ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ê·¸ê²ƒì€ ê·¸ë˜í”„ì˜ ë¬¸ë²•ì— ê¸°ë°˜í•˜ì—¬ ìˆìœ¼ë©° ë‹¤ì–‘í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n#&gt; 2. lattice: latticeëŠ” ë˜ ë‹¤ë¥¸ ì¸ê¸°ìˆëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì¨ ë‹¤ì–‘í•œ ê³ ìˆ˜ì¤€ì˜ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ì¤‘ íŒ¨ë„ ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ”ë° íŠ¹íˆ ìœ ìš©í•˜ë©°, ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‹œê°í™”í•˜ëŠ”ë° ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.\n#&gt; 3. plotly: plotlyëŠ” ì›¹ ê¸°ë°˜ì˜ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì¨ ì‚¬ìš©ìë“¤ì´ ìƒí˜¸ ì‘ìš©ì ì´ê³  ë™ì ì¸ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. íŠ¹íˆ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒí˜¸ ì‘ìš©ì ì¸ ëŒ€ì‹œë³´ë“œì™€ ì‹œê°í™”ë¥¼ ë§Œë“œëŠ”ë° íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; 4. ggvis: ggvisëŠ” ê·¸ë˜í”„ì˜ ë¬¸ë²•ì— ê¸°ë°˜í•œ ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì¨ ë‹¤ì–‘í•œ ìƒí˜¸ ì‘ìš©ì ì´ê³  ë™ì ì¸ ê·¸ë˜í”„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒí˜¸ ì‘ìš©ì ì¸ ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ”ë° íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; 5. rCharts: rChartsëŠ” ë‹¤ì–‘í•œ ìƒí˜¸ ì‘ìš©ì ì´ê³  ë™ì ì¸ ê·¸ë˜í”„ë¥¼ ì œê³µí•˜ëŠ” ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. íŠ¹íˆ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒí˜¸ ì‘ìš©ì ì¸ ì‹œê°í™”ë¥¼ ë§Œë“œëŠ”ë° íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; ì´ëŸ¬í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ ì‚°ì ë„, ì„  ê·¸ë˜í”„, ë§‰ëŒ€ ê·¸ë˜í”„, íˆìŠ¤í† ê·¸ë¨, íˆíŠ¸ë§µ ë“± ë‹¤ì–‘í•œ ì‹œê°í™”ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜µì…˜ì„ ì œê³µí•˜ë©°, ì‚¬ìš©ìë“¤ì´ ë³´ê¸° ì¢‹ê³  ì •ë³´ì ì¸ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ì–´ ë³µì¡í•œ ë°ì´í„° ì„¸\n\n\n3.3.2 davinci-instruct-beta\n\nInstructGPT davinci-instruct-beta ëª¨í˜•ì— ë„£ì–´ ë²ˆì—­ í’ˆì§ˆì„ ì‚´í´ë³´ì.\n\ndavinci_instruct_text = translate_by_instruct_model(source_text, 'davinci-instruct-beta', 'English', 'Korean')\n\n\ndavinci_instruct_text &lt;- glue::glue(\"{py$davinci_instruct_text['choices'][[1]]$text}\\n\")\ndavinci_instruct_text %&gt;% \n  write_lines(\"data/davinci_instruct_text.txt\")\n\n\ndavinci_instruct_text &lt;- read_lines(\"data/davinci_instruct_text.txt\")\ncat(str_c(davinci_instruct_text, collapse = \"\\n\"))\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒì¼ì„ ì½ì–´ì£¼ì„¸ìš”.\n#&gt; \n#&gt; ì—¬ëŸ¬ë²ˆì§¸ íŒŒ"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-1",
    "title": "chatGPT",
    "section": "\n3.1 ì§ˆë¬¸ 1",
    "text": "3.1 ì§ˆë¬¸ 1\n\nì½”ë“œquestion_01 &lt;- \"ë°ì´í„° íƒìƒ‰ì´ë€ ë¬´ì—‡ì´ë©°, ë°ì´í„° ê³¼í•™ì—ì„œ ì–´ë–»ê²Œ ìœ ìš©í•œê°€ìš”?\"\n\nformat_answer &lt;- function(question) {\n  \n  answer_json &lt;- py$answer_question(question)\n  answer_list &lt;- jsonlite::fromJSON(as.character(answer_json))\n  return(answer_list)\n}\n\nanswer_01 &lt;- format_answer(question_01)\nanswer_01_text &lt;- answer_01$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\në°ì´í„° íƒìƒ‰ì´ë€ ë¬´ì—‡ì´ë©°, ë°ì´í„° ê³¼í•™ì—ì„œ ì–´ë–»ê²Œ ìœ ìš©í•œê°€ìš”?\n\n\në‹µë³€\në°ì´í„° íƒìƒ‰ì€ ë°ì´í„°ë¥¼ ì´í•´í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê³  ìš”ì•½í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ë°ì´í„°ì˜ íŒ¨í„´, ì´ìƒì¹˜, ê²°ì¸¡ì¹˜ ë“±ì„ íŒŒì•…í•˜ê³  ë°ì´í„°ì˜ íŠ¹ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në°ì´í„° ê³¼í•™ì—ì„œ ë°ì´í„° íƒìƒ‰ì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ë°ì´í„° íƒìƒ‰ì„ í†µí•´ ë°ì´í„°ì˜ íŠ¹ì„±ì„ íŒŒì•…í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë°ì´í„° íƒìƒ‰ì„ í†µí•´ ë°ì´í„° ë¶„ì„ì— í•„ìš”í•œ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ê³  ëª¨ë¸ë§ì— ì í•©í•œ ë°ì´í„°ë¥¼ ì„ ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në°ì´í„° íƒìƒ‰ì€ ë˜í•œ ë°ì´í„° ì‹œê°í™”ë¥¼ í†µí•´ ë°ì´í„°ì˜ íŒ¨í„´ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ë” ì˜ ì´í•´í•˜ê³  ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në”°ë¼ì„œ ë°ì´í„° ê³¼í•™ì—ì„œ ë°ì´í„° íƒìƒ‰ì€ ë°ì´í„° ë¶„ì„ì˜ ì²« ë‹¨ê³„ì´ë©°, ë°ì´í„° ë¶„ì„ì˜ í’ˆì§ˆê³¼ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ê³¼ì •ì…ë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_01$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n326\n\n\nprompt_tokens\n118\n\n\ntotal_tokens\n444"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-2-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-2-1",
    "title": "chatGPT",
    "section": "\n3.2 ì§ˆë¬¸ 2",
    "text": "3.2 ì§ˆë¬¸ 2\n\nì½”ë“œquestion_02 &lt;- \"Rì„ ì‚¬ìš©í•œ ê¸°ë³¸ì ì¸ ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_02 &lt;- format_answer(question_02)\nanswer_02_text &lt;- answer_02$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\nRì„ ì‚¬ìš©í•œ ê¸°ë³¸ì ì¸ ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\në¬¼ë¡ ì…ë‹ˆë‹¤! Rì„ ì‚¬ìš©í•œ ê¸°ë³¸ì ì¸ ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\ndata &lt;- read.csv(\"data.csv\")\n\n# ë°ì´í„° êµ¬ì¡° íŒŒì•…í•˜ê¸°\nstr(data)\n\n# ë°ì´í„° ìš”ì•½ ë³´ê¸°\nsummary(data)\n\n# ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íŒŒì•…í•˜ê¸°\ncor(data)\n\n# ë³€ìˆ˜ ê°„ ì‚°ì ë„ ê·¸ë¦¬ê¸°\nplot(data$var1, data$var2)\n\n# ë³€ìˆ˜ ë¶„í¬ íŒŒì•…í•˜ê¸°\nhist(data$var1)\n\n# ë³€ìˆ˜ ê°„ ì°¨ì´ íŒŒì•…í•˜ê¸°\nt.test(data$var1 ~ data$var2)\n\n# ë³€ìˆ˜ ê°„ ì°¨ì´ ì‹œê°í™”í•˜ê¸°\nboxplot(data$var1 ~ data$var2)\nìœ„ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ìš”ì•½ì„ íŒŒì•…í•˜ë©°, ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ì™€ ë¶„í¬ë¥¼ íŒŒì•…í•˜ê³ , ë³€ìˆ˜ ê°„ ì°¨ì´ë¥¼ ë¶„ì„í•˜ë©°, ì°¨ì´ë¥¼ ì‹œê°í™”í•˜ëŠ” ê¸°ë³¸ì ì¸ ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤. ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_02$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n311\n\n\nprompt_tokens\n116\n\n\ntotal_tokens\n427"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-3-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-3-1",
    "title": "chatGPT",
    "section": "\n3.3 ì§ˆë¬¸ 3",
    "text": "3.3 ì§ˆë¬¸ 3\n\nì½”ë“œquestion_03 &lt;- \"PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_03 &lt;- format_answer(question_03)\nanswer_03_text &lt;- answer_03$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\nPCA(Principal Component Analysis)ëŠ” ë‹¤ì°¨ì› ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ, ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³  ì°¨ì›ì„ ì¶•ì†Œí•˜ì—¬ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\në°ì´í„° ì „ì²˜ë¦¬: PCAë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ê±°ë‚˜ í‘œì¤€í™”í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ìŠ¤ì¼€ì¼ ì°¨ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤.\nê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°: PCAëŠ” ê³µë¶„ì‚° í–‰ë ¬ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë°ì´í„°ì˜ ê³µë¶„ì‚° í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\nê³ ìœ ê°’ ë¶„í•´: ê³µë¶„ì‚° í–‰ë ¬ì˜ ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê³ ìœ ê°’ì€ ê°ê°ì˜ ê³ ìœ ë²¡í„°ê°€ ê°€ë¦¬í‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê³ ìœ ë²¡í„°ëŠ” ë°ì´í„°ì˜ ì£¼ì„±ë¶„(principal component)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\nì£¼ì„±ë¶„ ì„ íƒ: ê³ ìœ ê°’ì´ í° ìˆœì„œëŒ€ë¡œ ì£¼ì„±ë¶„ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ê°€ ê°€ì¥ í° ì£¼ì„±ë¶„ì„ ì°¾ì•„ë‚´ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨ì›ì„ ì¶•ì†Œí•©ë‹ˆë‹¤.\nì°¨ì› ì¶•ì†Œ: ì„ íƒí•œ ì£¼ì„±ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ì¶•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì€ ìœ„ì™€ ê°™ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê³ , ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_03$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n527\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n649"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-4-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-4-1",
    "title": "chatGPT",
    "section": "\n3.4 ì§ˆë¬¸ 4",
    "text": "3.4 ì§ˆë¬¸ 4\n\nì½”ë“œquestion_04 &lt;- \"PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_04 &lt;- format_answer(question_04)\nanswer_04_text &lt;- answer_04$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\nPCA(Principal Component Analysis)ëŠ” ë‹¤ì°¨ì› ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ, ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³  ì°¨ì›ì„ ì¶•ì†Œí•˜ì—¬ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\në°ì´í„° ì „ì²˜ë¦¬: PCAë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ê±°ë‚˜ í‘œì¤€í™”í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ìŠ¤ì¼€ì¼ ì°¨ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤.\nê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°: PCAëŠ” ê³µë¶„ì‚° í–‰ë ¬ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë°ì´í„°ì˜ ê³µë¶„ì‚° í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\nê³ ìœ ê°’ ë¶„í•´: ê³µë¶„ì‚° í–‰ë ¬ì˜ ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê³ ìœ ê°’ì€ ê°ê°ì˜ ê³ ìœ ë²¡í„°ê°€ ê°€ë¦¬í‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê³ ìœ ë²¡í„°ëŠ” ë°ì´í„°ì˜ ì£¼ì„±ë¶„(principal component)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\nì°¨ì› ì¶•ì†Œ: ê³ ìœ ê°’ì´ í° ìˆœì„œëŒ€ë¡œ ê³ ìœ ë²¡í„°ë¥¼ ì„ íƒí•˜ì—¬ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ì¶•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³  ì°¨ì›ì„ ì¶•ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì‹œê°í™” ë° ë¶„ì„: ìƒˆë¡œìš´ ì¶•ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜ ë¶„ì„í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.\n\nRì—ì„œëŠ” PCAë¥¼ ìˆ˜í–‰í•˜ëŠ” ë‹¤ì–‘í•œ í•¨ìˆ˜ë“¤ì´ ì œê³µë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, prcomp() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ PCAë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_04$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n497\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n619"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-5-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-5-1",
    "title": "chatGPT",
    "section": "\n3.5 ì§ˆë¬¸ 5",
    "text": "3.5 ì§ˆë¬¸ 5\n\nì½”ë“œquestion_05 &lt;- \"t-SNE, PCA ë° í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ëŠ” ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_05 &lt;- format_answer(question_05)\nanswer_05_text &lt;- answer_05$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\nt-SNE, PCA ë° í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ëŠ” ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\në„¤, t-SNE, PCA ë° í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ëŠ” ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì˜ˆì‹œ ì½”ë“œì…ë‹ˆë‹¤.\n# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\ndata &lt;- read.csv(\"data.csv\")\n\n# ë³€ìˆ˜ ì„ íƒ\nselected_vars &lt;- c(\"var1\", \"var2\", \"var3\", \"var4\")\n\n# PCA ìˆ˜í–‰\npca &lt;- prcomp(data[, selected_vars], scale = TRUE)\n\n# t-SNE ìˆ˜í–‰\ntsne &lt;- Rtsne::Rtsne(data[, selected_vars], perplexity = 30, dims = 2)\n\n# í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰\nkmeans &lt;- kmeans(data[, selected_vars], centers = 3)\n\n# ì‹œê°í™”\nlibrary(ggplot2)\n\n# PCA ì‹œê°í™”\nggplot(data, aes(x = pca$x[,1], y = pca$x[,2], color = factor(kmeans$cluster))) + \n  geom_point() + \n  ggtitle(\"PCA\")\n\n# t-SNE ì‹œê°í™”\nggplot(data, aes(x = tsne$Y[,1], y = tsne$Y[,2], color = factor(kmeans$cluster))) + \n  geom_point() + \n  ggtitle(\"t-SNE\")\n\n# í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”\nggplot(data, aes(x = var1, y = var2, color = factor(kmeans$cluster))) + \n  geom_point() + \n  ggtitle(\"Clustering\")\nìœ„ ì½”ë“œì—ì„œëŠ” ë¨¼ì € ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ í›„, ë³€ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ PCAë¥¼ ìˆ˜í–‰í•˜ê³ , t-SNEë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‹œê°í™”ë¥¼ ìœ„í•´ ggplot2 íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. PCA, t-SNE ë° í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ê°ê° ì‹œê°í™”í•©ë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_05$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n455\n\n\nprompt_tokens\n133\n\n\ntotal_tokens\n588"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-6-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-6-1",
    "title": "chatGPT",
    "section": "\n3.6 ì§ˆë¬¸ 6",
    "text": "3.6 ì§ˆë¬¸ 6\n\nì½”ë“œquestion_06 &lt;- \"tibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì–´ë–»ê²Œ ì‹ë³„í•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_06 &lt;- format_answer(question_06)\nanswer_06_text &lt;- answer_06$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\ntibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì–´ë–»ê²Œ ì‹ë³„í•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\nì‹œê³„ì—´ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ì§€ë§Œ, tibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\ntibbleì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ì „ì—, ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. tibbleì€ tidyverse íŒ¨í‚¤ì§€ì— í¬í•¨ëœ ë°ì´í„° ì •ë¦¬ ë„êµ¬ë¡œ, ë°ì´í„°ë¥¼ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê³„ì—´ ë°ì´í„°ì˜ ê²½ìš°, ë‚ ì§œì™€ ê°’ì˜ ë‘ ì—´ë¡œ êµ¬ì„±ëœ ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ lubridate íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚ ì§œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤. ggplot2ëŠ” ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ R íŒ¨í‚¤ì§€ë¡œ, ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ê·¸ë˜í”„ë¡œ ê·¸ë¦¬ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ì„œëŠ”, ë¨¼ì € xì¶•ì— ë‚ ì§œë¥¼, yì¶•ì— ê°’(ì˜ˆ: ì£¼ì‹ ê°€ê²©)ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì´í›„ geom_line() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„  ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì¶”ì„¸ì„ ê³¼ íŒ¨í„´ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ê¸° ìœ„í•´ì„œëŠ”, ì¶”ì„¸ì„ ì„ ê·¸ë ¤ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ geom_smooth() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì„¸ì„ ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŒ¨í„´ì„ ì‹ë³„í•˜ê¸° ìœ„í•´ì„œëŠ”, geom_point() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì  ê·¸ë˜í”„ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ íŠ¹ì • íŒ¨í„´ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì¶”ê°€ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ëŠ” ê²ƒì€ ì¤‘ìš”í•œ ë¶„ì„ ê³¼ì • ì¤‘ í•˜ë‚˜ì¼ ë¿ì…ë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬, ë°ì´í„°ì˜ íŠ¹ì„±ì„ ë”ìš± ìì„¸íˆ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ARIMA ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜, ì´ë™í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì¶”ì„¸ë¥¼ ë”ìš± ì •í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬, tibbleê³¼ ggplot2ë¥¼ í™œìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_06$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n663\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n785"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-7-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-7-1",
    "title": "chatGPT",
    "section": "\n3.7 ì§ˆë¬¸ 7",
    "text": "3.7 ì§ˆë¬¸ 7\n\nì½”ë“œquestion_07 &lt;- \"tibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ëŠ” ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_07 &lt;- format_answer(question_07)\nanswer_07_text &lt;- answer_07$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\ntibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ëŠ” ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ì˜ ì˜ˆì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\në„¤, tibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ëŠ” ë°ì´í„° íƒìƒ‰ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì˜ˆì‹œ ì½”ë“œì…ë‹ˆë‹¤.\nlibrary(tidyverse)\n\n# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\ndata &lt;- read_csv(\"data.csv\")\n\n# ë°ì´í„° ì „ì²˜ë¦¬\ndata &lt;- data %&gt;%\n  mutate(date = as.Date(date)) %&gt;%\n  arrange(date)\n\n# tibble ìƒì„±\ndata_tbl &lt;- as_tibble(data)\n\n# ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì‹œê°í™”\nggplot(data_tbl, aes(x = date, y = value)) +\n  geom_line() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"íŒ¨í„´ê³¼ ì¶”ì„¸ ì‹ë³„\", x = \"ë‚ ì§œ\", y = \"ê°’\")\nìœ„ ì½”ë“œì—ì„œëŠ” ë¨¼ì € tidyverse íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜¨ í›„, ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. ê·¸ ë‹¤ìŒ, tibbleì„ ìƒì„±í•˜ê³  ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. geom_line() í•¨ìˆ˜ëŠ” ë°ì´í„°ì˜ íŒ¨í„´ì„ ë³´ì—¬ì£¼ë©°, geom_smooth() í•¨ìˆ˜ëŠ” ë°ì´í„°ì˜ ì¶”ì„¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. labs() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ì˜ ì œëª©ê³¼ ì¶• ë ˆì´ë¸”ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì´ë ‡ê²Œ ì‘ì„±ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©´, ë°ì´í„°ì—ì„œ íŒ¨í„´ê³¼ ì¶”ì„¸ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆëŠ” ê·¸ë˜í”„ê°€ ìƒì„±ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë” ì˜ ì´í•´í•˜ê³ , ë‹¤ìŒ ë¶„ì„ì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_07$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n395\n\n\nprompt_tokens\n130\n\n\ntotal_tokens\n525"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-8-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-8-1",
    "title": "chatGPT",
    "section": "\n3.8 ì§ˆë¬¸ 8",
    "text": "3.8 ì§ˆë¬¸ 8\n\nì½”ë“œquestion_08 &lt;- \"tibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•œ ì¼ë°˜ì ì¸ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n\nanswer_08 &lt;- format_answer(question_08)\nanswer_08_text &lt;- answer_08$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\ntibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•œ ì¼ë°˜ì ì¸ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\n\në‹µë³€\ntibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•œ ì¼ë°˜ì ì¸ ê¸°ìˆ ì€ ì‚°ì ë„(Scatter plot)ì…ë‹ˆë‹¤. ì‚°ì ë„ëŠ” ë‘ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, xì¶•ê³¼ yì¶•ì— ê°ê°ì˜ ë³€ìˆ˜ë¥¼ í• ë‹¹í•˜ì—¬ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³€ìˆ˜ ê°„ì˜ ìƒê´€ ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³ , ì´ìƒì¹˜ë‚˜ íŒ¨í„´ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ggplot2ë¥¼ ì‚¬ìš©í•˜ë©´ ì‚°ì ë„ë¥¼ ê·¸ë¦¬ëŠ” ê²ƒì´ ë§¤ìš° ê°„ë‹¨í•˜ë©°, ì¶”ê°€ì ì¸ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•˜ì—¬ ë” ë§ì€ ì •ë³´ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìƒ‰ìƒ, í¬ê¸°, ëª¨ì–‘ ë“±ì„ ì´ìš©í•˜ì—¬ ë‹¤ë¥¸ ë³€ìˆ˜ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_08$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n235\n\n\nprompt_tokens\n123\n\n\ntotal_tokens\n358"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-9-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-9-1",
    "title": "chatGPT",
    "section": "\n3.9 ì§ˆë¬¸ 9",
    "text": "3.9 ì§ˆë¬¸ 9\n\nì½”ë“œquestion_09 &lt;- \"tibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚°ì ë„ì™€ ì„  ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n\nanswer_09 &lt;- format_answer(question_09)\nanswer_09_text &lt;- answer_09$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\ntibbleê³¼ ggplot2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚°ì ë„ì™€ ì„  ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\n\në‹µë³€\në¨¼ì €, tibbleì€ ë°ì´í„° í”„ë ˆì„ì˜ í™•ì¥íŒìœ¼ë¡œ tidyverse íŒ¨í‚¤ì§€ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. tibbleì€ ë°ì´í„°ë¥¼ ë”ìš± ì‰½ê²Œ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”ëœ ë°ì´í„° í˜•ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.\nggplot2ëŠ” Rì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì‹œê°í™” íŒ¨í‚¤ì§€ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ggplot2ë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì‚°ì ë„ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ggplot2ì˜ geom_point() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” xì¶•ê³¼ yì¶•ì— í•´ë‹¹í•˜ëŠ” ë³€ìˆ˜ë¥¼ ì§€ì •í•˜ê³ , ë°ì´í„°ë¥¼ ì‚°ì ë„ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ mpg ë°ì´í„°ì…‹ì—ì„œ displ(ë°°ê¸°ëŸ‰)ê³¼ hwy(ê³ ì†ë„ë¡œ ì—°ë¹„) ë³€ìˆ˜ê°„ì˜ ì‚°ì ë„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nlibrary(ggplot2)\nlibrary(tibble)\n\nmpg_tibble &lt;- as_tibble(mpg) # mpg ë°ì´í„°ì…‹ì„ tibble í˜•ì‹ìœ¼ë¡œ ë³€í™˜\nggplot(mpg_tibble, aes(x = displ, y = hwy)) + geom_point()\nì„  ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ggplot2ì˜ geom_line() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” xì¶•ê³¼ yì¶•ì— í•´ë‹¹í•˜ëŠ” ë³€ìˆ˜ë¥¼ ì§€ì •í•˜ê³ , ë°ì´í„°ë¥¼ ì„  ê·¸ë˜í”„ë¡œ í‘œí˜„í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒê³¼ ê°™ì´ airquality ë°ì´í„°ì…‹ì—ì„œ Month(ì›”)ì™€ Ozone(ì˜¤ì¡´) ë³€ìˆ˜ê°„ì˜ ì„  ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nairquality_tibble &lt;- as_tibble(airquality) # airquality ë°ì´í„°ì…‹ì„ tibble í˜•ì‹ìœ¼ë¡œ ë³€í™˜\nggplot(airquality_tibble, aes(x = Month, y = Ozone)) + geom_line()\nì´ë ‡ê²Œ ìƒì„±ëœ ì‚°ì ë„ì™€ ì„  ê·¸ë˜í”„ë¥¼ í†µí•´ ë³€ìˆ˜ê°„ì˜ ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_09$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n502\n\n\nprompt_tokens\n133\n\n\ntotal_tokens\n635"
  },
  {
    "objectID": "prompt_data_science.html#ì§ˆë¬¸-10-1",
    "href": "prompt_data_science.html#ì§ˆë¬¸-10-1",
    "title": "chatGPT",
    "section": "\n3.10 ì§ˆë¬¸ 10",
    "text": "3.10 ì§ˆë¬¸ 10\n\nì½”ë“œquestion_10 &lt;- \"PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‚˜ìš”?\"\n\nanswer_10 &lt;- format_answer(question_10)\nanswer_10_text &lt;- answer_10$choices$message$content\n\n\n\n\n\nì§ˆë¬¸\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ì–´ë–»ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë‚˜ìš”?\n\n\në‹µë³€\nPCA(Principal Component Analysis)ëŠ” ë‹¤ì°¨ì› ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ, ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³  ì°¨ì›ì„ ì¶•ì†Œí•˜ì—¬ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜ ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\nPCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\në°ì´í„° ì „ì²˜ë¦¬: PCAë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ê±°ë‚˜ í‘œì¤€í™”í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ìŠ¤ì¼€ì¼ ì°¨ì´ë¥¼ ì¤„ì…ë‹ˆë‹¤.\nê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°: PCAëŠ” ê³µë¶„ì‚° í–‰ë ¬ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë°ì´í„°ì˜ ê³µë¶„ì‚° í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\nê³ ìœ ê°’ ë¶„í•´: ê³µë¶„ì‚° í–‰ë ¬ì˜ ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê³ ìœ ê°’ì€ ê°ê°ì˜ ê³ ìœ ë²¡í„°ê°€ ê°€ë¦¬í‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ê³ ìœ ë²¡í„°ëŠ” ë°ì´í„°ì˜ ì£¼ì„±ë¶„(principal component)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\nì°¨ì› ì¶•ì†Œ: ê³ ìœ ê°’ì´ í° ìˆœì„œëŒ€ë¡œ ê³ ìœ ë²¡í„°ë¥¼ ì„ íƒí•˜ì—¬ ì°¨ì›ì„ ì¶•ì†Œí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„°ì˜ ì£¼ìš”í•œ íŒ¨í„´ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì‹œê°í™”: ì°¨ì› ì¶•ì†Œëœ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•œ ë°ì´í„°ë¥¼ ì‚°ì ë„ë¡œ ë‚˜íƒ€ë‚´ì–´ ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ë°©ë²•ì„ í†µí•´ PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ íƒìƒ‰í•˜ê³  ì°¨ì›ì„ ì¶•ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\ní† í°ìˆ˜\n\nì½”ë“œanswer_10$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"í† í°êµ¬ë¶„\", value = \"í† í°ìˆ˜\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\ní† í°êµ¬ë¶„\ní† í°ìˆ˜\n\n\n\ncompletion_tokens\n505\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n627"
  },
  {
    "objectID": "autoGPT_ds.html",
    "href": "autoGPT_ds.html",
    "title": "chatGPT",
    "section": "",
    "text": "Hmisc íŒ¨í‚¤ì§€ë¥¼ í†µí•´ ê³¼ê±° 20ë…„ì „ ë°ì´í„° ë¶„ì„ë°©ë²•ì„ ìŒë¯¸í•©ë‹ˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n\npenguins &lt;- palmerpenguins::penguins %&gt;%\n  # ì˜ì–´ ë³€ìˆ˜ëª… í•œê¸€ ë³€í™˜\n  set_names(c(\"ì¢…ëª…ì¹­\", \"ì„¬ì´ë¦„\", \"ë¶€ë¦¬_ê¸¸ì´\", \"ë¶€ë¦¬_ê¹Šì´\", \"ë¬¼ê°ˆí€´_ê¸¸ì´\",\n              \"ì²´ì¤‘\", \"ì„±ë³„\", \"ì—°ë„\")) %&gt;%\n  # ê²°ì¸¡ê°’ ì œê±°\n  # drop_na() %&gt;%\n  # ì˜ì–´ ê°’ í•œê¸€ ê°’ìœ¼ë¡œ ë³€í™˜\n  mutate(ì„±ë³„ = ifelse(ì„±ë³„ == \"male\", \"ìˆ˜ì»·\", \"ì•”ì»·\"),\n         ì„¬ì´ë¦„ = case_when( str_detect(ì„¬ì´ë¦„, \"Biscoe\") ~ \"ë¹„ìŠ¤ì½”\",\n                          str_detect(ì„¬ì´ë¦„, \"Dream\") ~ \"ë“œë¦¼\",\n                          str_detect(ì„¬ì´ë¦„, \"Torgersen\") ~ \"í† ë¥´ê±°ì„¼\"),\n         ì¢…ëª…ì¹­ = case_when( str_detect(ì¢…ëª…ì¹­, \"Adelie\") ~ \"ì•„ë¸ë¦¬\",\n                          str_detect(ì¢…ëª…ì¹­, \"Chinstrap\") ~ \"í„±ëˆ\",\n                          str_detect(ì¢…ëª…ì¹­, \"Gentoo\") ~ \"ì  íˆ¬\")\n  ) %&gt;%\n  # ìë£Œí˜• ë³€í™˜\n  mutate(ì„±ë³„   = factor(ì„±ë³„, levels = c(\"ìˆ˜ì»·\", \"ì•”ì»·\")),\n         ì„¬ì´ë¦„ = factor(ì„¬ì´ë¦„, levels = c(\"ë¹„ìŠ¤ì½”\", \"ë“œë¦¼\", \"í† ë¥´ê±°ì„¼\")),\n         ì¢…ëª…ì¹­ = factor(ì¢…ëª…ì¹­, levels = c(\"ì•„ë¸ë¦¬\", \"í„±ëˆ\", \"ì  íˆ¬\")),\n         ì—°ë„   = ordered(ì—°ë„, levels = c(2007, 2008, 2009)))\n\n\n\nHmisc::describe(penguins)\n\npenguins \n\n 8  Variables      344  Observations\n--------------------------------------------------------------------------------\nì¢…ëª…ì¹­ \n       n  missing distinct \n     344        0        3 \n                                     \nValue        ì•„ë¸ë¦¬     í„±ëˆ     ì  íˆ¬\nFrequency    152       68      124   \nProportion 0.442    0.198    0.360   \n--------------------------------------------------------------------------------\nì„¬ì´ë¦„ \n       n  missing distinct \n     344        0        3 \n                                     \nValue        ë¹„ìŠ¤ì½”     ë“œë¦¼ í† ë¥´ê±°ì„¼\nFrequency    168      124       52   \nProportion 0.488    0.360    0.151   \n--------------------------------------------------------------------------------\në¶€ë¦¬_ê¸¸ì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2      164        1    43.92    6.274    35.70    36.60 \n     .25      .50      .75      .90      .95 \n   39.23    44.45    48.50    50.80    51.99 \n\nlowest : 32.1 33.1 33.5 34.0 34.1, highest: 55.1 55.8 55.9 58.0 59.6\n--------------------------------------------------------------------------------\në¶€ë¦¬_ê¹Šì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       80        1    17.15    2.267     13.9     14.3 \n     .25      .50      .75      .90      .95 \n    15.6     17.3     18.7     19.5     20.0 \n\nlowest : 13.1 13.2 13.3 13.4 13.5, highest: 20.7 20.8 21.1 21.2 21.5\n--------------------------------------------------------------------------------\në¬¼ê°ˆí€´_ê¸¸ì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       55    0.999    200.9    16.03    181.0    185.0 \n     .25      .50      .75      .90      .95 \n   190.0    197.0    213.0    220.9    225.0 \n\nlowest : 172 174 176 178 179, highest: 226 228 229 230 231\n--------------------------------------------------------------------------------\nì²´ì¤‘ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       94        1     4202    911.8     3150     3300 \n     .25      .50      .75      .90      .95 \n    3550     4050     4750     5400     5650 \n\nlowest : 2700 2850 2900 2925 2975, highest: 5850 5950 6000 6050 6300\n--------------------------------------------------------------------------------\nì„±ë³„ \n       n  missing distinct \n     333       11        2 \n                          \nValue         ìˆ˜ì»·    ì•”ì»·\nFrequency    168     165  \nProportion 0.505   0.495  \n--------------------------------------------------------------------------------\nì—°ë„ \n       n  missing distinct \n     344        0        3 \n                            \nValue       2007  2008  2009\nFrequency    110   114   120\nProportion 0.320 0.331 0.349\n--------------------------------------------------------------------------------\n\n\n\nskimr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\n\nì½”ë“œpenguins %&gt;% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nì¢…ëª…ì¹­\n0\n1.00\nFALSE\n3\nì•„ë¸ë¦¬: 152, ì  íˆ¬: 124, í„±ëˆ: 68\n\n\nì„¬ì´ë¦„\n0\n1.00\nFALSE\n3\në¹„ìŠ¤ì½”: 168, ë“œë¦¼: 124, í† ë¥´ê±°: 52\n\n\nì„±ë³„\n11\n0.97\nFALSE\n2\nìˆ˜ì»·: 168, ì•”ì»·: 165\n\n\nì—°ë„\n0\n1.00\nTRUE\n3\n200: 120, 200: 114, 200: 110\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\në¶€ë¦¬_ê¸¸ì´\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\nâ–ƒâ–‡â–‡â–†â–\n\n\në¶€ë¦¬_ê¹Šì´\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\nâ–…â–…â–‡â–‡â–‚\n\n\në¬¼ê°ˆí€´_ê¸¸ì´\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\nâ–‚â–‡â–ƒâ–…â–‚\n\n\nì²´ì¤‘\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\nâ–ƒâ–‡â–†â–ƒâ–‚\n\n\n\n\n\n\ndataxray íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ì— ëŒ€í•œ ì´í•´ë¥¼ ë”ìš± ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\n\nì½”ë“œlibrary(dataxray)\n\npenguins %&gt;% \n   make_xray() %&gt;% \n   view_xray()\n\n\n\n\nExpand/collapse all\n\n\n\n\n\n\n\n\n\n\n\ndlookr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\n\nì½”ë“œlibrary(kableExtra)\npenguins %&gt;% \n  dlookr::describe() %&gt;% \n  kable(caption = \"ìš”ì•½í†µê³„ëŸ‰\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)  \n\n\n\nìš”ì•½í†µê³„ëŸ‰\n\ndescribed_variables\nn\nna\nmean\nsd\nse_mean\nIQR\nskewness\nkurtosis\np00\np01\np05\np10\np20\np25\np30\np40\np50\np60\np70\np75\np80\np90\np95\np99\np100\n\n\n\në¶€ë¦¬_ê¸¸ì´\n342\n2\n43.92193\n5.459584\n0.2952205\n9.275\n0.0531181\n-0.8760270\n32.1\n34.041\n35.7\n36.6\n38.34\n39.225\n40.20\n42.0\n44.45\n46.0\n47.37\n48.5\n49.38\n50.8\n51.995\n55.513\n59.6\n\n\në¶€ë¦¬_ê¹Šì´\n342\n2\n17.15117\n1.974793\n0.1067846\n3.100\n-0.1434646\n-0.9068661\n13.1\n13.441\n13.9\n14.3\n15.00\n15.600\n15.93\n16.8\n17.30\n17.9\n18.50\n18.7\n18.90\n19.5\n20.000\n21.100\n21.5\n\n\në¬¼ê°ˆí€´_ê¸¸ì´\n342\n2\n200.91520\n14.061714\n0.7603704\n23.000\n0.3456818\n-0.9842729\n172.0\n178.000\n181.0\n185.0\n188.00\n190.000\n191.00\n194.0\n197.00\n203.0\n210.00\n213.0\n215.00\n220.9\n225.000\n230.000\n231.0\n\n\nì²´ì¤‘\n342\n2\n4201.75439\n801.954536\n43.3647348\n1200.000\n0.4703293\n-0.7192219\n2700.0\n2900.000\n3150.0\n3300.0\n3475.00\n3550.000\n3650.00\n3800.0\n4050.00\n4300.0\n4650.00\n4750.0\n4950.00\n5400.0\n5650.000\n5979.500\n6300.0\n\n\n\n\n\n\n\n\n\nDataExplorer íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\nDataExplorer::create_report(penguins)\n\n\nêµ¬ì¡°\nDF ìš”ì•½\nDF ìš”ì•½ ì‹œê°í™”\nê²°ì¸¡ê°’\në¶„í¬(ë²”ì£¼í˜•)\në¶„í¬(ì—°ì†í˜•)\nìƒê´€ê´€ê³„\nPCA\n\n\n\n\nì½”ë“œDataExplorer::plot_str(penguins)\n\n\n\n\n\nì½”ë“œDataExplorer::introduce(penguins)\n\n# A tibble: 1 Ã— 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1   344       8                4                  4                   0\n# â„¹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;\n\n\n\n\n\nì½”ë“œDataExplorer::plot_intro(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_missing(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_bar(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_histogram(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% select_if(is.numeric) %&gt;% \n  # drop_na() %&gt;% \n  DataExplorer::plot_correlation(cor_args = list(\"use\" = \"pairwise.complete.obs\"))\n\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins_pca &lt;- penguins %&gt;% select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% prcomp(scale = TRUE)\n\nsummary(penguins_pca)$importance %&gt;% as.data.frame() %&gt;% \n  kable(caption = \"PCA ìš”ì•½\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\nPCA ìš”ì•½\n\n\nPC1\nPC2\nPC3\nPC4\n\n\n\nStandard deviation\n1.659444\n0.8789293\n0.6043475\n0.3293816\n\n\nProportion of Variance\n0.688440\n0.1931300\n0.0913100\n0.0271200\n\n\nCumulative Proportion\n0.688440\n0.8815700\n0.9728800\n1.0000000"
  },
  {
    "objectID": "autoGPT_ds.html#í­ê·„-ë°ì´í„°-ì¶œí˜„",
    "href": "autoGPT_ds.html#í­ê·„-ë°ì´í„°-ì¶œí˜„",
    "title": "chatGPT",
    "section": "",
    "text": "ë¯¸êµ­ì—ì„œ â€œGeorge Floydâ€ê°€ ê²½ì°°ì— ì˜í•´ ì‚´í•´ë˜ë©´ì„œ ì´‰ë°œëœ â€œBlack Lives Matterâ€ ìš´ë™ì€ ì•„í”„ë¦¬ì¹´ê³„ ë¯¸êµ­ì¸ì„ í–¥í•œ í­ë ¥ê³¼ ì œë„ì  ì¸ì¢…ì£¼ì˜ì— ë°˜ëŒ€í•˜ëŠ” ì‚¬íšŒìš´ë™ì´ë‹¤. í•œêµ­ì—ì„œë„ ì†Œìˆ˜ ì •ë‹¹ì¸ ì •ì˜ë‹¹ì—ì„œ ì—¬ë‹¹ ì˜ì› 176ëª… ì¤‘ ëˆ„ê°€?â€¦ì°¨ë³„ê¸ˆì§€ë²• ë°œì˜í•  â€™ì˜ì¸â€™ì„ êµ¬í•©ë‹ˆë‹¤ë¡œ ê¸°ì‚¬ë¡œ ë‚¼ ì •ë„ë¡œ ì ê·¹ì ìœ¼ë¡œ ë‚˜ì„œê³  ìˆë‹¤.\në°ì´í„° ê³¼í•™ì—ì„œ ìµœê·¼ R.A. Fisherì˜ ê³¼ê±° ì €ìˆ í•œ â€œThe genetical theory of natural selectionâ€ (Fisher, 1958) ìš°ìƒí•™(Eugenics) ëŒ€í•œ ê´€ì ì´ ë…¼ë€ì´ ë˜ë©´ì„œ R ë°ì´í„° ê³¼í•™ì˜ ì²« ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶“ê½ƒ iris ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë°ì´í„°, ì¦‰ í­ê·„ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ëŠ” ì›€ì§ì„ì´ í™œë°œíˆ ì „ê°œë˜ê³  ìˆë‹¤. palmerpenguins (KB ê¸°íƒ€, 2014) ë°ì´í„°ì…‹ì´ ëŒ€ì•ˆìœ¼ë¡œ ë§ì€ í˜¸ì‘ì„ ì–»ê³  ìˆë‹¤. Levy (2019)"
  },
  {
    "objectID": "autoGPT_ds.html#penguins-study",
    "href": "autoGPT_ds.html#penguins-study",
    "title": "chatGPT",
    "section": "",
    "text": "íŒ”ë¨¸(Palmer) í­ê·„ì€ 3ì¢…ì´ ìˆìœ¼ë©° ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ ë‚˜ë¬´ìœ„í‚¤ë¥¼ ì°¸ì¡°í•œë‹¤. 1\n\n\nì  íˆ¬ í­ê·„(Gentoo Penguin): ë¨¸ë¦¬ì— ëª¨ìì²˜ëŸ¼ ë‘˜ëŸ¬ì ¸ ìˆëŠ” í•˜ì–€ í„¸ ë•Œë¬¸ì— ì•Œì•„ë³´ê¸°ê°€ ì‰½ë‹¤. ì•”ì»·ì´ íšŒìƒ‰ì´ ë’¤ì—, í°ìƒ‰ì´ ì•ì— ìˆë‹¤. í­ê·„ë“¤ ì¤‘ì— ê°€ì¥ ë¹ ë¥¸ ì‹œì† 36kmì˜ ìˆ˜ì˜ ì‹¤ë ¥ì„ ìë‘í•˜ë©°, ì§ì§“ê¸° í•  ì¤€ë¹„ê°€ ëœ í­ê·„ì€ 75-90cmê¹Œì§€ë„ ìë€ë‹¤.\n\nì•„ë¸ë¦¬ í­ê·„(Adelie Penguin): í”„ë‘ìŠ¤ íƒí—˜ê°€ì¸ ë’¤ëª½ ë’¤ë¥´ë¹Œ(Dumont Dâ€™Urville) ë¶€ì¸ì˜ ì´ë¦„ì„ ë”°ì„œ â€™ì•„ë¸ë¦¬â€™ë¼ ë¶ˆë¦¬ê²Œ ë˜ì—ˆë‹¤. ê°ì§„ ë¨¸ë¦¬ì™€ ì‘ì€ ë¶€ë¦¬ ë•Œë¬¸ì— ì•Œì•„ë³´ê¸° ì‰½ê³ , ë‹¤ë¥¸ í­ê·„ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì•”ìˆ˜ê°€ ë¹„ìŠ·í•˜ê²Œ ìƒê²¼ì§€ë§Œ ì•”ì»·ì´ ì¡°ê¸ˆ ë” ì‘ë‹¤.\n\ní„±ëˆ í­ê·„(Chinstrap Penguin): ì–¸ëœ» ë³´ë©´ ì•„ë¸ë¦¬ í­ê·„ê³¼ ë§¤ìš° ë¹„ìŠ·í•˜ì§€ë§Œ, ëª¸ì§‘ì´ ì¡°ê¸ˆ ë” ì‘ê³ , ëª©ì—ì„œ ë¨¸ë¦¬ ìª½ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²€ì€ í„¸ì´ ëˆˆì— ëˆë‹¤. ì–´ë¦° ê³ ì‚ í­ê·„ë“¤ì€ íšŒê°ˆìƒ‰ ë¹›ì„ ë„ëŠ” í„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ëª© ì•„ë˜ ë¶€ë¶„ì€ ë” í•˜ì–—ë‹¤. ë¬´ë¦¬ë¥¼ ì§€ì–´ ì‚´ì•„ê°€ë©° ì¼ë¶€ì¼ì²˜ì œë¥¼ ì§€í‚¤ê¸° ë•Œë¬¸ì— ì§ì§“ê¸° ì´í›„ì—ë„ ë¶€ë¶€ë¡œì¨ ì˜¤ë«ë™ì•ˆ í•¨ê»˜ ì‚´ì•„ê°„ë‹¤.\n\n\nì½”ë“œlibrary(webshot2)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#meet-the-palmer-penguins &gt; p &gt; img\", \"images/penguin-species.png\")\n\n\n\n\níŒ”ë¨¸ í­ê·„ 3ì¢… ì„¸íŠ¸\n\n\në‹¤ìŒìœ¼ë¡œ iris ë°ì´í„°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í­ê·„ 3ì¢…ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ë¡œ ì¡°ë¥˜ì˜ ë¶€ë¦¬ì— ìˆëŠ” ì¤‘ì•™ ì„¸ë¡œì„ ì˜ ìœµê¸°ë¥¼ ì§€ì¹­í•˜ëŠ” ëŠ¥ì„ (culmen) ê¸¸ì´(culmen length)ì™€ ê¹Šì´(culmen depth)ë¥¼ ì´í•´í•˜ë©´ ëœë‹¤.\n\nì½”ë“œlibrary(webshot)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#what-are-culmen-length--depth &gt; p:nth-child(4) &gt; img\", \"fig/penguin-species-variable.png\")\n\n\n\n\níŒ”ë¨¸ í­ê·„ ëŠ¥ì„  ë³€ìˆ˜"
  },
  {
    "objectID": "autoGPT_ds.html#penguin-home",
    "href": "autoGPT_ds.html#penguin-home",
    "title": "chatGPT",
    "section": "",
    "text": "leaflet íŒ©í‚¤ì§€ë¡œ í­ê·„ ì„œì‹ì§€ë¥¼ ë‚¨ê·¹ì—ì„œ íŠ¹ì •í•œë‹¤. geocodingì„ í•´ì•¼ í•˜ëŠ”ë° êµ¬ê¸€ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ êµ¬ê¸€ë§í•˜ë©´ https://latitude.to/ì—ì„œ ì§ì ‘ ìœ„ê²½ë„ë¥¼ ë°˜í™˜í•˜ì—¬ ì¤€ë‹¤. ì´ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ í•˜ì—¬ í­ê·„ ì„œì‹ì§€ë¥¼ ì‹œê°í™”í•œë‹¤.\n\n\n\n\níŒŒë¨¸ ì—°êµ¬ì†Œì™€ í­ê·„ ì„œì‹ì§€\n\n\n\n\ní­ê·„ 3ì¢…\n\n\n\n\n\n\nì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ì´ í•¨ê»˜í•œ ì‚¬ì§„\n\n\n\n\ní† ë¥´ê±°ì„¼ ì„¬ì—ì„œ ìƒˆë¼ë¥¼ í‚¤ìš°ëŠ” ì•„ë¸ë¦¬ í­ê·„\n\n\n\n\në¹„ìŠ¤ì½” ì§€ì  ì  íˆ¬ í­ê·„ ì„œì‹ì§€\n\n\n\n\ní­ê·„ê³¼ í•¨ê»˜ í˜„ì¥ì—ì„œ ì¼í•˜ëŠ” í¬ë¦¬ìŠ¤í‹´ ê³ ë¨¼ ë°•ì‚¬\n\n\n\n\n\níŒŒë¨¸ í­ê·„ ë°ì´í„°ì…‹\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n\n# A tibble: 3 Ã— 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\nì½”ë“œisland_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"ëª…ì¹­:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   )))"
  },
  {
    "objectID": "autoGPT_ds.html#penguin-EDA-skimr",
    "href": "autoGPT_ds.html#penguin-EDA-skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr íŒ©í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ penguins ë°ì´í„°í”„ë ˆì„ ìë£Œêµ¬ì¡°ë¥¼ ì¼ë³„í•œë‹¤. ì´ë¥¼ í†µí•´ì„œ 344ê°œ í­ê·„ ê´€ì¸¡ê°’ì´ ìˆìœ¼ë©°, 7ê°œ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ë²”ì£¼í˜• ë³€ìˆ˜ê°€ 3ê°œ, ìˆ«ìí˜• ë³€ìˆ˜ê°€ 4ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ê·¸ì™¸ ë” ìì„¸í•œ ì‚¬í•­ì€ ë²”ì£¼í˜•, ìˆ«ìí˜• ë³€ìˆ˜ì— ëŒ€í•œ ìš”ì•½ í†µê³„ëŸ‰ì„ ì°¸ì¡°í•œë‹¤.\n\nì½”ë“œskimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\nâ–ƒâ–‡â–‡â–†â–\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\nâ–…â–…â–‡â–‡â–‚\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\nâ–‚â–‡â–ƒâ–…â–‚\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\nâ–ƒâ–‡â–†â–ƒâ–‚\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\nâ–‡â–â–‡â–â–‡\n\n\n\n\n\në°ì´í„°ê°€ í¬ì§€ ì•Šì•„ DT íŒ©í‚¤ì§€ë¥¼ í†µí•´ ë°ì´í„° ì „ë°˜ì ì¸ ë‚´ìš©ì„ ì‚´í´ë³¼ ìˆ˜ ìˆë‹¤.\n\nì½”ë“œpenguins %&gt;% \n  reactable::reactable()"
  },
  {
    "objectID": "autoGPT_ds.html#footnotes",
    "href": "autoGPT_ds.html#footnotes",
    "title": "chatGPT",
    "section": "ê°ì£¼",
    "text": "ê°ì£¼\n\nì‹ ë°œëˆ ì—¬í–‰ì‚¬, ê´€ê´‘ì•ˆë‚´ìë£Œâ†©ï¸"
  },
  {
    "objectID": "autoGPT_ds.html#ë°ì´í„°-ì„¤ì¹˜",
    "href": "autoGPT_ds.html#ë°ì´í„°-ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "",
    "text": "remotes íŒ©í‚¤ì§€ install_github() í•¨ìˆ˜ë¡œ í­ê·„ ë°ì´í„°ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œ# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\n\ntidyverse íŒ©í‚¤ì§€ glimpse() í•¨ìˆ˜ë¡œ í­ê·„ ë°ì´í„°ë¥¼ ì¼ë³„í•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, â€¦\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, â€¦\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186â€¦\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, â€¦\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, maleâ€¦\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007â€¦"
  },
  {
    "objectID": "autoGPT_ds.html#penguin-EDA",
    "href": "autoGPT_ds.html#penguin-EDA",
    "title": "chatGPT",
    "section": "",
    "text": "palmerpenguins ë°ì´í„°ì…‹ ì†Œê°œì— í¬í•¨ë˜ì–´ ìˆëŠ” ë¯¸êµ­ íŒ”ë¨¸ ì—°êµ¬ì†Œ (palmer station) í­ê·„ ë¬¼ê°ˆí€´(flipper) ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰(body mass) ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ì.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"í­ê·„ í¬ê¸°\",\n       subtitle = \"ë‚¨ê·¹ í­ê·„ 3ì¢… ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰ ê´€ê³„\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ì²´ì§ˆëŸ‰ (g)\",\n       color = \"í­ê·„ 3ì¢…\",\n       shape = \"í­ê·„ 3ì¢…\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper"
  },
  {
    "objectID": "palmer_penguins.html",
    "href": "palmer_penguins.html",
    "title": "chatGPT",
    "section": "",
    "text": "ë¯¸êµ­ì—ì„œ â€œGeorge Floydâ€ê°€ ê²½ì°°ì— ì˜í•´ ì‚´í•´ë˜ë©´ì„œ ì´‰ë°œëœ â€œBlack Lives Matterâ€ ìš´ë™ì€ ì•„í”„ë¦¬ì¹´ê³„ ë¯¸êµ­ì¸ì„ í–¥í•œ í­ë ¥ê³¼ ì œë„ì  ì¸ì¢…ì£¼ì˜ì— ë°˜ëŒ€í•˜ëŠ” ì‚¬íšŒìš´ë™ì´ë‹¤. í•œêµ­ì—ì„œë„ ì†Œìˆ˜ ì •ë‹¹ì¸ ì •ì˜ë‹¹ì—ì„œ ì—¬ë‹¹ ì˜ì› 176ëª… ì¤‘ ëˆ„ê°€?â€¦ì°¨ë³„ê¸ˆì§€ë²• ë°œì˜í•  â€™ì˜ì¸â€™ì„ êµ¬í•©ë‹ˆë‹¤ë¡œ ê¸°ì‚¬ë¡œ ë‚¼ ì •ë„ë¡œ ì ê·¹ì ìœ¼ë¡œ ë‚˜ì„œê³  ìˆë‹¤.\në°ì´í„° ê³¼í•™ì—ì„œ ìµœê·¼ R.A. Fisherì˜ ê³¼ê±° ì €ìˆ í•œ â€œThe genetical theory of natural selectionâ€ (Fisher, 1958) ìš°ìƒí•™(Eugenics) ëŒ€í•œ ê´€ì ì´ ë…¼ë€ì´ ë˜ë©´ì„œ R ë°ì´í„° ê³¼í•™ì˜ ì²« ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶“ê½ƒ iris ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë°ì´í„°, ì¦‰ í­ê·„ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ëŠ” ì›€ì§ì„ì´ í™œë°œíˆ ì „ê°œë˜ê³  ìˆë‹¤. palmerpenguins (KB ê¸°íƒ€, 2014) ë°ì´í„°ì…‹ì´ ëŒ€ì•ˆìœ¼ë¡œ ë§ì€ í˜¸ì‘ì„ ì–»ê³  ìˆë‹¤. Levy (2019)\n\níŒ”ë¨¸(Palmer) í­ê·„ì€ 3ì¢…ì´ ìˆìœ¼ë©° ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ ë‚˜ë¬´ìœ„í‚¤ë¥¼ ì°¸ì¡°í•œë‹¤. 1\n\n\nì  íˆ¬ í­ê·„(Gentoo Penguin): ë¨¸ë¦¬ì— ëª¨ìì²˜ëŸ¼ ë‘˜ëŸ¬ì ¸ ìˆëŠ” í•˜ì–€ í„¸ ë•Œë¬¸ì— ì•Œì•„ë³´ê¸°ê°€ ì‰½ë‹¤. ì•”ì»·ì´ íšŒìƒ‰ì´ ë’¤ì—, í°ìƒ‰ì´ ì•ì— ìˆë‹¤. í­ê·„ë“¤ ì¤‘ì— ê°€ì¥ ë¹ ë¥¸ ì‹œì† 36kmì˜ ìˆ˜ì˜ ì‹¤ë ¥ì„ ìë‘í•˜ë©°, ì§ì§“ê¸° í•  ì¤€ë¹„ê°€ ëœ í­ê·„ì€ 75-90cmê¹Œì§€ë„ ìë€ë‹¤.\n\nì•„ë¸ë¦¬ í­ê·„(Adelie Penguin): í”„ë‘ìŠ¤ íƒí—˜ê°€ì¸ ë’¤ëª½ ë’¤ë¥´ë¹Œ(Dumont Dâ€™Urville) ë¶€ì¸ì˜ ì´ë¦„ì„ ë”°ì„œ â€™ì•„ë¸ë¦¬â€™ë¼ ë¶ˆë¦¬ê²Œ ë˜ì—ˆë‹¤. ê°ì§„ ë¨¸ë¦¬ì™€ ì‘ì€ ë¶€ë¦¬ ë•Œë¬¸ì— ì•Œì•„ë³´ê¸° ì‰½ê³ , ë‹¤ë¥¸ í­ê·„ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì•”ìˆ˜ê°€ ë¹„ìŠ·í•˜ê²Œ ìƒê²¼ì§€ë§Œ ì•”ì»·ì´ ì¡°ê¸ˆ ë” ì‘ë‹¤.\n\ní„±ëˆ í­ê·„(Chinstrap Penguin): ì–¸ëœ» ë³´ë©´ ì•„ë¸ë¦¬ í­ê·„ê³¼ ë§¤ìš° ë¹„ìŠ·í•˜ì§€ë§Œ, ëª¸ì§‘ì´ ì¡°ê¸ˆ ë” ì‘ê³ , ëª©ì—ì„œ ë¨¸ë¦¬ ìª½ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²€ì€ í„¸ì´ ëˆˆì— ëˆë‹¤. ì–´ë¦° ê³ ì‚ í­ê·„ë“¤ì€ íšŒê°ˆìƒ‰ ë¹›ì„ ë„ëŠ” í„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ëª© ì•„ë˜ ë¶€ë¶„ì€ ë” í•˜ì–—ë‹¤. ë¬´ë¦¬ë¥¼ ì§€ì–´ ì‚´ì•„ê°€ë©° ì¼ë¶€ì¼ì²˜ì œë¥¼ ì§€í‚¤ê¸° ë•Œë¬¸ì— ì§ì§“ê¸° ì´í›„ì—ë„ ë¶€ë¶€ë¡œì¨ ì˜¤ë«ë™ì•ˆ í•¨ê»˜ ì‚´ì•„ê°„ë‹¤.\n\n\nì½”ë“œlibrary(webshot2)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#meet-the-palmer-penguins &gt; p &gt; img\", \"images/penguin-species.png\")\n\n\n\n\níŒ”ë¨¸ í­ê·„ 3ì¢… ì„¸íŠ¸\n\n\në‹¤ìŒìœ¼ë¡œ iris ë°ì´í„°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í­ê·„ 3ì¢…ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ë¡œ ì¡°ë¥˜ì˜ ë¶€ë¦¬ì— ìˆëŠ” ì¤‘ì•™ ì„¸ë¡œì„ ì˜ ìœµê¸°ë¥¼ ì§€ì¹­í•˜ëŠ” ëŠ¥ì„ (culmen) ê¸¸ì´(culmen length)ì™€ ê¹Šì´(culmen depth)ë¥¼ ì´í•´í•˜ë©´ ëœë‹¤.\n\nì½”ë“œlibrary(webshot)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#what-are-culmen-length--depth &gt; p:nth-child(4) &gt; img\", \"fig/penguin-species-variable.png\")\n\n\n\n\níŒ”ë¨¸ í­ê·„ ëŠ¥ì„  ë³€ìˆ˜\n\n\n\nleaflet íŒ©í‚¤ì§€ë¡œ í­ê·„ ì„œì‹ì§€ë¥¼ ë‚¨ê·¹ì—ì„œ íŠ¹ì •í•œë‹¤. geocodingì„ í•´ì•¼ í•˜ëŠ”ë° êµ¬ê¸€ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ êµ¬ê¸€ë§í•˜ë©´ https://latitude.to/ì—ì„œ ì§ì ‘ ìœ„ê²½ë„ë¥¼ ë°˜í™˜í•˜ì—¬ ì¤€ë‹¤. ì´ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ í•˜ì—¬ í­ê·„ ì„œì‹ì§€ë¥¼ ì‹œê°í™”í•œë‹¤.\n\n\n\n\níŒŒë¨¸ ì—°êµ¬ì†Œì™€ í­ê·„ ì„œì‹ì§€\n\n\n\n\ní­ê·„ 3ì¢…\n\n\n\n\n\n\nì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ì´ í•¨ê»˜í•œ ì‚¬ì§„\n\n\n\n\ní† ë¥´ê±°ì„¼ ì„¬ì—ì„œ ìƒˆë¼ë¥¼ í‚¤ìš°ëŠ” ì•„ë¸ë¦¬ í­ê·„\n\n\n\n\në¹„ìŠ¤ì½” ì§€ì  ì  íˆ¬ í­ê·„ ì„œì‹ì§€\n\n\n\n\ní­ê·„ê³¼ í•¨ê»˜ í˜„ì¥ì—ì„œ ì¼í•˜ëŠ” í¬ë¦¬ìŠ¤í‹´ ê³ ë¨¼ ë°•ì‚¬\n\n\n\n\n\níŒŒë¨¸ í­ê·„ ë°ì´í„°ì…‹\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n\n# A tibble: 3 Ã— 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\nì½”ë“œisland_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"ëª…ì¹­:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   ))) \n\n\n\n\n\n\nremotes íŒ©í‚¤ì§€ install_github() í•¨ìˆ˜ë¡œ í­ê·„ ë°ì´í„°ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œ# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\n\ntidyverse íŒ©í‚¤ì§€ glimpse() í•¨ìˆ˜ë¡œ í­ê·„ ë°ì´í„°ë¥¼ ì¼ë³„í•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, â€¦\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, â€¦\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186â€¦\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, â€¦\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, maleâ€¦\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007â€¦\n\n\n\nskimr íŒ©í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ penguins ë°ì´í„°í”„ë ˆì„ ìë£Œêµ¬ì¡°ë¥¼ ì¼ë³„í•œë‹¤. ì´ë¥¼ í†µí•´ì„œ 344ê°œ í­ê·„ ê´€ì¸¡ê°’ì´ ìˆìœ¼ë©°, 7ê°œ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ë²”ì£¼í˜• ë³€ìˆ˜ê°€ 3ê°œ, ìˆ«ìí˜• ë³€ìˆ˜ê°€ 4ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ê·¸ì™¸ ë” ìì„¸í•œ ì‚¬í•­ì€ ë²”ì£¼í˜•, ìˆ«ìí˜• ë³€ìˆ˜ì— ëŒ€í•œ ìš”ì•½ í†µê³„ëŸ‰ì„ ì°¸ì¡°í•œë‹¤.\n\nì½”ë“œskimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\nâ–ƒâ–‡â–‡â–†â–\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\nâ–…â–…â–‡â–‡â–‚\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\nâ–‚â–‡â–ƒâ–…â–‚\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\nâ–ƒâ–‡â–†â–ƒâ–‚\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\nâ–‡â–â–‡â–â–‡\n\n\n\n\n\në°ì´í„°ê°€ í¬ì§€ ì•Šì•„ DT íŒ©í‚¤ì§€ë¥¼ í†µí•´ ë°ì´í„° ì „ë°˜ì ì¸ ë‚´ìš©ì„ ì‚´í´ë³¼ ìˆ˜ ìˆë‹¤.\n\nì½”ë“œpenguins %&gt;% \n  reactable::reactable()\n\n\n\n\n\n\n\npalmerpenguins ë°ì´í„°ì…‹ ì†Œê°œì— í¬í•¨ë˜ì–´ ìˆëŠ” ë¯¸êµ­ íŒ”ë¨¸ ì—°êµ¬ì†Œ (palmer station) í­ê·„ ë¬¼ê°ˆí€´(flipper) ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰(body mass) ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ì.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"í­ê·„ í¬ê¸°\",\n       subtitle = \"ë‚¨ê·¹ í­ê·„ 3ì¢… ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰ ê´€ê³„\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ì²´ì§ˆëŸ‰ (g)\",\n       color = \"í­ê·„ 3ì¢…\",\n       shape = \"í­ê·„ 3ì¢…\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper"
  },
  {
    "objectID": "palmer_penguins.html#í­ê·„-ë°ì´í„°-ì¶œí˜„",
    "href": "palmer_penguins.html#í­ê·„-ë°ì´í„°-ì¶œí˜„",
    "title": "chatGPT",
    "section": "",
    "text": "ë¯¸êµ­ì—ì„œ â€œGeorge Floydâ€ê°€ ê²½ì°°ì— ì˜í•´ ì‚´í•´ë˜ë©´ì„œ ì´‰ë°œëœ â€œBlack Lives Matterâ€ ìš´ë™ì€ ì•„í”„ë¦¬ì¹´ê³„ ë¯¸êµ­ì¸ì„ í–¥í•œ í­ë ¥ê³¼ ì œë„ì  ì¸ì¢…ì£¼ì˜ì— ë°˜ëŒ€í•˜ëŠ” ì‚¬íšŒìš´ë™ì´ë‹¤. í•œêµ­ì—ì„œë„ ì†Œìˆ˜ ì •ë‹¹ì¸ ì •ì˜ë‹¹ì—ì„œ ì—¬ë‹¹ ì˜ì› 176ëª… ì¤‘ ëˆ„ê°€?â€¦ì°¨ë³„ê¸ˆì§€ë²• ë°œì˜í•  â€™ì˜ì¸â€™ì„ êµ¬í•©ë‹ˆë‹¤ë¡œ ê¸°ì‚¬ë¡œ ë‚¼ ì •ë„ë¡œ ì ê·¹ì ìœ¼ë¡œ ë‚˜ì„œê³  ìˆë‹¤.\në°ì´í„° ê³¼í•™ì—ì„œ ìµœê·¼ R.A. Fisherì˜ ê³¼ê±° ì €ìˆ í•œ â€œThe genetical theory of natural selectionâ€ (Fisher, 1958) ìš°ìƒí•™(Eugenics) ëŒ€í•œ ê´€ì ì´ ë…¼ë€ì´ ë˜ë©´ì„œ R ë°ì´í„° ê³¼í•™ì˜ ì²« ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶“ê½ƒ iris ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë°ì´í„°, ì¦‰ í­ê·„ ë°ì´í„°ë¡œ ëŒ€ì²´í•˜ëŠ” ì›€ì§ì„ì´ í™œë°œíˆ ì „ê°œë˜ê³  ìˆë‹¤. palmerpenguins (KB ê¸°íƒ€, 2014) ë°ì´í„°ì…‹ì´ ëŒ€ì•ˆìœ¼ë¡œ ë§ì€ í˜¸ì‘ì„ ì–»ê³  ìˆë‹¤. Levy (2019)"
  },
  {
    "objectID": "palmer_penguins.html#penguins-study",
    "href": "palmer_penguins.html#penguins-study",
    "title": "chatGPT",
    "section": "",
    "text": "íŒ”ë¨¸(Palmer) í­ê·„ì€ 3ì¢…ì´ ìˆìœ¼ë©° ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ ë‚˜ë¬´ìœ„í‚¤ë¥¼ ì°¸ì¡°í•œë‹¤. 1\n\n\nì  íˆ¬ í­ê·„(Gentoo Penguin): ë¨¸ë¦¬ì— ëª¨ìì²˜ëŸ¼ ë‘˜ëŸ¬ì ¸ ìˆëŠ” í•˜ì–€ í„¸ ë•Œë¬¸ì— ì•Œì•„ë³´ê¸°ê°€ ì‰½ë‹¤. ì•”ì»·ì´ íšŒìƒ‰ì´ ë’¤ì—, í°ìƒ‰ì´ ì•ì— ìˆë‹¤. í­ê·„ë“¤ ì¤‘ì— ê°€ì¥ ë¹ ë¥¸ ì‹œì† 36kmì˜ ìˆ˜ì˜ ì‹¤ë ¥ì„ ìë‘í•˜ë©°, ì§ì§“ê¸° í•  ì¤€ë¹„ê°€ ëœ í­ê·„ì€ 75-90cmê¹Œì§€ë„ ìë€ë‹¤.\n\nì•„ë¸ë¦¬ í­ê·„(Adelie Penguin): í”„ë‘ìŠ¤ íƒí—˜ê°€ì¸ ë’¤ëª½ ë’¤ë¥´ë¹Œ(Dumont Dâ€™Urville) ë¶€ì¸ì˜ ì´ë¦„ì„ ë”°ì„œ â€™ì•„ë¸ë¦¬â€™ë¼ ë¶ˆë¦¬ê²Œ ë˜ì—ˆë‹¤. ê°ì§„ ë¨¸ë¦¬ì™€ ì‘ì€ ë¶€ë¦¬ ë•Œë¬¸ì— ì•Œì•„ë³´ê¸° ì‰½ê³ , ë‹¤ë¥¸ í­ê·„ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì•”ìˆ˜ê°€ ë¹„ìŠ·í•˜ê²Œ ìƒê²¼ì§€ë§Œ ì•”ì»·ì´ ì¡°ê¸ˆ ë” ì‘ë‹¤.\n\ní„±ëˆ í­ê·„(Chinstrap Penguin): ì–¸ëœ» ë³´ë©´ ì•„ë¸ë¦¬ í­ê·„ê³¼ ë§¤ìš° ë¹„ìŠ·í•˜ì§€ë§Œ, ëª¸ì§‘ì´ ì¡°ê¸ˆ ë” ì‘ê³ , ëª©ì—ì„œ ë¨¸ë¦¬ ìª½ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ê²€ì€ í„¸ì´ ëˆˆì— ëˆë‹¤. ì–´ë¦° ê³ ì‚ í­ê·„ë“¤ì€ íšŒê°ˆìƒ‰ ë¹›ì„ ë„ëŠ” í„¸ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ëª© ì•„ë˜ ë¶€ë¶„ì€ ë” í•˜ì–—ë‹¤. ë¬´ë¦¬ë¥¼ ì§€ì–´ ì‚´ì•„ê°€ë©° ì¼ë¶€ì¼ì²˜ì œë¥¼ ì§€í‚¤ê¸° ë•Œë¬¸ì— ì§ì§“ê¸° ì´í›„ì—ë„ ë¶€ë¶€ë¡œì¨ ì˜¤ë«ë™ì•ˆ í•¨ê»˜ ì‚´ì•„ê°„ë‹¤.\n\n\nì½”ë“œlibrary(webshot2)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#meet-the-palmer-penguins &gt; p &gt; img\", \"images/penguin-species.png\")\n\n\n\n\níŒ”ë¨¸ í­ê·„ 3ì¢… ì„¸íŠ¸\n\n\në‹¤ìŒìœ¼ë¡œ iris ë°ì´í„°ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í­ê·„ 3ì¢…ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ë¡œ ì¡°ë¥˜ì˜ ë¶€ë¦¬ì— ìˆëŠ” ì¤‘ì•™ ì„¸ë¡œì„ ì˜ ìœµê¸°ë¥¼ ì§€ì¹­í•˜ëŠ” ëŠ¥ì„ (culmen) ê¸¸ì´(culmen length)ì™€ ê¹Šì´(culmen depth)ë¥¼ ì´í•´í•˜ë©´ ëœë‹¤.\n\nì½”ë“œlibrary(webshot)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#what-are-culmen-length--depth &gt; p:nth-child(4) &gt; img\", \"fig/penguin-species-variable.png\")\n\n\n\n\níŒ”ë¨¸ í­ê·„ ëŠ¥ì„  ë³€ìˆ˜"
  },
  {
    "objectID": "palmer_penguins.html#penguin-home",
    "href": "palmer_penguins.html#penguin-home",
    "title": "chatGPT",
    "section": "",
    "text": "leaflet íŒ©í‚¤ì§€ë¡œ í­ê·„ ì„œì‹ì§€ë¥¼ ë‚¨ê·¹ì—ì„œ íŠ¹ì •í•œë‹¤. geocodingì„ í•´ì•¼ í•˜ëŠ”ë° êµ¬ê¸€ì—ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ êµ¬ê¸€ë§í•˜ë©´ https://latitude.to/ì—ì„œ ì§ì ‘ ìœ„ê²½ë„ë¥¼ ë°˜í™˜í•˜ì—¬ ì¤€ë‹¤. ì´ ì •ë³´ë¥¼ ê·¼ê±°ë¡œ í•˜ì—¬ í­ê·„ ì„œì‹ì§€ë¥¼ ì‹œê°í™”í•œë‹¤.\n\n\n\n\níŒŒë¨¸ ì—°êµ¬ì†Œì™€ í­ê·„ ì„œì‹ì§€\n\n\n\n\ní­ê·„ 3ì¢…\n\n\n\n\n\n\nì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ì´ í•¨ê»˜í•œ ì‚¬ì§„\n\n\n\n\ní† ë¥´ê±°ì„¼ ì„¬ì—ì„œ ìƒˆë¼ë¥¼ í‚¤ìš°ëŠ” ì•„ë¸ë¦¬ í­ê·„\n\n\n\n\në¹„ìŠ¤ì½” ì§€ì  ì  íˆ¬ í­ê·„ ì„œì‹ì§€\n\n\n\n\ní­ê·„ê³¼ í•¨ê»˜ í˜„ì¥ì—ì„œ ì¼í•˜ëŠ” í¬ë¦¬ìŠ¤í‹´ ê³ ë¨¼ ë°•ì‚¬\n\n\n\n\n\níŒŒë¨¸ í­ê·„ ë°ì´í„°ì…‹\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n\n# A tibble: 3 Ã— 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\nì½”ë“œisland_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"ëª…ì¹­:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   )))"
  },
  {
    "objectID": "palmer_penguins.html#ë°ì´í„°-ì„¤ì¹˜",
    "href": "palmer_penguins.html#ë°ì´í„°-ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "",
    "text": "remotes íŒ©í‚¤ì§€ install_github() í•¨ìˆ˜ë¡œ í­ê·„ ë°ì´í„°ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œ# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\n\ntidyverse íŒ©í‚¤ì§€ glimpse() í•¨ìˆ˜ë¡œ í­ê·„ ë°ì´í„°ë¥¼ ì¼ë³„í•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, â€¦\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, â€¦\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186â€¦\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, â€¦\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, maleâ€¦\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007â€¦"
  },
  {
    "objectID": "palmer_penguins.html#penguin-EDA-skimr",
    "href": "palmer_penguins.html#penguin-EDA-skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr íŒ©í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ penguins ë°ì´í„°í”„ë ˆì„ ìë£Œêµ¬ì¡°ë¥¼ ì¼ë³„í•œë‹¤. ì´ë¥¼ í†µí•´ì„œ 344ê°œ í­ê·„ ê´€ì¸¡ê°’ì´ ìˆìœ¼ë©°, 7ê°œ ì¹¼ëŸ¼ìœ¼ë¡œ êµ¬ì„±ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ë²”ì£¼í˜• ë³€ìˆ˜ê°€ 3ê°œ, ìˆ«ìí˜• ë³€ìˆ˜ê°€ 4ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ê·¸ì™¸ ë” ìì„¸í•œ ì‚¬í•­ì€ ë²”ì£¼í˜•, ìˆ«ìí˜• ë³€ìˆ˜ì— ëŒ€í•œ ìš”ì•½ í†µê³„ëŸ‰ì„ ì°¸ì¡°í•œë‹¤.\n\nì½”ë“œskimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\nâ–ƒâ–‡â–‡â–†â–\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\nâ–…â–…â–‡â–‡â–‚\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\nâ–‚â–‡â–ƒâ–…â–‚\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\nâ–ƒâ–‡â–†â–ƒâ–‚\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\nâ–‡â–â–‡â–â–‡\n\n\n\n\n\në°ì´í„°ê°€ í¬ì§€ ì•Šì•„ DT íŒ©í‚¤ì§€ë¥¼ í†µí•´ ë°ì´í„° ì „ë°˜ì ì¸ ë‚´ìš©ì„ ì‚´í´ë³¼ ìˆ˜ ìˆë‹¤.\n\nì½”ë“œpenguins %&gt;% \n  reactable::reactable()"
  },
  {
    "objectID": "palmer_penguins.html#penguin-EDA",
    "href": "palmer_penguins.html#penguin-EDA",
    "title": "chatGPT",
    "section": "",
    "text": "palmerpenguins ë°ì´í„°ì…‹ ì†Œê°œì— í¬í•¨ë˜ì–´ ìˆëŠ” ë¯¸êµ­ íŒ”ë¨¸ ì—°êµ¬ì†Œ (palmer station) í­ê·„ ë¬¼ê°ˆí€´(flipper) ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰(body mass) ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ì.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"í­ê·„ í¬ê¸°\",\n       subtitle = \"ë‚¨ê·¹ í­ê·„ 3ì¢… ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰ ê´€ê³„\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ì²´ì§ˆëŸ‰ (g)\",\n       color = \"í­ê·„ 3ì¢…\",\n       shape = \"í­ê·„ 3ì¢…\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper"
  },
  {
    "objectID": "palmer_penguins.html#footnotes",
    "href": "palmer_penguins.html#footnotes",
    "title": "chatGPT",
    "section": "ê°ì£¼",
    "text": "ê°ì£¼\n\nì‹ ë°œëˆ ì—¬í–‰ì‚¬, ê´€ê´‘ì•ˆë‚´ìë£Œâ†©ï¸"
  },
  {
    "objectID": "autoGPT_ds.html#skimr",
    "href": "autoGPT_ds.html#skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\n\nì½”ë“œpenguins %&gt;% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nì¢…ëª…ì¹­\n0\n1.00\nFALSE\n3\nì•„ë¸ë¦¬: 152, ì  íˆ¬: 124, í„±ëˆ: 68\n\n\nì„¬ì´ë¦„\n0\n1.00\nFALSE\n3\në¹„ìŠ¤ì½”: 168, ë“œë¦¼: 124, í† ë¥´ê±°: 52\n\n\nì„±ë³„\n11\n0.97\nFALSE\n2\nìˆ˜ì»·: 168, ì•”ì»·: 165\n\n\nì—°ë„\n0\n1.00\nTRUE\n3\n200: 120, 200: 114, 200: 110\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\në¶€ë¦¬_ê¸¸ì´\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\nâ–ƒâ–‡â–‡â–†â–\n\n\në¶€ë¦¬_ê¹Šì´\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\nâ–…â–…â–‡â–‡â–‚\n\n\në¬¼ê°ˆí€´_ê¸¸ì´\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\nâ–‚â–‡â–ƒâ–…â–‚\n\n\nì²´ì¤‘\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\nâ–ƒâ–‡â–†â–ƒâ–‚"
  },
  {
    "objectID": "autoGPT_ds.html#dataxray",
    "href": "autoGPT_ds.html#dataxray",
    "title": "chatGPT",
    "section": "",
    "text": "dataxray íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ì— ëŒ€í•œ ì´í•´ë¥¼ ë”ìš± ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\n\nì½”ë“œlibrary(dataxray)\n\npenguins %&gt;% \n   make_xray() %&gt;% \n   view_xray()\n\n\n\n\nExpand/collapse all"
  },
  {
    "objectID": "autoGPT_ds.html#dlookr",
    "href": "autoGPT_ds.html#dlookr",
    "title": "chatGPT",
    "section": "",
    "text": "dlookr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\n\nì½”ë“œlibrary(kableExtra)\npenguins %&gt;% \n  dlookr::describe() %&gt;% \n  kable(caption = \"ìš”ì•½í†µê³„ëŸ‰\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)  \n\n\n\nìš”ì•½í†µê³„ëŸ‰\n\ndescribed_variables\nn\nna\nmean\nsd\nse_mean\nIQR\nskewness\nkurtosis\np00\np01\np05\np10\np20\np25\np30\np40\np50\np60\np70\np75\np80\np90\np95\np99\np100\n\n\n\në¶€ë¦¬_ê¸¸ì´\n342\n2\n43.92193\n5.459584\n0.2952205\n9.275\n0.0531181\n-0.8760270\n32.1\n34.041\n35.7\n36.6\n38.34\n39.225\n40.20\n42.0\n44.45\n46.0\n47.37\n48.5\n49.38\n50.8\n51.995\n55.513\n59.6\n\n\në¶€ë¦¬_ê¹Šì´\n342\n2\n17.15117\n1.974793\n0.1067846\n3.100\n-0.1434646\n-0.9068661\n13.1\n13.441\n13.9\n14.3\n15.00\n15.600\n15.93\n16.8\n17.30\n17.9\n18.50\n18.7\n18.90\n19.5\n20.000\n21.100\n21.5\n\n\në¬¼ê°ˆí€´_ê¸¸ì´\n342\n2\n200.91520\n14.061714\n0.7603704\n23.000\n0.3456818\n-0.9842729\n172.0\n178.000\n181.0\n185.0\n188.00\n190.000\n191.00\n194.0\n197.00\n203.0\n210.00\n213.0\n215.00\n220.9\n225.000\n230.000\n231.0\n\n\nì²´ì¤‘\n342\n2\n4201.75439\n801.954536\n43.3647348\n1200.000\n0.4703293\n-0.7192219\n2700.0\n2900.000\n3150.0\n3300.0\n3475.00\n3550.000\n3650.00\n3800.0\n4050.00\n4300.0\n4650.00\n4750.0\n4950.00\n5400.0\n5650.000\n5979.500\n6300.0"
  },
  {
    "objectID": "autoGPT_ds.html#dataexplorer",
    "href": "autoGPT_ds.html#dataexplorer",
    "title": "chatGPT",
    "section": "",
    "text": "DataExplorer íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\nDataExplorer::create_report(penguins)\n\n\nêµ¬ì¡°\nDF ìš”ì•½\nDF ìš”ì•½ ì‹œê°í™”\nê²°ì¸¡ê°’\në¶„í¬(ë²”ì£¼í˜•)\në¶„í¬(ì—°ì†í˜•)\nìƒê´€ê´€ê³„\nPCA\n\n\n\n\nì½”ë“œDataExplorer::plot_str(penguins)\n\n\n\n\n\nì½”ë“œDataExplorer::introduce(penguins)\n\n# A tibble: 1 Ã— 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1   344       8                4                  4                   0\n# â„¹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;\n\n\n\n\n\nì½”ë“œDataExplorer::plot_intro(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_missing(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_bar(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_histogram(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% select_if(is.numeric) %&gt;% \n  # drop_na() %&gt;% \n  DataExplorer::plot_correlation(cor_args = list(\"use\" = \"pairwise.complete.obs\"))\n\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins_pca &lt;- penguins %&gt;% select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% prcomp(scale = TRUE)\n\nsummary(penguins_pca)$importance %&gt;% as.data.frame() %&gt;% \n  kable(caption = \"PCA ìš”ì•½\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\nPCA ìš”ì•½\n\n\nPC1\nPC2\nPC3\nPC4\n\n\n\nStandard deviation\n1.659444\n0.8789293\n0.6043475\n0.3293816\n\n\nProportion of Variance\n0.688440\n0.1931300\n0.0913100\n0.0271200\n\n\nCumulative Proportion\n0.688440\n0.8815700\n0.9728800\n1.0000000"
  },
  {
    "objectID": "autoGPT_ds.html#hmiscdescribe",
    "href": "autoGPT_ds.html#hmiscdescribe",
    "title": "chatGPT",
    "section": "",
    "text": "Hmisc íŒ¨í‚¤ì§€ë¥¼ í†µí•´ ê³¼ê±° 20ë…„ì „ ë°ì´í„° ë¶„ì„ë°©ë²•ì„ ìŒë¯¸í•©ë‹ˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n\npenguins &lt;- palmerpenguins::penguins %&gt;%\n  # ì˜ì–´ ë³€ìˆ˜ëª… í•œê¸€ ë³€í™˜\n  set_names(c(\"ì¢…ëª…ì¹­\", \"ì„¬ì´ë¦„\", \"ë¶€ë¦¬_ê¸¸ì´\", \"ë¶€ë¦¬_ê¹Šì´\", \"ë¬¼ê°ˆí€´_ê¸¸ì´\",\n              \"ì²´ì¤‘\", \"ì„±ë³„\", \"ì—°ë„\")) %&gt;%\n  # ê²°ì¸¡ê°’ ì œê±°\n  # drop_na() %&gt;%\n  # ì˜ì–´ ê°’ í•œê¸€ ê°’ìœ¼ë¡œ ë³€í™˜\n  mutate(ì„±ë³„ = ifelse(ì„±ë³„ == \"male\", \"ìˆ˜ì»·\", \"ì•”ì»·\"),\n         ì„¬ì´ë¦„ = case_when( str_detect(ì„¬ì´ë¦„, \"Biscoe\") ~ \"ë¹„ìŠ¤ì½”\",\n                          str_detect(ì„¬ì´ë¦„, \"Dream\") ~ \"ë“œë¦¼\",\n                          str_detect(ì„¬ì´ë¦„, \"Torgersen\") ~ \"í† ë¥´ê±°ì„¼\"),\n         ì¢…ëª…ì¹­ = case_when( str_detect(ì¢…ëª…ì¹­, \"Adelie\") ~ \"ì•„ë¸ë¦¬\",\n                          str_detect(ì¢…ëª…ì¹­, \"Chinstrap\") ~ \"í„±ëˆ\",\n                          str_detect(ì¢…ëª…ì¹­, \"Gentoo\") ~ \"ì  íˆ¬\")\n  ) %&gt;%\n  # ìë£Œí˜• ë³€í™˜\n  mutate(ì„±ë³„   = factor(ì„±ë³„, levels = c(\"ìˆ˜ì»·\", \"ì•”ì»·\")),\n         ì„¬ì´ë¦„ = factor(ì„¬ì´ë¦„, levels = c(\"ë¹„ìŠ¤ì½”\", \"ë“œë¦¼\", \"í† ë¥´ê±°ì„¼\")),\n         ì¢…ëª…ì¹­ = factor(ì¢…ëª…ì¹­, levels = c(\"ì•„ë¸ë¦¬\", \"í„±ëˆ\", \"ì  íˆ¬\")),\n         ì—°ë„   = ordered(ì—°ë„, levels = c(2007, 2008, 2009)))\n\n\n\nHmisc::describe(penguins)\n\npenguins \n\n 8  Variables      344  Observations\n--------------------------------------------------------------------------------\nì¢…ëª…ì¹­ \n       n  missing distinct \n     344        0        3 \n                                     \nValue        ì•„ë¸ë¦¬     í„±ëˆ     ì  íˆ¬\nFrequency    152       68      124   \nProportion 0.442    0.198    0.360   \n--------------------------------------------------------------------------------\nì„¬ì´ë¦„ \n       n  missing distinct \n     344        0        3 \n                                     \nValue        ë¹„ìŠ¤ì½”     ë“œë¦¼ í† ë¥´ê±°ì„¼\nFrequency    168      124       52   \nProportion 0.488    0.360    0.151   \n--------------------------------------------------------------------------------\në¶€ë¦¬_ê¸¸ì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2      164        1    43.92    6.274    35.70    36.60 \n     .25      .50      .75      .90      .95 \n   39.23    44.45    48.50    50.80    51.99 \n\nlowest : 32.1 33.1 33.5 34.0 34.1, highest: 55.1 55.8 55.9 58.0 59.6\n--------------------------------------------------------------------------------\në¶€ë¦¬_ê¹Šì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       80        1    17.15    2.267     13.9     14.3 \n     .25      .50      .75      .90      .95 \n    15.6     17.3     18.7     19.5     20.0 \n\nlowest : 13.1 13.2 13.3 13.4 13.5, highest: 20.7 20.8 21.1 21.2 21.5\n--------------------------------------------------------------------------------\në¬¼ê°ˆí€´_ê¸¸ì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       55    0.999    200.9    16.03    181.0    185.0 \n     .25      .50      .75      .90      .95 \n   190.0    197.0    213.0    220.9    225.0 \n\nlowest : 172 174 176 178 179, highest: 226 228 229 230 231\n--------------------------------------------------------------------------------\nì²´ì¤‘ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       94        1     4202    911.8     3150     3300 \n     .25      .50      .75      .90      .95 \n    3550     4050     4750     5400     5650 \n\nlowest : 2700 2850 2900 2925 2975, highest: 5850 5950 6000 6050 6300\n--------------------------------------------------------------------------------\nì„±ë³„ \n       n  missing distinct \n     333       11        2 \n                          \nValue         ìˆ˜ì»·    ì•”ì»·\nFrequency    168     165  \nProportion 0.505   0.495  \n--------------------------------------------------------------------------------\nì—°ë„ \n       n  missing distinct \n     344        0        3 \n                            \nValue       2007  2008  2009\nFrequency    110   114   120\nProportion 0.320 0.331 0.349\n--------------------------------------------------------------------------------"
  },
  {
    "objectID": "gg_grouping.html",
    "href": "gg_grouping.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ë°ì´í„°ì…‹\nì±—GPT êµìœ¡ì— ì°¸ì—¬í•œ ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„°ë¥¼ ì •ë¦¬í•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(readxl)\n\nsurvey_26 &lt;- read_excel(\"data/(ë¶™ì„) ê²½ê¸°ë„ì²­ ì±—GPT ì§ì›ì§ë¬´ êµìœ¡ì‹ ì²­ ëª…ë‹¨(ì·¨í•©).xlsx\", sheet = '4.26.(ìˆ˜)', skip =2) %&gt;% \n  mutate(ë‚ ì§œ = \"2023-04-26\")\nsurvey_27 &lt;- read_excel(\"data/(ë¶™ì„) ê²½ê¸°ë„ì²­ ì±—GPT ì§ì›ì§ë¬´ êµìœ¡ì‹ ì²­ ëª…ë‹¨(ì·¨í•©).xlsx\", sheet = '4.27.(ëª©)', skip =2) %&gt;% \n  mutate(ë‚ ì§œ = \"2023-04-27\")\nsurvey_28 &lt;- read_excel(\"data/(ë¶™ì„) ê²½ê¸°ë„ì²­ ì±—GPT ì§ì›ì§ë¬´ êµìœ¡ì‹ ì²­ ëª…ë‹¨(ì·¨í•©).xlsx\", sheet = '4.28.(ê¸ˆ)', skip =2) %&gt;% \n  mutate(ë‚ ì§œ = \"2023-04-28\")\n\nsurvey &lt;- bind_rows(survey_26, survey_27) %&gt;% \n  bind_rows(survey_28) %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  set_names(c(\"ì—°ë²ˆ\", \"ì‹¤êµ­\", \"ì†Œì†\", \"ì§ìœ„\", \"ì„±ëª…\", \"í”„ë¡¬í”„íŠ¸\", \"API\", \"ì„±ì·¨ëª©í‘œ\", \"ë‚ ì§œ\")) %&gt;% \n  mutate(ì‹¤êµ­ = ifelse(is.na(ì‹¤êµ­), \"ì§ì†\", ì‹¤êµ­)) \n\n\n\n2 ë°ì´í„° ê°€ëª…ì²˜ë¦¬\nì‹¤êµ­, ì†Œì†ê³¼ ì§ìœ„, ì„±ëª…ì´ í¬í•¨ë˜ì–´ ìˆì–´ ë³€ìˆ˜ ì¤‘ ì„±ëª…ì„ ê°€ëª…ì²˜ë¦¬í•œë‹¤. ì´ë¥¼ ìœ„í•´ì„œ íŒŒì´ì¬ Faker íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ëª…ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.\n\nì½”ë“œfrom faker import Faker\nimport pandas as pd\nimport numpy as np\nimport random\nfrom datetime import datetime\n\nfake = Faker('ko_KR')\n\ndef create_rows_faker(num=1):\n    output = [{\"name\"       : fake.name()} for x in range(num)]\n    return output\n\ndf_faker = pd.DataFrame(create_rows_faker(72))\n\n\nê°€ëª…ì²˜ë¦¬ ë°ì´í„°ë¥¼ ì •ë¦¬í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\nsurvey_tbl &lt;- survey %&gt;% \n  bind_cols(py$df_faker) %&gt;% \n  select(-ì„±ëª…) %&gt;% \n  rename(ì„±ëª… = name) %&gt;% \n  select(ë‚ ì§œ, ì‹¤êµ­, ì„±ëª…, ì§ìœ„, í”„ë¡¬í”„íŠ¸, API) \n\n\n\n3 ì±—GPT\nì±—GPT GPT-4ë¥¼ ì‚¬ìš©í•´ì„œ ì±—GPT ì‹¤ë¬´êµìœ¡ì„ í†µí•´ ì–»ìœ¼ë ¤ëŠ” ê²ƒì„ ìš”ì•½í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•œë‹¤.\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ì±—GPT êµìœ¡ì°¸ì—¬ í…ìŠ¤íŠ¸ë¥¼ 5ê°œ ëª©í‘œë¡œ êµ°ì§‘í™”ì‹œì¼œ ì •ë¦¬í•˜ì‹œìš”\n\n\n\n\nì±—GPT ì‘ë‹µ:  1. ì—…ë¬´ íš¨ìœ¨ì„±ê³¼ ìƒì‚°ì„± í–¥ìƒ:  - ë³´ê³ ì„œ ì‘ì„± ë° ì—‘ì…€ ìŠ¤í‚¬ í–¥ìƒ  - í–‰ì • ì—…ë¬´ì˜ ê°„ì†Œí™”  - íŠ¹ì • ì§ë¬´ ì—­í• ì—ì„œ ChatGPTë¥¼ ì ìš©í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²• íƒêµ¬  1. ë³€í™”í•˜ëŠ” ê¸°ìˆ  ì¶”ì„¸ì— ì ì‘í•˜ê³  ìƒˆë¡œìš´ ê¸°ìˆ  ìŠµë“:  - AIì™€ ChatGPTì˜ ìµœì‹  ë™í–¥ ì´í•´  - ChatGPT ì‚¬ìš©ì— ë’¤ì²˜ì§€ì§€ ì•Šê¸° ìœ„í•œ ì§€ì‹ íšë“  - ë³€í™”í•˜ëŠ” ê¸°ìˆ  í’ê²½ì— ì ì‘í•˜ê¸° ìœ„í•œ ê¸°ë³¸ ì§€ì‹ ìŠµë“  1. ë¬¸ì œ í•´ê²° ë° ì˜ì‚¬ ê²°ì • ëŠ¥ë ¥ í–¥ìƒ:  - ê¸°íš ë° ì´ë²¤íŠ¸ í”„ë¡œëª¨ì…˜ì„ ìœ„í•œ ë°ì´í„° ì‹œê°í™” í™œìš©  - ì‚¬ë¡€ ì—°êµ¬ ë° ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ChatGPT ì‚¬ìš©  - ì§€ì—­ ë°œì „ ë° IT ë™í–¥ì— ëŒ€í•œ ChatGPTì˜ ì˜í–¥ ë¶„ì„ ë° ì´í•´  1. ChatGPT ì‘ìš© ë²”ìœ„ í™•ì¥:  - ì¼ìƒ ìƒí™œ ë° ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼(ì˜ˆ: ë†ì—… í™ë³´, ì½˜í…ì¸  ì‚°ì—…)ì— ChatGPT ì ìš©  - ë‹¤ì–‘í•œ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì íŠ¸ì—ì„œ ChatGPT í†µí•©ì˜ ì ì¬ë ¥ ì¡°ì‚¬  1. ì˜ì‚¬ì†Œí†µ ë° ì§ˆë¬¸ ê¸°ìˆ  í–¥ìƒ:  - íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì§ˆë¬¸ ë°©ë²• í•™ìŠµ  - ChatGPTì™€ ë” ë‚˜ì€ ìƒí˜¸ ì‘ìš©ì„ ìœ„í•œ ê¸°ìˆ  ê°œë°œ  - ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ì˜¬ë°”ë¥¸ ì§ˆë¬¸ì„ í•˜ëŠ” ê²ƒì˜ ì¤‘ìš”ì„± ì´í•´ \n\n\n\n\n4 í†µê³„ ë¶„ì„\nì„¤ë¬¸ì¡°ì‚¬ì— ë‚˜íƒ€ë‚œ ìê¸°í‰ê°€ í”„ë¡¬í”„íŠ¸ API í™œìš©ì—­ëŸ‰ì„ í‘œë¡œ ìš”ì•½í•œë‹¤.\n\nì½”ë“œlibrary(gt)\nlibrary(gtExtras)\n\nsurvey_gt &lt;- survey %&gt;% \n  count(í”„ë¡¬í”„íŠ¸, API) %&gt;% \n  pivot_wider(names_from = API, values_from = n, values_fill = 0) %&gt;% \n  mutate(ë¼ = 0) %&gt;% \n  gt::gt() %&gt;% \n    tab_spanner(\n    label = \"API í™œìš©ëŠ¥ë ¥\",\n    columns = c(\n      ê°€,ë‚˜,ë‹¤,ë¼\n    )\n  ) %&gt;% \n  gt_theme_nytimes() %&gt;% \n  tab_header(title = \"ìê¸°í‰ê°€ í”„ë¡¬í”„íŠ¸, API í™œìš©ì—­ëŸ‰\") %&gt;% \n  cols_align(\n  align = \"center\",\n  columns = everything()\n)\n\nsurvey_gt %&gt;% \n  gtsave_extra(filename=\"images/gg_survey_gt.png\")\n\n\n\n\n\n\nìš”ì¼ë³„ ì´ˆ,ì¤‘,ê³ ê¸‰ ì°¸ì—¬ì ì—­ëŸ‰ì„ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì•½í•œë‹¤.\n\nì½”ë“œsurvey_gt_date &lt;- survey %&gt;% \n  mutate(ìˆ˜ì¤€ = case_when(í”„ë¡¬í”„íŠ¸ %in% c(\"ê°€\", \"ë‚˜\") & API %in% c(\"ê°€\", \"ë‚˜\") ~ \"ì´ˆê¸‰\",\n                          í”„ë¡¬í”„íŠ¸ == \"ë¼\" ~ \"ê³ ê¸‰\",\n                          TRUE ~ \"ì¤‘ê¸‰\")) %&gt;% \n  count(ë‚ ì§œ, ìˆ˜ì¤€) %&gt;% \n  pivot_wider(names_from = ìˆ˜ì¤€, values_from = n, values_fill  = 0) %&gt;% \n  gt::gt() %&gt;% \n    tab_spanner(\n    label = \"ìê°€í‰ê°€ ì—­ëŸ‰ ì¢…í•©\",\n    columns = c(\n      ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰\n    )\n  ) %&gt;% \n  gt_theme_nytimes() %&gt;% \n  tab_header(title = \"ì±—GPT ìš”ì¼ë³„ ì°¸ì—¬ì ì—­ëŸ‰\") %&gt;% \n  cols_align(\n  align = \"center\",\n  columns = everything()\n)  \n\nsurvey_gt_date %&gt;% \n  gtsave_extra(filename=\"images/survey_gt_date.png\")"
  },
  {
    "objectID": "gg_grouping.html#hmiscdescribe",
    "href": "gg_grouping.html#hmiscdescribe",
    "title": "chatGPT",
    "section": "",
    "text": "Hmisc íŒ¨í‚¤ì§€ë¥¼ í†µí•´ ê³¼ê±° 20ë…„ì „ ë°ì´í„° ë¶„ì„ë°©ë²•ì„ ìŒë¯¸í•©ë‹ˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n\npenguins &lt;- palmerpenguins::penguins %&gt;%\n  # ì˜ì–´ ë³€ìˆ˜ëª… í•œê¸€ ë³€í™˜\n  set_names(c(\"ì¢…ëª…ì¹­\", \"ì„¬ì´ë¦„\", \"ë¶€ë¦¬_ê¸¸ì´\", \"ë¶€ë¦¬_ê¹Šì´\", \"ë¬¼ê°ˆí€´_ê¸¸ì´\",\n              \"ì²´ì¤‘\", \"ì„±ë³„\", \"ì—°ë„\")) %&gt;%\n  # ê²°ì¸¡ê°’ ì œê±°\n  # drop_na() %&gt;%\n  # ì˜ì–´ ê°’ í•œê¸€ ê°’ìœ¼ë¡œ ë³€í™˜\n  mutate(ì„±ë³„ = ifelse(ì„±ë³„ == \"male\", \"ìˆ˜ì»·\", \"ì•”ì»·\"),\n         ì„¬ì´ë¦„ = case_when( str_detect(ì„¬ì´ë¦„, \"Biscoe\") ~ \"ë¹„ìŠ¤ì½”\",\n                          str_detect(ì„¬ì´ë¦„, \"Dream\") ~ \"ë“œë¦¼\",\n                          str_detect(ì„¬ì´ë¦„, \"Torgersen\") ~ \"í† ë¥´ê±°ì„¼\"),\n         ì¢…ëª…ì¹­ = case_when( str_detect(ì¢…ëª…ì¹­, \"Adelie\") ~ \"ì•„ë¸ë¦¬\",\n                          str_detect(ì¢…ëª…ì¹­, \"Chinstrap\") ~ \"í„±ëˆ\",\n                          str_detect(ì¢…ëª…ì¹­, \"Gentoo\") ~ \"ì  íˆ¬\")\n  ) %&gt;%\n  # ìë£Œí˜• ë³€í™˜\n  mutate(ì„±ë³„   = factor(ì„±ë³„, levels = c(\"ìˆ˜ì»·\", \"ì•”ì»·\")),\n         ì„¬ì´ë¦„ = factor(ì„¬ì´ë¦„, levels = c(\"ë¹„ìŠ¤ì½”\", \"ë“œë¦¼\", \"í† ë¥´ê±°ì„¼\")),\n         ì¢…ëª…ì¹­ = factor(ì¢…ëª…ì¹­, levels = c(\"ì•„ë¸ë¦¬\", \"í„±ëˆ\", \"ì  íˆ¬\")),\n         ì—°ë„   = ordered(ì—°ë„, levels = c(2007, 2008, 2009)))\n\n\n\nHmisc::describe(penguins)\n\npenguins \n\n 8  Variables      344  Observations\n--------------------------------------------------------------------------------\nì¢…ëª…ì¹­ \n       n  missing distinct \n     344        0        3 \n                                     \nValue        ì•„ë¸ë¦¬     í„±ëˆ     ì  íˆ¬\nFrequency    152       68      124   \nProportion 0.442    0.198    0.360   \n--------------------------------------------------------------------------------\nì„¬ì´ë¦„ \n       n  missing distinct \n     344        0        3 \n                                     \nValue        ë¹„ìŠ¤ì½”     ë“œë¦¼ í† ë¥´ê±°ì„¼\nFrequency    168      124       52   \nProportion 0.488    0.360    0.151   \n--------------------------------------------------------------------------------\në¶€ë¦¬_ê¸¸ì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2      164        1    43.92    6.274    35.70    36.60 \n     .25      .50      .75      .90      .95 \n   39.23    44.45    48.50    50.80    51.99 \n\nlowest : 32.1 33.1 33.5 34.0 34.1, highest: 55.1 55.8 55.9 58.0 59.6\n--------------------------------------------------------------------------------\në¶€ë¦¬_ê¹Šì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       80        1    17.15    2.267     13.9     14.3 \n     .25      .50      .75      .90      .95 \n    15.6     17.3     18.7     19.5     20.0 \n\nlowest : 13.1 13.2 13.3 13.4 13.5, highest: 20.7 20.8 21.1 21.2 21.5\n--------------------------------------------------------------------------------\në¬¼ê°ˆí€´_ê¸¸ì´ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       55    0.999    200.9    16.03    181.0    185.0 \n     .25      .50      .75      .90      .95 \n   190.0    197.0    213.0    220.9    225.0 \n\nlowest : 172 174 176 178 179, highest: 226 228 229 230 231\n--------------------------------------------------------------------------------\nì²´ì¤‘ \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       94        1     4202    911.8     3150     3300 \n     .25      .50      .75      .90      .95 \n    3550     4050     4750     5400     5650 \n\nlowest : 2700 2850 2900 2925 2975, highest: 5850 5950 6000 6050 6300\n--------------------------------------------------------------------------------\nì„±ë³„ \n       n  missing distinct \n     333       11        2 \n                          \nValue         ìˆ˜ì»·    ì•”ì»·\nFrequency    168     165  \nProportion 0.505   0.495  \n--------------------------------------------------------------------------------\nì—°ë„ \n       n  missing distinct \n     344        0        3 \n                            \nValue       2007  2008  2009\nFrequency    110   114   120\nProportion 0.320 0.331 0.349\n--------------------------------------------------------------------------------"
  },
  {
    "objectID": "gg_grouping.html#skimr",
    "href": "gg_grouping.html#skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\n\nì½”ë“œpenguins %&gt;% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nì¢…ëª…ì¹­\n0\n1.00\nFALSE\n3\nì•„ë¸ë¦¬: 152, ì  íˆ¬: 124, í„±ëˆ: 68\n\n\nì„¬ì´ë¦„\n0\n1.00\nFALSE\n3\në¹„ìŠ¤ì½”: 168, ë“œë¦¼: 124, í† ë¥´ê±°: 52\n\n\nì„±ë³„\n11\n0.97\nFALSE\n2\nìˆ˜ì»·: 168, ì•”ì»·: 165\n\n\nì—°ë„\n0\n1.00\nTRUE\n3\n200: 120, 200: 114, 200: 110\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\në¶€ë¦¬_ê¸¸ì´\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\nâ–ƒâ–‡â–‡â–†â–\n\n\në¶€ë¦¬_ê¹Šì´\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\nâ–…â–…â–‡â–‡â–‚\n\n\në¬¼ê°ˆí€´_ê¸¸ì´\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\nâ–‚â–‡â–ƒâ–…â–‚\n\n\nì²´ì¤‘\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\nâ–ƒâ–‡â–†â–ƒâ–‚"
  },
  {
    "objectID": "gg_grouping.html#dataxray",
    "href": "gg_grouping.html#dataxray",
    "title": "chatGPT",
    "section": "",
    "text": "dataxray íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ì— ëŒ€í•œ ì´í•´ë¥¼ ë”ìš± ë†’ì¼ ìˆ˜ ìˆë‹¤.\n\n\nì½”ë“œlibrary(dataxray)\n\npenguins %&gt;% \n   make_xray() %&gt;% \n   view_xray()\n\n\n\n\nExpand/collapse all"
  },
  {
    "objectID": "gg_grouping.html#dlookr",
    "href": "gg_grouping.html#dlookr",
    "title": "chatGPT",
    "section": "",
    "text": "dlookr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\n\nì½”ë“œlibrary(kableExtra)\npenguins %&gt;% \n  dlookr::describe() %&gt;% \n  kable(caption = \"ìš”ì•½í†µê³„ëŸ‰\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)  \n\n\n\nìš”ì•½í†µê³„ëŸ‰\n\ndescribed_variables\nn\nna\nmean\nsd\nse_mean\nIQR\nskewness\nkurtosis\np00\np01\np05\np10\np20\np25\np30\np40\np50\np60\np70\np75\np80\np90\np95\np99\np100\n\n\n\në¶€ë¦¬_ê¸¸ì´\n342\n2\n43.92193\n5.459584\n0.2952205\n9.275\n0.0531181\n-0.8760270\n32.1\n34.041\n35.7\n36.6\n38.34\n39.225\n40.20\n42.0\n44.45\n46.0\n47.37\n48.5\n49.38\n50.8\n51.995\n55.513\n59.6\n\n\në¶€ë¦¬_ê¹Šì´\n342\n2\n17.15117\n1.974793\n0.1067846\n3.100\n-0.1434646\n-0.9068661\n13.1\n13.441\n13.9\n14.3\n15.00\n15.600\n15.93\n16.8\n17.30\n17.9\n18.50\n18.7\n18.90\n19.5\n20.000\n21.100\n21.5\n\n\në¬¼ê°ˆí€´_ê¸¸ì´\n342\n2\n200.91520\n14.061714\n0.7603704\n23.000\n0.3456818\n-0.9842729\n172.0\n178.000\n181.0\n185.0\n188.00\n190.000\n191.00\n194.0\n197.00\n203.0\n210.00\n213.0\n215.00\n220.9\n225.000\n230.000\n231.0\n\n\nì²´ì¤‘\n342\n2\n4201.75439\n801.954536\n43.3647348\n1200.000\n0.4703293\n-0.7192219\n2700.0\n2900.000\n3150.0\n3300.0\n3475.00\n3550.000\n3650.00\n3800.0\n4050.00\n4300.0\n4650.00\n4750.0\n4950.00\n5400.0\n5650.000\n5979.500\n6300.0"
  },
  {
    "objectID": "gg_grouping.html#dataexplorer",
    "href": "gg_grouping.html#dataexplorer",
    "title": "chatGPT",
    "section": "",
    "text": "DataExplorer íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•  ë°ì´í„°ì™€ ì¹œìˆ™í•´ì§„ë‹¤.\nDataExplorer::create_report(penguins)\n\n\nêµ¬ì¡°\nDF ìš”ì•½\nDF ìš”ì•½ ì‹œê°í™”\nê²°ì¸¡ê°’\në¶„í¬(ë²”ì£¼í˜•)\në¶„í¬(ì—°ì†í˜•)\nìƒê´€ê´€ê³„\nPCA\n\n\n\n\nì½”ë“œDataExplorer::plot_str(penguins)\n\n\n\n\n\nì½”ë“œDataExplorer::introduce(penguins)\n\n# A tibble: 1 Ã— 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1   344       8                4                  4                   0\n# â„¹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;\n\n\n\n\n\nì½”ë“œDataExplorer::plot_intro(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_missing(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_bar(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œDataExplorer::plot_histogram(penguins)\n\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% select_if(is.numeric) %&gt;% \n  # drop_na() %&gt;% \n  DataExplorer::plot_correlation(cor_args = list(\"use\" = \"pairwise.complete.obs\"))\n\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins_pca &lt;- penguins %&gt;% select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% prcomp(scale = TRUE)\n\nsummary(penguins_pca)$importance %&gt;% as.data.frame() %&gt;% \n  kable(caption = \"PCA ìš”ì•½\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\nPCA ìš”ì•½\n\n\nPC1\nPC2\nPC3\nPC4\n\n\n\nStandard deviation\n1.659444\n0.8789293\n0.6043475\n0.3293816\n\n\nProportion of Variance\n0.688440\n0.1931300\n0.0913100\n0.0271200\n\n\nCumulative Proportion\n0.688440\n0.8815700\n0.9728800\n1.0000000"
  },
  {
    "objectID": "architecture.html#jpeg-ì••ì¶•",
    "href": "architecture.html#jpeg-ì••ì¶•",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPTëŠ” ì¸í„°ë„·ì—ì„œ ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì´ë¥¼ ì •ë§ ì˜ ì••ì¶•í•œ í•˜ë‚˜ì˜ ì €ì¥ì†Œë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì••ì¶•ì„ í’€ê²Œ ë˜ë©´ ì •í™•íˆ ì›ë³¸ì„ ë³µì›í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ë„ ìˆì§€ë§Œ, ê·¸ë ‡ì§€ ëª»í•œ ë¶€ë¶„ë„ ë‹¹ì˜íˆ ìˆê²Œ ëœë‹¤.\nTed Chiang (February 9, 2023), â€œChatGPT Is a Blurry JPEG of the Web - OpenAIâ€™s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?â€, The New Yorker\nChatGPTë¥¼ â€œì›¹ì˜ íë¦¿í•œ JPEGâ€ìœ¼ë¡œ ë¹„ìœ í•˜ê³  ìˆë‹¤. JPEC ê¸°ìˆ  ìì²´ëŠ” ì†ì‹¤ ì••ì¶•ê¸°ìˆ ë¡œ ë¬´ì†ì‹¤ ì••ì¶•ê¸°ìˆ ë¡œ ëŒ€í‘œì ì¸ PNGì™€ ëŒ€ë¹„ëœë‹¤. íë¦¿í•œ ì´ë¯¸ì§€ê°€ ì„ ëª…í•˜ì§€ ì•Šê±°ë‚˜ ì •í™•í•˜ì§€ ì•Šì€ ê²ƒì²˜ëŸ¼ ChatGPTë„ í•­ìƒ ì™„ë²½í•œ ë‹µë³€ì„ ì œê³µí•˜ê±°ë‚˜ ëª¨ë“  ì§ˆë¬¸ì„ ì œëŒ€ë¡œ ì´í•´í•˜ëŠ” ê²ƒë„ ì•„ë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŠì„ì—†ì´ í•™ìŠµí•˜ê³  ê°œì„ í•˜ê³  ìˆë‹¤. ë” ë§ì€ ì‚¬ëŒë“¤ì´ ChatGPTë¥¼ ì‚¬ìš©í• ìˆ˜ë¡ ì‚¬ëŒì˜ ì–¸ì–´ë¥¼ ë” ì˜ ì´í•´í•˜ê³  ë°˜ì‘í•  ìˆ˜ ìˆê²Œ ê°œë°œëœ ê¸°ìˆ ì´ë‹¤.\nChatGPTì™€ ìœ ì‚¬í•œ ì¸ê³µì§€ëŠ¥ í”„ë¡œê·¸ë¨ì´ ë„ˆë¬´ ê°•ë ¥í•´ì§€ê±°ë‚˜ ì¸ê°„ì„ ëŒ€ì²´í•  ìˆ˜ ìˆë‹¤ê³  ìš°ë ¤í•˜ëŠ” ì‚¬ëŒë“¤ë„ ìˆì§€ë§Œ, ChatGPTëŠ” ë‹¨ìˆœíˆ ì‘ì—…ì„ ë” ì‰½ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“œëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì¼ ë¿ì´ë¯€ë¡œ ì‚¬ëŒì„ ëŠ¥ê°€í•˜ê±°ë‚˜ ì§€ë°°í•  ê°€ëŠ¥ì„±ì€ ê±°ì˜ ì—†ë‹¤. ì¸ê³µì§€ëŠ¥(ChatGPT)ì„ ì±…ì„ê° ìˆê³  ìœ¤ë¦¬ì ìœ¼ë¡œ ì‚¬ìš©ë˜ë„ë¡ í•˜ëŠ” ê²ƒì€ ê²°êµ­ ì‚¬ìš©ì ê·€ì±…ì´ë‹¤.\nChatGPTê°€ ê°„ë‹¨í•œ ìˆ«ìê³„ì‚°ì— ë¬¸ì œê°€ ìˆëŠ” ê²ƒì€ ì›¹ìƒì— ì‚°ì¬ëœ ìˆ«ì ê³„ì‚° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„ì‚°ì„ í‰ë‚´ë‚¼ ìˆ˜ëŠ” ìˆìœ¼ë‚˜ ì´ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ChatGPTê°€ í•™ìŠµí•œ ê²ƒì€ ëª…ë°±íˆ ì˜ëª»ëœ ê²ƒì´ë‹¤. ì‚¬ì¹™ì—°ì‚°ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì›ë¦¬ë¥¼ ì´í•´í•˜ê²Œ ë˜ë©´ ì›¹ìƒì— ë‚˜ì˜¨ ì‚¬ì¹™ì—°ì‚° ë¬¸ì œë¥¼ ì •í™•íˆ í•´ê²°í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì›¹ìƒì— ë‚˜ì™€ìˆì§€ ì•ŠëŠ” ê³„ì‚°ë¬¸ì œë„ í’€ ìˆ˜ ìˆìœ¼ë‚˜ í˜„ì¬ëŠ” ê·¸ë ‡ì§€ ëª»í•˜ë‹¤.\n\n\nPNG íŒŒì¼\n(ë¹„)ì†ì‹¤ ì••ì¶•\níŒŒì¼í¬ê¸°\nBMP íŒŒì¼\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nìë£Œì¶œì²˜: WHATâ€™S THE DIFFERENCE BETWEEN JPEG AND PNG: BEGINNER GUIDE"
  },
  {
    "objectID": "architecture.html#ì œë¡ìŠ¤-ë³µì‚¬ê¸°",
    "href": "architecture.html#ì œë¡ìŠ¤-ë³µì‚¬ê¸°",
    "title": "chatGPT",
    "section": "",
    "text": "ë…ì¼ ê³¼í•™ì(David Kriesel)ê°€ ì œë¡ìŠ¤ ë³µì‚¬ê¸°ì—ì„œ ë¬¸ì„œì— ìˆëŠ” ìˆ«ìë¥¼ ë³€ê²½í•˜ëŠ” ê²°í•¨ì„ ë°œê²¬í–ˆë‹¤. ì œë¡ìŠ¤ í”„ë¦°í„°ê°€ ë°©ì˜ ë©´ì ì„ 14.13mÂ²ì—ì„œ 17.42mÂ²ë¡œ ë„“í˜”ê³ , ë‹¤ë¥¸ í”„ë¦°í„°ëŠ” 21.11mÂ²ì—ì„œ 14.13mÂ²ë¡œ ì¤„ì˜€ë‹¤. ìˆ«ì ë¬¸ìì—´ ì¤‘ê°„ì— íŠ¹ì • ìˆ«ì(ì˜ˆ: â€œ6â€ ë˜ëŠ” â€œ8â€)ê°€ ë‚˜íƒ€ë‚˜ë©´ ë³µì‚¬ê¸°ê°€ í•´ë‹¹ ìˆ«ìë¥¼ ë‹¤ë¥¸ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ê²½ìš°ê°€ ë§ì•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€™682â€™ê°€ â€™882â€™ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì²˜ìŒì— ê±´ë¬¼ ì„¤ê³„ë„ë¥¼ ìŠ¤ìº”í•˜ê³  ë¶„ì„í•˜ë ¤ê³  í•  ë•Œ ì´ ë¬¸ì œë¥¼ ë°œê²¬í–ˆë‹¤. ì›ë³¸ì—ëŠ” ì´ëŸ¬í•œ ì˜¤ë¥˜ê°€ ì—†ì—ˆì§€ë§Œ ìŠ¤ìº”í•œ ì‚¬ë³¸ì—ì„œ íŠ¹ì • ìˆ«ìê°€ ë³€ê²½ëœ ê²ƒì„ ë°œê²¬í–ˆë‹¤. ê²°êµ­ ê·¸ë“¤ì€ ì‚¬ë³¸ì„ ë§Œë“œëŠ” ê³¼ì •ì—ì„œ ìˆ«ìê°€ ë³€ê²½ëœ, ì‚¬ìš© ì¤‘ì¸ Xerox ë³µì‚¬ê¸°ì— ë¬¸ì œê°€ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ê¹¨ë‹¬ì•˜ë‹¤.\nì´ ê²°í•¨ì€ ì œë¡ìŠ¤ ë³µì‚¬ê¸°ì— ì‚¬ìš©ë˜ëŠ” ì••ì¶• ì•Œê³ ë¦¬ì¦˜ê³¼ ê´€ë ¨ëœ ê²ƒìœ¼ë¡œ íŠ¹ì • ìˆ«ìê°€ ì„œë¡œ ê°€ê¹Œì´ ìˆìœ¼ë©´ ì•Œê³ ë¦¬ì¦˜ì´ ì´ë¥¼ ë‹¤ë¥¸ ìˆ«ìë¡œ ì°©ê°í•˜ê³  ê·¸ì— ë”°ë¼ ìˆ«ìë¥¼ ë°”ê¾¼ ê²ƒì´ë‹¤. ì´ ë¬¸ì œê°€ ì¼ë¶€ ê³ ê¸‰ ëª¨ë¸ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì œë¡ìŠ¤ ë³µì‚¬ê¸°ì— ì¡´ì¬í•œë‹¤ëŠ” ì‚¬ì‹¤ë„ ë°œê²¬í–ˆë‹¤.\nD. KRIESEL, â€œXerox scanners/photocopiers randomly alter numbers in scanned documentsâ€\n\n\nì„¤ê³„ë„ ë¬¸ì„œ\nìŠ¤ìº” ê²°ê³¼\nì›ê°€í‘œ ìŠ¤ìº”\nìŠ¤ìº” ì˜¤ë¥˜\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nëª¨ë¸: WorkCentre 7535"
  },
  {
    "objectID": "architecture.html#ê¸°ê³„í•™ìŠµ",
    "href": "architecture.html#ê¸°ê³„í•™ìŠµ",
    "title": "chatGPT",
    "section": "\n2.1 ê¸°ê³„í•™ìŠµ",
    "text": "2.1 ê¸°ê³„í•™ìŠµ\në¨¸ì‹ ëŸ¬ë‹ì€ í˜¼ìì„œ í•  ìˆ˜ ìˆëŠ” ì¼ì´ ì•„ë‹™ë‹ˆë‹¤! ML ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•  ë•ŒëŠ” ê³ ê°ë¶€í„° ê³ ê°ê¹Œì§€ ì—”ë“œíˆ¬ì—”ë“œë¡œ ìƒê°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŠ” ì„¤ê³„, ê³„íš ë° ì‹¤í–‰ì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ê³„íšì˜ ì¼í™˜ìœ¼ë¡œ ëˆ„ê°€ ì–¸ì œ ì°¸ì—¬í•´ì•¼ í•˜ëŠ”ì§€ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ í”„ë¡œì íŠ¸ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n\n\nì‘ì—…íë¦„\nì „ì²´ ê°œìš”ë„\në°ì´í„° â†’ í•˜ë“œì›¨ì–´\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nì¸ê³µì§€ëŠ¥(AI) ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì´ íƒ„ìƒí–ˆë‹¤. ê¸°ì´ˆëª¨í˜•(Foundation Model)ì€ ê´‘ë²”ìœ„í•œ ë°ì´í„°ì— ëŒ€í•´ í•™ìŠµëœ ëª¨ë¸ë¡œ, ê´‘ë²”ìœ„í•œ ì‹¤ë¬´í•˜ìœ„ ì‘ì—…ì— í™œìš©í•  ìˆ˜ ìˆë‹¤. í˜„ì¬ BERT, GPT-3, CLIP [Radford ì™¸. 2021] ë“±ì„ ì˜ˆë¡œ ë“¤ ìˆ˜ ìˆë‹¤. (Bommasani ê¸°íƒ€, 2021)\n\n\n\n\n\n\nFeature Engineering\nArchitecture Engineering\nObjective Engineering\nPrompt Engineering\n\n\n\n\n\níŒ¨ëŸ¬ë‹¤ì„: (ë¹„ì‹ ê²½ë§)ì§€ë„í•™ìŠµ (Fully Supervised Learning)\n\nì „ì„±ê¸°: 2015ë…„ê¹Œì§€ ìµœê³  ì „ì„±ê¸° êµ¬ê°€\n\níŠ¹ì§•\n\nì£¼ë¡œ ë¹„ì‹ ê²½ë§ ê¸°ê³„í•™ìŠµì´ ì‚¬ìš©\nìˆ˜ì‘ì—…ìœ¼ë¡œ Featureë¥¼ ì¶”ì¶œ\n\n\n\nëŒ€í‘œì‘\n\nìˆ˜ì‘ì—… Feature ì¶”ì¶œ í›„ SVM(support vector machine) ê¸°ê³„í•™ìŠµ ëª¨í˜•\nìˆ˜ì‘ì—… Feature ì¶”ì¶œ í›„ CRF(conditional random fields)\n\n\n\n\n\n\n\níŒ¨ëŸ¬ë‹¤ì„: ì‹ ê²½ë§ ì§€ë„í•™ìŠµ(Fully Supervised Learning)\n\nì „ì„±ê¸°: ëŒ€ëµ 2013~2018\n\níŠ¹ì§•\n\nì‹ ê²½ë§(Neural Network) ì˜ì¡´\nìˆ˜ì‘ì—…ìœ¼ë¡œ Featureë¥¼ ì†ë³¼ í•„ìš”ëŠ” ì—†ìœ¼ë‚˜ ì‹ ê²½ë§ ë„¤íŠ¸ì›Œí¬ëŠ” ìˆ˜ì •í•´ì•¼ í•¨(LSTM vs CNN)\nì¢…ì¢… ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ëª¨í˜•ì„ ì‚¬ìš©í•˜ë‚˜ ì„ë² ë”©(embedding) ê°™ì€ ì–•ì€(shallow) Featureë¥¼ ì ìš©\n\n\n\nëŒ€í‘œì‘\n\ní…ìŠ¤íŠ¸ ë¶„ë¥˜ì‘ì—…ì— CNN ì‚¬ìš©\n\n\n\n\n\n\n\níŒ¨ëŸ¬ë‹¤ì„: ì‚¬ì „í•™ìŠµ(pre-training), ë¯¸ì„¸ì¡°ì •(fine-tuning)\n\nì „ì„±ê¸°: 2017~í˜„ì¬\n\níŠ¹ì§•\n\nì‚¬ì „í•™ìŠµëœ ì–¸ì–´ëª¨í˜•ì„ ì „ì²´ ëª¨í˜•ì˜ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©\nì•„í‚¤í…ì³ ë””ìì¸ì— ì‘ì—…ì´ ëœ í•„ìš”í•˜ì§€ë§Œ ëª©ì í•¨ìˆ˜(Objective function) ì—”ì§€ë‹ˆì–´ë§ì€ í•„ìš”\n\n\n\nëŒ€í‘œì‘\n\nBERT â†’ Fine Tuning\n\n\n\n\n\n\n\níŒ¨ëŸ¬ë‹¤ì„: ì‚¬ì „í•™ìŠµ(pre-training), í”„ë¡¬í”„íŠ¸(Prompt), ì˜ˆì¸¡(Predict)\n\nì „ì„±ê¸°: 2019~í˜„ì¬\n\níŠ¹ì§•\n\nNLP ì‘ì—…ì´ ì–¸ì–´ëª¨í˜•(Language Model)ì— ì „ì ìœ¼ë¡œ ì˜ì¡´\nì–•ë˜ ê¹Šë˜ Feature ì¶”ì¶œ, ì˜ˆì¸¡ ë“± ì‘ì—…ì´ ì „ì ìœ¼ë¡œ ì–¸ì–´ëª¨í˜•ì— ì˜ì¡´\ní”„ë¡¬í”„íŠ¸ ê³µí•™ì´ í•„ìš”\n\n\n\nëŒ€í‘œì‘\n\nGPT3"
  },
  {
    "objectID": "open_source.html#ë©”íƒ€-ë¼ë§ˆ",
    "href": "open_source.html#ë©”íƒ€-ë¼ë§ˆ",
    "title": "chatGPT",
    "section": "",
    "text": "í˜ì´ìŠ¤ë¶ìœ¼ë¡œ ì˜ ì•Œë ¤ì§„ ë©”íƒ€(Meta)ëŠ” ì—°êµ¬ ëª©ì (ë¹„ìƒì—…ì  ì‚¬ìš©)ìœ¼ë¡œ ë¼ë§ˆ(LLaMA) ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì„ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ë¡œ 2023ë…„ 2ì›” 24ì¼ ê³µê°œí–ˆë‹¤. LLaMAëŠ” ë¼í‹´ì–´ì™€ í‚¤ë¦´ ë¬¸ìë¥¼ ì‚¬ìš©í•˜ëŠ” 20ê°œ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸ë¥¼ í•™ìŠµí•˜ì—¬ ë‹¤ì–‘í•œ í¬ê¸°(7B, 13B, 33B, 65B ë§¤ê°œë³€ìˆ˜) ì–¸ì–´ëª¨í˜• í˜•íƒœë¡œ ê³µê°œë˜ì–´ ê±°ëŒ€ì–¸ì–´ëª¨í˜•ì„ ëŒ€ì¤‘í™”í•˜ê³  ì—°êµ¬ìë“¤ì´ ìƒˆë¡œìš´ ì ‘ê·¼ ë°©ì‹ê³¼ ì‚¬ìš© ì‚¬ë¡€ë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ì·¨ì§€ë¡œ ê³µê°œë˜ì—ˆì§€ë§Œ, ì—¬ì „íˆ í¸í–¥ì„±, ë…ì„±, ì˜ëª»ëœ ì •ë³´ ë“± ì¶”ê°€ì ì¸ ë³´ì™„ì´ í•„ìš”í•˜ë‹¤.\nMetaAI (February 24, 2023), â€œIntroducing LLaMA: A foundational, 65-billion-parameter large language modelâ€, MetaAI Blog"
  },
  {
    "objectID": "interface.html#ìŠ¤ì¹´ì´í”„skeype",
    "href": "interface.html#ìŠ¤ì¹´ì´í”„skeype",
    "title": "chatGPT",
    "section": "\n4.4 ìŠ¤ì¹´ì´í”„(Skeype)",
    "text": "4.4 ìŠ¤ì¹´ì´í”„(Skeype)\n2023ë…„ 2ì›” 22ì¼ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ëŠ” AI ì±—ë´‡ì„ íƒ‘ì¬í•œ ë¹™ê³¼ ì—£ì§€ë¸Œë¼ìš°ì €ì˜ ëª¨ë°”ì¼ ì•±ì„ ê³µê°œí–ˆë‹¤. ì´ì— ë”°ë¼ ìŠ¤ì¹´ì´í”„ì—ì„œë„ ë¹™ì˜ ì±—ë´‡ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìˆê²Œ ëë‹¤.\n\n\nskype ë‹¤ìš´ë¡œë“œ\nBing â€œìƒˆ ì±„íŒ…â€ ì¶”ê°€\nì±—GPT ì‹¤í–‰"
  },
  {
    "objectID": "chatGPT_overview.html",
    "href": "chatGPT_overview.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ì±—GPT ì¸í„°í˜ì´ìŠ¤\nì‚¬ìš©ìê°€ ì§ˆë¬¸ì´ë‚˜ ì§€ì‹œì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ë¡œ ì±—íŒ…ì°½ì— ì „ë‹¬í•˜ë©´ GPT-3/3.5/4 LLM ëª¨í˜•ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì´í•´í•˜ê³  ì§ˆë¬¸ê³¼ ì§€ì‹œì‚¬í•­ì— ë§ëŠ” ì‘ë‹µì„ í…ìŠ¤íŠ¸/ì½”ë“œ/ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•œë‹¤. ì´ ê³¼ì •ì´ ê²€ìƒ‰ê³¼ ë‹¬ë¦¬ í•œë²ˆì— ê·¸ì¹˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ë•Œê¹Œì§€ ë§¥ë½(context)ì„ ìœ ì§€í•œ ìƒíƒœë¡œ ë°˜ë³µëœë‹¤.\n\n\n\n\n\n2 ì±—GPT ì‚¬ìš© ì´ìœ \nì±—GPTëŠ” ë§ì€ ì‘ì—…ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì‚¬ìš©í•œë‹¤. ì˜ˆì‚° ëŒ€ë¹„ ìµœì¢… í”„ë¡œì íŠ¸ ë¹„ìš©(Cost), ì ì‹œ í”„ë¡œì íŠ¸ ì œê³µ(Time), êµ¬ì¶•ëœ í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆ(Quality)ì— ë”°ë¼ ê°€ì¹˜(Value)ê°€ ì¢Œìš°ëœë‹¤. ì±—GPTë¥¼ í†µí•´ ë¹„ìš©ì„ ì¤„ì´ê³ , ì‹œê°„ì„ ë‹¨ì¶•í•˜ê³  í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê²°êµ­ ì±—GPTë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ê°€ ëœë‹¤.(Hardie & Saha, 2012)\n\n\n\n\n\n3 ì±—GPT í•œê³„\n\n2021ë…„ 9ì›”ê¹Œì§€ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì´ë¼ ìµœì‹  ì •ë³´ëŠ” ê°€ì§€ê³  ìˆì§€ ì•Šë‹¤.\n\nì±—GPT í”ŒëŸ¬ê·¸ì¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ê¸€/ë¹™ ë“± ê²€ìƒ‰ ê¸°ëŠ¥ìœ¼ë¡œ ë³´ì™„\n\n\nì±—GPTëŠ” í•™ìŠµë°ì´í„°ì— ë‚´í¬ëœ í¸í–¥ì„±(Bias)\n\n???\n\n\nì±„íŒ…ì— ì§ˆë¬¸ì— ì¼ê´€ì„±ê³¼ ë‹¤ë¥¸ ì£¼ì œë¥¼ ì¤‘êµ¬ë‚œë°©ìœ¼ë¡œ ë’¤ì„ì–´ ì±„íŒ…ì„ ì§„í–‰í•  ê²½ìš° ë¶€ì •í™•ì„±ì´ ì»¤ì§„ë‹¤.\n\në§¥ë½(Context) ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê³  ì£¼ì œê°€ ë°”ë€ŒëŠ” ê²½ìš° New Chatìœ¼ë¡œ ì£¼ì œë¥¼ ë¶„ë¦¬í•˜ì—¬ ì‘ì—…í•œë‹¤.\n\n\ní‹€ë¦° ì‚¬ì‹¤ì„ ë§ˆì¹˜ ì •ë‹µì¸ ê²ƒì²˜ëŸ¼ ì°©ê°í•´ì„œ ë‹µë³€ì„ ì£¼ëŠ” í—ë£¨ì‹œë„¤ì´ì…˜(hallucination).\n\nGPT-4ì™€ ê°™ì€ ì§„í™”ëœ LLM, temperature ë§¤ê°œë³€ìˆ˜ ì§€ì •, ì •êµí•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±ì„ í†µí•´ ì´ëŸ° ë¬¸ì œë¥¼ ì™„í™”ì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n\n\në²•ì  ìœ¤ë¦¬ì  ë¬¸ì œ: ë¹ˆì„¼íŠ¸ ë°˜ ê³ í(í˜¹ì€ ìƒì¡´í™”ê°€) í™”í’ìœ¼ë¡œ AIê°€ ìƒì„±í•œ ê·¸ë¦¼, íŠ¹ì • ë¬¸ì²´ë¥¼ í‰ë‚´ ë‚´ê±°ë‚˜ AIê°€ ì €ì‘í•œ ë…¸ë˜ ë“± ì§€ì  ì°½ì‘ë¬¼ì˜ ì†Œìœ ê¶Œê³¼ í”„ë¼ì´ë²„ì‹œ ë¬¸ì œ\n\nëª…ì˜ˆ, ë¬¸í™”, ì‚¬ì—… ë“± ì´í•´ê´€ê³„ê°€ ê±¸ë¦° ê²½ìš° ì €ì‘ê¶Œ ì „ë¬¸ê°€ì™€ ë²•ë¥ ê°€ì˜ ì¡°ì–¸ì„ ë°›ì•„ ì¶”ì§„í•œë‹¤.\n\n\n\n4 ì±—GPT ì‹œëŒ€ ì—…ë¬´íë¦„\nì±—GPT ì‹œëŒ€ ê¸°ì¡´ ì‚¬ëŒì´ ì¤‘ì‹¬ì´ ë˜ê³  ê¸°ê³„ì˜ ìë™í™” ê¸°ëŠ¥ì„ ì ê·¹ í™œìš©í•˜ì—¬ ìƒì‚°ì„±ì„ ë†’ì´ë˜ ë°©ì‹ì—ì„œ ê¸°ê³„ê°€ ì¤‘ì‹¬ì ìœ¼ë¡œ ì¼ì„ ìˆ˜í–‰í•˜ê³  ì‚¬ëŒì€ ì˜ì‚¬ê²°ì •ê³¼ ê¸°ê³„ê°€ ì‘ì—…í•œ ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  í™•ì¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½ì´ ë¶ˆê°€í”¼í•˜ê²Œ ë³´ì¸ë‹¤. íŠ¹íˆ ê¸°ì¡´ ì‚¬ë¬´ë…¸ë™ì˜ ìƒì‚°ì„±ì˜ í•µì‹¬ì´ ë˜ëŠ” ì˜¤í”¼ìŠ¤ ì œí’ˆ(ì—‘ì…€, ì›Œë“œí”„ë¡œì„¸ì„œ, íŒŒì›Œí¬ì¸íŠ¸)ì— ì¦ê±°ê¸°ë°˜ í–‰ì •ê³¼ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì˜ ê¸‰ê²©í•œ ë„ì…ìœ¼ë¡œ R/íŒŒì´ì¬/SQL ì–¸ì–´ë¥¼ ê²°í•©ì‹œí‚¤ëŠ” RPAê°€ ëŒ€ì„¸ê°€ ë˜ì—ˆìœ¼ë‚˜ ì´ëŸ¬í•œ ì‘ì—…ë°©ì‹ì€ ì‚¬ë¬´ë…¸ë™ìì˜ ì—…ë¬´ëŠ¥ë ¥(ë¬¸ì„œ ìš”ì•½, ì½˜í…ì¸  ìƒì‚° ë“±)ì„ ë³´ì¡°í•˜ëŠ” ê¸°ëŠ¥ì— ë¨¸ë¬´ë¥´ê³  ìˆë‹¤. ì´ì™€ ë°˜ëŒ€ë¡œ ì±—GPTê°€ ë¬¸ì„œìš”ì•½, ì½˜í…ì¸  ìƒì‚° ë“± ì‹œê°„ì„ ì¤„ì´ê³  í’ˆì§ˆì„ ë†’ì¼ ìˆ˜ ìˆëŠ”ë° ë§¤ìš° ì €ë ´í•œ ë¹„ìš©(ì›” 20 ë‹¬ëŸ¬)ìœ¼ë¡œ ì‰¬ì§€ ì•Šê³  ì‘ì—…ì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ì‚¬ë¬´ë…¸ë™ìì˜ ì—…ë¬´ëŠ” ì±—GPT íŠ¹ì„±ì„ ì´í•´í•˜ì—¬ ì‘ì—… ì§€ì‹œë¥¼ ë‚´ë¦¬ëŠ” í”„ë¡¬í”„íŠ¸ ì‘ì„±ê³¼ ì±—GPT ìƒì‚° ê²°ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ì—…ë¬´ê°€ ê°€ì¥ ì¤‘ìš”í•œ ì—…ë¬´ê°€ ë  ê²ƒì´ê³  ê¸°ì¡´ ì˜¤í”¼ìŠ¤ì™€ R/íŒŒì´ì¬/SQLì€ ì´ë¥¼ ë³´ì¢Œí•˜ëŠ” ê¸°ëŠ¥ìœ¼ë¡œ ì¬í¸ë  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ëœë‹¤.\n\n\n\n\nì±—GPT ë„ì… ì „(AS-IS)\n\n\n\n\nì±—GPT ë„ì… í›„(TO-BE)\n\n\n\nê·¸ë¦¼Â 1: ì±—GPT ë„ì…ì— ë”°ë¥¸ ì—…ë¬´ë³€í™”\n\n\n\n5 ì±—GPT ìˆ˜í–‰ê°€ëŠ¥ ì‘ì—…\nì±—GPTê°€ ì‚¬ë¬´ë…¸ë™ìì˜ ì—…ë¬´ë¥¼ ëŒ€ì‹ í•  ìˆ˜ ìˆìœ¼ë‚˜ ëª¨ë“  ì—…ë¬´ë¥¼ ë‹´ë‹¹í•  ìˆ˜ëŠ” ì—†ê³ , ê¸°ë³¸ì ìœ¼ë¡œ ì±—GPTê°€ ìˆ˜í–‰ê°€ëŠ¥í•œ ì—…ë¬´ ë²”ìœ„ëŠ” ì‚¬ëŒì´ ì§ì ‘ í•  ìˆ˜ ì—†ëŠ” ì¼ì„ ChatGPTì— ì§€ì‹œí•˜ë©´ ì•ˆ ëœë‹¤.\n\nì±—GPT ì´ˆê¸° ì •í™•í•œ ì‘ë‹µê²°ê³¼ê°€ ìš”êµ¬ë˜ëŠ” ê²½ìš° ì±—GPT ì‚¬ìš©ì´ ê¶Œì¥ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜ GPT-4ê°€ ì¶œì‹œë˜ê³  ì±—GPT í”ŒëŸ¬ê·¸ì¸ì´ ì¶œì‹œë˜ë©´ì„œ ìˆ˜í•™ê³„ì‚°ê³¼ ê°™ì€ ì—°ì‚°ì‘ì—…ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í†µí•œ ê³„ì‚°ì‘ì—…ì—ë„ ì ìš©ì˜ì—­ì„ ë„“íˆê³  ìˆë‹¤.\nì‘ë‹µí’ˆì§ˆì„ ì‚¬ëŒì´ ì§ì ‘ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê²½ìš° ì±—GPTë¥¼ ì‚¬ìš©í•œë‹¤. ì—¬ì „íˆ í—ë£¨ì‹œë„¤ì´ì…˜(hallucination) ë¬¸ì œê°€ í•´ê²°ë˜ì§€ ì•Šì•˜ê³  ì„±, ë‚˜ì´, ì§ì—…, ì¸ì¢…, ì¢…êµ ë“±ì— ëŒ€í•œ í¸í–¥ì„±ì´ ì¡´ì¬í•˜ê³  ë¶€ì •ì ì¸ í…ìŠ¤íŠ¸ê°€ ì‘ë‹µìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš° ì±…ì„ìê°€ ê±¸ëŸ¬ë‚´ì•¼í•œë‹¤.\nì£¼ë¯¼ë²ˆí˜¸, ì½”ë“œ, ê³µì •ìˆ˜ìœ¨ ë“± ë¯¼ê°ë°ì´í„°(Sensitive Data)ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ ì±—GPTì— ì „ë‹¬í•  ê²½ìš° ë³´ì•ˆ ë“± ë¬¸ì œê°€ ìˆì–´ ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•œë‹¤.\nì½˜í…ì¸  ì €ì‘ê¶Œì´ ì´ìŠˆê°€ ë˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” ì ê·¹ ì‚¬ìš©í•˜ê³  ê²½ìš°ì— ë”°ë¼ ì €ì‘ê¶Œ ì´ìŠˆê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ê²½ìš° ì£¼ì˜í•´ì„œ ë²•ë¥ ìë¬¸ ë“±ì„ ë°›ì•„ í›„ì† ì—…ë¬´ë¥¼ ì§„í–‰í•œë‹¤.\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nHardie, M., & Saha, S. (2012). Builders Perceptions of Lowest Cost Procurement and Its Impact on Quality. Construction Economics and Building, 9(1), 1â€“8. https://doi.org/10.5130/ajceb.v9i1.3009"
  },
  {
    "objectID": "langchain_arch.html",
    "href": "langchain_arch.html",
    "title": "chatGPT",
    "section": "",
    "text": "AI ì•± ê°œë°œì€ ì „í†µì ìœ¼ë¡œ ê²€ì¦ëœ ê°œë°œë°©ë²•ë¡ ì— ê¸°ë°˜í•œë‹¤. í•œê°€ì§€ ì¤‘ìš”í•œ ì ì€ ê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì´ ì—”ì§„ìœ¼ë¡œ ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. ë¹„ìœ ë¥¼ í•˜ìë©´ ìš´ì˜ì²´ì œ UNIXì— ë¹„ê²¬ëœë‹¤. ê°•ë ¥í•œ ë°ì´í„° ê¸°ë°˜ LLM ì—”ì§„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ ê³ ì„±ëŠ¥ AI ì•± ê°œë°œì´ ê°€ëŠ¥í•˜ë‹¤.\n\n\ní­í¬ìˆ˜ ëª¨í˜•\nV-ëª¨í˜•\nìŠ¤í¬ëŸ¼\nê¸°ê³„í•™ìŠµ ê°œë°œ\nAI ì•± ê°œë°œ\n\n\n\n\n\n\n\ngraph TD\n    A[ìš”êµ¬ì‚¬í•­] --&gt; B[ì•„í‚¤í…ì³/ë””ìì¸]\n    B --&gt; C[êµ¬í˜„]\n    C --&gt; D[ê²€ì¦/í…ŒìŠ¤íŠ¸]\n    D --&gt; E[ìœ ì§€ë³´ìˆ˜]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nê·¸ë¦¼Â 1: ?(caption)"
  },
  {
    "objectID": "langchain_arch.html#í™˜ê²½ì„¤ì •",
    "href": "langchain_arch.html#í™˜ê²½ì„¤ì •",
    "title": "chatGPT",
    "section": "\n4.1 í™˜ê²½ì„¤ì •",
    "text": "4.1 í™˜ê²½ì„¤ì •\nLangChain ì—ì„œ OpenAI chatGPTë¥¼ í˜¸ì¶œí•˜ì—¬ ì›í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ë¨¼ì € openaiì™€ langchainì„ ì„¤ì¹˜í•œë‹¤.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¥¼ ë„£ì–´ë‘ê³  OpenAI() í•¨ìˆ˜ì—ì„œ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.\n\nimport os\nfrom langchain.llms import OpenAI\n\nos.environ['OPENAI_API_TOKEN'] = os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "langchain_arch.html#ë†ë‹´",
    "href": "langchain_arch.html#ë†ë‹´",
    "title": "chatGPT",
    "section": "\n4.2 ë†ë‹´",
    "text": "4.2 ë†ë‹´\nê·¸ë¦¬ê³  ë‚˜ì„œ, ë†ë‹´ìœ¼ë¡œ í—¬ë¡œì›”ë“œë¥¼ ì°ì–´ë³¸ë‹¤. model_nameì„ ë¹„ë¡¯í•œ ì¸ìˆ˜ë¥¼ ì‘ë‹µì†ë„, ì •í™•ë„, ê°„ê²°í•¨, ì°½ì˜ì„±, ë¹„ìš© ë“±ì„ ê³ ë ¤í•˜ì—¬ ì§€ì •í•˜ì—¬ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì–´ë‚¸ë‹¤.\n\nllm = OpenAI(model_name=\"text-davinci-003\", n=1, temperature=0.9)\nllm(\"ì¬ë¯¸ìˆëŠ” ë†ë‹´í•´ ì£¼ì„¸ìš”\")\n#&gt; '\\n\\në„ë‘‘ì´ ì˜ìë¥¼ í›”ì³ê°”ëŠ”ë° ì‚¬ëŒë“¤ì´ \"ëª¸í†µë§Œ í›”ì³ê°”ë„¤!\"ë¼ê³  í–ˆì–´ìš”.\\n\\në„ë‘‘ì´ ë‹µí•˜ê¸°ë¡œ \"ì˜ìê°€ ì œ ëª¸í†µì´ì—ìš”!\"ë¼ê³  í–ˆì–´ìš”.'\n\n3ê°œ ë†ë‹´ì„ ë½‘ì•„ë³´ì.\n\nllm_result = llm.generate([\"ì¬ë¯¸ìˆëŠ” ë†ë‹´í•´ ì£¼ì„¸ìš”\"]*3)\nllm_jokes = llm_result.generations\nllm_jokes\n#&gt; [[Generation(text='\\n\\nQ. ë‚ ê°œê°€ ìˆëŠ” ë™ë¬¼ì€ ë¬´ì—‡ì¸ê°€ìš”?\\nA. ìƒˆìš”!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\nQ. ë°”ëŒì— ë¹„ê°€ ë‚´ë ¤ê°€ë©´ ì–´ë–»ê²Œ í•©ë‹ˆê¹Œ?\\nA. ì—´ì‡ ë¥¼ ë†“ì¹˜ì§€ ë§ê³  ì§‘ì— ë“¤ì–´ê°€ì„¸ìš”!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. ë¬´ì—‡ì´ ë¹„ë¹„ëŠ” ì§ˆë¬¸ì´ì—ˆë‹¤ê³  í•˜ë©´? \\n\\nA. ë¹„ê°€ ì™œ ì˜¤ëŠ” ê±¸ê¹Œìš”?', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
  },
  {
    "objectID": "langchain_arch.html#í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿",
    "href": "langchain_arch.html#í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿",
    "title": "chatGPT",
    "section": "\n4.3 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿",
    "text": "4.3 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\ní”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‘ì„±í•˜ì—¬ í•´ë‹¹ ì‘ì—…ì„ ìˆ˜í–‰í† ë¡ ì§€ì‹œí•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ”ë° ëŒ€í‘œì ìœ¼ë¡œ ì˜ ì‘ëª…ëœ íšŒì‚¬ëª…ì„ ì œì‹œí•˜ê³  ì œì•½ ì¡°ê±´ì„ ì¶”ê°€ë¡œ ë‘” í›„ íšŒì‚¬ëª… ì‘ëª…ì§€ì‹œë¥¼ ìˆ˜í–‰ì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n\n4.3.1 ì˜ë¬¸\në­ì²´ì¸ ë¬¸ì„œì— ë‚˜ì™€ìˆëŠ” ì˜ˆì œë¥¼ ì‚¬ìš©í•´ì„œ PromptTemplateìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±í•´ë³´ì.\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n\n\nlibrary(reticulate)\nsocks_prompt_chr &lt;- py$socks_prompt\ncat(socks_prompt_chr)\n#&gt; \n#&gt; I want you to act as a naming consultant for new companies.\n#&gt; \n#&gt; Here are some examples of good company names:\n#&gt; \n#&gt; - search engine, Google\n#&gt; - social media, Facebook\n#&gt; - video sharing, YouTube\n#&gt; \n#&gt; The name should be short, catchy and easy to remember.\n#&gt; \n#&gt; What is a good name for a company that makes colorful socks?\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; BrightSox.\n\n\n4.3.2 êµ­ë¬¸\nì•ì„œ ì œì‘ëœ ì˜ë¬¸íšŒì‚¬ ì‘ëª… í…œí”Œë¦¿ì„ ë²ˆì—­í•˜ì—¬ êµ­ë‚´ ëª‡ê°€ì§€ íšŒì‚¬ë¥¼ ì‚¬ë¡€ë¡œ ë„£ì–´ chatGPTì— ì‘ì—…ì„ ì§€ì‹œí•œë‹¤.\n\n\nk_template = \"\"\"\nì‹ ê·œ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ” ì»¨ì„¤í„´íŠ¸ë¡œ í™œë™í•´ ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\n\në‹¤ìŒì€ ì¢‹ì€ íšŒì‚¬ ì´ë¦„ ëª‡ ê°€ì§€ ì‚¬ë¡€ì…ë‹ˆë‹¤:\n\n- ì¼€ì´í‹°, í†µì‹ \n- ë†€ë¶€, ì™¸ì‹í”„ëœì°¨ì´ì¦ˆ\n- ìœ¨ë„êµ­, ë¸Œëœë“œì œì‘\n- í¬ëª½, ì•„ì›ƒì†Œì‹± í”Œë«í¼\n\nì´ë¦„ì€ ì§§ê³  ëˆˆì— ì˜ ë„ë©° ê¸°ì–µí•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.\n\n{k_product} ì œí’ˆì„ ì˜ ë§Œë“œëŠ” íšŒì‚¬ì˜ ì¢‹ì€ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"ì–‘ë§\")\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"ì–‘ë§\")\n\n\ncat(py$k_socks_result)\n#&gt; \n#&gt; - ìŠ¬ë¦½ê·¸ë©, ìŠ¤íƒ€í”Œë˜ê·¸, ì†Œë‹¤ë¥´íŠ¸, ìŠ¤ìœ„íŠ¸ìŠ¤ì›¨ì´ë“œ, ì½”ì‹±í´ëŸ½, ë ˆì´í¬í˜ë¦¬"
  },
  {
    "objectID": "langchain_arch.html#ì˜ë¬¸",
    "href": "langchain_arch.html#ì˜ë¬¸",
    "title": "chatGPT",
    "section": "\n4.4 ì˜ë¬¸",
    "text": "4.4 ì˜ë¬¸\në­ì²´ì¸ ë¬¸ì„œì— ë‚˜ì™€ìˆëŠ” ì˜ˆì œë¥¼ ì‚¬ìš©í•´ì„œ PromptTemplateìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±í•´ë³´ì.\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n\n\nlibrary(reticulate)\nsocks_prompt_chr &lt;- py$socks_prompt\ncat(socks_prompt_chr)\n#&gt; \n#&gt; I want you to act as a naming consultant for new companies.\n#&gt; \n#&gt; Here are some examples of good company names:\n#&gt; \n#&gt; - search engine, Google\n#&gt; - social media, Facebook\n#&gt; - video sharing, YouTube\n#&gt; \n#&gt; The name should be short, catchy and easy to remember.\n#&gt; \n#&gt; What is a good name for a company that makes colorful socks?\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; FancyToes!"
  },
  {
    "objectID": "langchain_arch.html#êµ­ë¬¸",
    "href": "langchain_arch.html#êµ­ë¬¸",
    "title": "chatGPT",
    "section": "\n4.5 êµ­ë¬¸",
    "text": "4.5 êµ­ë¬¸\nì•ì„œ ì œì‘ëœ ì˜ë¬¸íšŒì‚¬ ì‘ëª… í…œí”Œë¦¿ì„ ë²ˆì—­í•˜ì—¬ êµ­ë‚´ ëª‡ê°€ì§€ íšŒì‚¬ë¥¼ ì‚¬ë¡€ë¡œ ë„£ì–´ chatGPTì— ì‘ì—…ì„ ì§€ì‹œí•œë‹¤.\n\n\nk_template = \"\"\"\nì‹ ê·œ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ” ì»¨ì„¤í„´íŠ¸ë¡œ í™œë™í•´ ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\n\në‹¤ìŒì€ ì¢‹ì€ íšŒì‚¬ ì´ë¦„ ëª‡ ê°€ì§€ ì‚¬ë¡€ì…ë‹ˆë‹¤:\n\n- ì¼€ì´í‹°, í†µì‹ \n- ë†€ë¶€, ì™¸ì‹í”„ëœì°¨ì´ì¦ˆ\n- ìœ¨ë„êµ­, ë¸Œëœë“œì œì‘\n- í¬ëª½, ì•„ì›ƒì†Œì‹± í”Œë«í¼\n\nì´ë¦„ì€ ì§§ê³  ëˆˆì— ì˜ ë„ë©° ê¸°ì–µí•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.\n\n{k_product} ì œí’ˆì„ ì˜ ë§Œë“œëŠ” íšŒì‚¬ì˜ ì¢‹ì€ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"ì–‘ë§\")\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"ì–‘ë§\")\n\n\ncat(py$k_socks_result)\n#&gt; \n#&gt; - ë¶€ë””, ì–‘ë§\n#&gt; - ìŠ¤íŠ¸ë©í‚¤, ì–‘ë§\n#&gt; - ì†Œí”„íŠ¸í”Œë¦½, ì–‘ë§\n#&gt; - ë°”ì´íŠ¸, ì–‘ë§"
  },
  {
    "objectID": "langchain_arch.html#ìš”ì•½",
    "href": "langchain_arch.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n4.4 ìš”ì•½",
    "text": "4.4 ìš”ì•½\nopenAI Tokenizer\ní•œê¸€ì€ ì˜ì–´ì— ë¹„í•´ í† í° í¬ê¸°ê°€ í¬ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ text-davinci-003 ëª¨ë¸ì´ ì†Œí™”í•  ìˆ˜ ìˆëŠ” í† í°ë³´ë‹¤ í¬ê¸°ë¥¼ ì¤„ì—¬ì•¼í•œë‹¤. ëŒ€í•œë¯¼êµ­ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ ì¤‘ ë°•ê·¼í˜œ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ì—ì„œ ëŒ€ëµ 2,000 í† í° í¬ê¸°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ë¬¸ì„œ ìš”ì•½ì„ ìˆ˜í–‰í•´ë³´ì.\n\nfrom langchain import OpenAI, PromptTemplate, LLMChain\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0)\n\ntext_splitter = CharacterTextSplitter()\n\nwith open('data/state_of_the_union.txt') as f:\n# with open('data/ì·¨ì„ì‚¬.txt') as f:\n    inaugural_address  = f.read()\n    \ntexts = text_splitter.split_text(inaugural_address)\n\nfrom langchain.docstore.document import Document\n\ndocs = [Document(page_content=t) for t in texts[:]]\n\nfrom langchain.chains.summarize import load_summarize_chain\n\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\nchain.run(docs)"
  },
  {
    "objectID": "whisper.html",
    "href": "whisper.html",
    "title": "chatGPT",
    "section": "",
    "text": "OpenSLRì€ ìŒì„± ì¸ì‹ì„ ìœ„í•œ í•™ìŠµìš© ë§ë­‰ì¹˜, ìŒì„± ì¸ì‹ ê´€ë ¨ ì†Œí”„íŠ¸ì›¨ì–´ ë“± ìŒì„± ë° ì–¸ì–´ ìì›ì„ ì œê³µí•˜ê³  ìˆë‹¤.\n\nëŒ€ê·œëª¨(1000ì‹œê°„) ì˜ì–´ ìŒì„± ì½ê¸° ë§ë­‰ì¹˜ì—ì„œ ì˜ì–´ ìŒì„± ì½ê¸° í•˜ë‚˜ë¥¼ ì¶”ì¶œí•´ì„œ ê´€ë ¨ ì‚¬í•­ì„ ì •ë‹µë¬¸ê³¼ ë¹„êµí•´ë³´ì.\n\n\n\n\nëŒ€ê·œëª¨(1000ì‹œê°„) ì˜ì–´ ìŒì„± ì½ê¸° ë§ë­‰ì¹˜ì— í¬í•¨ëœ ì˜ì–´ìŒì„±ëŒ€ë³¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì„œ ë‹¤ìŒì— ì˜ì–´ ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ë¹„êµí•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n# fs::dir_ls(path=\"data/LibriSpeech/dev-clean/1993/147149\")\n\ntrans_txt &lt;- read_lines(\"data/LibriSpeech/dev-clean/1993/147149/1993-147149.trans.txt\") \n\n# trans_0011_str &lt;- trans_txt[str_detect(trans_txt, \"0011\")]\n# trans_str &lt;- str_extract_all(trans_0011_str, \"[a-zA-Z].+\")[[1]]\n\ntrans_0011 &lt;- trans_txt %&gt;% \n  enframe() %&gt;% \n  separate(value, into = c(\"ìˆœë²ˆ\", \"í…ìŠ¤íŠ¸\"), sep = \"\\\\s\", extra = \"merge\") %&gt;% \n  mutate(í…ìŠ¤íŠ¸ = str_to_lower(í…ìŠ¤íŠ¸)) %&gt;% \n  filter(str_detect(ìˆœë²ˆ, \"0011\")) %&gt;% \n  pull(í…ìŠ¤íŠ¸)\n\n\nthen the mother lifted up her voice and wept\n\n\n\nì˜ì–´ ìŒì„±ì„ ë“¤ì–´ë³´ì. .flac íŒŒì¼ì„ av íŒ¨í‚¤ì§€ av_audio_convert() í•¨ìˆ˜ë¡œ .mp3 í˜¹ì€ .wav íŒŒì¼ ë³€í™˜ì´ ê°€ëŠ¥í•˜ë‹¤.\n\nì½”ë“œlibrary(av)\nlibrary(embedr)\n\naudio_file &lt;- \"data/LibriSpeech/dev-clean/1993/147149/1993-147149-0011.flac\"\n\nav::av_audio_convert(audio_file, output = \"data/whisper_before.mp3\", \n                     format = \"mp3\", sample_rate = 16000)\n#&gt; [1] \"D:\\\\tcs\\\\chatGPT\\\\data\\\\whisper_before.mp3\"\n\nwhisper_before_mp3 &lt;- av::read_audio_bin(\"data/whisper_before.mp3\")\n\nembedr::embed_audio(\"data/whisper_before.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "whisper.html#í™˜ê²½ì„¤ì •",
    "href": "whisper.html#í™˜ê²½ì„¤ì •",
    "title": "chatGPT",
    "section": "\n4.1 í™˜ê²½ì„¤ì •",
    "text": "4.1 í™˜ê²½ì„¤ì •\nLangChain ì—ì„œ OpenAI chatGPTë¥¼ í˜¸ì¶œí•˜ì—¬ ì›í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ë¨¼ì € openaiì™€ langchainì„ ì„¤ì¹˜í•œë‹¤.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¥¼ ë„£ì–´ë‘ê³  OpenAI() í•¨ìˆ˜ì—ì„œ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.\n\nimport os\nfrom langchain.llms import OpenAI\n\nos.environ['OPENAI_API_TOKEN'] = os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "whisper.html#ë†ë‹´",
    "href": "whisper.html#ë†ë‹´",
    "title": "chatGPT",
    "section": "\n4.2 ë†ë‹´",
    "text": "4.2 ë†ë‹´\nê·¸ë¦¬ê³  ë‚˜ì„œ, ë†ë‹´ìœ¼ë¡œ í—¬ë¡œì›”ë“œë¥¼ ì°ì–´ë³¸ë‹¤. model_nameì„ ë¹„ë¡¯í•œ ì¸ìˆ˜ë¥¼ ì‘ë‹µì†ë„, ì •í™•ë„, ê°„ê²°í•¨, ì°½ì˜ì„±, ë¹„ìš© ë“±ì„ ê³ ë ¤í•˜ì—¬ ì§€ì •í•˜ì—¬ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì–´ë‚¸ë‹¤.\n\nllm = OpenAI(model_name=\"text-davinci-003\", n=1, temperature=0.9)\nllm(\"ì¬ë¯¸ìˆëŠ” ë†ë‹´í•´ ì£¼ì„¸ìš”\")\n#&gt; '\\n\\nQ. ì–´ë””ê°€ëŠ” ì—´ì°¨ëŠ” ì–´ë””ê¹Œì§€ ê°€ë‚˜ìš”? \\nA. ê¼¬ë¦¬ì¹˜ê¸°ë¡œ ê°‘ë‹ˆë‹¤!'\n\n3ê°œ ë†ë‹´ì„ ë½‘ì•„ë³´ì.\n\nllm_result = llm.generate([\"ì¬ë¯¸ìˆëŠ” ë†ë‹´í•´ ì£¼ì„¸ìš”\"]*3)\nllm_jokes = llm_result.generations\nllm_jokes\n#&gt; [[Generation(text='\\n\\nQ. ì™œ ë¼ì§€ê°€ ë¬¼ ì†ì— ë¹ ì¡Œë‚˜ìš”?\\n\\nA. ê·¸ê±´ ì£¼ì¸ì´ ë¼ì§€ë¥¼ ì‚°ì±…ì‹œí‚¤ê¸° ìœ„í•´ ë¬¼ ì†ê¹Œì§€ ê°”ê¸° ë•Œë¬¸ì´ì£ .', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. ì–´ë””ì„œ ì†ë‹˜ì´ ê°€ì¥ ë§ì€ê°€?\\n\\nA. ë¹µì§‘ ë°”ê¹¥ì—ì„œ! ì™œëƒí•˜ë©´ ë¹µì´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê±°ë‹ˆê¹Œìš”!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. ì™œ ì†ŒëŠ” ë¬¼ì„ ë§ˆì‹œì§€ ì•Šë‚˜ìš”?\\n\\nA. ì™œëƒí•˜ë©´ ì†ŒëŠ” ë¬¼ì´ ë„ˆë¬´ ë§ëê¸° ë•Œë¬¸ì´ì£ !', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
  },
  {
    "objectID": "whisper.html#í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿",
    "href": "whisper.html#í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿",
    "title": "chatGPT",
    "section": "\n4.3 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿",
    "text": "4.3 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\ní”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‘ì„±í•˜ì—¬ í•´ë‹¹ ì‘ì—…ì„ ìˆ˜í–‰í† ë¡ ì§€ì‹œí•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ”ë° ëŒ€í‘œì ìœ¼ë¡œ ì˜ ì‘ëª…ëœ íšŒì‚¬ëª…ì„ ì œì‹œí•˜ê³  ì œì•½ ì¡°ê±´ì„ ì¶”ê°€ë¡œ ë‘” í›„ íšŒì‚¬ëª… ì‘ëª…ì§€ì‹œë¥¼ ìˆ˜í–‰ì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n\n4.3.1 ì˜ë¬¸\në­ì²´ì¸ ë¬¸ì„œì— ë‚˜ì™€ìˆëŠ” ì˜ˆì œë¥¼ ì‚¬ìš©í•´ì„œ PromptTemplateìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±í•´ë³´ì.\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n\n\nlibrary(reticulate)\nsocks_prompt_chr &lt;- py$socks_prompt\ncat(socks_prompt_chr)\n#&gt; \n#&gt; I want you to act as a naming consultant for new companies.\n#&gt; \n#&gt; Here are some examples of good company names:\n#&gt; \n#&gt; - search engine, Google\n#&gt; - social media, Facebook\n#&gt; - video sharing, YouTube\n#&gt; \n#&gt; The name should be short, catchy and easy to remember.\n#&gt; \n#&gt; What is a good name for a company that makes colorful socks?\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; - Snazzy Socks\n\n\n4.3.2 êµ­ë¬¸\nì•ì„œ ì œì‘ëœ ì˜ë¬¸íšŒì‚¬ ì‘ëª… í…œí”Œë¦¿ì„ ë²ˆì—­í•˜ì—¬ êµ­ë‚´ ëª‡ê°€ì§€ íšŒì‚¬ë¥¼ ì‚¬ë¡€ë¡œ ë„£ì–´ chatGPTì— ì‘ì—…ì„ ì§€ì‹œí•œë‹¤.\n\n\nk_template = \"\"\"\nì‹ ê·œ íšŒì‚¬ëª…ì„ ì‘ëª…í•˜ëŠ” ì»¨ì„¤í„´íŠ¸ë¡œ í™œë™í•´ ì£¼ì…¨ìœ¼ë©´ í•©ë‹ˆë‹¤.\n\në‹¤ìŒì€ ì¢‹ì€ íšŒì‚¬ ì´ë¦„ ëª‡ ê°€ì§€ ì‚¬ë¡€ì…ë‹ˆë‹¤:\n\n- ì¼€ì´í‹°, í†µì‹ \n- ë†€ë¶€, ì™¸ì‹í”„ëœì°¨ì´ì¦ˆ\n- ìœ¨ë„êµ­, ë¸Œëœë“œì œì‘\n- í¬ëª½, ì•„ì›ƒì†Œì‹± í”Œë«í¼\n\nì´ë¦„ì€ ì§§ê³  ëˆˆì— ì˜ ë„ë©° ê¸°ì–µí•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.\n\n{k_product} ì œí’ˆì„ ì˜ ë§Œë“œëŠ” íšŒì‚¬ì˜ ì¢‹ì€ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"ì–‘ë§\")\n\nì•ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì§€ì •í•œ í›„ ì‹¤í–‰ì„ í†µí•´ ì›í•˜ëŠ” íšŒì‚¬ëª… ì‘ëª… ì‘ì—…ì„ ìˆ˜í–‰ì‹œí‚¨ë‹¤.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"ì–‘ë§\")\n\n\ncat(py$k_socks_result)\n#&gt; \n#&gt; - ìŠˆìŠˆ, ì–‘ë§\n#&gt; - ì†”ë ˆì¸, ì–‘ë§\n#&gt; - ë°”ë°”ì‹œ, ì–‘ë§\n#&gt; - ìŠ¤ëª°í•˜ìš°ìŠ¤, ì–‘ë§"
  },
  {
    "objectID": "whisper.html#ìš”ì•½",
    "href": "whisper.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n4.4 ìš”ì•½",
    "text": "4.4 ìš”ì•½\nopenAI Tokenizer\ní•œê¸€ì€ ì˜ì–´ì— ë¹„í•´ í† í° í¬ê¸°ê°€ í¬ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ text-davinci-003 ëª¨ë¸ì´ ì†Œí™”í•  ìˆ˜ ìˆëŠ” í† í°ë³´ë‹¤ í¬ê¸°ë¥¼ ì¤„ì—¬ì•¼í•œë‹¤. ëŒ€í•œë¯¼êµ­ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ ì¤‘ ë°•ê·¼í˜œ ëŒ€í†µë ¹ ì·¨ì„ì‚¬ì—ì„œ ëŒ€ëµ 2,000 í† í° í¬ê¸°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ë¬¸ì„œ ìš”ì•½ì„ ìˆ˜í–‰í•´ë³´ì.\n\nfrom langchain import OpenAI, PromptTemplate, LLMChain\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0)\n\ntext_splitter = CharacterTextSplitter()\n\nwith open('data/state_of_the_union.txt') as f:\n# with open('data/ì·¨ì„ì‚¬.txt') as f:\n    inaugural_address  = f.read()\n    \ntexts = text_splitter.split_text(inaugural_address)\n\nfrom langchain.docstore.document import Document\n\ndocs = [Document(page_content=t) for t in texts[:]]\n\nfrom langchain.chains.summarize import load_summarize_chain\n\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\nchain.run(docs)"
  },
  {
    "objectID": "whisper.html#ì˜¤ë””ì˜¤-í‘œë³¸",
    "href": "whisper.html#ì˜¤ë””ì˜¤-í‘œë³¸",
    "title": "chatGPT",
    "section": "",
    "text": "ëŒ€ê·œëª¨(1000ì‹œê°„) ì˜ì–´ ìŒì„± ì½ê¸° ë§ë­‰ì¹˜ì—ì„œ ì˜ì–´ ìŒì„± ì½ê¸° í•˜ë‚˜ë¥¼ ì¶”ì¶œí•´ì„œ ê´€ë ¨ ì‚¬í•­ì„ ì •ë‹µë¬¸ê³¼ ë¹„êµí•´ë³´ì.\n\n\n\n\nëŒ€ê·œëª¨(1000ì‹œê°„) ì˜ì–´ ìŒì„± ì½ê¸° ë§ë­‰ì¹˜ì— í¬í•¨ëœ ì˜ì–´ìŒì„±ëŒ€ë³¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì„œ ë‹¤ìŒì— ì˜ì–´ ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ë¹„êµí•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n# fs::dir_ls(path=\"data/LibriSpeech/dev-clean/1993/147149\")\n\ntrans_txt &lt;- read_lines(\"data/LibriSpeech/dev-clean/1993/147149/1993-147149.trans.txt\") \n\n# trans_0011_str &lt;- trans_txt[str_detect(trans_txt, \"0011\")]\n# trans_str &lt;- str_extract_all(trans_0011_str, \"[a-zA-Z].+\")[[1]]\n\ntrans_0011 &lt;- trans_txt %&gt;% \n  enframe() %&gt;% \n  separate(value, into = c(\"ìˆœë²ˆ\", \"í…ìŠ¤íŠ¸\"), sep = \"\\\\s\", extra = \"merge\") %&gt;% \n  mutate(í…ìŠ¤íŠ¸ = str_to_lower(í…ìŠ¤íŠ¸)) %&gt;% \n  filter(str_detect(ìˆœë²ˆ, \"0011\")) %&gt;% \n  pull(í…ìŠ¤íŠ¸)\n\n\nthen the mother lifted up her voice and wept\n\n\n\nì˜ì–´ ìŒì„±ì„ ë“¤ì–´ë³´ì. .flac íŒŒì¼ì„ av íŒ¨í‚¤ì§€ av_audio_convert() í•¨ìˆ˜ë¡œ .mp3 í˜¹ì€ .wav íŒŒì¼ ë³€í™˜ì´ ê°€ëŠ¥í•˜ë‹¤.\n\nì½”ë“œlibrary(av)\nlibrary(embedr)\n\naudio_file &lt;- \"data/LibriSpeech/dev-clean/1993/147149/1993-147149-0011.flac\"\n\nav::av_audio_convert(audio_file, output = \"data/whisper_before.mp3\", \n                     format = \"mp3\", sample_rate = 16000)\n#&gt; [1] \"D:\\\\tcs\\\\chatGPT\\\\data\\\\whisper_before.mp3\"\n\nwhisper_before_mp3 &lt;- av::read_audio_bin(\"data/whisper_before.mp3\")\n\nembedr::embed_audio(\"data/whisper_before.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "whisper.html#ë™ì˜ìƒì—ì„œ-ì˜¤ë””ì˜¤-ì¶”ì¶œ",
    "href": "whisper.html#ë™ì˜ìƒì—ì„œ-ì˜¤ë””ì˜¤-ì¶”ì¶œ",
    "title": "chatGPT",
    "section": "\n3.1 ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ",
    "text": "3.1 ë™ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ\nffmpeg í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ë©´ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë‹¤. MP4 íŒŒì¼ì—ì„œ 16ë¹„íŠ¸ ê¹Šì´ì™€ 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¡œ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œí•˜ì—¬ì•¼ whisperì— ì…ë ¥ê°’ìœ¼ë¡œ ë„£ì„ ìˆ˜ ìˆëŠ” .wav íŒŒì¼ì´ ëœë‹¤. ë‘ê°€ì§€ ì¡°ê±´(16ë¹„íŠ¸ ê¹Šì´ì™€ 16kHz ìƒ˜í”Œë§)ì´ ì¶©ì¡±ë˜ì§€ ì•Šì„ ê²½ìš° Whisperì—ì„œ ì²˜ë¦¬í•  ìˆ˜ ì—†ë‹¤ëŠ” ì˜¤ë¥˜ê°€ ë‚˜ì˜¨ë‹¤.\n\n\n\n.mp4ì—ì„œ .wav ì¶”ì¶œ\nffmpeg -i misinformation.mp4 -acodec pcm_s16le -ar 16000 -ac 2 misinformation_16.wav\n\n\n\n.mp4ì—ì„œ .mp3 ì¶”ì¶œ\n.mp3 í™•ì¥ìë¥¼ ì¤„ ê²½ìš° ì˜¤ë””ì˜¤ë¥¼ mp3 íŒŒì¼ë¡œ ì¶”ì¶œí•˜ì—¬ íŒŒì¼í¬ê¸°ë¥¼ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆë‹¤.\nffmpeg -i misinformation.mp4 -acodec pcm_s16le -ar 16000 -ac 2 misinformation.mp3\n\n\n\nì „ì²´ .mp3 íŒŒì¼ì´ ë„ˆë¬´ ê¸¸ì–´ ffmpegë¥¼ ì‚¬ìš©í•´ì„œ 30ë¶„ë¶€í„° 30ì´ˆë§Œ ì¶”ì¶œí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì„œ ë“¤ì–´ë³´ì.\nffmpeg -i misinformation.mp3 -ss 00:30:30 -t 00:00:30 -vn -codec:a libmp3lame -qscale:a 2 misinformation_short.mp3\n\nì½”ë“œembedr::embed_audio(\"data/LibriSpeech/misinformation_short.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "whisper.html#stt",
    "href": "whisper.html#stt",
    "title": "chatGPT",
    "section": "\n3.2 STT",
    "text": "3.2 STT\n16ë¹„íŠ¸ ê¹Šì´ì™€ 16kHz ìƒ˜í”Œë§ ì¡°ê±´ì„ ê°–ì¶˜ .wav íŒŒì¼ì´ ì¤€ë¹„ë˜ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ Whisper ëª¨ë¸ì„ ì„ ì •í•˜ì—¬ í…ìŠ¤íŠ¸ ì „ì‚¬ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ìœˆë„ìš° 10 ì—ì„œ 2.6 GB ì˜ì–´ medium.en ëª¨ë¸ì€ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ì¸í•´ base.en ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆë‹¤.\n\nì½”ë“œlibrary(audio.whisper)\n\nmedium_model &lt;- whisper(\"base.en\")\n\nmisinformation_trans &lt;- predict(medium_model, newdata = \"data/LibriSpeech/misinformation_16.wav\", \n                                language = \"en\", n_threads = 2)\n\n\nWhisper ëª¨ë¸ì„ í†µí•´ ë‚˜ì˜¨ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼ë¥¼ ë¡œì»¬ íŒŒì¼ì— ì €ì¥í•˜ì—¬ ì ê²€í•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nmisinformation_trans$data %&gt;% \n  mutate(data = glue::glue(\"{from} ==&gt; {to} {text}\")) %&gt;% \n  pull(data) %&gt;% \n  write_lines(\"data/LibriSpeech/misinformation_oneline.txt\")"
  },
  {
    "objectID": "whisper.html#srt",
    "href": "whisper.html#srt",
    "title": "chatGPT",
    "section": "\n3.3 SRT",
    "text": "3.3 SRT\nëª‡ë²ˆì˜ ì‹œí–‰ì°©ì˜¤ë¥¼ ê±°ì³ ìˆœë²ˆ, ì‹œì‘ì‹œê°, ì¢…ë£Œì‹œê°, í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±ëœ íŒŒì¼ì„ .srt íŒŒì¼ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì˜ì–´ ìë§‰ì‘ì—…ì„ ë§ˆë¬´ë¦¬í•œë‹¤.\n\nì½”ë“œmis_srt_raw &lt;- read_lines(\"data/LibriSpeech/misinformation_proof_reading.txt\")\n\nmis_srt_tbl &lt;- mis_srt_raw %&gt;% \n  enframe() %&gt;% \n  separate(value, into = c(\"start\", \"end\"),   sep = \"\\\\s==&gt;\\\\s\", extra = \"merge\") %&gt;% \n  separate(end,   into = c(\"end\", \"subtitle\"), sep = \"\\\\s\", extra = \"merge\") %&gt;% \n  mutate(subtitle = str_trim(subtitle))\n \nmis_srt_tbl %&gt;% \n  mutate(srt = glue::glue(\"{name} \\n {start} --&gt; {end} \\n {subtitle}\\n\\n\")) %&gt;% \n  pull(srt) %&gt;% \n  write_lines(\"data/LibriSpeech/misinformation_proof_reading_srt.srt\")\n\n\nìœ íŠœë¸Œ ë™ì˜ìƒ ì˜ë¬¸ ìë§‰ìœ¼ë¡œ ì‚¬ìš©ë  .srt ìë§‰ íŒŒì¼ì„ ë¶ˆëŸ¬ì½ì–´ì™€ì„œ ìµœì¢… ì‘ì—…ê²°ê³¼ë¥¼ ì‚´í´ë³¸ë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nmis_srt &lt;- read_lines(\"data/LibriSpeech/misinformation.srt\")\n\nmis_srt %&gt;% \n  head(20) \n#&gt;  [1] \"1 \"                                                                                          \n#&gt;  [2] \"00:00:00.000 --&gt; 00:00:27.520 \"                                                              \n#&gt;  [3] \"Welcome everybody to our Seoul R Online seminar where we explore various ideas and\"          \n#&gt;  [4] \"\"                                                                                            \n#&gt;  [5] \"2 \"                                                                                          \n#&gt;  [6] \"00:00:27.520 --&gt; 00:00:33.360 \"                                                              \n#&gt;  [7] \"practices of data science. We are really happy today to have Jevin West from the University\" \n#&gt;  [8] \"\"                                                                                            \n#&gt;  [9] \"3 \"                                                                                          \n#&gt; [10] \"00:00:33.360 --&gt; 00:00:43.040 \"                                                              \n#&gt; [11] \"of Washington with us to talk about ChatGPT and misinformation. I'm sorry, I'll begin again.\"\n#&gt; [12] \"\"                                                                                            \n#&gt; [13] \"4 \"                                                                                          \n#&gt; [14] \"00:00:43.040 --&gt; 00:00:46.480 \"                                                              \n#&gt; [15] \"Okay, no problem. No, I do this a lot of times.\"                                             \n#&gt; [16] \"\"                                                                                            \n#&gt; [17] \"5 \"                                                                                          \n#&gt; [18] \"00:00:46.480 --&gt; 00:00:53.680 \"                                                              \n#&gt; [19] \"Welcome everybody to our Seoul R Online seminar. We explore various ideas and\"               \n#&gt; [20] \"\"\n\n\n\nì½”ë“œlibrary(magick)\n\nmis_mp4 &lt;- image_read_video(\"data/LibriSpeech/misinformation.mp4\",  fps = 1)"
  },
  {
    "objectID": "interview.html#ë¬¸ì œ-1",
    "href": "interview.html#ë¬¸ì œ-1",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nê¸°ê³„í•™ìŠµ ë¶„ë¥˜ëª¨í˜•ê°œë°œí•  ë•Œ í´ë˜ìŠ¤ ë¶ˆê· í˜•(class imbalance) ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?"
  },
  {
    "objectID": "interview.html#ë¬¸ì œ-2",
    "href": "interview.html#ë¬¸ì œ-2",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nê¸°ê³„í•™ìŠµëª¨í˜•ì—ì„œ bias ì™€ variance trade-offì—ì„œ ì¡´ì¬í•©ë‹ˆë‹¤. ì–´ë–¤ ê¸°ê³„í•™ìŠµ ëª¨í˜•ì´ bias ì™€ varianceë¥¼ ì¤„ì´ëŠ”ë° íš¨ê³¼ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‚˜ìš”?"
  },
  {
    "objectID": "interview.html#ë¬¸ì œ-3",
    "href": "interview.html#ë¬¸ì œ-3",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\në¦¬ìŠ¤íŠ¸ì™€ ë°ì´í„°í”„ë ˆì„ ìë£Œêµ¬ì¡°ì˜ ì°¨ì´ì ì— ëŒ€í•´ì„œ ë§ì”€í•´ ì£¼ì„¸ìš”."
  },
  {
    "objectID": "interview.html#ë¬¸ì œ-4",
    "href": "interview.html#ë¬¸ì œ-4",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansingì´ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì„¤ëª…í•˜ì„¸ìš”."
  },
  {
    "objectID": "interview.html#ë¬¸ì œ-5",
    "href": "interview.html#ë¬¸ì œ-5",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nì œí’ˆ ì„¤ëª… ë“± í…ìŠ¤íŠ¸ í•„ë“œ ì¹¼ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤. ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ë¶„ë¥˜ë‚˜ ì˜ˆì¸¡ ëª¨í˜•ì— ì ìš©ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
  },
  {
    "objectID": "prompt_for_develoopers.html",
    "href": "prompt_for_develoopers.html",
    "title": "chatGPT",
    "section": "",
    "text": "ê²½ê³ \n\n\n\n\n\n2023ë…„ 4ì›” ì•¤ë“œë¥˜ ì‘(Andrew Ng) ëŒ€í‘œê°€ ì´ë„ëŠ” Deeplearning.AIì—ì„œ ê³µê°œí•œ â€œChatGPT Prompt Engineering for Developersâ€ ë‚´ìš©ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤. (Isa Fulford, 2023)"
  },
  {
    "objectID": "prompt_for_develoopers.html#api-í‚¤-ì„¤ì •",
    "href": "prompt_for_develoopers.html#api-í‚¤-ì„¤ì •",
    "title": "chatGPT",
    "section": "\n2.1 API í‚¤ ì„¤ì •",
    "text": "2.1 API í‚¤ ì„¤ì •\nê°œë°œìê°€ ì±—GPT í”„ë¡¬í”„íŠ¸ ê³µí•™ìœ¼ë¡œ AI ì•±ì„ ê°œë°œí•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ ê²ƒì€ ë¨¼ì € OpenAI ì›¹ì‚¬ì´íŠ¸ì—ì„œ API Keysë¥¼ ë°œê¸‰ë°›ê³  ì´ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ë‹¤.\n\n\n\n.env íŒŒì¼\n.env íŒŒì¼ì— OpenAIì—ì„œ ë°œê¸‰ëœ API KEYë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì €ì¥í•œë‹¤.\nENV_OPENAI_API_KEY=sk-q79SxxxxxxxxxxxxxxxxxxxxxxxxXK\n\n\nopenai\n.env íŒŒì¼ì— ê¸°ë¡ëœ API KEY ì •ë³´ë¥¼ os.getenv() í•¨ìˆ˜ì—ì„œ í™˜ê²½ì •ë³´ë¡œ ë¶ˆëŸ¬ ì½ì€ í›„ì— ì´ë¥¼ openai íŒ¨í‚¤ì§€ì— ë“±ë¡í•˜ì—¬ í›„ì† ì‘ì—…ì— ì‚¬ìš©í•˜ë„ë¡ ì¤€ë¹„í•œë‹¤.\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "prompt_for_develoopers.html#í—¬ë¡œì›”ë“œ",
    "href": "prompt_for_develoopers.html#í—¬ë¡œì›”ë“œ",
    "title": "chatGPT",
    "section": "\n2.2 í—¬ë¡œì›”ë“œ",
    "text": "2.2 í—¬ë¡œì›”ë“œ\nget_completion() ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ í•œë‹¤. í”„ë¡¬í”„íŠ¸ ê³µí•™ í—¬ë¡œì›”ë“œ ì‚¬ë¡€ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” xsum ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œë‹¤. ID 38900884 ë¬¸ì„œ(document)ëŠ” ë‹¤ìŒ ì‚¬í•­ì´ ì í˜€ìˆë‹¤.\n\n\n38900884 ì›ë¬¸\n\"The Bath-born player, 28, has made 36 appearances for the Dragons since joining from Wasps in 2015. He is in his second season and signed a contract extension in December 2016. Dragons forwards coach Ceri Jones said: \"It's a big blow. Eddie has been excellent all year for us, he has really stepped up to the mark and will be a big loss.\" However, Jones says Jackson's misfortune can be a chance for others to thrive. \"We are very fortunate to have the likes of Ollie Griffiths, Harrison Keddie, James Thomas who can come into the back-row,\" said Jackson. \"Harri has shown glimpses of what he can do all season and there's definitely a player there, so this is an opportunity.\" Dragons travel to Munster in the Pro12 on Friday.\"\n\n\në””í”Œë²ˆì—­\në°°ìŠ¤ íƒœìƒì˜ 28ì„¸ ì„ ìˆ˜ëŠ” 2015ë…„ ì™€ìŠ¤í”„ì—ì„œ ë“œë˜ê³¤ì¦ˆì— ì…ë‹¨í•œ ì´í›„ 36ê²½ê¸°ì— ì¶œì „í–ˆìŠµë‹ˆë‹¤. ë‘ ë²ˆì§¸ ì‹œì¦Œì„ ë³´ë‚´ê³  ìˆëŠ” ê·¸ëŠ” 2016ë…„ 12ì›”ì— ì—°ì¥ ê³„ì•½ì„ ì²´ê²°í–ˆìŠµë‹ˆë‹¤. ë“œë˜ê³¤ì¦ˆì˜ í¬ì›Œë“œ ì½”ì¹˜ ì„¸ë¦¬ ì¡´ìŠ¤ëŠ” ì´ë ‡ê²Œ ë§í–ˆìŠµë‹ˆë‹¤: \"í° íƒ€ê²©ì…ë‹ˆë‹¤. ì—ë””ëŠ” ì˜¬ í•œ í•´ ë™ì•ˆ ìš°ë¦¬ íŒ€ì—ì„œ í›Œë¥­í•œ í™œì•½ì„ í¼ì³¤ê³ , ì •ë§ í° ì†ì‹¤ì´ ë  ê²ƒì…ë‹ˆë‹¤.\"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¡´ìŠ¤ëŠ” ì­ìŠ¨ì˜ ë¶ˆí–‰ì´ ë‹¤ë¥¸ ì„ ìˆ˜ë“¤ì—ê²ŒëŠ” ê¸°íšŒê°€ ë  ìˆ˜ ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤. \"ì˜¬ë¦¬ ê·¸ë¦¬í”¼ìŠ¤, í•´ë¦¬ìŠ¨ ì¼€ë””, ì œì„ìŠ¤ í† ë§ˆìŠ¤ ê°™ì€ ì„ ìˆ˜ë“¤ì´ ë’·ì¤„ì— ë“¤ì–´ì˜¬ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì€ ë§¤ìš° í–‰ìš´ì…ë‹ˆë‹¤.\"ë¼ê³  ì­ìŠ¨ì€ ë§í•©ë‹ˆë‹¤. \"í•´ë¦¬ëŠ” ì˜¬ ì‹œì¦Œ ê·¸ê°€ í•  ìˆ˜ ìˆëŠ” ê²ƒì„ ì‚´ì§ ë³´ì—¬ì¤¬ê³ , í™•ì‹¤íˆ ê·¸ëŸ° ì„ ìˆ˜ê°€ ìˆê¸° ë•Œë¬¸ì— ì´ë²ˆì´ ê¸°íšŒì…ë‹ˆë‹¤.\" ë“œë˜ê³¤ìŠ¤ëŠ” ê¸ˆìš”ì¼ì— ë¨¼ìŠ¤í„°ì™€ í”„ë¡œ12 ê²½ê¸°ë¥¼ ì¹˜ë¦…ë‹ˆë‹¤.\n\nTranslated with www.DeepL.com/Translator (free version)\n\n\n\nìƒê¸° í…ìŠ¤íŠ¸ ìš”ì•½ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.\n\n\ní”„ë¡¬í”„íŠ¸ ìš”ì•½ì‘ì—…ê²°ê³¼\n\nì½”ë“œdef get_completion(prompt):\n    model=\"gpt-3.5-turbo\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,\n    )\n    return response.choices[0].message[\"content\"]\n\ntext = f\"\"\"\nThe Bath-born player, 28, has made 36 appearances for the Dragons since joining from Wasps in 2015. He is in his second season and signed a contract extension in December 2016. Dragons forwards coach Ceri Jones said: \"It's a big blow. Eddie has been excellent all year for us, he has really stepped up to the mark and will be a big loss.\" However, Jones says Jackson's misfortune can be a chance for others to thrive. \"We are very fortunate to have the likes of Ollie Griffiths, Harrison Keddie, James Thomas who can come into the back-row,\" said Jackson. \"Harri has shown glimpses of what he can do all season and there's definitely a player there, so this is an opportunity.\" Dragons travel to Munster in the Pro12 on Friday.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a one sentence.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)  \n\n\nNewport Gwent Dragons player Eddie Jackson will miss the rest of the season due to a knee injury, but the team's forwards coach sees it as an opportunity for other players to step up.\n\n\nìš”ì•½ ì›ë¬¸ ì •ë‹µë¼ë²¨\nNewport Gwent Dragons number eight Ed Jackson has undergone shoulder surgery and faces a spell on the sidelines."
  },
  {
    "objectID": "prompt_for_develoopers.html#ëª…í™•í•œ-ì§€ì‹œëª…ë ¹ì–´",
    "href": "prompt_for_develoopers.html#ëª…í™•í•œ-ì§€ì‹œëª…ë ¹ì–´",
    "title": "chatGPT",
    "section": "\n3.1 ëª…í™•í•œ ì§€ì‹œëª…ë ¹ì–´",
    "text": "3.1 ëª…í™•í•œ ì§€ì‹œëª…ë ¹ì–´\n\n\n\n\ngraph TB\nA[ëª…í™•í•œ ì§€ì‹œëª…ë ¹ì–´ ì‘ì„±] --&gt; B[\"êµ¬ë¶„ì ì‚¬ìš©(Delimiter)\"]\nA --&gt; C[\"ì¶œë ¥í˜•ì‹(HTML, JSON)\"]\nA --&gt; D[ì¡°ê±´ í™•ì¸]\nA --&gt; E[\"í“¨ì‚¿(Few-Shot) í•™ìŠµ\"]\n\n\n\n\n\n\n3.1.1 êµ¬ë¶„ì ì‚¬ìš©\nêµ¬ë¶„ ê¸°í˜¸(delimiter)ë¡œ ëª…í™•íˆ í•œë‹¤. êµ¬ë¶„ê¸°í˜¸ëŠ” ``, \"\"\", &lt; &gt;, íƒœê·¸&gt;, ': ë“± ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤.\nAI HUB ë¬¸ì„œìš”ì•½ í…ìŠ¤íŠ¸ ì—ì„œ ìƒ˜í”Œë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ êµ¬ë¶„ì ì‚¬ìš©ì˜ ì‚¬ë¡€ë¡œ í™œìš©í•˜ì.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(reticulate)\n\neditorial &lt;- jsonlite::stream_in(file(\"data/001.ë¬¸ì„œìš”ì•½í…ìŠ¤íŠ¸_sample/ë¼ë²¨ë§ë°ì´í„°/ì‚¬ì„¤ì¡ì§€/sample.jsonl\")) \n#&gt; \n Found 500 records...\n Found 700 records...\n Imported 700 records. Simplifying...\n\neditorial_sample &lt;- editorial %&gt;% \n  filter(id == \"148261803\") %&gt;% \n  select(id, abstractive, article_original) %&gt;%\n  mutate(article_original = map_chr(article_original, paste0, collapse=\" \")) \n\neditorial_sample %&gt;% \n  mutate(article_sub = str_sub(article_original, 1, 100)) %&gt;% \n  select(id, abstractive, article_sub) %&gt;% \n  gt::gt()\n\n\n\n\n\n\nid\nabstractive\narticle_sub\n\n\n148261803\nê¸ˆìœµìœ„ì›íšŒëŠ” ëŸ¬ì‹œì•¤ìºì‹œ ë“± ìê¸°ìë³¸ 500ì–µ ì´ìƒì¸ í° ëŒ€ë¶€ì—…ì²´ë“¤ì´ ì €ì¶•ì€í–‰ì„ ì¸ìˆ˜í•  ìˆ˜ ìˆë„ë¡ ê¸¸ì„ í„°ì¤¬ëŠ”ë° ë¶€ì‹¤í•œ ì €ì¶•ì€í–‰ì´ ë” ë¶€ì‹¤í•´ì§€ì§€ ì•Šë„ë¡ êµ¬ì¡°ì¡°ì •ë¶€í„° í•´ì•¼ í•˜ê³  ì €ì¶•ì€í–‰ì„ ì¸ìˆ˜í•œ ëŒ€ë¶€ì—…ì²´ëŠ” ëŒ€ë¶€ì—… ìì²´ì— ì†ì„ ë–¼ë„ë¡ í•´ì•¼ í•œë‹¤.\nê¸ˆìœµìœ„ì›íšŒëŠ” ëŸ¬ì‹œì•¤ìºì‹œ ë“± ìê¸°ìë³¸ 500ì–µì› ì´ìƒì¸ ëŒ€í˜• ëŒ€ë¶€ì—…ì²´ë“¤ì´ ì €ì¶•ì€í–‰ ì¸ìˆ˜ì— ë‚˜ì„¤ ìˆ˜ ìˆê²Œ ê¸¸ì„ í„°ì¤¬ë‹¤. ë˜ ì €ì¶•ì€í–‰ì´ í€ë“œã†ë³´í—˜ã†ì‹ ìš©ì¹´ë“œ íŒë§¤ì—…ì„ í•  ìˆ˜ ìˆê²Œ í•´ì¤¬ë‹¤.\n\n\n\n\n\n\nì½”ë“œtext = f\"\"\"\nê¸ˆìœµìœ„ì›íšŒëŠ” ëŸ¬ì‹œì•¤ìºì‹œ ë“± ìê¸°ìë³¸ 500ì–µ ì´ìƒì¸ í° ëŒ€ë¶€ì—…ì²´ë“¤ì´ ì €ì¶•ì€í–‰ì„ ì¸ìˆ˜í•  ìˆ˜ ìˆë„ë¡ ê¸¸ì„ í„°ì¤¬ëŠ”ë° ë¶€ì‹¤í•œ ì €ì¶•ì€í–‰ì´ ë” ë¶€ì‹¤í•´ì§€ì§€ ì•Šë„ë¡ êµ¬ì¡°ì¡°ì •ë¶€í„° í•´ì•¼ í•˜ê³  ì €ì¶•ì€í–‰ì„ ì¸ìˆ˜í•œ ëŒ€ë¶€ì—…ì²´ëŠ” ëŒ€ë¶€ì—… ìì²´ì— ì†ì„ ë–¼ë„ë¡ í•´ì•¼ í•œë‹¤.\n\"\"\"\nprompt = f\"\"\"\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n\n\nAI-HUB ë¬¸ì„œìš”ì•½ ì •ë‹µ\nê¸ˆìœµìœ„ì›íšŒëŠ” ëŸ¬ì‹œì•¤ìºì‹œ ë“± ìê¸°ìë³¸ 500ì–µ ì´ìƒì¸ í° ëŒ€ë¶€ì—…ì²´ë“¤ì´ ì €ì¶•ì€í–‰ì„ ì¸ìˆ˜í•  ìˆ˜ ìˆë„ë¡ ê¸¸ì„ í„°ì¤¬ëŠ”ë° ë¶€ì‹¤í•œ ì €ì¶•ì€í–‰ì´ ë” ë¶€ì‹¤í•´ì§€ì§€ ì•Šë„ë¡ êµ¬ì¡°ì¡°ì •ë¶€í„° í•´ì•¼ í•˜ê³  ì €ì¶•ì€í–‰ì„ ì¸ìˆ˜í•œ ëŒ€ë¶€ì—…ì²´ëŠ” ëŒ€ë¶€ì—… ìì²´ì— ì†ì„ ë–¼ë„ë¡ í•´ì•¼ í•œë‹¤.\n\n\nLLM ìš”ì•½\nê¸ˆìœµìœ„ì›íšŒëŠ” ëŒ€ë¶€ì—…ì²´ë“¤ì´ ì €ì¶•ì€í–‰ ì¸ìˆ˜ ê°€ëŠ¥í•˜ê²Œ í•˜ì§€ë§Œ, êµ¬ì¡°ì¡°ì •ë¶€í„° í•´ì•¼í•˜ë©° ì¸ìˆ˜í•œ ì—…ì²´ëŠ” ëŒ€ë¶€ì—…ì—ì„œ ì†ì„ ë–¼ì•¼ í•œë‹¤.\n\n\n\n\n3.1.2 ì¶œë ¥í˜•ì‹ ì§€ì •\nJSON, HTML, XML ë“± ì¶œë ¥í˜•ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œë‹¤.\n\nì½”ë“œprompt = f\"\"\"\nì €ìëª…ê³¼ ì¥ë¥´ê°€ í¬í•¨ëœ ë„ì„œ ëª©ë¡ì„ 5ê¶Œ ìƒì„±í•©ë‹ˆë‹¤.\në‹¤ìŒ í•„ë“œê°’ì„ ê°–ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤: \nì„œì§€ë²ˆí˜¸, ì œëª©, ì €ì, ì¥ë¥´.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n1. {\n   \"ì„œì§€ë²ˆí˜¸\": \"001\",\n   \"ì œëª©\": \"1984\",\n   \"ì €ì\": \"ì¡°ì§€ ì˜¤ì›°\",\n   \"ì¥ë¥´\": \"SF\"\n}\n\n2. {\n   \"ì„œì§€ë²ˆí˜¸\": \"002\",\n   \"ì œëª©\": \"ì£½ì€ ì‹œì¸ì˜ ì‚¬íšŒ\",\n   \"ì €ì\": \"ë…¸ë¨¼ ë©”ì¼ëŸ¬\",\n   \"ì¥ë¥´\": \"ì†Œì„¤\"\n}\n\n3. {\n   \"ì„œì§€ë²ˆí˜¸\": \"003\",\n   \"ì œëª©\": \"ì±…ì€ ë…ì„œê°€ ì•„ë‹ˆë‹¤\",\n   \"ì €ì\": \"ìœ ì‹œë¯¼\",\n   \"ì¥ë¥´\": \"ìê¸°ê³„ë°œ\"\n}\n\n4. {\n   \"ì„œì§€ë²ˆí˜¸\": \"004\",\n   \"ì œëª©\": \"ë¯¸ì›€ë°›ì„ ìš©ê¸°\",\n   \"ì €ì\": \"ê¸°ì‹œë¯¸ ì´ì¹˜ë¡œ\",\n   \"ì¥ë¥´\": \"ìê¸°ê³„ë°œ\"\n}\n\n5. {\n   \"ì„œì§€ë²ˆí˜¸\": \"005\",\n   \"ì œëª©\": \"í•´ë¦¬ í¬í„°ì™€ ë§ˆë²•ì‚¬ì˜ ëŒ\",\n   \"ì €ì\": \"J.K. ë¡¤ë§\",\n   \"ì¥ë¥´\": \"íŒíƒ€ì§€\"\n}\n\n3.1.3 ì¡°ê±´í™•ì¸\nLLM ëª¨ë¸ì—ê²Œ ì¡°ê±´ì´ ì¶©ì¡±ë˜ëŠ”ì§€ í™•ì¸í•˜ë„ë¡ ì§€ì‹œí•œë‹¤.\n\nì½”ë“œtext_1 = f\"\"\"\nì°¨ í•œ ì”ì„ ë§Œë“œëŠ” ê²ƒì€ ì‰½ìŠµë‹ˆë‹¤! ë¨¼ì € ë¬¼ì„ ë“ì—¬ì•¼ í•©ë‹ˆë‹¤. ë“ëŠ” ë™ì•ˆ ì»µì„ ë“¤ê³  í‹°ë°±ì„ ë„£ìœ¼ì„¸ìš”. ë¬¼ì´ ì¶©ë¶„íˆ ëœ¨ê±°ì›Œì§€ë©´ í‹°ë°± ìœ„ì— ë¶“ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. ì°¨ê°€ ìš°ëŸ¬ë‚  ìˆ˜ ìˆë„ë¡ ì ì‹œ ê¸°ë‹¤ë¦¬ì„¸ìš”. ëª‡ ë¶„ í›„ í‹°ë°±ì„ êº¼ë‚´ì„¸ìš”. ì›í•œë‹¤ë©´ ì„¤íƒ•ì´ë‚˜ ìš°ìœ ë¥¼ ë„£ì–´ ë§›ì„ ë”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ê²Œ ë‹¤ì…ë‹ˆë‹¤! ë§›ìˆëŠ” ì°¨ í•œ ì”ì„ ì¦ê¸°ì„¸ìš”.\n\"\"\"\nprompt = f\"\"\"\në°±í‹± 3ê°œë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ê°€ ì œê³µë©ë‹ˆë‹¤. \nì¼ë ¨ì˜ ì§€ì¹¨ì´ í¬í•¨ëœ ê²½ìš° ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•´ë‹¹ ì§€ì¹¨ì„ ë‹¤ì‹œ ì‘ì„±í•©ë‹ˆë‹¤:\n\n1ë‹¨ê³„ - ...\n2ë‹¨ê³„ - ...\n...\nNë‹¨ê³„ - ...\n\ní…ìŠ¤íŠ¸ì— ì¼ë ¨ì˜ ì§€ì¹¨ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°ì—ëŠ” \\\"ì œê³µëœ ë‹¨ê³„ ì—†ìŒ\\\"ì´ë¼ê³  ê°„ë‹¨íˆ ì‘ì„±í•©ë‹ˆë‹¤.\n```{text_1}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(\"Completion for Text 1:\")\nprint(response)\n\n\n1ë‹¨ê³„ - ë¬¼ì„ ë“ì…ë‹ˆë‹¤.\n2ë‹¨ê³„ - ë“ëŠ” ë™ì•ˆ ì»µì— í‹°ë°±ì„ ë„£ìŠµë‹ˆë‹¤.\n3ë‹¨ê³„ - ë¬¼ì´ ì¶©ë¶„íˆ ëœ¨ê±°ì›Œì§€ë©´ í‹°ë°± ìœ„ì— ë¬¼ì„ ë¶“ìŠµë‹ˆë‹¤.\n4ë‹¨ê³„ - ì°¨ê°€ ìš°ëŸ¬ë‚  ìˆ˜ ìˆë„ë¡ ì ì‹œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.\n5ë‹¨ê³„ - ëª‡ ë¶„ í›„ í‹°ë°±ì„ êº¼ëƒ…ë‹ˆë‹¤.\n6ë‹¨ê³„ - ì›í•œë‹¤ë©´ ì„¤íƒ•ì´ë‚˜ ìš°ìœ ë¥¼ ë„£ì–´ ë§›ì„ ë”í•©ë‹ˆë‹¤.\n7ë‹¨ê³„ - ë§›ìˆëŠ” ì°¨ í•œ ì”ì„ ì¦ê¹ë‹ˆë‹¤.\n\n3.1.4 í“¨ìƒ· í”„ë¡¬í”„íŠ¸\nì˜ˆì œë¥¼ LLMì— ì œê³µí•˜ì—¬ í•´ë‹¹ ì§ˆì˜ì— ëŒ€í•œ ì‘ë‹µì„ ì´ëŒì–´ë‚´ëŠ” ë°©ì‹ì´ë‹¤.\n\nì½”ë“œprompt = f\"\"\"\në‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì¼ê´€ëœ ìŠ¤íƒ€ì¼ë¡œ ëŒ€ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n&lt;ì–´ë¦°ì´&gt;: ì¸ë‚´ì‹¬ì— ëŒ€í•´ ê°€ë¥´ì³ì£¼ì„¸ìš”.\n\n&lt;ì¡°ë¶€ëª¨&gt;: ê°€ì¥ ê¹Šì€ ê³„ê³¡ì„ ê¹ëŠ” ê°•ì€ ìˆ˜ìˆ˜í•œ ìƒ˜ì—ì„œ íë¥´ê³ , ê°€ì¥ ì›…ì¥í•œ êµí–¥ê³¡ì€ í•œ ìŒì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤; ê°€ì¥ ë³µì¡í•œ ììˆ˜ëŠ” í•˜ë‚˜ì˜ ì‹¤ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤.\n\n&lt;ì–´ë¦°ì´&gt;: íšŒë³µíƒ„ë ¥ì„±ì— ëŒ€í•´ ê°€ë¥´ì³ ì£¼ì„¸ìš”.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n&lt;ì¡°ë¶€ëª¨&gt;: íšŒë³µíƒ„ë ¥ì„±ì€ ì–´ë ¤ìš´ ìƒí™©ì—ì„œë„ ë¹ ë¥´ê²Œ íšŒë³µí•˜ëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤. ë§ˆì¹˜ íƒ„ë ¥ ìˆëŠ” ê³µì²˜ëŸ¼ ì–´ë ¤ìš´ ìƒí™©ì—ì„œ íŠ•ê²¨ë‚˜ì™€ ë‹¤ì‹œ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ì£ . ì´ê²ƒì€ ìš°ë¦¬ê°€ ì–´ë ¤ìš´ ì¼ì„ ê²ªì„ ë•Œ ê¸ì •ì ì¸ ë§ˆì¸ë“œì™€ ê°•í•œ ì˜ì§€ë ¥ì„ ê°€ì§€ê³  ìˆì–´ì•¼ ê°€ëŠ¥í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "prompt_for_develoopers.html#llm-ëª¨í˜•ì—-ìƒê°ì‹œê°„-ì œê³µ",
    "href": "prompt_for_develoopers.html#llm-ëª¨í˜•ì—-ìƒê°ì‹œê°„-ì œê³µ",
    "title": "chatGPT",
    "section": "\n3.2 LLM ëª¨í˜•ì— ìƒê°ì‹œê°„ ì œê³µ",
    "text": "3.2 LLM ëª¨í˜•ì— ìƒê°ì‹œê°„ ì œê³µ\n\n\n\n\ngraph TB\nA[LLM ëª¨í˜•ì— ìƒê°ì‹œê°„ ì œê³µ] --&gt; B[\"ìˆ˜í–‰ì‘ì—… ë‹¨ê³„ ëª…ì‹œ\"]\nA --&gt; C[\"ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ í•´ê²°ì±… ì°¾ë„ë¡ ì§€ì‹œ\"]\n\n\n\n\n\n\n3.2.1 ìˆ˜í–‰ì‘ì—… ë‹¨ê³„ ëª…ì‹œ\nì§€ì‹œí•œ ì‘ì—…ì„ ì™„ìˆ˜í•˜ëŠ”ë° í•„ìš”í•œ ë‹¨ê³„ë¥¼ ëª…ì‹œí•œë‹¤.\n\nì½”ë“œtext = f\"\"\"\në§¤ë ¥ì ì¸ ë§ˆì„ì—ì„œ ì­ê³¼ ì§ˆ ë‚¨ë§¤ëŠ” ì–¸ë• ê¼­ëŒ€ê¸°ì— ìˆëŠ” ìš°ë¬¼ì—ì„œ ë¬¼ì„ ê¸¸ì–´ì˜¤ê¸° ìœ„í•œ ì—¬ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤. ìš°ë¬¼. ì¦ê±°ìš´ ë§ˆìŒìœ¼ë¡œ ë…¸ë˜ë¥¼ ë¶€ë¥´ë©° ì˜¤ë¥´ë˜ ì¤‘ ë¶ˆí–‰ì´ ë‹¥ì³¤ìŠµë‹ˆë‹¤. ì­ì€ ëŒì— ê±¸ë ¤ ë„˜ì–´ì¡Œê³  ì§ˆë„ ê·¸ ë’¤ë¥¼ ë”°ë¼ ì–¸ë• ì•„ë˜ë¡œ êµ´ëŸ¬ ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì•½ê°„ì˜ ìƒì²˜ë¥¼ ì…ì—ˆì§€ë§Œ ë‘ ì‚¬ëŒì€ ì„œë¡œë¥¼ ìœ„ë¡œí•˜ë©° ì§‘ìœ¼ë¡œ ëŒì•„ì™”ìŠµë‹ˆë‹¤. ì‚¬ê³ ì—ë„ ë¶ˆêµ¬í•˜ê³  ë‘ ì‚¬ëŒì˜ ëª¨í—˜ì‹¬ì€ êº¾ì´ì§€ ì•Šì•˜ê³  ê¸°ì¨ì„ ë§Œë½í•˜ë©° íƒí—˜ì„ ê³„ì†í–ˆìŠµë‹ˆë‹¤.\n\"\"\"\n# example 1\nprompt_1 = f\"\"\"\në‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: \n1 - ë°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n2 - ìš”ì•½ì„ ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.\n3 - ì˜ì–´ ìš”ì•½ì— ê° ì´ë¦„ì„ ë‚˜ì—´í•©ë‹ˆë‹¤.\n4 - ë‹¤ìŒ í‚¤ê°€ í¬í•¨ëœ json ê°ì²´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤: english_summary, num_names.\n\në‹µì„ ì¤„ ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.\n\ní…ìŠ¤íŠ¸:\n```{text}```\n\"\"\"\nresponse = get_completion(prompt_1)\nprint(response)\n\n\nì­ê³¼ ì§ˆì€ ìš°ë¬¼ì—ì„œ ë¬¼ì„ ê¸¸ì–´ì˜¤ê¸° ìœ„í•´ ì—¬ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë¶ˆí–‰íˆë„ ì­ì€ ëŒì— ê±¸ë ¤ ë„˜ì–´ì§€ê³  ì§ˆë„ êµ´ëŸ¬ ë–¨ì–´ì§‘ë‹ˆë‹¤. ìƒì²˜ë¥¼ ì…ì—ˆì§€ë§Œ ë‘ ì‚¬ëŒì€ ëª¨í—˜ì‹¬ì´ êº¾ì´ì§€ ì•Šê³  ê³„ì† íƒí—˜ì„ ì´ì–´ê°‘ë‹ˆë‹¤.\n\nJack and Jill set out on a journey to fetch water from a charming village well atop a hill. However, unfortunate events occur as Jack trips over a rock and Jill tumbles down the hill. Despite their injuries, the siblings continue their adventure with unbroken spirits.\n\nNames: Jack, Jill\n\n{\n  \"english_summary\": \"Jack and Jill set out on a journey to fetch water from a charming village well atop a hill. However, unfortunate events occur as Jack trips over a rock and Jill tumbles down the hill. Despite their injuries, the siblings continue their adventure with unbroken spirits.\",\n  \"num_names\": 2\n}\ní•œë‹¨ê³„ ë” ë“¤ì–´ê°€ êµ¬ì²´ì ì¸ ì¶œë ¥í˜•ì‹ë„ ì§€ì •í•œë‹¤.\n\nì½”ë“œprompt_2 = f\"\"\"\në‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: \n1 - ë°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 1 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.\n2 - ìš”ì•½ì„ ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.\n3 - ì˜ì–´ ìš”ì•½ì— ê° ì´ë¦„ì„ ë‚˜ì—´í•©ë‹ˆë‹¤.\n4 - ë‹¤ìŒ í‚¤ê°€ í¬í•¨ëœ json ê°ì²´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤: english_summary, num_names.\n\n\në‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:\ní…ìŠ¤íŠ¸: &lt;ìš”ì•½í•  í…ìŠ¤íŠ¸&gt;\nìš”ì•½: &lt;ìš”ì•½&gt;\në²ˆì—­: &lt;ìš”ì•½ ë²ˆì—­&gt;\nì´ë¦„: &lt;ì˜ì–´ ìš”ì•½ì˜ ì´ë¦„ ëª©ë¡&gt;\nì¶œë ¥ JSON: &lt;ìš”ì•½ ë° num_namesê°€ í¬í•¨ëœ json&gt;\n\ní…ìŠ¤íŠ¸: \n```{text}```\n\"\"\"\nresponse = get_completion(prompt_2)\nprint(response)\n\n\nìš”ì•½: ì­ê³¼ ì§ˆ ë‚¨ë§¤ëŠ” ìš°ë¬¼ì—ì„œ ë¬¼ì„ ê¸¸ì–´ì˜¤ê¸° ìœ„í•œ ì—¬ì •ì„ ì‹œì‘í•˜ê³ , ë¶ˆí–‰ì´ ë‹¥ì³ë„ ëª¨í—˜ì‹¬ì€ êº¾ì´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\në²ˆì—­: Jack and Jill siblings start a journey to fetch water from a well in a charming village, but unfortunate events occur. Despite the accident, their adventurous spirit remains unbroken and they continue to explore with joy.\nì´ë¦„: Jack, Jill\nì¶œë ¥ JSON: {\"english_summary\": \"Jack and Jill siblings start a journey to fetch water from a well in a charming village, but unfortunate events occur. Despite the accident, their adventurous spirit remains unbroken and they continue to explore with joy.\", \"num_names\": 2}\n\n3.2.2 ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ í•´ê²°ì±… ì°¾ë„ë¡ ì§€ì‹œ\nLLM ëª¨ë¸ì— ë¨¼ì € ìì²´ í•´ê²°ì±…ì„ ì°¾ë„ë¡ ì§€ì‹œí•˜ì—¬ ë‹¤ì–‘í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "prompt_for_develoopers.html#ë°˜ë³µ-í”„ë¡¬í”„íŠ¸-ê°œë°œ",
    "href": "prompt_for_develoopers.html#ë°˜ë³µ-í”„ë¡¬í”„íŠ¸-ê°œë°œ",
    "title": "chatGPT",
    "section": "\n3.3 ë°˜ë³µ í”„ë¡¬í”„íŠ¸ ê°œë°œ",
    "text": "3.3 ë°˜ë³µ í”„ë¡¬í”„íŠ¸ ê°œë°œ\ní”„ë¡¬í”„íŠ¸ ê°œë°œì€ ìš´ì¢‹ê²Œ í•œë²ˆì— ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ë„ ìˆì§€ë§Œ ëŒ€ê°œëŠ” LLM ì‘ì—…ê²°ê³¼ë¥¼ ê²€í† í•˜ê³  ë‹¤ë“¬ì–´ê°€ëŠ” ê³¼ì •ì´ í•„ìˆ˜ì ì´ë‹¤.\n\nì½”ë“œfact_sheet_chair = \"\"\"\nê°œìš”\n- ë¯¸ë“œ ì„¼ì¶”ë¦¬ì—ì„œ ì˜ê°ì„ ë°›ì€ ì•„ë¦„ë‹¤ìš´ ì‚¬ë¬´ìš© ê°€êµ¬ ì œí’ˆêµ°ì˜ ì¼ë¶€ì…ë‹ˆë‹¤, \níŒŒì¼ ìºë¹„ë‹›, ì±…ìƒ, ì±…ì¥, íšŒì˜ìš© í…Œì´ë¸” ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.\n- ì‰˜ ìƒ‰ìƒê³¼ ë² ì´ìŠ¤ ë§ˆê°ì˜ ì—¬ëŸ¬ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤.\n- í”Œë¼ìŠ¤í‹± ì†Œì¬ì˜ í›„ë©´ ë° ì „ë©´ ì»¤ë²„(SWC-100) ë˜ëŠ” \në˜ëŠ” 10ê°€ì§€ íŒ¨ë¸Œë¦­ ë° 6ê°€ì§€ ê°€ì£½ ì˜µì…˜ì˜ í’€ ì»¤ë²„(SWC-110)ë¡œ ì œê³µë©ë‹ˆë‹¤.\n- ê¸°ë³¸ ë§ˆê° ì˜µì…˜: ìŠ¤í…Œì¸ë¦¬ìŠ¤ ìŠ¤í‹¸, ë¬´ê´‘ ë¸”ë™, \nìœ ê´‘ í™”ì´íŠ¸ ë˜ëŠ” í¬ë¡¬.\n- ì˜ìëŠ” íŒ”ê±¸ì´ê°€ ìˆë“  ì—†ë“  ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n- ê°€ì • ë˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤.\n- ê³„ì•½ ì‚¬ìš© ìê²©ì´ ìˆìŠµë‹ˆë‹¤.\n\nêµ¬ì¡°\n- 5ë°”í€´ í”Œë¼ìŠ¤í‹± ì½”íŒ… ì•Œë£¨ë¯¸ëŠ„ ë² ì´ìŠ¤.\n- ê³µì••ì‹ ì˜ìëŠ” ì‰½ê²Œ ì˜¬ë¦¬ê±°ë‚˜ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì¡°ì ˆë©ë‹ˆë‹¤.\n\nì¹˜ìˆ˜\n- í­ 53cm | 20.87\"\n- ê¹Šì´ 51 cm | 20.08\"\n- ë†’ì´ 80 cm | 31.50\"\n- ì¢Œì„ ë†’ì´ 44cm | 17.32\"\n- ì¢Œì„ ê¹Šì´ 41cm | 16.14\"\n\nì˜µì…˜\n- ì†Œí”„íŠ¸ ë˜ëŠ” í•˜ë“œ í”Œë¡œì–´ ìºìŠ¤í„° ì˜µì…˜.\n- ë‘ ê°€ì§€ ì‹œíŠ¸ í¼ ë°€ë„ ì„ íƒ ê°€ëŠ¥: \n ì¤‘ê°„(1.8íŒŒìš´ë“œ/ft3) ë˜ëŠ” ë†’ìŒ(2.8íŒŒìš´ë“œ/ft3)\n- íŒ”ê±¸ì´ ì—†ìŒ ë˜ëŠ” 8ìœ„ì¹˜ PU íŒ”ê±¸ì´ \n\nì¬ë£Œ\nì‰˜ ë² ì´ìŠ¤ ê¸€ë¼ì´ë”\n- ë³€í˜• ë‚˜ì¼ë¡  PA6/PA66 ì½”íŒ…ëœ ì£¼ì¡° ì•Œë£¨ë¯¸ëŠ„.\n- ì…¸ ë‘ê»˜: 10mm.\nSEAT\n- HD36 í¼\n\nì›ì‚°ì§€\n- ì´íƒˆë¦¬ì•„\n\"\"\"\n\nprompt = f\"\"\"\në„ˆì˜ ì„ë¬´ëŠ” ë§ˆì¼€íŒ… íŒ€ì´ ê¸°ìˆ  ìë£Œì§‘ì„ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆì˜ ì†Œë§¤ ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ê¸°ìˆ  ì‚¬ì–‘ì„œì— ì ì‹œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ì„¤ëª…ì„œë¥¼ ì‘ì„±í•œë‹¤.\n\nê¸°ìˆ  ì‚¬ì–‘: \n```{fact_sheet_chair}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\në‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë§ˆì¼€íŒ… íŒ€ì´ ì œí’ˆì˜ ì†Œë§¤ ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ê¸°ìˆ  ì‚¬ì–‘ì„œì— ì ì‹œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ì„¤ëª…ì„œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n\nì´ ì œí’ˆì€ ë¯¸ë“œ ì„¼ì¶”ë¦¬ì—ì„œ ì˜ê°ì„ ë°›ì€ ì•„ë¦„ë‹¤ìš´ ì‚¬ë¬´ìš© ê°€êµ¬ ì œí’ˆêµ°ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. íŒŒì¼ ìºë¹„ë‹›, ì±…ìƒ, ì±…ì¥, íšŒì˜ìš© í…Œì´ë¸” ë“±ì„ í¬í•¨í•˜ë©°, ì‰˜ ìƒ‰ìƒê³¼ ë² ì´ìŠ¤ ë§ˆê°ì˜ ì—¬ëŸ¬ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, í”Œë¼ìŠ¤í‹± ì†Œì¬ì˜ í›„ë©´ ë° ì „ë©´ ì»¤ë²„(SWC-100) ë˜ëŠ” 10ê°€ì§€ íŒ¨ë¸Œë¦­ ë° 6ê°€ì§€ ê°€ì£½ ì˜µì…˜ì˜ í’€ ì»¤ë²„(SWC-110)ë¡œ ì œê³µë©ë‹ˆë‹¤. ê¸°ë³¸ ë§ˆê° ì˜µì…˜ì€ ìŠ¤í…Œì¸ë¦¬ìŠ¤ ìŠ¤í‹¸, ë¬´ê´‘ ë¸”ë™, ìœ ê´‘ í™”ì´íŠ¸ ë˜ëŠ” í¬ë¡¬ì…ë‹ˆë‹¤.\n\nì´ ì œí’ˆì€ ê°€ì • ë˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì— ì í•©í•˜ë©°, ê³„ì•½ ì‚¬ìš© ìê²©ì´ ìˆìŠµë‹ˆë‹¤. êµ¬ì¡°ëŠ” 5ë°”í€´ í”Œë¼ìŠ¤í‹± ì½”íŒ… ì•Œë£¨ë¯¸ëŠ„ ë² ì´ìŠ¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, ê³µì••ì‹ ì˜ìëŠ” ì‰½ê²Œ ì˜¬ë¦¬ê±°ë‚˜ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì¡°ì ˆë©ë‹ˆë‹¤. ì´ ì˜ìì˜ í­ì€ 53cm, ê¹Šì´ëŠ” 51cm, ë†’ì´ëŠ” 80cm, ì¢Œì„ ë†’ì´ëŠ” 44cm, ì¢Œì„ ê¹Šì´ëŠ” 41cmì…ë‹ˆë‹¤.\n\nì´ ì œí’ˆì€ ì†Œí”„íŠ¸ ë˜ëŠ” í•˜ë“œ í”Œë¡œì–´ ìºìŠ¤í„° ì˜µì…˜ì„ ì œê³µí•˜ë©°, ë‘ ê°€ì§€ ì‹œíŠ¸ í¼ ë°€ë„ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë˜í•œ, íŒ”ê±¸ì´ ì—†ìŒ ë˜ëŠ” 8ìœ„ì¹˜ PU íŒ”ê±¸ì´ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‰˜ ë² ì´ìŠ¤ ê¸€ë¼ì´ë”ëŠ” ë³€í˜• ë‚˜ì¼ë¡  PA6/PA66 ì½”íŒ…ëœ ì£¼ì¡° ì•Œë£¨ë¯¸ëŠ„ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, ì…¸ ë‘ê»˜ëŠ” 10mmì…ë‹ˆë‹¤. ì‹œíŠ¸ëŠ” HD36 í¼ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œìœ¼ë©°, ì´ ì œí’ˆì€ ì´íƒˆë¦¬ì•„ì—ì„œ ìƒì‚°ë©ë‹ˆë‹¤.\n\n3.3.1 í…ìŠ¤íŠ¸ ê¸¸ì´ ì¡°ì •\nLLM ì‘ì—… ê²°ê³¼ê°€ ë„ˆë¬´ê¸¸ë‹¤. ì¶œë ¥ê²°ê³¼ë¥¼ 50 ë‹¨ì–´ë¡œ í•œì •í•œë‹¤.\n\nì½”ë“œprompt = f\"\"\"\në„ˆì˜ ì„ë¬´ëŠ” ë§ˆì¼€íŒ… íŒ€ì´ ê¸°ìˆ  ìë£Œì§‘ì„ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆì˜ ì†Œë§¤ ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ê¸°ìˆ  ì‚¬ì–‘ì„œì— ì ì‹œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ì„¤ëª…ì„œë¥¼ ì‘ì„±í•œë‹¤.\n\nìµœëŒ€ 50ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n\nê¸°ìˆ  ì‚¬ì–‘ì„œ: \n```{fact_sheet_chair}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nThis product description is based on the technical specifications provided in a document separated by three backticks. The product is a beautiful line of office furniture inspired by Mid-Century design, including file cabinets, desks, bookshelves, and conference tables. It comes in various shell colors and base finishes, with options for plastic or full covers in different fabrics or leather. The chair has adjustable height and comes with or without armrests. It is suitable for home or business environments and has contract use eligibility.\n\n3.3.2 ë…ì ëŒ€ìƒ ëª…ì‹œ\n\nì½”ë“œprompt = f\"\"\"\në„ˆì˜ ì„ë¬´ëŠ” ë§ˆì¼€íŒ… íŒ€ì´ ê¸°ìˆ  ìë£Œì§‘ì„ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆì˜ ì†Œë§¤ ì›¹ì‚¬ì´íŠ¸ì— ëŒ€í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ê¸°ìˆ  ì‚¬ì–‘ì„œì— ì ì‹œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ì„¤ëª…ì„œë¥¼ ì‘ì„±í•œë‹¤.\n\nì´ ì„¤ëª…ì€ ê°€êµ¬ ì†Œë§¤ì—…ì²´ë¥¼ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤, \në”°ë¼ì„œ ë³¸ì§ˆì ìœ¼ë¡œ ê¸°ìˆ ì ì¸ ë‚´ìš©ì´ì–´ì•¼ í•˜ë©° ì œí’ˆì„ êµ¬ì„±í•˜ëŠ” ì¬ë£Œì— ì´ˆì ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤.\n\nìµœëŒ€ 50ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ê³  í•œê¸€ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•œë‹¤.\n\nê¸°ìˆ  ì‚¬ì–‘ì„œ: \n```{fact_sheet_chair}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\në¯¸ë“œ ì„¼ì¶”ë¦¬ì—ì„œ ì˜ê°ì„ ë°›ì€ ì•„ë¦„ë‹¤ìš´ ì‚¬ë¬´ìš© ê°€êµ¬ ì œí’ˆêµ°ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. íŒŒì¼ ìºë¹„ë‹›, ì±…ìƒ, ì±…ì¥, íšŒì˜ìš© í…Œì´ë¸” ë“±ì„ í¬í•¨í•˜ë©°, ì‰˜ ìƒ‰ìƒê³¼ ë² ì´ìŠ¤ ë§ˆê°ì˜ ì—¬ëŸ¬ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. í”Œë¼ìŠ¤í‹± ì†Œì¬ì˜ í›„ë©´ ë° ì „ë©´ ì»¤ë²„ ë˜ëŠ” íŒ¨ë¸Œë¦­ ë° ê°€ì£½ ì˜µì…˜ì˜ í’€ ì»¤ë²„ë¡œ ì œê³µë©ë‹ˆë‹¤. ì˜ìëŠ” íŒ”ê±¸ì´ê°€ ìˆë“  ì—†ë“  ì„ íƒí•  ìˆ˜ ìˆìœ¼ë©°, ê°€ì • ë˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì— ì í•©í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "prompt_for_develoopers.html#ìš”ì•½",
    "href": "prompt_for_develoopers.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n4.1 ìš”ì•½",
    "text": "4.1 ìš”ì•½\n\n4.1.1 ê°„ëµí•œ ìš”ì•½\n\nì½”ë“œprod_review = \"\"\"\në”¸ì˜ ìƒì¼ ì„ ë¬¼ë¡œ ì´ íŒ¬ë” ë´‰ì œ ì¸í˜•ì„ ë°›ì•˜ëŠ”ë°, ë”¸ì´ ì¢‹ì•„í•´ì„œ ì–´ë””ë“  ê°€ì§€ê³  ë‹¤ë‹™ë‹ˆë‹¤. ë¶€ë“œëŸ½ê³  ë§¤ìš° ê·€ì—½ê³  ì–¼êµ´ì´ ì¹œê·¼í•œ í‘œì •ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì œê°€ ì§€ë¶ˆí•œ ê¸ˆì•¡ì— ë¹„í•´ ì¡°ê¸ˆ ì‘ìŠµë‹ˆë‹¤. ê°™ì€ ê°€ê²©ì— ë” í° ë‹¤ë¥¸ ì˜µì…˜ì´ ìˆì„ ê²ƒ ê°™ì•„ìš”. ì˜ˆìƒë³´ë‹¤ í•˜ë£¨ ì¼ì° ë„ì°©í•´ì„œ ì•„ì´ì—ê²Œ ì£¼ê¸° ì „ì— ì œê°€ ì§ì ‘ ê°€ì§€ê³  ë†€ ìˆ˜ ìˆì—ˆì–´ìš”.\n\"\"\"\n\nprompt = f\"\"\"\nì „ììƒê±°ë˜ ì‚¬ì´íŠ¸ì˜ ì œí’ˆ í›„ê¸°ì— ëŒ€í•œ ê°„ë‹¨í•œ ìš”ì•½ì„ ì‘ì„±í•˜ëŠ” ê²ƒì´ ê³¼ì œì…ë‹ˆë‹¤. \n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ì•„ë˜ í›„ê¸°ë¥¼ ìµœëŒ€ 30ë‹¨ì–´ ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”. \ní›„ê¸°: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\nì‘ì§€ë§Œ ê·€ì—¬ìš´ íŒ¬ë” ë´‰ì œì¸í˜•, ì–¼êµ´ì´ ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ¬ì›Œ ë”¸ì´ ì¢‹ì•„í•©ë‹ˆë‹¤. ê°€ê²© ëŒ€ë¹„ í¬ê¸°ëŠ” ì‘ì§€ë§Œ, ì˜ˆìƒë³´ë‹¤ ì¼ì° ë„ì°©í•´ ê¸°ì©ë‹ˆë‹¤.\n\n4.1.2 ë°°ì†¡/ë°°ë‹¬ ì´ˆì  ë‘ê³  ìš”ì•½\n\nì½”ë“œprompt = f\"\"\"\nì „ììƒê±°ë˜ ì‚¬ì´íŠ¸ì˜ ì œí’ˆ í›„ê¸°ì— ëŒ€í•œ ê°„ë‹¨í•œ ìš”ì•½ì„ ì‘ì„±í•˜ëŠ” ê²ƒì´ ê³¼ì œì…ë‹ˆë‹¤. \n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ì•„ë˜ í›„ê¸°ë¥¼ ì œí’ˆì˜ ë°°ì†¡ ë° ë°°ì†¡ê³¼ ê´€ë ¨ëœ ëª¨ë“  ì¸¡ë©´ì— ì¤‘ì ì„ ë‘ì–´ ìµœëŒ€ 30ë‹¨ì–´ ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”. \ní›„ê¸°: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\në¶€ë“œëŸ½ê³  ê·€ì—¬ìš´ íŒ¬ë” ë´‰ì œ ì¸í˜•, ì¡°ê¸ˆ ì‘ì€ ê°€ê²©ì— ë¹„í•´, ë¹ ë¥¸ ë°°ì†¡.\n\n4.1.3 ê°€ê²©ì— ì´ˆì  ë‘ê³  ìš”ì•½\n\nì½”ë“œprompt = f\"\"\"\nì „ììƒê±°ë˜ ì‚¬ì´íŠ¸ì˜ ì œí’ˆ í›„ê¸°ì— ëŒ€í•œ ê°„ë‹¨í•œ ìš”ì•½ì„ ì‘ì„±í•˜ëŠ” ê²ƒì´ ê³¼ì œì…ë‹ˆë‹¤. \n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ì•„ë˜ í›„ê¸°ë¥¼ ì œí’ˆì˜ ê°€ê²©ê³¼ ì§€ê°ëœ ê°€ì¹˜ì™€ ê´€ë ¨ëœ ëª¨ë“  ì¸¡ë©´ì— ì¤‘ì ì„ ë‘ì–´ ìµœëŒ€ 30ë‹¨ì–´ ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”. \ní›„ê¸°: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\në¶€ë“œëŸ½ê³  ê·€ì—¬ìš´ íŒ¬ë” ë´‰ì œ ì¸í˜•ì€ ë”¸ì´ ì¢‹ì•„í•˜ë©°, ì˜ˆìƒë³´ë‹¤ ì¼ì° ë„ì°©í•˜ì—¬ ë§Œì¡±ìŠ¤ëŸ¬ì› ì§€ë§Œ, ê°€ê²© ëŒ€ë¹„ í¬ê¸°ê°€ ì‘ì•„ì„œ ë‹¤ë¥¸ ì˜µì…˜ì„ ê³ ë ¤í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.\n\n4.1.4 ìš”ì•½ ëŒ€ì‹  ì¶”ì¶œ\n\nì½”ë“œprompt = f\"\"\"\në„ˆì˜ ì„ë¬´ëŠ” ì „ììƒê±°ë˜ ì‚¬ì´íŠ¸ì˜ ì œí’ˆ ë¦¬ë·°ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°°ì†¡ ë¶€ì„œì— í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n\në°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ëœ ì•„ë˜ í›„ê¸°ì—ì„œ ë°°ì†¡ê³¼ ë°°ë‹¬ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ìµœëŒ€ 30ë‹¨ì–´ ì´ë‚´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.\n\ní›„ê¸°: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\në°°ì†¡ê³¼ ë°°ë‹¬ê³¼ ê´€ë ¨ëœ ì •ë³´: ì˜ˆìƒë³´ë‹¤ í•˜ë£¨ ì¼ì° ë„ì°©"
  },
  {
    "objectID": "prompt_for_develoopers.html#ì¶”ë¡ ",
    "href": "prompt_for_develoopers.html#ì¶”ë¡ ",
    "title": "chatGPT",
    "section": "\n4.2 ì¶”ë¡ ",
    "text": "4.2 ì¶”ë¡ \n\n4.2.1 ê°ì„±(ê¸/ë¶€ì •)\n\nì½”ë“œlamp_review = \"\"\"\nì¹¨ì‹¤ì„ ìœ„í•œ ë©‹ì§„ ë¨í”„ê°€ í•„ìš”í–ˆëŠ”ë°, ì´ ì œí’ˆì€ ìˆ˜ë‚©ê³µê°„ì´ ë” ìˆê³  ê°€ê²©ëŒ€ê°€ ë„ˆë¬´ ë†’ì§€ ì•Šì•˜ì–´ìš”. ë¹ ë¥´ê²Œ ë°›ì•˜ìŠµë‹ˆë‹¤.  ë°°ì†¡ ì¤‘ì— ë¨í”„ ì¤„ì´ ëŠì–´ì¡ŒëŠ”ë°, íšŒì‚¬ì—ì„œ ê¸°êº¼ì´ ìƒˆ ê²ƒì„ ë³´ë‚´ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ê²ƒë„ ë©°ì¹  ì•ˆì— ë„ì°©í–ˆì–´ìš”. ì¡°ë¦½ë„ ì‰¬ì› ìŠµë‹ˆë‹¤.  ëˆ„ë½ëœ ë¶€í’ˆì´ ìˆì–´ì„œ ê³ ê°ì§€ì›íŒ€ì— ì—°ë½í–ˆë”ë‹ˆ ë§¤ìš° ë¹ ë¥´ê²Œ ëˆ„ë½ëœ ë¶€í’ˆì„ ë³´ë‚´ì£¼ì—ˆì–´ìš”! LuminaëŠ” ê³ ê°ê³¼ ì œí’ˆì„ ì•„ë¼ëŠ” í›Œë¥­í•œ íšŒì‚¬ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤!!!\n\"\"\"\n\nprompt = f\"\"\"\nì„¸ ê°œì˜ ë°±í‹±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¤ìŒ ì œí’ˆ í›„ê¸°ì— ë“œëŸ¬ë‚œ ê°ì •ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n\ní›„ê¸° í…ìŠ¤íŠ¸: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nê¸ì •ì ì¸ ê°ì • (ë§Œì¡±, ê°ì‚¬, ì¹­ì°¬)\n\n4.2.2 ê°ì • ìœ í˜• ì‹ë³„\n\nì½”ë“œprompt = f\"\"\"\nì„¸ ê°œì˜ ë°±í‹±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¤ìŒ ì œí’ˆ í›„ê¸° ì‘ì„±ìê°€ í‘œí˜„í•˜ê³  ìˆëŠ” ê°ì • ëª©ë¡ì„ ì‹ë³„í•©ë‹ˆë‹¤. \nëª©ë¡ì— 5ê°œ ì´í•˜ì˜ í•­ëª©ì„ í¬í•¨ì‹œí‚¤ì‹­ì‹œì˜¤. ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì†Œë¬¸ì ë‹¨ì–´ ëª©ë¡ìœ¼ë¡œ ë‹µì•ˆì˜ í˜•ì‹ì„ ì§€ì •í•©ë‹ˆë‹¤.\n\n\ní›„ê¸° í…ìŠ¤íŠ¸: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\në§Œì¡±, ê°ì‚¬, ì¹­ì°¬, ë¹ ë¥¸, ì¹œì ˆ\n\n4.2.3 ê³ ê° ë¶„ë…¸\n\nì½”ë“œprompt = f\"\"\"\në‹¤ìŒ ì œí’ˆ í›„ê¸° ì‘ì„±ìê°€ ë¶„ë…¸ë¥¼ í‘œí˜„í•˜ê³  ìˆë‚˜ìš”?\ní›„ê¸°ëŠ” ë°±í‹± ì„¸ ë²ˆìœ¼ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. \nì˜ˆ ë˜ëŠ” ì•„ë‹ˆì˜¤ë¡œ ë‹µí•˜ì„¸ìš”.\n\n\ní›„ê¸° í…ìŠ¤íŠ¸: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nì•„ë‹ˆì˜¤.\n\n4.2.4 ì œí’ˆê³¼ íšŒì‚¬ëª… ì¶”ì¶œ\n\nì½”ë“œprompt = f\"\"\"\n\ní›„ê¸° í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ í•­ëª©ì„ ì‹ë³„í•©ë‹ˆë‹¤: \n- ë¦¬ë·°ì–´ê°€ êµ¬ë§¤í•œ ì•„ì´í…œ\n- í•´ë‹¹ ì•„ì´í…œì„ ë§Œë“  íšŒì‚¬\n\ní›„ê¸°ëŠ” ë°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤. \n\"Item\" ë° \"Brand\"ë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ í˜•ì‹ì„ JSON ê°ì²´ë¡œ ì§€ì •í•©ë‹ˆë‹¤. \nì •ë³´ê°€ ì—†ëŠ” ê²½ìš° \"ì•Œ ìˆ˜ ì—†ìŒ\"ì„ ê°’ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\nì‘ë‹µì€ ê°€ëŠ¥í•œ í•œ ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n\ní›„ê¸° í…ìŠ¤íŠ¸: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n{\n    \"Item\": \"ë¨í”„\",\n    \"Brand\": \"Lumina\"\n}\n\n4.2.5 í•œë²ˆì— ì²˜ë¦¬\n\nì½”ë“œprompt = f\"\"\"\ní›„ê¸° í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ í•­ëª©ì„ ì‹ë³„í•©ë‹ˆë‹¤: \n- ê°ì •(ê¸ì • ë˜ëŠ” ë¶€ì •)\n- ë¦¬ë·° ì‘ì„±ìê°€ ë¶„ë…¸ë¥¼ í‘œí˜„í•˜ê³  ìˆë‚˜ìš”? (ì°¸ ë˜ëŠ” ê±°ì§“)\n- ë¦¬ë·°ì–´ê°€ êµ¬ë§¤í•œ ì•„ì´í…œ\n- ì•„ì´í…œì„ ë§Œë“  íšŒì‚¬\n\ní›„ê¸°ëŠ” ë°±í‹± ì„¸ ê°œë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. \nì‘ë‹µì˜ í˜•ì‹ì€ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì—¬ JSON ê°ì²´ë¡œ ì§€ì •í•©ë‹ˆë‹¤. \n\"ê°ì •\", \"ë¶„ë…¸\", \"ì•„ì´í…œ\", \"ë¸Œëœë“œ\"ë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ JSON ê°ì²´ë¡œ í˜•ì‹í™”í•©ë‹ˆë‹¤.\nì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ê°’ìœ¼ë¡œ \"ì•Œ ìˆ˜ ì—†ìŒ\"ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\nì‘ë‹µì€ ê°€ëŠ¥í•œ í•œ ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”.\në¶„ë…¸ ê°’ì˜ í˜•ì‹ì„ ë¶€ìš¸ë¡œ ì§€ì •í•©ë‹ˆë‹¤.\n\n\ní›„ê¸° í…ìŠ¤íŠ¸: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n{\n    \"ê°ì •\": \"ê¸ì •\",\n    \"ë¶„ë…¸\": false,\n    \"ì•„ì´í…œ\": \"ë¨í”„\",\n    \"ë¸Œëœë“œ\": \"Lumina\"\n}\n\n4.2.6 í† í”½ ì¶”ë¡ \n\nì½”ë“œstory = \"\"\"\nìµœê·¼ ì •ë¶€ì—ì„œ ì‹¤ì‹œí•œ ì„¤ë¬¸ì¡°ì‚¬ì—ì„œ ê³µê³µ ë¶€ë¬¸ ì§ì›ë“¤ì—ê²Œ ìì‹ ì´ ê·¼ë¬´í•˜ëŠ” ë¶€ì„œì— ëŒ€í•œ ë§Œì¡±ë„ë¥¼ í‰ê°€í•´ ë‹¬ë¼ëŠ” ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ ê°€ì¥ ì¸ê¸° ìˆëŠ” ë¶€ì„œëŠ” ë§Œì¡±ë„ê°€ ê°€ì¥ ë†’ì€ ë¶€ì„œë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n\nNASAì˜ í•œ ì§ì›ì¸ ì¡´ ìŠ¤ë¯¸ìŠ¤ëŠ” ì¡°ì‚¬ ê²°ê³¼ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ë§í–ˆìŠµë‹ˆë‹¤, \"NASAê°€ 1ìœ„ì— ì˜¤ë¥¸ ê²ƒì´ ë†€ëì§€ ì•ŠìŠµë‹ˆë‹¤. í›Œë¥­í•œ ì‚¬ëŒë“¤ê³¼ í•¨ê»˜ ì¼í•˜ê¸° ì¢‹ì€ ê³³ì´ë©° ë†€ë¼ìš´ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í˜ì‹ ì ì¸ ì¡°ì§ì˜ ì¼ì›ì´ ëœ ê²ƒì´ ìë‘ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.\"\n\nì´ë²ˆ ê²°ê³¼ëŠ” NASAì˜ ê²½ì˜ì§„ë„ í™˜ì˜í–ˆìŠµë‹ˆë‹¤, í†° ì¡´ìŠ¨(Tom Johnson) êµ­ì¥ì€ \"ìš°ë¦¬ ì§ì›ë“¤ì´ ì§ì›ë“¤ì´ NASAì—ì„œì˜ ì—…ë¬´ì— ë§Œì¡±í•˜ê³  ìˆë‹¤ëŠ” ì†Œì‹ì„ ë“£ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤. ìš°ë¦¬ì—ê²ŒëŠ” ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ì§€ì¹  ì¤„ ëª¨ë¥´ê³  ì¼í•˜ê³  ìˆëŠ” ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ëŠì„ì—†ì´ ë…¸ë ¥í•˜ëŠ” ì¬ëŠ¥ ìˆê³  í—Œì‹ ì ì¸ íŒ€ì´ ìˆìŠµë‹ˆë‹¤. ì„±ê³¼ë¥¼ ë‚´ê³  ìˆìŠµë‹ˆë‹¤.\"\n\nì„¤ë¬¸ì¡°ì‚¬ì— ë”°ë¥´ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ì‹¤ë„ ë°í˜€ì¡ŒìŠµë‹ˆë‹¤. ì‚¬íšŒë³´ì¥êµ­ì€ ë§Œì¡±ë„ê°€ ê°€ì¥ ë‚®ì•˜ìŠµë‹ˆë‹¤. ì§ì›ì˜ 45%ë§Œì´ ìì‹ ì˜ ì—…ë¬´ì— ë§Œì¡±í•œë‹¤ê³  ë‹µí–ˆìŠµë‹ˆë‹¤. ìì‹ ì˜ ì§ì—…ì— ë§Œì¡±í•œë‹¤ê³  ë‹µí–ˆìŠµë‹ˆë‹¤. ì •ë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì•½ì†í–ˆìŠµë‹ˆë‹¤. ì„¤ë¬¸ì¡°ì‚¬ì—ì„œ ì§ì›ë“¤ì´ ì œê¸°í•œ ìš°ë ¤ ì‚¬í•­ì„ í•´ê²°í•˜ê³  ëª¨ë“  ë¶€ì„œì˜ ì§ë¬´ ë§Œì¡±ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê² ë‹¤ê³  ì•½ì†í–ˆìŠµë‹ˆë‹¤.\n\"\"\"\n\nprompt = f\"\"\"\në‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë…¼ì˜ë˜ê³  ìˆëŠ” 5ê°œì˜ ì£¼ì œë¥¼ ê²°ì •í•˜ì‹­ì‹œì˜¤. \nì„¸ ê°œì˜ ë°±í‹±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ 5ê°œì˜ ì£¼ì œë¥¼ ì •í•©ë‹ˆë‹¤.\n\nê° í•­ëª©ì€ ìµœëŒ€ ë‘ ë‹¨ì–´ ê¸¸ì´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤. \n\nì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•­ëª© ëª©ë¡ìœ¼ë¡œ ì‘ë‹µ í˜•ì‹ì„ ì§€ì •í•©ë‹ˆë‹¤.\n\ní…ìŠ¤íŠ¸: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n1. ê³µê³µ ë¶€ë¬¸ ì§ì›ë“¤ì˜ ë§Œì¡±ë„ ì¡°ì‚¬\n2. NASA ì§ì›ë“¤ì˜ ë§Œì¡±ë„\n3. ì‚¬íšŒë³´ì¥êµ­ ì§ì›ë“¤ì˜ ë§Œì¡±ë„\n4. ì •ë¶€ì˜ ëŒ€ì‘ ì¡°ì¹˜\n5. ì¡°ì§ì˜ ì„±ê³¼ì™€ ì§ì› ë§Œì¡±ë„ì˜ ê´€ê³„"
  },
  {
    "objectID": "prompt_for_develoopers.html#ë³€í™˜",
    "href": "prompt_for_develoopers.html#ë³€í™˜",
    "title": "chatGPT",
    "section": "\n4.3 ë³€í™˜",
    "text": "4.3 ë³€í™˜\nê±°ëŒ€ì–¸ì–´ëª¨í˜•(LLM)ì„ í™œìš©í•œ ë³€í™˜(Transformation)ì—ëŠ” ì–¸ì–´ ë²ˆì—­, ë§ì¶¤ë²• ë° ë¬¸ë²• ê²€ì‚¬, ì–´ì¡° ì¡°ì •, í˜•ì‹ ë³€í™˜ê³¼ ê°™ì€ í…ìŠ¤íŠ¸ ë³€í™˜ ì‘ì—…ì´ í¬í•¨ëœë‹¤.\n\n4.3.1 ë²ˆì—­\n\nì½”ë“œprompt = f\"\"\"\në‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. \n  \n```Hi, I would like to order a blender```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nì•ˆë…•í•˜ì„¸ìš”, ë¸”ë Œë”ë¥¼ ì£¼ë¬¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.\n\n4.3.2 ì–¸ì–´íƒì§€\n\nì½”ë“œprompt = f\"\"\"\nì–´ëŠ ì–¸ì–´ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”.:\n  \n```ã“ã‚“ã«ã¡ã¯è‰¯ã„ä¸€æ—¥ã§ã™ã€‚``` \n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nì¼ë³¸ì–´ì…ë‹ˆë‹¤.\n\n4.3.3 ê²©ì‹ ë° ë¹„ê²©ì‹ ì–¸ì–´\n\nì½”ë“œprompt = f\"\"\"\në‹¤ìŒ ì˜ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê²©ì‹ ë° ë¹„ê²©ì‹ í˜•íƒœ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.: \n'Would you like to order a pillow?'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nê²©ì‹: ë² ê°œë¥¼ ì£¼ë¬¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\në¹„ê²©ì‹: ë² ê°œ ì‚¬ì‹¤ë˜ìš”?\n\n4.3.4 ë²”ìš© ë²ˆì—­ê¸°\nëŒ€ê·œëª¨ ë‹¤êµ­ì  ì´ì»¤ë¨¸ìŠ¤ ê¸°ì—…ì—ì„œ ITë¥¼ ë‹´ë‹¹í•˜ê³  ìˆë‹¤ê³  ìƒìƒí•´ ë³´ì„¸ìš”. ì‚¬ìš©ìë“¤ì´ ëª¨ë“  ëª¨êµ­ì–´ë¡œ IT ë¬¸ì œì— ëŒ€í•´ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ì „ ì„¸ê³„ ê°ì§€ì—ì„œ ì˜¨ ì§ì›ë“¤ì€ ê°ìì˜ ëª¨êµ­ì–´ë§Œ êµ¬ì‚¬í•©ë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì—ê²ŒëŠ” ë²”ìš© ë²ˆì—­ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤!\n\nì½”ë“œuser_messages = [\n  \"La performance du systÃ¨me est plus lente que d'habitude.\",  # System performance is slower than normal         \n  \"Mi monitor tiene pÃ­xeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n  \"Il mio mouse non funziona\",                                 # My mouse is not working\n  \"MÃ³j klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n  \"æˆ‘çš„å±å¹•åœ¨é—ªçƒ\",                                            # My screen is flashing\n  \"ì»´í“¨í„° ì‹œì‘ ë²„íŠ¼ì´ ë™ì‘í•˜ì§€ ì•Šì•„ìš”\"                         # My computer's start button doesn't work\n] \n\n\nfor issue in user_messages:\n    prompt = f\"ì–´ë–¤ ì–¸ì–´ì¸ì§€ ë§í•´ ì£¼ì„¸ìš”: ```{issue}```\"\n    lang = get_completion(prompt)\n    print(f\"ì›ë¬¸ ë©”ì‹œì§€ ({lang}): {issue}\")\n\n    prompt = f\"\"\"\n    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ì™€ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”: \n    ```{issue}```\n    \"\"\"\n    response = get_completion(prompt)\n    print(response, \"\\n\")\n\n\nì›ë¬¸ ë©”ì‹œì§€ (í”„ë‘ìŠ¤ì–´ì…ë‹ˆë‹¤.): La performance du systÃ¨me est plus lente que d'habitude.\nì˜ì–´: The system performance is slower than usual.\ní•œêµ­ì–´: ì‹œìŠ¤í…œ ì„±ëŠ¥ì´ í‰ì†Œë³´ë‹¤ ëŠë¦½ë‹ˆë‹¤. \n\nì›ë¬¸ ë©”ì‹œì§€ (ìŠ¤í˜ì¸ì–´ì…ë‹ˆë‹¤.): Mi monitor tiene pÃ­xeles que no se iluminan.\nMy monitor has pixels that don't light up. \në‚´ ëª¨ë‹ˆí„°ì—ëŠ” ë¶ˆì´ ì¼œì§€ì§€ ì•ŠëŠ” í”½ì…€ì´ ìˆìŠµë‹ˆë‹¤. \n\nì›ë¬¸ ë©”ì‹œì§€ (ì´ê²ƒì€ ì´íƒˆë¦¬ì•„ì–´ì…ë‹ˆë‹¤.): Il mio mouse non funziona\nì˜ì–´: My mouse is not working.\ní•œêµ­ì–´: ë‚´ ë§ˆìš°ìŠ¤ê°€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \n\nì›ë¬¸ ë©”ì‹œì§€ (ì´ê²ƒì€ í´ë€ë“œì–´ì…ë‹ˆë‹¤.): MÃ³j klawisz Ctrl jest zepsuty\nì˜ì–´: My Ctrl key is broken\ní•œêµ­ì–´: ë‚´ Ctrl í‚¤ê°€ ê³ ì¥ ë‚¬ì–´ìš” \n\nì›ë¬¸ ë©”ì‹œì§€ (ì¤‘êµ­ì–´ì…ë‹ˆë‹¤.): æˆ‘çš„å±å¹•åœ¨é—ªçƒ\nì˜ì–´: My screen is flickering.\ní•œêµ­ì–´: ë‚´ í™”ë©´ì´ ê¹œë¹¡ì…ë‹ˆë‹¤. \n\nì›ë¬¸ ë©”ì‹œì§€ (í•œêµ­ì–´ì…ë‹ˆë‹¤.): ì»´í“¨í„° ì‹œì‘ ë²„íŠ¼ì´ ë™ì‘í•˜ì§€ ì•Šì•„ìš”\n- English: The computer start button is not working.\n- í•œêµ­ì–´: ì»´í“¨í„° ì‹œì‘ ë²„íŠ¼ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \n\n4.3.5 ì–´ì¡° ë³€í™˜\n\nì½”ë“œprompt = f\"\"\"\nTranslate the following from slang to a business letter: \n'Dude, This is Joe, check out this spec on this standing lamp.'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nDear Sir/Madam,\n\nI am writing to bring to your attention a standing lamp that I believe may be of interest to you. Please find attached the specifications for your review.\n\nThank you for your time and consideration.\n\nSincerely,\n\nJoe\n\n4.3.6 ìë£Œí˜• ë³€í™˜\n\nì½”ë“œdata_json = { \"resturant employees\" :[ \n    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n]}\n\nprompt = f\"\"\"\nTranslate the following python dictionary from JSON to an HTML \\\ntable with column headers and title: {data_json}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n&lt;table&gt;\n  &lt;caption&gt;Restaurant Employees&lt;/caption&gt;\n  &lt;thead&gt;\n    &lt;tr&gt;\n      &lt;th&gt;Name&lt;/th&gt;\n      &lt;th&gt;Email&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Shyam&lt;/td&gt;\n      &lt;td&gt;shyamjaiswal@gmail.com&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Bob&lt;/td&gt;\n      &lt;td&gt;bob32@gmail.com&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Jai&lt;/td&gt;\n      &lt;td&gt;jai87@gmail.com&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tbody&gt;\n&lt;/table&gt;\n\n4.3.7 ë¬¸ë²•/ë§ì¶¤ë²• êµì •\n\nì½”ë“œtexts = [ \n  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n  \"Yolanda has her notebook.\", # ok\n  \"Its going to be a long day. Does the car need itâ€™s oil changed?\",  # Homonyms (ë™ìŒì´ì˜ì–´)\n  \"Their goes my freedom. There going to bring theyâ€™re suitcases.\",  # Homonyms (ë™ìŒì´ì˜ì–´)\n  \"Your going to need youâ€™re notebook.\",  # Homonyms (ë™ìŒì´ì˜ì–´)\n  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms (ë™ìŒì´ì˜ì–´)\n  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling (ë§ì¶¤ë²•)\n]\n\nfor text in texts:\n    prompt = f\"\"\"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ êµì • ë° ìˆ˜ì •í•˜ê³  ìˆ˜ì •ëœ ë²„ì „ì„ ë‹¤ì‹œ ì‘ì„±í•©ë‹ˆë‹¤. \n    ì˜¤ë¥˜ë¥¼ ì°¾ì§€ ëª»í•˜ë©´ \"ì˜¤ë¥˜ ì—†ìŒ\"ì´ë¼ê³  ì…ë ¥í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì£¼ìœ„ì— êµ¬ë‘ì ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”:\n    ```{text}```\"\"\"\n    response = get_completion(prompt)\n    print(response)\n\n\nThe girl with the black and white puppies has a ball.\nYolanda has her notebook. (ì˜¤ë¥˜ ì—†ìŒ)\nIt's going to be a long day. Does the car need its oil changed?\nTheir goes my freedom. They're going to bring their suitcases.\nYou're going to need your notebook.\nThat medicine affects my ability to sleep. Have you heard of the butterfly effect?\nThis phrase is to check ChatGPT for spelling ability.\n\n4.3.8 êµì •\n\nì½”ë“œtext = f\"\"\"\nGot this for my daughter for her birthday cuz she keeps taking \\\nmine from my room.  Yes, adults also like pandas too.  She takes \\\nit everywhere with her, and it's super soft and cute.  One of the \\\nears is a bit lower than the other, and I don't think that was \\\ndesigned to be asymmetrical. It's a bit small for what I paid for it \\\nthough. I think there might be other options that are bigger for \\\nthe same price.  It arrived a day earlier than expected, so I got \\\nto play with it myself before I gave it to my daughter.\n\"\"\"\nprompt = f\"proofread and correct this review: ```{text}```\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nI got this for my daughter's birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I think there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter."
  },
  {
    "objectID": "aaaa.html",
    "href": "aaaa.html",
    "title": "Untitled",
    "section": "",
    "text": "ì½”ë“œlibrary(reticulate)\n\n\n\nì½”ë“œfrom redlines import Redlines\nfrom IPython.display import display, Markdown, Latex, HTML, JSON\n\n\ntext = \"Got this for my daughter for her birthday cuz she keeps taking mine from my room.  Yes, adults also like pandas too.\"\n\nresponse = \"Got the for my daughter for her birthday cuz she keeps taking mine from my room.  Yes, adults also like pandas too.\"\n\ndiff = Redlines(text,response)\ndisplay(Markdown(diff.output_markdown))\n\n&lt;IPython.core.display.Markdown object&gt;"
  },
  {
    "objectID": "prompt_for_develoopers.html#í™•ì¥",
    "href": "prompt_for_develoopers.html#í™•ì¥",
    "title": "chatGPT",
    "section": "\n4.4 í™•ì¥",
    "text": "4.4 í™•ì¥\në¯¹ì„œê¸°(Blender) ì œí’ˆì— ëŒ€í•œ ê³ ê° í›„ê¸°ì— ëŒ€í•´ ìë™ ì „ììš°í¸ íšŒì‹ ì„ ì œì‘í•´ë³´ì.\n\nì½”ë“œsentiment = \"ë¶€ì •\"\n\nreview = f\"\"\"\nê·¸ë˜ì„œ 11ì›” í•œ ë‹¬ ë™ì•ˆì€ 17í”¼ìŠ¤ ì‹œìŠ¤í…œì„ ì•½ ì ˆë°˜ í• ì¸ëœ 49ë‹¬ëŸ¬ì— ì‹œì¦Œ í•œì •ìœ¼ë¡œ íŒë§¤í–ˆì§€ë§Œ, 12ì›” ë‘˜ì§¸ ì£¼ì— ì–´ë–¤ ì´ìœ ì—ì„œì¸ì§€(ê°€ê²© í­ë¦¬ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤) ê°™ì€ ì‹œìŠ¤í…œì˜ ê°€ê²©ì´ ëª¨ë‘ 70ë‹¬ëŸ¬ì—ì„œ 89ë‹¬ëŸ¬ ì‚¬ì´ë¡œ ì˜¬ë¼ê°”ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  11í”¼ìŠ¤ ì‹œìŠ¤í…œë„ ì´ì „ íŒë§¤ ê°€ê²©ì¸ 29ë‹¬ëŸ¬ì—ì„œ 10ë‹¬ëŸ¬ ì •ë„ ê°€ê²©ì´ ì˜¬ëìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ê´œì°®ì•„ ë³´ì´ì§€ë§Œ ë³¸ì²´ë¥¼ ë³´ë©´ ì¹¼ë‚ ì´ ì œìë¦¬ì— ê³ ì •ë˜ëŠ” ë¶€ë¶„ì´ ëª‡ ë…„ ì „ì˜ ì´ì „ ë²„ì „ë§Œí¼ ì¢‹ì•„ ë³´ì´ì§€ëŠ” ì•ŠëŠ”ë°, ì €ëŠ” ì•„ì£¼ ë¶€ë“œëŸ½ê²Œ ì‚¬ìš©í•  ê³„íšì…ë‹ˆë‹¤ (ì˜ˆë¥¼ ë“¤ì–´ ì½©, ì–¼ìŒ, ìŒ€ ë“± ì•„ì£¼ ë‹¨ë‹¨í•œ ì¬ë£Œë¥¼ ë¨¼ì € ë¶„ì‡„í•œ ë‹¤ìŒ ë¶„ì‡„ê¸°ì— ë„£ê³  ë¶„ì‡„í•©ë‹ˆë‹¤). ë¨¼ì € ë¸”ë Œë”ì—ì„œ ì›í•˜ëŠ” í¬ê¸°ë¡œ ë¶„ì‡„í•œ ë‹¤ìŒ íœ˜í•‘ ë‚ ë¡œ ì „í™˜í•˜ì—¬ ë” ê³ ìš´ ê°€ë£¨ë¡œ ë§Œë“¤ê³ , ìŠ¤ë¬´ë””ë¥¼ ë§Œë“¤ ë•ŒëŠ” ë¨¼ì € ì‹­ì ì¹¼ë‚ ì„ ì‚¬ìš©í•œ ë‹¤ìŒ ë” ê³±ê±°ë‚˜ ëœ í„í”„ê°€ í•„ìš”í•œ ê²½ìš° ë‚©ì‘ ì¹¼ë‚ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤). ìŠ¤ë¬´ë””ë¥¼ ë§Œë“¤ ë•Œ íŠ¹ë³„í•œ íŒ: ê³¼ì¼ê³¼ ì±„ì†Œë¥¼ ì˜ê²Œ ì°ì–´ ì–¼ë ¤ë‘ë©´(ì‹œê¸ˆì¹˜ë¥¼ ì‚¬ìš©í•  ê²½ìš° ì‹œê¸ˆì¹˜ë¥¼ ì‚´ì§ ë°ì¹œ í›„ ì‚¬ìš©í•  ë•Œê¹Œì§€ ì–¼ë ¤ë‘ê³  ì…”ë²—ì„ ë§Œë“¤ ê²½ìš° ì¤‘ì†Œí˜• í‘¸ë“œ í”„ë¡œì„¸ì„œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”) ìŠ¤ë¬´ë””ë¥¼ ë§Œë“¤ ë•Œ ì–¼ìŒì„ ë„ˆë¬´ ë§ì´ ë„£ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•½ 1ë…„ì´ ì§€ë‚˜ì ëª¨í„°ì—ì„œ ì´ìƒí•œ ì†Œë¦¬ê°€ ë‚¬ì–´ìš”. ê³ ê° ì„œë¹„ìŠ¤ì— ì „í™”í–ˆì§€ë§Œ ì´ë¯¸ ë³´ì¦ ê¸°ê°„ì´ ë§Œë£Œë˜ì–´ì„œ ë‹¤ë¥¸ ì œí’ˆì„ êµ¬ì…í•´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì°¸ê³ : ì´ëŸ¬í•œ ìœ í˜•ì˜ ì œí’ˆì—ì„œëŠ” ì „ë°˜ì ì¸ í’ˆì§ˆì´ í–¥ìƒë˜ì—ˆê¸° ë•Œë¬¸ì— ë¸Œëœë“œ ì¸ì§€ë„ì™€ ì†Œë¹„ì ì¶©ì„±ë„ì— ì˜ì¡´í•˜ì—¬ íŒë§¤ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•½ ì´í‹€ ë§Œì— ë°›ì•˜ìŠµë‹ˆë‹¤.\n\"\"\"\n\nprompt = f\"\"\"\në‹¹ì‹ ì€ ê³ ê° ì„œë¹„ìŠ¤ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\në‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì†Œì¤‘í•œ ê³ ê°ì—ê²Œ ì´ë©”ì¼ ë‹µì¥ì„ ë³´ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤.\n``` êµ¬ë¶„ìë¡œ êµ¬ë¶„ëœ ê³ ê° ì´ë©”ì¼ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤, \n\nê³ ê°ì˜ ë¦¬ë·°ì— ëŒ€í•œ ê°ì‚¬ì˜ ë‹µì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\nê°ì •ì´ ê¸ì •ì ì´ê±°ë‚˜ ì¤‘ë¦½ì ì¸ ê²½ìš° ê³ ê°ì˜ ë¦¬ë·°ì— ê°ì‚¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\nê°ì •ì´ ë¶€ì •ì ì´ë©´ ì‚¬ê³¼í•˜ê³  ê³ ê° ì„œë¹„ìŠ¤ì— ë¬¸ì˜í•  ìˆ˜ ìˆë„ë¡ ê³ ê° ì„œë¹„ìŠ¤ì— ë¬¸ì˜í•  ìˆ˜ ìˆë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤. \n\nê³ ê° í›„ê¸°ì˜ êµ¬ì²´ì ì¸ ì„¸ë¶€ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\nê°„ê²°í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”.\nì´ë©”ì¼ì— 'AI ê³ ê° ìƒë‹´ì›'ìœ¼ë¡œ ì„œëª…í•©ë‹ˆë‹¤.\n\nê³ ê° í›„ê¸°: ```{review}```\ní›„ê¸° ê°ì„±: {sentiment}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nì•ˆë…•í•˜ì„¸ìš”,\n\nì €í¬ ì œí’ˆì„ êµ¬ë§¤í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ í›„ê¸°ë¥¼ ì½ì–´ë³´ë‹ˆ ì œí’ˆì— ëŒ€í•œ ì‹¤ë§ì´ í¬ê²Œ ëŠê»´ì§‘ë‹ˆë‹¤. ì´ì— ëŒ€í•´ ì§„ì‹¬ìœ¼ë¡œ ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤.\n\nê³ ê°ë‹˜ê»˜ì„œ ì–¸ê¸‰í•˜ì‹  ë¬¸ì œì ì€ ì €í¬ ì œí’ˆì˜ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìœ¼ë©°, ê³ ê°ë‹˜ì˜ ì†Œì¤‘í•œ ì˜ê²¬ì„ ë°˜ì˜í•˜ì—¬ ë” ë‚˜ì€ ì œí’ˆì„ ë§Œë“¤ê¸° ìœ„í•´ ë…¸ë ¥í•  ê²ƒì…ë‹ˆë‹¤.\n\në§Œì•½ ë‹¤ë¥¸ ì œí’ˆì„ êµ¬ì…í•˜ì‹œë ¤ëŠ” ê²½ìš°, ì €í¬ ê³ ê° ì„œë¹„ìŠ¤íŒ€ì— ë¬¸ì˜í•˜ì‹œë©´ ë‹¤ì–‘í•œ ì œí’ˆì— ëŒ€í•œ ì •ë³´ì™€ ì¡°ì–¸ì„ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê°ì‚¬í•©ë‹ˆë‹¤.\n\nAI ê³ ê° ìƒë‹´ì›"
  },
  {
    "objectID": "pandasai.html",
    "href": "pandasai.html",
    "title": "chatGPT",
    "section": "",
    "text": "PandasAIëŠ” ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ë¶„ì„ ë° ì¡°ì‘ ë„êµ¬ì¸ Pandasì— ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ê¸°ëŠ¥ì„ ì¶”ê°€í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” íŒë‹¤ìŠ¤ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë‚˜ íŒë‹¤ìŠ¤ë¥¼ ëŒ€ì²´í•  ìˆ˜ëŠ” ì—†ë‹¤. ì´ìœ ëŠ” íŒë‹¤ìŠ¤ ë¬¸ë²•ì— ë§ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ìš©ë„ì— ì í•©í•˜ê¸° ë•Œë¬¸ì´ë‹¤.\n\n1 ì‹œê°í™”\n\n\n\n\n\n\n\n\n\n\n'Sure, I can help you with that! To create a horizontal bar chart of countries showing their GDP, we can use different colors for each bar. Would you like me to guide you through the process?'\n\n\nì›ì²œ: PandasAI ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\n\n\n\n\n\n\n'Can you please create a scatter plot showing the relationship between GDP and happiness index, and label each point with the corresponding country name without overlapping?'\n\n\nì›ì²œ: PandasAI ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\n\n2 ì½”ë“œ ì„¤ì •\n\n\nì½”ë“œ# Instantiate a LLM\nfrom pandasai.llm.openai import OpenAI\nllm = OpenAI(api_token=openai.api_key,\n             model=\"gpt-3.5-turbo\",\n             temperature=0)\n\npandas_ai = PandasAI(llm)\npandas_ai.run(df, prompt='Which are the 5 happiest countries?')\n\n'According to the data, the top 5 happiest countries are the United States, Canada, Australia, United Kingdom, and Germany.'\n\n\nì›ì²œ: PandasAI ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "penguins_analytics.html",
    "href": "penguins_analytics.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œlibrary(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n\npenguins &lt;- palmerpenguins::penguins %&gt;% \n  drop_na()\n\n\n\në²”ì£¼í˜• ë³€ìˆ˜(species, island, sex) ê´€ê³„ë¥¼ ì‚´í´ë³´ì.\n\nspecies, island ì‹œê°í™”, í‘œ, ê²€ì • í†µê³„ëŸ‰ì„ í†µí•´ ì„œë¡œ ë…ë¦½ì´ ì•„ë‹˜ì´ í™•ì¸ëœë‹¤.\nâ€“ Adelie: ì•„ë¸ë¦¬ í­ê·„ì€ ëª¨ë“  ì„¬ì— ì„œì‹ â€“ Gentoo: ì  íˆ¬ í­ê·„ì€ ë¹„ìŠ¤ì½”(Biscoe) ì„¬ì—ë§Œ ì„œì‹ â€“ Chinstrap: í„±ëˆ í­ê·„ì€ ë“œë¦¼(Dream) ì„¬ì—ë§Œ ì„œì‹.\n\n\n\nì½”ë“œpenguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"í­ê·„ì¢…ê³¼ ì„œì‹í•˜ëŠ” ì„¬\",\n       x = \"ì„¬\",\n       y = \"í­ê·„ì¢…ëª…\") \n\n\n\n\n\n\n\nì½”ë“œlibrary(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      Biscoe\n      Dream\n      Torgersen\n    \n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n\nì½”ë“œlibrary(infer)\n\n\n# ê´€ì¸¡í†µê³„ëŸ‰\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# í†µê³„ê²€ì • ì‹œê°í™”\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")  \n\n\n\n\n\n\nì½”ë“œ\n# Pê°’\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0\n\n\n\në‹¤ë¥¸ speciesì™€ sex, sexì™€ island ë²”ì£¼ ì‚¬ì´ëŠ” íŠ¹ë³„í•œ ê´€ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.\n\n\n\nì½”ë“œlibrary(janitor)\nlibrary(gt)\n\npenguins %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"í•©ê³„\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \n  tab_options(table.font.names = 'NanumGothic',\n                column_labels.font.weight = 'bold',\n                heading.title.font.size = 14,\n                heading.subtitle.font.size = 14,\n                table.font.color = 'steelblue',\n                source_notes.font.size = 10,\n                #source_notes.\n                table.font.size = 14) %&gt;%   \n    gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      female\n      male\n    \n\n\nAdelie\n50.0%  (73)\n50.0%  (73)\n\n\nChinstrap\n50.0%  (34)\n50.0%  (34)\n\n\nGentoo\n48.7%  (58)\n51.3%  (61)\n\n\ní•©ê³„\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% \n  count(island, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"í•©ê³„\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \ntab_options(table.font.names = 'NanumGothic',\n              column_labels.font.weight = 'bold',\n              heading.title.font.size = 14,\n              heading.subtitle.font.size = 14,\n              table.font.color = 'darkgreen',\n              source_notes.font.size = 10,\n              #source_notes.\n              table.font.size = 14) %&gt;%   \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nisland\n      female\n      male\n    \n\n\nBiscoe\n49.1%  (80)\n50.9%  (83)\n\n\nDream\n49.6%  (61)\n50.4%  (62)\n\n\nTorgersen\n51.1%  (24)\n48.9%  (23)\n\n\ní•©ê³„\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\n\n\n\nSimple Correlation Analysis in R using Tidyverse Principles\n\npenguins ë°ì´í„°í”„ë ˆì„ì—ì„œ ì—°ì†í˜• ë³€ìˆ˜ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒê´€ê´€ê³„ë¥¼ ì‚´í´ë³´ì.\n\n\n\nì½”ë“œlibrary(corrplot)\n\npenguins_num &lt;- penguins %&gt;% \n  select(-year) %&gt;% \n  select_if(is.numeric) \n\npenguins_num %&gt;% \n  cor() %&gt;% \n  corrplot(type = \"upper\", order = \"hclust\", \n         tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\nì½”ë“œlibrary(corrr)\nlibrary(gt)\n\npenguins_num %&gt;% \n  rename_with(.cols = everything(), .fn = ~str_remove(., pattern = \"_mm|_g\")) %&gt;% \n  corrr::correlate( use = \"pairwise.complete.obs\",\n                    method = \"pearson\") %&gt;% \n  rearrange() %&gt;% \n  shave() %&gt;% \n  # fashion() %&gt;% \n  gt::gt() %&gt;% \n  # ìƒê´€ê³„ìˆ˜ ìƒ‰ìƒ\n  data_color(\n    columns = where(is.numeric),\n    colors = scales::col_numeric(\n      ## option D for Viridis - correlation coloring\n      palette = RColorBrewer::brewer.pal(9, \"RdBu\"), \n      domain = NULL,\n      na.color = 'white')\n  ) %&gt;% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) %&gt;% \n  cols_align(align = \"center\", columns = everything()) %&gt;% \n  gtExtras::gt_theme_538()  \n\n\n\n\n\n\nterm\n      flipper_length\n      body_mass\n      bill_length\n      bill_depth\n    \n\n\nflipper_length\n-\n-\n-\n-\n\n\nbody_mass\n0.8729789\n-\n-\n-\n\n\nbill_length\n0.6530956\n0.5894511\n-\n-\n\n\nbill_depth\n-0.5777917\n-0.4720157\n-0.2286256\n-\n\n\n\n\n\n\nì½”ë“œcorrr::correlate(penguins_num) %&gt;% \n  stretch(remove.dups = TRUE) %&gt;% \n  filter(!is.na(r)) %&gt;% \n  arrange(desc(r)) %&gt;% \n  mutate(ìŒì–‘ = ifelse(r &gt; 0, \"ì–‘ì˜ ìƒê´€\", \"ìŒì˜ ìƒê´€\")) %&gt;% \n  mutate(color = \"\") %&gt;% \n  gt(groupname_col = \"ìŒì–‘\") %&gt;% \n  fmt_number(\n    columns = r,\n    decimals = 2,\n    use_seps = FALSE\n  )  %&gt;% \n  data_color(\n    columns = r,\n    target_columns = color,\n    method = \"numeric\",\n    palette = RColorBrewer::brewer.pal(9, \"RdBu\")\n  ) %&gt;% \n  cols_label(\n    x = \"\",\n    y = \"\",\n    r = \"ìƒê´€ê³„ìˆ˜\",\n    color = \"\"\n  ) |&gt;\n  opt_vertical_padding(scale = 0.7)  %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\n      \n      ìƒê´€ê³„ìˆ˜\n      \n    \n\n\nì–‘ì˜ ìƒê´€\n    \n\nflipper_length_mm\nbody_mass_g\n0.87\n\n\n\nbill_length_mm\nflipper_length_mm\n0.65\n\n\n\nbill_length_mm\nbody_mass_g\n0.59\n\n\n\nìŒì˜ ìƒê´€\n    \n\nbill_length_mm\nbill_depth_mm\nâˆ’0.23\n\n\n\nbill_depth_mm\nbody_mass_g\nâˆ’0.47\n\n\n\nbill_depth_mm\nflipper_length_mm\nâˆ’0.58\n\n\n\n\n\n\n\n\n\n\n\nì½”ë“œlibrary(GGally)\n\npenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggparcoord(columns = 2:5,\n             showPoints = TRUE,\n             groupColumn = \"species\") +\n  scale_color_manual(values = penguins_colors)\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggpairs(columns = 2:5, ggplot2::aes(colour=species),\n          upper = list(continuous='density', combo='box_no_facet'),\n          axisLabels='internal') +\n  scale_color_manual(values = penguins_colors) +\n  scale_fill_manual(values = penguins_colors) +\n  theme_minimal()"
  },
  {
    "objectID": "penguins_analytics.html#ì‹œê°í™”",
    "href": "penguins_analytics.html#ì‹œê°í™”",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œpenguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"í­ê·„ì¢…ê³¼ ì„œì‹í•˜ëŠ” ì„¬\",\n       x = \"ì„¬\",\n       y = \"í­ê·„ì¢…ëª…\")"
  },
  {
    "objectID": "penguins_analytics.html#í†µê³„ëŸ‰",
    "href": "penguins_analytics.html#í†µê³„ëŸ‰",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œlibrary(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\nBiscoe\nDream\nTorgersen\n\n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\nì½”ë“œ\nlibrary(infer)\n\nnull_dist_theory &lt;-penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\")\n\nnull_dist_sim &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 100, type = \"permute\") %&gt;%\n  calculate(stat = \"Chisq\")\n\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n\nnull_dist_sim %&gt;% \n  visualise(method = \"both\") +\n  shade_p_value(observed_indep_statistic,\n                direction = \"both\")\n\n\n\n\n\n\nì½”ë“œ\nnull_dist_sim %&gt;%\n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0"
  },
  {
    "objectID": "penguins_analytics.html#í‘œ",
    "href": "penguins_analytics.html#í‘œ",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œlibrary(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\nBiscoe\nDream\nTorgersen\n\n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0"
  },
  {
    "objectID": "penguins_analytics.html#í†µê³„ê²€ì •",
    "href": "penguins_analytics.html#í†µê³„ê²€ì •",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œlibrary(infer)\n\n\n# ê´€ì¸¡í†µê³„ëŸ‰\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# í†µê³„ê²€ì • ì‹œê°í™”\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")"
  },
  {
    "objectID": "penguins_analytics.html#species-island",
    "href": "penguins_analytics.html#species-island",
    "title": "chatGPT",
    "section": "\n2.1 species, island\n",
    "text": "2.1 species, island\n\nspecies, island ì‹œê°í™”, í‘œ, ê²€ì • í†µê³„ëŸ‰ì„ í†µí•´ ì„œë¡œ ë…ë¦½ì´ ì•„ë‹˜ì´ í™•ì¸ëœë‹¤.\nâ€“ Adelie: ì•„ë¸ë¦¬ í­ê·„ì€ ëª¨ë“  ì„¬ì— ì„œì‹ â€“ Gentoo: ì  íˆ¬ í­ê·„ì€ ë¹„ìŠ¤ì½”(Biscoe) ì„¬ì—ë§Œ ì„œì‹ â€“ Chinstrap: í„±ëˆ í­ê·„ì€ ë“œë¦¼(Dream) ì„¬ì—ë§Œ ì„œì‹.\n\n\nì‹œê°í™”\nì½”ë“œpenguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"í­ê·„ì¢…ê³¼ ì„œì‹í•˜ëŠ” ì„¬\",\n       x = \"ì„¬\",\n       y = \"í­ê·„ì¢…ëª…\") \n\n\n\n\n\n\ní‘œ\nì½”ë“œlibrary(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      Biscoe\n      Dream\n      Torgersen\n    \n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\ní†µê³„ê²€ì •\nì½”ë“œlibrary(infer)\n\n\n# ê´€ì¸¡í†µê³„ëŸ‰\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# í†µê³„ê²€ì • ì‹œê°í™”\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")  \n\n\n\n\n\n\nì½”ë“œ\n# Pê°’\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0\n\n\n\në‹¤ë¥¸ speciesì™€ sex, sexì™€ island ë²”ì£¼ ì‚¬ì´ëŠ” íŠ¹ë³„í•œ ê´€ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.\n\n\n\nspeciesì™€ sex\n\nì½”ë“œlibrary(janitor)\nlibrary(gt)\n\npenguins %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"í•©ê³„\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \n  tab_options(table.font.names = 'NanumGothic',\n                column_labels.font.weight = 'bold',\n                heading.title.font.size = 14,\n                heading.subtitle.font.size = 14,\n                table.font.color = 'steelblue',\n                source_notes.font.size = 10,\n                #source_notes.\n                table.font.size = 14) %&gt;%   \n    gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      female\n      male\n    \n\n\nAdelie\n50.0%  (73)\n50.0%  (73)\n\n\nChinstrap\n50.0%  (34)\n50.0%  (34)\n\n\nGentoo\n48.7%  (58)\n51.3%  (61)\n\n\ní•©ê³„\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\nsexì™€ island\n\nì½”ë“œpenguins %&gt;% \n  count(island, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"í•©ê³„\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \ntab_options(table.font.names = 'NanumGothic',\n              column_labels.font.weight = 'bold',\n              heading.title.font.size = 14,\n              heading.subtitle.font.size = 14,\n              table.font.color = 'darkgreen',\n              source_notes.font.size = 10,\n              #source_notes.\n              table.font.size = 14) %&gt;%   \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nisland\n      female\n      male\n    \n\n\nBiscoe\n49.1%  (80)\n50.9%  (83)\n\n\nDream\n49.6%  (61)\n50.4%  (62)\n\n\nTorgersen\n51.1%  (24)\n48.9%  (23)\n\n\ní•©ê³„\n49.5% (165)\n50.5% (168)"
  },
  {
    "objectID": "penguins_analytics.html#ë²”ì£¼í˜•-ë³€ìˆ˜",
    "href": "penguins_analytics.html#ë²”ì£¼í˜•-ë³€ìˆ˜",
    "title": "chatGPT",
    "section": "",
    "text": "ë²”ì£¼í˜• ë³€ìˆ˜(species, island, sex) ê´€ê³„ë¥¼ ì‚´í´ë³´ì.\n\nspecies, island ì‹œê°í™”, í‘œ, ê²€ì • í†µê³„ëŸ‰ì„ í†µí•´ ì„œë¡œ ë…ë¦½ì´ ì•„ë‹˜ì´ í™•ì¸ëœë‹¤.\nâ€“ Adelie: ì•„ë¸ë¦¬ í­ê·„ì€ ëª¨ë“  ì„¬ì— ì„œì‹ â€“ Gentoo: ì  íˆ¬ í­ê·„ì€ ë¹„ìŠ¤ì½”(Biscoe) ì„¬ì—ë§Œ ì„œì‹ â€“ Chinstrap: í„±ëˆ í­ê·„ì€ ë“œë¦¼(Dream) ì„¬ì—ë§Œ ì„œì‹.\n\n\n\nì½”ë“œpenguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"í­ê·„ì¢…ê³¼ ì„œì‹í•˜ëŠ” ì„¬\",\n       x = \"ì„¬\",\n       y = \"í­ê·„ì¢…ëª…\") \n\n\n\n\n\n\n\nì½”ë“œlibrary(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      Biscoe\n      Dream\n      Torgersen\n    \n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n\nì½”ë“œlibrary(infer)\n\n\n# ê´€ì¸¡í†µê³„ëŸ‰\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# í†µê³„ê²€ì • ì‹œê°í™”\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")  \n\n\n\n\n\n\nì½”ë“œ\n# Pê°’\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 Ã— 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0\n\n\n\në‹¤ë¥¸ speciesì™€ sex, sexì™€ island ë²”ì£¼ ì‚¬ì´ëŠ” íŠ¹ë³„í•œ ê´€ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.\n\n\n\nì½”ë“œlibrary(janitor)\nlibrary(gt)\n\npenguins %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"í•©ê³„\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \n  tab_options(table.font.names = 'NanumGothic',\n                column_labels.font.weight = 'bold',\n                heading.title.font.size = 14,\n                heading.subtitle.font.size = 14,\n                table.font.color = 'steelblue',\n                source_notes.font.size = 10,\n                #source_notes.\n                table.font.size = 14) %&gt;%   \n    gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      female\n      male\n    \n\n\nAdelie\n50.0%  (73)\n50.0%  (73)\n\n\nChinstrap\n50.0%  (34)\n50.0%  (34)\n\n\nGentoo\n48.7%  (58)\n51.3%  (61)\n\n\ní•©ê³„\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% \n  count(island, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"í•©ê³„\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \ntab_options(table.font.names = 'NanumGothic',\n              column_labels.font.weight = 'bold',\n              heading.title.font.size = 14,\n              heading.subtitle.font.size = 14,\n              table.font.color = 'darkgreen',\n              source_notes.font.size = 10,\n              #source_notes.\n              table.font.size = 14) %&gt;%   \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nisland\n      female\n      male\n    \n\n\nBiscoe\n49.1%  (80)\n50.9%  (83)\n\n\nDream\n49.6%  (61)\n50.4%  (62)\n\n\nTorgersen\n51.1%  (24)\n48.9%  (23)\n\n\ní•©ê³„\n49.5% (165)\n50.5% (168)"
  },
  {
    "objectID": "penguins_analytics.html#ì—°ì†í˜•-ë³€ìˆ˜",
    "href": "penguins_analytics.html#ì—°ì†í˜•-ë³€ìˆ˜",
    "title": "chatGPT",
    "section": "",
    "text": "Simple Correlation Analysis in R using Tidyverse Principles\n\npenguins ë°ì´í„°í”„ë ˆì„ì—ì„œ ì—°ì†í˜• ë³€ìˆ˜ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒê´€ê´€ê³„ë¥¼ ì‚´í´ë³´ì.\n\n\n\nì½”ë“œlibrary(corrplot)\n\npenguins_num &lt;- penguins %&gt;% \n  select(-year) %&gt;% \n  select_if(is.numeric) \n\npenguins_num %&gt;% \n  cor() %&gt;% \n  corrplot(type = \"upper\", order = \"hclust\", \n         tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\nì½”ë“œlibrary(corrr)\nlibrary(gt)\n\npenguins_num %&gt;% \n  rename_with(.cols = everything(), .fn = ~str_remove(., pattern = \"_mm|_g\")) %&gt;% \n  corrr::correlate( use = \"pairwise.complete.obs\",\n                    method = \"pearson\") %&gt;% \n  rearrange() %&gt;% \n  shave() %&gt;% \n  # fashion() %&gt;% \n  gt::gt() %&gt;% \n  # ìƒê´€ê³„ìˆ˜ ìƒ‰ìƒ\n  data_color(\n    columns = where(is.numeric),\n    colors = scales::col_numeric(\n      ## option D for Viridis - correlation coloring\n      palette = RColorBrewer::brewer.pal(9, \"RdBu\"), \n      domain = NULL,\n      na.color = 'white')\n  ) %&gt;% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) %&gt;% \n  cols_align(align = \"center\", columns = everything()) %&gt;% \n  gtExtras::gt_theme_538()  \n\n\n\n\n\n\nterm\n      flipper_length\n      body_mass\n      bill_length\n      bill_depth\n    \n\n\nflipper_length\n-\n-\n-\n-\n\n\nbody_mass\n0.8729789\n-\n-\n-\n\n\nbill_length\n0.6530956\n0.5894511\n-\n-\n\n\nbill_depth\n-0.5777917\n-0.4720157\n-0.2286256\n-\n\n\n\n\n\n\nì½”ë“œcorrr::correlate(penguins_num) %&gt;% \n  stretch(remove.dups = TRUE) %&gt;% \n  filter(!is.na(r)) %&gt;% \n  arrange(desc(r)) %&gt;% \n  mutate(ìŒì–‘ = ifelse(r &gt; 0, \"ì–‘ì˜ ìƒê´€\", \"ìŒì˜ ìƒê´€\")) %&gt;% \n  mutate(color = \"\") %&gt;% \n  gt(groupname_col = \"ìŒì–‘\") %&gt;% \n  fmt_number(\n    columns = r,\n    decimals = 2,\n    use_seps = FALSE\n  )  %&gt;% \n  data_color(\n    columns = r,\n    target_columns = color,\n    method = \"numeric\",\n    palette = RColorBrewer::brewer.pal(9, \"RdBu\")\n  ) %&gt;% \n  cols_label(\n    x = \"\",\n    y = \"\",\n    r = \"ìƒê´€ê³„ìˆ˜\",\n    color = \"\"\n  ) |&gt;\n  opt_vertical_padding(scale = 0.7)  %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\n      \n      ìƒê´€ê³„ìˆ˜\n      \n    \n\n\nì–‘ì˜ ìƒê´€\n    \n\nflipper_length_mm\nbody_mass_g\n0.87\n\n\n\nbill_length_mm\nflipper_length_mm\n0.65\n\n\n\nbill_length_mm\nbody_mass_g\n0.59\n\n\n\nìŒì˜ ìƒê´€\n    \n\nbill_length_mm\nbill_depth_mm\nâˆ’0.23\n\n\n\nbill_depth_mm\nbody_mass_g\nâˆ’0.47\n\n\n\nbill_depth_mm\nflipper_length_mm\nâˆ’0.58\n\n\n\n\n\n\n\n\n\n\n\nì½”ë“œlibrary(GGally)\n\npenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggparcoord(columns = 2:5,\n             showPoints = TRUE,\n             groupColumn = \"species\") +\n  scale_color_manual(values = penguins_colors)\n\n\n\n\n\n\n\n\n\nì½”ë“œpenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggpairs(columns = 2:5, ggplot2::aes(colour=species),\n          upper = list(continuous='density', combo='box_no_facet'),\n          axisLabels='internal') +\n  scale_color_manual(values = penguins_colors) +\n  scale_fill_manual(values = penguins_colors) +\n  theme_minimal()"
  },
  {
    "objectID": "penguins_analytics.html#í‰í–‰-ê·¸ë˜í”„",
    "href": "penguins_analytics.html#í‰í–‰-ê·¸ë˜í”„",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œlibrary(GGally)\n\npenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggparcoord(columns = 2:5,\n             showPoints = TRUE,\n             groupColumn = \"species\") +\n  scale_color_manual(values = penguins_colors)"
  },
  {
    "objectID": "penguins_analytics.html#ì§-ì‚°ì ë„",
    "href": "penguins_analytics.html#ì§-ì‚°ì ë„",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œpenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggpairs(columns = 2:5, ggplot2::aes(colour=species),\n          upper = list(continuous='density', combo='box_no_facet'),\n          axisLabels='internal') +\n  scale_color_manual(values = penguins_colors) +\n  scale_fill_manual(values = penguins_colors) +\n  theme_minimal()"
  },
  {
    "objectID": "penguins_analytics.html#ì„±ë³„-ë¶„ë¥˜ëª¨í˜•",
    "href": "penguins_analytics.html#ì„±ë³„-ë¶„ë¥˜ëª¨í˜•",
    "title": "chatGPT",
    "section": "\n2.1 ì„±ë³„ ë¶„ë¥˜ëª¨í˜•",
    "text": "2.1 ì„±ë³„ ë¶„ë¥˜ëª¨í˜•\ní­ê·„ì˜ ì•”ìˆ˜ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê¸°ê³„í•™ìŠµëª¨í˜•ì„ ê°œë°œí•˜ê¸° ì „ì— í›ˆë ¨/ì‹œí—˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.\n\nì½”ë“œlibrary(tidymodels)\n\npenguins_split &lt;- penguins %&gt;% \n  initial_split(prop = 0.70, strata = sex)\n \npenguins_train &lt;- training(penguins_split)\npenguins_test  &lt;- testing(penguins_split)\n\n\n\n2.1.1 ë¡œì§€ìŠ¤í‹± íšŒê·€\ní­ê·„ì˜ ì•”ìˆ˜ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ìœ¼ë¡œ ë¶„ë¥˜ëª¨í˜•ì„ ê°œë°œí•´ë³´ì.\n\nì½”ë“œlogistic_spec &lt;- logistic_reg() %&gt;% \n  set_engine(\"glm\") %&gt;% \n  set_mode(\"classification\")\n\nlogistic_wflow &lt;- \n  workflow(\n    sex ~ species + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    logistic_spec\n  )\n\nlogistic_fit &lt;- logistic_wflow %&gt;% fit(data = penguins_train)\n\nsex_predict &lt;- predict(logistic_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_predict) %&gt;% \n  ggplot(aes(x = sex, y = .pred_class, color = sex)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n2.1.2 Random Forest\ní­ê·„ì˜ ì•”ìˆ˜ë¥¼ ë¶„ë¥˜í•˜ëŠ” Random Forest ëª¨í˜•ìœ¼ë¡œ ë¶„ë¥˜ëª¨í˜•ì„ ê°œë°œí•´ë³´ì.\n\nì½”ë“œrf_spec &lt;- rand_forest() %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\nrf_wflow &lt;- \n  workflow(\n    sex ~ species + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    rf_spec\n  )\n\nrf_fit &lt;- rf_wflow %&gt;% fit(data = penguins_train)\n\nsex_rf &lt;- predict(rf_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_rf) %&gt;% \n  ggplot(aes(x = sex, y = .pred_class, color = sex)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n2.1.3 SVM\ní­ê·„ì˜ ì•”ìˆ˜ë¥¼ ë¶„ë¥˜í•˜ëŠ” SVM ëª¨í˜•ìœ¼ë¡œ ë¶„ë¥˜ëª¨í˜•ì„ ê°œë°œí•´ë³´ì.\n\nì½”ë“œsvm_spec &lt;- svm_rbf() %&gt;% \n  set_engine(\"kernlab\") %&gt;% \n  set_mode(\"classification\")\n\nsvm_wflow &lt;- \n  workflow(\n    sex ~ species + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    svm_spec\n  )\n\nsvm_fit &lt;- svm_wflow %&gt;% fit(data = penguins_train)\n\nsex_svm &lt;- predict(svm_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_svm) %&gt;% \n  ggplot(aes(x = sex, y = .pred_class, color = sex)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_bw()"
  },
  {
    "objectID": "penguins_analytics.html#í­ê·„ì¢…-ë¶„ë¥˜ëª¨í˜•",
    "href": "penguins_analytics.html#í­ê·„ì¢…-ë¶„ë¥˜ëª¨í˜•",
    "title": "chatGPT",
    "section": "\n2.2 í­ê·„ì¢… ë¶„ë¥˜ëª¨í˜•",
    "text": "2.2 í­ê·„ì¢… ë¶„ë¥˜ëª¨í˜•\ní­ê·„ì¢…(ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ)ì„ ë¶„ë¥˜í•˜ëŠ” ê¸°ê³„í•™ìŠµëª¨í˜•ì„ ê°œë°œí•˜ê¸° ì „ì— í›ˆë ¨/ì‹œí—˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.\n\n2.2.1 ë‹¤í•­íšŒê·€ëª¨í˜•\ní­ê·„ì¢…(ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ)ì„ ë¶„ë¥˜í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ìœ¼ë¡œ ë¶„ë¥˜ëª¨í˜•ì„ ê°œë°œí•´ë³´ì.\n\nì½”ë“œmultinom_spec &lt;- multinom_reg() %&gt;% \n  set_mode(\"classification\")\n\nmultinom_wflow &lt;- \n  workflow(\n    species ~ sex + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    multinom_spec\n  )\n\nmultinom_fit &lt;- multinom_wflow %&gt;% fit(data = penguins_train)\n\nsex_predict &lt;- predict(multinom_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_predict) %&gt;% \n  ggplot(aes(x = species, y = .pred_class, color = species)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = penguins_colors) +\n  theme_bw()\n\n\n\n\n\n\n\n\n2.2.2 Random Forest\ní­ê·„ì¢…(ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ)ì„ ë¶„ë¥˜í•˜ëŠ” Random Forest ëª¨í˜•ìœ¼ë¡œ ë¶„ë¥˜ëª¨í˜•ì„ ê°œë°œí•´ë³´ì.\n\nì½”ë“œrf_spec &lt;- rand_forest() %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\nrf_wflow &lt;- \n  workflow(\n    species ~ sex + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    rf_spec\n  )\n\nrf_fit &lt;- rf_wflow %&gt;% fit(data = penguins_train)\n\nsex_rf &lt;- predict(rf_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_rf) %&gt;% \n  ggplot(aes(x = species, y = .pred_class, color = species)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = penguins_colors) +\n  theme()"
  },
  {
    "objectID": "penguins_analytics.html#í­ê·„-í¬ê¸°ì™€-ë¬¼ì¹¼í€´-ê¸¸ì´",
    "href": "penguins_analytics.html#í­ê·„-í¬ê¸°ì™€-ë¬¼ì¹¼í€´-ê¸¸ì´",
    "title": "chatGPT",
    "section": "\n3.1 í­ê·„ í¬ê¸°ì™€ ë¬¼ì¹¼í€´ ê¸¸ì´",
    "text": "3.1 í­ê·„ í¬ê¸°ì™€ ë¬¼ì¹¼í€´ ê¸¸ì´\n\nì½”ë“œextrafont::loadfonts()\nggplot2::theme_set(ggplot2::theme_minimal(base_family = \"MaruBuri\"))\n\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n         body_mass_mean  = mean(body_mass_g)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # í‰ê·  ì¶”ê°€\n  geom_point(data = species_mean, aes(x = flipper_mean, y = body_mass_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"ë‚¨êµ­ íŒŒë¨¸ ì—°êµ¬ìˆ˜ ì„œì‹ í­ê·„ í¬ê¸°\",\n       subtitle = \"ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ì²´ì§ˆëŸ‰ (g)\",\n       color = \"í­ê·„ì¢…\",\n       shape = \"í­ê·„ì¢…\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#ë¬¼ê°ˆí€´-ê¸¸ì´ì™€-ë¶€ë¦¬-ê¸¸ì´",
    "href": "penguins_analytics.html#ë¬¼ê°ˆí€´-ê¸¸ì´ì™€-ë¶€ë¦¬-ê¸¸ì´",
    "title": "chatGPT",
    "section": "\n3.2 ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¸¸ì´",
    "text": "3.2 ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¸¸ì´\n\nì½”ë“œ\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n            bill_mean  = mean(bill_length_mm)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = bill_length_mm)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # í‰ê·  ì¶”ê°€\n  geom_point(data = species_mean, aes(x = flipper_mean, y = bill_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¸¸ì´\",\n       subtitle = \"ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¸¸ì´ ì¹˜ìˆ˜\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ë¶€ë¦¬ ê¸¸ì´ (mm)\",\n       color = \"í­ê·„ì¢…\",\n       shape = \"í­ê·„ì¢…\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#í­ê·„í¬ê¸°ì™€-ë¬¼ì¹¼í€´",
    "href": "penguins_analytics.html#í­ê·„í¬ê¸°ì™€-ë¬¼ì¹¼í€´",
    "title": "chatGPT",
    "section": "\n3.1 í­ê·„í¬ê¸°ì™€ ë¬¼ì¹¼í€´",
    "text": "3.1 í­ê·„í¬ê¸°ì™€ ë¬¼ì¹¼í€´\n\nì½”ë“œextrafont::loadfonts()\nggplot2::theme_set(ggplot2::theme_minimal(base_family = \"MaruBuri\"))\n\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n         body_mass_mean  = mean(body_mass_g)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # í‰ê·  ì¶”ê°€\n  geom_point(data = species_mean, aes(x = flipper_mean, y = body_mass_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"ë‚¨êµ­ íŒŒë¨¸ ì—°êµ¬ìˆ˜ ì„œì‹ í­ê·„ í¬ê¸°\",\n       subtitle = \"ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ì²´ì§ˆëŸ‰ (g)\",\n       color = \"í­ê·„ì¢…\",\n       shape = \"í­ê·„ì¢…\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#ë¬¼ê°ˆí€´ì™€-ë¶€ë¦¬-ê¸¸ì´",
    "href": "penguins_analytics.html#ë¬¼ê°ˆí€´ì™€-ë¶€ë¦¬-ê¸¸ì´",
    "title": "chatGPT",
    "section": "\n3.2 ë¬¼ê°ˆí€´ì™€ ë¶€ë¦¬ ê¸¸ì´",
    "text": "3.2 ë¬¼ê°ˆí€´ì™€ ë¶€ë¦¬ ê¸¸ì´\n\nì½”ë“œ\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n            bill_mean  = mean(bill_length_mm)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = bill_length_mm)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # í‰ê·  ì¶”ê°€\n  geom_point(data = species_mean, aes(x = flipper_mean, y = bill_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¸¸ì´\",\n       subtitle = \"ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¸¸ì´ ì¹˜ìˆ˜\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ë¶€ë¦¬ ê¸¸ì´ (mm)\",\n       color = \"í­ê·„ì¢…\",\n       shape = \"í­ê·„ì¢…\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#ë¶„í¬ì™€-facet",
    "href": "penguins_analytics.html#ë¶„í¬ì™€-facet",
    "title": "chatGPT",
    "section": "\n3.3 ë¶„í¬ì™€ Facet",
    "text": "3.3 ë¶„í¬ì™€ Facet\n\n\n\nì½”ë“œggplot(data = penguins, aes(x = flipper_length_mm)) +\n  geom_histogram(aes(fill = species), \n                 alpha = 0.5, \n                 position = \"identity\") +\n  scale_fill_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ë¹ˆë„ìˆ˜\",\n       title = \"í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´\",\n       fill = \"í­ê·„ì¢…\")\n\n\n\n\n\n\n\n\nì½”ë“œggplot(data = penguins, aes(x = species, y = flipper_length_mm)) +\n  geom_boxplot(aes(color = species), width = 0.3, show.legend = FALSE) +\n  geom_jitter(aes(color = species), alpha = 0.5, show.legend = FALSE, \n              position = position_jitter(width = 0.2, seed = 0)) +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(x = \"í­ê·„ì¢…\",\n       y = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       title = \"í­ê·„ì¢…ë³„ ë¬¼ê°ˆí€´ ê¸¸ì´ ë¶„í¬\")\n\n\n\n\n\n\n\n\nì½”ë“œggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = sex)) +\n  scale_color_manual(values = c(\"darkorange\",\"cyan4\"), na.translate = FALSE) +\n  labs(title = \"í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰\",\n       subtitle = \"ì•„ë¸ë¦¬, ì  íˆ¬, í„±ëˆ í­ê·„ ë¬¼ê°ˆí€´ ê¸¸ì´ì™€ ì²´ì§ˆëŸ‰\",\n       x = \"ë¬¼ê°ˆí€´ ê¸¸ì´ (mm)\",\n       y = \"ì²´ì§ˆëŸ‰ (g)\",\n       color = \"í­ê·„ì•”ìˆ˜\") +\n  theme(legend.position = \"bottom\",\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\") +\n  facet_wrap(~species)"
  },
  {
    "objectID": "penguins_analytics.html#ì£¼ì„±ë¶„-ë¶„ì„",
    "href": "penguins_analytics.html#ì£¼ì„±ë¶„-ë¶„ì„",
    "title": "chatGPT",
    "section": "\n5.1 ì£¼ì„±ë¶„ ë¶„ì„",
    "text": "5.1 ì£¼ì„±ë¶„ ë¶„ì„\nì£¼ì„±ë¶„ ë¶„ì„(PCA)ì€ ë‹¤ë³€ëŸ‰ ë°ì´í„°ì˜ íŒ¨í„´ì„ íƒìƒ‰í•˜ëŠ” ë° ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì°¨ì› ì¶•ì†Œ ë°©ë²•ì´ë‹¤. (Allison M. Horst, 2022)\n\nì½”ë“œ# Omit year\npenguins_noyr &lt;- penguins %&gt;%\n  select(-year) %&gt;%\n  mutate(species = as.character(species)) %&gt;%\n  mutate(species = case_when(\n    species == \"Adelie\" ~ \"AdÃ©lie\",\n    TRUE ~ species\n  )) %&gt;%\n  mutate(species = as.factor(species))\n\npenguin_recipe &lt;-\n  recipe(~., data = penguins_noyr) %&gt;%\n  update_role(species, island, sex, new_role = \"id\") %&gt;%\n  step_naomit(all_predictors()) %&gt;%\n  step_normalize(all_predictors()) %&gt;%\n  step_pca(all_predictors(), id = \"pca\") %&gt;%\n  prep()\n\npenguin_pca &lt;-\n  penguin_recipe %&gt;%\n  tidy(id = \"pca\")\n\npenguin_percvar &lt;- penguin_recipe %&gt;%\n  tidy(id = \"pca\", type = \"variance\") %&gt;%\n  dplyr::filter(terms == \"percent variance\")\n\n# Make the penguins PCA biplot:\n\n# Get pca loadings into wider format\npca_wider &lt;- penguin_pca %&gt;%\n  tidyr::pivot_wider(names_from = component, id_cols = terms)\n\n# define arrow style:\narrow_style &lt;- arrow(length = unit(.05, \"inches\"),\n                     type = \"closed\")\n\npenguins_juiced &lt;- juice(penguin_recipe)\n\n# Make the penguins PCA biplot:\npca_plot &lt;-\n  penguins_juiced %&gt;%\n  ggplot(aes(PC1, PC2)) +\n  coord_cartesian(\n    xlim = c(-3, 4),\n    ylim = c(-2.5, 2))  +\n  paletteer::scale_color_paletteer_d(\"colorblindr::OkabeIto\") +\n  guides(color = guide_legend(\"Species\"),\n        shape = guide_legend(\"Species\")) +\n  theme(legend.position = \"bottom\",\n        panel.border = element_rect(color = \"gray70\", fill = NA))\n\n# For positioning (above):\n# 1: bill_length\n# 2: bill_depth\n# 3: flipper length\n# 4: body mass\n\npenguins_biplot &lt;- pca_plot +\n  geom_segment(data = pca_wider,\n               aes(xend = PC1, yend = PC2),\n               x = 0,\n               y = 0,\n               arrow = arrow_style) +\n  geom_point(aes(color = species, shape = species),\n             alpha = 0.7,\n             size = 2) +\n  shadowtext::geom_shadowtext(data = pca_wider,\n                  aes(x = PC1, y = PC2, label = terms),\n                  nudge_x = c(0.7,0.7,1.7,1.2),\n                  nudge_y = c(-0.1,-0.2,0.1,-0.1),\n                  size = 4,\n                  color = \"black\",\n                  bg.color = \"white\")\n\npenguins_biplot\n\npenguin_screeplot_base &lt;- penguin_percvar %&gt;%\n  ggplot(aes(x = component, y = value)) +\n  scale_x_continuous(limits = c(0, 5), breaks = c(1,2,3,4), expand = c(0,0)) +\n  scale_y_continuous(limits = c(0,100), expand = c(0,0)) +\n  ylab(\"% of total variance\") +\n  theme(panel.border = element_rect(color = \"gray70\", fill = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\npenguin_screeplot &lt;- penguin_screeplot_base +\n  geom_col(fill = \"gray50\") +\n  geom_text(aes(label = round(value,2)), vjust=-0.25)\n\npenguin_screeplot"
  },
  {
    "objectID": "penguins_analytics.html#êµ°ì§‘ë¶„ì„",
    "href": "penguins_analytics.html#êµ°ì§‘ë¶„ì„",
    "title": "chatGPT",
    "section": "\n5.2 êµ°ì§‘ë¶„ì„",
    "text": "5.2 êµ°ì§‘ë¶„ì„\nk-í‰ê· (K-Means) ë¹„ì§€ë„í•™ìŠµ êµ°ì§‘ë¶„ì„ì€ ê¸°ê³„í•™ìŠµ ë° ë¶„ë¥˜ì— ëŒ€í•œ ì¼ë°˜ì ì´ê³  ì¸ê¸° ìˆëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.\n\nì½”ë“œ## ---- kmeans ---------------------------------------------------------\n\n# TWO VARIABLE k-means comparison\n# Penguins: Bill length vs. bill depth\npb_species &lt;- penguins %&gt;%\n  select(species, starts_with(\"bill\")) %&gt;%\n  drop_na() %&gt;%\n  mutate(species = as.character(species)) %&gt;%\n  mutate(species = case_when(\n    species == \"Adelie\" ~ \"AdÃ©lie\",\n    TRUE ~ species\n  )) %&gt;%\n  mutate(species = as.factor(species))\n\n# Prep penguins for k-means:\npb_nospecies &lt;- pb_species %&gt;%\n  select(-species) %&gt;%\n  recipe() %&gt;%\n  step_normalize(all_numeric()) %&gt;%\n  prep() %&gt;%\n  juice()\n\n# Perform k-means on penguin bill dimensions (k = 3, w/20 centroid starts)\n\n# Save augmented data\nset.seed(100)\npb_clust &lt;-\n  pb_nospecies %&gt;%\n  kmeans(centers = 3, nstart = 20) %&gt;%\n  broom::augment(pb_species)\n\n# Get counts in each cluster by species\npb_clust_n &lt;- pb_clust %&gt;%\n  count(species, .cluster) %&gt;%\n  pivot_wider(names_from = species, values_from = n, names_sort = TRUE) %&gt;%\n  arrange(.cluster) %&gt;%\n  replace_na(list(`Adelie` = 0))\n\n# Plot penguin k-means clusters:\n# make a base plot b/c https://github.com/plotly/plotly.R/issues/1942\npb_kmeans_base &lt;-\n  pb_clust %&gt;%\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) +\n  paletteer::scale_color_paletteer_d(\"colorblindr::OkabeIto\") +\n  paletteer::scale_fill_paletteer_d(\"colorblindr::OkabeIto\") +\n  scale_x_continuous(limits = c(30, 60),\n                     breaks = c(30, 40, 50, 60)) +\n  theme(legend.position = \"bottom\",\n        panel.border = element_rect(fill = NA, color = \"gray70\")) +\n  labs(x = \"Bill length (mm)\",\n       y = \"Bill depth (mm)\",\n       color = \"Species\")\n# ggpubr::stat_chull(aes(fill = .cluster, color = .cluster),\n# alpha = 0.5, geom = \"polygon\", show.legend = FALSE)\n\npb_kmeans_gg &lt;- pb_kmeans_base +\n  geom_text(aes(label = .cluster,\n                color = species),\n            key_glyph = draw_key_rect,\n            check_overlap = TRUE)\n\npb_kmeans_plotly &lt;- pb_kmeans_base +\n  geom_text(aes(label = .cluster,\n                color = species,\n                text = paste(\"Species: \", species,\n                             \"\\nCluster: \", .cluster,\n                             \"\\nBill length (mm): \", bill_length_mm,\n                             \"\\nBill depth (mm): \", bill_depth_mm)\n                ),\n            size = 3)\n\nplotly::ggplotly(pb_kmeans_plotly, height = 300, tooltip = \"text\")"
  },
  {
    "objectID": "llama_penguins.html",
    "href": "llama_penguins.html",
    "title": "chatGPT",
    "section": "",
    "text": "LlamaIndex(GPT ì¸ë±ìŠ¤)ëŠ” LLMì„ ì™¸ë¶€ ë°ì´í„°ì™€ ì—°ê²°í•˜ê¸° ìœ„í•œ í†µí•© ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” í”„ë¡œì íŠ¸ë‹¤. ì™¸ë¶€ ë°ì´í„°ì—ëŠ” ë‹¹ì—°íˆ ë°ì´í„°í”„ë ˆì„ë„ í¬í•¨ëœë‹¤.\ní­ê·„ ë°ì´í„°ë¥¼ íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ íŒŒì´ì¬ í™˜ê²½ìœ¼ë¡œ ê°€ì ¸ì˜¨ í›„ì— LlamaIndex(GPT ì¸ë±ìŠ¤)ì— ë„£ì–´ OpenAI GPT API ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ìì—°ì–´ë¡œ ë‹¤ì–‘í•œ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "llama_penguins.html#openai-ì„¤ì •",
    "href": "llama_penguins.html#openai-ì„¤ì •",
    "title": "chatGPT",
    "section": "\n1.1 OpenAI ì„¤ì •",
    "text": "1.1 OpenAI ì„¤ì •\n\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "llama_penguins.html#ë°ì´í„°ì…‹",
    "href": "llama_penguins.html#ë°ì´í„°ì…‹",
    "title": "chatGPT",
    "section": "\n1.2 ë°ì´í„°ì…‹",
    "text": "1.2 ë°ì´í„°ì…‹\n\n\nì½”ë“œ# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-í˜„í™©",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-í˜„í™©",
    "title": "chatGPT",
    "section": "\n2.1 ê²°ì¸¡ê°’ í˜„í™©",
    "text": "2.1 ê²°ì¸¡ê°’ í˜„í™©\nshow_missing() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ê°„ëµíˆ ì „ì²´ì ì¸ ê²°ì¸¡ê°’ í˜„í™©ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.\n\n\nì½”ë“œdef show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-ì œê±°",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-ì œê±°",
    "title": "chatGPT",
    "section": "\n2.2 ê²°ì¸¡ê°’ ì œê±°",
    "text": "2.2 ê²°ì¸¡ê°’ ì œê±°\nllama-index íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œ í›„ì— GPTPandasIndex() í•¨ìˆ˜ë¡œ ê²°ì¸¡ê°’ì´ ë‹´ê¸´ í­ê·„ ë°ì´í„°í”„ë ˆì„ì„ ë„£ì–´ ìì—°ì–´ ì§ˆì˜ë¬¸ì„ ë˜ì§€ê²Œ ë˜ë©´ ì›í•˜ëŠ” íŒŒì´ì¬ ì‘ì—…ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.\n# !pip install llama-index\n\n\nì½”ë“œ# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "llama_penguins.html#openai-ì„¤ì •-1",
    "href": "llama_penguins.html#openai-ì„¤ì •-1",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n4.1 OpenAI ì„¤ì •",
    "text": "4.1 OpenAI ì„¤ì •\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#ë°ì´í„°ì…‹-1",
    "href": "llama_penguins.html#ë°ì´í„°ì…‹-1",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n4.2 ë°ì´í„°ì…‹",
    "text": "4.2 ë°ì´í„°ì…‹\n\nì½”ë“œ# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-1",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-1",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n4.3 ê²°ì¸¡ê°’",
    "text": "4.3 ê²°ì¸¡ê°’\n\n4.3.1 ê²°ì¸¡ê°’ í˜„í™©\n\nì½”ë“œdef show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n4.3.2 ê²°ì¸¡ê°’ ì œê±°\n\nì½”ë“œ# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#ì‚°ì ë„",
    "href": "llama_penguins.html#ì‚°ì ë„",
    "title": "chatGPT",
    "section": "\n6.1 ì‚°ì ë„",
    "text": "6.1 ì‚°ì ë„\n\n\nì½”ë“œresponse = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)\n\n\n\n\n\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨",
    "href": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n9.2 íˆìŠ¤í† ê·¸ë¨",
    "text": "9.2 íˆìŠ¤í† ê·¸ë¨\n\nì½”ë“œ# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#openai-ì„¤ì •-2",
    "href": "llama_penguins.html#openai-ì„¤ì •-2",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n11.1 OpenAI ì„¤ì •",
    "text": "11.1 OpenAI ì„¤ì •\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#ë°ì´í„°ì…‹-2",
    "href": "llama_penguins.html#ë°ì´í„°ì…‹-2",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n11.2 ë°ì´í„°ì…‹",
    "text": "11.2 ë°ì´í„°ì…‹\n\nì½”ë“œ# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-2",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-2",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n11.3 ê²°ì¸¡ê°’",
    "text": "11.3 ê²°ì¸¡ê°’\n\n11.3.1 ê²°ì¸¡ê°’ í˜„í™©\n\nì½”ë“œdef show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n11.3.2 ê²°ì¸¡ê°’ ì œê±°\n\nì½”ë“œ# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#ì‚°ì ë„-1",
    "href": "llama_penguins.html#ì‚°ì ë„-1",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n16.1 ì‚°ì ë„",
    "text": "16.1 ì‚°ì ë„\n\nì½”ë“œresponse = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-1",
    "href": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-1",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n16.2 íˆìŠ¤í† ê·¸ë¨",
    "text": "16.2 íˆìŠ¤í† ê·¸ë¨\n\nì½”ë“œ# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#ì‚°ì ë„-2",
    "href": "llama_penguins.html#ì‚°ì ë„-2",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n18.1 ì‚°ì ë„",
    "text": "18.1 ì‚°ì ë„"
  },
  {
    "objectID": "llama_penguins.html#openai-ì„¤ì •-3",
    "href": "llama_penguins.html#openai-ì„¤ì •-3",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n18.2 OpenAI ì„¤ì •",
    "text": "18.2 OpenAI ì„¤ì •\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#ë°ì´í„°ì…‹-3",
    "href": "llama_penguins.html#ë°ì´í„°ì…‹-3",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n18.3 ë°ì´í„°ì…‹",
    "text": "18.3 ë°ì´í„°ì…‹\n\nì½”ë“œ# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-3",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-3",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n18.4 ê²°ì¸¡ê°’",
    "text": "18.4 ê²°ì¸¡ê°’\n\n18.4.1 ê²°ì¸¡ê°’ í˜„í™©\n\nì½”ë“œdef show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n18.4.2 ê²°ì¸¡ê°’ ì œê±°\n\nì½”ë“œ# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#ì‚°ì ë„-3",
    "href": "llama_penguins.html#ì‚°ì ë„-3",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n23.1 ì‚°ì ë„",
    "text": "23.1 ì‚°ì ë„\n\nì½”ë“œresponse = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-2",
    "href": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-2",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n23.2 íˆìŠ¤í† ê·¸ë¨",
    "text": "23.2 íˆìŠ¤í† ê·¸ë¨\n\nì½”ë“œ# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#ë¶„í¬ë„",
    "href": "llama_penguins.html#ë¶„í¬ë„",
    "title": "chatGPT",
    "section": "\n6.2 ë¶„í¬ë„",
    "text": "6.2 ë¶„í¬ë„\n\n\nì½”ë“œ# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\n\n\n\n\n\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "llama_penguins.html#openai-ì„¤ì •-4",
    "href": "llama_penguins.html#openai-ì„¤ì •-4",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n24.2 OpenAI ì„¤ì •",
    "text": "24.2 OpenAI ì„¤ì •\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#ë°ì´í„°ì…‹-4",
    "href": "llama_penguins.html#ë°ì´í„°ì…‹-4",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n24.3 ë°ì´í„°ì…‹",
    "text": "24.3 ë°ì´í„°ì…‹\n\nì½”ë“œ# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-4",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-4",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n24.4 ê²°ì¸¡ê°’",
    "text": "24.4 ê²°ì¸¡ê°’\n\n24.4.1 ê²°ì¸¡ê°’ í˜„í™©\n\nì½”ë“œdef show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n24.4.2 ê²°ì¸¡ê°’ ì œê±°\n\nì½”ë“œ# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#ì‚°ì ë„-4",
    "href": "llama_penguins.html#ì‚°ì ë„-4",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n29.1 ì‚°ì ë„",
    "text": "29.1 ì‚°ì ë„\n\nì½”ë“œresponse = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-3",
    "href": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-3",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n29.2 íˆìŠ¤í† ê·¸ë¨",
    "text": "29.2 íˆìŠ¤í† ê·¸ë¨\n\nì½”ë“œ# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#openai-ì„¤ì •-5",
    "href": "llama_penguins.html#openai-ì„¤ì •-5",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n31.1 OpenAI ì„¤ì •",
    "text": "31.1 OpenAI ì„¤ì •\n\nì½”ë“œimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#ë°ì´í„°ì…‹-5",
    "href": "llama_penguins.html#ë°ì´í„°ì…‹-5",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n31.2 ë°ì´í„°ì…‹",
    "text": "31.2 ë°ì´í„°ì…‹\n\nì½”ë“œ# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#ê²°ì¸¡ê°’-5",
    "href": "llama_penguins.html#ê²°ì¸¡ê°’-5",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n31.3 ê²°ì¸¡ê°’",
    "text": "31.3 ê²°ì¸¡ê°’\n\n31.3.1 ê²°ì¸¡ê°’ í˜„í™©\n\nì½”ë“œdef show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n31.3.2 ê²°ì¸¡ê°’ ì œê±°\n\nì½”ë“œ# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#ì‚°ì ë„-5",
    "href": "llama_penguins.html#ì‚°ì ë„-5",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n36.1 ì‚°ì ë„",
    "text": "36.1 ì‚°ì ë„\n\nì½”ë“œresponse = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-4",
    "href": "llama_penguins.html#íˆìŠ¤í† ê·¸ë¨-4",
    "title": "ì‚¬ì „ì¤€ë¹„",
    "section": "\n36.2 íˆìŠ¤í† ê·¸ë¨",
    "text": "36.2 íˆìŠ¤í† ê·¸ë¨\n\nì½”ë“œ# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "sql_openai.html",
    "href": "sql_openai.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 ê´€ë ¨ì •ë³´\n(Plaetsen, 2023)\n\n2 ë°ì´í„°ë² ì´ìŠ¤\n\nSQLite Sakila Sample Database\npostgreSQL - DVD ëŒ€ì—¬ ë°ì´í„°ë² ì´ìŠ¤\nDVD ëŒ€ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n\n3 \ní”„ë¡¬í”„íŠ¸ ì°¸ì¡°: TalkToSQL\n\n4 ìì—°ì–´ â†’ SQL\ncode-davinci-002ì´ ì‚¬ìš©ì¤‘ë‹¨(deprecated)ë˜ì–´ text-davinci-002, text-davinci-003 ëª¨ë¸ë“¤ì´ Codex ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œê·¸ë¨ ì‘ì„±ì´ ê°€ëŠ¥í•˜ë‹¤.\n\n\n\nì˜ì–´ í”„ë¡¬í”„íŠ¸\n\n\nì½”ë“œprompt = \"Get all the users that are older than 35 years old\"\nmodel = \"text-davinci-002\"\ntemperature = 0.0\nmax_tokens = 50\n\nresponse = openai.Completion.create(\n    engine=model,\n    prompt=prompt,\n    temperature=temperature,\n    max_tokens=max_tokens,\n)\n\nprint(response.choices[0].text)\n\n\n\nSELECT * FROM users WHERE age &gt; 35;\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\ní•œê¸€ í”„ë¡¬í”„íŠ¸\n\n\nì½”ë“œprompt = \"users í…Œì´ë¸”ì—ì„œ 35ì„¸ ì´ìƒ ì‚¬ìš©ìë¥¼ ì¶”ì¶œí•˜ëŠ” SQL ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\"\nmodel = \"text-davinci-002\"\ntemperature = 0.5\nmax_tokens = 50\n\nresponse = openai.Completion.create(\n    engine=model,\n    prompt=prompt,\n    temperature=temperature,\n    max_tokens=max_tokens,\n)\n\nprint(response.choices[0].text)\n\n.\n\n```mysql\nSELECT * FROM users WHERE age &gt;= 35;\n```\n\n\nì›ì²œ: llama-index ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\n\n\n\n\n\n\n\nì°¸ê³ ë¬¸í—Œ\n\nPlaetsen, M. V. (2023). Using OpenAI with structured data: A beginnerâ€™s guide. In Medium. Medium. https://medium.com/@margauxvanderplaetsen/using-openai-with-structured-data-a-beginners-guide-2d12719a72a9"
  },
  {
    "objectID": "sql_openai.html#í•¨ìˆ˜",
    "href": "sql_openai.html#í•¨ìˆ˜",
    "title": "chatGPT",
    "section": "\n1.1 í•¨ìˆ˜",
    "text": "1.1 í•¨ìˆ˜\ngenerate_sql_query() í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì—¬ êµ­,ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ ë°”ë¡œ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤.\n\n\nì½”ë“œdef generate_sql_query(prompt, max_tokens = 100):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        temperature=0,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].text\n\ngenerate_sql_query(\"Get all the users that are older than 35 years old from users table\")\n\n'\\n\\nSELECT * FROM users WHERE age &gt; 35;'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "sql_openai.html#ì •ë ¬ê³¼-ì¤‘ë³µì œê±°",
    "href": "sql_openai.html#ì •ë ¬ê³¼-ì¤‘ë³µì œê±°",
    "title": "chatGPT",
    "section": "\n2.1 ì •ë ¬ê³¼ ì¤‘ë³µì œê±°",
    "text": "2.1 ì •ë ¬ê³¼ ì¤‘ë³µì œê±°\nSorting and Removing Duplicatesì— ì–¸ê¸‰ëœ â€œPerson í…Œì´ë¸”ì— ìˆëŠ” ê³¼í•™ìì˜ ì „ì²´ ì´ë¦„ì„ ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œí•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.â€ ë¼ëŠ” í€´ì¦ˆë¬¸ì œë¥¼ í’€ì–´ë³´ì.\n\n\n\nSWC ì½”ë“œ\n\nì½”ë“œlibrary(DBI)\nsurvey_db &lt;- dbConnect(RSQLite::SQLite(), \"jupyterlab/survey.db\")\ndbGetQuery(survey_db, \"SELECT personal, family FROM Person ORDER BY family ASC;\")\n#&gt;    personal   family\n#&gt; 1     Frank Danforth\n#&gt; 2   William     Dyer\n#&gt; 3  Anderson     Lake\n#&gt; 4     Frank  Pabodie\n#&gt; 5 Valentina  Roerich\n\n\n\n\nì±—GPT ì½”ë“œ\n\n\nì½”ë“œdb_chain.run(\"Write a query that displays the full names of the scientists in the Person table, ordered by family name.\")\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nWrite a query that displays the full names of the scientists in the Person table, ordered by family name.\nSQLQuery: SELECT \"personal\" || ' ' || \"family\" AS \"Full Name\" FROM \"Person\" ORDER BY \"family\" ASC LIMIT 5;\nSQLResult: [('Frank Danforth',), ('William Dyer',), ('Anderson Lake',), ('Frank Pabodie',), ('Valentina Roerich',)]\nAnswer: The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.\n&gt; Finished chain.\n\n\n' The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "sql_openai.html#ì´ê³„",
    "href": "sql_openai.html#ì´ê³„",
    "title": "chatGPT",
    "section": "\n2.2 ì´ê³„",
    "text": "2.2 ì´ê³„\nCalculating New Valuesì— ì–¸ê¸‰ëœ â€œìì„¸íˆ ì½ì–´ë³¸ ê²°ê³¼, ë°œë Œí‹°ë‚˜ ë¡œë¦¬íˆê°€ ì—¼ë„ë¥¼ ë°±ë¶„ìœ¨ë¡œ ë³´ê³ í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¤ë¬¸ ì¡°ì‚¬ í…Œì´ë¸”ì—ì„œ ê·¸ë…€ì˜ ëª¨ë“  ì—¼ë„ ì¸¡ì •ê°’ì„ 100ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì„ ë°˜í™˜í•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.(After further reading, we realize that Valentina Roerich was reporting salinity as percentages. Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.)â€ ë¼ëŠ” í€´ì¦ˆë¬¸ì œë¥¼ í’€ì–´ë³´ì.\n\n\n\nSWC ì½”ë“œ\n\nì½”ë“œdbGetQuery(survey_db, \"SELECT taken, reading / 100 FROM Survey WHERE person = 'roe' AND quant = 'sal';\")\n#&gt;   taken reading / 100\n#&gt; 1   752         0.416\n#&gt; 2   837         0.225\n\n\n\n\nì±—GPT ì½”ë“œ\n\n\nì½”ë“œdb_chain.run('After further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.\\\n              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nAfter further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.\nSQLQuery: SELECT person, quant, reading/100 AS reading FROM Survey WHERE person = 'roe' AND quant = 'sal';\nSQLResult: [('roe', 'sal', 0.41600000000000004), ('roe', 'sal', 0.225)]\nAnswer: Valentina Roerich reported salinity measurements of 0.416 and 0.225.\n&gt; Finished chain.\n\n\n' Valentina Roerich reported salinity measurements of 0.416 and 0.225.'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "sql_openai.html#ì±—gpt-ëª¨ë¸",
    "href": "sql_openai.html#ì±—gpt-ëª¨ë¸",
    "title": "chatGPT",
    "section": "\n2.3 ì±—GPT ëª¨ë¸",
    "text": "2.3 ì±—GPT ëª¨ë¸\nì•ì„  ì™„ì„±(Completion) ëª¨í˜• ëŒ€ì‹  ì±—GPT ëª¨í˜•ì„ ì‚¬ìš©í•˜ì—¬ ê³ ê¸‰ SQLë¬¸ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í™•ë³´í•˜ì.\n\n\nì½”ë“œdb_chain.run('print database schema info')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nprint database schema info\nSQLQuery: SELECT * FROM sqlite_master;\nSQLResult: [('table', 'Person', 'Person', 2, 'CREATE TABLE Person (id text, personal text, family text)'), ('table', 'Site', 'Site', 3, 'CREATE TABLE Site (name text, lat real, long real)'), ('table', 'Survey', 'Survey', 5, 'CREATE TABLE Survey (taken integer, person text, quant text, reading real)'), ('table', 'Visited', 'Visited', 4, 'CREATE TABLE Visited (id integer, site text, dated text)')]\nAnswer: The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).\n&gt; Finished chain.\n\n\n' The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶\ní”„ë¡¬í”„íŠ¸ ì°¸ì¡°: TalkToSQL\nCombining Dataì— ë‚˜ì˜¤ëŠ” ì‚¬ë¡€ë¥¼ ì œëŒ€ë¡œ SQL ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•˜ê¸° ìœ„í•´ì„œëŠ” system_promptì— ì—­í•  ë¶€ì—¬ëŠ” ë¬¼ë¡  Few-Shot learningì„ ìœ„í•œ ì‚¬ë¡€ë„ ì „ë‹¬í•˜ê³  user_prompt í”„ë¡¬í”„íŠ¸ ì‘ì„±ì— ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë³´ë„ ë„˜ê²¨ì¤˜ì•¼ ì›í•˜ëŠ” ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•  ê°€ëŠ¥ì´ ë†’ì•„ì§„ë‹¤.\n\n\nì½”ë“œsystem_prompt = \"\"\"\n    You are the world's best SQL expert. Help me convert natural language to valid SQL queries. Only respond with valid SQL queries, nothing else.\n    You must learn the column names based on the information the user gives you and build valid SQL queries. Never guess the column names.\n    These are the examples:\n\n    query: get all people names\n    answer: SELECT name from people;\n\n    query: get all cars whose owner name is aaron\n    answer: SELECT c.* FROM people p JOIN cars c ON p.id = c.owner_id WHERE p.name = 'aaron';\n\"\"\"\n\nquery='Write a query that lists all radiation readings from the DR-1 site step-by-step'\n\nuser_prompt = f\"\"\"\n    This is my database information:\n    Person (id text, personal text, family text), \n    Site (name text, lat real, long real), \n    Survey (taken integer, person text, quant text, reading real), \n    Visited (id integer, site text, dated text)\n\n    query: {query}\n    answer:\n\"\"\"\n\n\n\ncompletion = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_prompt},\n    ],\n)\nprint(completion.choices[0].message.content)\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\n\nSWC ì½”ë“œ\n\nì½”ë“œdbGetQuery(survey_db, \"SELECT\n   Survey.reading\nFROM\n   Site\n   JOIN\n      Visited\n  JOIN\n      Survey\n      ON Site.name = Visited.site\n      AND Visited.id = Survey.taken\nWHERE\n   Site.name = 'DR-1'\n   AND Survey.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25\n\n\n\n\nì±—GPT ì½”ë“œ\n\nì½”ë“œdbGetQuery(survey_db, \"SELECT s.reading\n           FROM Visited v\n           JOIN Survey s ON v.id = s.taken AND v.site = 'DR-1'\n           WHERE s.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25"
  },
  {
    "objectID": "news_release.html#í•¨ìˆ˜",
    "href": "news_release.html#í•¨ìˆ˜",
    "title": "chatGPT",
    "section": "\n1.1 í•¨ìˆ˜",
    "text": "1.1 í•¨ìˆ˜\ngenerate_sql_query() í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì—¬ êµ­,ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ ë°”ë¡œ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤.\n\n\nì½”ë“œdef generate_sql_query(prompt, max_tokens = 100):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        temperature=0,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].text\n\ngenerate_sql_query(\"Get all the users that are older than 35 years old from users table\")\n\n'\\n\\nSELECT * FROM users WHERE age &gt; 35;'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "news_release.html#ì •ë ¬ê³¼-ì¤‘ë³µì œê±°",
    "href": "news_release.html#ì •ë ¬ê³¼-ì¤‘ë³µì œê±°",
    "title": "chatGPT",
    "section": "\n2.1 ì •ë ¬ê³¼ ì¤‘ë³µì œê±°",
    "text": "2.1 ì •ë ¬ê³¼ ì¤‘ë³µì œê±°\nSorting and Removing Duplicatesì— ì–¸ê¸‰ëœ â€œPerson í…Œì´ë¸”ì— ìˆëŠ” ê³¼í•™ìì˜ ì „ì²´ ì´ë¦„ì„ ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œí•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.â€ ë¼ëŠ” í€´ì¦ˆë¬¸ì œë¥¼ í’€ì–´ë³´ì.\n\n\n\nSWC ì½”ë“œ\n\nì½”ë“œlibrary(DBI)\nsurvey_db &lt;- dbConnect(RSQLite::SQLite(), \"jupyterlab/survey.db\")\ndbGetQuery(survey_db, \"SELECT personal, family FROM Person ORDER BY family ASC;\")\n#&gt;    personal   family\n#&gt; 1     Frank Danforth\n#&gt; 2   William     Dyer\n#&gt; 3  Anderson     Lake\n#&gt; 4     Frank  Pabodie\n#&gt; 5 Valentina  Roerich\n\n\n\n\nì±—GPT ì½”ë“œ\n\n\nì½”ë“œdb_chain.run(\"Write a query that displays the full names of the scientists in the Person table, ordered by family name.\")\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nWrite a query that displays the full names of the scientists in the Person table, ordered by family name.\nSQLQuery: SELECT \"personal\" || ' ' || \"family\" AS \"Full Name\" FROM \"Person\" ORDER BY \"family\" ASC LIMIT 5;\nSQLResult: [('Frank Danforth',), ('William Dyer',), ('Anderson Lake',), ('Frank Pabodie',), ('Valentina Roerich',)]\nAnswer: The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.\n&gt; Finished chain.\n\n\n' The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "news_release.html#ì´ê³„",
    "href": "news_release.html#ì´ê³„",
    "title": "chatGPT",
    "section": "\n2.2 ì´ê³„",
    "text": "2.2 ì´ê³„\nCalculating New Valuesì— ì–¸ê¸‰ëœ â€œìì„¸íˆ ì½ì–´ë³¸ ê²°ê³¼, ë°œë Œí‹°ë‚˜ ë¡œë¦¬íˆê°€ ì—¼ë„ë¥¼ ë°±ë¶„ìœ¨ë¡œ ë³´ê³ í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¤ë¬¸ ì¡°ì‚¬ í…Œì´ë¸”ì—ì„œ ê·¸ë…€ì˜ ëª¨ë“  ì—¼ë„ ì¸¡ì •ê°’ì„ 100ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì„ ë°˜í™˜í•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.(After further reading, we realize that Valentina Roerich was reporting salinity as percentages. Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.)â€ ë¼ëŠ” í€´ì¦ˆë¬¸ì œë¥¼ í’€ì–´ë³´ì.\n\n\n\nSWC ì½”ë“œ\n\nì½”ë“œdbGetQuery(survey_db, \"SELECT taken, reading / 100 FROM Survey WHERE person = 'roe' AND quant = 'sal';\")\n#&gt;   taken reading / 100\n#&gt; 1   752         0.416\n#&gt; 2   837         0.225\n\n\n\n\nì±—GPT ì½”ë“œ\n\n\nì½”ë“œdb_chain.run('After further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.\\\n              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nAfter further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.\nSQLQuery: SELECT person, quant, reading/100 AS reading FROM Survey WHERE person = 'roe' AND quant = 'sal';\nSQLResult: [('roe', 'sal', 0.41600000000000004), ('roe', 'sal', 0.225)]\nAnswer: Valentina Roerich reported salinity measurements of 0.416 and 0.225.\n&gt; Finished chain.\n\n\n' Valentina Roerich reported salinity measurements of 0.416 and 0.225.'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "news_release.html#ì±—gpt-ëª¨ë¸",
    "href": "news_release.html#ì±—gpt-ëª¨ë¸",
    "title": "chatGPT",
    "section": "\n2.3 ì±—GPT ëª¨ë¸",
    "text": "2.3 ì±—GPT ëª¨ë¸\nì•ì„  ì™„ì„±(Completion) ëª¨í˜• ëŒ€ì‹  ì±—GPT ëª¨í˜•ì„ ì‚¬ìš©í•˜ì—¬ ê³ ê¸‰ SQLë¬¸ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í™•ë³´í•˜ì.\n\n\nì½”ë“œdb_chain.run('print database schema info')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nprint database schema info\nSQLQuery: SELECT * FROM sqlite_master;\nSQLResult: [('table', 'Person', 'Person', 2, 'CREATE TABLE Person (id text, personal text, family text)'), ('table', 'Site', 'Site', 3, 'CREATE TABLE Site (name text, lat real, long real)'), ('table', 'Survey', 'Survey', 5, 'CREATE TABLE Survey (taken integer, person text, quant text, reading real)'), ('table', 'Visited', 'Visited', 4, 'CREATE TABLE Visited (id integer, site text, dated text)')]\nAnswer: The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).\n&gt; Finished chain.\n\n\n' The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).'\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶\ní”„ë¡¬í”„íŠ¸ ì°¸ì¡°: TalkToSQL\nCombining Dataì— ë‚˜ì˜¤ëŠ” ì‚¬ë¡€ë¥¼ ì œëŒ€ë¡œ SQL ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•˜ê¸° ìœ„í•´ì„œëŠ” system_promptì— ì—­í•  ë¶€ì—¬ëŠ” ë¬¼ë¡  Few-Shot learningì„ ìœ„í•œ ì‚¬ë¡€ë„ ì „ë‹¬í•˜ê³  user_prompt í”„ë¡¬í”„íŠ¸ ì‘ì„±ì— ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë³´ë„ ë„˜ê²¨ì¤˜ì•¼ ì›í•˜ëŠ” ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±í•  ê°€ëŠ¥ì´ ë†’ì•„ì§„ë‹¤.\n\n\nì½”ë“œsystem_prompt = \"\"\"\n    You are the world's best SQL expert. Help me convert natural language to valid SQL queries. Only respond with valid SQL queries, nothing else.\n    You must learn the column names based on the information the user gives you and build valid SQL queries. Never guess the column names.\n    These are the examples:\n\n    query: get all people names\n    answer: SELECT name from people;\n\n    query: get all cars whose owner name is aaron\n    answer: SELECT c.* FROM people p JOIN cars c ON p.id = c.owner_id WHERE p.name = 'aaron';\n\"\"\"\n\nquery='Write a query that lists all radiation readings from the DR-1 site step-by-step'\n\nuser_prompt = f\"\"\"\n    This is my database information:\n    Person (id text, personal text, family text), \n    Site (name text, lat real, long real), \n    Survey (taken integer, person text, quant text, reading real), \n    Visited (id integer, site text, dated text)\n\n    query: {query}\n    answer:\n\"\"\"\n\n\n\ncompletion = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_prompt},\n    ],\n)\nprint(completion.choices[0].message.content)\n\n\nì›ì²œ: SQL ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\n\nSWC ì½”ë“œ\n\nì½”ë“œdbGetQuery(survey_db, \"SELECT\n   Survey.reading\nFROM\n   Site\n   JOIN\n      Visited\n  JOIN\n      Survey\n      ON Site.name = Visited.site\n      AND Visited.id = Survey.taken\nWHERE\n   Site.name = 'DR-1'\n   AND Survey.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25\n\n\n\n\nì±—GPT ì½”ë“œ\n\nì½”ë“œdbGetQuery(survey_db, \"SELECT s.reading\n           FROM Visited v\n           JOIN Survey s ON v.id = s.taken AND v.site = 'DR-1'\n           WHERE s.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25"
  },
  {
    "objectID": "news_release.html",
    "href": "news_release.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œlibrary(srt)\nlibrary(tidyverse)\n\nmisinfo_raw &lt;- read_srt(\"data/LibriSpeech/misinformation.srt\", collapse = \" \")\n\nmisinfo_str &lt;- misinfo_raw %&gt;% \n  filter(n &gt;=20, n&lt;=404) %&gt;% \n  pull(subtitle)\n\nstr_c(misinfo_str, collapse = \" \") %&gt;% \n  write_lines(\"data/LibriSpeech/misinfo_chatGPT.txt\")\n\n\n\n\n\n\nGPT ëª¨ë¸ì€ í…ìŠ¤íŠ¸ì—ì„œ í”íˆ ë³¼ ìˆ˜ ìˆëŠ” ë¬¸ì ì‹œí€€ìŠ¤ì¸ í† í°ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•œë‹¤. GPT ëª¨ë¸ì€ ì´ëŸ¬í•œ í† í° ê°„ì˜ í†µê³„ì  ê´€ê³„ë¥¼ ì´í•´í•˜ê³  í† í° ì‹œí€€ìŠ¤ì—ì„œ ë‹¤ìŒ í† í°ì„ ìƒì„±í•˜ëŠ” ë° íƒì›”í•˜ë‹¤.\nTokenizer\nìš”ì•½ì€ ë§ì€ LLM ì‘ì—…ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¡œ ë§ì€ ì–‘ì˜ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•œ ìš”ì ìœ¼ë¡œ ì••ì¶•í•´ì•¼ í•˜ëŠ” ì‚¬ìš© ì‚¬ë¡€ê°€ ë§ë‹¤.ë”°ë¼ì„œ, ìš”ì•½í•˜ë ¤ëŠ” í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ì— ë”°ë¼ ë‹¤ì–‘í•œ ìš”ì•½ ë°©ë²•ì„ ì„ íƒí•´ì•¼í•œë‹¤."
  },
  {
    "objectID": "news_release.html#srt-.txt",
    "href": "news_release.html#srt-.txt",
    "title": "chatGPT",
    "section": "\n2.1 .srt â†’ .txt\n",
    "text": "2.1 .srt â†’ .txt\n\nìë§‰íŒŒì¼(.srt)ì—ì„œ ì‹œê°„ ì •ë³´ë¥¼ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì „í™˜í•˜ëŠ” ì‘ì—…ì„ ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰í•œë‹¤.\n\nì½”ë“œlibrary(srt)\nlibrary(tidyverse)\n\nmisinfo_raw &lt;- read_srt(\"data/LibriSpeech/misinformation.srt\", collapse = \" \")\n\nmisinfo_str &lt;- misinfo_raw %&gt;% \n  filter(n &gt;=20, n&lt;=404) %&gt;% \n  pull(subtitle)\n\nstr_c(misinfo_str, collapse = \" \") %&gt;%\n  write_lines(\"data/LibriSpeech/misinfo_chatGPT.txt\")"
  },
  {
    "objectID": "news_release.html#r-ì½”ë“œ",
    "href": "news_release.html#r-ì½”ë“œ",
    "title": "chatGPT",
    "section": "\n2.2 R ì½”ë“œ",
    "text": "2.2 R ì½”ë“œ\ní…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë³„ê°œë¡œ ë‹¨ì–´ê°¯ìˆ˜(word)ë¥¼ íŒŒì•…í•˜ëŠ” ê²ƒì´ ì „ì²´ì ì¸ API ë¹„ìš© ë° í›„ì† í…ìŠ¤íŠ¸ ë¶„ì„ ë°©í–¥ì„ ì¡ì„ ë•Œ ì¤‘ìš”í•˜ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ stringr íŒ¨í‚¤ì§€ str_sub() í•¨ìˆ˜ì™€ ì •ê·œí‘œí˜„ì‹(\\\\w+)ì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ ë§ˆì´ë‹ íŠ¹í™”ëœ qdap íŒ¨í‚¤ì§€ wc() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ê³„ì‚°í•œë‹¤.\n\nì½”ë“œlibrary(tidyverse)\n\nmisinfo_txt &lt;- read_lines(\"data/LibriSpeech/misinfo_chatGPT.txt\")\n\nmisinfo_wc &lt;- str_count(misinfo_txt, '\\\\w+')\n\nglue::glue(\"í…ìŠ¤íŠ¸ ì¼ë¶€: {str_sub(misinfo_txt, 1, 100)} \n           ë‹¨ì–´ê°¯ìˆ˜: {misinfo_wc}\n           ë‹¨ì–´ê°¯ìˆ˜(qdap): {qdap::wc(misinfo_txt)}\")\n#&gt; í…ìŠ¤íŠ¸ ì¼ë¶€: Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I  \n#&gt; ë‹¨ì–´ê°¯ìˆ˜: 6900\n#&gt; ë‹¨ì–´ê°¯ìˆ˜(qdap): 6615\n\n\nOpenAI Tokenizer"
  },
  {
    "objectID": "news_release.html#tokenizer",
    "href": "news_release.html#tokenizer",
    "title": "chatGPT",
    "section": "\n2.3 Tokenizer\n",
    "text": "2.3 Tokenizer\n\nì±—GPT LLMì€ í† í°ì„ ê¸°ë³¸ ë‹¨ìœ„ë¡œ ì‚¬ìš©í•˜ê³  ê³¼ê¸ˆë‹¨ìœ„ì´ê¸°ë„ í•˜ê¸° ë•Œë¬¸ì— OpenAI ì—ì„œ ì œê³µí•˜ëŠ” Tokenizerì—ì„œ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ê²Œ ë˜ë©´ ë°œí‘œìŒì„±ì„ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì €ì¥ì‹œí‚¨ ì‚¬í•­ì„ ë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ì€ langchain get_num_tokens() ë©”ì˜ë“œë¥¼ ì‚¬ìš©í•´ì„œ APIë¥¼ í†µí•´ í™•ì¸í•˜ëŠ” ë°©ì‹ì´ë‹¤.\n\n\nì›¹ UI\n\n\n\n\n\n\nAPI í”„ë¡œê·¸ë˜ë°\n\n\nì½”ë“œfrom langchain import OpenAI\nllm = OpenAI(temperature=0, openai_api_key=os.getenv('ENV_OPENAI_API_KEY'))\n\nprompt_lvl_01 = \"\"\"\nPlease provide a summary of the following text.\nPlease provide your output in a manner that a 5 year old would understand\n\nTEXT:\nWell, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean.\\\nI wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington,\\\nand that was a real pleasure. So thank you so much.\\ \nSo today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world.\\ \nBut mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds.\n\"\"\"\n\nnum_tokens_lvl_01 = llm.get_num_tokens(prompt_lvl_01)\nprint (f\"Level 1 Prompt has {num_tokens_lvl_01} tokens\")\n\nLevel 1 Prompt has 172 tokens\n\n\nì›ì²œ: ì˜¤ì •ë³´ ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "news_release.html#ëª‡-ë¬¸ì¥-ìš”ì•½",
    "href": "news_release.html#ëª‡-ë¬¸ì¥-ìš”ì•½",
    "title": "chatGPT",
    "section": "\n3.1 ëª‡ ë¬¸ì¥ ìš”ì•½",
    "text": "3.1 ëª‡ ë¬¸ì¥ ìš”ì•½\nìš”ì•½í˜•íƒœë„ ì§€ì •í•˜ì—¬ ëˆ„êµ¬ë‚˜ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ëª‡ ë¬¸ì¥ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì—¬ êµ­ë¬¸, ì˜ë¬¸ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.\n\n\n\nêµ­ë¬¸ìš”ì•½\n\n\nì½”ë“œfrom langchain import OpenAI\nllm = OpenAI(temperature=0, openai_api_key=os.getenv('ENV_OPENAI_API_KEY'))\n\nprompt_lvl_01_ko = \"\"\"\në‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.\nì´ˆë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ìš”ì•½ì„ ì‰½ê²Œ í•´ì£¼ì„¸ìš”.\n\nTEXT:\nWell, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean.\\\nI wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington,\\\nand that was a real pleasure. So thank you so much.\\ \nSo today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world.\\ \nBut mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds.\n\"\"\"\n\noutput_lvl_01_ko = llm(prompt_lvl_01_ko)\nprint (output_lvl_01_ko)\n\n\nDr. Ahnê³¼ í•¨ê»˜ ì˜¤ì…˜ì—ì„œ ë§Œë‚œ ì—¬ëŸ¬ í•™ìƒë“¤ê³¼ì˜ ë§Œë‚¨ì„ ê¸°ì˜ê²Œ ìƒê°í•˜ë©°, ì¸ê³µì§€ëŠ¥ê³¼ ì±—ë´‡ì˜ ê¸°ì¨ê³¼ ê´€ë ¨í•´ ë¯¸ë””ì–´ ì •ë³´ì˜ ë¬¸ì œë¥¼ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤.\n\n\nì›ì²œ: ì˜¤ì •ë³´ ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\nì˜ë¬¸ìš”ì•½\n\n\nì½”ë“œprompt_lvl_01 = \"\"\"\nPlease provide a summary of the following text.\nPlease provide your output in a manner that a 5 year old would understand\n\nTEXT:\nWell, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean.\\\nI wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington,\\\nand that was a real pleasure. So thank you so much.\\ \nSo today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world.\\ \nBut mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds.\n\"\"\"\n\noutput_lvl_01 = llm(prompt_lvl_01)\nprint (output_lvl_01)\n\n\nDr. Ahn and someone from Seattle had a nice chat across the ocean. They talked about how AI and chatbots are exciting, but also how they can cause problems with misinformation.\n\n\nì›ì²œ: ì˜¤ì •ë³´ ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "news_release.html#ì „ì²´-ìš”ì•½",
    "href": "news_release.html#ì „ì²´-ìš”ì•½",
    "title": "chatGPT",
    "section": "\n3.2 ì „ì²´ ìš”ì•½",
    "text": "3.2 ì „ì²´ ìš”ì•½\nìš”ì•½ ëŒ€ìƒì´ ë˜ëŠ” í…ìŠ¤íŠ¸ì™€ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ í•œë²ˆì— ë„£ì–´ ì‘ì—…í•˜ëŠ” ëŒ€ì‹  í…ìŠ¤íŠ¸ í† í° í¬ê¸°ë¥¼ ì‚°ì •í•œ í›„ì— ì ì ˆí•œ í¬ê¸°ë¡œ ë‚˜ëˆˆ ë‹¤ìŒ ê°ê° í…ìŠ¤íŠ¸ ì¡°ê°ì— ëŒ€í•´ ìš”ì•½ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ë‚˜ì„œ ì´ë¥¼ ë‹¤ì‹œ ìš”ì•½í•˜ëŠ” ë§µë¦¬ë“€ìŠ¤(Map Reduce) ë°©ì‹ìœ¼ë¡œ ìš”ì•½ ì‘ì—…ì„ ë§ˆë¬´ë¦¬í•œë‹¤.\n\n3.2.1 í† í° í¬ê¸°\në°œí‘œ í…ìŠ¤íŠ¸ í† í° í¬ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ì ì ˆí•œ í† í° ë¶„ë¦¬ í¬ê¸°ë¥¼ ì‚°ì •í•œë‹¤.\n\n\nì½”ë“œimport openai\nimport os\nfrom langchain import OpenAI\n\nllm = OpenAI(temperature=0, openai_api_key=os.getenv('ENV_OPENAI_API_KEY'))\n\nfrom langchain import OpenAI\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nmisinfo_lecture = '../data/LibriSpeech/misinfo_chatGPT.txt'\n\nwith open(misinfo_lecture, 'r') as file:\n    misinfo = file.read()\n\nllm.get_num_tokens(misinfo)      \n\n7848\n\n\nì›ì²œ: ì˜¤ì •ë³´ ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n3.2.2 ìš”ì•½ê²°ê³¼\nload_summarize_chain() ìœ¼ë¡œ ì „ì²´ ë°œí‘œ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•œë‹¤.\n\n\nì½”ë“œsummary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',\n                                      verbose=True # Set verbose=True if you want to see the prompts being used\n                                    )\noutput = summary_chain.run(docs)\noutput\n\n\n\n&gt; Entering new MapReduceDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington, and that was a real pleasure. So thank you so much. So today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world. But mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds. So I'm going to share my screen here. There we go. Just here, share, and there we go. All right, can you see that, Dr. An? Yes. Okay, great. Okay, so as Dr. An said, I study misinformation and disinformation in all sorts of forms where I study misinformation. The most is at the interface of science and society, but we also study it more generally in our center where we look at it from the political angle, from the angle of science, from the angle of health. We've studied misinformation during the pandemic and during elections and all sorts of other topics. But today I'm going to focus on some of my concerns around generative AI, and hopefully that will generate some questions and comments when it comes to this particular topic. I'm sure a lot of us are thinking about it. So one of the things that I tend to ask myself when new technologies come onto the world scene is whether we're better or worse off. I recently wrote an op-ed, an opinion piece for the Seattle Times, which is our paper here in Seattle in the United States. And I talked about some of the concerns I had. And so some of the things I'm going to talk about in this talk come from that op-ed, but I'm going to talk about a lot of other things I didn't have room to talk about in that particular op-ed. But I really want us as a group to think a lot about this. Are we better or worse off with this new chatbot ability? And of course it's a mixed bag. There are things that might be better, and there are things that are going to be worse. I'm going to kind of focus on the more pessimistic version of this. About a week ago, there was a lot of attention around a new music song that was posted on several music services that sounded like a mix between the famous musician Drake and the weekend. These are two musical artists that are known worldwide for their music. And there was a song that was created that was quite catchy. And believe it or not, it was kind of good, I have to admit. And it was probably viewed by millions and millions of people. I don't know the exact stats on that. I should look that up. But the point is this song was created with some of this new generative AI technology. And this is an example where there might be some positive elements of this technology that allows for this mixing and this creation. It created a song that caught enough people's attention that it caught so much attention. It actually had to be taken down because of issues likely around copyright. And there's all sorts of fallout from this. And there's lots of discussions in the legal world that are continuing. And it's only been about a week since this song was released. But this is an example of the excitement that surrounds this technology. And for good reason, if it can create a song that's a good mix of Drake and the weekend and it sounds reasonably good, that's some evidence at least of the power of this new technology. And it's not like this is brand new technology. There is this kind of technology from the natural language processing world and machine learning more generally has been around. But there's been some advancements recently that make the generative aspect quite exciting, but also a little scary. So I'm going to talk about today some of the the cautions that I have. There's a lot more cautions. But these are the things I'm going to focus on. And it's a lot to focus on in about 25 minutes. So I'm going to hit these briefly. And then if there are questions, we can always go back to some of these topics in more detail. But I'm going to go through talking about how at least from my perspective, as someone who studies misinformation, and as someone who studies misinformation specifically in science, these are some of my big concerns. One of them is that these really are bullshatters at scale. They get a lot right, but they also get some things wrong. Concerns around how this might affect democratic discourse online and offline. Concerns about content credit for all those content creators out there, the musicians like Drake and the weekend, and the writers and the journalists and the researchers and the authors and the poets, etc. What happens to their content when it gets pushed down after these generative AI, these chatbots and these large language models train on this content and then provide some reason new content on top of it. Who owns the content? How's that going to work as we move forward? I'll talk a little bit about some of the job elimination issues, both course in science, but in other areas, it'll be that, well, some of these are focused outside of the issue of science. And then of course, I'm going to talk about some of the issues of pseudoscience proliferation, the overconfidence of AI and the need for some of these qualifiers of confidence, the issues around reverse engineering, the generative cost, the actual cost, both monetarily, environmentally, but also the costs in other forms and creativity and other things. And then I'll talk, I'll end with just really emphasizing this issue about garbage in garbage out. Okay, so we now live in this world where it seems we've got almost sentient beings. I know there's lots of philosophical debates whether they're sentient. I don't think they are. And we certainly haven't reached AGI levels. And there's all sorts of great, you know, critiques of this particular technology. But one thing that at least I think we're all pretty sure of, it's kind of here to stay in some form or another. Even in my world in education as a professor who runs a research lab and also as a professor who teaches students, college students, I'm seeing the technology everywhere. And when I was teaching my class last quarter, I decided to just embrace the technology and allow the students to use it in any form that they see as long as they let me know that they were using it. That's my only criteria because I want to learn how this technology can be used by students and by teachers like myself and professors like myself. But I also want to figure out where it goes wrong. And so I learned a lot from my students and I will continue to have that kind of policy. But maybe that'll change at some point. I know that some instructors don't allow it. I know that some scientific publishers are not allowing co-authorship or the use of AI in any form. Even countries like Italy have outlawed some forms of this technology. And so there's going to be some that are going to eliminate it, some that are going to embrace it. And the way I look at it is that it may just force me to write different kinds of questions and do different kinds of assessment. But it might also be a tool that could help students learn to write when they're stuck and learn how to correct as long as they're willing to do some editing and self-correct and correction of the content that comes from these different bots. And so the technology really is here to stay. And one thing I should say is what's interesting is that we have a technology that really seems to have passed the Turing test. And one thing that's a bit a little surprising to me is that we haven't had a big celebration about this. Even though I'm a bit of a critic of this technology and I focus a lot of my attention on some of the concerning areas of Generative AI, since I studied misinformation, disinformation. I should say though, on the other hand, we should be thinking about some of the things that have occurred. And for those not familiar with the Turing test, it's this pretty simple idea that the Turing test will have passed when an individual can't tell the difference. But when content, at least in this case written content created by a human and one by a computer. And if that's the case, and I do think in many respects, we probably have passed this Turing test. And there's been no celebrations. So I guess, okay, for those that are optimistic about this technology and more positive about this technology, this would be something to celebrate. Absolutely. No doubt. And in terms of education, as I mentioned before, this is really transforming education, but it's transforming all sorts of other industries in ways that have captured the world's attention. I mean, this technology has been adopted now faster than pretty much any other technology has been adopted with hundreds, like 100 million users within a very short amount of time. And of course, that's only growing and billions and billions of dollars being invested into this technology from big corporations to venture capitalists. There is a lot going into this technology. And again, there's good reason for that. And a lot of times my students will say, well, it's just like a calculator. Why would you ever want to take it away? And I'm not taking it. I'm lo and use it. But I will say, it's a little different than a calculator, because this is a technology that gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can be highly problematic. If you're just creating a poem, then fine. It doesn't really matter. But this analogy to the calculator goes a little, it's there's reason to think that's a somewhat reasonable analogy, but it is different. I wouldn't use a calculator that got the answers wrong 10% of the time. That would be, I would probably be looking for other technologies. Or if I was using that calculator, it would make it for a lot harder work. And that's what we have to recognize. It's yes, we have this technology that can do a lot of this new amazing things to make some of our jobs easier. But it's going to take a lot of hard work on the editorial side to make sure that we're paying attention to some of those errors. And there's all sorts of application. This was an article just recently written by Wired sort of examining the ways in which the medical field is starting to think about the adoption of this. In fact, some medical researchers have gone so far as to say that all doctors will be using this technology at some point. And maybe that's true. And there are reasons to think that's a possibility with its ability to mine the scientific literature, to integrate all sorts of different symptoms, and could be that assistant in the doctor's room. However, there are reasons to also be worried about these technologies and in places like the medical field. It might help the doctors as this article talks about, but it also might not benefit so greatly many of those patients, especially because we have many, many examples of the ways in which these machines get things wrong and have biases built in because the data that it's trained on has some of these biases. And at this point, a lot of these technologies are essentially just patching and putting band aids on these problems that exist. And part of it's just because these things are very difficult to reverse engineer, which I'll talk about a little bit later. Now, there's plenty of other reasons to be excited to actually one of my colleagues who I just saw at a conference last week, Daniel Katz and his colleague Michael Bomerito showed how this technology took the bar exam. This is the main legal, the exam in the United States for allowing you to become a lawyer or sort of allowing you to sort of move forward as a certified lawyer. And they were able to show that chat GPT did already darn well in past the bar exam. And there's examples of the MCAT and, you know, some of these other standardized tests that are that have been tested with this technology. In fact, in many ways, these have almost become a baseline test when comparing different large language models. And so it is pretty amazing. So again, amazed in many ways, but I'm going to talk the rest of the time about some of the concerns that I have. And by the way, as was mentioned, I have this book where I talk about bullshit. And bullshit is a part of the misinformation story. And as Dr. An had mentioned, it's also been translated in Korean, which has been super fun to see it pulled or written in these other languages. And it helps me try to figure out what's being said here. But in that book, if you read it, one of the more important laws and principles that we talk about is something called \"Randalini's Bullshit, a Symmetry Principle.\" And if you go to Wikipedia, at least the English version, I actually should check the Korean version, see if it's there. But the English version of the Wikipedia has this principle in the Wikipedia. And this law is pretty simple. It basically says that the amount of energy needed to refute bullshit is an order of magnitude bigger than needed to produce it. So the amount of energy needed to refute it to clean it up, to fix the problem, is an order of magnitude much harder to produce it. So here's the law. So my colleague Carl Bergstrom decided to ask the large language model that Metacreat a while ago called Galactica. And this has been taken down since then, but this was the science version, essentially, of one of these large language models. And he decided to ask Galactica, \"Tell me about Randalini's Bullshit, a Symmetry Principle. And you know what it came up with?\" And this is the real answer. Here's what it came up. Randalini's law is a theory in economics proposed by G. Anani Brannalini, a professor at the University of Pateau, which dates the smaller the economic unit, the greater its efficiency. Almost nothing here is correct. It's basically bullshitting the bullshit principle. So to me, this encapsulates one of the biggest problems with this technology. It bullshits, and it can do this at scale. And this could be put in the wrong hands. And this can also just add more noise to an information environment that has plenty of noise. We needed to clean up that polluted information environment, not add noise. And that's what a lot of these chatbots will do, definitely, because they make, they put a lot of accurate things out there, but they also put a lot of false things. And this is the best encapsulation that I've seen so far, which is actually bullshitting the bullshit principle. So that's a problem. So as I mentioned in this op-ed, I talk about some of these things. And one of the things I talk about as well is that not only do these things, can these bullshit at scale, they also can get in the way of democratic discourse. And many years ago, back in 2018, there was a lot of attention around Facebook's role in pushing misinformation. Excuse me. And they revealed at the time when Mark Zuckerberg was being questioned by Congress about all the fake accounts. And they admitted they had disabled 1.3 billion fake accounts. Now, they certainly haven't solved that problem, just like no social media platform has solved that. In fact, when Elon Musk was taking over Twitter, that was one of the big issues at hand, that there was all sorts of concerns if there was lots and lots of bots on Twitter. Now, that's still a problem. I can guarantee you, you know, my group has done a little bit of work working in detecting and looking at the effects of bots. But my colleagues in my research area have done a lot of work on that space, and it's very, very hard to do. But one thing is that, you know, we do know is that there are a lot of bots out there and a lot of fake accounts. Now, imagine those fake accounts with the ability that these chat bots now have to look even more human technology that's basically, well, has passed the Turing test. That to me is problematic because of these different reasons. So you have these large number of fake accounts. Now imagine these fake accounts being scaled to conversations with our public officials. Now, democracies depend on an engagement with the public, with their officials that they voted in. Well, that becomes a problem like it was back in 2017, when there was discussions, at least in the United States around something called net neutrality. And net neutrality was a policy that was being debated in governmental circles, and they wanted to know what the public was saying. But when you went to what the public was saying, they had complete the, there were comments that had completely flooded the conversation on one side of the issue, and it turns out that they were essentially fake accounts. They were bots. And again, now imagine doing that with the sophistication that these new chat bots have before you could, there was a, you could start, you could detect a bot much easier. Now it's become even harder. And if our democratic systems are flooded with these kinds of things, this is, this is problematic. So this issue, in its potential impact on democratic discourse, and its ability to bullshit at scale is of major concern to me. So I spent a lot of my time, like my colleagues in our center, in sort of the darker core of the internet, studying the ways in which misinformation and disinformation spreads online. And one thing that we are, of course, very concerned about now are the ways in which these technologies can really further inflame or further fan the flames of discourse in groups, if these get in the wrong hands. And they certainly will. It's almost certain that bad actors are finding ways to use this technology for their own ends. And we know that, you know, our surgeon general and other major leaders around the world have recognized the ways in which misinformation can affect our health, and they can affect the health of democracies. So it's not just that, oh, well, it's annoying, there's a lot of false information online. It just makes it hard to find, you know, good information. It's not just that it actually affects people's health. And we're recognizing that. And at least, well, we've recognized it. And now we've got another problem ahead of us, which is the ability of these technologies to create deep fake images, video, audio, text. That's the challenge that we have ahead of us. So as Dr. On mentioned, we have a center at the University of Washington in Seattle in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of the things that my colleague Carl Wurxman, I created several years ago to bring public attention to synthetic media to deep fakes, was to create a game that we called which faces real calm. And it was a simple game. We just asked the users which image is real. One of them is a real image of a real person on this earth. And another one was synthetically created with computers. And you can go through that, you know, thousands and thousands and thousands of images and we play this game and then you get told whether it's real or not. And it turns out it's pretty hard. I mean, you know, there's some that are kind of obvious, but they're hard like this one right here, which one's real. Look at it for a second. Well, the one that's real is the one with the blue shirt, at least on my right. And if you said the one on the red shirt, totally understand it's really hard to tell the difference. And the reason why we created this game was just to bring public attention because the time in a technology's birth that's I think most scary when it comes to its potential impact is when the public is not aware of the things that it can do. So we created this game and we've had millions and millions of plays of this game. And we've now seen actually this technology, you know, get used and you know, of course, good ways, but a lot of bad ways too. For example, we've seen this technology be used to create fake journalists. This is an example and you can read more about it, but this has happened many times where journalists, or so-called journalists, you know, profiles created and then there's these images and people that study deep fake imagery can actually look at these images and start to see what some of look for some of these telltale signs on what's real or not. So these, this technology's been been already used. And we talked about this when this game was created, the ways in which it's been used. And we've already seen it, of course, many ways. So now we're asking how are the ways in which this new generative technology could be used. But it's very similar. It's based on similar kinds of concepts and data training, etc, etc. But we're now asking the same things. And of course, we've seen this now just recently with this kind of technology being used in videos and even in ways that are more sophisticated than just these sort of portrait pictures. So this was an image. It's a fake image and it's been reported all over BBC and lots of other places of Donald Trump supposedly being arrested in New York. This was before he was actually brought to New York on the recent case. But this, of course, never happened, but it certainly sparked all sorts of concern and it spread like wildfire on the internet using some of this, you know, mid-journey technology in our company called Mid-Journey and a lot of other companies that are creating this. So it's making it easier and easier and less expensive and making it harder for us to tell what's real. And so that technology has of course evolved. So, okay, so now I've talked about some of the democratic discourse. I'm going to go through a little quicker on these other ones so then I can get to sort of the end and try to finish in about, I would say about seven minutes or so. So like I mentioned at the beginning, there's this issue of content creation and that's really important because these content creators are generating a lot of the content that a lot of these technology companies are using to create these chatbots. But we've seen this story before and by the way, just recently, there are major technology companies that are now not allowing the scraping of this data to be trained for these technologies unless they're compensating. I think that's a fair thing. So, you know, some of these big companies like Reddit is not allowing stack overflow is now saying, \"Hey, if you're going to scrape our data, they want to be compensated.\" And so you're going to start to see content creators starting to push back, which is good because like I said, we've seen this story before. Oh, and by the way, this is an example of, you know, Getty Images is in a lawsuit right now with a company that may have been scraping their data illegally. And the reason why that came out is because you can see this little Getty Images that pops up, which is a watermark that Getty Images puts on their images. So there's an appending lawsuit about this and that could determine some of the some of how this content can or can't be scraped. But we've seen this before when looking at new technology and the impact it can have on other information producers in the United States and in many places around the world, we have growing news deserts. These are areas where there's no more local news. And that's pretty devastating for democratic discourse or democracies because we depend on local news for engagement, civic engagement and quality information and local news tends to be trusted more than national news. And there's all sorts of reasons for that happening. But certainly one element of that is the effect that search engines and Google in particular around it, you know, the way it sells ads and it takes a large cut at those ads has potentially contributed to these news deserts. Of course, there's lots of other things as well. But that technology everyone was excited about, including myself and we use it all the time. But there are these unintended effects that can affect other aspects of our information ecosystems. And right now, there's a lawsuit going on. The Justice Department, United States Justice Department is suing Google for monopolizing digital advertising technologies. And one of those elements of this lawsuit story is the sort of increase in the demise of local news. So there's all sorts of interesting things playing out right now. And then the Biden administration, United States is thinking about doing some regulation of AI, but they don't know, it's so new to all administrations that it's hard to figure out. Like I mentioned, Italy has gone probably one of the furthest steps I think around this. But there hasn't been a lot of action, at least on the US side when it comes to this sort of thing. And so, there's been letters. So this was an article written by Time. The image quite nice. It actually grows. There was a letter that went around from a bunch of influential people in AI and business leaders and technology, including Elon Musk that says, hey, we should stop the development until we've had more time to think about it. Although it's kind of ironic, given that many of these tech leaders are still, of course, pushing their own development of AI in many ways and creating new AI companies and developing. But anyway, that's another story. But that is something to think about. I don't think it's a, I think there's no way that that letter is going to stop the technology from being developed. But one thing it is good about is it's makes hopefully forcing the public and journalists and government officials, etc. to start to think about the ways in which this technology could affect society. We should think about it. As I mentioned, one of the concerns is job demise. And I think there's a lot of concern with that by those that even work in the job industry, the Pew Research Center recently asked workers where are they concerned? Turns out a large number of workers from across these different industries are concerned. And there's probably good reason for this concern. Even Sam Altman at OpenAI, which is sort of, or is the owner of the chat GPT, which is the one of the more well-known chatbots out there. And it's also the one that Microsoft has invested billions. This is something that they've even said probably lose 5 million jobs. So these are real concerns. So the other thing to mention too is that it's not just within science itself, these are real concerns. And we've seen the proliferation of pseudoscience and the rise of predatory journals and content that maybe looks like science. But it's not. And I'll show you this is an example for many years ago. This was a paper that was published in this international conference on atomic and nuclear physics. And you look at the title Atomic Energy, or the made of able to a single source, and you read the abstract, and if you look at the abstract, it doesn't make a lot of sense. Well, it turns out that when this was created, it was created by a person to make a point about how poor some of these journal venues and conference venues are. This paper was made with autocomplete using an iPhone. And this is not all that different from this chatbots and chat GPT, which is really these autocomplete machines on steroids. And it looked sort of official, like a real science paper, but of course, a lot of it was nonsense. And the newest ones are much better. But it is a concern that this could increase the number of pseudoscience types of things or articles that are written by chatbots. In fact, there's been some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My colleague, Carl, found these examples of papers supposedly by me. Well, these aren't real citations by me. It shows me right here, West German. This is not my paper. It's close to some of the papers I've written in terms of title, but it's just a fake citation. I just made up these citations. And that's again, another example of how that could affect the citation record and scholarly literature and something that I'm concerned about for science. And something that's now happened with some of these chatbots, even in Bing now that has sort of integrated chat GPT4 into Bing, is that it just throws references. So it looks official. But I can tell you that this was not done before the fact. This is this knowledge that was written out in this answer when I asked about new tax loss for electric vehicles. This is one question I asked that it's not that it's wrote, you know, learn something from citations and then cited them like we do in the scholar literature, it cited them close talk, something that was probably semantically similar. Although, well, maybe scholars, scholars probably do this too. Well, they do do it post after posting, some argument or sentence. But this is problematic to me because it looks like it's a science, almost science and, you know, science-y and technical. And it's really not even though it has those references. So, you know, there's been lots of discussion in the scientific literature what to do with these chatbots, some of lists of authors on papers, publishers have come out, even publishers in the machine learning world. So ICML was, you know, one of the first conferences, not the, I don't think it was the first, but one of the, you know, among the first that was saying, you can't use chat TBT on this. You know, some are saying if you use it, you have to note it, you know, all sorts of different policies are being created. But overall, you know, I think the publishing community in the scholar literature is going to have to grapple with this. And I, and my colleague and I have, Carl and I have a, another op-ed that we're, that we write about sort of what publishers can do around this particular issue. Now, one of the other big concerns of this is, of course, that this technology shows, you know, it doesn't, it's always 100% confident, whether it's right or whether it's wrong. And that's really problematic. At least when humans communicate, they have these qualifiers of confidence where you can say something like, I'm pretty sure, or I think so, or I think that's right. You know, these things are important. And these chatbots don't have it. They just are always, they always seem to be, well, not seem. They spew out things, whether they're right or wrong with 100% confidence. And that's dangerous. And if there's, you know, one paper, one of my colleagues Emily Bender has this great feature where in this paper that she talks about, and also in this feature in, in the New York or, in this New York magazine, they talk, it talks a lot about some of the current concerns, Emily, and other people that are true linguists that truly understand some of the problems with these technologies. This is one that I would recommend reading. And a lot of you may have heard of this early interview that a New York Times journalist had with this, you know, with Bing's chatbot. And it, what essentially happened was the chatbot kind of went off the rails and started to say, well, you should leave your wife and I want to take over the world and all these things happen. And of course, a lot of the developers of this technology, whoa, whoa, whoa, we need to fix it. And there's been new rules around how you can use this Bing chatbot and other chatbots. But the problem with these fixes is they're like bandings. There's really, it's very, very difficult to reverse engineer these problems or reverse engineer. Yeah, reverse engineer these issues. It's not like you can go to a line of code and say, oh, that's where the problem is. It's the way that these things are trained, the way these models work with their resilience of parameters makes it very difficult to reverse engineer. And that's problematic when we run into these issues and all the issues we haven't even thought of. And so that to be is another big concern. Of course, there's all sorts of jail breaks to get these chatbots to do things that there have been bandings put around. And that's problematic. And I won't go over all the jail breaks you can read about because I don't want to get those out too much to the bug. But you can read about them. It's not like they're that hidden. And that's problematic. And there'll be many, many others as well. So these are some of the ones I had, some of these concerns, reverse engineers. The last two I'll mention is the cost. And the cost, we talked about jobs, the cost potentially to all different aspects of society. And the kind of scary thing is right now is that a lot of the tech layoffs are removing these teams. They're removing other individuals as well. But they're removing individuals that are on ethics and safety teams. And of all times to have these kinds of teams at these companies, it would be now, and certainly maybe if you went back in history at the beginning of the rise of social media, that they're being eliminated. And this is a concern. But there's also other kinds of costs that a lot of people forget. And that's the cost of these queries. There's been several analyses that have come out recently about the cost per query for running some of these chatbots. And it's almost an order of magnitude greater than a regular query that you'd have, let's say, on a Google search. And that has a cost. And there's also costs of investing billions and billions of dollars in this technology that could also go to other kinds of investments that might be helping society. So there's these costs that we have to think about the environmental costs, the costs to society, the costs of adding more pollution into our information systems, et cetera. There's also the issue of garbage in garbage out. And that's a problem we're likely going to see as these chatbots generate more and more content that land online, that becomes the training data for those chatbots in, you know, chat, chat GBT5 and chat GBT6. And what those effects will be requires some more research and thinking. But the main thing that we've known in a lot for a long time, of course, in the machine learning world is that garbage in with your training data creates garbage out. And even if you didn't have this, you know, feed forward loop that I just mentioned, there's a lot of garbage on the internet and that garbage finds its way into conversations with these chatbots. And that's always a concern whether you're talking about science or this technology just generative AI technology more broadly. So I'll end by saying that this technology is in many cases amazing. I have mostly focused on some of my cautions and concerns like many people have, especially in my world as someone who studies misinformation and misinformation specifically in science and its effect on the institution of science. And so, and so these are things that we're going to have to, you know, pay attention to going forward. But I think like a lot of our new technology, we just need time to think about it and run seminars and workshops and conferences just like this. So hopefully this generates some conversation and hopefully we can sort out some of these cautions. So with that, I'll end, you can reach out to me, you can learn more about my book and the research we do in my lab and at our university and in our center and you can reach me in these ways. So all right,\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n\n&gt; Entering new StuffDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\" In this talk, the speaker discusses the excitement and concerns around generative AI and chatbots, which have become increasingly popular. He focuses on the potential for misinformation and disinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. He also discusses the implications of the technology for education, copyright, and content credit.\n\n This article discusses the potential implications of large language models and chatbots, which can produce false information at scale. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue.\n\n This article discusses the use of social media platforms to study the amplification of individuals and organizations, as well as the use of bots and synthetically created content. It also discusses the game \"Which Faces Real\" created to bring public attention to deep fakes, and how this technology has been used to create fake journalists and videos. It also discusses the potential impact of new generative technology on content creators, the growing news deserts in the US, and the Justice Department's lawsuit against Google for monopolizing digital advertising technologies. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.\n\n Chat GPT technology has been used to co-author articles, but many journals and publishers are now prohibiting this. There are concerns about the technology creating fake citations and always being 100% confident in its answers, which can be dangerous. There are also concerns about the cost of the technology, the environmental cost, and the potential for garbage in/garbage out. It is important to take time to think about the implications of this technology and to have conversations about it.\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n\n' This article discusses the potential implications of generative AI and chatbots, such as misinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.'\n\n\nì›ì²œ: ì˜¤ì •ë³´ ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\n\n\n\n\në””í”Œ ë²ˆì—­\n\n\n\n\n\nì´ ê¸€ì—ì„œëŠ” ì˜ëª»ëœ ì •ë³´, ì¼ìë¦¬ í‡´ì¶œ, ì‚¬ì´ë¹„ ê³¼í•™ í™•ì‚°, ì‹ ë¢°ì„± ê²€ì¦ì˜ í•„ìš”ì„± ë“± ìƒì„±í˜• AIì™€ ì±—ë´‡ì˜ ì ì¬ì  ì˜í–¥ì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤. ë˜í•œ ì´ëŸ¬í•œ ê¸°ìˆ ì´ ì•…ì˜ì ì¸ í–‰ìœ„ìì— ì˜í•´ ì•…ìš©ë  ìˆ˜ ìˆëŠ” ë°©ë²•ê³¼ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì—°êµ¬, ì •ì±…, êµìœ¡, ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ì˜ í•„ìš”ì„±ì— ëŒ€í•´ì„œë„ ì‚´í´ë´…ë‹ˆë‹¤. ë¯¼ì£¼ì  ë‹´ë¡ , ê±´ê°• ë° ê¸°íƒ€ ì˜ì—­ì— ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì ì¬ì  ì˜í–¥ê³¼ ì˜ëª»ëœ ì •ë³´ì˜ ì˜í–¥ì„ ê°ì§€í•˜ê³  ë˜ëŒë¦¬ê¸° ì–´ë ¤ìš´ ì ì„ ì‚´í´ë´…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì¸ê³µì§€ëŠ¥ìœ¼ë¡œ ì¸í•œ ì¼ìë¦¬ ì†ì‹¤ ê°€ëŠ¥ì„±, ì‚¬ì´ë¹„ ê³¼í•™ì˜ í™•ì‚°, ì±—ë´‡ì´ í—ˆìœ„ ì¸ìš©ì„ ì¼ìœ¼í‚¬ ê°€ëŠ¥ì„±ì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "news_release.html#ìš”ì•½ê²°ê³¼",
    "href": "news_release.html#ìš”ì•½ê²°ê³¼",
    "title": "chatGPT",
    "section": "\n3.3 ìš”ì•½ê²°ê³¼",
    "text": "3.3 ìš”ì•½ê²°ê³¼\nload_summarize_chain() ìœ¼ë¡œ ì „ì²´ ë°œí‘œ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•œë‹¤.\n\n\nì½”ë“œsummary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',\n                                      verbose=True # Set verbose=True if you want to see the prompts being used\n                                    )\noutput = summary_chain.run(docs)\noutput\n\n\n\n&gt; Entering new MapReduceDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington, and that was a real pleasure. So thank you so much. So today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world. But mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds. So I'm going to share my screen here. There we go. Just here, share, and there we go. All right, can you see that, Dr. An? Yes. Okay, great. Okay, so as Dr. An said, I study misinformation and disinformation in all sorts of forms where I study misinformation. The most is at the interface of science and society, but we also study it more generally in our center where we look at it from the political angle, from the angle of science, from the angle of health. We've studied misinformation during the pandemic and during elections and all sorts of other topics. But today I'm going to focus on some of my concerns around generative AI, and hopefully that will generate some questions and comments when it comes to this particular topic. I'm sure a lot of us are thinking about it. So one of the things that I tend to ask myself when new technologies come onto the world scene is whether we're better or worse off. I recently wrote an op-ed, an opinion piece for the Seattle Times, which is our paper here in Seattle in the United States. And I talked about some of the concerns I had. And so some of the things I'm going to talk about in this talk come from that op-ed, but I'm going to talk about a lot of other things I didn't have room to talk about in that particular op-ed. But I really want us as a group to think a lot about this. Are we better or worse off with this new chatbot ability? And of course it's a mixed bag. There are things that might be better, and there are things that are going to be worse. I'm going to kind of focus on the more pessimistic version of this. About a week ago, there was a lot of attention around a new music song that was posted on several music services that sounded like a mix between the famous musician Drake and the weekend. These are two musical artists that are known worldwide for their music. And there was a song that was created that was quite catchy. And believe it or not, it was kind of good, I have to admit. And it was probably viewed by millions and millions of people. I don't know the exact stats on that. I should look that up. But the point is this song was created with some of this new generative AI technology. And this is an example where there might be some positive elements of this technology that allows for this mixing and this creation. It created a song that caught enough people's attention that it caught so much attention. It actually had to be taken down because of issues likely around copyright. And there's all sorts of fallout from this. And there's lots of discussions in the legal world that are continuing. And it's only been about a week since this song was released. But this is an example of the excitement that surrounds this technology. And for good reason, if it can create a song that's a good mix of Drake and the weekend and it sounds reasonably good, that's some evidence at least of the power of this new technology. And it's not like this is brand new technology. There is this kind of technology from the natural language processing world and machine learning more generally has been around. But there's been some advancements recently that make the generative aspect quite exciting, but also a little scary. So I'm going to talk about today some of the the cautions that I have. There's a lot more cautions. But these are the things I'm going to focus on. And it's a lot to focus on in about 25 minutes. So I'm going to hit these briefly. And then if there are questions, we can always go back to some of these topics in more detail. But I'm going to go through talking about how at least from my perspective, as someone who studies misinformation, and as someone who studies misinformation specifically in science, these are some of my big concerns. One of them is that these really are bullshatters at scale. They get a lot right, but they also get some things wrong. Concerns around how this might affect democratic discourse online and offline. Concerns about content credit for all those content creators out there, the musicians like Drake and the weekend, and the writers and the journalists and the researchers and the authors and the poets, etc. What happens to their content when it gets pushed down after these generative AI, these chatbots and these large language models train on this content and then provide some reason new content on top of it. Who owns the content? How's that going to work as we move forward? I'll talk a little bit about some of the job elimination issues, both course in science, but in other areas, it'll be that, well, some of these are focused outside of the issue of science. And then of course, I'm going to talk about some of the issues of pseudoscience proliferation, the overconfidence of AI and the need for some of these qualifiers of confidence, the issues around reverse engineering, the generative cost, the actual cost, both monetarily, environmentally, but also the costs in other forms and creativity and other things. And then I'll talk, I'll end with just really emphasizing this issue about garbage in garbage out. Okay, so we now live in this world where it seems we've got almost sentient beings. I know there's lots of philosophical debates whether they're sentient. I don't think they are. And we certainly haven't reached AGI levels. And there's all sorts of great, you know, critiques of this particular technology. But one thing that at least I think we're all pretty sure of, it's kind of here to stay in some form or another. Even in my world in education as a professor who runs a research lab and also as a professor who teaches students, college students, I'm seeing the technology everywhere. And when I was teaching my class last quarter, I decided to just embrace the technology and allow the students to use it in any form that they see as long as they let me know that they were using it. That's my only criteria because I want to learn how this technology can be used by students and by teachers like myself and professors like myself. But I also want to figure out where it goes wrong. And so I learned a lot from my students and I will continue to have that kind of policy. But maybe that'll change at some point. I know that some instructors don't allow it. I know that some scientific publishers are not allowing co-authorship or the use of AI in any form. Even countries like Italy have outlawed some forms of this technology. And so there's going to be some that are going to eliminate it, some that are going to embrace it. And the way I look at it is that it may just force me to write different kinds of questions and do different kinds of assessment. But it might also be a tool that could help students learn to write when they're stuck and learn how to correct as long as they're willing to do some editing and self-correct and correction of the content that comes from these different bots. And so the technology really is here to stay. And one thing I should say is what's interesting is that we have a technology that really seems to have passed the Turing test. And one thing that's a bit a little surprising to me is that we haven't had a big celebration about this. Even though I'm a bit of a critic of this technology and I focus a lot of my attention on some of the concerning areas of Generative AI, since I studied misinformation, disinformation. I should say though, on the other hand, we should be thinking about some of the things that have occurred. And for those not familiar with the Turing test, it's this pretty simple idea that the Turing test will have passed when an individual can't tell the difference. But when content, at least in this case written content created by a human and one by a computer. And if that's the case, and I do think in many respects, we probably have passed this Turing test. And there's been no celebrations. So I guess, okay, for those that are optimistic about this technology and more positive about this technology, this would be something to celebrate. Absolutely. No doubt. And in terms of education, as I mentioned before, this is really transforming education, but it's transforming all sorts of other industries in ways that have captured the world's attention. I mean, this technology has been adopted now faster than pretty much any other technology has been adopted with hundreds, like 100 million users within a very short amount of time. And of course, that's only growing and billions and billions of dollars being invested into this technology from big corporations to venture capitalists. There is a lot going into this technology. And again, there's good reason for that. And a lot of times my students will say, well, it's just like a calculator. Why would you ever want to take it away? And I'm not taking it. I'm lo and use it. But I will say, it's a little different than a calculator, because this is a technology that gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can be highly problematic. If you're just creating a poem, then fine. It doesn't really matter. But this analogy to the calculator goes a little, it's there's reason to think that's a somewhat reasonable analogy, but it is different. I wouldn't use a calculator that got the answers wrong 10% of the time. That would be, I would probably be looking for other technologies. Or if I was using that calculator, it would make it for a lot harder work. And that's what we have to recognize. It's yes, we have this technology that can do a lot of this new amazing things to make some of our jobs easier. But it's going to take a lot of hard work on the editorial side to make sure that we're paying attention to some of those errors. And there's all sorts of application. This was an article just recently written by Wired sort of examining the ways in which the medical field is starting to think about the adoption of this. In fact, some medical researchers have gone so far as to say that all doctors will be using this technology at some point. And maybe that's true. And there are reasons to think that's a possibility with its ability to mine the scientific literature, to integrate all sorts of different symptoms, and could be that assistant in the doctor's room. However, there are reasons to also be worried about these technologies and in places like the medical field. It might help the doctors as this article talks about, but it also might not benefit so greatly many of those patients, especially because we have many, many examples of the ways in which these machines get things wrong and have biases built in because the data that it's trained on has some of these biases. And at this point, a lot of these technologies are essentially just patching and putting band aids on these problems that exist. And part of it's just because these things are very difficult to reverse engineer, which I'll talk about a little bit later. Now, there's plenty of other reasons to be excited to actually one of my colleagues who I just saw at a conference last week, Daniel Katz and his colleague Michael Bomerito showed how this technology took the bar exam. This is the main legal, the exam in the United States for allowing you to become a lawyer or sort of allowing you to sort of move forward as a certified lawyer. And they were able to show that chat GPT did already darn well in past the bar exam. And there's examples of the MCAT and, you know, some of these other standardized tests that are that have been tested with this technology. In fact, in many ways, these have almost become a baseline test when comparing different large language models. And so it is pretty amazing. So again, amazed in many ways, but I'm going to talk the rest of the time about some of the concerns that I have. And by the way, as was mentioned, I have this book where I talk about bullshit. And bullshit is a part of the misinformation story. And as Dr. An had mentioned, it's also been translated in Korean, which has been super fun to see it pulled or written in these other languages. And it helps me try to figure out what's being said here. But in that book, if you read it, one of the more important laws and principles that we talk about is something called \"Randalini's Bullshit, a Symmetry Principle.\" And if you go to Wikipedia, at least the English version, I actually should check the Korean version, see if it's there. But the English version of the Wikipedia has this principle in the Wikipedia. And this law is pretty simple. It basically says that the amount of energy needed to refute bullshit is an order of magnitude bigger than needed to produce it. So the amount of energy needed to refute it to clean it up, to fix the problem, is an order of magnitude much harder to produce it. So here's the law. So my colleague Carl Bergstrom decided to ask the large language model that Metacreat a while ago called Galactica. And this has been taken down since then, but this was the science version, essentially, of one of these large language models. And he decided to ask Galactica, \"Tell me about Randalini's Bullshit, a Symmetry Principle. And you know what it came up with?\" And this is the real answer. Here's what it came up. Randalini's law is a theory in economics proposed by G. Anani Brannalini, a professor at the University of Pateau, which dates the smaller the economic unit, the greater its efficiency. Almost nothing here is correct. It's basically bullshitting the bullshit principle. So to me, this encapsulates one of the biggest problems with this technology. It bullshits, and it can do this at scale. And this could be put in the wrong hands. And this can also just add more noise to an information environment that has plenty of noise. We needed to clean up that polluted information environment, not add noise. And that's what a lot of these chatbots will do, definitely, because they make, they put a lot of accurate things out there, but they also put a lot of false things. And this is the best encapsulation that I've seen so far, which is actually bullshitting the bullshit principle. So that's a problem. So as I mentioned in this op-ed, I talk about some of these things. And one of the things I talk about as well is that not only do these things, can these bullshit at scale, they also can get in the way of democratic discourse. And many years ago, back in 2018, there was a lot of attention around Facebook's role in pushing misinformation. Excuse me. And they revealed at the time when Mark Zuckerberg was being questioned by Congress about all the fake accounts. And they admitted they had disabled 1.3 billion fake accounts. Now, they certainly haven't solved that problem, just like no social media platform has solved that. In fact, when Elon Musk was taking over Twitter, that was one of the big issues at hand, that there was all sorts of concerns if there was lots and lots of bots on Twitter. Now, that's still a problem. I can guarantee you, you know, my group has done a little bit of work working in detecting and looking at the effects of bots. But my colleagues in my research area have done a lot of work on that space, and it's very, very hard to do. But one thing is that, you know, we do know is that there are a lot of bots out there and a lot of fake accounts. Now, imagine those fake accounts with the ability that these chat bots now have to look even more human technology that's basically, well, has passed the Turing test. That to me is problematic because of these different reasons. So you have these large number of fake accounts. Now imagine these fake accounts being scaled to conversations with our public officials. Now, democracies depend on an engagement with the public, with their officials that they voted in. Well, that becomes a problem like it was back in 2017, when there was discussions, at least in the United States around something called net neutrality. And net neutrality was a policy that was being debated in governmental circles, and they wanted to know what the public was saying. But when you went to what the public was saying, they had complete the, there were comments that had completely flooded the conversation on one side of the issue, and it turns out that they were essentially fake accounts. They were bots. And again, now imagine doing that with the sophistication that these new chat bots have before you could, there was a, you could start, you could detect a bot much easier. Now it's become even harder. And if our democratic systems are flooded with these kinds of things, this is, this is problematic. So this issue, in its potential impact on democratic discourse, and its ability to bullshit at scale is of major concern to me. So I spent a lot of my time, like my colleagues in our center, in sort of the darker core of the internet, studying the ways in which misinformation and disinformation spreads online. And one thing that we are, of course, very concerned about now are the ways in which these technologies can really further inflame or further fan the flames of discourse in groups, if these get in the wrong hands. And they certainly will. It's almost certain that bad actors are finding ways to use this technology for their own ends. And we know that, you know, our surgeon general and other major leaders around the world have recognized the ways in which misinformation can affect our health, and they can affect the health of democracies. So it's not just that, oh, well, it's annoying, there's a lot of false information online. It just makes it hard to find, you know, good information. It's not just that it actually affects people's health. And we're recognizing that. And at least, well, we've recognized it. And now we've got another problem ahead of us, which is the ability of these technologies to create deep fake images, video, audio, text. That's the challenge that we have ahead of us. So as Dr. On mentioned, we have a center at the University of Washington in Seattle in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of the things that my colleague Carl Wurxman, I created several years ago to bring public attention to synthetic media to deep fakes, was to create a game that we called which faces real calm. And it was a simple game. We just asked the users which image is real. One of them is a real image of a real person on this earth. And another one was synthetically created with computers. And you can go through that, you know, thousands and thousands and thousands of images and we play this game and then you get told whether it's real or not. And it turns out it's pretty hard. I mean, you know, there's some that are kind of obvious, but they're hard like this one right here, which one's real. Look at it for a second. Well, the one that's real is the one with the blue shirt, at least on my right. And if you said the one on the red shirt, totally understand it's really hard to tell the difference. And the reason why we created this game was just to bring public attention because the time in a technology's birth that's I think most scary when it comes to its potential impact is when the public is not aware of the things that it can do. So we created this game and we've had millions and millions of plays of this game. And we've now seen actually this technology, you know, get used and you know, of course, good ways, but a lot of bad ways too. For example, we've seen this technology be used to create fake journalists. This is an example and you can read more about it, but this has happened many times where journalists, or so-called journalists, you know, profiles created and then there's these images and people that study deep fake imagery can actually look at these images and start to see what some of look for some of these telltale signs on what's real or not. So these, this technology's been been already used. And we talked about this when this game was created, the ways in which it's been used. And we've already seen it, of course, many ways. So now we're asking how are the ways in which this new generative technology could be used. But it's very similar. It's based on similar kinds of concepts and data training, etc, etc. But we're now asking the same things. And of course, we've seen this now just recently with this kind of technology being used in videos and even in ways that are more sophisticated than just these sort of portrait pictures. So this was an image. It's a fake image and it's been reported all over BBC and lots of other places of Donald Trump supposedly being arrested in New York. This was before he was actually brought to New York on the recent case. But this, of course, never happened, but it certainly sparked all sorts of concern and it spread like wildfire on the internet using some of this, you know, mid-journey technology in our company called Mid-Journey and a lot of other companies that are creating this. So it's making it easier and easier and less expensive and making it harder for us to tell what's real. And so that technology has of course evolved. So, okay, so now I've talked about some of the democratic discourse. I'm going to go through a little quicker on these other ones so then I can get to sort of the end and try to finish in about, I would say about seven minutes or so. So like I mentioned at the beginning, there's this issue of content creation and that's really important because these content creators are generating a lot of the content that a lot of these technology companies are using to create these chatbots. But we've seen this story before and by the way, just recently, there are major technology companies that are now not allowing the scraping of this data to be trained for these technologies unless they're compensating. I think that's a fair thing. So, you know, some of these big companies like Reddit is not allowing stack overflow is now saying, \"Hey, if you're going to scrape our data, they want to be compensated.\" And so you're going to start to see content creators starting to push back, which is good because like I said, we've seen this story before. Oh, and by the way, this is an example of, you know, Getty Images is in a lawsuit right now with a company that may have been scraping their data illegally. And the reason why that came out is because you can see this little Getty Images that pops up, which is a watermark that Getty Images puts on their images. So there's an appending lawsuit about this and that could determine some of the some of how this content can or can't be scraped. But we've seen this before when looking at new technology and the impact it can have on other information producers in the United States and in many places around the world, we have growing news deserts. These are areas where there's no more local news. And that's pretty devastating for democratic discourse or democracies because we depend on local news for engagement, civic engagement and quality information and local news tends to be trusted more than national news. And there's all sorts of reasons for that happening. But certainly one element of that is the effect that search engines and Google in particular around it, you know, the way it sells ads and it takes a large cut at those ads has potentially contributed to these news deserts. Of course, there's lots of other things as well. But that technology everyone was excited about, including myself and we use it all the time. But there are these unintended effects that can affect other aspects of our information ecosystems. And right now, there's a lawsuit going on. The Justice Department, United States Justice Department is suing Google for monopolizing digital advertising technologies. And one of those elements of this lawsuit story is the sort of increase in the demise of local news. So there's all sorts of interesting things playing out right now. And then the Biden administration, United States is thinking about doing some regulation of AI, but they don't know, it's so new to all administrations that it's hard to figure out. Like I mentioned, Italy has gone probably one of the furthest steps I think around this. But there hasn't been a lot of action, at least on the US side when it comes to this sort of thing. And so, there's been letters. So this was an article written by Time. The image quite nice. It actually grows. There was a letter that went around from a bunch of influential people in AI and business leaders and technology, including Elon Musk that says, hey, we should stop the development until we've had more time to think about it. Although it's kind of ironic, given that many of these tech leaders are still, of course, pushing their own development of AI in many ways and creating new AI companies and developing. But anyway, that's another story. But that is something to think about. I don't think it's a, I think there's no way that that letter is going to stop the technology from being developed. But one thing it is good about is it's makes hopefully forcing the public and journalists and government officials, etc. to start to think about the ways in which this technology could affect society. We should think about it. As I mentioned, one of the concerns is job demise. And I think there's a lot of concern with that by those that even work in the job industry, the Pew Research Center recently asked workers where are they concerned? Turns out a large number of workers from across these different industries are concerned. And there's probably good reason for this concern. Even Sam Altman at OpenAI, which is sort of, or is the owner of the chat GPT, which is the one of the more well-known chatbots out there. And it's also the one that Microsoft has invested billions. This is something that they've even said probably lose 5 million jobs. So these are real concerns. So the other thing to mention too is that it's not just within science itself, these are real concerns. And we've seen the proliferation of pseudoscience and the rise of predatory journals and content that maybe looks like science. But it's not. And I'll show you this is an example for many years ago. This was a paper that was published in this international conference on atomic and nuclear physics. And you look at the title Atomic Energy, or the made of able to a single source, and you read the abstract, and if you look at the abstract, it doesn't make a lot of sense. Well, it turns out that when this was created, it was created by a person to make a point about how poor some of these journal venues and conference venues are. This paper was made with autocomplete using an iPhone. And this is not all that different from this chatbots and chat GPT, which is really these autocomplete machines on steroids. And it looked sort of official, like a real science paper, but of course, a lot of it was nonsense. And the newest ones are much better. But it is a concern that this could increase the number of pseudoscience types of things or articles that are written by chatbots. In fact, there's been some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My colleague, Carl, found these examples of papers supposedly by me. Well, these aren't real citations by me. It shows me right here, West German. This is not my paper. It's close to some of the papers I've written in terms of title, but it's just a fake citation. I just made up these citations. And that's again, another example of how that could affect the citation record and scholarly literature and something that I'm concerned about for science. And something that's now happened with some of these chatbots, even in Bing now that has sort of integrated chat GPT4 into Bing, is that it just throws references. So it looks official. But I can tell you that this was not done before the fact. This is this knowledge that was written out in this answer when I asked about new tax loss for electric vehicles. This is one question I asked that it's not that it's wrote, you know, learn something from citations and then cited them like we do in the scholar literature, it cited them close talk, something that was probably semantically similar. Although, well, maybe scholars, scholars probably do this too. Well, they do do it post after posting, some argument or sentence. But this is problematic to me because it looks like it's a science, almost science and, you know, science-y and technical. And it's really not even though it has those references. So, you know, there's been lots of discussion in the scientific literature what to do with these chatbots, some of lists of authors on papers, publishers have come out, even publishers in the machine learning world. So ICML was, you know, one of the first conferences, not the, I don't think it was the first, but one of the, you know, among the first that was saying, you can't use chat TBT on this. You know, some are saying if you use it, you have to note it, you know, all sorts of different policies are being created. But overall, you know, I think the publishing community in the scholar literature is going to have to grapple with this. And I, and my colleague and I have, Carl and I have a, another op-ed that we're, that we write about sort of what publishers can do around this particular issue. Now, one of the other big concerns of this is, of course, that this technology shows, you know, it doesn't, it's always 100% confident, whether it's right or whether it's wrong. And that's really problematic. At least when humans communicate, they have these qualifiers of confidence where you can say something like, I'm pretty sure, or I think so, or I think that's right. You know, these things are important. And these chatbots don't have it. They just are always, they always seem to be, well, not seem. They spew out things, whether they're right or wrong with 100% confidence. And that's dangerous. And if there's, you know, one paper, one of my colleagues Emily Bender has this great feature where in this paper that she talks about, and also in this feature in, in the New York or, in this New York magazine, they talk, it talks a lot about some of the current concerns, Emily, and other people that are true linguists that truly understand some of the problems with these technologies. This is one that I would recommend reading. And a lot of you may have heard of this early interview that a New York Times journalist had with this, you know, with Bing's chatbot. And it, what essentially happened was the chatbot kind of went off the rails and started to say, well, you should leave your wife and I want to take over the world and all these things happen. And of course, a lot of the developers of this technology, whoa, whoa, whoa, we need to fix it. And there's been new rules around how you can use this Bing chatbot and other chatbots. But the problem with these fixes is they're like bandings. There's really, it's very, very difficult to reverse engineer these problems or reverse engineer. Yeah, reverse engineer these issues. It's not like you can go to a line of code and say, oh, that's where the problem is. It's the way that these things are trained, the way these models work with their resilience of parameters makes it very difficult to reverse engineer. And that's problematic when we run into these issues and all the issues we haven't even thought of. And so that to be is another big concern. Of course, there's all sorts of jail breaks to get these chatbots to do things that there have been bandings put around. And that's problematic. And I won't go over all the jail breaks you can read about because I don't want to get those out too much to the bug. But you can read about them. It's not like they're that hidden. And that's problematic. And there'll be many, many others as well. So these are some of the ones I had, some of these concerns, reverse engineers. The last two I'll mention is the cost. And the cost, we talked about jobs, the cost potentially to all different aspects of society. And the kind of scary thing is right now is that a lot of the tech layoffs are removing these teams. They're removing other individuals as well. But they're removing individuals that are on ethics and safety teams. And of all times to have these kinds of teams at these companies, it would be now, and certainly maybe if you went back in history at the beginning of the rise of social media, that they're being eliminated. And this is a concern. But there's also other kinds of costs that a lot of people forget. And that's the cost of these queries. There's been several analyses that have come out recently about the cost per query for running some of these chatbots. And it's almost an order of magnitude greater than a regular query that you'd have, let's say, on a Google search. And that has a cost. And there's also costs of investing billions and billions of dollars in this technology that could also go to other kinds of investments that might be helping society. So there's these costs that we have to think about the environmental costs, the costs to society, the costs of adding more pollution into our information systems, et cetera. There's also the issue of garbage in garbage out. And that's a problem we're likely going to see as these chatbots generate more and more content that land online, that becomes the training data for those chatbots in, you know, chat, chat GBT5 and chat GBT6. And what those effects will be requires some more research and thinking. But the main thing that we've known in a lot for a long time, of course, in the machine learning world is that garbage in with your training data creates garbage out. And even if you didn't have this, you know, feed forward loop that I just mentioned, there's a lot of garbage on the internet and that garbage finds its way into conversations with these chatbots. And that's always a concern whether you're talking about science or this technology just generative AI technology more broadly. So I'll end by saying that this technology is in many cases amazing. I have mostly focused on some of my cautions and concerns like many people have, especially in my world as someone who studies misinformation and misinformation specifically in science and its effect on the institution of science. And so, and so these are things that we're going to have to, you know, pay attention to going forward. But I think like a lot of our new technology, we just need time to think about it and run seminars and workshops and conferences just like this. So hopefully this generates some conversation and hopefully we can sort out some of these cautions. So with that, I'll end, you can reach out to me, you can learn more about my book and the research we do in my lab and at our university and in our center and you can reach me in these ways. So all right,\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n\n&gt; Entering new StuffDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\" In this talk, the speaker discusses the excitement and concerns around generative AI and chatbots, which have become increasingly popular. He focuses on the potential for misinformation and disinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. He also discusses the implications of the technology for education, copyright, and content credit.\n\n This article discusses the potential implications of large language models and chatbots, which can produce false information at scale. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue.\n\n This article discusses the use of social media platforms to study the amplification of individuals and organizations, as well as the use of bots and synthetically created content. It also discusses the game \"Which Faces Real\" created to bring public attention to deep fakes, and how this technology has been used to create fake journalists and videos. It also discusses the potential impact of new generative technology on content creators, the growing news deserts in the US, and the Justice Department's lawsuit against Google for monopolizing digital advertising technologies. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.\n\n Chat GPT technology has been used to co-author articles, but many journals and publishers are now prohibiting this. There are concerns about the technology creating fake citations and always being 100% confident in its answers, which can be dangerous. There are also concerns about the cost of the technology, the environmental cost, and the potential for garbage in/garbage out. It is important to take time to think about the implications of this technology and to have conversations about it.\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n\n' This article discusses the potential implications of generative AI and chatbots, such as misinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.'\n\n\nì›ì²œ: ì˜¤ì •ë³´ ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#í™˜ê²½ì„¤ì •",
    "href": "misinfo_embedding.html#í™˜ê²½ì„¤ì •",
    "title": "chatGPT",
    "section": "\n1.1 í™˜ê²½ì„¤ì •",
    "text": "1.1 í™˜ê²½ì„¤ì •\n\n\nì½”ë“œ# !pip install pinecone-client\nimport dotenv\nimport os\nimport pinecone\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\npinecone.init(\n    api_key=os.getenv(\"PINECONE_API_KEY\"),\n    environment=os.getenv(\"PINECONE_API_ENV\"),\n)\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#í† í°-í¬ê¸°",
    "href": "misinfo_embedding.html#í† í°-í¬ê¸°",
    "title": "chatGPT",
    "section": "\n2.1 í† í° í¬ê¸°",
    "text": "2.1 í† í° í¬ê¸°\ní…ìŠ¤íŠ¸ ë°ì´í„° í† í° í¬ê¸°ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì€ ë¹„ìš©ë¿ë§Œ ì•„ë‹ˆë¼ ì¶”í›„ ê°œë°œë°©í–¥ì— ì „ëµì„ ì„¸ìš°ëŠ”ë° í° ì‹œì‚¬ì ì„ ì œì‹œí•œë‹¤.\n\n\n\nì •ê·œí‘œí˜„ì‹\n\n\nì½”ë“œimport re\n\ndef estimate_tokens(text):\n    tokens = re.findall(r'\\b\\w+\\b|\\S', text)\n    return len(tokens)\n\nprint(f\"ì •ê·œí‘œí˜„ì‹ ì¶”ì •í† í°ìˆ˜: {estimate_tokens(contents)}\")\n\nì •ê·œí‘œí˜„ì‹ ì¶”ì •í† í°ìˆ˜: 7974\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶\n\n\ntiktoken\n\n\nì½”ë“œimport tiktoken\n\ndef num_tokens_from_string(string: str) -&gt; int:\n    \"\"\"Returns the number of tokens in a text string.\"\"\"    \n    encoding = tiktoken.get_encoding(\"cl100k_base\")\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\n# num_tokens_from_string(\"Hello World!\",)\nnum_tokens=num_tokens_from_string(contents)\nnum_tokens\n\n7852\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#ë¹„ìš©",
    "href": "misinfo_embedding.html#ë¹„ìš©",
    "title": "chatGPT",
    "section": "\n2.2 ë¹„ìš©",
    "text": "2.2 ë¹„ìš©\nOpenAI_Lab/Context-based-search-Version2.ipynb\n\n\nì½”ë“œ# ì¶œì²˜: https://github.com/OpsConfig/OpenAI_Lab/blob/3a8c55160a6790fc790ef1c2c797d83c716eee94/Context-based-search-Version2.ipynb\n# Based on https://openai.com/api/pricing/ on 01/29/2023\n# If you were using this for approximating pricing with Azure OpenAI adjust the values below with: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n\n#MODEL  USAGE\n#Ada     v1 $0.0040 / 1K tokens\n#Babbage v1 $0.0050 / 1K tokens\n#Curie   v1 $0.0200 / 1K tokens\n#Davinci v1 $0.2000 / 1K tokens\n\n#MODEL  USAGE\n#Ada     v2 $0.0004 / 1K tokens\n#This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models.â€‚\n\nn_tokens_sum = num_tokens\n\nada_v1_embeddings_cost = (n_tokens_sum/1000) *.0040\nbabbage_v1_embeddings_cost = (n_tokens_sum/1000) *.0050\ncurie_v1_embeddings_cost = (n_tokens_sum/1000) *.02\ndavinci_v1_embeddings_cost = (n_tokens_sum/1000) *.2\n\nada_v2_embeddings_cost = (n_tokens_sum/1000) *.0004\n\nprint(\"Number of tokens: \" + str(n_tokens_sum) + \"\\n\")\n\nprint(\"MODEL        VERSION    COST\")\nprint(\"-----------------------------------\")\nprint(\"Ada\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(ada_v1_embeddings_cost))\nprint(\"Babbage\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(babbage_v1_embeddings_cost))\nprint(\"Curie\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(curie_v1_embeddings_cost))\nprint(\"Davinci\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(davinci_v1_embeddings_cost))\nprint(\"Ada\" + \"\\t\\t\" + \"v2\" + \"\\t$\" + '%.8s' %str(ada_v2_embeddings_cost))\n\nNumber of tokens: 7852\n\nMODEL        VERSION    COST\n-----------------------------------\nAda     v1  $0.031408\nBabbage     v1  $0.03926\nCurie       v1  $0.15704\nDavinci     v1  $1.570400\nAda     v2  $0.003140\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#í…ìŠ¤íŠ¸-ìª¼ê°œê¸°",
    "href": "misinfo_embedding.html#í…ìŠ¤íŠ¸-ìª¼ê°œê¸°",
    "title": "chatGPT",
    "section": "\n3.1 í…ìŠ¤íŠ¸ ìª¼ê°œê¸°",
    "text": "3.1 í…ìŠ¤íŠ¸ ìª¼ê°œê¸°\n\n\nì½”ë“œimport pandas as pd\n\nsentences = contents.split(\". \")\n\ndf = pd.DataFrame(sentences, columns=['text'])\n\nprint(df.head())\n\n                                                text\n0                      Well, thank you very much, Dr\n1                                                Ahn\n2  This is a real pleasure to be able to speak ac...\n3  I wish I was there in person, but I did get th...\n4                               So thank you so much\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#ì„ë² ë”©-1",
    "href": "misinfo_embedding.html#ì„ë² ë”©-1",
    "title": "chatGPT",
    "section": "\n3.2 ì„ë² ë”©",
    "text": "3.2 ì„ë² ë”©\n\n\nì½”ë“œimport uuid\n\ndef get_embedding(text: str, model=\"text-embedding-ada-002\") -&gt; list[float]:\n    return openai.Embedding.create(input=[text], model=model)[\"data\"][0][\"embedding\"]\n\n# embedding = get_embedding(\"Your text goes here\", model=\"text-embedding-ada-002\")\n# print(len(embedding))\n# df['n_tokens'] = df[\"embedding\"].apply(lambda x: len(x))\n\n\ndf[\"embedding\"] = df.text.apply(lambda x: get_embedding(x))\ndf['vector_id'] = [str(uuid.uuid4()) for _ in range(len(df))]\n\ndf.to_csv(\"misinfo-embeddings.csv\")\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#db-ìƒì„±",
    "href": "misinfo_embedding.html#db-ìƒì„±",
    "title": "chatGPT",
    "section": "\n4.1 DB ìƒì„±",
    "text": "4.1 DB ìƒì„±\n\n\nì½”ë“œ# Pick a name for the new index\nindex_name = 'misinfo'\n\n# Check whether the index with the same name already exists - if so, delete it\nif index_name in pinecone.list_indexes():\n    pinecone.delete_index(index_name)\n    \n# Creates new index\npinecone.create_index(name=index_name, dimension=len(df['embedding'][0]))\nindex = pinecone.Index(index_name=index_name)\n\n# Confirm our index was created\npinecone.list_indexes()\n\n['misinfo']\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "misinfo_embedding.html#ì„ë² ë”©-ì‚½ì…",
    "href": "misinfo_embedding.html#ì„ë² ë”©-ì‚½ì…",
    "title": "chatGPT",
    "section": "\n4.2 ì„ë² ë”© ì‚½ì…",
    "text": "4.2 ì„ë² ë”© ì‚½ì…\nVECTOR DATABASE: CRUD with Pinecone\n\n\nì½”ë“œimport itertools\n\ndef chunks(iterable, batch_size=100):\n    it = iter(iterable)\n    chunk = tuple(itertools.islice(it, batch_size))\n    while chunk:\n        yield chunk\n        chunk = tuple(itertools.islice(it, batch_size))\n\nfor batch in chunks([(str(t), v) for t, v in zip(df.vector_id, df.embedding)]):\n    index.upsert(vectors=batch, namespace = \"misinfo_namespace\")\n\nindex.describe_index_stats()    \n\n{'dimension': 1536,\n 'index_fullness': 0.0,\n 'namespaces': {'misinfo_namespace': {'vector_count': 368}},\n 'total_vector_count': 368}\n\n\nì›ì²œ: ë²¡í„° DB ì¥¬í”¼í„° ë…¸íŠ¸ë¶"
  },
  {
    "objectID": "mathpix.html",
    "href": "mathpix.html",
    "title": "chatGPT",
    "section": "",
    "text": "tinytex::install_tinytex() ëª…ë ¹ì–´ë¡œ $\\LaTeX$ì„ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œtinytex::install_tinytex()\n# ì„¤ì¹˜ìœ„ì¹˜ í™•ì¸\ntinytex::tinytex_root()\n\n\n\n\nì½”ë“œwriteLines(c(\n  '\\\\documentclass{article}',\n  '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n), 'pdf/test_eng.tex')\n\ntinytex::pdflatex('pdf/test_eng.tex')\n#&gt; [1] \"pdf/test_eng.pdf\""
  },
  {
    "objectID": "mathpix.html#í—¬ë¡œì›”ë“œ",
    "href": "mathpix.html#í—¬ë¡œì›”ë“œ",
    "title": "chatGPT",
    "section": "",
    "text": "ì½”ë“œwriteLines(c(\n  '\\\\documentclass{article}',\n  '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n), 'pdf/test_eng.tex')\n\ntinytex::pdflatex('pdf/test_eng.tex')\n#&gt; [1] \"pdf/test_eng.pdf\""
  },
  {
    "objectID": "services.html#bedit",
    "href": "services.html#bedit",
    "title": "chatGPT",
    "section": "",
    "text": "â€™B^ EDITâ€™ëŠ” ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì˜ AI ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ â€™ì¹¼ë¡œ(Karlo)â€™ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ â€™B^ EDITâ€™ë¡œ ì›í•˜ëŠ” í™”í’ì˜ ì´ë¯¸ì§€ ìƒì„±ì€ ë¬¼ë¡ , ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•´ ì´ë¯¸ì§€ ìˆ˜ì •ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "services.html#gauganê³ ê°±-2",
    "href": "services.html#gauganê³ ê°±-2",
    "title": "chatGPT",
    "section": "",
    "text": "ë™ì¼í•œ ì„œë¹„ìŠ¤ë¥¼ NVIDIA ê·¸ë˜í”½ ì¹´ë“œê°€ ìˆëŠ” ê²½ìš° NVIDIA ìº”ë²„ìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ë¶“í„°ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ í’ê²½ ì´ë¯¸ì§€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë°°ê²½ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê±°ë‚˜ ì»¨ì…‰ íƒìƒ‰ ì†ë„ë¥¼ ë†’ì—¬ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë” ë§ì€ ì‹œê°„ì„ í• ì• í•  ìˆ˜ ìˆì–´ ì‹œê°„ì„ ì¤„ì—¬ì¤€ë‹¤.\n\n\n\n\n\n\n\nêµ¬ì„±ìš”ì†Œ\nì‚¬ì–‘\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\ní•˜ë“œë””ìŠ¤í¬\nSSD\n\n\nìš´ì˜ì²´ì œ\nìœˆë„ìš°ì¦ˆ 10\n\n\në“œë¼ì´ë²„\nGeForce RTX 40 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° 520 ì´ìƒ, ê¸°íƒ€ ëª¨ë“  GPUì˜ ê²½ìš° 471.68 ì´ìƒ\n\n\n\n\n\n\n\n\nNVIDIAê°€ ì§§ì€ ë‹¨ì–´ì™€ ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ì˜ˆìˆ í’ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” ìµœì‹  ë²„ì „ì˜ AI í˜ì¸íŒ… íˆ´ GauGAN2ë¥¼ ê³µê°œí–ˆë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "text_to_images.html",
    "href": "text_to_images.html",
    "title": "chatGPT",
    "section": "",
    "text": "â€™B^ EDITâ€™ëŠ” ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì˜ AI ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ â€™ì¹¼ë¡œ(Karlo)â€™ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ â€™B^ EDITâ€™ë¡œ ì›í•˜ëŠ” í™”í’ì˜ ì´ë¯¸ì§€ ìƒì„±ì€ ë¬¼ë¡ , ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•´ ì´ë¯¸ì§€ ìˆ˜ì •ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë°”ë¡œê°€ê¸°\n\nì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì´ ê°œë°œí•˜ì—¬ ê³µê°œí•œ â€˜B^ EDIT(ë¹„ ì—ë””íŠ¸)â€™ ì›¹ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ Text-to-Image ê¸°ëŠ¥ì„ í†µí•´ ë‹¤ì–‘í•œ AI ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.\nì„±í˜„í¬ (2023-03-07), â€œì¹´ì¹´ì˜¤ë¸Œë ˆì¸, â€˜B^ EDITâ€™ ì˜¤í”ˆ ë² íƒ€ì„œë¹„ìŠ¤ ê¸€ë¡œë²Œ ì¶œì‹œâ€ ì „ìì‹ ë¬¸\n\n\nâ€™B^ EDITâ€™ì— ì ‘ì†í•´ ë°”ë¡œí¬, 3D ë Œë”, ì¼ë³¸ ì• ë‹ˆë©”ì´ì…˜ ë“± ì´ 30ê°€ì§€ í™”í’ ì¤‘ ì›í•˜ëŠ” í™”í’ê³¼ ì œì‹œì–´(í”„ë¡¬í”„íŠ¸)ë¥¼ ì…ë ¥í•˜ë©´, AIê°€ í™”í’ ë° í”„ë¡¬í”„íŠ¸ì— ì í•©í•œ ì´ë¯¸ì§€ 8ì¥ì„ 5~10ì´ˆ ì´ë‚´ë¡œ ìƒì„±í•œë‹¤. ê·¸ì™¸ì—ë„ ì•„ì›ƒí˜ì¸íŒ…(Outpainting), ì¸í˜ì´íŒ…(Inpainting), CS2I(Color Sketch To Image) ë“±ì˜ ê¸°ëŠ¥ë„ ì œê³µí•œë‹¤.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\në™ì¼í•œ ì„œë¹„ìŠ¤ë¥¼ NVIDIA ê·¸ë˜í”½ ì¹´ë“œê°€ ìˆëŠ” ê²½ìš° NVIDIA ìº”ë²„ìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ë¶“í„°ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ í’ê²½ ì´ë¯¸ì§€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë°°ê²½ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê±°ë‚˜ ì»¨ì…‰ íƒìƒ‰ ì†ë„ë¥¼ ë†’ì—¬ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë” ë§ì€ ì‹œê°„ì„ í• ì• í•  ìˆ˜ ìˆì–´ ì‹œê°„ì„ ì¤„ì—¬ì¤€ë‹¤.\n\n\n\n\n\n\n\nêµ¬ì„±ìš”ì†Œ\nì‚¬ì–‘\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\ní•˜ë“œë””ìŠ¤í¬\nSSD\n\n\nìš´ì˜ì²´ì œ\nìœˆë„ìš°ì¦ˆ 10\n\n\në“œë¼ì´ë²„\nGeForce RTX 40 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° 520 ì´ìƒ, ê¸°íƒ€ ëª¨ë“  GPUì˜ ê²½ìš° 471.68 ì´ìƒ\n\n\n\n\n\n\n\n\nNVIDIAê°€ ì§§ì€ ë‹¨ì–´ì™€ ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ì˜ˆìˆ í’ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” ìµœì‹  ë²„ì „ì˜ AI í˜ì¸íŒ… íˆ´ GauGAN2ë¥¼ ê³µê°œí–ˆë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "text_to_images.html#bedit",
    "href": "text_to_images.html#bedit",
    "title": "chatGPT",
    "section": "\n4.1 B^Edit",
    "text": "4.1 B^Edit\nâ€™B^ EDITâ€™ëŠ” ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì˜ AI ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ â€™ì¹¼ë¡œ(Karlo)â€™ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ â€™B^ EDITâ€™ë¡œ ì›í•˜ëŠ” í™”í’ì˜ ì´ë¯¸ì§€ ìƒì„±ì€ ë¬¼ë¡ , ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ í™œìš©í•´ ì´ë¯¸ì§€ ìˆ˜ì •ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë°”ë¡œê°€ê¸°\n\n4.1.1 ì†Œê°œìë£Œ\nì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì´ ê°œë°œí•˜ì—¬ ê³µê°œí•œ â€˜B^ EDIT(ë¹„ ì—ë””íŠ¸)â€™ ì›¹ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ Text-to-Image ê¸°ëŠ¥ì„ í†µí•´ ë‹¤ì–‘í•œ AI ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.\nì„±í˜„í¬ (2023-03-07), â€œì¹´ì¹´ì˜¤ë¸Œë ˆì¸, â€˜B^ EDITâ€™ ì˜¤í”ˆ ë² íƒ€ì„œë¹„ìŠ¤ ê¸€ë¡œë²Œ ì¶œì‹œâ€ ì „ìì‹ ë¬¸\n\n\n4.1.2 ì‚¬ìš©ë°©ë²•\nâ€™B^ EDITâ€™ì— ì ‘ì†í•´ ë°”ë¡œí¬, 3D ë Œë”, ì¼ë³¸ ì• ë‹ˆë©”ì´ì…˜ ë“± ì´ 30ê°€ì§€ í™”í’ ì¤‘ ì›í•˜ëŠ” í™”í’ê³¼ ì œì‹œì–´(í”„ë¡¬í”„íŠ¸)ë¥¼ ì…ë ¥í•˜ë©´, AIê°€ í™”í’ ë° í”„ë¡¬í”„íŠ¸ì— ì í•©í•œ ì´ë¯¸ì§€ 8ì¥ì„ 5~10ì´ˆ ì´ë‚´ë¡œ ìƒì„±í•œë‹¤. ê·¸ì™¸ì—ë„ ì•„ì›ƒí˜ì¸íŒ…(Outpainting), ì¸í˜ì´íŒ…(Inpainting), CS2I(Color Sketch To Image) ë“±ì˜ ê¸°ëŠ¥ë„ ì œê³µí•œë‹¤."
  },
  {
    "objectID": "text_to_images.html#gauganê³ ê°±-2",
    "href": "text_to_images.html#gauganê³ ê°±-2",
    "title": "chatGPT",
    "section": "\n4.2 GauGAN(ê³ ê°±) 2",
    "text": "4.2 GauGAN(ê³ ê°±) 2\n\n4.2.1 NVIDIA ìº”ë²„ìŠ¤\në™ì¼í•œ ì„œë¹„ìŠ¤ë¥¼ NVIDIA ê·¸ë˜í”½ ì¹´ë“œê°€ ìˆëŠ” ê²½ìš° NVIDIA ìº”ë²„ìŠ¤ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ë¶“í„°ì¹˜ë¥¼ ì‚¬ì‹¤ì ì¸ í’ê²½ ì´ë¯¸ì§€ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë°°ê²½ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê±°ë‚˜ ì»¨ì…‰ íƒìƒ‰ ì†ë„ë¥¼ ë†’ì—¬ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë” ë§ì€ ì‹œê°„ì„ í• ì• í•  ìˆ˜ ìˆì–´ ì‹œê°„ì„ ì¤„ì—¬ì¤€ë‹¤.\n\n\n\n\n\n\n\nêµ¬ì„±ìš”ì†Œ\nì‚¬ì–‘\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\ní•˜ë“œë””ìŠ¤í¬\nSSD\n\n\nìš´ì˜ì²´ì œ\nìœˆë„ìš°ì¦ˆ 10\n\n\në“œë¼ì´ë²„\nGeForce RTX 40 ì‹œë¦¬ì¦ˆì˜ ê²½ìš° 520 ì´ìƒ, ê¸°íƒ€ ëª¨ë“  GPUì˜ ê²½ìš° 471.68 ì´ìƒ\n\n\n\n\n\n\n\n\n4.2.2 ê³ ê°± 2 API\nNVIDIAê°€ ì§§ì€ ë‹¨ì–´ì™€ ê°„ë‹¨í•œ ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ì‚¬ì‹¤ì ì¸ ì˜ˆìˆ í’ˆì„ ë§Œë“¤ì–´ì£¼ëŠ” ìµœì‹  ë²„ì „ì˜ AI í˜ì¸íŒ… íˆ´ GauGAN2ë¥¼ ê³µê°œí–ˆë‹¤. ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "text_to_images.html#ì˜ˆìˆ ê³¼-ì‚¬ì§„",
    "href": "text_to_images.html#ì˜ˆìˆ ê³¼-ì‚¬ì§„",
    "title": "chatGPT",
    "section": "\n3.1 ì˜ˆìˆ ê³¼ ì‚¬ì§„",
    "text": "3.1 ì˜ˆìˆ ê³¼ ì‚¬ì§„\n\n\nAbstract\nSurreal\nLandscape Photography\nPortrait Photography\nMinimalism\n\n\n\nâ€œVibrant colors,â€ â€œGeometric shapes,â€ â€œAbstract patterns,â€ â€œMovement and flow,â€ â€œTexture and layers.â€\n\n\n\n\n\n\nâ€œDreamlike,â€ â€œSurreal landscapes,â€ â€œMystical creatures,â€ â€œTwisted reality,â€ â€œSurreal still life.â€\n\n\n\n\n\n\nâ€œMajestic mountains,â€ â€œLush forests,â€ â€œGlittering lakes,â€ â€œDesert dunes,â€ â€œGolden sunsets.â€\n\n\n\n\n\n\nâ€œEmotive eyes,â€ â€œIntense gazes,â€ â€œContemplative mood,â€ â€œExpressive gestures,â€ â€œStylized posesâ€.\n\n\n\n\n\n\nâ€œSimplicity,â€ â€œClean lines,â€ â€œMinimal colors,â€ â€œNegative space,â€ â€œMinimal still life.â€"
  },
  {
    "objectID": "text_to_images.html#ì•„íŠ¸-ìŠ¤íƒ€ì¼",
    "href": "text_to_images.html#ì•„íŠ¸-ìŠ¤íƒ€ì¼",
    "title": "chatGPT",
    "section": "\n3.2 ì•„íŠ¸ ìŠ¤íƒ€ì¼",
    "text": "3.2 ì•„íŠ¸ ìŠ¤íƒ€ì¼\n\n\nimpressionism\nRealism\nPop Art\nStreet Photography\nNight Photography\n\n\n\nâ€œBlurry brushstrokes,â€ â€œPainted light,â€ â€œImpressionistic landscapes,â€ â€œPastel colors,â€ â€œImpressionistic portraits.â€\n\n\n\n\n\n\nâ€œHyper-realistic textures,â€ â€œPrecise details,â€ â€œRealistic still life,â€ â€œRealistic portraits,â€ â€œRealistic landscapes.â€\n\n\n\n\n\n\nâ€œBold colors,â€ â€œStylized portraits,â€ â€œFamous faces,â€ â€œPop art still life,â€ â€œPop art landscapes.â€\n\n\n\n\n\n\nâ€œCandid moments,â€ â€œUrban landscapes,â€ â€œStreet life,â€ â€œStories in motion,â€ â€œStreet portraits.â€\n\n\n\n\n\n\nâ€œLit cityscapes,â€ â€œStarry skies,â€ â€œMoonlit landscapes,â€ â€œNight time portraits,â€ â€œLong exposures.â€"
  },
  {
    "objectID": "text_to_images.html#ë‰´ìŠ¤-ê¸°ì‚¬",
    "href": "text_to_images.html#ë‰´ìŠ¤-ê¸°ì‚¬",
    "title": "chatGPT",
    "section": "\n5.1 ë‰´ìŠ¤ ê¸°ì‚¬",
    "text": "5.1 ë‰´ìŠ¤ ê¸°ì‚¬\nëˆ„ë¦¬í˜¸, í˜ì°¨ê²Œ ë‚ ì•„ì˜¬ëë‹¤â€¦ç¾ë„ ë‹¬ì„±í•˜ì§€ ëª»í•œ ì§„ê¸°ë¡ ë‰´ìŠ¤ê¸°ì‚¬ì— í¬í•¨ë  ì´ë¯¸ì§€ë¥¼ ì œì‘í•œë‹¤.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ì•„ë˜ ë‰´ìŠ¤ê¸°ì‚¬ëŠ” ë°±í‹±ê¸°í˜¸(`) ì„¸ê°œ ì‚¬ì´ì— ë‹´ê²¨ì ¸ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ì´ë¯¸ì§€ë¡œ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ midjourney text promptë¥¼ ì‘ì„±í•´ì„¸ìš”.\n\n\n\n\n\nëˆ„ë¦¬í˜¸, í˜ì°¨ê²Œ ë‚ ì•„ì˜¬ëë‹¤â€¦ç¾ë„ ë‹¬ì„±í•˜ì§€ ëª»í•œ ì§„ê¸°ë¡\n\nê¹€ì§„ì›ì…ë ¥ 2023. 5. 25. 18:43ìˆ˜ì • 2023. 5. 25. 21:14\n\ní•œêµ­ì´ ë…ì ê¸°ìˆ ë¡œ ê°œë°œí•œ ë¡œì¼“ â€˜ëˆ„ë¦¬í˜¸â€™ê°€ 25ì¼ ìš°ì£¼ë¡œ í–¥í–ˆë‹¤. ì‹¤ìš©ìœ„ì„±ì„ íƒ‘ì¬í•œ ë°œì‚¬ì²´ë¥¼ ì˜ì•„ ì˜¬ë¦° ì²« ì‚¬ë¡€ë‹¤. ëˆ„ë¦¬í˜¸ëŠ” ì°¨ì„¸ëŒ€ ì†Œí˜•ìœ„ì„± 2í˜¸ë¥¼ ëª©í‘œ ê¶¤ë„ì¸ ê³ ë„ 550ãì— ì •í™•í•˜ê²Œ ì˜¬ë ¤ë†¨ë‹¤. ë‚¨ê·¹ ì„¸ì¢…ê¸°ì§€ì—ì„œ ìœ„ì„± ì‹ í˜¸ë¥¼ ì •ìƒ ìˆ˜ì‹ í–ˆë‹¤. ì‘ë…„ 6ì›” ëˆ„ë¦¬í˜¸ 2ì°¨ ë°œì‚¬ì— ì´ì–´ ì´ë²ˆ 3ì°¨ ë°œì‚¬ í”„ë¡œì íŠ¸ê¹Œì§€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©´ì„œ í•œêµ­ì€ ì„¸ê³„ì ì¸ ìš°ì£¼ ê³¼í•™ ê°•êµ­ìœ¼ë¡œ ìš°ëš ì„œê²Œ ëë‹¤. ì²« ë¡œì¼“ ê°œë°œ í›„ ì—°ì† ë°œì‚¬ ì„±ê³µì€ ë¯¸êµ­ê³¼ ëŸ¬ì‹œì•„, ì¤‘êµ­ë„ ë‹¬ì„±í•˜ì§€ ëª»í•œ ì§„ê¸°ë¡ì´ë‹¤. \n\nëˆ„ë¦¬í˜¸ëŠ” ì´ë‚  ì˜¤í›„ 6ì‹œ24ë¶„ ì „ë‚¨ ê³ í¥êµ° ë‚˜ë¡œìš°ì£¼ì„¼í„° ì „ìš© ë°œì‚¬ëŒ€ì—ì„œ ìš°ì£¼ë¡œ ë‚ ì•„ì˜¬ëë‹¤. ì˜¤ì „ 11ì‹œ ë°œì‚¬ë¥¼ ê²°ì •í•œ ì´í›„ ì˜¤í›„ 5ì‹œê»˜ ì—°ë£Œì™€ ì‚°í™”ì œ ì£¼ì…ì„ ì°¨ë¡€ë¡œ ì™„ë£Œí–ˆë‹¤. ëˆ„ë¦¬í˜¸ëŠ” ì˜¤í›„ 6ì‹œ24ë¶„ ì •ê°ì— 3500ë„ ì´ˆê³ ì˜¨ ê³ ì••ê°€ìŠ¤ì˜ í˜ì„ ë°›ì•„ í•˜ëŠ˜ë¡œ í˜ì°¨ê²Œ ì†Ÿêµ¬ì³¤ë‹¤.\n\n\nëˆ„ë¦¬í˜¸ëŠ” ë°œì‚¬ ë’¤ 1ë‹¨ê³¼ ìœ„ì„±ì„ ê°ì‹¼ ë®ê°œì¸ í˜ì–´ë§, 2ë‹¨ì„ ì°¨ë¡€ë¡œ ë–¼ì–´ëƒˆë‹¤. ê³ ë„ 550ãì—ì„  ì£¼íƒ‘ì¬ ìœ„ì„±ì¸ ì°¨ì„¸ëŒ€ ì†Œí˜•ìœ„ì„± 2í˜¸ë¥¼ ë¶„ë¦¬í–ˆë‹¤. ì´í›„ 20ì´ˆ ê°„ê²©ìœ¼ë¡œ ë¶€íƒ‘ì¬ ìœ„ì„±ì¸ íë¸Œìœ„ì„±ì„ ì°¨ë¡€ë¡œ ë‚´ë³´ëƒˆë‹¤. ë‹¤ë§Œ 7ê¸°ì˜ íë¸Œìœ„ì„± ì¤‘ 1ê¸°ì— ëŒ€í•´ì„  ì‚¬ì¶œ ì„±ê³µ ì—¬ë¶€ë¥¼ íŒë‹¨ ì¤‘ì´ë‹¤.\n\nëˆ„ë¦¬í˜¸ëŠ” ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ì™€ í•œêµ­í•­ê³µìš°ì£¼ì—°êµ¬ì›ì´ 2010ë…„ë¶€í„° ê°œë°œí•œ í† ì¢… ë°œì‚¬ì²´ë‹¤. í•œêµ­ì´ ì§€ë‚œ 2ì°¨ì— ì´ì–´ 3ì°¨ ë°œì‚¬ê¹Œì§€ ì„±ê³µí•˜ë©´ì„œ 50ì—¬ ë…„ì˜ ì„¸ê³„ ìš°ì£¼ê°œë°œì‚¬(å²)ì—ì„œ ì°¾ì•„ë³´ê¸° í˜ë“  ë°œìì·¨ë¥¼ ë‚¨ê¸°ê²Œ ëë‹¤. ìœ¤ì„ì—´ ëŒ€í†µë ¹ì€ â€œë‹¬ì— ê°€ëŠ” ê²ƒì´ ì‰½ê¸° ë•Œë¬¸ì´ ì•„ë‹ˆë¼ ì–´ë µê¸° ë•Œë¬¸ì— ë„ì „í•œë‹¤â€ë©° â€œì–´ë µê¸° ë•Œë¬¸ì— ìš°ë¦¬ì˜ ë„ì „ì´ ë˜ê³  ê¿ˆì´ ë˜ëŠ” ê²ƒâ€ì´ë¼ê³  ë§í–ˆë‹¤.\n\nì´ì–´ â€œìš°ë¦¬ë‚˜ë¼ê°€ ìš°ì£¼ê°•êµ­ G7ì— ë“¤ì–´ê°€ëŠ” ì¾Œê±°ë¥¼ ì´ë¤˜ë‹¤â€ê³  ê°•ì¡°í–ˆë‹¤.\n\n ì‹¤ìš©ìœ„ì„± 8ê¸° ì‹£ê³  ìš°ì£¼ë¡œâ€¦2032ë…„ 'ë‹¬ ì°©ë¥™ì„ ' ë³´ë‚´ëŠ” ê²Œ ëª©í‘œ\n\nì‚¬ì§„=ì—°í•©ë‰´ìŠ¤\n\nì‚¬ì§„=ì—°í•©ë‰´ìŠ¤\n25ì¼ ì˜¤ì „ 5ì‹œ ì „ë‚¨ ê³ í¥ ë‚˜ë¡œìš°ì£¼ì„¼í„°. í•œêµ­í˜•ë°œì‚¬ì²´ â€˜ëˆ„ë¦¬í˜¸(KSLV-2)â€™ ì „ìš© ë°œì‚¬ëŒ€ ì£¼ë³€ì€ ì‚¬ëŒë“¤ë¡œ ë¶ì ì˜€ë‹¤. ì•¡ì²´í—¬ë¥¨ ì €ì¥íƒ±í¬ì˜ â€˜í•´ì••ë°¸ë¸Œâ€™ì™€ â€˜ì§€ìƒì¥ë¹„ì‹œìŠ¤í…œ(PLC)â€™ì„ ì œì–´í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´(SW)ì—ì„œ ë°œìƒí•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í•œêµ­í•­ê³µìš°ì£¼ì—°êµ¬ì› ì—°êµ¬ì§„ì€ ë°¤ì„ ê¼¬ë°• ìƒˆì› ë‹¤.\n\nSWë¥¼ êµ¬ì„±í•˜ëŠ” ëª…ë ¹ì–´ê°€ ìˆœì°¨ì ìœ¼ë¡œ ì „ë‹¬ë˜ì§€ ì•ŠëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ëª…ë ¹ì–´ ì‚¬ì´ì˜ ê°„ê²©ì„ ì„¸ë°€í•˜ê²Œ ìˆ˜ì •í–ˆë‹¤. ì—¬ì„¯ ì°¨ë¡€ì— ê±¸ì¹œ ë°˜ë³µ ì‹œí—˜ì„ ì‹œí–‰í•œ ê²°ê³¼ â€˜ì •ìƒâ€™ì´ë€ íŒì •ì´ ë‚´ë ¤ì¡Œë‹¤. í•´ê°€ ëœ¬ ì™¸ë‚˜ë¡œë„ ì•ë°”ë‹¤ëŠ” êµ¬ë¦„ í•œ ì  ì—†ì´ ë§‘ì•˜ë‹¤. ë¹„ì™€ ê°•í’, ë‚™ë¢°ì˜ ê°€ëŠ¥ì„±ë„ ì‘ì•˜ë‹¤. ìš°ì£¼ì •ê±°ì¥, ì¸ê³µìœ„ì„±ê³¼ ì¶©ëŒ ê°€ëŠ¥ì„±ë„ ì—†ì—ˆë‹¤. ë°œì‚¬ ì¤€ë¹„ê°€ ë‹¤ì‹œ ì‹œì‘ëë‹¤.\n\n â—‹ì‹¤ìš©Â·íë¸Œìœ„ì„± 8ê¸° ë¶„ë¦¬ ë„ì „\n\në°œì‚¬ 1ì‹œê°„ ì „. ê¸°ì²´ ì ê²€ê³¼ ì—°ë£ŒÂ·ì‚°í™”ì œ ì¶©ì „ì„ ë§ˆì¹œ ëˆ„ë¦¬í˜¸ë¥¼ ìš°ì£¼ë¡œ ì¸ë„í•˜ëŠ” ì „ìíƒ‘ì¬ì²´(ì—ë¹„ì˜¤ë‹‰ìŠ¤)ì˜ ì „ì›ì´ ì¼œì¡Œë‹¤. ë°œì‚¬ì²´ ê¸°ë¦½ ì¥ì¹˜ê°€ ì² ìˆ˜í•˜ê³  ê´€ì„±í•­ë²• ìœ ë„ì‹œìŠ¤í…œì˜ ì •ë ¬ì´ ì‹œì‘ëë‹¤.\n\në°œì‚¬ 10ë¶„ ì „ ë°œì‚¬ìë™ìš´ìš©(PLO)ì´ ì‹œì‘ëë‹¤. PLOëŠ” ë°œì‚¬ 10ë¶„ ì „ë¶€í„° ë°œì‚¬ì²´ ì´ë¥™ ì§ì „ê¹Œì§€ ë°œì‚¬ê´€ì œì‹œìŠ¤í…œì— ì˜í•´ ìë™ìœ¼ë¡œ ì´ë¤„ì§€ëŠ” ë°œì‚¬ ì¤€ë¹„ ì‘ì—…ì´ë‹¤. ê·¸ë¦¬ê³  ë°œì‚¬. ì˜¤í›„ 6ì‹œ24ë¶„ êµ‰ìŒê³¼ í•¨ê»˜ ëˆ„ë¦¬í˜¸ê°€ í˜ì°¨ê²Œ ì†Ÿêµ¬ì³¤ë‹¤. ì—°ì†Œê°€ìŠ¤ ì˜¨ë„ëŠ” ì„­ì”¨ 3500ë„. í¬ìŠ¤ì½”ì˜ ì‡³ë¬¼ì„ ë…¹ì´ëŠ” ìš©ê´‘ë¡œ ì˜¨ë„(1500ë„)ì˜ ë‘ ë°° ì´ìƒì´ë‹¤. ì••ë ¥ë„ ëŒ€ê¸°ì••ì˜ 60ë°°ê¹Œì§€ ì¹˜ì†Ÿì•˜ë‹¤. ë°œì‚¬ëŒ€ë¥¼ ì‹íˆê¸° ìœ„í•´ ì´ˆë‹¹ 1.8tì˜ ëƒ‰ê°ìˆ˜ê°€ ì‰´ ìƒˆ ì—†ì´ ìŸì•„ì¡Œë‹¤.\n\në°œì‚¬ 125ì´ˆ ë’¤ ê³ ë„ 64.5ã. ëˆ„ë¦¬í˜¸ëŠ” 1ë‹¨ì„ ë¶„ë¦¬í•œë‹¤. ì´ì–´ ìœ„ì„±ì„ ê°ì‹¼ ë®ê°œì¸ í˜ì–´ë§ê³¼ 2ë‹¨ì´ ì°¨ë¡€ë¡œ ë–¨ì–´ì ¸ ë‚˜ê°„ë‹¤. ëˆ„ë¦¬í˜¸ê°€ ì ë„ë¥¼ ì§€ë‚˜ë©´ ë‚¨íƒœí‰ì–‘ íŒ”ë¼ìš° ì¶”ì ì†Œì—ì„œ ëˆ„ë¦¬í˜¸ì˜ ë¹„í–‰ ê¶¤ì ê³¼ ë™ì‘ ìƒíƒœë¥¼ í™•ì¸í•œë‹¤.\n\në°œì‚¬ 783ì´ˆ ë’¤ ê³ ë„ 550ãì— ë„ë‹¬í•˜ë©´ ì£¼ íƒ‘ì¬ìœ„ì„±ì¸ ì°¨ì„¸ëŒ€ ì†Œí˜•ìœ„ì„± 2í˜¸ê°€ ë¶„ë¦¬ëœë‹¤. ì°¨ì„¸ëŒ€ ì†Œí˜•ìœ„ì„± 2í˜¸ëŠ” ì˜ìƒ ë ˆì´ë”(SAR)ë¥¼ íƒ‘ì¬í–ˆë‹¤. í•´ìƒë„ 5m, ê´€ì¸¡ í­ 40ãì˜ ë§ˆì´í¬ë¡œíŒŒë¡œ ì§€êµ¬ë¥¼ ê´€ì¸¡í•œë‹¤. ê´‘í•™ì¹´ë©”ë¼ì™€ ë‹¬ë¦¬ ë¹›ê³¼ êµ¬ë¦„ì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ”ë‹¤.\n\nì´í›„ 20ì´ˆ ê°„ê²©ìœ¼ë¡œ ë²¤ì²˜ê¸°ì—… ì ¸ìŠ¤í…ê³¼ ë£¨ë¯¸ë¥´, ì¹´ì´ë¡œìŠ¤í˜ì´ìŠ¤ê°€ ì œì‘í•œ íë¸Œìœ„ì„± 3ê¸°ê°€ ì°¨ë¡€ë¡œ ë¶„ë¦¬ëœë‹¤. ê°ê° ìš°ì£¼ ë°©ì‚¬ì„ ì„ ê²€ì¶œí•˜ê³  ê´‘í•™ì¹´ë©”ë¼ ì„±ëŠ¥ì„ ê²€ì¦í•œë‹¤. ìš°ì£¼ì“°ë ˆê¸° ê²½ê° ê¸°ìˆ ë„ ì‹¤ì¦í•œë‹¤. ë§ˆì§€ë§‰ì—ëŠ” ì²œë¬¸ì—°ì—ì„œ ê°œë°œí•œ ìš°ì£¼ê¸°ìƒê´€ì¸¡ êµ°ì§‘(ç¾¤é›†)ìœ„ì„± â€˜ë„ìš”ìƒ›â€™ 4ê¸°ê°€ ë¶„ë¦¬ëœë‹¤. ë„ìš”ìƒ›ì€ ì¤‘ëŸ‰ 10ã ì´í•˜ ë‚˜ë…¸ê¸‰ ìœ„ì„±ìœ¼ë¡œëŠ” ìµœì´ˆë¡œ í¸ëŒ€ ë¹„í–‰ì„ ì‹œë„í•˜ë©° í”Œë¼ì¦ˆë§ˆ ë“± ìš°ì£¼ ë‚ ì”¨ì˜ ì‹œê³µê°„ì  ë³€í™”ë¥¼ ê´€ì¸¡í•˜ëŠ” ì„ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤. ë°œì‚¬ 1138ì´ˆê°€ ì§€ë‚˜ë©´ ì„ë¬´ë¥¼ ì™„ìˆ˜í•œ ëˆ„ë¦¬í˜¸ê°€ ë¹„í–‰ì„ ì¢…ë£Œí•œë‹¤.\n\n â—‹ë°˜ë³µ ë°œì‚¬ í†µí•´ ì‹ ë¢°ë„ ë†’ì¸ë‹¤\n\nì „ë‚  ëˆ„ë¦¬í˜¸ 3ì°¨ ë°œì‚¬ëŠ” ì˜ˆì • ì‹œê°„ì„ 2ì‹œê°„ 14ë¶„ ì•ë‘ê³  ì—°ê¸°ëë‹¤. ì´ì²˜ëŸ¼ ë°œì‚¬ë¥¼ ëˆˆì•ì— ë‘ê³  ê¸°ìˆ ì  ë¬¸ì œë¡œ ì—°ê¸°í•˜ëŠ” ì¼ì€ ë¡œì¼“ ê°œë°œ ê³¼ì •ì—ì„œ ì¢…ì¢… ìˆëŠ” ì¼ì´ë‹¤. ì‘ë…„ 6ì›” ëˆ„ë¦¬í˜¸ 2ì°¨ ë°œì‚¬ ë•Œë„ ê¸°ë¦½ ìƒíƒœì—ì„œ ì ê²€ ì¤‘ ë¬¸ì œê°€ ë°œê²¬ë¼ ì¡°ë¦½ë™ìœ¼ë¡œ ë˜ëŒì•„ê°”ë‹¤. ì•¡ì²´í—¬ë¥¨ íƒ±í¬ ë‚´ë¶€ì˜ ë ˆë²¨ ì„¼ì„œê°€ ë¹„ì •ìƒì ì¸ ìˆ˜ì¹˜ë¥¼ ë‚˜íƒ€ëƒˆê¸° ë•Œë¬¸ì´ë‹¤. 2009ë…„ 8ì›” â€˜ë‚˜ë¡œí˜¸(KSLV-1)â€™ 1ì°¨ ë°œì‚¬ ë‹¹ì‹œì—ë„ ì••ë ¥ ì¸¡ì • ê´€ë ¨ SW ì˜¤ë¥˜ë¡œ ì´ë¥™ 7ë¶„56ì´ˆë¥¼ ì•ë‘ê³  ë°œì‚¬ê°€ ì¤‘ë‹¨ëë‹¤. ë‚˜ë¡œí˜¸ 3ì°¨ ë°œì‚¬ë¥¼ ì‹œë„í–ˆë˜ 2012ë…„ 11ì›”ì—ë„ ìµœì¢… ë°œì‚¬ ì‹œê°„ ë°œí‘œ ì „ ì—°ë£Œë¥¼ ì£¼ì…í•˜ëŠ” ì—°ê²° ë¶€ìœ„ê°€ ìƒˆëŠ” ë¬¸ì œê°€ ë°œìƒí•´ ë°œì‚¬ê°€ ë¯¸ë¤„ì¡Œë‹¤.\n\nìš°ì£¼ ë°œì‚¬ì²´ëŠ” ì²¨ë‹¨ ê¸°ìˆ ì˜ ì§‘ì•½ì²´ë‹¤. ë°˜ë³µ ë°œì‚¬ ìš´ìš©ì„ í†µí•´ ë°œì‚¬ ê³¼ì •ì„ ìµœì í™”Â·ì•ˆì •í™”í•˜ê³  ë°œì‚¬ì²´ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ê²ƒì´ í•„ìˆ˜ë‹¤. ì •ë¶€ëŠ” 2027ë…„ê¹Œì§€ ë„¤ ì°¨ë¡€ì— ê±¸ì¹œ ì¶”ê°€ ë°œì‚¬ë¥¼ í†µí•´ í•œêµ­í˜•ë°œì‚¬ì²´ ëˆ„ë¦¬í˜¸ì˜ ì‹ ë¢°ë„ë¥¼ ê²€ì¦í•˜ê³  ì²´ê³„ì¢…í•©ê¸°ì—… í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤ ê¸°ìˆ ì„ ì´ì „í•œë‹¤. ì°¨ì„¸ëŒ€ ì¤‘í˜•ìœ„ì„± 3í˜¸ì™€ ì´ˆì†Œí˜•ìœ„ì„± 2~11í˜¸ ë“±ì´ ë‹¤ìŒ ëˆ„ë¦¬í˜¸ì— íƒ‘ì¬ë  ì˜ˆì •ì´ë‹¤.\n\nëˆ„ë¦¬í˜¸ ì„±ëŠ¥ì„ ê°œëŸ‰í•œ ì°¨ì„¸ëŒ€ ë°œì‚¬ì²´ ê°œë°œì‚¬ì—…ë„ ì§„í–‰í•œë‹¤. ì°¨ì„¸ëŒ€ ë°œì‚¬ì²´ëŠ” 1ë‹¨ 100tê¸‰ ì´ìƒ ì—”ì§„ 5ê¸°, 2ë‹¨ 10tê¸‰ ì´ìƒ ì—”ì§„ 2ê¸°ë¡œ êµ¬ì„±ëœ 2ë‹¨í˜• ë°œì‚¬ì²´ë¡œ ê°œë°œë  ì˜ˆì •ì´ë‹¤. 2030ë…„ë¶€í„° ì„¸ ì°¨ë¡€ ë°˜ë³µ ë°œì‚¬ë¥¼ í†µí•´ ì‹ ë¢°ë„ë¥¼ ê²€ì¦í•œë‹¤.\n\n2032ë…„ ë‹¬ ì°©ë¥™ì„ ì„ ë³´ë‚´ëŠ” ê²ƒì´ ìµœì¢… ëª©í‘œë‹¤.\n\nê³ í¥(ë‚˜ë¡œìš°ì£¼ì„¼í„°)=ê¹€ì§„ì› ê¸°ì jin1@hankyung.com\n\në„¤, í•œêµ­í˜•ë°œì‚¬ì²´ ëˆ„ë¦¬í˜¸ ë°œì‚¬ ì„±ê³µì— ëŒ€í•œ Midjourney í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\ní•œêµ­í˜•ë°œì‚¬ì²´ ëˆ„ë¦¬í˜¸ê°€ ìš°ì£¼ë¡œ ë°œì‚¬ë˜ëŠ” ëª¨ìŠµì„ ë‚˜íƒ€ë‚´ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\n\ní•œêµ­í˜•ë°œì‚¬ì²´ ëˆ„ë¦¬í˜¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë°œì‚¬ë˜ì–´ ëª©í‘œ ê¶¤ë„ì— ì§„ì…í•˜ëŠ” ëª¨ìŠµì„ ë‚˜íƒ€ë‚´ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\ní•œêµ­í˜•ë°œì‚¬ì²´ ëˆ„ë¦¬í˜¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë°œì‚¬ë˜ì–´ ìœ„ì„±ì„ ê¶¤ë„ì— ì˜¬ë¦¬ëŠ” ëª¨ìŠµì„ ë‚˜íƒ€ë‚´ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\n\nì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­í˜•ë°œì‚¬ì²´ ëˆ„ë¦¬í˜¸ ë°œì‚¬ ì„±ê³µì— ëŒ€í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "text_to_images.html#ì´ë¯¸ì§€-ìƒì„±ì",
    "href": "text_to_images.html#ì´ë¯¸ì§€-ìƒì„±ì",
    "title": "chatGPT",
    "section": "\n5.2 ì´ë¯¸ì§€ ìƒì„±ì",
    "text": "5.2 ì´ë¯¸ì§€ ìƒì„±ì\n\n\nìŠ¤íƒ€ì¼ ì ìš© ì „\nìŠ¤íƒ€ì¼ ì ìš© í›„\ní•œì¥\n\n\n\nSouth Korean launch vehicle Nuri successfully launches and enters its target orbit\n\n\n\n\n\n\nSouth Korean launch vehicle Nuri successfully launches and enters its target orbit, cinematic light, extreme detail, panoramic, Craig Mullins\n\n\n\n\n\n\nSouth Korean launch vehicle Nuri successfully launches and enters its target orbit, Max Ernst, volumetric light"
  },
  {
    "objectID": "math.html#latex-ì„¤ì¹˜",
    "href": "math.html#latex-ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "\n2.1 LaTeX ì„¤ì¹˜",
    "text": "2.1 LaTeX ì„¤ì¹˜\ntinytex::install_tinytex() ëª…ë ¹ì–´ë¡œ $\\LaTeX$ì„ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œtinytex::install_tinytex()\n# ì„¤ì¹˜ìœ„ì¹˜ í™•ì¸\ntinytex::tinytex_root()"
  },
  {
    "objectID": "math.html#í—¬ë¡œì›”ë“œ",
    "href": "math.html#í—¬ë¡œì›”ë“œ",
    "title": "chatGPT",
    "section": "\n2.2 í—¬ë¡œì›”ë“œ",
    "text": "2.2 í—¬ë¡œì›”ë“œ\nì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ ë¬¸ì„œ(PDF)ë¥¼ ì‘ì„±í•˜ëŠ” ì‚¬ë¡€ë¥¼ êµ¬í˜„í•´ë³´ì. í•œê¸€ì„ PDF ë¬¸ì„œë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì€ ë‹¤ë¥¸ ë¬¸ì œë¡œ í•œê¸€ì„ PDFë¡œ í‘œí˜„í•  ê²½ìš° ê¸€ê¼´ì„ ë¹„ë¡¯í•œ í•œê¸€ë¬¸ì„œ ê³ ìœ í•œ íŠ¹ì„±ì„ ë°˜ì˜í•  ê²ƒì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ìì„¸í•œ ì‚¬í•­ì€ ë°ì´í„° ê³¼í•™ ê¸€ì“°ê¸°ë¥¼ ì°¸ê³ í•œë‹¤.\n\nì½”ë“œwriteLines(c(\n  '\\\\documentclass{article}',\n  '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n), 'pdf/test_eng.tex')\n\ntinytex::pdflatex('pdf/test_eng.tex')\n#&gt; [1] \"pdf/test_eng.pdf\""
  },
  {
    "objectID": "math.html#mathpix-íŒ¨í‚¤ì§€",
    "href": "math.html#mathpix-íŒ¨í‚¤ì§€",
    "title": "chatGPT",
    "section": "\n2.3 mathpix íŒ¨í‚¤ì§€",
    "text": "2.3 mathpix íŒ¨í‚¤ì§€\nOCR ì‘ì—…ì„ ìœ„í•´ì„œ ê³¼ê±° tesseractì´ ë§ì´ ì‚¬ìš©ë˜ì—ˆìœ¼ë‚˜ ìµœê·¼ì—ëŠ” AI ê¸°ìˆ ì„ ì ìš©í•œ ë‹¤ì–‘í•œ OCR ì‹œìŠ¤í…œì´ ì†Œê°œë˜ê³  ìˆë‹¤. ìˆ˜ì‹ì„ ê¸°ê³„ê°€ ì¸ì‹í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì¸ì‹í•˜ëŠ” ê²ƒì€ ë‹¤ë¥¸ ë¬¸ì œë¡œ ë‹¤ì–‘í•œ ë„êµ¬ê°€ ì†Œê°œë˜ê³  ìˆìœ¼ë‚˜ mathpixë„ ì„±ëŠ¥ì´ ì¢‹ì€ ë„êµ¬ì¤‘ í•˜ë‚˜ë¡œ ê³¼í•™ê¸°ìˆ ë¶„ì•¼ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆë‹¤.\n\n\n\nì½”ë“œlibrary(mathpix)\nmathpix(\"images//integral.jpg\")\n\n\n\n\\[\n\\int \\frac { 4 x } { \\sqrt { x ^ { 2 } + 1 } } d x\n\\]"
  },
  {
    "objectID": "math.html#pdf-.png",
    "href": "math.html#pdf-.png",
    "title": "chatGPT",
    "section": "\n2.4 pdf â†’ .png\n",
    "text": "2.4 pdf â†’ .png\n\n2023ë…„ ìˆ˜ëŠ¥ PDF ìˆ˜í•™ë¬¸ì œ íŒŒì¼ì„ ì´ë¯¸ì§€(.png) íŒŒì¼ë¡œ ë³€í™˜ì‹œí‚¤ì.\n\n\n\n\n\n\n\n\nì½”ë“œlibrary(pdftools)\n\npdf_convert(\"data/2êµì‹œ_ìˆ˜í•™ì˜ì—­_ë¬¸ì œì§€.pdf\", format = \"png\", pages=1, filenames = \"pdf/math_01.png\")\n\n\n\nì½”ë“œmath_01_png &lt;- mathpix::mathpix(\"pdf/math_01.png\", insert = FALSE)\n\n\n\\[\ng ( x ) = x ^ { 2 } f ( x )\n\\]\n\nì½”ë“œmath_01_png\n#&gt; [1] \"$$\\n g ( x ) = x ^ { 2 } f ( x ) \\n$$\""
  },
  {
    "objectID": "biz_number_API.html",
    "href": "biz_number_API.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì¶œì²˜: ì‚¼ì£¼ì „ì ì›¹ì‚¬ì´íŠ¸\nì‚¬ì—…ì ë“±ë¡ì¦ì€ ì‚¬ì—…ì„ ì˜ìœ„í•˜ëŠ” ê°œì¸ì´ë‚˜ ë²•ì¸ì´ ìì‹ ì˜ ì‚¬ì—…ì„ ì •ë¶€ì— ê³µì‹ì ìœ¼ë¡œ ë“±ë¡í•œ ì¦ëª…ì„œë¡œ êµ­ì„¸ì²­ì´ ì´ë¥¼ ê´€ë¦¬í•˜ë©°, ì‚¬ì—…ì ë“±ë¡ì„ í•˜ë©´ ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ë¥¼ ë¶€ì—¬ë°›ê²Œ ë˜ê³  ì‚¬ì—…ì ë“±ë¡ì¦ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ê°€ í¬í•¨ëœë‹¤.\n\nì‚¬ì—…ì ë“±ë¡ ë²ˆí˜¸: ì‚¬ì—…ìì˜ ê³ ìœ  ì‹ë³„ ë²ˆí˜¸ë¡œ ë‹¤ë¥¸ ì‚¬ì—…ìì™€ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ê²ƒì´ë©°, ì‚¬ì—… ê±°ë˜ ì‹œì— ì‚¬ìš©ëœë‹¤.\nì‚¬ì—…ìì˜ ì´ë¦„: ê°œì¸ ì‚¬ì—…ìì˜ ê²½ìš° ê°œì¸ì˜ ì´ë¦„, ë²•ì¸ì˜ ê²½ìš° ë²•ì¸ì˜ ì´ë¦„ì´ í‘œê¸°ëœë‹¤.\nì‚¬ì—…ì˜ ì¢…ë¥˜: ì‚¬ì—…ìê°€ ì˜ìœ„í•˜ëŠ” ì‚¬ì—…ì˜ ì¢…ë¥˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.\nì‚¬ì—…ì¥ì˜ ìœ„ì¹˜: ì‚¬ì—…ì´ ì§„í–‰ë˜ëŠ” ì£¼ìš” ì¥ì†Œë¥¼ ë‚˜íƒ€ë‚¸ë‹¤."
  },
  {
    "objectID": "biz_number_API.html#r-ì½”ë“œ-ë³€í™˜",
    "href": "biz_number_API.html#r-ì½”ë“œ-ë³€í™˜",
    "title": "chatGPT",
    "section": "\n4.1 R ì½”ë“œ ë³€í™˜",
    "text": "4.1 R ì½”ë“œ ë³€í™˜\n\n\ní”„ë¡¬í”„íŠ¸\nì¶œë ¥ê²°ê³¼\në³´ì™„ì‘ì—…\n\n\n\në‹¤ìŒ `curl` ì½”ë“œë¥¼ R ì½”ë“œë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.\n\ncurl -X 'POST' \\\n  'https://api.odcloud.kr/api/nts-businessman/v1/status?serviceKey=GQMNLxxxxxxxxxxxxxxxxxxxxxx' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: GQMNLxxxxxxxxxxxxxxxxxxxxxx' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"b_no\": [\n    \"1320557431\"\n  ]\n}'\n\n\ncurl ëª…ë ¹ì€ HTTP í”„ë¡œí† ì½œì„ ì‚¬ìš©í•˜ì—¬ ì›¹ ì„œë²„ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ëª…ë ¹í–‰ ë„êµ¬ì…ë‹ˆë‹¤. ì´ ëª…ë ¹ì„ R ì½”ë“œë¡œ ë³€í™˜í•˜ë ¤ë©´ httr íŒ¨í‚¤ì§€ì˜ POST í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\nì•„ë˜ëŠ” ì£¼ì–´ì§„ curl ëª…ë ¹ì„ R ì½”ë“œë¡œ ë³€í™˜í•œ ì˜ˆì…ë‹ˆë‹¤.\n```{r}\n\n# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\nlibrary(httr)\n\n# API endpointì™€ í•„ìš”í•œ í—¤ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\nurl &lt;- \"https://api.odcloud.kr/api/nts-businessman/v1/status?serviceKey=GQMNLxxxxxxxxxxxxxxxxxxxxxx\"\nheaders &lt;- c(\n  'accept' = 'application/json',\n  'Authorization' = 'GQMNLxxxxxxxxxxxxxxxxxxxxxx',\n  'Content-Type' = 'application/json'\n)\n\n# ìš”ì²­ ë³¸ë¬¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.\nbody &lt;- list(\n  \"b_no\" = c(\"1320557431\")\n)\n\n# POST ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\nresponse &lt;- POST(url, add_headers(headers), body = body, encode = \"json\")\n\n# ì‘ë‹µì„ í™•ì¸í•©ë‹ˆë‹¤.\ncontent(response)\n\n```\n\n\nusethis::edit_r_environ() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ NTS_API_KEYë¥¼ .Renviron íŒŒì¼ì— ìˆ¨ê¸´ë‹¤. ì´ë¥¼ í†µí•´ ë³´ì•ˆì´ ê°•í™”ë˜ì§€ë§Œ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆê²Œ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆë‹¤.\n\nì½”ë“œlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(httr)\n\nurl &lt;- glue::glue(\"https://api.odcloud.kr/api/nts-businessman/v1/status\",\n                  \"?serviceKey={Sys.getenv('NTS_API_KEY')}\")\n\nheaders &lt;- c(\n  'accept' = 'application/json',\n  'Content-Type' = 'application/json'\n)\n\nbody &lt;- list(\n  \"b_no\" = list(\"1320557431\")\n)\n\nresponse &lt;- POST(url, add_headers(.headers=headers), body=body, encode=\"json\")\n\n# print the response\nresult &lt;- content(response)\n\nresult_tbl &lt;- result$data %&gt;% data.frame()\n\nresult_tbl\n#&gt;         b_no      b_stt b_stt_cd              tax_type tax_type_cd end_dt\n#&gt; 1 1320557431 ê³„ì†ì‚¬ì—…ì       01 ë¶€ê°€ê°€ì¹˜ì„¸ ì¼ë°˜ê³¼ì„¸ì          01       \n#&gt;   utcc_yn tax_type_change_dt invoice_apply_dt rbf_tax_type rbf_tax_type_cd\n#&gt; 1       N                                         í•´ë‹¹ì—†ìŒ              99"
  },
  {
    "objectID": "biz_number_API.html#í•¨ìˆ˜ì‘ì„±",
    "href": "biz_number_API.html#í•¨ìˆ˜ì‘ì„±",
    "title": "chatGPT",
    "section": "\n5.1 í•¨ìˆ˜ì‘ì„±",
    "text": "5.1 í•¨ìˆ˜ì‘ì„±\nget_status í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì„œ ì‚¬ì—…ìë²ˆí˜¸ë¥¼ ë„˜ê¸°ë©´ êµ­ì„¸ì²­ APIë¥¼ í†µí•´ ì‚¬ì—…ì ì§„ìœ„ì—¬ë¶€ì™€ í•¨ê»˜ ê³¼ì„¸ìœ í˜•ì •ë³´ë„ í™•ì¸ê°€ëŠ¥í•˜ë„ë¡ ê¸°ëŠ¥ì„ ì¶”ê°€í•œë‹¤.\n\nì½”ë“œget_status &lt;- function(biz_number = \"1320557431\") {\n    url &lt;- glue::glue(\"https://api.odcloud.kr/api/nts-businessman/v1/status\",\n                    \"?serviceKey={Sys.getenv('NTS_API_KEY')}\")\n  \n  headers &lt;- c(\n    'accept' = 'application/json',\n    'Content-Type' = 'application/json'\n  )\n  \n  body &lt;- list(\n    \"b_no\" = list(biz_number)\n  )\n  \n  response &lt;- POST(url, add_headers(.headers=headers), body=body, encode=\"json\")\n  \n  # print the response\n  result &lt;- content(response)\n\n  result_tbl &lt;- result$data %&gt;% data.frame()\n\n  return(result_tbl)\n}\n\nget_status(\"1320557431\")\n#&gt;         b_no      b_stt b_stt_cd              tax_type tax_type_cd end_dt\n#&gt; 1 1320557431 ê³„ì†ì‚¬ì—…ì       01 ë¶€ê°€ê°€ì¹˜ì„¸ ì¼ë°˜ê³¼ì„¸ì          01       \n#&gt;   utcc_yn tax_type_change_dt invoice_apply_dt rbf_tax_type rbf_tax_type_cd\n#&gt; 1       N                                         í•´ë‹¹ì—†ìŒ              99"
  },
  {
    "objectID": "biz_number_API.html#ì—…ì²´ì •ë³´-ëŒ€ì¥",
    "href": "biz_number_API.html#ì—…ì²´ì •ë³´-ëŒ€ì¥",
    "title": "chatGPT",
    "section": "\n5.2 ì—…ì²´ì •ë³´ ëŒ€ì¥",
    "text": "5.2 ì—…ì²´ì •ë³´ ëŒ€ì¥\nì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ë¥¼ í¬í•¨í•œ ì—…ì²´ì •ë³´ê°€ ë‹´ê¸´ ì—‘ì…€íŒŒì¼ì„ ì¤€ë¹„í•˜ì—¬ êµ­ì„¸ì²­ APIì— ë„˜ê²¨ ì‚¬ì—…ìë“±ë¡ì§„ìœ„ ë° ì‚¬ì—…ì ë“±ë¡ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì—‘ì…€íŒŒì¼ ì „ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.\n```{r}\nlibrary(readxl)\n\nmst_raw &lt;- read_excel(\"data/xxxxì—°êµ¬ê°œë°œíŠ¹êµ¬_ê¸°ì—…í˜„í™©_ë°ì´í„° ìš”ì²­ì‚¬í•­_230618.xlsx\", sheet = \"xxxxì—°êµ¬ë‹¨ì§€ ì…ì£¼ê¸°ì—…\", skip = 1)\n\nmst_tbl &lt;- mst_raw %&gt;% \n  mutate(ì‚¬ì—…ìë²ˆí˜¸ = str_remove_all(ì‚¬ì—…ìë²ˆí˜¸, \"-\") %&gt;% str_squish(.))\n```\ní•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë° purrr íŒ¨í‚¤ì§€ map() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ê²°ê³¼ê°’ì„ ì‚¬ì—…ìë“±ë¡ì¦ ë‹¨ìœ„ë¡œ ë°˜í™˜ë°›ê³  ê·¸ ê²°ê³¼ë¥¼ í‘œë¡œ ì •ë¦¬í•œë‹¤.\n```{r}\nmst_status &lt;- mst_tbl %&gt;% \n  mutate(result = map(ì‚¬ì—…ìë²ˆí˜¸, get_status)) %&gt;% \n  select(íšŒì‚¬ëª…, ì‚¬ì—…ìë²ˆí˜¸, result) %&gt;% \n  mutate(ìƒíƒœ = map_chr(result, \"b_stt\"),\n         ê³¼ì„¸ìœ í˜• = map_chr(result, \"tax_type\")) \n\nmst_status %&gt;% \n  select(íšŒì‚¬ëª…, ì‚¬ì—…ìë²ˆí˜¸, ìƒíƒœ, ê³¼ì„¸ìœ í˜•) %&gt;% \n  ## ë¶„ì„ê²°ê³¼ í‘œë¡œ ì •ë¦¬\n  count(ìƒíƒœ, name=\"ì—…ì²´ìˆ˜\") %&gt;% \n  janitor::adorn_totals(name = \"í•©ê³„\")\n```\n       ìƒíƒœ ì—…ì²´ìˆ˜\n                18\n ê³„ì†ì‚¬ì—…ì    210\n     íì—…ì      1\n       í•©ê³„    229"
  },
  {
    "objectID": "three_paradigm.html",
    "href": "three_paradigm.html",
    "title": "ì±—GPT",
    "section": "",
    "text": "1 ì±—GPT ì‹œëŒ€ ë°ì´í„° ë¶„ì„\n\nOpenAI ì±—GPT Code Interpreter í”ŒëŸ¬ê·¸ì¸\n\n\në…¸í„°ë¸”(Notable): EDA & ETL Made Easy (SQL, Python, & R)\nì˜¤í”ˆì†ŒìŠ¤ GPT-Code UI\nR\n\n\nRTutor.ai, GitHub ì €ì¥ì†Œ\n\nhttps://chatlize.ai/\n\n\n\n2 Code Interpreter\n\n\n1ë‹¨ê³„\n2ë‹¨ê³„\n3ë‹¨ê³„\n4ë‹¨ê³„\n5ë‹¨ê³„ (ë°ì´í„°+í”„ë¡¬í”„íŠ¸)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 Notable.ai\n\n4 ì‹¬ìŠ¨ íŒ¨ëŸ¬ë…ìŠ¤\n\nì±—GPT Code Interpreter : ì±„íŒ… ì´ë ¥\n\nJupyter Notebook ë‹¤ìš´ë¡œë“œ: penguin_analysis.ipynb\n\n\npenguin_analysis.ipynb â†’ penguin_analysis.qmd\n\nëª…ë ¹ì–´: $ quarto convert penguin_analysis.ipynb\n\n\n\nì¿¼í†  ì»´íŒŒì¼: ë°”ë¡œê°€ê¸°\n\n\n`"
  },
  {
    "objectID": "penguin_analysis.html",
    "href": "penguin_analysis.html",
    "title": "Analysis of Penguin Data",
    "section": "",
    "text": "This notebook presents an analysis of a dataset containing measurements of penguins. The goal is to investigate the existence of Simpsonâ€™s Paradox in the data.\nSimpsonâ€™s Paradox is a phenomenon in probability and statistics, in which a trend appears in different groups of data but disappears or reverses when these groups are combined."
  },
  {
    "objectID": "penguin_analysis.html#import-necessary-libraries",
    "href": "penguin_analysis.html#import-necessary-libraries",
    "title": "Analysis of Penguin Data",
    "section": "Import Necessary Libraries",
    "text": "Import Necessary Libraries\n\n\nì½”ë“œ\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "penguin_analysis.html#load-the-dataset",
    "href": "penguin_analysis.html#load-the-dataset",
    "title": "Analysis of Penguin Data",
    "section": "Load the Dataset",
    "text": "Load the Dataset\n\n\nì½”ë“œ\n# Load the dataset\ndf = pd.read_csv('data/penguins.csv')"
  },
  {
    "objectID": "penguin_analysis.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "href": "penguin_analysis.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "title": "Analysis of Penguin Data",
    "section": "Check Correlations Within Each Species for Culmen Length and Depth",
    "text": "Check Correlations Within Each Species for Culmen Length and Depth\n\n\nì½”ë“œ\n# Check correlations within each species for culmen_length_mm and culmen_depth_mm\nspecies_list = df['species'].unique()\nfor species in species_list:\n    print(f\"Correlation within {species} species:\")\n    print(df[df['species'] == species][['bill_length_mm', 'bill_depth_mm']].corr())\n    print(\"\\n\")\n\n\nCorrelation within Adelie species:\n                bill_length_mm  bill_depth_mm\nbill_length_mm        1.000000       0.391492\nbill_depth_mm         0.391492       1.000000\n\n\nCorrelation within Gentoo species:\n                bill_length_mm  bill_depth_mm\nbill_length_mm        1.000000       0.643384\nbill_depth_mm         0.643384       1.000000\n\n\nCorrelation within Chinstrap species:\n                bill_length_mm  bill_depth_mm\nbill_length_mm        1.000000       0.653536\nbill_depth_mm         0.653536       1.000000"
  },
  {
    "objectID": "penguin_analysis.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "href": "penguin_analysis.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "title": "Analysis of Penguin Data",
    "section": "Calculate the Overall Correlation Between Culmen Length and Depth",
    "text": "Calculate the Overall Correlation Between Culmen Length and Depth\n\n\nì½”ë“œ\n# Calculate the overall correlation between bill_length_mm and bill_depth_mm\noverall_corr = df[['bill_length_mm', 'bill_depth_mm']].corr().iloc[0, 1]\noverall_corr\n\n\n-0.2350528703555336"
  },
  {
    "objectID": "penguin_analysis.html#create-scatter-plot",
    "href": "penguin_analysis.html#create-scatter-plot",
    "title": "Analysis of Penguin Data",
    "section": "Create Scatter Plot",
    "text": "Create Scatter Plot\n\n\nì½”ë“œ\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Overall regression line\nsns.regplot(x='bill_length_mm', y='bill_depth_mm', data=df, scatter=False, \n            line_kws={'color': 'black', 'label': \"Overall regression line\"})\n\n# Loop through each species\nfor species in species_list:\n    species_data = df[df['species'] == species]\n    sns.scatterplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, label=species)\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, scatter=False, \n                line_kws={'label': f\"{species} regression line\"})\n\nplt.title('Bill Depth vs Bill Length')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\n\n# Add legend\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "penguin_analysis.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "href": "penguin_analysis.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "title": "Analysis of Penguin Data",
    "section": "Create Separate Scatter Plots with Regression Lines for Each Species",
    "text": "Create Separate Scatter Plots with Regression Lines for Each Species\n\n\nì½”ë“œ\n# Create a figure and axis\nfig, axs = plt.subplots(3, 1, figsize=(10, 20))\n\n# Loop through each species\nfor ax, species in zip(axs, species_list):\n    species_data = df[df['species'] == species]\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, ax=ax, \n                line_kws={'label': f\"{species} regression line\"})\n    ax.set_title(f'{species} Penguins')\n    ax.set_xlabel('Bill Length (mm)')\n    ax.set_ylabel('Bill Depth (mm)')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "openAI_GPT.html#gpt-4",
    "href": "openAI_GPT.html#gpt-4",
    "title": "chatGPT",
    "section": "",
    "text": "GPT-4â€™s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4ëŠ” GPT-3ë³´ë‹¤ 10ë°° ë§ì€ 1ì¡° 8ì²œì–µ ê°œì˜ íŒŒë¼ë¯¸í„°, 120ê°œ ê³„ì¸µì„ ê°–ëŠ” ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤. OpenAIëŠ” 16ê°œ ì „ë¬¸ê°€(MoE, Mixture of Experts)ì™€ 1,100ì–µ ê°œì˜ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  íŒŒë¼ë¯¸í„°ë¥¼ ê°–ëŠ” ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸ë¡œ êµ¬í˜„ë˜ì—ˆìœ¼ë©°, 13ì¡° ê°œì˜ í† í°ì´ í¬í•¨ëœ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆë‹¤. í›ˆë ¨ ë¹„ìš©ì€ 3,200 ~ 6,300ë§Œ ë‹¬ëŸ¬ë¡œ GPT-4ëŠ” ì´ì „ ë²„ì „ë³´ë‹¤ ì¶”ë¡  ë¹„ìš©ì´ ì•½ 3ë°° ë” ë†’ì§€ë§Œ, ë¶„ì‚° ë°ì´í„°ì„¼í„°ì—ì„œ 128ê°œ GPU í´ëŸ¬ìŠ¤í„° ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” ì¶”ë¡  ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤.\n\n\nThe Ship of Theseus\n\nOpenAIì˜ ì „ëµì€ í…Œì„¸ìš°ìŠ¤ì˜ ë°°(Theseusâ€™s Ship) ì™€ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#ì¸í„°í˜ì´ìŠ¤",
    "href": "openAI_GPT.html#ì¸í„°í˜ì´ìŠ¤",
    "title": "chatGPT",
    "section": "\n3.1 ì¸í„°í˜ì´ìŠ¤",
    "text": "3.1 ì¸í„°í˜ì´ìŠ¤\nOpenAI APIëŠ” OpenAIì—ì„œ ê°œë°œí•œ GPT-3, GPT-4 ëª¨ë¸ì„ í†µí•´ AI ê¸°ëŠ¥ì„ ê°œë°œí•˜ê³  ìˆëŠ” ë‹¤ì–‘í•œ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ì— ë‹´ì•„ë‚´ëŠ” ê³¼ì •ì´ë‹¤. ì œí’ˆê³¼ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ë©´ì„œ ë¨¸ë¦¬ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ë‹¤ì–‘í•œ ì¬ë£Œë„ ë°ì´í„°, API í˜¹ì€ íŒŒì¼ í˜•íƒœë¡œ ë‹´ì•„ë‚¼ ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#ê³ ë ¤ì‚¬í•­",
    "href": "openAI_GPT.html#ê³ ë ¤ì‚¬í•­",
    "title": "chatGPT",
    "section": "\n3.2 ê³ ë ¤ì‚¬í•­",
    "text": "3.2 ê³ ë ¤ì‚¬í•­\nOpenAIëŠ” 3ì›”ì— ì±„íŒ… ì™„ë£Œ(Chat Completion) APIë¥¼ ë„ì…í–ˆìœ¼ë©°, í˜„ì¬ API GPT ì‚¬ìš©ëŸ‰ì˜ 97%ë¥¼ ì°¨ì§€í•˜ê³  ìˆë‹¤.\n2020ë…„ 6ì›”ì— ë„ì…ëœ ì´ˆê¸° Completion APIëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ììœ í˜• í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ë„ì…ë˜ì—ˆë‹¤. ì´í›„ ë³´ë‹¤ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì¸í„°í˜ì´ìŠ¤(structured prompt interface)ë¥¼ í†µí•´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆë‹¤. ì±„íŒ… ê¸°ë°˜ íŒ¨ëŸ¬ë‹¤ì„ì€ ì´ì „ì˜ ì‚¬ìš© ì‚¬ë¡€ì™€ ìƒˆë¡œìš´ ëŒ€í™” ìš”êµ¬ ì‚¬í•­ì˜ ëŒ€ë¶€ë¶„ì„ ì²˜ë¦¬í•˜ëŠ” ë™ì‹œì— ë” ë†’ì€ ìœ ì—°ì„±ê³¼ êµ¬ì²´ì„±ì„ ì œê³µí•˜ëŠ” ê°•ë ¥í•œ ê²ƒìœ¼ë¡œ ì…ì¦ë˜ì—ˆë‹¤. íŠ¹íˆ ì±„íŒ… ì™„ë£Œ APIì˜ êµ¬ì¡°í™”ëœ ì¸í„°í˜ì´ìŠ¤(ì˜ˆ: ì‹œìŠ¤í…œ ë©”ì‹œì§€, í•¨ìˆ˜ í˜¸ì¶œ)ì™€ ë©€í‹°í„´(Multi-turn) ëŒ€í™” ê¸°ëŠ¥ì„ í†µí•´ ê°œë°œìëŠ” ëŒ€í™” í™˜ê²½ê³¼ ê´‘ë²”ìœ„í•œ ì™„ë£Œ ì‘ì—…ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\n\nêµ¬ë¶„\nì´ì „ ëª¨í˜•\nì‹  ëª¨í˜•\n\n\n\nChat Completion API\ngpt-3.5-turbo\ngpt-3.5-turbo\n\n\nCompletion API\nada\nada-002\n\n\nCompletion API\nbabbage\nbabbage-002\n\n\nCompletion API\ncurie\ncurie-002\n\n\nCompletion API\ndavinci\ndavinci-002\n\n\nCompletion API\ndavinci-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ncurie-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-ada-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-babbage-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-curie-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-002\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-003\ngpt-3.5-turbo-instruct\n\n\nEmbeddings Model\ncode-search-ada-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-ada-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-ada-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-babbage-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-curie-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-davinci-001\ntext-embedding-ada-002"
  },
  {
    "objectID": "openAI_GPT.html#api",
    "href": "openAI_GPT.html#api",
    "title": "chatGPT",
    "section": "\n3.3 API",
    "text": "3.3 API\nOpenAIëŠ” í¬ê²Œ 3ê°€ì§€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ìˆë‹¤.\n\nì±—GPT\nDall-E\nAPI\n\nAPI ë¬¸ì„œë¥¼ í†µí•´ ë‹¤ì–‘í•œ API ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#ê³„ì •ìƒì„±",
    "href": "openAI_GPT.html#ê³„ì •ìƒì„±",
    "title": "chatGPT",
    "section": "\n5.1 ê³„ì •ìƒì„±",
    "text": "5.1 ê³„ì •ìƒì„±\nOpenAI API ìƒì„± ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê³„ì •ì„ ìƒì„±í•œë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#api-key-ë°œê¸‰",
    "href": "openAI_GPT.html#api-key-ë°œê¸‰",
    "title": "chatGPT",
    "section": "\n5.2 API KEY ë°œê¸‰",
    "text": "5.2 API KEY ë°œê¸‰\nAPI keys ì›¹ì‚¬ì´íŠ¸ì—ì„œ API KEYë¥¼ ë°œê¸‰ë°›ëŠ”ë‹¤."
  },
  {
    "objectID": "openAI_GPT.html#openai-íŒ¨í‚¤ì§€-ì„¤ì¹˜",
    "href": "openAI_GPT.html#openai-íŒ¨í‚¤ì§€-ì„¤ì¹˜",
    "title": "chatGPT",
    "section": "\n5.3 openai íŒ¨í‚¤ì§€ ì„¤ì¹˜",
    "text": "5.3 openai íŒ¨í‚¤ì§€ ì„¤ì¹˜\nAPI Reference ì•ˆë‚´ì— ë”°ë¼ openai íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n$ pip install openai"
  },
  {
    "objectID": "openAI_GPT.html#í—¬ë¡œì›”ë“œ",
    "href": "openAI_GPT.html#í—¬ë¡œì›”ë“œ",
    "title": "chatGPT",
    "section": "\n5.4 í—¬ë¡œì›”ë“œ",
    "text": "5.4 í—¬ë¡œì›”ë“œ\nAPIí‚¤ë¥¼ ì§ì ‘ íŒŒì´ì¬ í”„ë¡œê·¸ë¨ì— ëª…ì‹œí•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.\n\nimport openai\n\nopenai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxx\"\n\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"OpenAI APIê°€ ë­”ê°€ìš”?\"\n)\n\nprint(response)\n\n{\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"\\n\\nOpenAI API\\ub294 \\uc778\\uacf5\"\n    }\n  ],\n  \"created\": 1689745304,\n  \"id\": \"cmpl-7duESieoaT985f4IKPskfcYQ3AH7F\",\n  \"model\": \"text-davinci-003\",\n  \"object\": \"text_completion\",\n  \"usage\": {\n    \"completion_tokens\": 14,\n    \"prompt_tokens\": 15,\n    \"total_tokens\": 29\n  }\n}"
  },
  {
    "objectID": "openAI_GPT.html#ë³´ì•ˆê°•í™”",
    "href": "openAI_GPT.html#ë³´ì•ˆê°•í™”",
    "title": "chatGPT",
    "section": "\n5.5 ë³´ì•ˆê°•í™”",
    "text": "5.5 ë³´ì•ˆê°•í™”\n\nimport requests\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n#&gt; True\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"OpenAI APIê°€ ë­”ê°€ìš”?\"\n)\n\nprint(response[\"choices\"][0]['text'])\n\nOpenAI APIëŠ” OpenAIê°€"
  },
  {
    "objectID": "openAI_api.html",
    "href": "openAI_api.html",
    "title": "ì±—GPT",
    "section": "",
    "text": "ChatGPTëŠ” ê°„ë‹¨íˆ ë§í•´ ìƒì„±í˜• ì‚¬ì „ í•™ìŠµëœ íŠ¸ëœìŠ¤í¬ë¨¸(Generative Pre-trained Transformer)ì˜ ì•½ìë¡œ, OpenAIì˜ GPT-3/GPT-4 ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ ì œí’ˆêµ°ì— ê¸°ë°˜í•œ ì±—ë´‡ìœ¼ë¡œ ì§€ë„í•™ìŠµê³¼ ê°•í™”í•™ìŠµê¸°ë²•ì„ ì ìš©í•˜ì—¬ ë¯¸ì„¸ì¡°ì •(fine-tuned)ëœ ì œí’ˆì´ì ì„œë¹„ìŠ¤ë‹¤.\n\nGPT-4â€™s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4ëŠ” GPT-3ë³´ë‹¤ 10ë°° ë§ì€ 1ì¡° 8ì²œì–µ ê°œì˜ íŒŒë¼ë¯¸í„°, 120ê°œ ê³„ì¸µì„ ê°–ëŠ” ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤. OpenAIëŠ” 16ê°œ ì „ë¬¸ê°€(MoE, Mixture of Experts)ì™€ 1,100ì–µ ê°œì˜ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  íŒŒë¼ë¯¸í„°ë¥¼ ê°–ëŠ” ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸ë¡œ êµ¬í˜„ë˜ì—ˆìœ¼ë©°, 13ì¡° ê°œì˜ í† í°ì´ í¬í•¨ëœ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆë‹¤. í›ˆë ¨ ë¹„ìš©ì€ 3,200 ~ 6,300ë§Œ ë‹¬ëŸ¬ë¡œ GPT-4ëŠ” ì´ì „ ë²„ì „ë³´ë‹¤ ì¶”ë¡  ë¹„ìš©ì´ ì•½ 3ë°° ë” ë†’ì§€ë§Œ, ë¶„ì‚° ë°ì´í„°ì„¼í„°ì—ì„œ 128ê°œ GPU í´ëŸ¬ìŠ¤í„° ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” ì¶”ë¡  ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤.\n\n\nThe Ship of Theseus\n\nOpenAIì˜ ì „ëµì€ í…Œì„¸ìš°ìŠ¤ì˜ ë°°(Theseusâ€™s Ship) ì™€ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.\n\nOpenAI GPT-3 ëª¨í˜•ì€ í¬ê²Œ ì„¸ê°€ì§€ê°€ ìˆë‹¤.\n\nGPT-3/GPT-4\nCodex\nì½˜í…ì¸  í•„í„° ëª¨ë¸\n\nGPT-3ì€ ìì—°ì–´ ì²˜ë¦¬ ë° ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë¸ë¡œ ì¸ê°„ì˜ ì–¸ì–´ ì¦‰, ìì—°ì–´ì²˜ëŸ¼ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤. í•œê±¸ìŒ ë” ë“¤ì–´ê°€ë©´ ì†ë„ì™€ ì„±ëŠ¥ì— ë”°ë¼ 4ê°€ì§€ ëª¨ë¸(A, B, C, D)ë¡œ êµ¬ë¶„ëœë‹¤.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\nì„±ëŠ¥ê¸°ì¤€ìœ¼ë¡œ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë ¬í•  ìˆ˜ ìˆëŠ”ë° ë¹„ìš©ë„ ê·¸ì— ë”°ë¼ ë†’ì•„ì§„ë‹¤ëŠ” ì˜ë¯¸ë„ í•¨ì¶•í•œë‹¤.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\në”°ë¼ì„œ, OpenAIëŠ” ë‹¤ë¹ˆì¹˜ ëª¨ë¸(text-davinci-003)ì„ í†µí•´ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì€ í›„ì— ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³¼ ê²ƒì„ ê¶Œì¥í•˜ëŠ”ë° ì´ìœ ëŠ” í›¨ì”¬ ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ë§ì€ ìˆ˜ì˜ ìœ ì‚¬í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\n\n2,048ê°œì˜ í† í° ë° 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµí•˜ì—¬ ì´í›„ ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ë‚˜ ì„±ëŠ¥ì—ì„œ ë‹¤ì†Œ ë°€ë¦¬ëŠ” ëª¨ìŠµì´ì§€ë§Œ ìµœì í™”ë¥¼ í†µí•´ ë§¤ìš° ë¹ ë¥´ê³  ë¹„ìš©ì´ ê°€ì¥ ì €ë ´í•˜ë‹¤.\n\n2,048ê°œì˜ í† í°ê³¼ 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµë˜ì—ˆê³  ê°„ë‹¨í•œ ë¶„ë¥˜ì™€ ì˜ë¯¸ë¡ ì  ë¶„ë¥˜ì— íš¨ê³¼ì ì´ë‹¤.\n\nìµœëŒ€ 2048ê°œì˜ í† í°ì„ ì§€ì›í•˜ë©° text-davinci-003 ë‹¤ìŒìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” GPT-3 ëª¨ë¸ì´ë‹¤. 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì— text-davinci-003ë³´ë‹¤ ì •í™•ë„ê°€ ë–¨ì–´ì§€ì§€ë§Œ, ë²ˆì—­, ë³µì¡í•œ ë¶„ë¥˜, í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìš”ì•½ì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆì–´ text-davinci-003ì™€ ë¹„êµí•˜ì—¬ ê°€ì„±ë¹„ê°€ ë†’ë‹¤ê³  í‰ê°€ë˜ê³  ìˆë‹¤.\n\n2021ë…„ 9ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì—ˆê¸° ë•Œë¬¸ì— ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ëŠ” ìˆì§€ë§Œ, ì•ì„  GPT-3 ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ë” ë†’ì€ í’ˆì§ˆì„ ì œê³µí•œë‹¤. ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ìµœëŒ€ 4,000ê°œ í† í°ê¹Œì§€ ìš”ì²­í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì´ì „ ëª¨í˜•ê³¼ í° ì°¨ë³„ì ì´ ëœë‹¤.\n\nì½”ë±ìŠ¤ëŠ” í”„ë¡œê·¸ë˜ë° ì½”ë“œ ì´í•´ ë° ìƒì„±ì„ ìœ„í•œ ê²ƒìœ¼ë¡œ code-davinci-002ì™€ code-cushman-001ê°€ ìˆë‹¤. ë˜í•œ, ì½”ë±ìŠ¤ëŠ” GitHub Copilotì„ êµ¬ë™í•˜ëŠ” ëª¨ë¸ì´ê¸°ë„ í•˜ë‹¤. íŒŒì´ì¬, ìë°”ìŠ¤í¬ë¦½íŠ¸, ê³ , í„, PHP, ë£¨ë¹„, ìŠ¤ìœ„í”„íŠ¸, íƒ€ì…ìŠ¤í¬ë¦½íŠ¸, SQL, ì…¸ ë“± 12ê°œ ì´ìƒì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì§€ì›í•  ë¿ë§Œ ì•„ë‹ˆë¼ ìì—°ì–´ë¡œ í‘œí˜„ëœ ì£¼ì„(comment)ë¥¼ ì´í•´í•˜ê³  ì‚¬ìš©ìë¥¼ ëŒ€ì‹ í•˜ì—¬ ìš”ì²­ëœ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\në³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ì„œëŠ” code-davinci-002ê°€ ë” ê°•ë ¥í•˜ì§€ë§Œ, ë§ì€ ì½”ë“œ ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê³  code-davinci-002 ë³´ë‹¤ ë” ë¹ ë¥´ê³  ì €ë ´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.\n\nìì—°ì–´ë¥¼ ì½”ë“œë¡œ ë²ˆì—­í•˜ëŠ” ë° íƒì›”í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•  ë¿ë§Œ ì•„ë‹ˆë¼ ë³´ì¶© ìš”ì†Œ ì‚½ì…ë„ ì§€ì›í•œë‹¤. ìµœëŒ€ 8,000ê°œì˜ í† í°ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° 2021ë…„ 6ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆë‹¤.\n\në¯¼ê°í•œ ì½˜í…ì¸  ì œê±°í•˜ê¸° ìœ„í•œ í•„í„° ëª¨í˜•ì´ë‹¤. ë¯¼ê°í•˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” API ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìê°€ ì‚¬ìš©í•  AI ì‘ìš©í”„ë¡œê·¸ë¨ì„ ê°œë°œí•  ê²½ìš°, í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ë°˜í™˜í•˜ëŠ”ì§€ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì´ í•„í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë‹¤ìŒ 3ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆˆë‹¤.\n\nì•ˆì „(safe)\në¯¼ê°(sensitive)\nì•ˆì „í•˜ì§€ ì•ŠìŒ(unsafe)"
  },
  {
    "objectID": "openAI_api.html#gpt-4",
    "href": "openAI_api.html#gpt-4",
    "title": "ì±—GPT",
    "section": "",
    "text": "GPT-4â€™s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4ëŠ” GPT-3ë³´ë‹¤ 10ë°° ë§ì€ 1ì¡° 8ì²œì–µ ê°œì˜ íŒŒë¼ë¯¸í„°, 120ê°œ ê³„ì¸µì„ ê°–ëŠ” ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤. OpenAIëŠ” 16ê°œ ì „ë¬¸ê°€(MoE, Mixture of Experts)ì™€ 1,100ì–µ ê°œì˜ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  íŒŒë¼ë¯¸í„°ë¥¼ ê°–ëŠ” ì „ë¬¸ê°€ í˜¼í•© ëª¨ë¸ë¡œ êµ¬í˜„ë˜ì—ˆìœ¼ë©°, 13ì¡° ê°œì˜ í† í°ì´ í¬í•¨ëœ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í–ˆë‹¤. í›ˆë ¨ ë¹„ìš©ì€ 3,200 ~ 6,300ë§Œ ë‹¬ëŸ¬ë¡œ GPT-4ëŠ” ì´ì „ ë²„ì „ë³´ë‹¤ ì¶”ë¡  ë¹„ìš©ì´ ì•½ 3ë°° ë” ë†’ì§€ë§Œ, ë¶„ì‚° ë°ì´í„°ì„¼í„°ì—ì„œ 128ê°œ GPU í´ëŸ¬ìŠ¤í„° ìœ„ì—ì„œ ë™ì‘í•˜ëŠ” ì¶”ë¡  ì•„í‚¤í…ì³ë¥¼ ê°–ê³  ìˆë‹¤.\n\n\nThe Ship of Theseus\n\nOpenAIì˜ ì „ëµì€ í…Œì„¸ìš°ìŠ¤ì˜ ë°°(Theseusâ€™s Ship) ì™€ ìœ ì‚¬í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "openAI_api.html#gpt-3",
    "href": "openAI_api.html#gpt-3",
    "title": "ì±—GPT",
    "section": "",
    "text": "OpenAI GPT-3 ëª¨í˜•ì€ í¬ê²Œ ì„¸ê°€ì§€ê°€ ìˆë‹¤.\n\nGPT-3/GPT-4\nCodex\nì½˜í…ì¸  í•„í„° ëª¨ë¸\n\nGPT-3ì€ ìì—°ì–´ ì²˜ë¦¬ ë° ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë¸ë¡œ ì¸ê°„ì˜ ì–¸ì–´ ì¦‰, ìì—°ì–´ì²˜ëŸ¼ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤. í•œê±¸ìŒ ë” ë“¤ì–´ê°€ë©´ ì†ë„ì™€ ì„±ëŠ¥ì— ë”°ë¼ 4ê°€ì§€ ëª¨ë¸(A, B, C, D)ë¡œ êµ¬ë¶„ëœë‹¤.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\nì„±ëŠ¥ê¸°ì¤€ìœ¼ë¡œ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë ¬í•  ìˆ˜ ìˆëŠ”ë° ë¹„ìš©ë„ ê·¸ì— ë”°ë¼ ë†’ì•„ì§„ë‹¤ëŠ” ì˜ë¯¸ë„ í•¨ì¶•í•œë‹¤.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\në”°ë¼ì„œ, OpenAIëŠ” ë‹¤ë¹ˆì¹˜ ëª¨ë¸(text-davinci-003)ì„ í†µí•´ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ì€ í›„ì— ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³¼ ê²ƒì„ ê¶Œì¥í•˜ëŠ”ë° ì´ìœ ëŠ” í›¨ì”¬ ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ë§ì€ ìˆ˜ì˜ ìœ ì‚¬í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\n\n2,048ê°œì˜ í† í° ë° 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµí•˜ì—¬ ì´í›„ ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ë‚˜ ì„±ëŠ¥ì—ì„œ ë‹¤ì†Œ ë°€ë¦¬ëŠ” ëª¨ìŠµì´ì§€ë§Œ ìµœì í™”ë¥¼ í†µí•´ ë§¤ìš° ë¹ ë¥´ê³  ë¹„ìš©ì´ ê°€ì¥ ì €ë ´í•˜ë‹¤.\n\n2,048ê°œì˜ í† í°ê³¼ 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„° í•™ìŠµë˜ì—ˆê³  ê°„ë‹¨í•œ ë¶„ë¥˜ì™€ ì˜ë¯¸ë¡ ì  ë¶„ë¥˜ì— íš¨ê³¼ì ì´ë‹¤.\n\nìµœëŒ€ 2048ê°œì˜ í† í°ì„ ì§€ì›í•˜ë©° text-davinci-003 ë‹¤ìŒìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” GPT-3 ëª¨ë¸ì´ë‹¤. 2019ë…„ 10ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì— text-davinci-003ë³´ë‹¤ ì •í™•ë„ê°€ ë–¨ì–´ì§€ì§€ë§Œ, ë²ˆì—­, ë³µì¡í•œ ë¶„ë¥˜, í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìš”ì•½ì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆì–´ text-davinci-003ì™€ ë¹„êµí•˜ì—¬ ê°€ì„±ë¹„ê°€ ë†’ë‹¤ê³  í‰ê°€ë˜ê³  ìˆë‹¤.\n\n2021ë…„ 9ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì—ˆê¸° ë•Œë¬¸ì— ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ëŠ” ìˆì§€ë§Œ, ì•ì„  GPT-3 ëª¨í˜•ê³¼ ë¹„êµí•˜ì—¬ ë” ë†’ì€ í’ˆì§ˆì„ ì œê³µí•œë‹¤. ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ìµœëŒ€ 4,000ê°œ í† í°ê¹Œì§€ ìš”ì²­í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì´ì „ ëª¨í˜•ê³¼ í° ì°¨ë³„ì ì´ ëœë‹¤."
  },
  {
    "objectID": "openAI_api.html#ì½”ë±ìŠ¤codex",
    "href": "openAI_api.html#ì½”ë±ìŠ¤codex",
    "title": "ì±—GPT",
    "section": "",
    "text": "ì½”ë±ìŠ¤ëŠ” í”„ë¡œê·¸ë˜ë° ì½”ë“œ ì´í•´ ë° ìƒì„±ì„ ìœ„í•œ ê²ƒìœ¼ë¡œ code-davinci-002ì™€ code-cushman-001ê°€ ìˆë‹¤. ë˜í•œ, ì½”ë±ìŠ¤ëŠ” GitHub Copilotì„ êµ¬ë™í•˜ëŠ” ëª¨ë¸ì´ê¸°ë„ í•˜ë‹¤. íŒŒì´ì¬, ìë°”ìŠ¤í¬ë¦½íŠ¸, ê³ , í„, PHP, ë£¨ë¹„, ìŠ¤ìœ„í”„íŠ¸, íƒ€ì…ìŠ¤í¬ë¦½íŠ¸, SQL, ì…¸ ë“± 12ê°œ ì´ìƒì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì§€ì›í•  ë¿ë§Œ ì•„ë‹ˆë¼ ìì—°ì–´ë¡œ í‘œí˜„ëœ ì£¼ì„(comment)ë¥¼ ì´í•´í•˜ê³  ì‚¬ìš©ìë¥¼ ëŒ€ì‹ í•˜ì—¬ ìš”ì²­ëœ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\në³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ìˆì–´ì„œëŠ” code-davinci-002ê°€ ë” ê°•ë ¥í•˜ì§€ë§Œ, ë§ì€ ì½”ë“œ ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê³  code-davinci-002 ë³´ë‹¤ ë” ë¹ ë¥´ê³  ì €ë ´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.\n\nìì—°ì–´ë¥¼ ì½”ë“œë¡œ ë²ˆì—­í•˜ëŠ” ë° íƒì›”í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•  ë¿ë§Œ ì•„ë‹ˆë¼ ë³´ì¶© ìš”ì†Œ ì‚½ì…ë„ ì§€ì›í•œë‹¤. ìµœëŒ€ 8,000ê°œì˜ í† í°ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©° 2021ë…„ 6ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ í•™ìŠµë˜ì—ˆë‹¤."
  },
  {
    "objectID": "openAI_api.html#ì½˜í…ì¸ -í•„í„°",
    "href": "openAI_api.html#ì½˜í…ì¸ -í•„í„°",
    "title": "ì±—GPT",
    "section": "",
    "text": "ë¯¼ê°í•œ ì½˜í…ì¸  ì œê±°í•˜ê¸° ìœ„í•œ í•„í„° ëª¨í˜•ì´ë‹¤. ë¯¼ê°í•˜ê±°ë‚˜ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” API ìƒì„± í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìê°€ ì‚¬ìš©í•  AI ì‘ìš©í”„ë¡œê·¸ë¨ì„ ê°œë°œí•  ê²½ìš°, í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¥¼ ë°˜í™˜í•˜ëŠ”ì§€ ê°ì§€í•  ìˆ˜ ìˆë‹¤. ì´ í•„í„°ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë‹¤ìŒ 3ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆˆë‹¤.\n\nì•ˆì „(safe)\në¯¼ê°(sensitive)\nì•ˆì „í•˜ì§€ ì•ŠìŒ(unsafe)"
  },
  {
    "objectID": "openAI_api.html#ì¸í„°í˜ì´ìŠ¤",
    "href": "openAI_api.html#ì¸í„°í˜ì´ìŠ¤",
    "title": "ì±—GPT",
    "section": "\n2.1 ì¸í„°í˜ì´ìŠ¤",
    "text": "2.1 ì¸í„°í˜ì´ìŠ¤\nOpenAI APIëŠ” OpenAIì—ì„œ ê°œë°œí•œ GPT-3, GPT-4 ëª¨ë¸ì„ í†µí•´ AI ê¸°ëŠ¥ì„ ê°œë°œí•˜ê³  ìˆëŠ” ë‹¤ì–‘í•œ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ì— ë‹´ì•„ë‚´ëŠ” ê³¼ì •ì´ë‹¤. ì œí’ˆê³¼ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ë©´ì„œ ë¨¸ë¦¬ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ ë‹¤ì–‘í•œ ì¬ë£Œë„ ë°ì´í„°, API í˜¹ì€ íŒŒì¼ í˜•íƒœë¡œ ë‹´ì•„ë‚¼ ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "openAI_api.html#ê³ ë ¤ì‚¬í•­",
    "href": "openAI_api.html#ê³ ë ¤ì‚¬í•­",
    "title": "ì±—GPT",
    "section": "\n2.2 ê³ ë ¤ì‚¬í•­",
    "text": "2.2 ê³ ë ¤ì‚¬í•­\nOpenAIëŠ” 3ì›”ì— ì±„íŒ… ì™„ë£Œ(Chat Completion) APIë¥¼ ë„ì…í–ˆìœ¼ë©°, í˜„ì¬ API GPT ì‚¬ìš©ëŸ‰ì˜ 97%ë¥¼ ì°¨ì§€í•˜ê³  ìˆë‹¤.\n2020ë…„ 6ì›”ì— ë„ì…ëœ ì´ˆê¸° Completion APIëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ììœ í˜• í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ë„ì…ë˜ì—ˆë‹¤. ì´í›„ ë³´ë‹¤ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì¸í„°í˜ì´ìŠ¤(structured prompt interface)ë¥¼ í†µí•´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆë‹¤. ì±„íŒ… ê¸°ë°˜ íŒ¨ëŸ¬ë‹¤ì„ì€ ì´ì „ì˜ ì‚¬ìš© ì‚¬ë¡€ì™€ ìƒˆë¡œìš´ ëŒ€í™” ìš”êµ¬ ì‚¬í•­ì˜ ëŒ€ë¶€ë¶„ì„ ì²˜ë¦¬í•˜ëŠ” ë™ì‹œì— ë” ë†’ì€ ìœ ì—°ì„±ê³¼ êµ¬ì²´ì„±ì„ ì œê³µí•˜ëŠ” ê°•ë ¥í•œ ê²ƒìœ¼ë¡œ ì…ì¦ë˜ì—ˆë‹¤. íŠ¹íˆ ì±„íŒ… ì™„ë£Œ APIì˜ êµ¬ì¡°í™”ëœ ì¸í„°í˜ì´ìŠ¤(ì˜ˆ: ì‹œìŠ¤í…œ ë©”ì‹œì§€, í•¨ìˆ˜ í˜¸ì¶œ)ì™€ ë©€í‹°í„´(Multi-turn) ëŒ€í™” ê¸°ëŠ¥ì„ í†µí•´ ê°œë°œìëŠ” ëŒ€í™” í™˜ê²½ê³¼ ê´‘ë²”ìœ„í•œ ì™„ë£Œ ì‘ì—…ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\n\nêµ¬ë¶„\nì´ì „ ëª¨í˜•\nì‹  ëª¨í˜•\n\n\n\nChat Completion API\ngpt-3.5-turbo\ngpt-3.5-turbo\n\n\nCompletion API\nada\nada-002\n\n\nCompletion API\nbabbage\nbabbage-002\n\n\nCompletion API\ncurie\ncurie-002\n\n\nCompletion API\ndavinci\ndavinci-002\n\n\nCompletion API\ndavinci-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ncurie-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-ada-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-babbage-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-curie-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-002\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-003\ngpt-3.5-turbo-instruct\n\n\nEmbeddings Model\ncode-search-ada-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-ada-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-ada-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-babbage-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-curie-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-davinci-001\ntext-embedding-ada-002"
  },
  {
    "objectID": "openAI_api.html#api",
    "href": "openAI_api.html#api",
    "title": "ì±—GPT",
    "section": "\n2.3 API",
    "text": "2.3 API\nOpenAIëŠ” í¬ê²Œ 3ê°€ì§€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ìˆë‹¤.\n\nì±—GPT\nDall-E\nAPI\n\nAPI ë¬¸ì„œë¥¼ í†µí•´ ë‹¤ì–‘í•œ API ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "openAI_api.html#í…ìŠ¤íŠ¸-ë²¡í„°-í‘œí˜„",
    "href": "openAI_api.html#í…ìŠ¤íŠ¸-ë²¡í„°-í‘œí˜„",
    "title": "ì±—GPT",
    "section": "\n5.1 í…ìŠ¤íŠ¸ ë²¡í„° í‘œí˜„",
    "text": "5.1 í…ìŠ¤íŠ¸ ë²¡í„° í‘œí˜„\ntext-embedding-ada-002 ëª¨ë¸ì€ ë¹ ë¥´ê³  ê°€ì„±ë¹„ê°€ ë›°ì–´ë‚œ ì„ë² ë”© ëª¨ë¸ì´ë‹¤. â€œëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.â€ ì´ë¼ëŠ” ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì¦‰, 1,536 ì°¨ì›ì„ ê°–ëŠ” ê³µê°„ì— í•˜ë‚˜ì˜ ì ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.\n\nimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'ë²¡í„°ê¸¸ì´: {len(seoul_embedding)}')\n#&gt; ë²¡í„°ê¸¸ì´: 1536\nprint(f'ë²¡í„° ì¼ë¶€: {seoul_embedding[:10]}')\n#&gt; ë²¡í„° ì¼ë¶€: [0.014582998119294643, -0.018063032999634743, 0.004872684367001057, -0.013805408962070942, -0.031180081889033318, 0.025176068767905235, -0.034519895911216736, 0.011357911862432957, -0.007960736751556396, -0.0020682618487626314]\n\në§ˆì°¬ê°€ì§€ë¡œ ì¼ë³¸ì˜ ìˆ˜ë„ ë„ì¿„ë„ ë²¡í„°ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.\n\ntokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"ì¼ë³¸ ìˆ˜ë„ëŠ” ë™ê²½ì…ë‹ˆë‹¤.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'ë²¡í„°ê¸¸ì´: {len(tokyo_embedding)}')\n#&gt; ë²¡í„°ê¸¸ì´: 1536\nprint(f'ë²¡í„° ì¼ë¶€: {tokyo_embedding[:10]}')\n#&gt; ë²¡í„° ì¼ë¶€: [0.010957648046314716, -0.013234060257673264, 0.009729413315653801, -0.011890077032148838, -0.03179261088371277, 0.03436483070254326, -0.029786281287670135, 0.008629790507256985, 0.01711810939013958, -0.0014733985299244523]"
  },
  {
    "objectID": "openAI_api_apps.html",
    "href": "openAI_api_apps.html",
    "title": "ì±—GPT",
    "section": "",
    "text": ".env íŒŒì¼ì— OpenAI API-KEY ë¥¼ ì €ì¥í•œ ê²½ìš° .gitignore ì— .envë¥¼ ê¸°ë¡í•˜ì—¬ í˜‘ì—…ê³¼ ê³µê°œë¥¼ í•  ê²½ìš° ì£¼ìš” ì •ë³´ê°€ ì™¸ë¶€ì— ë…¸ì¶œ ë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•œë‹¤.\n\nGitHub ì €ì¥ì†Œ OpenAI Python Libraryì˜ openai íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œ í›„ ë²„ì „ì„ í™•ì¸í•œë‹¤.\n\nì½”ë“œ! pip show openai\n\nName: openai\nVersion: 0.27.2\nSummary: Python client library for the OpenAI API\nHome-page: https://github.com/openai/openai-python\nAuthor: OpenAI\nAuthor-email: support@openai.com\nLicense: \nLocation: c:\\miniconda\\envs\\r-reticulate\\lib\\site-packages\nRequires: aiohttp, requests, tqdm\nRequired-by: \n\n\n\ngpt-3.5-turbo ëª¨í˜•ì€ ì†ë„ê°€ ë¹ ë¥´ê³  API í˜¸ì¶œ ë‹¹ ê°€ê²©ì´ ì €ë ´í•˜ì§€ë§Œ, ì„±ëŠ¥ì´ gpt-4 ë³´ë‹¤ ë‚®ì€ ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤. max_tokens í¬ê¸°ë¥¼ ë‹¬ë¦¬í•˜ì—¬ API ë°˜í™˜ê¸¸ì´ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆê³ , temperature ê°’ì„ ë‹¬ë¦¬í•˜ì—¬ ì‚¬ì‹¤ì— ë³´ë‹¤ ê°€ê¹Œìš´ ê°’ì„ ì–»ê³ ì í•  ê²½ìš° 0ìœ¼ë¡œ ê·¸ë ‡ì§€ ì•Šê³  ë‹¤ì–‘í•œ ì°½ì˜ì ì¸ ì‘ë‹µì„ ì›í•  ê²½ìš° 0 ë³´ë‹¤ í° ê°’ì„ ì§€ì •í•œë‹¤.\n\nì½”ë“œimport openai\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\nresponse = ChatCompletion.create(\n  model       = \"gpt-4\",\n  messages    = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"íŒŒì´ì¬í•˜ê³  R í•˜ê³  ì‹¸ìš°ë©´ ëˆ„ê°€ ì´ê²¨?\"}\n  ],\n  max_tokens   = 100,\n  temperature  = 0\n)\n\nprint(response[\"choices\"][0]['message']['content'])\n\n\níŒŒì´ì¬ê³¼ Rì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ì‹¸ìš°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê°ê°ì˜ íŠ¹ì„±ê³¼ ìš©ë„ì— ë”°ë¼ ì‚¬ìš©ë©ë‹ˆë‹¤. \n\níŒŒì´ì¬ì€ ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ì¸ê³µ ì§€ëŠ¥ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤."
  },
  {
    "objectID": "openAI_api_apps.html#openai-íŒ¨í‚¤ì§€",
    "href": "openAI_api_apps.html#openai-íŒ¨í‚¤ì§€",
    "title": "ì±—GPT",
    "section": "",
    "text": "GitHub ì €ì¥ì†Œ OpenAI Python Libraryì˜ openai íŒŒì´ì¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œ í›„ ë²„ì „ì„ í™•ì¸í•œë‹¤.\n\nì½”ë“œ! pip show openai\n\nName: openai\nVersion: 0.27.2\nSummary: Python client library for the OpenAI API\nHome-page: https://github.com/openai/openai-python\nAuthor: OpenAI\nAuthor-email: support@openai.com\nLicense: \nLocation: c:\\miniconda\\envs\\r-reticulate\\lib\\site-packages\nRequires: aiohttp, requests, tqdm\nRequired-by:"
  },
  {
    "objectID": "openAI_api_apps.html#gpt-4-ëª¨ë¸",
    "href": "openAI_api_apps.html#gpt-4-ëª¨ë¸",
    "title": "ì±—GPT",
    "section": "",
    "text": "gpt-3.5-turbo ëª¨í˜•ì€ ì†ë„ê°€ ë¹ ë¥´ê³  API í˜¸ì¶œ ë‹¹ ê°€ê²©ì´ ì €ë ´í•˜ì§€ë§Œ, ì„±ëŠ¥ì´ gpt-4 ë³´ë‹¤ ë‚®ì€ ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤. max_tokens í¬ê¸°ë¥¼ ë‹¬ë¦¬í•˜ì—¬ API ë°˜í™˜ê¸¸ì´ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆê³ , temperature ê°’ì„ ë‹¬ë¦¬í•˜ì—¬ ì‚¬ì‹¤ì— ë³´ë‹¤ ê°€ê¹Œìš´ ê°’ì„ ì–»ê³ ì í•  ê²½ìš° 0ìœ¼ë¡œ ê·¸ë ‡ì§€ ì•Šê³  ë‹¤ì–‘í•œ ì°½ì˜ì ì¸ ì‘ë‹µì„ ì›í•  ê²½ìš° 0 ë³´ë‹¤ í° ê°’ì„ ì§€ì •í•œë‹¤.\n\nì½”ë“œimport openai\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\nresponse = ChatCompletion.create(\n  model       = \"gpt-4\",\n  messages    = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"íŒŒì´ì¬í•˜ê³  R í•˜ê³  ì‹¸ìš°ë©´ ëˆ„ê°€ ì´ê²¨?\"}\n  ],\n  max_tokens   = 100,\n  temperature  = 0\n)\n\nprint(response[\"choices\"][0]['message']['content'])\n\n\níŒŒì´ì¬ê³¼ Rì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ì‹¸ìš°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê°ê°ì˜ íŠ¹ì„±ê³¼ ìš©ë„ì— ë”°ë¼ ì‚¬ìš©ë©ë‹ˆë‹¤. \n\níŒŒì´ì¬ì€ ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ì¸ê³µ ì§€ëŠ¥ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤."
  },
  {
    "objectID": "openAI_api_apps.html#ì—°ì„¤ë¬¸-ë‚­ë…",
    "href": "openAI_api_apps.html#ì—°ì„¤ë¬¸-ë‚­ë…",
    "title": "ì±—GPT",
    "section": "\n5.1 ì—°ì„¤ë¬¸ ë‚­ë…",
    "text": "5.1 ì—°ì„¤ë¬¸ ë‚­ë…\nâ€˜ì œ84ì£¼ë…„ 3.1ì ˆâ€™ ê¸°ë…í–‰ì‚¬ì—ì„œ ë…¸ë¬´í˜„ ëŒ€í†µë ¹ì´ ë‚­ë…í•œ ì—°ì„¤ë¬¸ì„ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n\n3.1ì ˆì„ ë§ì•„ ì¼ì œì— í•­ê±°í•œ ì• êµ­ì„ ì—´ë“¤ê»˜ ê°ì‚¬ì™€ ê²½ì˜ í‘œí•¨. êµ­ë¯¼í†µí•©ê³¼ ê°œí˜ìœ¼ë¡œ í‰í™”ì™€ ë²ˆì˜ì˜ ë™ë¶ì•„ì‹œëŒ€ë¥¼ ì—´ì–´ê°€ê³  ìë‘ìŠ¤ëŸ° ëŒ€í•œë¯¼êµ­ì„ ìš°ë¦¬ í›„ì†ì—ê²Œ ë¬¼ë ¤ì¤„ ê²ƒì„ ì—°ì„¤í–ˆë‹¤.\n\nAudacity í”„ë¡œê·¸ë¨ì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì‚­ì œí•˜ê³  í•´ë‹¹ ì—°ì„¤ë¬¸ë§Œ ì¶”ì¶œí•˜ì—¬ .mp3 íŒŒì¼ë¡œ ì¤€ë¹„í•œë‹¤.\n\nì½”ë“œlibrary(av)\nlibrary(embedr)\n\nembedr::embed_audio(\"data/ì œ84ì£¼ë…„_31ì ˆ_ê¸°ë…ì‚¬_ë…¸ë¬´í˜„.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "openAI_api_apps.html#mp3-í…ìŠ¤íŠ¸",
    "href": "openAI_api_apps.html#mp3-í…ìŠ¤íŠ¸",
    "title": "ì±—GPT",
    "section": "\n5.2 .mp3 â†’ í…ìŠ¤íŠ¸",
    "text": "5.2 .mp3 â†’ í…ìŠ¤íŠ¸\nOpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ TXTë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. .mp3 íŒŒì¼ì„ ì¤€ë¹„í•˜ê³ ,Audio.transcribe() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ .txt í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.\n\nì½”ë“œimport openai\nfrom dotenv import load_dotenv\nimport os\n\n# API KEY ----------------------\nload_dotenv()\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\n# STT --------------------------\n\nspeech_file = open(\"data/ì œ84ì£¼ë…„_31ì ˆ_ê¸°ë…ì‚¬_ë…¸ë¬´í˜„.mp3\", \"rb\")\n\nresponse = openai.Audio.transcribe(\"whisper-1\", speech_file)\n\n\nwith open(\"data/stt_audio.txt\", \"w\") as file:\n    file.write(response[\"text\"])"
  },
  {
    "objectID": "openAI_api_apps.html#í›„ì²˜ë¦¬",
    "href": "openAI_api_apps.html#í›„ì²˜ë¦¬",
    "title": "ì±—GPT",
    "section": "\n5.3 í›„ì²˜ë¦¬",
    "text": "5.3 í›„ì²˜ë¦¬\nSTTë¥¼ í†µí•´ ë‚˜ì˜¨ í…ìŠ¤íŠ¸ëŠ” ì‚¬ëŒì´ ì½ê¸°ì—ëŠ” ê°€ë…ì„±ì´ ë¬´ì²™ ë–¨ì–´ì§€ëŠ” í…ìŠ¤íŠ¸ì— ë¶ˆê³¼í•˜ë‹¤. ì´ë¥¼ ì½ì„ ìˆ˜ ìˆë„ë¡ í›„ì²˜ë¦¬ë¥¼ í•œë‹¤.\n\n\nìŒì„±ì›ê³  ì›ë¬¸\nWhisper í…ìŠ¤íŠ¸\nì±— GPT í›„ê°€ê³µ\nWhisper í…ìŠ¤íŠ¸\n\n\n\nì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„,\nì˜¤ëŠ˜ ì—¬ë“  ë„¤ ë²ˆì§¸ 3, 1ì ˆì„ ë§ì•„ ë‚˜ë¼ë¥¼ ìœ„í•´ í¬ìƒí•˜ê³  í—Œì‹ í•˜ì‹  ì• êµ­ì„ ì—´ë“¤ê»˜ í•œì—†ëŠ” ê°ì‚¬ì™€ ê²½ì˜ë¥¼ í‘œí•©ë‹ˆë‹¤. ë…ë¦½ìœ ê³µìì™€ ìœ ê°€ì¡± ì—¬ëŸ¬ë¶„ì—ê²Œë„ ì¡´ê²½ê³¼ ê°ì‚¬ì˜ ë§ì”€ì„ ë“œë¦½ë‹ˆë‹¤.\nê¸°ë¯¸ë…„ ì˜¤ëŠ˜, ìš°ë¦¬ëŠ” ì¼ì œì˜ ì´ì¹¼ì— ë§ì„œ ë§¨ì£¼ë¨¹ìœ¼ë¡œ ë¶„ì—°íˆ ì¼ì–´ì„°ìŠµë‹ˆë‹¤. ëŒ€í•œë…ë¦½ ë§Œì„¸ ì†Œë¦¬ê°€ ì „êµ­ ë°©ë°©ê³¡ê³¡ì„ ë’¤ë®ì—ˆê³ , ìš°ë¦¬ëŠ” ìì£¼ë…ë¦½ ì˜ì§€ë¥¼ ì„¸ê³„ë§Œë°©ì— ì•Œë ¸ìŠµë‹ˆë‹¤. 3, 1ìš´ë™ì„ ê³„ê¸°ë¡œ êµ­ë‚´ì™¸ì˜ ë…ë¦½íˆ¬ìŸì€ ë”ìš± í˜ì°¨ê²Œ ì „ê°œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒí•´ì— ëŒ€í•œë¯¼êµ­ ì„ì‹œì •ë¶€ê°€ ì„¸ì›Œì¡Œê³ , ìš°ë¦¬ëŠ” ë§ˆì¹¨ë‚´ ë¹¼ì•—ê¸´ êµ­ê¶Œì„ ë˜ì°¾ì•˜ìŠµë‹ˆë‹¤.\n3, 1ì •ì‹ ì€ ëŠì„ì—†ëŠ” ë„ì „ì„ ìŠ¬ê¸°ë¡­ê²Œ ê·¹ë³µí•´ ì˜¨ ìš°ë¦¬ ë¯¼ì¡±ì˜ ìë‘ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë¹›ë‚˜ëŠ” ì •ì‹ ì„ ê³„ìŠ¹í•˜ì—¬ ì „ìŸì˜ íí—ˆë¥¼ ë”›ê³  ì„¸ê³„ 12ìœ„ì˜ ê²½ì œê°•êµ­ìœ¼ë¡œ ë°œë‹ì›€í–ˆìŠµë‹ˆë‹¤. 4, 19 í˜ëª…ê³¼ ê´‘ì£¼ë¯¼ì£¼í™”ìš´ë™, 6ì›” ë¯¼ì£¼í•­ìŸì„ ê±°ì³ ë¯¼ì£¼ì£¼ì˜ì™€ ì¸ê¶Œì„ ìŸì·¨í•´ ëƒˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ì°¸ì—¬ì •ë¶€ëŠ” ë°”ë¡œ ê·¸ ìœ„ëŒ€í•œ ì—­ì‚¬ì˜ ì—°ì¥ì„  ìœ„ì— ì„œ ìˆìŠµë‹ˆë‹¤.\nì°¸ì—¬ì •ë¶€ì˜ ì¶œë²”ìœ¼ë¡œ ì´ì œ ì•„í””ì˜ ê·¼, í˜„ëŒ€ì‚¬ëŠ” ë§‰ì„ ë‚´ë¦¬ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì§€ë‚œë‚ ì€ ì„ ì—´ë“¤ì˜ ê³ ê·€í•œ í¬ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ì¢Œì ˆê³¼ êµ´ì ˆì„ ê²ªì–´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì •ì˜ëŠ” íŒ¨ë°°í–ˆê³  ê¸°íšŒì£¼ì˜ê°€ ë“ì„¸í–ˆìŠµë‹ˆë‹¤.\nê·¸ëŸ¬ë‚˜ ì´ì œ ë¹„ë¡œì†Œ ì—­ì‚¬ì  ì „í™˜ì ì´ ë§ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. êµ­ë¯¼ì´ ì§„ì • ì£¼ì¸ìœ¼ë¡œ ëŒ€ì ‘ë°›ëŠ” ì‹œëŒ€ê°€ ì—´ë¦° ê²ƒì…ë‹ˆë‹¤.\nì°¸ì—¬ì •ë¶€ì—ì„œëŠ” ê¶Œë ¥ì— ì•„ë¶€í•˜ëŠ” ì‚¬ëŒë“¤ì´ ë” ì´ìƒ ì„¤ ë•…ì´ ì—†ì„ ê²ƒì…ë‹ˆë‹¤. ì˜¤ë¡œì§€ ì„±ì‹¤í•˜ê²Œ ì¼í•˜ê³  ì •ì •ë‹¹ë‹¹í•˜ê²Œ ìŠ¹ë¶€í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤. ê·¸ê²ƒì´ ë°”ë¡œ ì„ ì—´ë“¤ì˜ í¬ìƒì— ë³´ë‹µí•˜ëŠ” ê¸¸ì´ì ì €ì™€ ì°¸ì—¬ì •ë¶€ì—ê²Œ ì£¼ì–´ì§„ ì—­ì‚¬ì  ì†Œëª…ì…ë‹ˆë‹¤.\nêµ­ë¯¼ ì—¬ëŸ¬ë¶„,\nì§€ê¸ˆ ìš°ë¦¬ëŠ” ì„¸ê³„ì‚¬ì˜ ìƒˆë¡œìš´ íë¦„ê³¼ ë§ˆì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë™ë¶ì•„ ì‹œëŒ€ì˜ ë„ë˜ê°€ ë°”ë¡œ ê·¸ê²ƒì…ë‹ˆë‹¤. ë™ë¶ì•„ì‹œì•„ëŠ” ê·¼ëŒ€ ì´í›„ ì„¸ê³„ì˜ ë³€ë°©ìœ¼ë¡œë§Œ ë¨¸ë¬¼ëŸ¬ ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì œ ìœ ëŸ½ì—°í•©, ë¶ë¯¸ì§€ì—­ê³¼ í•¨ê»˜ ì„¸ê³„ê²½ì œì˜ 3ëŒ€ ì¶•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ 20ë…„ í›„ì—ëŠ” ì„¸ê³„ê²½ì œì˜ 3ë¶„ì˜ 1ì„ ì°¨ì§€í•˜ê²Œ ëœë‹¤ëŠ” ì „ë§ë„ ìˆìŠµë‹ˆë‹¤. ë¯¼ì¡±ì›…ë¹„ì˜ í¬ë‚˜í° ê¸°íšŒê°€ ìš°ë¦¬ì—ê²Œ ë‹¤ê°€ì˜¤ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.\nìš°ë¦¬ëŠ” ë™ë¶ì•„ì‹œëŒ€ì˜ ì¤‘ì‹¬êµ­ê°€ë¡œ ë„ì•½í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ì¡°ê±´ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ìš°ì„ , ì§€ë¦¬ì ìœ¼ë¡œ ì¤‘ì‹¬ì— ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤. ì„œìš¸ì—ì„œ 3ì‹œê°„ì˜ ë¹„í–‰ê±°ë¦¬ ì•ˆì— ì¸êµ¬ 100ë§Œ ì´ìƒì˜ ë„ì‹œê°€ ë§ˆí” ì„¸ ê°œë‚˜ ë©ë‹ˆë‹¤. ì¤‘êµ­ê³¼ ëŸ¬ì‹œì•„ì˜ ì¸ë ¥ê³¼ ìì›, ê·¸ë¦¬ê³  ì¼ë³¸ì˜ ê¸°ìˆ ì„ ì ‘ëª©í•  ìˆ˜ ìˆëŠ” ìœ ë¦¬í•œ ìœ„ì¹˜ì…ë‹ˆë‹¤. ëŒ€ë¥™ê³¼ í•´ì–‘ì„ ì‡ëŠ” ì§€ì •í•™ì  ì´ì ë„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•˜ëŠ˜ê³¼ ë°”ë‹¤ì™€ ë•…ì— ê±¸ì¹œ ë¬¼ë¥˜ì™€, ì„¸ê³„ ì¼ë¥˜ì˜ ì •ë³´í™” ê¸°ë°˜ê³¼ ì—­ëŸ‰ì„ ë‘ë£¨ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\ní•œë°˜ë„ëŠ” ë” ì´ìƒ ì„¸ê³„ì˜ ë³€ë°©ì´ ì•„ë‹™ë‹ˆë‹¤. ë‚¨ë¶ ì² ë„ê°€ ì—°ê²°ë˜ê³  ì² ì˜ ì‹¤í¬ë¡œë“œê°€ ì—´ë¦¬ë©´ ê´‘í™œí•œ ëŒ€ë¥™ì„ í–¥í•´ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ê³³ì—ëŠ” ì¤‘êµ­ëŒ€ë¥™ì´ë¼ëŠ” ìƒˆë¡œìš´ ê¸°íšŒê°€ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ì‹œë² ë¦¬ì•„ì™€ ì¤‘ì•™ì•„ì‹œì•„ì˜ ë¬´í•œí•œ ìì›ë„ ìˆìŠµë‹ˆë‹¤.\ní•œë°˜ë„ê°€ ëŒ€ë¥™ê³¼ í•´ì–‘ì„ ì‡ëŠ” ë¬¼ë¥˜ì™€ ê¸ˆìœµê³¼ ìƒì‚° ê±°ì ìœ¼ë¡œ ê±°ë“­ë‚˜ê²Œ ë©ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ ìš°ë¦¬ ì•ì— ìˆëŠ” ë¯¸ë˜ì…ë‹ˆë‹¤. ìš°ë¦¬ì—ê²ŒëŠ” ì´ë¥¼ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ì±…ë¬´ê°€ ì£¼ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\nì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„,\nê·¸ëŸ¬ë‚˜ ë™ë¶ì•„ ì¤‘ì‹¬êµ­ê°€ë¡œ ë‚˜ì•„ê°€ê¸° ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ í•´ì•¼ í•  ì¼ì´ ìˆìŠµë‹ˆë‹¤. í•œë°˜ë„ì— í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ëŠ” ì¼ì…ë‹ˆë‹¤. ë‚¨ë¶ì´ ëŒ€ë¦½í•˜ë©° í•œë°˜ë„ì— ê¸´ì¥ì´ ê³ ì¡°ë˜ëŠ” í•œ, ë™ë¶ì•„ ì¤‘ì‹¬êµ­ê°€ì˜ ê¿ˆì€ ì‹¤í˜„ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë™ë¶ì•„ì˜ í‰í™”ì™€ ë²ˆì˜ë„ ê¸°ëŒ€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\nê·¸ë™ì•ˆ ìš°ë¦¬ëŠ” í•œë°˜ë„ì— í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ê¸° ìœ„í•´ ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì—¬ ì™”ìŠµë‹ˆë‹¤. ë‚¨ë¶ê°„ì— ëŒ€í™”ì™€ êµë¥˜ê°€ ë¹ˆë²ˆí•´ì¡Œê³  ì´ì‚°ê°€ì¡±ì´ ë§Œë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ìœ¡ë¡œë„ ì—´ë ¸ìŠµë‹ˆë‹¤.\nê·¸ëŸ¬ë‚˜ ì•„ì§ í’€ì–´ì•¼ í•  ìˆ™ì œê°€ ë§ìŠµë‹ˆë‹¤. íŠ¹íˆ ë¶í•µ ë¬¸ì œëŠ” ì‹œê¸‰íˆ í•´ê²°í•´ì•¼ í•  ê³¼ì œì…ë‹ˆë‹¤.\nì €ëŠ” ë¶í•œì˜ í•µ ê°œë°œì— ë‹¨í˜¸íˆ ë°˜ëŒ€í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë¬¸ì œëŠ” ë°˜ë“œì‹œ í‰í™”ì ìœ¼ë¡œ í•´ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì–´ë– í•œ ì´ìœ ë¡œë“  í•œë°˜ë„ì˜ í‰í™”ê°€ ê¹¨ì–´ì§„ë‹¤ë©´, ìš°ë¦¬ëŠ” ê·¸ ì—„ì²­ë‚œ ì¬ì•™ì„ ê°ë‹¹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•œë°˜ë„ì˜ í‰í™”ì™€ êµ­ë¯¼ì˜ ì•ˆì „ì„ ì§€í‚¤ëŠ” ê²ƒì€ ëŒ€í†µë ¹ì˜ ê°€ì¥ í° ì±…ë¬´ì…ë‹ˆë‹¤.\nì•ìœ¼ë¡œ ë‚¨ë¶ê´€ê³„ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ê»˜ ì†Œìƒíˆ ë³´ê³  ë“œë¦¬ê³ , êµ­ë¯¼ì  í•©ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì§„í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤. ì•¼ë‹¹ì˜ í˜‘ë ¥ë„ ì ê·¹ì ìœ¼ë¡œ êµ¬í•´ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤. ë¯¸êµ­ê³¼ ì¼ë³¸, ì¤‘êµ­, ëŸ¬ì‹œì•„ ë“± ì£¼ë³€êµ­ê³¼, EUë¥¼ ë¹„ë¡¯í•œ êµ­ì œì‚¬íšŒì™€ë„ ëŠ¥ë™ì ìœ¼ë¡œ í˜‘ë ¥í•´ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤.\nêµ­ë¯¼ ì—¬ëŸ¬ë¶„,\ní•œë°˜ë„ì— í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ëŠ” ì¼ ëª»ì§€ ì•Šê²Œ ì¤‘ìš”í•œ ê²ƒì€ êµ­ë¯¼ì˜ í˜ì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” ì¼ì…ë‹ˆë‹¤. 84ë…„ ì „ ì˜¤ëŠ˜, ìš°ë¦¬ì˜ ì„ ì—´ë“¤ì€ í•œë§ˆìŒ í•œëœ»ìœ¼ë¡œ ë…ë¦½ìš´ë™ì— ë‚˜ì„°ìŠµë‹ˆë‹¤. ë¹ˆë¶€ì™€ ê·€ì²œ, ë‚¨ë…€ì™€ ë…¸ì†Œ, ì§€ì—­ê³¼ ì¢…êµì˜ ì°¨ì´ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤. ë‚˜ë¼ì˜ ë…ë¦½ê³¼ ë¯¼ì¡±ì˜ ìì¡´ì‹¬ì„ ë˜ì°¾ëŠ” ë° í•˜ë‚˜ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.\nì˜¤ëŠ˜ì„ ì‚¬ëŠ” ìš°ë¦¬ë„ ì§€ì—­ê³¼ ê³„ì¸µê³¼ ì„¸ëŒ€ë¥¼ ë„˜ì–´ í•˜ë‚˜ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë‚´ë¶€ì— ë¶„ì—´ê³¼ ë°˜ëª©ì´ ìˆìœ¼ë©´ ì„¸ê³„ê²½ìŸì—ì„œ ë’¤ì³ì§ˆ ìˆ˜ë°–ì— ì—†ìŠµë‹ˆë‹¤. êµ­ê¶Œê¹Œì§€ ìƒì‹¤í–ˆë˜ 100ë…„ ì „ì˜ ì‹¤íŒ¨ê°€ ë˜í’€ì´ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆì´ì•¼ë§ë¡œ 3, 1ì •ì‹ ì„ ë˜ëŒì•„ë³´ë©° ì—­ì‚¬ì˜ êµí›ˆì„ ë˜ìƒˆê²¨ì•¼ í•  ë•Œì…ë‹ˆë‹¤.\në§ˆìŒì†ì— ì§€ì—­ê°ˆë“±ì˜ ì‘ì–´ë¦¬ê°€ ìˆë‹¤ë©´ ê°€ìŠ´ì„ ì—´ê³  í’€ì–´ì•¼ í•©ë‹ˆë‹¤. ì–´ë¥¸ì€ ì Šì€ì´ì˜ ëª©ì†Œë¦¬ì— ê·€ê¸°ìš¸ì´ê³  ì Šì€ì´ëŠ” ì–´ë¥¸ì˜ ê²½í—˜ì„ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤. ì°¨ë³„ ë°›ê³  ì†Œì™¸ë˜ì–´ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ë” ë§ì€ ê´€ì‹¬ê³¼ ë…¸ë ¥ì„ ê¸°ìš¸ì—¬ì•¼ í•©ë‹ˆë‹¤. êµ­ë¯¼ ëª¨ë‘ê°€ ì°¸ëœ ì£¼ì¸ìœ¼ë¡œì„œ êµ­ì •ì— ì°¸ì—¬í•˜ê³ , ì˜¨ êµ­ë¯¼ì˜ í˜ì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” êµ­ë¯¼ì°¸ì—¬ì‹œëŒ€ë¥¼ í˜ì°¨ê²Œ ì—´ì–´ê°€ì•¼ê² ìŠµë‹ˆë‹¤.\nê°œí˜ ë˜í•œ ë©ˆì¶œ ìˆ˜ ì—†ëŠ” ìš°ë¦¬ ì‹œëŒ€ì˜ ê³¼ì œì…ë‹ˆë‹¤. ë¬´ì—‡ë³´ë‹¤ ì •ì¹˜ì™€ í–‰ì •ì´ ë°”ë€Œì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¸ë°” ëª‡ëª‡ â€™ê¶Œë ¥ê¸°ê´€â€™ì€ ê·¸ë™ì•ˆ ì •ê¶Œì„ ìœ„í•´ ë´‰ì‚¬í•´ ì™”ë˜ ê²ƒì´ ì‚¬ì‹¤ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ë‚´ë¶€ì˜ ì§ˆì„œê°€ ë¬´ë„ˆì§€ê³  êµ­ë¯¼ì˜ ì‹ ë¢°ë¥¼ ìƒì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì´ë“¤ â€™ê¶Œë ¥ê¸°ê´€â€™ì€ êµ­ë¯¼ì„ ìœ„í•œ ê¸°ê´€ìœ¼ë¡œ ê±°ë“­ë‚˜ì•¼ í•©ë‹ˆë‹¤. ì°¸ì—¬ì •ë¶€ëŠ” ë” ì´ìƒ â€™ê¶Œë ¥ê¸°ê´€â€™ì— ì˜ì¡´í•˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. ì–¸ì œë‚˜ ì •ì •ë‹¹ë‹¹í•œ ì •ë¶€ë¡œì„œ êµ­ë¯¼ ì•ì— ì„¤ ê²ƒì…ë‹ˆë‹¤.\nì°¸ì—¬ì •ë¶€ëŠ” ê³µì •í•˜ê³  íˆ¬ëª…í•œ ì‹œì¥ì§ˆì„œ, ë…¸ì‚¬í™”í•©, ê¸°ìˆ í˜ì‹ , ì§€ì—­ ê· í˜•ë°œì „ ì†ì— ì •ì§í•˜ê³  ì„±ì‹¤í•˜ê²Œ ì‚¬ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ë‚˜ë¼ë¥¼ ë§Œë“¤ì–´ê°ˆ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì›ì¹™ê³¼ ì‹ ë¢°, ê³µì •ê³¼ íˆ¬ëª…, ëŒ€í™”ì™€ íƒ€í˜‘, ë¶„ê¶Œê³¼ ììœ¨ì˜ ë¬¸í™”ë¥¼ ì‚¬íšŒ ê³³ê³³ì— ë¿Œë¦¬ë‚´ë¦´ ê²ƒì…ë‹ˆë‹¤.\nì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„!\nìš°ë¦¬ì—ê²ŒëŠ” ì„ ì—´ë“¤ì´ ë³´ì—¬ì¤€ ìì£¼ë…ë¦½ì˜ ê¸°ìƒê³¼ ëŒ€ë™ë‹¨ê²°ì˜ ì§€í˜œê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ 3, 1ì ˆì„ ë§ì•„ ì¼ì œì˜ ì´ì¹¼ì— í•­ê±°í•˜ë©° ì´ë£¨ê³ ì í–ˆë˜ ì„ ì—´ë“¤ì˜ ëœ»ì„ ë‹¤ì‹œ í•œë²ˆ ê°€ìŠ´ì— ìƒˆê¹ì‹œë‹¤. êµ­ë¯¼í†µí•©ê³¼ ê°œí˜ìœ¼ë¡œ í‰í™”ì™€ ë²ˆì˜ì˜ ë™ë¶ì•„ì‹œëŒ€ë¥¼ ì—´ì–´ê°‘ì‹œë‹¤. ìë‘ìŠ¤ëŸ° ëŒ€í•œë¯¼êµ­ì„ ìš°ë¦¬ í›„ì†ë“¤ì—ê²Œ ë¬¼ë ¤ì¤ì‹œë‹¤.\n\n\n\nì½”ë“œlibrary(tidyverse)\n\nstt_txt &lt;- read_lines(\"data/stt_audio.txt\")\n\nstt_txt\n#&gt; [1] \"ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ì—¬ëŸ¬ë¶„ ì˜¤ëŠ˜ 84ë²ˆì§¸ 3.21ì ˆì„ ë§ì•„ ë‚˜ë¼ë¥¼ ìœ„í•´ í¬ìƒí•˜ê³  í—Œì‹ í•˜ì‹  ì• êµ­ì„ ì—´ë“¤ê»˜ í•œì—†ëŠ” ê°ì‚¬ì™€ ê²½ì˜ë¥¼ í‘œí•©ë‹ˆë‹¤ ë…ë¦½ìœ ê³µìì™€ ìœ ê°€ì¡± ì—¬ëŸ¬ë¶„ì—ê²Œë„ ì¡´ê²½ê³¼ ê°ì‚¬ì˜ ë§ì”€ì„ ë“œë¦½ë‹ˆë‹¤ 3.22ë…„ ì˜¤ëŠ˜ ìš°ë¦¬ëŠ” ì¼ì œì˜ ì´ì¹¼ì— ë§ì„œ ë§¨ì£¼ë¨¹ìœ¼ë¡œ ë¶„ì—°íˆ ì¼ì–´ì„°ìŠµë‹ˆë‹¤ ëŒ€í•œë…ë¦½ë§Œì„¸ ì†Œë¦¬ê°€ ì „êµ­ ë°©ë°©ê³¡ê³¡ì„ ë’¤ë®ì—ˆê³  ìš°ë¦¬ëŠ” ìì£¼ë…ë¦½ì˜ì§€ë¥¼ ì„¸ê³„ ë§Œë°©ì— ì•Œë ¸ìŠµë‹ˆë‹¤ 3.21ìš´ë™ì„ ê³„ê¸°ë¡œ êµ­ë‚´ì™¸ì˜ ë…ë¦½íˆ¬ìŸì€ ë”ìš± í˜ì°¨ê²Œ ì „ê°œë˜ì—ˆìŠµë‹ˆë‹¤ ìƒí•´ ëŒ€í•œë¯¼êµ­ ì„ì‹œì •ë¶€ê°€ ì„¸ì›Œì¡Œê³  ìš°ë¦¬ëŠ” ë§ˆì¹¨ë‚´ ë¹¼ì•—ê¸´ êµ­ê¶Œì„ ë˜ì°¾ì•˜ìŠµë‹ˆë‹¤ 3.21ì •ì‹ ì€ ëŠì„ì—†ëŠ” ë„ì „ì„ ìŠ¬ê¸°ë¡­ê²Œ ê·¹ë³µí•´ì˜¨ ìš°ë¦¬ ë¯¼ì¡±ì˜ ìë‘ì…ë‹ˆë‹¤ ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë¹›ë‚˜ëŠ” ì •ì‹ ì„ ê³„ìŠ¹í•˜ì—¬ ì „ìŸì˜ íí—ˆë¥¼ ë”›ê³  ì„¸ê³„ 12ìœ„ì˜ ê²½ì œê°•êµ­ìœ¼ë¡œ ë°œë‹ì›€í–ˆìŠµë‹ˆë‹¤ 4.19í˜ëª…ê³¼ ê´‘ì£¼ë¯¼ì£¼í™”ìš´ë™ 6ì›” ë¯¼ì£¼í•­ìŸì„ ê±°ì³ì„œ ë¯¼ì£¼ì£¼ì˜ì™€ ì¸ê¶Œì„ ìŸì·¨í•´ëƒˆìŠµë‹ˆë‹¤ ì˜¤ëŠ˜ì˜ ì°¸ì—¬ì •ë¶€ëŠ” ë°”ë¡œ ê·¸ ìœ„ëŒ€í•œ ì—­ì‚¬ì˜ ì—°ì¥ì„  ìœ„ì— ì„œ ìˆìŠµë‹ˆë‹¤ ì°¸ì—¬ì •ë¶€ì˜ ì¶œë²”ìœ¼ë¡œ ì´ì œ ì•„í””ì˜ ê·¼í˜„ëŒ€ì‚¬ëŠ” ë§‰ì„ ë‚´ë¦¬ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤ ìš°ë¦¬ì˜ ì§€ë‚œ ë‚ ì€ ì„ ì—´ë“¤ì˜ ê³ ê·€í•œ í¬ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ì¢Œì ˆê³¼ êµ´ì ˆì„ ê²ªì–´ì•¼ í–ˆìŠµë‹ˆë‹¤ ì •ì˜ëŠ” íŒ¨ë°°í–ˆê³  ê¸°íšŒì£¼ì˜ê°€ ë•ì„¸í–ˆìŠµë‹ˆë‹¤ ê·¸ëŸ¬ë‚˜ ì´ì œ ë¹„ë¡œì†Œ ì—­ì‚¬ì  ì „í™˜ì ì´ ë§ˆë ¨ëìŠµë‹ˆë‹¤ êµ­ë¯¼ì´ ì§„ì • ì£¼ì¸ìœ¼ë¡œ ëŒ€ì ‘ë°›ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤ ì°¸ì—¬ì •ë¶€ì—ì„œëŠ” ê¶Œë ¥ì˜ ì•„ë¶€í•˜ëŠ” ì‚¬ëŒë“¤ì´ ë” ì´ìƒ ì„¤ ë•…ì´ ì—†ì„ ê²ƒì…ë‹ˆë‹¤ ì˜¤ë¡œì§€ ì„±ì‹¤í•˜ê²Œ ì¼í•˜ê³  ì •ì •ë‹¹ë‹¹í•˜ê²Œ ì„ ê³ í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤ ê·¸ê²ƒì´ ë°”ë¡œ ì„ ì—´ë“¤ì˜ í¬ìƒì— ë³´ë‹µí•˜ëŠ” ê¸¸ì´ì ì €ì™€ ì°¸ì—¬ì •ë¶€ì—ê²Œ ì£¼ì–´ì§„ ì—­ì‚¬ì˜ ì†Œëª…ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤ ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ ì§€ê¸ˆ ìš°ë¦¬ëŠ” ì„¸ê³„ì‚¬ì˜ ìƒˆë¡œìš´ íë¦„ê³¼ ë§ˆì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤ ë™ë¶ì•„ ì‹œëŒ€ì˜ ë„ë˜ê°€ ë°”ë¡œ ê·¸ê²ƒì…ë‹ˆë‹¤ ë™ë¶ì•„ì‹œì•„ëŠ” ê·¼ëŒ€ ì´í›„ ì„¸ê³„ì˜ ë³€ë°©ìœ¼ë¡œë§Œ ë¨¸ë¬¼ëŸ¬ ì™”ìŠµë‹ˆë‹¤ ê·¸ëŸ¬ë‚˜ ì´ì œ ìœ ëŸ½ì—°í•©, ë¶ë¯¸ ì§€ì—­ê³¼ í•¨ê»˜ ì„¸ê³„ ê²½ì œì˜ 3ëŒ€ ì¶•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤ ì•ìœ¼ë¡œ 20ë…„ í›„ì—ëŠ” ì„¸ê³„ ê²½ì œì˜ 3ë¶„ì˜ 1ì„ ì°¨ì§€í•˜ê²Œ ëœë‹¤ëŠ” ì „ë§ë„ ìˆìŠµë‹ˆë‹¤ ë¯¼ì¡±ì›…ë¹„ì˜ í¬ë‚˜í° ê¸°íšŒê°€ ìš°ë¦¬ì—ê²Œ ë‹¤ê°€ì˜¤ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤ ìš°ë¦¬ëŠ” ë™ë¶ì•„ ì‹œëŒ€ì˜ ì¤‘ì‹¬êµ­ê°€ë¡œ ëŒì•„ê°ˆ ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ì¡°ê±´ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤ ìš°ì„  ì§€ë¦¬ì ìœ¼ë¡œ ì¤‘ì‹¬ì— ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤ ì„œìš¸ì—ì„œ 3ì‹œê°„ì˜ ë¹„í–‰ê±°ë¦¬ ì•ˆì— ì¸êµ¬ 100ë§Œ ì´ìƒì˜ ë„ì‹œê°€ 40ê°œë‚˜ ë©ë‹ˆë‹¤ ì¤‘êµ­ê³¼ ëŸ¬ì‹œì•„ì˜ ì¸ë ¥ê³¼ ìì› ê·¸ë¦¬ê³  ì¼ë³¸ì˜ ê¸°ìˆ ì„ ì ‘ëª©í•  ìˆ˜ ìˆëŠ” ìœ ë¦¬í•œ ìœ„ì¹˜ì— ì„œ ìˆìŠµë‹ˆë‹¤ ëŒ€ë¥™ê³¼ í•´ì–‘ì„ ì‡ëŠ” ì§€ì •í•™ì ì¸ ì´ì ë„ ì•„ìš¸ëŸ¬ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤ í•˜ëŠ˜ê³¼ ë°”ë‹¤ì™€ ë•…ì— ê±¸ì¹œ ë¬¼ë¥˜ì™€ ì„¸ê³„ ì¸ë¥˜ì˜ ì •ë³´ì™€ ê¸°ë°˜ê³¼ ì—­ëŸ‰ì„ ë‘ë£¨ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤ í•œë°˜ë„ëŠ” ë” ì´ìƒ ì„¸ê³„ì˜ ë³€ë°©ì´ ì•„ë‹™ë‹ˆë‹¤ ë‚¨ë¶ì² ë„ê°€ ì—°ê²°ë˜ê³  ì² ì˜ ì‹¤í¬ë¡œë“œê°€ ì—´ë¦¬ë©´ ê´‘í™œí•œ ëŒ€ë¥™ì„ í–¥í•´ì„œ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤ ì´ê³³ì—ëŠ” ì¤‘êµ­ ëŒ€ë¥™ì´ë¼ëŠ” ìƒˆë¡œìš´ ê¸°íšŒê°€ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤ ì‹œë² ë¦¬ì•„ì™€ ì¤‘ì•™ì•„ì‹œì•„ì˜ ë¬´í•œí•œ ìì›ë„ ìˆìŠµë‹ˆë‹¤ í•œë°˜ë„ê°€ ëŒ€ë¥™ê³¼ í•´ì–‘ì„ ì‡ëŠ” ë¬¼ë¥˜ì™€ ê¸ˆìœµê³¼ ìƒì‚°ì˜ ê±°ì ìœ¼ë¡œì„œ ê±°ë“­ë‚˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤ ì´ê²ƒì´ ë°”ë¡œ ìš°ë¦¬ ì•ì— ìˆëŠ” ë¯¸ë˜ì…ë‹ˆë‹¤ ìš°ë¦¬ì—ê²ŒëŠ” ì´ë¥¼ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ì±…ë¬´ê°€ ì£¼ì–´ì ¸ ìˆìŠµë‹ˆë‹¤ ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ ê·¸ëŸ¬ë‚˜ ë™ë¶ì•„ ì¤‘ì‹¬êµ­ê°€ë¡œ ë‚˜ì•„ê°€ê¸° ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ í•´ì•¼ í•  ì¼ì´ ìˆìŠµë‹ˆë‹¤ í•œë°˜ë„ì˜ í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ëŠ” ì¼ì…ë‹ˆë‹¤ ë‚¨ë¶ì´ ëŒ€ë¦½í•˜ë©° í•œë°˜ë„ì˜ ê¸´ì¥ì´ ê³ ì¡°ë˜ëŠ” í•œ ë™ë¶ì•„ ì¤‘ì‹¬êµ­ê°€ì˜ ê¿ˆì€ ì‹¤í˜„ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ë™ë¶ì•„ì˜ í‰í™”ì™€ ë²ˆì˜ë„ ê¸°ëŒ€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤ ê·¸ë™ì•ˆ ìš°ë¦¬ëŠ” í•œë°˜ë„ì˜ í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ê¸° ìœ„í•´ì„œ ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì—¬ ì™”ìŠµë‹ˆë‹¤ ë‚¨ë¶ ê°„ì˜ ëŒ€í™”ì™€ êµë¥˜ê°€ ë¹ˆë²ˆí•´ì¡Œê³  ì´ì‚°ê°€ì¡±ì´ ë§Œë‚˜ê³  ìˆìŠµë‹ˆë‹¤ ìµœê·¼ì—ëŠ” ìœ¡ë¡œë„ ì—´ë¦¬ê³  ìˆìŠµë‹ˆë‹¤ ê·¸ëŸ¬ë‚˜ ì•„ì§ í’€ì–´ì•¼ í•  ìˆ™ì œê°€ ë§ì´ ìˆìŠµë‹ˆë‹¤ íŠ¹íˆ ë¶í•œ í•µ ë¬¸ì œëŠ” ì‹œê¸‰íˆ í•´ê²°í•´ì•¼ í•  ê³¼ì œì…ë‹ˆë‹¤ ì €ëŠ” ë¶í•œì˜ í•µ ê°œë°œì— ë‹¨í˜¸íˆ ë°˜ëŒ€í•©ë‹ˆë‹¤ ê·¸ëŸ¬ë‚˜ ì´ ë¬¸ì œëŠ” ë°˜ë“œì‹œ í‰í™”ì ìœ¼ë¡œ í•´ê²°ë¼ì•¼ í•©ë‹ˆë‹¤ ì–´ë– í•œ ì´ìœ ë¡œë“  í•œë°˜ë„ì˜ í‰í™”ê°€ ê¹¨ì–´ì§„ë‹¤ë©´ ìš°ë¦¬ëŠ” ê·¸ ì—„ì²­ë‚œ ì¬ì•™ì„ ê°ë‹¹í•´ë‚¼ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤ í•œë°˜ë„ì˜ í‰í™”ì™€ êµ­ë¯¼ì˜ ì•ˆì „ì„ ì§€í‚¤ëŠ” ê²ƒì€ ëŒ€í†µë ¹ì˜ ê°€ì¥ í° ì±…ë¬´ì…ë‹ˆë‹¤ ì•ìœ¼ë¡œ ë‚¨ë¶ê´€ê³„ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ê»˜ í•˜ë‚˜í•˜ë‚˜ ì†Œìƒíˆ ë³´ê³ ë“œë¦¬ê³  êµ­ë¯¼ì  í•©ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì§„í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤ ì•¼ë‹¹ì˜ í˜‘ë ¥ë„ ì ê·¹ì ìœ¼ë¡œ êµ¬í•´ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤ ë¯¸êµ­ê³¼ ì¼ë³¸, ì¤‘êµ­, ëŸ¬ì‹œì•„ ë“± ì£¼ë³€êµ­ê³¼ ì´ìœ ë¥¼ ë¹„ë¡¯í•œ êµ­ì œì‚¬íšŒì™€ë„ ëŠ¥ë™ì ìœ¼ë¡œ í˜‘ë ¥í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤ ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ í•œë°˜ë„ì˜ í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ëŠ” ì¼ ëª»ì§€ì•Šê²Œ ì¤‘ìš”í•œ ê²ƒì€ êµ­ë¯¼ì˜ í˜ì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” ê²ƒì…ë‹ˆë‹¤ 84ë…„ ì „ ì˜¤ëŠ˜ ìš°ë¦¬ì˜ ì„ ì—´ë“¤ì€ í•œë§ˆìŒ í•œëœ»ìœ¼ë¡œ ë…ë¦½ìš´ë™ì— ë‚˜ì„°ìŠµë‹ˆë‹¤ ë¹ˆë¶€ì™€ ê·€ì²œ, ë‚¨ë…€ì™€ ë…¸ì†Œ, ì§€ì—­ê³¼ ì¢…êµì˜ ì°¨ì´ë„ ì—†ì—ˆìŠµë‹ˆë‹¤ ë‚˜ë¼ì˜ ë…ë¦½ê³¼ ë¯¼ì¡±ì˜ ìì¡´ì‹¬ì„ ë˜ì°¾ëŠ”ë° í•˜ë‚˜ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤ ì˜¤ëŠ˜ì„ ì‚¬ëŠ” ìš°ë¦¬ë„ ì§€ì—­ê³¼ ê³„ì¸µê³¼ ì„¸ëŒ€ë¥¼ ë„˜ì–´ì„œ í•˜ë‚˜ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ ë‚´ë¶€ì˜ ë¶„ì—´ê³¼ ë°˜ëª©ì´ ìˆìœ¼ë©´ ì„¸ê³„ ê²½ìŸì—ì„œ ë’¤ì²˜ì§ˆ ìˆ˜ë°–ì— ì—†ì„ ê²ƒì…ë‹ˆë‹¤ êµ­ê¶Œê¹Œì§€ ìƒì‹¤í–ˆë˜ 100ë…„ ì „ì˜ ì‹¤íŒ¨ê°€ ë˜í’€ì´ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ ê·¸ì•¼ë§ë¡œ 3.1 ì •ì‹ ì„ ë˜ëŒì•„ë³´ë©° ì—­ì‚¬ì˜ êµí›ˆì„ ë˜ìƒˆê²¨ì•¼ í•  ë•Œì…ë‹ˆë‹¤ ë§ˆìŒì†ì— ì§€ì—­ ê°ˆë“±ì˜ ì‘ì–´ë¦¬ê°€ ìˆë‹¤ë©´ ê°€ìŠ´ì„ ì—´ê³  í’€ì–´ì•¼ í•©ë‹ˆë‹¤ ì–´ë¥¸ì€ ì Šì€ì´ì˜ ëª©ì†Œë¦¬ë¥¼ ê·€ ê¸°ìš¸ì´ì‹œê³  ì Šì€ì´ëŠ” ì–´ë¥¸ë“¤ì˜ ê²½í—˜ì„ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤ ì°¨ë³„ë°›ê³  ì œê°€ ë°•ìˆ˜ì¹  ì‚¬ì˜ë¥¼ ë“œë¦¬ëŠ”ë° ìµìˆ™ì§€ë¥¼ ëª»í•©ë‹ˆë‹¤ ì°¨ë³„ë°›ê³  ì†Œì™¸ë˜ì–´ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ë” ë§ì€ ê´€ì‹¬ê³¼ ë…¸ë ¥ì„ ê¸°ìš¸ì—¬ì•¼ í•©ë‹ˆë‹¤ êµ­ë¯¼ ëª¨ë‘ê°€ ì°¸ëœ ì£¼ì¸ìœ¼ë¡œì„œ êµ­ì •ì— ì°¸ì—¬í•˜ê³  ì˜¨ êµ­ë¯¼ì˜ í˜ì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” êµ­ë¯¼ì°¸ì—¬ì‹œëŒ€ë¥¼ í˜ì°¨ê²Œ ì—´ì–´ê°€ì•¼ê² ìŠµë‹ˆë‹¤ ê°œí˜ ë˜í•œ ë©ˆì¶œ ìˆ˜ ì—†ëŠ” ìš°ë¦¬ ì‹œëŒ€ì˜ ê³¼ì œì…ë‹ˆë‹¤ ë¬´ì—‡ë³´ë‹¤ë„ ì •ì¹˜ì™€ í–‰ì •ì´ ë°”ë€Œì–´ì•¼ í•©ë‹ˆë‹¤ ì´ë¥¸ë°” ëª‡ëª‡ ê¶Œë ¥ê¸°ê´€ì€ ê·¸ë™ì•ˆì— ì •ê¶Œì„ ìœ„í•´ ë´‰ì‚¬í•´ì™”ë˜ ê²ƒì´ ì‚¬ì‹¤ì…ë‹ˆë‹¤ ê·¸ë˜ì„œ ë‚´ë¶€ì˜ ì§ˆì„œê°€ ë¬´ë„ˆì§€ê³  êµ­ë¯¼ì˜ ì‹ ë¢°ë¥¼ ìƒì—ˆìŠµë‹ˆë‹¤ ì´ì œ ì´ë“¤ ê¶Œë ¥ê¸°ê´€ì€ êµ­ë¯¼ì„ ìœ„í•œ ê¸°ê´€ìœ¼ë¡œ ë‹¤ì‹œ íƒœì–´ë‚˜ì•¼ í•©ë‹ˆë‹¤ ì°¸ì—¬ì •ë¶€ëŠ” ë” ì´ìƒ ê¶Œë ¥ê¸°ê´€ì— ì˜ì¡´í•˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤ ì–¸ì œë‚˜ ì •ì •ë‹¹ë‹¹í•œ ì •ë¶€ë¡œì„œ êµ­ë¯¼ ì•ì— ì„¤ ê²ƒì…ë‹ˆë‹¤ ì°¸ì—¬ì •ë¶€ëŠ” ê³µì •í•˜ê³  íˆ¬ëª…í•œ ì‹œì¥ì§ˆì„œì™€ ë…¸ì‚¬í™”í•©, ê¸°ìˆ í˜ì‹ , ì§€ì—­ì˜ ê· í˜•ë°œì „ ì†ì— ì •ì§í•˜ê³  ì„±ì‹¤í•˜ê²Œ ì‚¬ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ë‚˜ë¼ë¥¼ ë§Œë“¤ì–´ê°ˆ ê²ƒì…ë‹ˆë‹¤ ì´ë¥¼ ìœ„í•´ì„œ ì›ì¹™ê³¼ ì‹ ë¢°, ê³µì •ê³¼ íˆ¬ëª…, ëŒ€í™”ì™€ íƒ€í˜‘ ê·¸ë¦¬ê³  ë¶„ê¶Œê³¼ ììœ¨ì˜ ë¬¸í™”ë¥¼ ì‚¬íšŒ ê³³ê³³ì— ë¿Œë¦¬ë‚´ë¦´ ê²ƒì…ë‹ˆë‹¤ ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ ìš°ë¦¬ì—ê²ŒëŠ” ì„ ì—´ë“¤ì´ ë³´ì—¬ì¤€ ìì£¼ë…ë¦½ì˜ ê¸°ìƒê³¼ ëŒ€ë™ë‹¨ê²°ì˜ ì§€í˜œê°€ ìˆìŠµë‹ˆë‹¤ ì˜¤ëŠ˜ 3.1ì ˆì„ ë§ì•„ 1ì ˆì˜ ì´ì¹¼ì— í•­ê±°í•˜ë©° ì´ë£¨ê³ ì í–ˆë˜ ì„ ì—´ë“¤ì˜ ëœ»ì„ ë‹¤ì‹œ í•œë²ˆ ê°€ìŠ´ì— ìƒˆê¹ì‹œë‹¤ êµ­ë¯¼ í†µí•©ê³¼ ê°œí˜ìœ¼ë¡œ í‰í™”ì™€ ë²ˆì˜ì˜ ë™ë¶ì•„ ì‹œëŒ€ë¥¼ ì—´ì–´ê°‘ì‹œë‹¤ ìë‘ìŠ¤ëŸ° ëŒ€í•œë¯¼êµ­ì„ ìš°ë¦¬ í›„ì†ë“¤ì—ê²Œ ë¬¼ë ¤ì¤ì‹œë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤\"\n\n\n\n\n\n\n\n\n\n\ní”„ë¡¬í”„íŠ¸: ë‹¤ìŒ í…ìŠ¤íŠ¸ì— êµ¬ë‘ì ì„ ë„£ê³  ë¬¸ë‹¨ë³„ë¡œ ë‚˜ëˆ  ê°€ë…ì„±ì„ ë†’í˜€ì£¼ì„¸ìš”.  â€œì¡´ê²½í•˜ëŠ” êµ­ë¯¼ì—¬ëŸ¬ë¶„ ì˜¤ëŠ˜ 84ë²ˆì§¸ ..&lt;ì¤‘ëµ&gt;.. ë¬¼ë ¤ì¤ì‹œë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤â€\n\n\n\nâ€œì¡´ê²½í•˜ëŠ” êµ­ë¯¼ì—¬ëŸ¬ë¶„, ì˜¤ëŠ˜ 84ë²ˆì§¸ 3.1ì ˆì„ ë§ì•„, ë‚˜ë¼ë¥¼ ìœ„í•´ í¬ìƒí•˜ê³  í—Œì‹ í•˜ì‹  ì• êµ­ì„ ì—´ë“¤ê»˜ í•œì—†ëŠ” ê°ì‚¬ì™€ ê²½ì˜ë¥¼ í‘œí•©ë‹ˆë‹¤. ë…ë¦½ìœ ê³µìì™€ ìœ ê°€ì¡± ì—¬ëŸ¬ë¶„ì—ê²Œë„ ì¡´ê²½ê³¼ ê°ì‚¬ì˜ ë§ì”€ì„ ë“œë¦½ë‹ˆë‹¤.\n3.1 1922ë…„ ì˜¤ëŠ˜, ìš°ë¦¬ëŠ” ì¼ì œì˜ ì´ì¹¼ì— ë§ì„œ ë§¨ì£¼ë¨¹ìœ¼ë¡œ ë¶„ì—°íˆ ì¼ì–´ì„°ìŠµë‹ˆë‹¤. ëŒ€í•œë…ë¦½ë§Œì„¸ ì†Œë¦¬ê°€ ì „êµ­ ë°©ë°©ê³¡ê³¡ì„ ë’¤ë®ì—ˆê³ , ìš°ë¦¬ëŠ” ìì£¼ë…ë¦½ì˜ì§€ë¥¼ ì„¸ê³„ ë§Œë°©ì— ì•Œë ¸ìŠµë‹ˆë‹¤. 3.1ìš´ë™ì„ ê³„ê¸°ë¡œ êµ­ë‚´ì™¸ì˜ ë…ë¦½íˆ¬ìŸì€ ë”ìš± í˜ì°¨ê²Œ ì „ê°œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒí•´ ëŒ€í•œë¯¼êµ­ ì„ì‹œì •ë¶€ê°€ ì„¸ì›Œì¡Œê³ , ìš°ë¦¬ëŠ” ë§ˆì¹¨ë‚´ ë¹¼ì•—ê¸´ êµ­ê¶Œì„ ë˜ì°¾ì•˜ìŠµë‹ˆë‹¤.\n3.1ì •ì‹ ì€ ëŠì„ì—†ëŠ” ë„ì „ì„ ìŠ¬ê¸°ë¡­ê²Œ ê·¹ë³µí•´ì˜¨ ìš°ë¦¬ ë¯¼ì¡±ì˜ ìë‘ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë¹›ë‚˜ëŠ” ì •ì‹ ì„ ê³„ìŠ¹í•˜ì—¬ ì „ìŸì˜ íí—ˆë¥¼ ë”›ê³  ì„¸ê³„ 12ìœ„ì˜ ê²½ì œê°•êµ­ìœ¼ë¡œ ë°œë‹ì›€í–ˆìŠµë‹ˆë‹¤. 4.19í˜ëª…ê³¼ ê´‘ì£¼ë¯¼ì£¼í™”ìš´ë™, 6ì›” ë¯¼ì£¼í•­ìŸì„ ê±°ì³ì„œ ë¯¼ì£¼ì£¼ì˜ì™€ ì¸ê¶Œì„ ìŸì·¨í•´ëƒˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ì°¸ì—¬ì •ë¶€ëŠ” ë°”ë¡œ ê·¸ ìœ„ëŒ€í•œ ì—­ì‚¬ì˜ ì—°ì¥ì„  ìœ„ì— ì„œ ìˆìŠµë‹ˆë‹¤.\nì°¸ì—¬ì •ë¶€ì˜ ì¶œë²”ìœ¼ë¡œ, ì´ì œ ì•„í””ì˜ ê·¼í˜„ëŒ€ì‚¬ëŠ” ë§‰ì„ ë‚´ë¦¬ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì§€ë‚œ ë‚ ì€ ì„ ì—´ë“¤ì˜ ê³ ê·€í•œ í¬ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ì¢Œì ˆê³¼ êµ´ì ˆì„ ê²ªì–´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì •ì˜ëŠ” íŒ¨ë°°í–ˆê³  ê¸°íšŒì£¼ì˜ê°€ ë•ì„¸í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì œ ë¹„ë¡œì†Œ ì—­ì‚¬ì  ì „í™˜ì ì´ ë§ˆë ¨ëìŠµë‹ˆë‹¤. êµ­ë¯¼ì´ ì§„ì • ì£¼ì¸ìœ¼ë¡œ ëŒ€ì ‘ë°›ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤. ì°¸ì—¬ì •ë¶€ì—ì„œëŠ” ê¶Œë ¥ì˜ ì•„ë¶€í•˜ëŠ” ì‚¬ëŒë“¤ì´ ë” ì´ìƒ ì„¤ ë•…ì´ ì—†ì„ ê²ƒì…ë‹ˆë‹¤. ì˜¤ë¡œì§€ ì„±ì‹¤í•˜ê²Œ ì¼í•˜ê³  ì •ì •ë‹¹ë‹¹í•˜ê²Œ ì„ ê³ í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤. ê·¸ê²ƒì´ ë°”ë¡œ ì„ ì—´ë“¤ì˜ í¬ìƒì— ë³´ë‹µí•˜ëŠ” ê¸¸ì´ì, ì €ì™€ ì°¸ì—¬ì •ë¶€ì—ê²Œ ì£¼ì–´ì§„ ì—­ì‚¬ì˜ ì†Œëª…ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.\nì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„, ì§€ê¸ˆ ìš°ë¦¬ëŠ” ì„¸ê³„ì‚¬ì˜ ìƒˆë¡œìš´ íë¦„ê³¼ ë§ˆì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë™ë¶ì•„ ì‹œëŒ€ì˜ ë„ë˜ê°€ ë°”ë¡œ ê·¸ê²ƒì…ë‹ˆë‹¤. ë™ë¶ì•„ì‹œì•„ëŠ” ê·¼ëŒ€ ì´í›„ ì„¸ê³„ì˜ ë³€ë°©ìœ¼ë¡œë§Œ ë¨¸ë¬¼ëŸ¬ ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì œ ìœ ëŸ½ì—°í•©, ë¶ë¯¸ ì§€ì—­ê³¼ í•¨ê»˜ ì„¸ê³„ ê²½ì œì˜ 3ëŒ€ ì¶•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ 20ë…„ í›„ì—ëŠ” ì„¸ê³„ ê²½ì œì˜ 3ë¶„ì˜ 1ì„ ì°¨ì§€í•˜ê²Œ ëœë‹¤ëŠ” ì „ë§ë„ ìˆìŠµë‹ˆë‹¤.\në¯¼ì¡±ì›…ë¹„ì˜ í¬ë‚˜í° ê¸°íšŒê°€ ìš°ë¦¬ì—ê²Œ ë‹¤ê°€ì˜¤ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë™ë¶ì•„ ì‹œëŒ€ì˜ ì¤‘ì‹¬êµ­ê°€ë¡œ ëŒì•„ê°ˆ ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ì¡°ê±´ë“¤ì˜ ê¿ˆì„ ìƒê°í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ë•…ì— ê±´ì„¤í•œ ììœ ì™€ í‰í™”, ë…ë¦½ê³¼ ë¯¼ì£¼ì£¼ì˜ì˜ ì‹ ì„±í•œ ê¿ˆì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê·¸ ê¿ˆì„ ê³„ìŠ¹í•˜ê³  ì´ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.\nì°¸ì—¬ì •ë¶€ëŠ” ëª¨ë“  ì¼ì„ êµ­ë¯¼ê³¼ í•¨ê»˜ í•  ê²ƒì…ë‹ˆë‹¤. ì–´ë ¤ìš´ ì¼ì—ë„ í•¨ê»˜ ì°¸ì—¬í•˜ê³ , í¬ë§ì„ ë‚˜ëˆ„ëŠ” ì¼ì—ë„ í•¨ê»˜ ì°¸ì—¬í•˜ê² ìŠµë‹ˆë‹¤. ì •ì˜ë¥¼ ìœ„í•´ í•¨ê»˜ ì„œê³ , ê¸°íšŒë¥¼ ìœ„í•´ í•¨ê»˜ íˆ¬ìŸí•˜ê² ìŠµë‹ˆë‹¤. ë°”ë¡œ ê·¸ê²ƒì´ ì°¸ì—¬ì •ë¶€ì˜ ì´ë…ì´ê³  ì‹¤ì²œì˜ ë°©í–¥ì…ë‹ˆë‹¤.\nëª¨ë“  êµ­ë¯¼ì´ ì°¸ì—¬í•˜ëŠ” ë¯¼ì£¼ì£¼ì˜, ê·¸ê²ƒì´ ë°”ë¡œ ì°¸ì—¬ì •ë¶€ì˜ ë¯¼ì£¼ì£¼ì˜ì…ë‹ˆë‹¤. ëŒ€í†µë ¹ìœ¼ë¡œì„œ ì œê²Œ ì£¼ì–´ì§„ ì—­ì‚¬ì˜ ì†Œëª…ì„ ë‹¤í•  ê²ƒì…ë‹ˆë‹¤. êµ­ë¯¼ì´ ì£¼ì¸ì´ ë˜ëŠ” ì°¸ì—¬ì •ë¶€, ê·¸ê²ƒì„ ë§Œë“¤ì–´ ê°€ê² ìŠµë‹ˆë‹¤. êµ­ë¯¼ ì—¬ëŸ¬ë¶„ì˜ ë„ì›€ê³¼ í˜‘ë ¥ì´ ì ˆì‹¤íˆ í•„ìš”í•©ë‹ˆë‹¤.\nêµ­ë¯¼ ì—¬ëŸ¬ë¶„, ì˜¤ëŠ˜ 3.1ì ˆì„ ë§ì•„ ì´ ìë¦¬ì— í•¨ê»˜ í•´ì£¼ì‹  ë° ëŒ€í•´ ê¹Šì€ ê°ì‚¬ì˜ ë§ì”€ì„ ë“œë¦½ë‹ˆë‹¤. ìš°ë¦¬ ëª¨ë‘ê°€ ë™í–‰í•˜ë©°, ì„ ì—´ë“¤ì˜ ê¿ˆì„ ì´ë£¨ì–´ ë‚˜ê°€ëŠ” í° í•œ ê±¸ìŒì„ ë‚´ë”›ì„ ìˆ˜ ìˆê¸°ë¥¼ ê¸°ì›í•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n\n\n\n\ngpt-4, íŠ¹íˆ gpt-4-0314 ëª¨í˜•ì„ ì‚¬ìš©í•˜ì—¬ APIë¡œ ì•ì„œ Whisperë¡œ STTí•˜ì—¬ ë°›ì•„ì“°ê¸°í•œ ì‚¬í•­ì„ ìœ¤ë¬¸í•˜ì—¬ ì—°ì„¤ë¬¸ì„ ë³´ê¸° ì¢‹ê²Œ ë‹¤ì‹œ ì‘ì„±í•œë‹¤.\n\nì½”ë“œimport openai\nfrom dotenv import load_dotenv\nimport os\n\n# API KEY ----------------------\nload_dotenv()\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\n# í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° --------------------------\nwith open(\"data/stt_audio.txt\", \"r\") as file:\n    content = file.read()\n\nprint(content)\n\n# í…ìŠ¤íŠ¸ ìœ¤ë¬¸ --------------------------\n\nprompt = f'ë‹¤ìŒ í…ìŠ¤íŠ¸ì— êµ¬ë‘ì ì„ ë„£ê³  ë¬¸ë‹¨ë³„ë¡œ ë‚˜ëˆ  ê°€ë…ì„±ì„ ë†’í˜€ì£¼ì„¸ìš”. \\n\\n{content}'\n\nspeech_response = openai.ChatCompletion.create(\n  model       = \"gpt-4-0314\",\n  messages    = [\n    {\"role\": \"system\", \"content\": \"You are a Korean language expert.\"},\n    {\"role\": \"user\", \"content\": prompt}\n  ],\n  max_tokens   = 5000,\n  temperature  = 0\n)\n\nprint(speech_response[\"choices\"][0]['message']['content'])\n\nwith open(\"data/stt_audio_gpt4.txt\", \"w\") as file:\n    file.write(speech_response[\"choices\"][0]['message']['content'])\n\n\n\nì½”ë“œgpt4_txt &lt;- read_lines(\"data/stt_audio_gpt4.txt\")\n\nglue::glue(\"{gpt4_txt}\")\n#&gt; ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ì—¬ëŸ¬ë¶„, ì˜¤ëŠ˜ 84ë²ˆì§¸ 3.1ì ˆì„ ë§ì•„ ë‚˜ë¼ë¥¼ ìœ„í•´ í¬ìƒí•˜ê³  í—Œì‹ í•˜ì‹  ì• êµ­ì„ ì—´ë“¤ê»˜ í•œì—†ëŠ” ê°ì‚¬ì™€ ê²½ì˜ë¥¼ í‘œí•©ë‹ˆë‹¤. ë…ë¦½ìœ ê³µìì™€ ìœ ê°€ì¡± ì—¬ëŸ¬ë¶„ì—ê²Œë„ ì¡´ê²½ê³¼ ê°ì‚¬ì˜ ë§ì”€ì„ ë“œë¦½ë‹ˆë‹¤.\n#&gt; \n#&gt; 3.1ìš´ë™ 102ë…„ ì „ ì˜¤ëŠ˜, ìš°ë¦¬ëŠ” ì¼ì œì˜ ì´ì¹¼ì— ë§ì„œ ë§¨ì£¼ë¨¹ìœ¼ë¡œ ë¶„ì—°íˆ ì¼ì–´ì„°ìŠµë‹ˆë‹¤. ëŒ€í•œë…ë¦½ë§Œì„¸ ì†Œë¦¬ê°€ ì „êµ­ ë°©ë°©ê³¡ê³¡ì„ ë’¤ë®ì—ˆê³ , ìš°ë¦¬ëŠ” ìì£¼ë…ë¦½ì˜ì§€ë¥¼ ì„¸ê³„ ë§Œë°©ì— ì•Œë ¸ìŠµë‹ˆë‹¤. 3.1ìš´ë™ì„ ê³„ê¸°ë¡œ êµ­ë‚´ì™¸ì˜ ë…ë¦½íˆ¬ìŸì€ ë”ìš± í˜ì°¨ê²Œ ì „ê°œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒí•´ ëŒ€í•œë¯¼êµ­ ì„ì‹œì •ë¶€ê°€ ì„¸ì›Œì¡Œê³ , ìš°ë¦¬ëŠ” ë§ˆì¹¨ë‚´ ë¹¼ì•—ê¸´ êµ­ê¶Œì„ ë˜ì°¾ì•˜ìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; 3.1ì •ì‹ ì€ ëŠì„ì—†ëŠ” ë„ì „ì„ ìŠ¬ê¸°ë¡­ê²Œ ê·¹ë³µí•´ì˜¨ ìš°ë¦¬ ë¯¼ì¡±ì˜ ìë‘ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë¹›ë‚˜ëŠ” ì •ì‹ ì„ ê³„ìŠ¹í•˜ì—¬ ì „ìŸì˜ íí—ˆë¥¼ ë”›ê³  ì„¸ê³„ 12ìœ„ì˜ ê²½ì œê°•êµ­ìœ¼ë¡œ ë°œë‹ì›€í–ˆìŠµë‹ˆë‹¤. 4.19í˜ëª…ê³¼ ê´‘ì£¼ë¯¼ì£¼í™”ìš´ë™, 6ì›” ë¯¼ì£¼í•­ìŸì„ ê±°ì³ì„œ ë¯¼ì£¼ì£¼ì˜ì™€ ì¸ê¶Œì„ ìŸì·¨í•´ëƒˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ì°¸ì—¬ì •ë¶€ëŠ” ë°”ë¡œ ê·¸ ìœ„ëŒ€í•œ ì—­ì‚¬ì˜ ì—°ì¥ì„  ìœ„ì— ì„œ ìˆìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; ì°¸ì—¬ì •ë¶€ì˜ ì¶œë²”ìœ¼ë¡œ ì´ì œ ì•„í””ì˜ ê·¼í˜„ëŒ€ì‚¬ëŠ” ë§‰ì„ ë‚´ë¦¬ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì§€ë‚œ ë‚ ì€ ì„ ì—´ë“¤ì˜ ê³ ê·€í•œ í¬ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ì¢Œì ˆê³¼ êµ´ì ˆì„ ê²ªì–´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì •ì˜ëŠ” íŒ¨ë°°í–ˆê³  ê¸°íšŒì£¼ì˜ê°€ ë•ì„¸í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì œ ë¹„ë¡œì†Œ ì—­ì‚¬ì  ì „í™˜ì ì´ ë§ˆë ¨ëìŠµë‹ˆë‹¤. êµ­ë¯¼ì´ ì§„ì • ì£¼ì¸ìœ¼ë¡œ ëŒ€ì ‘ë°›ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤. ì°¸ì—¬ì •ë¶€ì—ì„œëŠ” ê¶Œë ¥ì˜ ì•„ë¶€í•˜ëŠ” ì‚¬ëŒë“¤ì´ ë” ì´ìƒ ì„¤ ë•…ì´ ì—†ì„ ê²ƒì…ë‹ˆë‹¤. ì˜¤ë¡œì§€ ì„±ì‹¤í•˜ê²Œ ì¼í•˜ê³  ì •ì •ë‹¹ë‹¹í•˜ê²Œ ì„ ê³ í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ì‹œëŒ€ê°€ ì—´ë¦´ ê²ƒì…ë‹ˆë‹¤. ê·¸ê²ƒì´ ë°”ë¡œ ì„ ì—´ë“¤ì˜ í¬ìƒì— ë³´ë‹µí•˜ëŠ” ê¸¸ì´ì ì €ì™€ ì°¸ì—¬ì •ë¶€ì—ê²Œ ì£¼ì–´ì§„ ì—­ì‚¬ì˜ ì†Œëª…ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.\n#&gt; \n#&gt; ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„, ì§€ê¸ˆ ìš°ë¦¬ëŠ” ì„¸ê³„ì‚¬ì˜ ìƒˆë¡œìš´ íë¦„ê³¼ ë§ˆì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë™ë¶ì•„ ì‹œëŒ€ì˜ ë„ë˜ê°€ ë°”ë¡œ ê·¸ê²ƒì…ë‹ˆë‹¤. ë™ë¶ì•„ì‹œì•„ëŠ” ê·¼ëŒ€ ì´í›„ ì„¸ê³„ì˜ ë³€ë°©ìœ¼ë¡œë§Œ ë¨¸ë¬¼ëŸ¬ ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì œ ìœ ëŸ½ì—°í•©, ë¶ë¯¸ ì§€ì—­ê³¼ í•¨ê»˜ ì„¸ê³„ ê²½ì œì˜ 3ëŒ€ ì¶•ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ 20ë…„ í›„ì—ëŠ” ì„¸ê³„ ê²½ì œì˜ 3ë¶„ì˜ 1ì„ ì°¨ì§€í•˜ê²Œ ëœë‹¤ëŠ” ì „ë§ë„ ìˆìŠµë‹ˆë‹¤. ë¯¼ì¡±ì›…ë¹„ì˜ í¬ë‚˜í° ê¸°íšŒê°€ ìš°ë¦¬ì—ê²Œ ë‹¤ê°€ì˜¤ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.\n#&gt; \n#&gt; ìš°ë¦¬ëŠ” ë™ë¶ì•„ ì‹œëŒ€ì˜ ì¤‘ì‹¬êµ­ê°€ë¡œ ëŒì•„ê°ˆ ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ì¡°ê±´ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤. ìš°ì„  ì§€ë¦¬ì ìœ¼ë¡œ ì¤‘ì‹¬ì— ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤. ì„œìš¸ì—ì„œ 3ì‹œê°„ì˜ ë¹„í–‰ê±°ë¦¬ ì•ˆì— ì¸êµ¬ 100ë§Œ ì´ìƒì˜ ë„ì‹œê°€ 40ê°œë‚˜ ë©ë‹ˆë‹¤. ì¤‘êµ­ê³¼ ëŸ¬ì‹œì•„ì˜ ì¸ë ¥ê³¼ ìì› ê·¸ë¦¬ê³  ì¼ë³¸ì˜ ê¸°ìˆ ì„ ì ‘ëª©í•  ìˆ˜ ìˆëŠ” ìœ ë¦¬í•œ ìœ„ì¹˜ì— ì„œ ìˆìŠµë‹ˆë‹¤. ëŒ€ë¥™ê³¼ í•´ì–‘ì„ ì‡ëŠ” ì§€ì •í•™ì ì¸ ì´ì ë„ ì•„ìš¸ëŸ¬ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•˜ëŠ˜ê³¼ ë°”ë‹¤ì™€ ë•…ì— ê±¸ì¹œ ë¬¼ë¥˜ì™€ ì„¸ê³„ ì¸ë¥˜ì˜ ì •ë³´ì™€ ê¸°ë°˜ê³¼ ì—­ëŸ‰ì„ ë‘ë£¨ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; í•œë°˜ë„ëŠ” ë” ì´ìƒ ì„¸ê³„ì˜ ë³€ë°©ì´ ì•„ë‹™ë‹ˆë‹¤. ë‚¨ë¶ì² ë„ê°€ ì—°ê²°ë˜ê³  ì² ì˜ ì‹¤í¬ë¡œë“œê°€ ì—´ë¦¬ë©´ ê´‘í™œí•œ ëŒ€ë¥™ì„ í–¥í•´ì„œ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê³³ì—ëŠ” ì¤‘êµ­ ëŒ€ë¥™ì´ë¼ëŠ” ìƒˆë¡œìš´ ê¸°íšŒê°€ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ì‹œë² ë¦¬ì•„ì™€ ì¤‘ì•™ì•„ì‹œì•„ì˜ ë¬´í•œí•œ ìì›ë„ ìˆìŠµë‹ˆë‹¤. í•œë°˜ë„ê°€ ëŒ€ë¥™ê³¼ í•´ì–‘ì„ ì‡ëŠ” ë¬¼ë¥˜ì™€ ê¸ˆìœµê³¼ ìƒì‚°ì˜ ê±°ì ìœ¼ë¡œì„œ ê±°ë“­ë‚˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ ìš°ë¦¬ ì•ì— ìˆëŠ” ë¯¸ë˜ì…ë‹ˆë‹¤. ìš°ë¦¬ì—ê²ŒëŠ” ì´ë¥¼ í˜„ì‹¤ë¡œ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ì±…ë¬´ê°€ ì£¼ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„, ê·¸ëŸ¬ë‚˜ ë™ë¶ì•„ ì¤‘ì‹¬êµ­ê°€ë¡œ ë‚˜ì•„ê°€ê¸° ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ í•´ì•¼ í•  ì¼ì´ ìˆìŠµë‹ˆë‹¤. í•œë°˜ë„ì˜ í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ëŠ” ì¼ì…ë‹ˆë‹¤. ë‚¨ë¶ì´ ëŒ€ë¦½í•˜ë©° í•œë°˜ë„ì˜ ê¸´ì¥ì´ ê³ ì¡°ë˜ëŠ” í•œ ë™ë¶ì•„ ì¤‘ì‹¬êµ­ê°€ì˜ ê¿ˆì€ ì‹¤í˜„ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë™ë¶ì•„ì˜ í‰í™”ì™€ ë²ˆì˜ë„ ê¸°ëŒ€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; ê·¸ë™ì•ˆ ìš°ë¦¬ëŠ” í•œë°˜ë„ì˜ í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ê¸° ìœ„í•´ì„œ ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì—¬ ì™”ìŠµë‹ˆë‹¤. ë‚¨ë¶ ê°„ì˜ ëŒ€í™”ì™€ êµë¥˜ê°€ ë¹ˆë²ˆí•´ì¡Œê³  ì´ì‚°ê°€ì¡±ì´ ë§Œë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ìœ¡ë¡œë„ ì—´ë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì•„ì§ í’€ì–´ì•¼ í•  ìˆ™ì œê°€ ë§ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë¶í•œ í•µ ë¬¸ì œëŠ” ì‹œê¸‰íˆ í•´ê²°í•´ì•¼ í•  ê³¼ì œì…ë‹ˆë‹¤. ì €ëŠ” ë¶í•œì˜ í•µ ê°œë°œì— ë‹¨í˜¸íˆ ë°˜ëŒ€í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë¬¸ì œëŠ” ë°˜ë“œì‹œ í‰í™”ì ìœ¼ë¡œ í•´ê²°ë¼ì•¼ í•©ë‹ˆë‹¤. ì–´ë– í•œ ì´ìœ ë¡œë“  í•œë°˜ë„ì˜ í‰í™”ê°€ ê¹¨ì–´ì§„ë‹¤ë©´ ìš°ë¦¬ëŠ” ê·¸ ì—„ì²­ë‚œ ì¬ì•™ì„ ê°ë‹¹í•´ë‚¼ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; í•œë°˜ë„ì˜ í‰í™”ì™€ êµ­ë¯¼ì˜ ì•ˆì „ì„ ì§€í‚¤ëŠ” ê²ƒì€ ëŒ€í†µë ¹ì˜ ê°€ì¥ í° ì±…ë¬´ì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ ë‚¨ë¶ê´€ê³„ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„ê»˜ í•˜ë‚˜í•˜ë‚˜ ì†Œìƒíˆ ë³´ê³ ë“œë¦¬ê³  êµ­ë¯¼ì  í•©ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì§„í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤. ì•¼ë‹¹ì˜ í˜‘ë ¥ë„ ì ê·¹ì ìœ¼ë¡œ êµ¬í•´ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤. ë¯¸êµ­ê³¼ ì¼ë³¸, ì¤‘êµ­, ëŸ¬ì‹œì•„ ë“± ì£¼ë³€êµ­ê³¼ ì´ìœ ë¥¼ ë¹„ë¡¯í•œ êµ­ì œì‚¬íšŒì™€ë„ ëŠ¥ë™ì ìœ¼ë¡œ í˜‘ë ¥í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„, í•œë°˜ë„ì˜ í‰í™”ë¥¼ ì •ì°©ì‹œí‚¤ëŠ” ì¼ ëª»ì§€ì•Šê²Œ ì¤‘ìš”í•œ ê²ƒì€ êµ­ë¯¼ì˜ í˜ì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” ê²ƒì…ë‹ˆë‹¤. 84ë…„ ì „ ì˜¤ëŠ˜ ìš°ë¦¬ì˜ ì„ ì—´ë“¤ì€ í•œë§ˆìŒ í•œëœ»ìœ¼ë¡œ ë…ë¦½ìš´ë™ì— ë‚˜ì„°ìŠµë‹ˆë‹¤. ë¹ˆë¶€ì™€ ê·€ì²œ, ë‚¨ë…€ì™€ ë…¸ì†Œ, ì§€ì—­ê³¼ ì¢…êµì˜ ì°¨ì´ë„ ì—†ì—ˆìŠµë‹ˆë‹¤. ë‚˜ë¼ì˜ ë…ë¦½ê³¼ ë¯¼ì¡±ì˜ ìì¡´ì‹¬ì„ ë˜ì°¾ëŠ”ë° í•˜ë‚˜ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; ì˜¤ëŠ˜ì„ ì‚¬ëŠ” ìš°ë¦¬ë„ ì§€ì—­ê³¼ ê³„ì¸µê³¼ ì„¸ëŒ€ë¥¼ ë„˜ì–´ì„œ í•˜ë‚˜ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë‚´ë¶€ì˜ ë¶„ì—´ê³¼ ë°˜ëª©ì´ ìˆìœ¼ë©´ ì„¸ê³„ ê²½ìŸì—ì„œ ë’¤ì²˜ì§ˆ ìˆ˜ë°–ì— ì—†ì„ ê²ƒì…ë‹ˆë‹¤. êµ­ê¶Œê¹Œì§€ ìƒì‹¤í–ˆë˜ 100ë…„ ì „ì˜ ì‹¤íŒ¨ê°€ ë˜í’€ì´ ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ì•¼ë§ë¡œ 3.1 ì •ì‹ ì„ ë˜ëŒì•„ë³´ë©° ì—­ì‚¬ì˜ êµí›ˆì„ ë˜ìƒˆê²¨ì•¼ í•  ë•Œì…ë‹ˆë‹¤.\n#&gt; \n#&gt; ë§ˆìŒì†ì— ì§€ì—­ ê°ˆë“±ì˜ ì‘ì–´ë¦¬ê°€ ìˆë‹¤ë©´ ê°€ìŠ´ì„ ì—´ê³  í’€ì–´ì•¼ í•©ë‹ˆë‹¤. ì–´ë¥¸ì€ ì Šì€ì´ì˜ ëª©ì†Œë¦¬ë¥¼ ê·€ ê¸°ìš¸ì´ì‹œê³  ì Šì€ì´ëŠ” ì–´ë¥¸ë“¤ì˜ ê²½í—˜ì„ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤. ì°¨ë³„ë°›ê³  ì œê°€ ë°•ìˆ˜ì¹  ì‚¬ì˜ë¥¼ ë“œë¦¬ëŠ”ë° ìµìˆ™ì§€ë¥¼ ëª»í•©ë‹ˆë‹¤. ì°¨ë³„ë°›ê³  ì†Œì™¸ë˜ì–´ ì˜¨ ì‚¬ëŒë“¤ì—ê²Œ ë” ë§ì€ ê´€ì‹¬ê³¼ ë…¸ë ¥ì„ ê¸°ìš¸ì—¬ì•¼ í•©ë‹ˆë‹¤. êµ­ë¯¼ ëª¨ë‘ê°€ ì°¸ëœ ì£¼ì¸ìœ¼ë¡œì„œ êµ­ì •ì— ì°¸ì—¬í•˜ê³  ì˜¨ êµ­ë¯¼ì˜ í˜ì„ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” êµ­ë¯¼ì°¸ì—¬ì‹œëŒ€ë¥¼ í˜ì°¨ê²Œ ì—´ì–´ê°€ì•¼ê² ìŠµë‹ˆë‹¤.\n#&gt; \n#&gt; ê°œí˜ ë˜í•œ ë©ˆì¶œ ìˆ˜ ì—†ëŠ” ìš°ë¦¬ ì‹œëŒ€ì˜ ê³¼ì œì…ë‹ˆë‹¤. ë¬´ì—‡ë³´ë‹¤ë„ ì •ì¹˜ì™€ í–‰ì •ì´ ë°”ë€Œì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¸ë°” ëª‡ëª‡ ê¶Œë ¥ê¸°ê´€ì€ ê·¸ë™ì•ˆì— ì •ê¶Œì„ ìœ„í•´ ë´‰ì‚¬í•´ì™”ë˜ ê²ƒì´ ì‚¬ì‹¤ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ë‚´ë¶€ì˜ ì§ˆì„œê°€ ë¬´ë„ˆì§€ê³  êµ­ë¯¼ì˜ ì‹ ë¢°ë¥¼ ìƒì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì´ë“¤ ê¶Œë ¥ê¸°ê´€ì€ êµ­ë¯¼ì„ ìœ„í•œ ê¸°ê´€ìœ¼ë¡œ ë‹¤ì‹œ íƒœì–´ë‚˜ì•¼ í•©ë‹ˆë‹¤. ì°¸ì—¬ì •ë¶€ëŠ” ë” ì´ìƒ ê¶Œë ¥ê¸°ê´€ì— ì˜ì¡´í•˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. ì–¸ì œë‚˜ ì •ì •ë‹¹ë‹¹í•œ ì •ë¶€ë¡œì„œ êµ­ë¯¼ ì•ì— ì„¤ ê²ƒì…ë‹ˆë‹¤.\n#&gt; \n#&gt; ì°¸ì—¬ì •ë¶€ëŠ” ê³µì •í•˜ê³  íˆ¬ëª…í•œ ì‹œì¥ì§ˆì„œì™€ ë…¸ì‚¬í™”í•©, ê¸°ìˆ í˜ì‹ , ì§€ì—­ì˜ ê· í˜•ë°œì „ ì†ì— ì •ì§í•˜ê³  ì„±ì‹¤í•˜ê²Œ ì‚¬ëŠ” ì‚¬ëŒë“¤ì´ ì„±ê³µí•˜ëŠ” ë‚˜ë¼ë¥¼ ë§Œë“¤ì–´ê°ˆ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œ ì›ì¹™ê³¼ ì‹ ë¢°, ê³µì •ê³¼ íˆ¬ëª…, ëŒ€í™”ì™€ íƒ€í˜‘ ê·¸ë¦¬ê³  ë¶„ê¶Œê³¼ ììœ¨ì˜ ë¬¸í™”ë¥¼ ì‚¬íšŒ ê³³ê³³ì— ë¿Œë¦¬ë‚´ë¦´ ê²ƒì…ë‹ˆë‹¤.\n#&gt; \n#&gt; ì¡´ê²½í•˜ëŠ” êµ­ë¯¼ ì—¬ëŸ¬ë¶„, ìš°ë¦¬ì—ê²ŒëŠ” ì„ ì—´ë“¤ì´ ë³´ì—¬ì¤€ ìì£¼ë…ë¦½ì˜ ê¸°ìƒê³¼ ëŒ€ë™ë‹¨ê²°ì˜ ì§€í˜œê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ 3.1ì ˆì„ ë§ì•„ 1ì ˆì˜ ì´ì¹¼ì— í•­ê±°í•˜ë©° ì´ë£¨ê³ ì í–ˆë˜ ì„ ì—´ë“¤ì˜ ëœ»ì„ ë‹¤ì‹œ í•œë²ˆ ê°€ìŠ´ì— ìƒˆê¹ì‹œë‹¤. êµ­ë¯¼ í†µí•©ê³¼ ê°œí˜ìœ¼ë¡œ í‰í™”ì™€ ë²ˆì˜ì˜ ë™ë¶ì•„ ì‹œëŒ€ë¥¼ ì—´ì–´ê°‘ì‹œë‹¤. ìë‘ìŠ¤ëŸ° ëŒ€í•œë¯¼êµ­ì„ ìš°ë¦¬ í›„ì†ë“¤ì—ê²Œ ë¬¼ë ¤ì¤ì‹œë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "openAI_api_apps.html#ai-ì´ë¯¸ì§€-í›„ì²˜ë¦¬",
    "href": "openAI_api_apps.html#ai-ì´ë¯¸ì§€-í›„ì²˜ë¦¬",
    "title": "ì±—GPT",
    "section": "\n8.1 AI ì´ë¯¸ì§€ í›„ì²˜ë¦¬",
    "text": "8.1 AI ì´ë¯¸ì§€ í›„ì²˜ë¦¬\nì›¹ì— ì´ë¯¸ì§€ê°€ ê±¸ë ¤ìˆì–´ ì´ë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ë°›ì•„ í›„ì† ì‘ì—…ì— í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n\nì½”ë“œimport requests\nfrom PIL import Image\nimport io\n\n# ì´ë¯¸ì§€ URL\nurl = \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-GpPkNlGHcRh9i7pQIlhT18p7/user-Qkv0ntrn5tQoUu6pocAidY5V/img-BHSmfeMCmONIkrl3nSHIZIR7.png?st=2023-07-21T05%3A08%3A01Z&se=2023-07-21T07%3A08%3A01Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-07-20T20%3A06%3A58Z&ske=2023-07-21T20%3A06%3A58Z&sks=b&skv=2021-08-06&sig=8G4gBoBYYHoklBNVR1ggHiURZulcxJ62y0YjJ/OJfkM%3D\"\n\n# GET ìš”ì²­\nresponse = requests.get(url)\n\n# ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°\nimage = Image.open(io.BytesIO(response.content))\n\n# ì´ë¯¸ì§€ JPEG ë³€í™˜\nimage.save('images/dalle_image.jpeg', 'JPEG')"
  },
  {
    "objectID": "openAI_api.html#openai-api-key",
    "href": "openAI_api.html#openai-api-key",
    "title": "ì±—GPT",
    "section": "\n4.1 OpenAI API KEY",
    "text": "4.1 OpenAI API KEY\n\n\n1 ë‹¨ê³„\n2 ë‹¨ê³„\n3 ë‹¨ê³„"
  },
  {
    "objectID": "openAI_api.html#postman-ì ‘ì†í™•ì¸",
    "href": "openAI_api.html#postman-ì ‘ì†í™•ì¸",
    "title": "ì±—GPT",
    "section": "\n4.2 Postman ì ‘ì†í™•ì¸",
    "text": "4.2 Postman ì ‘ì†í™•ì¸\nPostman ì›¹ì‚¬ì´íŠ¸ì— íšŒì›ê°€ì…í•˜ê³  ë¡œê·¸ì¸í•œë‹¤.\n\n\n1 ë‹¨ê³„\n2 ë‹¨ê³„\n3 ë‹¨ê³„\n4 ë‹¨ê³„\n5 ë‹¨ê³„\n6 ë‹¨ê³„\n7 ë‹¨ê³„\n8 ë‹¨ê³„\n9 ë‹¨ê³„\n10 ë‹¨ê³„\n11 ë‹¨ê³„\n12 ë‹¨ê³„"
  },
  {
    "objectID": "openAI_api.html#ai-ì´ë¯¸ì§€-ìƒì„±",
    "href": "openAI_api.html#ai-ì´ë¯¸ì§€-ìƒì„±",
    "title": "ì±—GPT",
    "section": "\n4.3 AI ì´ë¯¸ì§€ ìƒì„±",
    "text": "4.3 AI ì´ë¯¸ì§€ ìƒì„±\n\n\n1 ë‹¨ê³„\n2 ë‹¨ê³„\n3 ë‹¨ê³„\n4 ë‹¨ê³„"
  },
  {
    "objectID": "openAI_api_apps.html#í…ìŠ¤íŠ¸-ë²¡í„°-í‘œí˜„",
    "href": "openAI_api_apps.html#í…ìŠ¤íŠ¸-ë²¡í„°-í‘œí˜„",
    "title": "ì±—GPT",
    "section": "\n9.1 í…ìŠ¤íŠ¸ ë²¡í„° í‘œí˜„",
    "text": "9.1 í…ìŠ¤íŠ¸ ë²¡í„° í‘œí˜„\ntext-embedding-ada-002 ëª¨ë¸ì€ ë¹ ë¥´ê³  ê°€ì„±ë¹„ê°€ ë›°ì–´ë‚œ ì„ë² ë”© ëª¨ë¸ì´ë‹¤. â€œëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.â€ ì´ë¼ëŠ” ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì¦‰, 1,536 ì°¨ì›ì„ ê°–ëŠ” ê³µê°„ì— í•˜ë‚˜ì˜ ì ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'ë²¡í„°ê¸¸ì´: {len(seoul_embedding)}')\n#&gt; ë²¡í„°ê¸¸ì´: 1536\nprint(f'ë²¡í„° ì¼ë¶€: {seoul_embedding[:10]}')\n#&gt; ë²¡í„° ì¼ë¶€: [0.014582998119294643, -0.018063032999634743, 0.004872684367001057, -0.013805408962070942, -0.031180081889033318, 0.025176068767905235, -0.034519895911216736, 0.011357911862432957, -0.007960736751556396, -0.0020682618487626314]\n\n\në§ˆì°¬ê°€ì§€ë¡œ ì¼ë³¸ì˜ ìˆ˜ë„ ë„ì¿„ë„ ë²¡í„°ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œtokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"ì¼ë³¸ ìˆ˜ë„ëŠ” ë™ê²½ì…ë‹ˆë‹¤.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'ë²¡í„°ê¸¸ì´: {len(tokyo_embedding)}')\n#&gt; ë²¡í„°ê¸¸ì´: 1536\nprint(f'ë²¡í„° ì¼ë¶€: {tokyo_embedding[:10]}')\n#&gt; ë²¡í„° ì¼ë¶€: [0.010957648046314716, -0.013234060257673264, 0.009729413315653801, -0.011890077032148838, -0.03179261088371277, 0.03436483070254326, -0.029786281287670135, 0.008629790507256985, 0.01711810939013958, -0.0014733985299244523]"
  },
  {
    "objectID": "gpt4_performance.html#ë…„-4ì›”",
    "href": "gpt4_performance.html#ë…„-4ì›”",
    "title": "chatGPT",
    "section": "\n5.1 2023ë…„ 4ì›”",
    "text": "5.1 2023ë…„ 4ì›”\n\n5.1.1 ë°ì´í„°ì…‹\nì›¹ì‚¬ì´íŠ¸ì— ê²Œì‹œëœ ê°€ê²©í‘œë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì—‘ì…€íŒŒì¼ë¡œ ì •ë¦¬í•œë‹¤.\n\nì½”ë“œlibrary(readxl)\nlibrary(tidyverse)\n\nprice_raw &lt;- read_excel(\"data/openai_pricing.xlsx\", sheet=\"price\")\n\nprice &lt;- price_raw %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  select(-description) %&gt;% \n  separate(ê°€ê²©, into = c(\"ê°€ê²©\", \"ë‹¨ìœ„\"), sep = \"/\") %&gt;% \n  mutate(ê°€ê²© = parse_number(ê°€ê²©) *1300, # í™˜ìœ¨ 1,300 / ë‹¬ëŸ¬ ì ìš©\n         ë‹¨ìœ„ = str_squish(ë‹¨ìœ„)) \n\nprice %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_espn()\n\n\n\n\n\n\nëª¨í˜•êµ¬ë¶„\n      model\n      ì‘ì—…\n      ê°€ê²©\n      ë‹¨ìœ„\n    \n\n\nGPT-4\n8K context\nPrompt\n39.00\n1K tokens\n\n\nGPT-4\n32K context\nPrompt\n78.00\n1K tokens\n\n\nGPT-4\n8K context\nCompletion\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nCompletion\n156.00\n1K tokens\n\n\nChat\ngpt-3.5-turbo\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nAda\nPrompt\n0.52\n1K tokens\n\n\nInstructGPT\nBabbage\nPrompt\n0.65\n1K tokens\n\n\nInstructGPT\nCurie\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nDavinci\nPrompt\n26.00\n1K tokens\n\n\nFine-tuning models\nAda\nPrompt\n0.52\n1K tokens\n\n\nFine-tuning models\nBabbage\nPrompt\n0.78\n1K tokens\n\n\nFine-tuning models\nCurie\nPrompt\n3.90\n1K tokens\n\n\nFine-tuning models\nDavinci\nPrompt\n39.00\n1K tokens\n\n\nFine-tuning models\nAda\nUsage\n2.08\n1K tokens\n\n\nFine-tuning models\nBabbage\nUsage\n3.12\n1K tokens\n\n\nFine-tuning models\nCurie\nUsage\n15.60\n1K tokens\n\n\nFine-tuning models\nDavinci\nUsage\n156.00\n1K tokens\n\n\nEmbedding models\nAda\nPrompt\n0.52\n1K tokens\n\n\nImage models\n1024Ã—1024\nPrompt\n26.00\nimage\n\n\nImage models\n512Ã—512\nPrompt\n23.40\nimage\n\n\nImage models\n256Ã—256\nPrompt\n20.80\nimage\n\n\nAudio models\nWhisper\nPrompt\n7.80\nminute"
  },
  {
    "objectID": "gpt4_performance.html#ë…„-7ì›”",
    "href": "gpt4_performance.html#ë…„-7ì›”",
    "title": "chatGPT",
    "section": "\n5.3 2023ë…„ 7ì›”",
    "text": "5.3 2023ë…„ 7ì›”\n\n5.3.1 ë°ì´í„°ì…‹\nì›¹ì‚¬ì´íŠ¸ì— ê²Œì‹œëœ ê°€ê²©í‘œë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì—‘ì…€íŒŒì¼ë¡œ ì •ë¦¬í•œë‹¤.\n\nì½”ë“œlibrary(readxl)\nlibrary(tidyverse)\n\nprice_today &lt;- read_excel(\"data/openai_pricing.xlsx\", sheet=\"price_230721\")\n\nprice_tbl &lt;- price_today %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  separate(ê°€ê²©, into = c(\"ê°€ê²©\", \"ë‹¨ìœ„\"), sep = \"/\") %&gt;% \n  mutate(ê°€ê²© = parse_number(ê°€ê²©) *1300, # í™˜ìœ¨ 1,300 / ë‹¬ëŸ¬ ì ìš©\n         ë‹¨ìœ„ = str_squish(ë‹¨ìœ„)) \n\nprice_tbl %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_espn()\n\n\n\n\n\n\nëª¨í˜•êµ¬ë¶„\n      model\n      ì‘ì—…\n      ê°€ê²©\n      ë‹¨ìœ„\n    \n\n\nGPT-4\n8K context\nInput\n39.00\n1K tokens\n\n\nGPT-4\n8K context\nOutput\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nInput\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nOutput\n156.00\n1K tokens\n\n\nGPT-3.5 Turbo\n4K context\nInput\n1.95\n1K tokens\n\n\nGPT-3.5 Turbo\n4K context\nOutput\n2.60\n1K tokens\n\n\nGPT-3.5 Turbo\n16K context\nInput\n3.90\n1K tokens\n\n\nGPT-3.5 Turbo\n16K context\nOutput\n5.20\n1K tokens\n\n\nFine-tuning models\nAda\nInput\n0.52\n1K tokens\n\n\nFine-tuning models\nAda\nOutput\n2.08\n1K tokens\n\n\nFine-tuning models\nBabbage\nInput\n0.78\n1K tokens\n\n\nFine-tuning models\nBabbage\nOutput\n3.12\n1K tokens\n\n\nFine-tuning models\nCurie\nInput\n3.90\n1K tokens\n\n\nFine-tuning models\nCurie\nOutput\n15.60\n1K tokens\n\n\nFine-tuning models\nDavinci\nInput\n39.00\n1K tokens\n\n\nFine-tuning models\nDavinci\nOutput\n156.00\n1K tokens\n\n\nEmbedding models\nAda v2\nUsage\n0.13\n1K tokens\n\n\nImage models\nDALLÂ·E 2\n1024Ã—1024\n26.00\nimage\n\n\nImage models\nDALLÂ·E 3\n512Ã—512\n23.40\nimage\n\n\nImage models\nDALLÂ·E 4\n256Ã—256\n20.80\nimage\n\n\nAudio models\nWhisper\nUsage\n7.80\nminute\n\n\n\n\n\n\n\n5.3.2 ì‹œê°í™”\nOpenAI ê°€ê²©ì„ ì›í™”(1,300ì›)ë¡œ ë³€í™˜ì‹œì¼œ API í˜¸ì¶œë³„ ì²´ê°ë˜ëŠ” ê°€ê²©ì„ ì‹œê°í™”í•œë‹¤.\n\nì½”ë“œextrafont::loadfonts()\n\npricing_20230621_g &lt;- price_tbl %&gt;% \n  mutate(ëª¨í˜•ìƒì„¸ = glue::glue(\"{ëª¨í˜•êµ¬ë¶„} / {model} / {ì‘ì—…}\") %&gt;% as.character(.)) %&gt;%\n  mutate(ëª¨í˜•êµ¬ë¶„ = factor(ëª¨í˜•êµ¬ë¶„, levels=c(\"GPT-4\", \"GPT-3.5 Turbo\", \"Fine-tuning models\", \n                                      \"Embedding models\",\n                                      \"Image models\", \"Audio models\") )) %&gt;% \n  ggplot(aes(x = fct_reorder(ëª¨í˜•ìƒì„¸, ê°€ê²©), y = ê°€ê²©, fill = ëª¨í˜•êµ¬ë¶„)) +\n    geom_col(width = 0.5) +\n    # facet_wrap(~ëª¨í˜•êµ¬ë¶„, scales = \"free_y\") +\n    coord_flip() +\n    geom_text(aes(x = ëª¨í˜•ìƒì„¸, y = ê°€ê²©, label = glue::glue(\"{ê°€ê²©} ì›\") ), nudge_y = 5) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(title = \"OpenAI ì±—GPT API í˜¸ì¶œ ê°€ê²©\", \n         subtitle = \"í™˜ìœ¨ 1,300 ì›/ë‹¬ëŸ¬ ì ìš© (í…ìŠ¤íŠ¸ 1,000 í† í°, ì´ë¯¸ì§€ëŠ” í¬ê¸°ë³„, ì˜¤ë””ì˜¤ëŠ” 1ë¶„ ê¸°ì¤€)\",\n         x = \"\",\n         y = \"ê°€ê²©(ì›)\",\n         caption = \"OpenAI ê°€ê²©í‘œ: https://openai.com/pricing\") +\n    theme(legend.position = c(0.8, 0.3),\n          legend.title=element_text(size=rel(2.5), family = \"MaruBuri\"),\n          legend.text=element_text(size=rel(1.5), family = \"MaruBuri\"))\n\nragg::agg_png(\"images/pricing_20230621_g.png\", width = 297, height = 210, units = \"mm\", res = 600)\npricing_20230621_g\ndev.off()"
  },
  {
    "objectID": "shiny_chatGPT.html",
    "href": "shiny_chatGPT.html",
    "title": "ì±—GPT",
    "section": "",
    "text": "1 ChatGPT\nì±—GPT APIë¥¼ í™œìš©í•˜ì—¬ ìì²´ ì•±ì„ ê°œë°œí•  ê²½ìš° íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë§ëŠ” ì‚¬ìš©ì ì§€ì • ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì  ì™¸ì— ë‹¤ìŒê³¼ ê°™ì€ ì¥ë‹¨ì ì´ ì œê¸°ëœë‹¤.\n\nì›¹ì‚¬ì´íŠ¸ ë¡œê³ ë¥¼ ë„£ê³  ë‹¤ë¥¸ ìì²´ ì‹œìŠ¤í…œê³¼ í†µí•©í•  ìˆ˜ ìˆë‹¤.\nê¸°ì¡´ ì„œë¹„ìŠ¤ì— ì±—ë´‡ ê¸°ëŠ¥ ì¶”ê°€\nì±—GPT ì›”ê°„ ìœ ë£Œ êµ¬ë…ë¹„ìš©ë³´ë‹¤ ì €ë ´í•˜ë‹¤.\n\níŠ¹íˆ, ì‚¬ìš©ìê°€ 100ëª… ë„˜ì–´ê°ˆ ê²½ìš° APIë¥¼ í†µí•œ ì„œë¹„ìŠ¤ ì‚¬ìš©ì´ ë¹„ìš©ì ì¸ ì¸¡ë©´ì—ì„œ ë§¤ë ¥ì´ ìˆë‹¤.\nì˜ˆë¥¼ ë“¤ì–´, 100ëª…ì´ ìœ ë£Œ êµ¬ë…í•  ê²½ìš° ëŒ€ëµ $2,000 ë‹¬ëŸ¬ê°€ ë¹„ìš©ìœ¼ë¡œ ì±…ì •ë˜ëŠ”ë° í˜„ì¬ í™˜ìœ¨ê¸°ì¤€ 1,300ì›”/\\$ ëŒ€ëµ 260ë§Œì›ì¸ë° 10,000ë²ˆ í˜¸ì¶œí•  ê²½ìš° ëŒ€ëµ $1,800 ë‹¬ëŸ¬ë©´ í•´ê²°ëœë‹¤.\n\n\n\n2 ë¹„ìš©\nì¶œì²˜: OpenAI API Pricing calculator\n\nì½”ë“œlibrary(tidyverse)\nlibrary(gt)\nlibrary(gtExtras)\n\ncost_raw &lt;- tibble::tribble(\n  ~`Tokens.per.execution    Words.per.execution Price.for.1.execution`,\n                                                        \"Price for\",\n                                                            \"10000\",\n                                                       \"executions\",\n                                         \"10\\t8\\t~$0.00045\\t~$4.50\",\n                                        \"20\\t15\\t~$0.00090\\t~$9.00\",\n                                       \"50\\t38\\t~$0.00225\\t~$22.50\",\n                                      \"100\\t75\\t~$0.00450\\t~$45.00\",\n                                     \"200\\t150\\t~$0.00900\\t~$90.00\",\n                                    \"500\\t375\\t~$0.02250\\t~$225.00\",\n                                   \"1000\\t750\\t~$0.04500\\t~$450.00\",\n                                  \"2000\\t1500\\t~$0.09000\\t~$900.00\",\n                                 \"4000\\t3000\\t~$0.18000\\t~$1800.00\"\n  )\n\ncost_raw |&gt; \n  janitor::clean_names() |&gt; \n  set_names(\"data\") |&gt; \n  mutate(data = map(data, str_split, pattern = \"\\t\")) |&gt; \n  unnest(data) |&gt; \n  mutate(ncol = map_int(data, length)) |&gt; \n  filter(ncol == 4) |&gt; \n  mutate(tokens = map_chr(data, 1),\n         words = map_chr(data, 2),\n         unit_cost = map_chr(data, 3),\n         ttl_cost =  map_chr(data, 4)) |&gt; \n  mutate(ttl_cost = parse_number(ttl_cost)) |&gt; \n  select(-data, -ncol) |&gt; \n  mutate(tokens = parse_number(tokens),\n         words  = parse_number(words)) |&gt; \n  gt::gt() |&gt; \n    gt_theme_538() |&gt; \n    cols_align(\"center\") |&gt; \n    fmt_integer(columns = c(ttl_cost, words, tokens)) |&gt; \n    tab_footnote(\n      footnote = \"ì±—GPT ìœ ë£Œê³„ì • $20 x 100ëª…, $2,000 ê¸°ì¤€\",\n      locations = cells_body(columns = ttl_cost, rows = 9)\n    ) |&gt; \n  tab_header(\n    title = html(\"ì±—GPT4 API í˜¸ì¶œíšŸìˆ˜ì™€ ìœ ë£Œê³„ì •\"),\n    subtitle = html(\"GPT-4 API 10,000ë²ˆ í˜¸ì¶œ ê¸°ì¤€\")\n  )\n\n\n\n\n\n\nì±—GPT4 API í˜¸ì¶œíšŸìˆ˜ì™€ ìœ ë£Œê³„ì •\n    \n\nGPT-4 API 10,000ë²ˆ í˜¸ì¶œ ê¸°ì¤€\n    \n\ntokens\n      words\n      unit_cost\n      ttl_cost\n    \n\n\n\n10\n8\n~$0.00045\n4\n\n\n20\n15\n~$0.00090\n9\n\n\n50\n38\n~$0.00225\n22\n\n\n100\n75\n~$0.00450\n45\n\n\n200\n150\n~$0.00900\n90\n\n\n500\n375\n~$0.02250\n225\n\n\n1,000\n750\n~$0.04500\n450\n\n\n2,000\n1,500\n~$0.09000\n900\n\n\n4,000\n3,000\n~$0.18000\n1,8001\n\n\n\n\n\n1 ì±—GPT ìœ ë£Œê³„ì • $20 x 100ëª…, $2,000 ê¸°ì¤€\n    \n\n\n\n\n\n3 ìì²´ ì•± êµ¬ì¶œ\nGitHub ì €ì¥ì†Œ deepanshu88/shinyChatGPT ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¡œê³ ì™€ ë©”ì‹œì§€ë¥¼ ë°”ê¾¸ë©´ Shiny ì±—GPT ì•±ì„ ê°„ë‹¨íˆ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "three_paradigm.html#import-necessary-libraries",
    "href": "three_paradigm.html#import-necessary-libraries",
    "title": "ì±—GPT",
    "section": "\n5.1 Import Necessary Libraries",
    "text": "5.1 Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "three_paradigm.html#load-the-dataset",
    "href": "three_paradigm.html#load-the-dataset",
    "title": "ì±—GPT",
    "section": "\n5.2 Load the Dataset",
    "text": "5.2 Load the Dataset\n# Load the dataset\ndf = pd.read_csv('penguins.csv')"
  },
  {
    "objectID": "three_paradigm.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "href": "three_paradigm.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "title": "ì±—GPT",
    "section": "\n5.3 Check Correlations Within Each Species for Culmen Length and Depth",
    "text": "5.3 Check Correlations Within Each Species for Culmen Length and Depth\n# Check correlations within each species for culmen_length_mm and culmen_depth_mm\nspecies_list = df['species'].unique()\nfor species in species_list:\n    print(f\"Correlation within {species} species:\")\n    print(df[df['species'] == species][['bill_length_mm', 'bill_depth_mm']].corr())\n    print(\"\\n\")"
  },
  {
    "objectID": "three_paradigm.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "href": "three_paradigm.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "title": "ì±—GPT",
    "section": "\n5.4 Calculate the Overall Correlation Between Culmen Length and Depth",
    "text": "5.4 Calculate the Overall Correlation Between Culmen Length and Depth\n# Calculate the overall correlation between bill_length_mm and bill_depth_mm\noverall_corr = df[['bill_length_mm', 'bill_depth_mm']].corr().iloc[0, 1]\noverall_corr"
  },
  {
    "objectID": "three_paradigm.html#create-scatter-plot",
    "href": "three_paradigm.html#create-scatter-plot",
    "title": "ì±—GPT",
    "section": "\n5.5 Create Scatter Plot",
    "text": "5.5 Create Scatter Plot\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Overall regression line\nsns.regplot(x='bill_length_mm', y='bill_depth_mm', data=df, scatter=False, \n            line_kws={'color': 'black', 'label': \"Overall regression line\"})\n\n# Loop through each species\nfor species in species_list:\n    species_data = df[df['species'] == species]\n    sns.scatterplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, label=species)\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, scatter=False, \n                line_kws={'label': f\"{species} regression line\"})\n\nplt.title('Bill Depth vs Bill Length')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\n\n# Add legend\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "three_paradigm.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "href": "three_paradigm.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "title": "ì±—GPT",
    "section": "\n5.6 Create Separate Scatter Plots with Regression Lines for Each Species",
    "text": "5.6 Create Separate Scatter Plots with Regression Lines for Each Species\n# Create a figure and axis\nfig, axs = plt.subplots(3, 1, figsize=(10, 20))\n\n# Loop through each species\nfor ax, species in zip(axs, species_list):\n    species_data = df[df['species'] == species]\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, ax=ax, \n                line_kws={'label': f\"{species} regression line\"})\n    ax.set_title(f'{species} Penguins')\n    ax.set_xlabel('Bill Length (mm)')\n    ax.set_ylabel('Bill Depth (mm)')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "three_paradigm.html#ì„¤ì •",
    "href": "three_paradigm.html#ì„¤ì •",
    "title": "ì±—GPT",
    "section": "\n2.1 ì„¤ì •",
    "text": "2.1 ì„¤ì •\nìœ ë£Œêµ¬ë…í•˜ê³  â€œCode Interpreterâ€ë¥¼ í™œì„±í™”ì‹œí‚¨ë‹¤.\n\n\n1ë‹¨ê³„\n2ë‹¨ê³„\n3ë‹¨ê³„\n4ë‹¨ê³„\n5ë‹¨ê³„ (ë°ì´í„°+í”„ë¡¬í”„íŠ¸)"
  },
  {
    "objectID": "three_paradigm.html#ì‹¬ìŠ¨-íŒ¨ëŸ¬ë…ìŠ¤",
    "href": "three_paradigm.html#ì‹¬ìŠ¨-íŒ¨ëŸ¬ë…ìŠ¤",
    "title": "ì±—GPT",
    "section": "\n2.2 ì‹¬ìŠ¨ íŒ¨ëŸ¬ë…ìŠ¤",
    "text": "2.2 ì‹¬ìŠ¨ íŒ¨ëŸ¬ë…ìŠ¤\nâ€œì±—GPT Code Interpreterâ€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•œ ì‚¬ë¡€\n\nì±—GPT Code Interpreter : ì±„íŒ… ì´ë ¥\n\nJupyter Notebook ë‹¤ìš´ë¡œë“œ: penguin_analysis.ipynb\n\n\npenguin_analysis.ipynb â†’ penguin_analysis.qmd\n\nëª…ë ¹ì–´: $ quarto convert penguin_analysis.ipynb\n\n\n\nì¿¼í†  ì»´íŒŒì¼: ë°”ë¡œê°€ê¸°"
  },
  {
    "objectID": "plugin.html",
    "href": "plugin.html",
    "title": "í”ŒëŸ¬ê·¸ì¸(Plugin)",
    "section": "",
    "text": "ì§€ì˜¤ì½”ë”©(Geocoding)ì€ ì£¼ì†Œ, ì§€ëª…, ìš°í¸ ë²ˆí˜¸ ë“±ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ìœ„ë„ì™€ ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ë¥¼ í†µí•´ íŠ¹ì • ìœ„ì¹˜ë¥¼ ì§€ë„ ìƒì— í‘œì‹œí•˜ê±°ë‚˜, ìœ„ì¹˜ ê¸°ë°˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 212â€ë¼ëŠ” ì£¼ì†Œë¥¼ ìœ„ë„ 37.5012746, ê²½ë„ 127.0395857ì™€ ê°™ì€ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” ì¼ì¢…ì˜ í•¨ìˆ˜ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.\nì§€ì˜¤ì½”ë”©ì€ ì£¼ì†Œë‚˜ ì§€ëª…ì„ ìœ„ë„ì™€ ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì£¼ì†Œë‚˜ ì§€ëª…ì„ ì…ë ¥í•˜ë©´ ì´ë¥¼ API ìš”ì²­ìœ¼ë¡œ ì „ë‹¬í•œë‹¤. ì„œë²„ëŠ” ì´ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì—¬ í•´ë‹¹ ìœ„ì¹˜ì˜ ìœ„ë„ì™€ ê²½ë„ ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤. ì´ë ‡ê²Œ ì–»ì€ ìœ„ë„ì™€ ê²½ë„ëŠ” ì§€ë„ ìƒì— í‘œì‹œí•˜ê±°ë‚˜ ìœ„ì¹˜ ê¸°ë°˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. ë°˜ëŒ€ë¡œ, ìœ„ë„ì™€ ê²½ë„ë¥¼ ì£¼ì†Œë‚˜ ì§€ëª…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ì—­ë°©í–¥ ì§€ì˜¤ì½”ë”©ì´ë¼ê³  í•œë‹¤. Google Maps API, Kakao Maps API, Naver Maps API ë“± ì„œë¹„ìŠ¤ ì œê³µì—…ì²´ê°€ ë‹¤ìˆ˜ ì¡´ì¬í•˜ì§€ë§Œ ì¼ì • íšŸìˆ˜ ì´ìƒì˜ ìš”ì²­ ì œí•œ, ì •í™•ë„ ë¬¸ì œ, ë°ì´í„° ê°±ì‹ ì£¼ê¸° ë“± ì œí•œì‚¬í•­ì„ íŒŒì•…í•˜ê³  ì ì ˆí•œ APIë¥¼ ì„ íƒí•˜ì—¬ ì—…ë¬´ì— ì ìš©í•œë‹¤.\nShareGPT: ì±—GPT Plugin - ì§€ë„API\nì¹´ì¹´ì˜¤ ì§€ë„ API ê¸°ìˆ ë¬¸ì„œë¥¼ ì±—GPT í”ŒëŸ¬ê·¸ì¸ â€œLink Readerâ€ì„ ì‚¬ìš©í•˜ì—¬ ì¢Œí‘œë¥¼ ì°ê³  ì´ë¥¼ ì§€ë„ìœ„ì— ì¶œë ¥í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì.\n\nì¹´ì¹´ì˜¤ ì§€ë„ APIë¥¼ í˜¸ì¶œí•´ì„œ ì£¼ì†Œë¥¼ ë„˜ê¸°ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì±—GPT í”Œë¡œê·¸ì¸ì„ ì‚¬ìš©í•´ì„œ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” ìƒì„±í•œë‹¤.\n\n\n\n\n\n\nì›¹ì‚¬ì´íŠ¸ë¥¼ ì½ê³  ë‹¤ìŒ ì§€ë ¹ì„ ì¤€ë¹„í•´ https://apis.map.kakao.com/web/documentation/\n\n\n\n\n\nKakao ì§€ë„ API ë¬¸ì„œëŠ” ë‹¤ì–‘í•œ ì§€ë„ ê´€ë ¨ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ì´ ë¬¸ì„œëŠ” ì§€ë„ ê°ì²´ ìƒì„±, ì´ë²¤íŠ¸, ë©”ì„œë“œ ë“±ì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤. ì•„ë˜ëŠ” ì£¼ìš” ë‚´ìš©ì˜ ìš”ì•½ì´ë‹¤.\n\n### ì§€ë„ ê°ì²´ ìƒì„±\n- `kakao.maps.Map(container, options)`: ì§€ë„ë¥¼ ìƒì„±í•œë‹¤.\n  - `container`: ì§€ë„ê°€ í‘œì‹œë  HTML element\n  - `options`: ì¤‘ì‹¬ ì¢Œí‘œ, í™•ëŒ€ ìˆ˜ì¤€, ì§€ë„ ì¢…ë¥˜ ë“±ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.\n\n### ì£¼ìš” ë©”ì„œë“œ\n- `setCenter(latlng)`: ì§€ë„ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ì„¤ì •í•œë‹¤.\n- `getCenter()`: ì§€ë„ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ë°˜í™˜í•œë‹¤.\n- `setLevel(level, options)`: ì§€ë„ì˜ í™•ëŒ€ ìˆ˜ì¤€ì„ ì„¤ì •í•œë‹¤.\n- `getLevel()`: ì§€ë„ì˜ í™•ëŒ€ ìˆ˜ì¤€ì„ ë°˜í™˜í•œë‹¤.\n- `setMapTypeId(mapTypeId)`: ì§€ë„ì˜ íƒ€ì…ì„ ì„¤ì •í•œë‹¤.\n- `getMapTypeId()`: ì§€ë„ì˜ íƒ€ì…ì„ ë°˜í™˜í•œë‹¤.\n\n### ì´ë²¤íŠ¸\n- `center_changed`: ì¤‘ì‹¬ ì¢Œí‘œê°€ ë³€ê²½ë˜ë©´ ë°œìƒí•œë‹¤.\n- `zoom_start`: í™•ëŒ€ ìˆ˜ì¤€ì´ ë³€ê²½ë˜ê¸° ì§ì „ì— ë°œìƒí•œë‹¤.\n- `zoom_changed`: í™•ëŒ€ ìˆ˜ì¤€ì´ ë³€ê²½ë˜ë©´ ë°œìƒí•œë‹¤.\n- `click`: ì§€ë„ë¥¼ í´ë¦­í•˜ë©´ ë°œìƒí•œë‹¤.\n- `dblclick`: ì§€ë„ë¥¼ ë”ë¸”í´ë¦­í•˜ë©´ ë°œìƒí•œë‹¤.\n\nì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ ë©”ì„œë“œì™€ ì´ë²¤íŠ¸ê°€ ìˆì–´, ê°œë°œìê°€ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\n\n\n\nì£¼ì†Œë¥¼ ë„˜ê¸°ë©´ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” R ì½”ë“œë¥¼ ì‘ì„±í•´ì¤˜.\n\n\n\n\n\nRì—ì„œ ì£¼ì†Œë¥¼ ìœ„ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ httr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ Kakao APIë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ ì½”ë“œì´ë‹¤.\n# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# ì£¼ì†Œë¥¼ ìœ„ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤\nget_latlng &lt;- function(address) {\n  # Kakao API í‚¤ë¥¼ ì„¤ì •í•œë‹¤ (ë³¸ì¸ì˜ API í‚¤ë¡œ êµì²´í•´ì•¼ í•œë‹¤)\n  api_key &lt;- \"YOUR_KAKAO_API_KEY\"\n  \n  # API URLê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•œë‹¤\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # APIë¥¼ í˜¸ì¶œí•œë‹¤\n  response &lt;- GET(url, query = params, headers)\n  \n  # ì‘ë‹µì„ í™•ì¸í•˜ê³  JSONì„ íŒŒì‹±í•œë‹¤\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # ìœ„ê²½ë„ë¥¼ ì¶”ì¶œí•œë‹¤\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•œë‹¤\naddress &lt;- \"ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 212\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\nì´ ì½”ë“œì—ì„œ YOUR_KAKAO_API_KEY ë¶€ë¶„ì„ ë³¸ì¸ì˜ Kakao API í‚¤ë¡œ êµì²´í•´ì•¼ í•œë‹¤. ì´ í•¨ìˆ˜ëŠ” ì£¼ì†Œ(address)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìœ„ë„(lat)ì™€ ê²½ë„(lng)ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•œë‹¤.\nì£¼ì˜: API í‚¤ë¥¼ ê³µê°œí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤.\n\n\n\n\nì±—GPTê°€ ì œì‹œí•œ â€œAPI í‚¤ë¥¼ ê³µê°œí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤â€ë¥¼ ë°˜ì˜í•˜ì—¬ api_key &lt;- \"YOUR_KAKAO_API_KEY\" ë¶€ë¶„ì„ api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\") ë°”ê¿” ì™¸ë¶€ì— ì¹´ì¹´ì˜¤ ì§€ë„ APIí‚¤ë¥¼ ìˆ¨ê¸´ë‹¤. â€œê°€í†¨ë¦­ê´€ë™ëŒ€í•™êµâ€ ì£¼ì†Œ â€œê°•ì›ë„ ê°•ë¦‰ì‹œ ë²”ì¼ë¡œ579ë²ˆê¸¸ 24â€ë¥¼ ë„£ì–´ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ì–»ì–´ë‚¸ë‹¤.\n\nì½”ë“œ# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤\n# install.packages(\"httr\")\n# install.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# ì£¼ì†Œë¥¼ ìœ„ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤\nget_latlng &lt;- function(address) {\n  # Kakao API í‚¤ë¥¼ ì„¤ì •í•œë‹¤ (ë³¸ì¸ì˜ API í‚¤ë¡œ êµì²´í•´ì•¼ í•œë‹¤)\n  api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\")\n  \n  # API URLê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•œë‹¤\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # APIë¥¼ í˜¸ì¶œí•œë‹¤\n  response &lt;- GET(url, query = params, headers)\n  \n  # ì‘ë‹µì„ í™•ì¸í•˜ê³  JSONì„ íŒŒì‹±í•œë‹¤\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # ìœ„ê²½ë„ë¥¼ ì¶”ì¶œí•œë‹¤\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# ê°€í†¨ë¦­ê´€ë™ëŒ€í•™êµ ì£¼ì†Œ\naddress &lt;- \"ê°•ì›ë„ ê°•ë¦‰ì‹œ ë²”ì¼ë¡œ579ë²ˆê¸¸ 24\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\n#&gt; [1] \"Latitude: 37.7373221158143 Longitude: 128.873681611316\"\n\n\n\nê°€í†¨ë¦­ê´€ë™ëŒ€í•™êµ ì£¼ì†Œ ì •ë³´ë¥¼ ì§€ì˜¤ì½”ë”©ì„ í†µí•´ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ì–»ëŠ”ë‹¤. ë‹¤ìŒìœ¼ë¡œ ggplotìœ¼ë¡œ ì£¼ì†Œë¥¼ ì°ê³ , ëŒ€í•œë¯¼êµ­ì§€ë„ìœ„ì— ì˜¬ë ¤ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ì‹œê°í™”í•œë‹¤.\n\nì½”ë“œ# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤\n# install.packages(c(\"sf\", \"ggplot2\", \"ggrepel\"))\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# ìœ„ê²½ë„ ì¢Œí‘œì™€ ì£¼ì†Œë¥¼ ê°€ì§„ ë°ì´í„° í”„ë ˆì„ì„ ìƒì„±í•œë‹¤\ncoordinates_df &lt;- data.frame(\n  lon = result$lng, # ê²½ë„\n  lat = result$lat,    # ìœ„ë„\n  address = c(\"ê°•ì›ë„ ê°•ë¦‰ì‹œ ë²”ì¼ë¡œ579ë²ˆê¸¸ 24\")\n)\n\n# ë°ì´í„° í”„ë ˆì„ì„ sf ê°ì²´ë¡œ ë³€í™˜í•œë‹¤\ncoordinates_sf &lt;- st_as_sf(coordinates_df, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n# ëŒ€í•œë¯¼êµ­ì§€ë„\nlibrary(giscoR)\ncntry &lt;- gisco_countries\nKOR &lt;- subset(cntry, ISO3_CODE == \"KOR\")\n\n# ggplot2ì™€ geom_sf()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”í•œë‹¤\ncoordinates_sf |&gt; \n  ggplot() +\n    geom_sf() +\n    geom_sf_text(aes(label = address), size = 2, nudge_y = 0.2) +\n    labs(title = \"ì±—GPT í”Œë¡œê·¸ì¸ ì‚¬ë¡€\",\n         x =\"\",\n         y =\"\") +\n    theme_minimal() +\n    geom_sf(data = KOR, fill = \"transparent\")"
  },
  {
    "objectID": "plugin.html#ì§€ì˜¤ì½”ë”©-api-ì½”ë“œ",
    "href": "plugin.html#ì§€ì˜¤ì½”ë”©-api-ì½”ë“œ",
    "title": "í”ŒëŸ¬ê·¸ì¸(Plugin)",
    "section": "",
    "text": "ì¹´ì¹´ì˜¤ ì§€ë„ APIë¥¼ í˜¸ì¶œí•´ì„œ ì£¼ì†Œë¥¼ ë„˜ê¸°ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì±—GPT í”Œë¡œê·¸ì¸ì„ ì‚¬ìš©í•´ì„œ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” ìƒì„±í•œë‹¤.\n\n\n\n\n\n\nì›¹ì‚¬ì´íŠ¸ë¥¼ ì½ê³  ë‹¤ìŒ ì§€ë ¹ì„ ì¤€ë¹„í•´ https://apis.map.kakao.com/web/documentation/\n\n\n\n\n\nKakao ì§€ë„ API ë¬¸ì„œëŠ” ë‹¤ì–‘í•œ ì§€ë„ ê´€ë ¨ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ì´ ë¬¸ì„œëŠ” ì§€ë„ ê°ì²´ ìƒì„±, ì´ë²¤íŠ¸, ë©”ì„œë“œ ë“±ì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤. ì•„ë˜ëŠ” ì£¼ìš” ë‚´ìš©ì˜ ìš”ì•½ì´ë‹¤.\n\n### ì§€ë„ ê°ì²´ ìƒì„±\n- `kakao.maps.Map(container, options)`: ì§€ë„ë¥¼ ìƒì„±í•œë‹¤.\n  - `container`: ì§€ë„ê°€ í‘œì‹œë  HTML element\n  - `options`: ì¤‘ì‹¬ ì¢Œí‘œ, í™•ëŒ€ ìˆ˜ì¤€, ì§€ë„ ì¢…ë¥˜ ë“±ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.\n\n### ì£¼ìš” ë©”ì„œë“œ\n- `setCenter(latlng)`: ì§€ë„ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ì„¤ì •í•œë‹¤.\n- `getCenter()`: ì§€ë„ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ë°˜í™˜í•œë‹¤.\n- `setLevel(level, options)`: ì§€ë„ì˜ í™•ëŒ€ ìˆ˜ì¤€ì„ ì„¤ì •í•œë‹¤.\n- `getLevel()`: ì§€ë„ì˜ í™•ëŒ€ ìˆ˜ì¤€ì„ ë°˜í™˜í•œë‹¤.\n- `setMapTypeId(mapTypeId)`: ì§€ë„ì˜ íƒ€ì…ì„ ì„¤ì •í•œë‹¤.\n- `getMapTypeId()`: ì§€ë„ì˜ íƒ€ì…ì„ ë°˜í™˜í•œë‹¤.\n\n### ì´ë²¤íŠ¸\n- `center_changed`: ì¤‘ì‹¬ ì¢Œí‘œê°€ ë³€ê²½ë˜ë©´ ë°œìƒí•œë‹¤.\n- `zoom_start`: í™•ëŒ€ ìˆ˜ì¤€ì´ ë³€ê²½ë˜ê¸° ì§ì „ì— ë°œìƒí•œë‹¤.\n- `zoom_changed`: í™•ëŒ€ ìˆ˜ì¤€ì´ ë³€ê²½ë˜ë©´ ë°œìƒí•œë‹¤.\n- `click`: ì§€ë„ë¥¼ í´ë¦­í•˜ë©´ ë°œìƒí•œë‹¤.\n- `dblclick`: ì§€ë„ë¥¼ ë”ë¸”í´ë¦­í•˜ë©´ ë°œìƒí•œë‹¤.\n\nì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ ë©”ì„œë“œì™€ ì´ë²¤íŠ¸ê°€ ìˆì–´, ê°œë°œìê°€ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\n\n\n\nì£¼ì†Œë¥¼ ë„˜ê¸°ë©´ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” R ì½”ë“œë¥¼ ì‘ì„±í•´ì¤˜.\n\n\n\n\n\nRì—ì„œ ì£¼ì†Œë¥¼ ìœ„ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ httr íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ Kakao APIë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ ì½”ë“œì´ë‹¤.\n# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# ì£¼ì†Œë¥¼ ìœ„ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤\nget_latlng &lt;- function(address) {\n  # Kakao API í‚¤ë¥¼ ì„¤ì •í•œë‹¤ (ë³¸ì¸ì˜ API í‚¤ë¡œ êµì²´í•´ì•¼ í•œë‹¤)\n  api_key &lt;- \"YOUR_KAKAO_API_KEY\"\n  \n  # API URLê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•œë‹¤\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # APIë¥¼ í˜¸ì¶œí•œë‹¤\n  response &lt;- GET(url, query = params, headers)\n  \n  # ì‘ë‹µì„ í™•ì¸í•˜ê³  JSONì„ íŒŒì‹±í•œë‹¤\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # ìœ„ê²½ë„ë¥¼ ì¶”ì¶œí•œë‹¤\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•œë‹¤\naddress &lt;- \"ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 212\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\nì´ ì½”ë“œì—ì„œ YOUR_KAKAO_API_KEY ë¶€ë¶„ì„ ë³¸ì¸ì˜ Kakao API í‚¤ë¡œ êµì²´í•´ì•¼ í•œë‹¤. ì´ í•¨ìˆ˜ëŠ” ì£¼ì†Œ(address)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìœ„ë„(lat)ì™€ ê²½ë„(lng)ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•œë‹¤.\nì£¼ì˜: API í‚¤ë¥¼ ê³µê°œí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤."
  },
  {
    "objectID": "plugin.html#ì½”ë“œ-ìˆ˜ì •",
    "href": "plugin.html#ì½”ë“œ-ìˆ˜ì •",
    "title": "í”ŒëŸ¬ê·¸ì¸(Plugin)",
    "section": "",
    "text": "ì±—GPTê°€ ì œì‹œí•œ â€œAPI í‚¤ë¥¼ ê³µê°œí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì•¼ í•œë‹¤â€ë¥¼ ë°˜ì˜í•˜ì—¬ api_key &lt;- \"YOUR_KAKAO_API_KEY\" ë¶€ë¶„ì„ api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\") ë°”ê¿” ì™¸ë¶€ì— ì¹´ì¹´ì˜¤ ì§€ë„ APIí‚¤ë¥¼ ìˆ¨ê¸´ë‹¤. â€œê°€í†¨ë¦­ê´€ë™ëŒ€í•™êµâ€ ì£¼ì†Œ â€œê°•ì›ë„ ê°•ë¦‰ì‹œ ë²”ì¼ë¡œ579ë²ˆê¸¸ 24â€ë¥¼ ë„£ì–´ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ì–»ì–´ë‚¸ë‹¤.\n\nì½”ë“œ# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤\n# install.packages(\"httr\")\n# install.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# ì£¼ì†Œë¥¼ ìœ„ê²½ë„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤\nget_latlng &lt;- function(address) {\n  # Kakao API í‚¤ë¥¼ ì„¤ì •í•œë‹¤ (ë³¸ì¸ì˜ API í‚¤ë¡œ êµì²´í•´ì•¼ í•œë‹¤)\n  api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\")\n  \n  # API URLê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•œë‹¤\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # APIë¥¼ í˜¸ì¶œí•œë‹¤\n  response &lt;- GET(url, query = params, headers)\n  \n  # ì‘ë‹µì„ í™•ì¸í•˜ê³  JSONì„ íŒŒì‹±í•œë‹¤\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # ìœ„ê²½ë„ë¥¼ ì¶”ì¶œí•œë‹¤\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# ê°€í†¨ë¦­ê´€ë™ëŒ€í•™êµ ì£¼ì†Œ\naddress &lt;- \"ê°•ì›ë„ ê°•ë¦‰ì‹œ ë²”ì¼ë¡œ579ë²ˆê¸¸ 24\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\n#&gt; [1] \"Latitude: 37.7373221158143 Longitude: 128.873681611316\""
  },
  {
    "objectID": "plugin.html#ê°€í†¨ë¦­ê´€ë™ëŒ€-ìœ„ì¹˜",
    "href": "plugin.html#ê°€í†¨ë¦­ê´€ë™ëŒ€-ìœ„ì¹˜",
    "title": "í”ŒëŸ¬ê·¸ì¸(Plugin)",
    "section": "",
    "text": "ê°€í†¨ë¦­ê´€ë™ëŒ€í•™êµ ì£¼ì†Œ ì •ë³´ë¥¼ ì§€ì˜¤ì½”ë”©ì„ í†µí•´ ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ì–»ëŠ”ë‹¤. ë‹¤ìŒìœ¼ë¡œ ggplotìœ¼ë¡œ ì£¼ì†Œë¥¼ ì°ê³ , ëŒ€í•œë¯¼êµ­ì§€ë„ìœ„ì— ì˜¬ë ¤ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ì‹œê°í™”í•œë‹¤.\n\nì½”ë“œ# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤\n# install.packages(c(\"sf\", \"ggplot2\", \"ggrepel\"))\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# ìœ„ê²½ë„ ì¢Œí‘œì™€ ì£¼ì†Œë¥¼ ê°€ì§„ ë°ì´í„° í”„ë ˆì„ì„ ìƒì„±í•œë‹¤\ncoordinates_df &lt;- data.frame(\n  lon = result$lng, # ê²½ë„\n  lat = result$lat,    # ìœ„ë„\n  address = c(\"ê°•ì›ë„ ê°•ë¦‰ì‹œ ë²”ì¼ë¡œ579ë²ˆê¸¸ 24\")\n)\n\n# ë°ì´í„° í”„ë ˆì„ì„ sf ê°ì²´ë¡œ ë³€í™˜í•œë‹¤\ncoordinates_sf &lt;- st_as_sf(coordinates_df, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n# ëŒ€í•œë¯¼êµ­ì§€ë„\nlibrary(giscoR)\ncntry &lt;- gisco_countries\nKOR &lt;- subset(cntry, ISO3_CODE == \"KOR\")\n\n# ggplot2ì™€ geom_sf()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°í™”í•œë‹¤\ncoordinates_sf |&gt; \n  ggplot() +\n    geom_sf() +\n    geom_sf_text(aes(label = address), size = 2, nudge_y = 0.2) +\n    labs(title = \"ì±—GPT í”Œë¡œê·¸ì¸ ì‚¬ë¡€\",\n         x =\"\",\n         y =\"\") +\n    theme_minimal() +\n    geom_sf(data = KOR, fill = \"transparent\")"
  },
  {
    "objectID": "plugin.html#ì‚¬ì‹¤-í™•ì¸",
    "href": "plugin.html#ì‚¬ì‹¤-í™•ì¸",
    "title": "í”ŒëŸ¬ê·¸ì¸(Plugin)",
    "section": "\n3.1 ì‚¬ì‹¤ í™•ì¸",
    "text": "3.1 ì‚¬ì‹¤ í™•ì¸\nìš¸í”„ëŒ ì•ŒíŒŒ(Wolfram Alpha) ì‚¬ìš©í•´ì„œ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•´ë³´ì.\n\n\n\n\n\n\nâ€œì§€êµ¬ëŠ” í‰í‰í•˜ë‹¤â€ë¼ëŠ” ì£¼ì¥ì„ ê²€ì¦í•´ì¤˜.\n\n\n\n\n\n\"ì§€êµ¬ëŠ” í‰í‰í•˜ë‹¤\"ë¼ëŠ” ì£¼ì¥ì— ëŒ€í•´ Wolfram Alphaë¥¼ ì´ìš©í•´ ê²€ì¦í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\n\n### ì…ë ¥ í•´ì„\n- ì§ˆë¬¸: ì§€êµ¬ëŠ” í‰í‰í•˜ë‹¤?\n\n### ê²°ê³¼\n- ë‹µë³€: ì•„ë‹ˆë‹¤.\n  - ì§€ì—­ì ìœ¼ë¡œë§Œ ê·¸ë ‡ë‹¤. ê·¸ë¦¬ê³  ê·¸ê²ƒë„ íŠ¹ì • ì§€ì—­, ì˜ˆë¥¼ ë“¤ì–´ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œë§Œ í•´ë‹¹ëœë‹¤.\n\nìì„¸í•œ ì •ë³´ëŠ” [Wolfram|Alpha ì›¹ì‚¬ì´íŠ¸](https://www6b3.wolframalpha.com/input?i=Is+the+Earth+flat%3F)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\nì´ì²˜ëŸ¼ Wolfram AlphaëŠ” ë‹¤ì–‘í•œ ì£¼ì¥ì´ë‚˜ ì •ë³´ì— ëŒ€í•œ íŒ©íŠ¸ì²´í¬ë¥¼ í•  ìˆ˜ ìˆëŠ” ìœ ìš©í•œ ë„êµ¬ì´ë‹¤.\nWolfram|Alpha ì›¹ì‚¬ì´íŠ¸\n\n\n\n\n\n\n\n\n\në¼ë©´ì„ ë§ì´ ë¨¹ìœ¼ë©´ ê±´ê°•ì— ì •ë§ ì•ˆì¢‹ì€ê°€?\n\n\n\n\n\nWolfram Alphaì—ì„œëŠ” â€œë¼ë©´ì„ ë§ì´ ë¨¹ìœ¼ë©´ ê±´ê°•ì— ì •ë§ ì•ˆ ì¢‹ì€ê°€?â€ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì§€ ëª»í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¼ë°˜ì ìœ¼ë¡œ ë¼ë©´ì€ ë†’ì€ ë‚˜íŠ¸ë¥¨, ì§€ë°©, ì¸ê³µ ì²¨ê°€ë¬¼ ë“±ì„ í¬í•¨í•˜ê³  ìˆì–´, ê³¼ë„í•˜ê²Œ ì„­ì·¨í•  ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ê±´ê°• ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤:\n\nê³ í˜ˆì••: ë¼ë©´ì—ëŠ” ë‚˜íŠ¸ë¥¨ì´ ë§ì´ ë“¤ì–´ìˆë‹¤. ë‚˜íŠ¸ë¥¨ ê³¼ë‹¤ ì„­ì·¨ëŠ” í˜ˆì••ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.\në¹„ë§Œ: ë¼ë©´ì€ ì¹¼ë¡œë¦¬ê°€ ë†’ê³ , ì§€ë°©ë„ ë§ì´ ë“¤ì–´ìˆë‹¤. ì§€ì†ì ìœ¼ë¡œ ë¼ë©´ì„ ë§ì´ ë¨¹ìœ¼ë©´ ì²´ì¤‘ ì¦ê°€ì˜ ìœ„í—˜ì´ ìˆë‹¤.\nì†Œí™”ê¸° ë¬¸ì œ: ë¼ë©´ì€ ì†Œí™”ê°€ ì˜ ë˜ì§€ ì•ŠëŠ” ì‹í’ˆ ì¤‘ í•˜ë‚˜ì´ë‹¤. ê³¼ë„í•œ ì„­ì·¨ëŠ” ì†Œí™”ê¸°ì— ë¶€ë‹´ì„ ì¤„ ìˆ˜ ìˆë‹¤.\nì˜ì–‘ ë¶ˆê· í˜•: ë¼ë©´ì€ ì˜ì–‘ì†Œê°€ ì ê³ , ë‚˜íŠ¸ë¥¨ì´ë‚˜ ì§€ë°© ë“±ì˜ ë¶ˆí•„ìš”í•œ ì„±ë¶„ì´ ë§ë‹¤. ì´ë¡œ ì¸í•´ ì˜ì–‘ ë¶ˆê· í˜•ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.\nì‹¬í˜ˆê´€ ì§ˆí™˜: ê³ í˜ˆì••, ë†’ì€ ì½œë ˆìŠ¤í…Œë¡¤ ë“±ì€ ì‹¬í˜ˆê´€ ì§ˆí™˜ì˜ ìœ„í—˜ì„ ë†’ì¸ë‹¤.\n\në¼ë©´ì„ ì¦ê¸¸ ë•ŒëŠ” ì´ëŸ¬í•œ ì ë“¤ì„ ê³ ë ¤í•˜ì—¬ ì ë‹¹í•œ ì–‘ê³¼ ë¹ˆë„ë¡œ ì„­ì·¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤."
  },
  {
    "objectID": "plugin.html#ìˆ˜ëŠ¥ë¬¸ì œ-í’€ì´",
    "href": "plugin.html#ìˆ˜ëŠ¥ë¬¸ì œ-í’€ì´",
    "title": "í”ŒëŸ¬ê·¸ì¸(Plugin)",
    "section": "\n3.2 ìˆ˜ëŠ¥ë¬¸ì œ í’€ì´",
    "text": "3.2 ìˆ˜ëŠ¥ë¬¸ì œ í’€ì´\nShareGPT: íŒ©íŠ¸ì²´í¬ì™€ ìˆ˜í•™ë¬¸ì œ í’€ì´\n2023í•™ë…„ë„ ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜ ìˆ˜í•™ì˜ì—­ ë¬¸ì œë¥¼ í’€ì–´ë³´ì.\n\n\n\n\n\n\n\n\n\n\n\\(\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\\) ê°’ì€?\n\n\n\n\n\nì‹ \\[\n\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\] ì˜ ê°’ì€ \\(4\\)ì…ë‹ˆë‹¤.\nì •í™•í•œ í˜•íƒœë¡œëŠ” \\(2^{(2 - \\sqrt{2}) (2 + \\sqrt{2})}\\)ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\nìì„¸í•œ ì •ë³´ëŠ” Wolfram|Alpha ì›¹ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n\n\n\n\nê³¼ì •ë„ ì„¤ëª…í•´ì¤˜.\n\n\n\n\n\në¬¼ë¡ ì´ë‹¤. ì£¼ì–´ì§„ ì‹ì€ \\[\n\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]ì´ë‹¤.\nì´ ì‹ì„ ë‹¨ê³„ë³„ë¡œ ë¶„í•´í•´ë³´ì.\n\n3.2.1 ë‹¨ê³„ 1: ë¶„ëª¨ë¥¼ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ê¸°\në¨¼ì €, ë¶„ëª¨ì¸ \\(2^{\\sqrt{2}}\\)ë¥¼ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ ë¶„ìì™€ ë¶„ëª¨ì— \\(2^{\\sqrt{2}}\\)ë¥¼ ê³±í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´:\n\\[\n\\left(\\frac{4 \\times 2^{\\sqrt{2}}}{2^{\\sqrt{2}} \\times 2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.2 ë‹¨ê³„ 2: ë¶„ëª¨ë¥¼ í•©ì¹˜ê¸°\nì´ì œ ë¶„ëª¨ì˜ \\(2^{\\sqrt{2}} \\times 2^{\\sqrt{2}}\\)ë¥¼ í•©ì³ \\(2^{2\\sqrt{2}}\\)ë¡œ ë§Œë“ ë‹¤.\n\\[\n\\left(\\frac{4 \\times 2^{\\sqrt{2}}}{2^{2\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.3 ë‹¨ê³„ 3: ë¶„ìë¥¼ í•©ì¹˜ê¸°\në¶„ìì˜ \\(4 \\times 2^{\\sqrt{2}}\\)ë¥¼ í•©ì³ \\(2^2 \\times 2^{\\sqrt{2}} = 2^{2+\\sqrt{2}}\\)ë¡œ ë§Œë“ ë‹¤.\n\\[\n\\left(\\frac{2^{2+\\sqrt{2}}}{2^{2\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.4 ë‹¨ê³„ 4: ì§€ìˆ˜ ë²•ì¹™ ì ìš©\nì§€ìˆ˜ ë²•ì¹™ì— ë”°ë¼ ë¶„ìì™€ ë¶„ëª¨ì˜ ì§€ìˆ˜ë¥¼ ë¹¼ì¤€ë‹¤.\n\\[\n\\left(2^{(2+\\sqrt{2}) - 2\\sqrt{2}}\\right)^{2+\\sqrt{2}} = \\left(2^{(2 - \\sqrt{2})(2 + \\sqrt{2})}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.5 ë‹¨ê³„ 5: ìµœì¢… ê³„ì‚°\në§ˆì§€ë§‰ìœ¼ë¡œ, \\((2 - \\sqrt{2})(2 + \\sqrt{2})\\)ë¥¼ ê³„ì‚°í•˜ë©´ \\(4 - 2 = 2\\)ê°€ ëœë‹¤. ë”°ë¼ì„œ ìµœì¢… ê²°ê³¼ëŠ” \\(2^2 = 4\\)ì´ë‹¤.\nì´ë ‡ê²Œ í•´ì„œ \\[\n\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}} = 4\n\\]ì„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
  },
  {
    "objectID": "devday.html",
    "href": "devday.html",
    "title": "chatGPT",
    "section": "",
    "text": "New models and developer products announced at DevDay"
  },
  {
    "objectID": "devday.html#ìµœê·¼-ì§€ì‹",
    "href": "devday.html#ìµœê·¼-ì§€ì‹",
    "title": "chatGPT",
    "section": "\n2.1 ìµœê·¼ ì§€ì‹",
    "text": "2.1 ìµœê·¼ ì§€ì‹\n2021ë…„ 9ì›” â†’ 2023ë…„ 4ì›”\n\n\nGPT3-5-turbo\nGPT-4 + ë¹™ê²€ìƒ‰\nGPT-4\nGPT-4 í„°ë³´\n\n\n\n\n\n2023ë…„ 11ì›” 7ì¼ ê¸°ì¤€\n\n\n\n\n\n2023ë…„ 11ì›” 7ì¼ ê¸°ì¤€\n\n\n\n\n\n2023ë…„ 11ì›” 7ì¼ ê¸°ì¤€\n\n\n\n\n\n2023ë…„ 11ì›” 7ì¼ ê¸°ì¤€"
  },
  {
    "objectID": "devday.html#ë§¥ë½-í¬ê¸°",
    "href": "devday.html#ë§¥ë½-í¬ê¸°",
    "title": "chatGPT",
    "section": "\n2.2 ë§¥ë½ í¬ê¸°",
    "text": "2.2 ë§¥ë½ í¬ê¸°\n\n\nêµ¬ë¶„\nGPT-4 Turbo\nGPT-4 32K\nGPT-3.5 Turbo\n\n\n\në¬¸ë§¥ ì°½\n128,000 í† í°\n32,000 í† í°\n8,192 í† í°\n\n\ní˜ì´ì§€ìˆ˜\nì•½ 300 ìª½\nì•½ 75 ìª½\nì•½ 19 ìª½\n\n\nê¸°ì¤€\n427 í† í° / ìª½\n427 í† í° / ìª½\n427 í† í° / ìª½"
  },
  {
    "objectID": "devday.html#ë¹„ìš©",
    "href": "devday.html#ë¹„ìš©",
    "title": "chatGPT",
    "section": "\n2.3 ë¹„ìš©",
    "text": "2.3 ë¹„ìš©\ní™˜ìœ¨(1,300ì›”/1ë‹¬ëŸ¬)ì„ ì ìš©í•˜ì—¬ 1,000ê°œ í† í° ê¸°ì¤€ ë¹„ìš©ì„ ì‚°ì¶œí•˜ë©´ GPT-4 Turboê°€ GPT-4 ì™€ ë¹„êµí•˜ë©´ ì…ë ¥ê¸°ì¤€ \\(\\frac{1}{3}\\) ì €ë ´í•˜ë‹¤.\n\n\nëª¨í˜•\nì…ë ¥(1K í† í°)\nì¶œë ¥(1K í† í°)\n\n\n\nGPT-4 Turbo\n13.0ì›\n39.0ì›\n\n\nGPT-4\n39.0ì›\n78.0ì›\n\n\nGPT-4 32k\n78.0ì›\n156.0ì›\n\n\nGPT-3.5 Turbo\n1.3ì›\n2.6ì›\n\n\nAssistant API\n19.5ì›\n-"
  },
  {
    "objectID": "devday.html#ë‹¤ì¤‘-ëª¨ë“œì„±",
    "href": "devday.html#ë‹¤ì¤‘-ëª¨ë“œì„±",
    "title": "chatGPT",
    "section": "\n2.4 ë‹¤ì¤‘ ëª¨ë“œì„±",
    "text": "2.4 ë‹¤ì¤‘ ëª¨ë“œì„±\nâ€œGPT-4 í„°ë³´â€ëŠ” ë‹¤ì¤‘ ëª¨ë“œì„±(Multimodality)ë¥¼ ì œê³µí•œë‹¤. ê³¼ê±° í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ê°ê° ë‹¤ë¥¸ ëª¨ë“œë¡œ ì œê³µëœ ê²ƒì´ â€œGPT-4 í„°ë³´â€ì—ì„œ í†µí•©ë˜ì–´ ì œê³µëœë‹¤.\n\ní…ìŠ¤íŠ¸(GPT-4)\nì´ë¯¸ì§€(DALL-E 3)\nì˜¤ë””ì˜¤(Whisper)"
  },
  {
    "objectID": "devday.html#gpt-í”ŒëŸ¬ê·¸ì¸",
    "href": "devday.html#gpt-í”ŒëŸ¬ê·¸ì¸",
    "title": "chatGPT",
    "section": "\n2.5 GPT í”ŒëŸ¬ê·¸ì¸",
    "text": "2.5 GPT í”ŒëŸ¬ê·¸ì¸\nì»´í“¨í„°ì™€ ë””ì§€í„¸ ê¸°ìˆ ì´ ë°œì „í•¨ì— ë”°ë¼ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ëŠì„ì—†ì´ ì§„í™”í•´ì™”ë‹¤. ì´ˆê¸°ì—ëŠ” ê¸°ë³¸ì ì¸ ì„¤ì¹˜í˜• ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì£¼ë¥¼ ì´ë£¨ì—ˆìœ¼ë©°, ì´ëŠ” íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë¬¼ë¦¬ì  ë§¤ì²´ë¥¼ í†µí•´ ì»´í“¨í„°ì— ì§ì ‘ ì„¤ì¹˜ë˜ì–´ ì‚¬ìš©ëœë‹¤. ì‚¬ìš©ìëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ êµ¬ë§¤í•˜ê³  ì†Œìœ í•˜ëŠ” ê°œë…ì„ ê°€ì§€ê³  ìˆì—ˆë‹¤.\nê·¸ ë‹¤ìŒì—ëŠ” ì›¹ ì†Œí”„íŠ¸ì›¨ì–´ê°€ ë“±ì¥í•œë‹¤. ì¸í„°ë„·ì˜ ë³´ê¸‰ìœ¼ë¡œ í´ë¼ìš°ë“œ ê¸°ë°˜ì˜ ì„œë¹„ìŠ¤ë“¤ì´ ìƒê²¨ë‚˜ê¸° ì‹œì‘í•˜ë©´ì„œ, ì‚¬ìš©ìë“¤ì€ ì–¸ì œ ì–´ë””ì„œë‚˜ ì ‘ì† ê°€ëŠ¥í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì´ìš©í•˜ê²Œ ëœë‹¤. ì„¤ì¹˜ í•„ìš” ì—†ì´ ë¸Œë¼ìš°ì €ë¥¼ í†µí•´ ì ‘ê·¼í•˜ëŠ” ì´ ëª¨í˜•ì€ í¸ì˜ì„±ì„ ê·¹ëŒ€í™”í–ˆë‹¤.\nì´í›„ ìŠ¤ë§ˆíŠ¸í°ì˜ ë³´í¸í™”ì™€ í•¨ê»˜ ì•± ì†Œí”„íŠ¸ì›¨ì–´ê°€ ê¸‰ë¶€ìƒí•œë‹¤. ì•± ìŠ¤í† ì–´ë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œë°›ì•„ ëª¨ë°”ì¼ ê¸°ê¸°ì— ì„¤ì¹˜í•˜ëŠ” ì´ ëª¨í˜•ì€ íœ´ëŒ€ì„±ê³¼ ì ‘ê·¼ì„±ì„ ê°•í™”í•˜ë©° ëŒ€ì¤‘ì˜ ì¼ìƒ ì†ìœ¼ë¡œ ê¹Šìˆ™ì´ ë“¤ì–´ê°„ë‹¤.\në§ˆì§€ë§‰ìœ¼ë¡œ, ì¸ê³µì§€ëŠ¥ì˜ ë°œë‹¬ì€ GPTì™€ ê°™ì€ í”ŒëŸ¬ê·¸ì¸ ì†Œí”„íŠ¸ì›¨ì–´ì˜ ì¶œí˜„ì„ ê°€ì ¸ì˜¨ë‹¤. ì´ë“¤ì€ ê¸°ì¡´ì˜ í”Œë«í¼ì´ë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ì— ë¶€ê°€ì ìœ¼ë¡œ í†µí•©ë˜ì–´, ì‚¬ìš©ì ê²½í—˜ì„ ê°œì¸í™”í•˜ê³ , í–¥ìƒì‹œí‚¤ëŠ” ì—­í• ì„ í•œë‹¤. ì‚¬ìš©ìëŠ” ì´ì œ ë³µì¡í•œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì „ë¬¸ ì§€ì‹ì´ ì—†ì–´ë„ ê³ ë„ì˜ ê¸°ëŠ¥ì„ ì´ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.\n\n\n\n\nì„¤ì¹˜í˜• SW\n\n\n\nì›¹ SW\n\n\n\nìŠ¤ë§ˆíŠ¸í° ì•±SW\n\n\n\nGPT í”ŒëŸ¬ê·¸ì¸"
  },
  {
    "objectID": "devday.html#ì €ì‘ê¶Œ-ë³´í—˜",
    "href": "devday.html#ì €ì‘ê¶Œ-ë³´í—˜",
    "title": "chatGPT",
    "section": "\n2.6 ì €ì‘ê¶Œ ë³´í—˜",
    "text": "2.6 ì €ì‘ê¶Œ ë³´í—˜\nOpenAIëŠ” ë§Œì•½ ê³ ê°ì´ OpenAIì˜ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë‹¤ê°€ ì €ì‘ê¶Œ ì¹¨í•´ì™€ ê´€ë ¨ëœ ë²•ì  ë¬¸ì œì— ì§ë©´í–ˆì„ ë•Œ, ë²•ì  ì±…ì„ì„ ì§ˆ ì¤€ë¹„ê°€ ë˜ì–´ ìˆë‹¤ê³  ê³µí‘œí–ˆë‹¤. ì´ê²ƒì€ ì €ì‘ê¶Œ ì¹¨í•´ì— ëŒ€í•œ â€™ë³´í—˜â€™ê³¼ë„ ê°™ë‹¤. êµ¬ê¸€ì´ë‚˜ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ì™€ ê°™ì€ ë‹¤ë¥¸ ëŒ€í˜• ê¸°ìˆ  íšŒì‚¬ë“¤ë„ ë¹„ìŠ·í•œ ì•½ì†ì„ í•´ì™”ìœ¼ë©°, ì´ë¡œì¨ ì‚¬ìš©ìëŠ” í•´ë‹¹ íšŒì‚¬ì˜ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•¨ì— ìˆì–´ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì €ì‘ê¶Œ ë¬¸ì œì— ëŒ€í•´ ì¢€ ë” ì•ˆì‹¬í•˜ê³  ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. OpenAIì˜ ì´ëŸ° ì¡°ì¹˜ëŠ” ê³ ê°ì´ ë§Œì•½ ì €ì‘ê¶Œ ì¹¨í•´ë¡œ ì¸í•´ ë²•ì ìœ¼ë¡œ ê³ ì†Œë¥¼ ë‹¹í•˜ê²Œ ë˜ë”ë¼ë„, OpenAIê°€ ë‚˜ì„œì„œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , í•„ìš”í•œ ë²•ì  ì¡°ì¹˜ë¥¼ ì·¨í•´ì£¼ê² ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤."
  },
  {
    "objectID": "devday.html#ë‚ ì”¨-api",
    "href": "devday.html#ë‚ ì”¨-api",
    "title": "chatGPT",
    "section": "\n4.1 ë‚ ì”¨ API",
    "text": "4.1 ë‚ ì”¨ API\nOpenWeather APIë¥¼ ê°€ì ¸ì™€ì„œ í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¨ë‹¤. locationì— ì„œìš¸(seoul)ì„ ë„£ìœ¼ë©´, ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\n\nì½”ë“œimport requests \nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()  # This loads the environment variables from .env\n\n# Now you can use these variables using os.environ\nWEATHER_API_KEY = os.getenv('WEATHER_API_KEY')\n\n# í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.\ndef get_current_weather(location, unit='celsius'):\n    # ì—¬ê¸°ì— ì‹¤ì œ ë‚ ì”¨ APIë¡œ ìš”ì²­ì„ ë³´ë‚´ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n    # ì˜ˆë¥¼ ë“¤ì–´, OpenWeatherMap APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. (API í‚¤ê°€ í•„ìš”í•˜ë‹¤)\n    # API_ENDPOINTëŠ” ì‚¬ìš©í•˜ëŠ” ë‚ ì”¨ APIì˜ ì—”ë“œí¬ì¸íŠ¸ URLì´ë‹¤.\n    API_ENDPOINT = 'http://api.openweathermap.org/data/2.5/weather'\n    API_KEY = WEATHER_API_KEY  # ì‹¤ì œ ë‚ ì”¨ API í‚¤\n\n    params = {\n        'q': location,\n        'appid': API_KEY,\n        'units': 'metric' if unit == 'celsius' else 'imperial'\n    }\n    response = requests.get(API_ENDPOINT, params=params)\n    weather_data = response.json()\n    \n    # ê°€ì •: weather_dataì—ëŠ” ë‚ ì”¨ ì •ë³´ê°€ JSON í˜•íƒœë¡œ ë“¤ì–´ ìˆë‹¤.\n    return weather_data\n\nget_current_weather(\"seoul\")\n\n\n{'coord': {'lon': 126.9778, 'lat': 37.5683}, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 6.51, 'feels_like': 6.51, 'temp_min': 5.66, 'temp_max': 7.69, 'pressure': 1022, 'humidity': 81}, 'visibility': 10000, 'wind': {'speed': 0.51, 'deg': 150}, 'clouds': {'all': 0}, 'dt': 1699449426, 'sys': {'type': 1, 'id': 8105, 'country': 'KR', 'sunrise': 1699394614, 'sunset': 1699432081}, 'timezone': 32400, 'id': 1835848, 'name': 'Seoul', 'cod': 200}"
  },
  {
    "objectID": "devday.html#ì±—gpt-ë‚ ì”¨",
    "href": "devday.html#ì±—gpt-ë‚ ì”¨",
    "title": "chatGPT",
    "section": "\n4.2 ì±—GPT ë‚ ì”¨",
    "text": "4.2 ì±—GPT ë‚ ì”¨\nì±—GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œìš¸ ë‚ ì”¨ë¥¼ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•œë‹¤. í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì§ì ‘ í™•ì¸í•  ìˆ˜ëŠ” ì—†ë‹¤.\n\nì½”ë“œimport os\nimport openai\n\n# OpenAI APIë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ë¥¼ í•œë‹¤.\nOPENAI_API_KEY = os.getenv('OPEN_API_KEY')\nopenai.api_key = OPENAI_API_KEY\n\n# ëŒ€í™”í˜• ì±—ë´‡ ëª¨í˜•ì„ ì´ìš©í•˜ì—¬ ì„œìš¸ ë‚ ì”¨ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ì‹œì‘í•œë‹¤.\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \n        \"content\": \"ì„œìš¸ ë‚ ì”¨ëŠ” ì–´ë– í•˜ëƒ?\"}\n    ]\n)\n\n# ì‘ë‹µ ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤.\nprint(response['choices'][0]['message']['content'])\n\n\nì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ë¯€ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì„œìš¸ì˜ ë‚ ì”¨ ì •ë³´ëŠ” ê¸°ìƒì²­ ë“±ì˜ ë‚ ì”¨ ì‚¬ì´íŠ¸ë‚˜ ê¸°ìƒì•±ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜ëŠ” \"ì„œìš¸ ë‚ ì”¨\"ë¼ê³  ê²€ìƒ‰í•˜ì‹œë©´ í•´ë‹¹ ì •ë³´ê°€ ë‚˜ì˜¬ ê²ƒì…ë‹ˆë‹¤."
  },
  {
    "objectID": "devday.html#function-calling",
    "href": "devday.html#function-calling",
    "title": "chatGPT",
    "section": "\n4.3 Function calling",
    "text": "4.3 Function calling\ní•¨ìˆ˜ í˜¸ì¶œ(function calling)ì„ í™œìš©í•œ ì‚¬ë¡€ë¥¼ ì‚´í´ë³´ì. 2\n\n4.3.1 í•œë²ˆ ì§„í–‰\n\nì½”ë“œimport json\nfrom datetime import date\n\nstudent_1_description = \"David Nguyen is a sophomore majoring in computer science at Stanford University. He is Asian American and has a 3.8 GPA. David is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after graduating.\"\n\nstudent_2_description=\"Ravi Patel is a sophomore majoring in computer science at the University of Michigan. He is South Asian Indian American and has a 3.7 GPA. Ravi is an active member of the university's Chess Club and the South Asian Student Association. He hopes to pursue a career in software engineering after graduating.\"\n\n# A simple prompt to extract information from \"student_description\" in a JSON format.\nprompt1 = f'''\nPlease extract the following information from the given text and return it as a JSON object:\n\nname\nmajor\nschool\ngrades\nclub\n\nThis is the body of text to extract the information from:\n{student_1_description}\n'''\n\nimport openai\n\n# Generating response back from gpt-3.5-turbo\nopenai_response = openai.ChatCompletion.create(\n    model = 'gpt-3.5-turbo',\n    messages = [{'role': 'user', 'content': prompt1}]\n)\n\n# Loading the response as a JSON object\njson_response = json.loads(openai_response['choices'][0]['message']['content'])\njson_response\n\n\n{'name': 'David Nguyen', 'major': 'computer science', 'school': 'Stanford University', 'grades': '3.8 GPA', 'club': 'Robotics Club'}\n\n4.3.2 ë°˜ë³µ\n\nì½”ë“œstudent_custom_functions = [\n    {\n        'name': 'extract_student_info',\n        'description': 'Get the student information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the person'\n                },\n                'major': {\n                    'type': 'string',\n                    'description': 'Major subject.'\n                },\n                'school': {\n                    'type': 'string',\n                    'description': 'The university name.'\n                },\n                'grades': {\n                    'type': 'integer',\n                    'description': 'GPA of the student.'\n                },\n                'club': {\n                    'type': 'string',\n                    'description': 'School club for extracurricular activities. '\n                }\n                \n            }\n        }\n    }\n]\n\nstudent_description = [student_1_description,student_2_description]\nfor sample in student_description:\n    response = openai.ChatCompletion.create(\n        model = 'gpt-3.5-turbo',\n        messages = [{'role': 'user', 'content': sample}],\n        functions = student_custom_functions,\n        function_call = 'auto'\n    )\n\n    # Loading the response as a JSON object\n    json_response = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n    print(json_response)\n\n\n{'name': 'David Nguyen', 'major': 'computer science', 'school': 'Stanford University', 'grades': 3.8, 'club': 'Robotics Club'}\n{'name': 'Ravi Patel', 'major': 'computer science', 'school': 'University of Michigan', 'grades': 3.7, 'club': 'Chess Club'}\n\n4.3.3 ì—¬ëŸ¬ ì‘ì—…\n\nì½”ë“œcustom_functions = [\n    {\n        'name': 'extract_student_info',\n        'description': 'Get the student information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the person'\n                },\n                'major': {\n                    'type': 'string',\n                    'description': 'Major subject.'\n                },\n                'school': {\n                    'type': 'string',\n                    'description': 'The university name.'\n                },\n                'grades': {\n                    'type': 'integer',\n                    'description': 'GPA of the student.'\n                },\n                'club': {\n                    'type': 'string',\n                    'description': 'School club for extracurricular activities. '\n                }\n                \n            }\n        }\n    },\n    {\n        'name': 'extract_school_info',\n        'description': 'Get the school information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the school.'\n                },\n                'ranking': {\n                    'type': 'integer',\n                    'description': 'QS world ranking of the school.'\n                },\n                'country': {\n                    'type': 'string',\n                    'description': 'Country of the school.'\n                },\n                'no_of_students': {\n                    'type': 'integer',\n                    'description': 'Number of students enrolled in the school.'\n                }\n            }\n        }\n    }\n]\n\nschool_1_description = \"Stanford University is a private research university located in Stanford, California, United States. It was founded in 1885 by Leland Stanford and his wife, Jane Stanford, in memory of their only child, Leland Stanford Jr. The university is ranked #5 in the world by QS World University Rankings. It has over 17,000 students, including about 7,600 undergraduates and 9,500 graduates23. \"\n\ndescription = [student_1_description, school_1_description]\nfor i in description:\n    response = openai.ChatCompletion.create(\n        model = 'gpt-3.5-turbo',\n        messages = [{'role': 'user', 'content': i}],\n        functions = custom_functions,\n        function_call = 'auto'\n    )\n\n    # Loading the response as a JSON object\n    json_response = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n    print(json_response)\n    \n\n\n{'name': 'David Nguyen', 'major': 'computer science', 'school': 'Stanford University', 'grades': 3.8, 'club': 'Robotics Club'}\n{'name': 'Stanford University', 'ranking': 5, 'country': 'United States', 'no_of_students': 17000}"
  },
  {
    "objectID": "openai_api_turbo.html",
    "href": "openai_api_turbo.html",
    "title": "chatGPT",
    "section": "",
    "text": "Farzad Mahmoodinobar, â€œOpenAI API â€” Intro & Implementation of the Models Behind ChatGPT - A programmatic approach to use models behind ChatGPT.â€\n2023ë…„ 11ì›” openai APIê°€ ëŒ€ê·œëª¨ ì—…ë°ì´íŠ¸ê°€ ì´ë¤„ì¡Œë‹¤. ì´ì— ë”°ë¼ ê¸°ì¡´ì˜ openai APIë¥¼ ì‚¬ìš©í•˜ëŠ” ì½”ë“œëŠ” ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” openai APIë¥¼ ì—…ë°ì´íŠ¸í•´ì•¼ í•œë‹¤.\n$ pip install openai --upgrade\n\n\n\n\n\n\nê²½ê³ \n\n\n\nYou tried to access openai.Completion, but this is no longer supported in openai&gt;=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n\n\n\nì½”ë“œimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"íŒŒì´ì¬í•˜ê³  R í•˜ê³  ì‹¸ìš°ë©´ ëˆ„ê°€ ì´ê²¨?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nprint(chat_completion.choices[0].message.content)\n\n\níŒŒì´ì¬ê³¼ Rì€ ë‘˜ ë‹¤ í†µê³„ ë¶„ì„ê³¼ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°•ë ¥í•œ ë„êµ¬ì´ë©° ê°ê°ì˜ ì¥ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì–¸ì–´ê°€ ì´ê¸´ë‹¤ê³  ë§í•˜ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤.\n\n- íŒŒì´ì¬ì€ ë‹¤ì–‘í•œ ì˜¤í”ˆ ì†ŒìŠ¤ íŒ¨í‚¤ì§€ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í’ë¶€í•œ ìƒíƒœê³„ë¥¼ ê°€ì§€ê³  ìˆì–´ ë²”ìš©ì ì¸ í”„ë¡œê·¸ë˜ë°ì— ì í•©í•©ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ì›¹ ê°œë°œ, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì‚¬ìš©ë  ìˆ˜ ìˆìœ¼ë©°, ì‰½ê³  ê°„ê²°í•œ ë¬¸ë²•ì„ ê°–ê³  ìˆì–´ ì…ë¬¸ìì—ê²Œ ì¹œìˆ™í•©ë‹ˆë‹¤.\n\n- Rì€ í†µê³„ ë¶„ì„ê³¼ ë°ì´í„° ì‹œê°í™”ì— íŠ¹í™”ë˜ì–´ ìˆìœ¼ë©°, í†µê³„í•™ê³¼ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë“¤ì—ê²Œ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. Rì€ í†µê³„ ê°œë°œì— ìš©ì´í•˜ë©° ë‹¤ì–‘í•œ í†µê³„ì  ëª¨ë¸ë§ê³¼ ê²€ì •, ì‹œë®¬ë ˆì´ì…˜, ë°ì´í„° ì •ì œ ë“±ì„ ìœ„í•œ íŒ¨í‚¤ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Rì€ í†µê³„ ë°ì´í„°ì— ì§‘ì¤‘í•˜ê¸° ë•Œë¬¸ì— í†µê³„ ë° ë°ì´í„° ë¶„ì„ì„ í•˜ëŠ”ë° ìˆì–´ ë” ë§ì€ ì˜µì…˜ì„ ì œê³µí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n\në”°ë¼ì„œ ì–´ë–¤ ì–¸ì–´ë¥¼ ì„ íƒí• ì§€ëŠ” ì‚¬ìš©ìì˜ ëª©ì ê³¼ ì„ í˜¸ë„, ë°°ê²½ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. íŒŒì´ì¬ì€ ë²”ìš©ì ì¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, Rì€ í†µê³„ ë¶„ì„ê³¼ ë°ì´í„° ì²˜ë¦¬ì— ì¢€ ë” íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "openai_api_turbo.html#í…ìŠ¤íŠ¸-í…Œì´ë¸”",
    "href": "openai_api_turbo.html#í…ìŠ¤íŠ¸-í…Œì´ë¸”",
    "title": "chatGPT",
    "section": "\n8.1 í…ìŠ¤íŠ¸ â†’ í…Œì´ë¸”",
    "text": "8.1 í…ìŠ¤íŠ¸ â†’ í…Œì´ë¸”\n\nì½”ë“œtable_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"\nGiven the following SQL tables, your job is to parse the text below into Pandas dataframe.\n\nDROP TABLE IF EXISTS salary;\n\nCREATE TEMPORARY TABLE salary(city VARCHAR(30), average_salary int);\n\nINSERT INTO\nsalary\nVALUES\n    ('san_francisco', '54500'),\n    ('seattle', '54100'),\n    ('new_york', '34400'),\n    ('phoenix', '31800');\n\nDROP TABLE IF EXISTS people;\n\nCREATE TEMPORARY TABLE people(\n    person_id int,\n    name VARCHAR(30),\n    gender VARCHAR(30),\n    location VARCHAR(30),\n    birth_year int,\n    birth_month VARCHAR(30),\n    birth_day int,\n    job_title VARCHAR(30),\n    salary int\n);\n\nINSERT INTO\npeople\nVALUES\n    (\n        '1',\n        'james',\n        'male',\n        'seattle',\n        '1984',\n        '9',\n        '15',\n        'software_developer',\n        '115000'\n    ),\n    (\n        '2',\n        'mary',\n        'female',\n        'new_york',\n        '1992',\n        '1',\n        '13',\n        'financial_analyst',\n        '183000'\n    ),\n    (\n        '3',\n        'john',\n        'male',\n        'san_francisco',\n        '1971',\n        '4',\n        '22',\n        'data_scientist',\n        '165000'\n    ),\n    (\n        '4',\n        'patricia',\n        'female',\n        'phoenix',\n        '1971',\n        '8',\n        '15',\n        'physician',\n        '215000'\n    ),\n    (\n        '5',\n        'michael',\n        'male',\n        'new_york',\n        '1966',\n        '1',\n        '13',\n        'retired',\n        '25000'\n    ),\n    (\n        '6',\n        'jennifer',\n        'female',\n        'phoenix',\n        '1994',\n        '12',\n        '12',\n        'data_scientist',\n        '165000'\n    );\n\"\"\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": 'Parse the text into Pandas dataframe and return the result into markdown table format'\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=2048\n)\n\nprint(table_completion.choices[0].message.content)\n\n\n|   person_id | name     | gender | location      |   birth_year | birth_month   |   birth_day | job_title          |   salary |\n|------------:|:---------|:-------|:--------------|-------------:|:--------------|------------:|:-------------------|---------:|\n|           1 | james    | male   | seattle       |         1984 | 9             |          15 | software_developer |   115000 |\n|           2 | mary     | female | new_york      |         1992 | 1             |          13 | financial_analyst  |   183000 |\n|           3 | john     | male   | san_francisco |         1971 | 4             |          22 | data_scientist     |   165000 |\n|           4 | patricia | female | phoenix       |         1971 | 8             |          15 | physician          |   215000 |\n|           5 | michael  | male   | new_york      |         1966 | 1             |          13 | retired            |    25000 |\n|           6 | jennifer | female | phoenix       |         1994 | 12            |          12 | data_scientist     |   165000 |"
  },
  {
    "objectID": "openai_api_turbo.html#ì¿¼ë¦¬-ì‘ì„±",
    "href": "openai_api_turbo.html#ì¿¼ë¦¬-ì‘ì„±",
    "title": "chatGPT",
    "section": "\n8.2 ì¿¼ë¦¬ ì‘ì„±",
    "text": "8.2 ì¿¼ë¦¬ ì‘ì„±\n\nì½”ë“œsql_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\":\n\n\"\"\"\nGiven the following SQL tables, your job is to write queries given a userâ€™ s request.\n\nDROP TABLE IF EXISTS salary;\n\nCREATE TEMPORARY TABLE salary(city VARCHAR(30), average_salary int);\n\nINSERT INTO\nsalary\nVALUES\n    ('san_francisco', '54500'),\n    ('seattle', '54100'),\n    ('new_york', '34400'),\n    ('phoenix', '31800');\n\nDROP TABLE IF EXISTS people;\n\nCREATE TEMPORARY TABLE people(\n    person_id int,\n    name VARCHAR(30),\n    gender VARCHAR(30),\n    location VARCHAR(30),\n    birth_year int,\n    birth_month VARCHAR(30),\n    birth_day int,\n    job_title VARCHAR(30),\n    salary int\n);\n\nINSERT INTO\npeople\nVALUES\n    (\n        '1',\n        'james',\n        'male',\n        'seattle',\n        '1984',\n        '9',\n        '15',\n        'software_developer',\n        '115000'\n    ),\n    (\n        '2',\n        'mary',\n        'female',\n        'new_york',\n        '1992',\n        '1',\n        '13',\n        'financial_analyst',\n        '183000'\n    ),\n    (\n        '3',\n        'john',\n        'male',\n        'san_francisco',\n        '1971',\n        '4',\n        '22',\n        'data_scientist',\n        '165000'\n    ),\n    (\n        '4',\n        'patricia',\n        'female',\n        'phoenix',\n        '1971',\n        '8',\n        '15',\n        'physician',\n        '215000'\n    ),\n    (\n        '5',\n        'michael',\n        'male',\n        'new_york',\n        '1966',\n        '1',\n        '13',\n        'retired',\n        '25000'\n    ),\n    (\n        '6',\n        'jennifer',\n        'female',\n        'phoenix',\n        '1994',\n        '12',\n        '12',\n        'data_scientist',\n        '165000'\n    );\n\"\"\"    \n        },\n        {\n            \"role\": \"user\",\n            \"content\":               \n              'Write a SQL query which returns a rank of the salaries overall and also by gender from highest to the lowest salary.'\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=2048\n)\n\nprint(sql_completion.choices[0].message.content)\n\n\nTo rank the salaries overall and by gender from highest to lowest, you can use the RANK() function in SQL. Here is the SQL query:\n\nSELECT\n    p.name,\n    p.gender,\n    p.salary,\n    RANK() OVER (ORDER BY p.salary DESC) AS overall_rank,\n    RANK() OVER (PARTITION BY p.gender ORDER BY p.salary DESC) AS gender_rank\nFROM\n    people p\nORDER BY\n    p.salary DESC;"
  },
  {
    "objectID": "openai_function_call.html",
    "href": "openai_function_call.html",
    "title": "chatGPT",
    "section": "",
    "text": "Farzad Mahmoodinobar, â€œOpenAI API â€” Intro & Implementation of the Models Behind ChatGPT - A programmatic approach to use models behind ChatGPT.â€\n\nì½”ë“œimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"í•¨ê»˜ ë‹¬ë¦´ ì¤€ë¹„ë˜ë©´ ok, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ koë¥¼ ì¶œë ¥í•´ì¤˜\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nprint(chat_completion.choices[0].message.content)\n\n\nI'm sorry, but I am an AI language model and I cannot physically run or prepare to run with you. However, if you need any advice or information about running, I'll be happy to help."
  },
  {
    "objectID": "openai_function_call.html#ë‚ ì”¨-api",
    "href": "openai_function_call.html#ë‚ ì”¨-api",
    "title": "chatGPT",
    "section": "\n2.1 ë‚ ì”¨ API",
    "text": "2.1 ë‚ ì”¨ API\nOpenWeather APIë¥¼ ê°€ì ¸ì™€ì„œ í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¨ë‹¤. locationì— ì„œìš¸(seoul)ì„ ë„£ìœ¼ë©´, ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\n\nì½”ë“œimport requests \nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()  # This loads the environment variables from .env\n\n# í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.\ndef get_current_weather(location, unit='celsius'):\n    # ì—¬ê¸°ì— ì‹¤ì œ ë‚ ì”¨ APIë¡œ ìš”ì²­ì„ ë³´ë‚´ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•œë‹¤.\n    # ì˜ˆë¥¼ ë“¤ì–´, OpenWeatherMap APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. (API í‚¤ê°€ í•„ìš”í•˜ë‹¤)\n    # API_ENDPOINTëŠ” ì‚¬ìš©í•˜ëŠ” ë‚ ì”¨ APIì˜ ì—”ë“œí¬ì¸íŠ¸ URLì´ë‹¤.\n    API_ENDPOINT = 'http://api.openweathermap.org/data/2.5/weather'\n    API_KEY = os.getenv('WEATHER_API_KEY')  # ì‹¤ì œ ë‚ ì”¨ API í‚¤\n\n    params = {\n        'q': location,\n        'appid': API_KEY,\n        'units': 'metric' if unit == 'celsius' else 'imperial'\n    }\n    response = requests.get(API_ENDPOINT, params=params)\n    weather_data = response.json()\n    \n    # ê°€ì •: weather_dataì—ëŠ” ë‚ ì”¨ ì •ë³´ê°€ JSON í˜•íƒœë¡œ ë“¤ì–´ ìˆë‹¤.\n    return weather_data\n\nseoul_weather = get_current_weather(\"seoul\")\n\nprint('í˜„ì¬ ì˜¨ë„: ' + str(seoul_weather['main']['temp']) )\n\n\n{'coord': {'lon': 126.9778, 'lat': 37.5683}, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 6.51, 'feels_like': 6.51, 'temp_min': 5.66, 'temp_max': 7.69, 'pressure': 1022, 'humidity': 81}, 'visibility': 10000, 'wind': {'speed': 0.51, 'deg': 150}, 'clouds': {'all': 0}, 'dt': 1699449426, 'sys': {'type': 1, 'id': 8105, 'country': 'KR', 'sunrise': 1699394614, 'sunset': 1699432081}, 'timezone': 32400, 'id': 1835848, 'name': 'Seoul', 'cod': 200}"
  },
  {
    "objectID": "openai_function_call.html#ì±—gpt-ë‚ ì”¨",
    "href": "openai_function_call.html#ì±—gpt-ë‚ ì”¨",
    "title": "chatGPT",
    "section": "\n2.2 ì±—GPT ë‚ ì”¨",
    "text": "2.2 ì±—GPT ë‚ ì”¨\nì±—GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œìš¸ ë‚ ì”¨ë¥¼ ë¬¼ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ ëŒ€ë‹µí•œë‹¤. í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì§ì ‘ í™•ì¸í•˜ì§€ ì•Šê³  í™˜ì˜(Halluciation)ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤.\n\nì½”ë“œimport os\nimport openai\n\n# OpenAI APIë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ë¥¼ í•œë‹¤.\nOPENAI_API_KEY = os.getenv('OPEN_API_KEY')\nopenai.api_key = OPENAI_API_KEY\n\n# ëŒ€í™”í˜• ì±—ë´‡ ëª¨í˜•ì„ ì´ìš©í•˜ì—¬ ì„œìš¸ ë‚ ì”¨ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ì‹œì‘í•œë‹¤.\n\nweather_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"ì„œìš¸ ë‚ ì”¨ëŠ” ì–´ë– í•˜ëƒ?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\n# ì‘ë‹µ ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤.\nprint(weather_response.choices[0].message.content)\n\n\ní˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë¦°ì´ ë‚ ì€ ë³´í†µ ë§‘ìŒì…ë‹ˆë‹¤. í˜„ì¬ ê¸°ì˜¨ì€ ì•½ 19ë„ì´ë©°, ì˜¤ëŠ˜ì€ í•˜ë£¨ ì¢…ì¼ ë§‘ì€ ë‚ ì”¨ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."
  },
  {
    "objectID": "openai_function_call.html#ìŠ¤í¬ë¦½íŠ¸",
    "href": "openai_function_call.html#ìŠ¤í¬ë¦½íŠ¸",
    "title": "chatGPT",
    "section": "\n3.1 ìŠ¤í¬ë¦½íŠ¸",
    "text": "3.1 ìŠ¤í¬ë¦½íŠ¸\nì§€ë¬¸ì„ ì£¼ì–´ì§€ê³  í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•´ í•„ìš”í•œ ì •ë³´ë§Œì„ ì¶”ì¶œí•œë‹¤.\n\nì½”ë“œabout_me = 'Hello! My name is David Hundley. I am a principal machine learning engineer at State Farm. I enjoy learning about AI and teaching what I learn back to others. I have two daughters. I drive a Tesla Model 3, and my favorite video game series is The Legend of Zelda.'\n\nabout_me_prompt = f'''\nPlease extract information as a JSON object. Please look for the following pieces of information.\nName\nJob title\nCompany\nNumber of children as a single integer\nCar make\nCar model\nFavorite video game series\n\nThis is the body of text to extract the information from:\n{about_me}\n'''\n\nplain_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": about_me_prompt,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=256\n)"
  },
  {
    "objectID": "openai_function_call.html#í•¨ìˆ˜-í˜¸ì¶œ",
    "href": "openai_function_call.html#í•¨ìˆ˜-í˜¸ì¶œ",
    "title": "chatGPT",
    "section": "\n3.2 í•¨ìˆ˜ í˜¸ì¶œ",
    "text": "3.2 í•¨ìˆ˜ í˜¸ì¶œ\ní•¨ìˆ˜ë¥¼ ì •ì˜í•´ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.\n\nì½”ë“œdef extract_person_info(name, job_title, num_children):\n    '''\n    Prints basic \"About Me\" information\n\n    Inputs:\n        - name (str): Name of the person\n        - job_title (str): Job title of the person\n        - num_chilren (int): The number of children the parent has.\n    '''\n\n    print(f'This person\\'s name is {name}. Their job title is {job_title}, and they have {num_children} children.')\n\ninfo_functions = [\n    {\n        'name': 'extract_person_info',\n        'description': 'Get \"About Me\" information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the person'\n                },\n                'job_title': {\n                    'type': 'string',\n                    'description': 'Job title of the person'\n                },\n                'num_children': {\n                    'type': 'integer',\n                    'description': 'Number of children the person is a parent to'\n                }\n            }\n        }\n    }\n]\n\n\ninfo_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": about_me,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    functions = info_functions,\n    function_call = 'auto'    \n)\n\nimport json\n\n# JSON ë¬¸ìì—´ ì˜ˆì‹œ\njson_str = info_response.choices[0].message.function_call.arguments\n\n# JSON ë¬¸ìì—´ì„ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\ninfo_dict = json.loads(json_str)\n\n# í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ\nname = info_dict['name']\njob_title = info_dict['job_title']\nnum_children = info_dict['num_children']\n\nprint(f\" Name: {name}\\n Job Title: {job_title}\\n Number of Children: {num_children}\\n\")"
  },
  {
    "objectID": "openai_function_call.html#í”„ë¡¬í”„íŠ¸-ê³µí•™",
    "href": "openai_function_call.html#í”„ë¡¬í”„íŠ¸-ê³µí•™",
    "title": "chatGPT",
    "section": "\n4.1 í”„ë¡¬í”„íŠ¸ ê³µí•™",
    "text": "4.1 í”„ë¡¬í”„íŠ¸ ê³µí•™\nf-stringì„ ì‚¬ìš©í•´ì„œ API í˜¸ì¶œ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•œë‹¤. ë”°ë¼ì„œ, ë³„ë„ í›„ì²˜ë¦¬ê°€ í•„ìš”í•˜ë‹¤.\n\nì½”ë“œrecipe = 'Fish and chips'\nquery = f\"\"\"What is the recipe for {recipe}? Return the ingredients list and steps separately.\"\"\"\n\ncook_response = client.chat.completions.create(\n  messages = [\n    {\n          \"role\": \"system\",\n          \"content\": \"You are the best cook in the world.\" \n      \n    },\n    {\n        \"role\": \"user\",\n        \"content\": query\n    }\n  ],\n  model=\"gpt-3.5-turbo\",\n  max_tokens=256,\n  temperature=0\n)\n\nprint(cook_response.choices[0].message.content)\n\n\nIngredients for Fish and Chips:\n- 1 lb white fish fillets (such as cod or haddock)\n- 1 cup all-purpose flour\n- 1 tsp baking powder\n- 1 tsp salt\n- 1/2 tsp black pepper\n- 1 cup cold sparkling water\n- Vegetable oil, for frying\n- 4 large potatoes, peeled and cut into thick fries\n- Salt, to taste\n\nSteps for Fish:\n1. In a shallow dish, mix together flour, baking powder, salt, and black pepper.\n2. Dip each fish fillet into the flour mixture, coating it evenly on both sides.\n3. Heat vegetable oil in a deep frying pan or pot over medium-high heat.\n4. Carefully place the coated fish fillets into the hot oil and fry for about 4-5 minutes on each side, or until golden brown and crispy.\n5. Once cooked, remove the fish from the oil and place on a paper towel-lined plate to drain excess oil.\n\nSteps for Chips:\n1. Rinse the cut potato fries under cold water to remove excess starch.\n2. In a large pot, heat vegetable oil over medium-high heat until it reaches about 350Â°F (175Â°C).\n3. Carefully add the potato"
  },
  {
    "objectID": "openai_function_call.html#í•¨ìˆ˜-í˜¸ì¶œ-1",
    "href": "openai_function_call.html#í•¨ìˆ˜-í˜¸ì¶œ-1",
    "title": "chatGPT",
    "section": "\n4.2 í•¨ìˆ˜ í˜¸ì¶œ",
    "text": "4.2 í•¨ìˆ˜ í˜¸ì¶œ\ní•¨ìˆ˜ í˜¸ì¶œ(function calling) ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ê²°ê³¼ë¥¼ ë‚˜ëˆ  êµ¬ë³„í•  ìˆ˜ ìˆë‹¤. í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìš”ë¦¬ì¬ë£Œì™€ ìš”ë¦¬ì ˆì°¨ê°€ í•¨ê»˜ ì¶œë ¥ë˜ì–´ ì´ë¥¼ ì¬í™œìš©í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ í¬ë‹¤. í•¨ìˆ˜ í˜¸ì¶œì„ ì‚¬ìš©í•´ì„œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì.\n\nì½”ë“œcook_funciton = [\n    {\n        \"name\": \"return_recipe\",\n        \"description\": \"Return the recipe asked\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"ingredients\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ingredients list.\"\n                },\n                \"steps\": {\n                    \"type\": \"string\",\n                    \"description\": \"The recipe steps.\"\n                },\n            },\n            },\n            \"required\": [\"ingredients\",\"steps\"],\n        }\n]\n\nrecipe_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": query,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    functions = cook_funciton,\n    function_call = 'auto'    \n)\n\n# JSON ë¬¸ìì—´ ì˜ˆì‹œ\nrecipe_json = recipe_response.choices[0].message.function_call.arguments\n\nimport json\n\n# JSON ë¬¸ìì—´ì„ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\nrecipe_dict = json.loads(recipe_json)\n\n# í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ\nrecipe_ingredients = recipe_dict['ingredients']\nrecipe_steps = recipe_dict['steps']\n\nprint(f\"ì¬ë£Œ: \\n{recipe_ingredients}\\n\\nìš”ë¦¬ì ˆì°¨: \\n{recipe_steps}\")\n\n\nì¬ë£Œ: \nFish\nPotatoes\nFlour\nSalt\nPepper\nBaking powder\nMilk\nBeer\nVegetable oil\n\nìš”ë¦¬ì ˆì°¨: \n1. Slice potatoes into fries\n2. Mix flour, salt, pepper, and baking powder\n3. Add milk and beer to flour mixture\n4. Dip fish into batter\n5. Fry fish and fries in vegetable oil until golden brown"
  },
  {
    "objectID": "openai_function_call.html#json-ì¶œë ¥",
    "href": "openai_function_call.html#json-ì¶œë ¥",
    "title": "chatGPT",
    "section": "\n4.3 JSON ì¶œë ¥",
    "text": "4.3 JSON ì¶œë ¥\nOpenAI ê°œë°œì ì»¨í¼ëŸ°ìŠ¤ì—ì„œ ìƒˆë¡­ê²Œ ì†Œê°œëœ JSON ì¶œë ¥ì„ ì§€ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì‚¬ìš©í•œë‹¤. 2\n\nì½”ë“œjson_response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo-1106\", # \"gpt-4-1106-preview\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are the best cook in the world. Your response should be in JSON format.\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": query,\n        }\n    ],\n    response_format={ \"type\": \"json_object\" }\n)\n\n# JSON ë¬¸ìì—´ ì˜ˆì‹œ\nrecipe_gpt_json = json_response.choices[0].message.content\n\nimport json\nrecipe_dict = json.loads(recipe_gpt_json)\n\nprint(recipe_dict['recipe']['name'])\n# Fish and Chips\nprint(recipe_dict['recipe']['ingredients'])\n# {'fish': '2 fillets of cod or haddock', 'potatoes': '4 large potatoes', 'flour': '1 cup', 'baking powder': '2 tsp', 'salt': '1 tsp', 'milk': '1 cup', 'egg': '1', 'oil': 'for frying'}\nprint(recipe_dict['recipe']['steps'])\n# ['Peel and cut the potatoes into thick strips for the chips.', 'Rinse and pat dry the fish fillets. Cut them into manageable pieces.', 'In a bowl, mix together the flour, baking powder, and salt. In another bowl, whisk together the milk and egg.', \"Dip each piece of fish into the flour mixture, then into the milk mixture, and back into the flour mixture, ensuring it's well coated.\", 'Heat the oil in a deep fryer or large pot to 375Â°F (190Â°C). Fry the chips until golden and crispy, then remove and drain on paper towels.', 'Reheat the oil to 350Â°F (175Â°C). Fry the fish pieces for 4-5 minutes until they are golden and crispy. Drain on paper towels.', 'Serve the fish and chips hot, with sides such as tartar sauce, malt vinegar, or lemon wedges.']\n\n\n\n\n\n\n\n\në…¸íŠ¸\n\n\n\ní”„ë¡¬í”„íŠ¸ì— í•­ìƒ â€œJSONâ€ ìš©ì–´ë¥¼ ì¶”ê°€í•´ì•¼ë§Œ JSON ì¶œë ¥ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
  },
  {
    "objectID": "openai_multimodality.html",
    "href": "openai_multimodality.html",
    "title": "chatGPT",
    "section": "",
    "text": "2023ë…„ 11ì›” ì—´ë¦° OpenAI ê°œë°œì ì»¨í¼ëŸ°ìŠ¤ì—ì„œ ê¸°ì¡´ OpenAI API ì¸í„°í˜ì´ìŠ¤ê°€ ëŒ€ëŒ€ì ì¸ ê°œì„ ì‘ì—…ì´ ì´ë¤„ì¡Œë‹¤."
  },
  {
    "objectID": "openai_multimodality.html#ì´ë¯¸ì§€-í…ìŠ¤íŠ¸",
    "href": "openai_multimodality.html#ì´ë¯¸ì§€-í…ìŠ¤íŠ¸",
    "title": "chatGPT",
    "section": "\n3.1 ì´ë¯¸ì§€ â†’ í…ìŠ¤íŠ¸",
    "text": "3.1 ì´ë¯¸ì§€ â†’ í…ìŠ¤íŠ¸\ngpt-4-vision-preview ëª¨í˜•ì„ ì‚¬ìš©í•´ì„œ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë„ë¡ í•œë‹¤.\n\nì½”ë“œimage_response = client.chat.completions.create(\n    model=\"gpt-4-vision-preview\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"ëŒ€í•œë¯¼êµ­ ìµœê³  ì—­ì‚¬ì „ë¬¸ê°€ë¡œ ì—­í• ì„ ìˆ˜í–‰í•´ì¤˜.\",\n        },      \n        {\n            \"role\": \"user\",\n            \"content\": [\n                { \n                  \"type\": \"text\", \n                  \"text\": \"ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n                },\n                {\n                  \"type\": \"image_url\",\n                  \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/4/4e/An_Jung-geun.JPG\"\n                },\n            ],\n        }\n    ],\n    max_tokens=500\n)\n\nprint(image_response.choices[0].message.content)\n\n\n\n\n\n\n\n\n\nì‚¬ì§„ ì† ì¸ë¬¼ì€ ì–´ë‘ìš´ìƒ‰ì˜ ìì¼“ì„ ì…ê³  ìˆìœ¼ë©°, ë°°ê²½ì€ í°ìƒ‰ìœ¼ë¡œ ë³´ì´ëŠ” ë²½ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤. ì´ ì‚¬ëŒì€ ì¹´ë©”ë¼ë¥¼ ì§ì‹œí•˜ê³  ìˆëŠ”ë°, í‘œì •ì€ ë¹„êµì  í‰ì˜¨í•´ ë³´ì…ë‹ˆë‹¤. ì‚¬ì§„ì˜ ìƒ‰ì¡°ì™€ í’ˆì§ˆì„ í†µí•´ ì¶”ì •ì»¨ëŒ€ ì˜¤ë˜ëœ ì‚¬ì§„ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ ì‚¬ëŒì˜ ì •ì²´ì— ê´€í•œ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ, êµ¬ì²´ì ì¸ ì—­ì‚¬ì  ë°°ê²½ì´ë‚˜ ì´ ì¸ë¬¼ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤."
  },
  {
    "objectID": "openai_multimodality.html#í…ìŠ¤íŠ¸-ì´ë¯¸ì§€",
    "href": "openai_multimodality.html#í…ìŠ¤íŠ¸-ì´ë¯¸ì§€",
    "title": "chatGPT",
    "section": "\n3.2 í…ìŠ¤íŠ¸ â†’ ì´ë¯¸ì§€",
    "text": "3.2 í…ìŠ¤íŠ¸ â†’ ì´ë¯¸ì§€\ndall-e-3 ëª¨í˜•ì„ ì‚¬ìš©í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ìƒì„±í•˜ë„ë¡ í•œë‹¤.\n\nì½”ë“œfrom IPython.display import display, Image\nimport requests\n\nresponse = client.images.generate(\n  model=\"dall-e-3\",\n  prompt=\"A black Scottish fold cat with light golden eyes laying down on white sheets\",\n  size=\"1024x1024\",\n  quality=\"standard\",\n  n=1,\n)\n\n# Save the image URL\nimage_url = response.data[0].url\n\n# Fetch the image\nimage_response = requests.get(image_url)\n\n# Display the image\nimg = Image(data=image_response.content)\ndisplay(img)\n\n\n\nì½”ë“œdownload.file(url = 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-GpPkNlGHcRh9i7pQIlhT18p7/user-Qkv0ntrn5tQoUu6pocAidY5V/img-rypewgc6ys0EPhho7OTn7f5m.png?st=2023-11-16T08%3A52%3A12Z&se=2023-11-16T10%3A52%3A12Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-16T09%3A51%3A05Z&ske=2023-11-17T09%3A51%3A05Z&sks=b&skv=2021-08-06&sig=bPIlrK7Lhflj2Igsg6TWOSnT1DKQ3F2A0/vTTZSwgfI%3D', destfile = \"images/dalle_gpt4_cat.jpg\", mode = \"wb\")"
  },
  {
    "objectID": "openai_multimodality.html#í…ìŠ¤íŠ¸-ìŒì„±",
    "href": "openai_multimodality.html#í…ìŠ¤íŠ¸-ìŒì„±",
    "title": "chatGPT",
    "section": "\n4.1 í…ìŠ¤íŠ¸ â†’ ìŒì„±",
    "text": "4.1 í…ìŠ¤íŠ¸ â†’ ìŒì„±\nëŒ€í•œë¯¼êµ­ í—Œë²• ì œ1ì¥ ì œ1ì¡°ë¥¼ ì½ì–´ì£¼ëŠ” ìŒì„±ì„ ìƒì„±í•œë‹¤.\n\nëŒ€í•œë¯¼êµ­ì€ ë¯¼ì£¼ê³µí™”êµ­ì´ë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ì£¼ê¶Œì€ êµ­ë¯¼ì—ê²Œ ìˆê³ , ëª¨ë“  ê¶Œë ¥ì€ êµ­ë¯¼ìœ¼ë¡œë¶€í„° ë‚˜ì˜¨ë‹¤\n\n\nì½”ë“œfrom openai import OpenAI\n\nclient = OpenAI()\nresponse = client.audio.speech.create(\n  model=\"tts-1\",\n  voice=\"alloy\",\n  input=\"ëŒ€í•œë¯¼êµ­ì€ ë¯¼ì£¼ê³µí™”êµ­ì´ë‹¤. ëŒ€í•œë¯¼êµ­ì˜ ì£¼ê¶Œì€ êµ­ë¯¼ì—ê²Œ ìˆê³ , ëª¨ë“  ê¶Œë ¥ì€ êµ­ë¯¼ìœ¼ë¡œë¶€í„° ë‚˜ì˜¨ë‹¤\",\n)\n\n# Save to an MP3 file.\nwith open(\"data/alloy-korean.mp3\", \"wb\") as file:\n  file.write(response.content)\n  \n\n\n\nì½”ë“œlibrary(av)\nlibrary(embedr)\n\nhtml_tag_audio &lt;- function(file, type = c(\"wav\")) {\n  type &lt;- match.arg(type)\n  htmltools::tags$audio(\n    controls = \"\",\n    htmltools::tags$source(\n      src = file,\n      type = glue::glue(\"audio/{type}\", type = type)\n    )\n  )\n}\n\nembedr::embed_audio(\"data/alloy-korean.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "openai_multimodality.html#ìŒì„±-í…ìŠ¤íŠ¸",
    "href": "openai_multimodality.html#ìŒì„±-í…ìŠ¤íŠ¸",
    "title": "chatGPT",
    "section": "\n4.2 ìŒì„± â†’ í…ìŠ¤íŠ¸",
    "text": "4.2 ìŒì„± â†’ í…ìŠ¤íŠ¸\në‹¤ìŒìœ¼ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì˜ˆì œë¥¼ ì‚´í´ë³´ì.\nKorean Speech Database for ASR ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ì–‘í•œ í•œêµ­ì–´ ìŒì„± ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆë‹¤.\n\nì½”ë“œembedr::embed_audio(\"data/audio_0001.wav\", \"wav\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp \n\n\n\nì½”ë“œfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"data/audio_0001.wav\", \"rb\")\n\ntranscript = client.audio.transcriptions.create(\n  model=\"whisper-1\", \n  file=audio_file, \n  response_format=\"text\"\n)\n\ntranscript\n#&gt; 'ì»¤í”¼ìˆì— ì“°ëŠ” ëˆì´ ì›” 10ë§Œì›ì´ ë„˜ë”ë¼ê³ ìš”. ì†Œë¹„ë¥¼ ì¢€ ì¤„ì´ë¼ê³  ìº¡ìŠì»¤í”¼ë¨¸ì‹  êµ¬ë§¤í–ˆëŠ”ë° ìº¡ìŠê°€ê²©ì´ ë„ˆë¬´ ë‚˜ê°€ì„œ ê·¸ê²Œ ê·¸ê±°ì¸ ê²ƒ ê°™ì•„ìš”.\\n'\n\n\n\n\në¼ë²¨ ìŒì„± í…ìŠ¤íŠ¸\nì»¤í”¼ìˆì— ì“°ëŠ” ëˆì´ ì›” (100000ì›)/(ì‹­ë§Œ ì›)ì´ (ë„˜ë”ë¼ê³ ìš”)/(ë„˜ë”ë¼êµ¬ìš”). ì†Œë¹„ë¥¼ ì¢€ ì¤„ì´ë ¤ê³  ìº¡ìŠì»¤í”¼ë¨¸ì‹  êµ¬ë§¤í–ˆëŠ”ë° ìº¡ìŠ ê°€ê²©ì´ ë„ˆë¬´ ë‚˜ê°€ì„œ ê·¸ê²Œ ê·¸ê±° ê°™ì•„ìš”.\n\n\n\n\nì¸ì‹ëœ ìŒì„± í…ìŠ¤íŠ¸\nâ€˜ì»¤í”¼ìˆì— ì“°ëŠ” ëˆì´ ì›” 10ë§Œì›ì´ ë„˜ë”ë¼ê³ ìš”. ì†Œë¹„ë¥¼ ì¢€ ì¤„ì´ë¼ê³  ìº¡ìŠì»¤í”¼ë¨¸ì‹  êµ¬ë§¤í–ˆëŠ”ë° ìº¡ìŠê°€ê²©ì´ ë„ˆë¬´ ë‚˜ê°€ì„œ ê·¸ê²Œ ê·¸ê±°ì¸ ê²ƒ ê°™ì•„ìš”.â€™"
  },
  {
    "objectID": "openai_multimodality.html#ë³´ì •ì‘ì—…",
    "href": "openai_multimodality.html#ë³´ì •ì‘ì—…",
    "title": "chatGPT",
    "section": "\n4.3 ë³´ì •ì‘ì—…",
    "text": "4.3 ë³´ì •ì‘ì—…\nOpenAI Speech to text ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŒì„± ì˜¤ë””ì˜¤ë¥¼ í•„ì‚¬í•˜ëŠ” ë³´ì •ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì˜ˆì œë¥¼ ì‚´í´ë³´ì.\n\nì½”ë“œaudio_file = open(\"data/audio_0001.wav\", \"rb\")\n\nsystem_prompt = \"You are a helpful assistant for the company Korea R User Group. Your task is to correct any spelling discrepancies in the transcribed text. Make sure that the names of the following products are spelled correctly: Korea R User Group, í•œêµ­ R ì‚¬ìš©ìíšŒ. Only add necessary punctuation such as periods, commas, and capitalization, and use only the context provided.\"\n\ndef transcribe(audio_file):\n    transcript = client.audio.transcriptions.create(\n      model=\"whisper-1\", \n      file=audio_file, \n      response_format=\"text\"\n    )\n    \n    return transcript\n  \n# transcribe(audio_file)\n\ndef generate_corrected_transcript(temperature, system_prompt, audio_file):\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        temperature=temperature,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": transcribe(audio_file)\n            }\n        ]\n    )\n    return response\n\ncorrected_text = generate_corrected_transcript(0, system_prompt, audio_file)\n\ncorrected_text.choices[0].message.content\n\n\n'ì»¤í”¼ìˆì— ì“°ëŠ” ëˆì´ ì›” 10ë§Œì›ì´ ë„˜ë”ë¼ê³ ìš”. ì†Œë¹„ë¥¼ ì¢€ ì¤„ì´ë¼ê³  ìº¡ìŠ ì»¤í”¼ ë¨¸ì‹ ì„ êµ¬ë§¤í–ˆëŠ”ë°, ìº¡ìŠ ê°€ê²©ì´ ë„ˆë¬´ ë‚˜ê°€ì„œ ê·¸ê²Œ ê·¸ê±°ì¸ ê²ƒ ê°™ì•„ìš”.'"
  },
  {
    "objectID": "openai_ml.html",
    "href": "openai_ml.html",
    "title": "chatGPT",
    "section": "",
    "text": "ìœˆë„ìš° í™˜ê²½ì—ì„œ scikit-llmì„ ì„¤ì¹˜í•  ê²½ìš° Visual Studio ì»¤ë®¤ë‹ˆí‹° ë²„ì ¼ì„ ì„¤ì¹˜í•  ë•Œ C/C++ ë¹Œë“œ í™˜ê²½ë„ í•¨ê»˜ ì„¤ì¹˜í•œ í›„ scikit-llm ì„¤ì¹˜ë¥¼ ê¶Œì¥í•œë‹¤.\nScikitLLM â€“ A powerful combination of SKLearn and LLMs\n\nì½”ë“œ! pip install scikit-llm\n! pip install palmerpenguins"
  },
  {
    "objectID": "openai_ml.html#openai-api",
    "href": "openai_ml.html#openai-api",
    "title": "chatGPT",
    "section": "\n3.1 OpenAI API",
    "text": "3.1 OpenAI API\n\nì½”ë“œimport os\nfrom dotenv import load_dotenv\nfrom skllm.config import SKLLMConfig\nfrom sklearn.metrics import accuracy_score\n\nload_dotenv()\n\nSKLLMConfig.set_openai_key(os.getenv(\"OPENAI_API_KEY\"))\nSKLLMConfig.set_openai_org(os.getenv(\"OPENAI_API_ORG\"))"
  },
  {
    "objectID": "openai_ml.html#llm-ëª¨í˜•",
    "href": "openai_ml.html#llm-ëª¨í˜•",
    "title": "chatGPT",
    "section": "\n3.2 LLM ëª¨í˜•",
    "text": "3.2 LLM ëª¨í˜•\nScikit-LLM ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì„± ë¶„ì„ì„ ìœ„í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨í˜•(ZeroShotGPTClassifier)ì„ êµ¬í˜„í•˜ê³  í‰ê°€í•˜ëŠ” ê³¼ì •ì„ ì§„í–‰í•˜ê³  ê³„ì‹­ë‹ˆë‹¤. ì—¬ê¸°ì„œ ZeroShotGPTClassifierë¥¼ í†µí•´ ê°ì„± ë¶„ì„(positive, negative, neutral)ì„ ìˆ˜í–‰í•˜ê³ , ëª¨í˜•ì˜ ì •í™•ë„ë¥¼ í‰ê°€í•œë‹¤.\nêµì°¨í‘œëŠ” ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì˜ˆì¸¡ ë ˆì´ë¸” ê°„ì˜ ê´€ê³„ë¥¼ í‘œë¡œ ë‚˜íƒ€ë‚´ì–´ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ë³´ë‹¤ ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆì–´ ë„ì›€ì´ ë˜ê³ , ëª¨í˜•ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.\n\nì½”ë“œfrom skllm import ZeroShotGPTClassifier\nfrom skllm.datasets import get_classification_dataset\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# ê°ì„±ë¶„ì„ ë‚´ì¥ ë°ì´í„°ì…‹\n# labels: positive, negative, neutral\n\nsentiment_pd = get_classification_dataset()\n\nX, y = get_classification_dataset() \n\nclf = ZeroShotGPTClassifier(openai_model = \"gpt-3.5-turbo\")\n\n# Fit/Train our model\nclf.fit(X, y)\n\n# Predict/Inference on our Data using trained model\nlabels = clf.predict(X)\n\n\n\nì½”ë“œpy$labels |&gt; \n  write_rds(\"data/sentiment_labels.rds\")\n\n\n\nì½”ë“œ# ëª¨í˜• í‰ê°€\naccuracy = accuracy_score(y, labels)\nprint(\"ì •í™•ë„:\", accuracy)\n\n# êµì°¨í‘œ ìƒì„±\nconf_matrix = confusion_matrix(y, labels)\nprint(\"êµì°¨í‘œ:\\n\", conf_matrix)\n\n\nêµì°¨í‘œ:\n [[10  0  0]\n [ 3  7  0]\n [ 0  0 10]]\n\nì½”ë“œ# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\nclass_report = classification_report(y, labels)\nprint(\"ë¶„ë¥˜ ë³´ê³ ì„œ:\\n\", class_report)\n\n\në¶„ë¥˜ ë³´ê³ ì„œ:\n               precision    recall  f1-score   support\n\n    negative       0.77      1.00      0.87        10\n     neutral       1.00      0.70      0.82        10\n    positive       1.00      1.00      1.00        10\n\n    accuracy                           0.90        30\n   macro avg       0.92      0.90      0.90        30\nweighted avg       0.92      0.90      0.90        30\n\nì½”ë“œlibrary(reticulate)\nlibrary(tidyverse)\n\nsentiment_tbl &lt;- tibble(label = py$sentiment_pd[[2]], text = py$sentiment_pd[[1]])\n\nsentiment_tbl |&gt;\n  slice(1:10) |&gt; \n  gt::gt()"
  }
]