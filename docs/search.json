[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 근간모형 개발자\n\n\n\n\n\n2 AI 응용제품 개발자\n\n\n\n\n\n3 AI 제품 사용자"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "chatGPT가 연 새로운 시대를 데이터 과학자와 함께 합니다."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "블로그",
    "section": "",
    "text": "AI가 쏘아올린 작은 공\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAI가 기존 데이터 과학 패러다임을 바꾸고 있습니다.\n\n\n\n\n\n\n2023년 02월 21일\n\n\n이광춘\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\n비쥬얼 스튜디오 코드 IDE를 사용하여 개발 생산성을 높인다.\n\n\n\n\n\n\n2023년 01월 26일\n\n\n이광춘\n\n\n\n\n\n\n일치 없음"
  },
  {
    "objectID": "codex.html",
    "href": "codex.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 Codex\nLow-code and GPT-3: easier said than done with OpenAI Codex\n\n주석을 코드로 전환\n맥락을 보고 다음 코드를 자동 작성\n라이브러리, API 등 추천을 통해 새로운 지식 전달\n주석 자동 추가\n동일한 기능을 갖지면 효율성 좋은 코드로 변환\n\n2 이미지 생성\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nastronaut <- image_read(response$data$url)\nprint(astronaut)\n#> # A tibble: 1 × 7\n#>   format width height colorspace matte filesize density\n#>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n#> 1 PNG      256    256 sRGB       FALSE   197109 72x72\n\n\n\n\n\n\n\n\n3 예측모형\n\n코드penguins_classification_instruction <- \n  glue::glue(\"# R language\\n\",\n             \"Build sex classification machine learning model withe palmer penguin datatset\\n\",\n             \"Use palmer penguins data package for dataset\\n\",\n             \"Use tidymodels framework\\n\",\n             \"Use random forest model\\n\",\n             \"Include evaluation metrics including accruacy, precision, reall\")\n\nbuild_model <- create_completion(\n    model=\"code-davinci-002\",\n    prompt = penguins_classification_instruction,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\n\n\n코드\nparsed_code <- str_split(build_model$choices$text, \"\\n\")[[1]]\n\nwrite_lines(parsed_code, \"palmer_penguins.Rmd\")"
  },
  {
    "objectID": "deepL.html",
    "href": "deepL.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 deeplR 패키지\n한국에서는 서비스가 되지 않아 API를 사용할 수 없어요… 근데 일본은 ㅎㅎ\n\n코드library(deeplr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "hf.html",
    "href": "hf.html",
    "title": "chatGPT",
    "section": "",
    "text": "파이썬을 계속 사용하다보니 무조건 가상환경을 사용해야 한다는 걸 절실히 느끼게 된다. 시간이 지나면 어떤 패키지들을 설치했었는지 확인이 되지 않고 어떤 것이 문제가 되어 잘 돌던 코드가 제대로 실행되지 않는지 파악이 힘드는 지경에 이르게 된다.\n파이썬3에서 venv, virtualenv 두가지 가상환경 팩키지가 제공되는데 선택을 해야한다. 결론은 파이썬3에서 venv가 지원되니 별도 패키지 설치없이 venv로 가는 것이 좋다.\n\npython3 -m venv <가상환경 명칭>\nsource <가상환경 명칭>/bin/activate\npip install -U pip\npip install pandas\npip freeze > requirements.txt\n\n가상환경 생성부터 주요한 가상환경 설정 방법을 순차적으로 파악해보자.\n\n\n생성\n활성화\n파이썬\npip 설치\n판다스 설치\nfreeze\nrequirements.txt\n가상환경 구조\ndeactivate\n\n\n\npy-3.10.9 tidyverse in ~/venv\n○ → python3 -m venv venv\n\n\npy-3.10.9 tidyverse in ~/venv\n○ → source venv/bin/activate\n\n## .\\venv\\Scripts\\activate ## 윈도우즈\n\n\n○ → which python\n/Users/tidyverse/venv/venv/bin/python\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install -U pip\nRequirement already satisfied: pip in ./venv/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Using cached pip-23.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install pandas\nCollecting pandas\n  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 5.7 MB/s eta 0:00:00\nCollecting pytz>=2020.1\n  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\nCollecting numpy>=1.20.3\n  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.8/19.8 MB 4.3 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.1\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting six>=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, six, numpy, python-dateutil, pandas\nSuccessfully installed numpy-1.24.2 pandas-1.5.3 python-dateutil-2.8.2 pytz-2022.7.1 six-1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze\nnumpy==1.24.2\npandas==1.5.3\npython-dateutil==2.8.2\npytz==2022.7.1\nsix==1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze > requirements.txt\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → tree -L 2\n.\n├── requirements.txt\n└── venv\n    ├── bin\n    ├── include\n    ├── lib\n    └── pyvenv.cfg\n\n4 directories, 2 files\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → deactivate\n\npy-3.10.9 tidyverse in ~/venv\n○ →"
  },
  {
    "objectID": "hf.html#환경-설정",
    "href": "hf.html#환경-설정",
    "title": "chatGPT",
    "section": "환경 설정",
    "text": "환경 설정\n파이썬 가상환경을 준비하고 transformers 및 연관 패키지를 설치한다.\n\n코드library(reticulate)\n\nuse_python(\"~/venv/venv/bin/python\")\nreticulate::py_config()\nreticulate::py_available()\n\nreticulate::py_install(\"transformers\", pip = TRUE)\nreticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)"
  },
  {
    "objectID": "hf.html#감정-분류",
    "href": "hf.html#감정-분류",
    "title": "chatGPT",
    "section": "\n3.1 감정 분류",
    "text": "3.1 감정 분류\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n코드library(reticulate)\nlibrary(tidyverse)\n\nuse_python(\"~/venv/venv/bin/python\")\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf.html#ner",
    "href": "hf.html#ner",
    "title": "chatGPT",
    "section": "\n3.2 NER",
    "text": "3.2 NER\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n코드# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf.html#질의응답",
    "href": "hf.html#질의응답",
    "title": "chatGPT",
    "section": "\n3.3 질의응답",
    "text": "3.3 질의응답\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n코드# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf.html#요약",
    "href": "hf.html#요약",
    "title": "chatGPT",
    "section": "\n3.4 요약",
    "text": "3.4 요약\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n코드summarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf.html#번역",
    "href": "hf.html#번역",
    "title": "chatGPT",
    "section": "\n3.5 번역",
    "text": "3.5 번역\nLanguage Technology Research Group at the University of Helsinki 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n코드# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\""
  },
  {
    "objectID": "hf.html#텍스트-생성",
    "href": "hf.html#텍스트-생성",
    "title": "chatGPT",
    "section": "\n3.6 텍스트 생성",
    "text": "3.6 텍스트 생성\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가 반응을 자동생성시켜 답신을 작성할 수 있다.\n\n코드generator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. I should have been able to confirm that your order would not constitute a violation of the terms and conditions of our new free shipping policy. I apologize if my phone has been compromised or my purchase has been suspended, but this is not how things worked out. Thanks so much. Thanks again. Best,\n#> \n#> John."
  },
  {
    "objectID": "hf.html#참고문헌",
    "href": "hf.html#참고문헌",
    "title": "chatGPT",
    "section": "\n3.7 참고문헌",
    "text": "3.7 참고문헌\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "hf_windows.html",
    "href": "hf_windows.html",
    "title": "chatGPT",
    "section": "",
    "text": "reticulate, “Installing Python Packages”\n\n\n생성\n환경 확인\n사용시작\n\n\n\nreticulate 패키지 conda_create() 함수로 새로운 환경을 생성한다.\n\n코드library(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n\n\n\n\nreticulate::py_available() 명령어로 파이썬 환경을 활용가능한지 확인하고 reticulate::py_config() 상세한 위치를 파악한다.\n\n코드library(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n\n\n\n\nuse_python() 함수로 파이썬 위치를 특정하고 관련 패키지 설치를 시작한다. 준비된 파이썬 가상환경에 transformers 및 연관 패키지를 설치한다.\n\n코드\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)"
  },
  {
    "objectID": "hf_windows.html#감정-분류",
    "href": "hf_windows.html#감정-분류",
    "title": "chatGPT",
    "section": "\n2.1 감정 분류",
    "text": "2.1 감정 분류\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n코드library(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf_windows.html#ner",
    "href": "hf_windows.html#ner",
    "title": "chatGPT",
    "section": "\n2.2 NER",
    "text": "2.2 NER\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n코드# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf_windows.html#질의응답",
    "href": "hf_windows.html#질의응답",
    "title": "chatGPT",
    "section": "\n2.3 질의응답",
    "text": "2.3 질의응답\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n코드# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf_windows.html#요약",
    "href": "hf_windows.html#요약",
    "title": "chatGPT",
    "section": "\n2.4 요약",
    "text": "2.4 요약\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n코드summarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf_windows.html#번역",
    "href": "hf_windows.html#번역",
    "title": "chatGPT",
    "section": "\n2.5 번역",
    "text": "2.5 번역\nLanguage Technology Research Group at the University of Helsinki 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n코드# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\""
  },
  {
    "objectID": "hf_windows.html#텍스트-생성",
    "href": "hf_windows.html#텍스트-생성",
    "title": "chatGPT",
    "section": "\n2.6 텍스트 생성",
    "text": "2.6 텍스트 생성\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가 반응을 자동생성시켜 답신을 작성할 수 있다.\n\n코드generator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you"
  },
  {
    "objectID": "hf_windows.html#참고문헌",
    "href": "hf_windows.html#참고문헌",
    "title": "chatGPT",
    "section": "\n2.7 참고문헌",
    "text": "2.7 참고문헌\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "image2image.html",
    "href": "image2image.html",
    "title": "chatGPT",
    "section": "",
    "text": "openai 패키지 create_image() 함수를 사용하여 이미지를 제작할 수 있다.\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "interview.html",
    "href": "interview.html",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n기계학습 분류모형개발할 때 클래스 불균형(class imbalance) 문제를 어떻게 처리하나요?\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n기계학습모형에서 bias 와 variance trade-off에서 존재합니다. 어떤 기계학습 모형이 bias 와 variance를 줄이는데 효과적으로 알려져 있나요?\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n리스트와 데이터프레임 자료구조의 차이점에 대해서 말씀해 주세요.\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansing이 어떻게 다른지 설명하세요.\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n제품 설명 등 텍스트 필드 칼럼이 있습니다. 기계학습 알고리즘 분류나 예측 모형에 적용시킬 수 있는 방법을 설명해주세요."
  },
  {
    "objectID": "interview.html#visualization",
    "href": "interview.html#visualization",
    "title": "chatGPT",
    "section": "\n2.1 Visualization",
    "text": "2.1 Visualization\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\nData Analytics에서 시각화는 매우 중요합니다. 어떻게 가르칠것인지 커러큘럼, 교수방법, 프로젝트 진행방법, 평가방법에 대해서 말씀해주세요. (5분)"
  },
  {
    "objectID": "interview.html#eda",
    "href": "interview.html#eda",
    "title": "chatGPT",
    "section": "\n2.2 EDA",
    "text": "2.2 EDA\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n탐색적 데이터 분석(EDA)가 훌륭한 기계학습 알고리즘 개발과 함께 매우 중요합니다. 어떻게 가르칠것인지 커러큘럼, 교수방법, 프로젝트 진행방법, 평가방법에 대해서 말씀해주세요. (5분)"
  },
  {
    "objectID": "koGPT.html",
    "href": "koGPT.html",
    "title": "chatGPT",
    "section": "",
    "text": "R 패키지\n\nhuggingfaceR\ntext\n\n\n블로그\n\nR, Reticulate, and Hugging Face Models\nHello Transformers from R\n\n\n\n\nreticulate 최신버전을 설치하고 나서, miniconda를 설치한다. 기존 설치된 경우 install_miniconda(force = TRUE) 인자를 넣어 재설치한다.\n\n코드remotes::install_github(\"rstudio/reticulate\")\nreticulate::install_miniconda(force = TRUE)\n\n\n\n\n\n\n\n\n노트\n\n\n\nminiconda 설치에 어려움이 생긴경우 rminiconda가 대안이 될 수 있다.\n\nrminiconda\n\n\n\n\n\n코드devtools::install_github(\"farach/huggingfaceR\")\n\n\n\nhuggingfaceR README.md 파일에 실린 헬로월드 텍스트 분류 모형을 돌려보자.\n\n코드library(huggingfaceR)\nlibrary(reticulate)\n\nuse_python(\"C:/Users/statkclee/AppData/Local/r-miniconda/envs/huggingfaceR/python.exe\")\n# hf_python_depends('transformers') # 빠진 라이브러리 설치\n\ndistilBERT <- hf_load_pipeline(\n  model_id = \"distilbert-base-uncased-finetuned-sst-2-english\", \n  task = \"text-classification\")\n\ndistilBERT(\"I like you. I love you\")\n#> [[1]]\n#> [[1]]$label\n#> [1] \"POSITIVE\"\n#> \n#> [[1]]$score\n#> [1] 0.9998739"
  },
  {
    "objectID": "koGPT.html#인기-모형",
    "href": "koGPT.html#인기-모형",
    "title": "chatGPT",
    "section": "\n2.1 인기 모형",
    "text": "2.1 인기 모형\n다운로드 횟수가 많은 hugginface 모형은 다음과 같다.\n\n코드library(reactable)\nmodels %>% \n  select(-private, -sha) %>% \n  reactable::reactable(\n    searchable = TRUE, minRows = 10,\n    columns = list(downloads = colDef(format = colFormat(separators  = TRUE)),\n                   model = colDef(align = \"center\"),\n                   task = colDef(align = \"center\")))"
  },
  {
    "objectID": "math.html",
    "href": "math.html",
    "title": "chatGPT",
    "section": "",
    "text": "GPT-4의 구체적인 기능이나 개선 사항은 아직 공개되지 않았지만, 일반적으로 후속 모델은 이전 모델보다 성능이 개선되는 것이 대부분이다. GPT-4의 추론능력이 GPT-3.5와 비교하여 어떤 부분이 개선되었는지 다음과 같이 예측해볼 수 있다:\n특히, GPT-4는 추론역량(Reasoning)이 이전 모델과 비교하여 향상된 것이 확인된다."
  },
  {
    "objectID": "middle_school.html#한글질문-준비",
    "href": "middle_school.html#한글질문-준비",
    "title": "chatGPT",
    "section": "\n2.1 한글질문 준비",
    "text": "2.1 한글질문 준비\n\nlibrary(tidyverse)\nlibrary(openai)\n\nkorean_question <- \"중학교에서 수학에서 나오는 연립방정식을 설명해줘\"\nkorean_question\n#> [1] \"중학교에서 수학에서 나오는 연립방정식을 설명해줘\""
  },
  {
    "objectID": "middle_school.html#질문번역",
    "href": "middle_school.html#질문번역",
    "title": "chatGPT",
    "section": "\n2.2 질문번역",
    "text": "2.2 질문번역\n\n\nkorean_question_input <- glue::glue(\"translate it into English: {korean_question}\")\n\nquestion_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = korean_question_input,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ntranslated_questions <- str_extract(question_model$choices$text, \"\\\\b[^\\\\W].+\\\\b\")\n\ntranslated_questions\n#> [1] \"Explain the system of linear equations that comes from middle school math\""
  },
  {
    "objectID": "middle_school.html#chatgpt-영문-답변",
    "href": "middle_school.html#chatgpt-영문-답변",
    "title": "chatGPT",
    "section": "\n2.3 chatGPT 영문 답변",
    "text": "2.3 chatGPT 영문 답변\n\n\nanswer_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = translated_questions,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nchatGPT_answer <- answer_model$choices$text\ncat(chatGPT_answer)\n#> \n#> \n#> A system of linear equations is a set of two or more linear equations that contains the same variables. The equations are usually referred to as simultaneous equations, as they are usually solved together.\n#> \n#> In the context of middle school math, a linear equation generally consists of two variables, and the equations are primarily used to solve problems involving rate, distance, and time. The general form of a linear equation is y=mx+b, where m is the slope of the line, x is the independent variable, and b is the y-intercept. The slope and y-intercept can be found by plotting the points that make up the equation on a graph. \n#> \n#> Once the slope and y-intercept have been determined, other linear equations can be written by substituting different values for the slope and y-intercept. For example, if the slope of a linear equation is m=5 and the y-intercept is b=3, then the equation can be written as y=5x+3. Different values can also be plugged into the equation to solve for either x or y.\n#> \n#> In a system of linear equations, two equations are combined to form one equation. By solving both equations simultaneously, a more general solution can be found. This process is usually done by using elimination, substitution, or graphing. Once the solution has been found, it can be used to answer questions about the relationships between the variables."
  },
  {
    "objectID": "middle_school.html#chatgpt-답변-번역",
    "href": "middle_school.html#chatgpt-답변-번역",
    "title": "chatGPT",
    "section": "\n2.4 chatGPT 답변 번역",
    "text": "2.4 chatGPT 답변 번역\n\n\nchatGPT_answer_request <- glue::glue(\"한국어로 번역해주세요: {chatGPT_answer}\")\n\nreturn_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = chatGPT_answer_request,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(return_model$choices$text)\n#> \n#> \n#> 회귀방정식은 동일한 변수를 포함하는 두 개 이상의 선형방정식들의 시스템입니다. 이 방정식들은 일반적으로 동시 방정식으로 불리며, 같이 풀릴 때가 많습니다.\n#> \n#> 중학교 수학에서의 선형방정식은 일반적으로 두 개의 변수를 가지며, 이 방정식들은 비율이나 거리, 시간 등 문제를 풀때 많이 사용됩니다. 선형방정식의 일반적인 형태는 y=mx+b 입니다. 여기서 m은 선의 기울기, x는 독립변수, b는 y절편입니다. 기울기와 y절편은 방정식의 점들을 그래프에 그려 구할 수 있습니다.\n#> \n#> 기울기와 y절편이 결정되면 다른 값들로 선형방정식을 작성할 수도 있습니다. 예를 들어, 선형 방정식의 기울기가 m=5이고 y절편이 b=3인 경우, y=5x+3으로 방정식을 작성할 수 있습니다. 또한 다른 값들을 방정식에 대입하여 x값 또는 y값을 구할 수도 있습니다.\n#> \n#> 회귀방정식 시스템들은 두 개의 방정식을 하나의 방정식으로 결합합니다. 두 방정식을 동시에 풀게 되어 상대적으로 더 일반적인 해답을 구할 수 있습니다."
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html",
    "href": "posts/20230126-vscode/ide_vscode.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "R을 설치한다.\n\nlanguageserver 패키지를 설치한다.\n\n\ninstall.packages(\"languageserver\")\n\n\nVisual Studio Code 에서 R extension을 설치한다.\n\n.R 파일에 개발을 시작한다.\n\n\nR extension을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. VS Code 에 필수적인 R extension은 다음을 꼽을 수 있다. R extension을 설치하면 RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 편리하다.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Code를 실행하고 R Extension 설치\n\n\n\nR Extension 설치되면 코드 창 상단에 실행버튼이 활성화되고 Ctrl + Enter 혹은 Ctrl + Shift + Enter\n\n\nR 코드 실행화면"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "href": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "title": "Visual Studio Code",
    "section": "keybindings.json",
    "text": "keybindings.json\nkeybindings.json 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 등록시킨다. 자료출처: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: '이광춘'\\ndate: '2023-01-31'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#html-미리보기",
    "href": "posts/20230126-vscode/ide_vscode.html#html-미리보기",
    "title": "Visual Studio Code",
    "section": "HTML 미리보기",
    "text": "HTML 미리보기\n.Rmd 파일을  CTRL  +  Shift  +  k  단축키로 컴파일시키면 .html 파일이 생성된다. .html 파일 결과를 직접 실시간으로 확인하고자 한다면, 마이크로소프트가 개발한 Live Preview - VS Code Extension 플러그인을 설치한다."
  },
  {
    "objectID": "posts/20230127-ide/ide_war.html",
    "href": "posts/20230127-ide/ide_war.html",
    "title": "AI가 쏘아올린 작은 공",
    "section": "",
    "text": "데이터 과학 편집기\n데이터 과학 제품과 서비스 개발을 위해서 IDE(통합개발환경)을 두고 RStudio와 Jupyter 두 진영으로 나눠 치열한 경쟁을 펼쳤다. 각자 장점을 두고 범위를 확대하면서 진정한 데이터 과학 패자가 되고자 한편의 드라마를 펼쳤다.\n그 중심에는 RStudio와 아나콘다가 있으며 마치 현대차와 기아차처럼 동일한 자동차인데 세부 구성과 디자인에 차이만 있을 뿐 어느 것이 더 우월하고 좋다는 마케팅을 펼쳤다.\n\n\n\n마이크로소프트의 등장\n데이터 과학 편집기에 Visual Studio Code가 등장하면서 큰 변화가 일어나고 있다. 특히 인공지능 기능을 탑재한 Extension이 VS Code에 추가되면서 기존 RStudio와 쥬피터 IDE가 하던 기능을 넘어 새로운 지평을 열어가고 있다.\n그 중심에는 GitHub을 마이크로소프트가 인수하면서 새로 출시한 부조종사(Copilot)이 있고 조만간 CodeGPT도 도입되면 기존 RStudio와 Jupyter는 기존과 전혀 다른 위상을 가지게 될 것으로 보인다."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 백만 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다."
  },
  {
    "objectID": "rcoding.html",
    "href": "rcoding.html",
    "title": "chatGPT",
    "section": "",
    "text": "Low-code and GPT-3: easier said than done with OpenAI Codex\n코덱스(Codex)는 OpenAI에서 개발한 획기적인 AI 기술로, 사용자가 입력한 질문에 응답하여 사람과 유사한 텍스트를 생성할 수 있다. 딥러닝 알고리즘을 사용하여 책, 기사 및 기타 형태의 서면 콘텐츠를 포함한 방대한 양의 텍스트 데이터를 분석하여 언어와 문맥에 대한 포괄적인 이해를 바탕으로 텍스트를 생성한다.코덱스는 챗봇, 가상 비서, 글쓰기 도구 등 다양한 애플리케이션과 통합하여 사용자에게 자연스럽고 유창한 텍스트 응답을 제공한다.\n코덱스의 프로그래밍 기능은 가장 강력한 애플리케이션 중 하나로 방대한 양의 코드와 문서를 분석하여 사용자가 제공한 지시명령어(Prompt)에 응답하여 코드 스니펫(Snippet)을 생성할 수 있으므로 코드를 보다 효율적이고 정확하게 작성해야 하는 개발자에게 매우 유용한 도구로 자리잡아가고 있다.\n코덱스는 파이썬, 자바, C++, R 등 다양한 프로그래밍 언어와 함께 사용할 수 있으며, 현재 코드 맥락(Context)에 따라 전체 함수나 클래스를 생성할 수 있으며, 구문적으로 정확하고 모범 사례(Best Practice)를 따르는 코드를 제안함으로써 코드 작성에 필요한 시간과 노력을 줄여 개발자가 새로운 기능을 설계하거나 기존 기능을 개선하는 등 보다 복잡한 작업에 집중할 수 있게 한다.\n코덱스의 프로그래밍 기능의 주요 이점 중 하나는 생성하는 코드의 의미와 목적을 이해한다는 점이다. 즉, 작동할 뿐만 아니라 구조적으로 강건하고 읽기 쉬운 코드를 제안하여 오류를 줄이고 코드베이스의 전반적인 품질을 개선하는 데 도움을 준다. 전반적으로 코덱스의 프로그래밍 기능은 개발자의 코드 작성 방식에 혁신을 가져올 잠재력을 가지고 있다.\n\n주석을 코드로 전환\n맥락을 보고 다음 코드를 자동 작성\n라이브러리, API 등 추천을 통해 새로운 지식 전달\n주석 자동 추가\n동일한 기능을 갖지면 효율성 좋은 코드로 변환"
  },
  {
    "objectID": "rcoding.html#주석달기",
    "href": "rcoding.html#주석달기",
    "title": "chatGPT",
    "section": "\n5.1 주석달기",
    "text": "5.1 주석달기"
  },
  {
    "objectID": "rcoding.html#roxygen-추가",
    "href": "rcoding.html#roxygen-추가",
    "title": "chatGPT",
    "section": "\n5.2 Roxygen 추가",
    "text": "5.2 Roxygen 추가"
  },
  {
    "objectID": "rcoding.html#스크립트-함수",
    "href": "rcoding.html#스크립트-함수",
    "title": "chatGPT",
    "section": "\n5.3 스크립트 → 함수",
    "text": "5.3 스크립트 → 함수"
  },
  {
    "objectID": "rcoding.html#함수에-단위-테스트-추천",
    "href": "rcoding.html#함수에-단위-테스트-추천",
    "title": "chatGPT",
    "section": "\n5.4 함수에 단위 테스트 추천",
    "text": "5.4 함수에 단위 테스트 추천"
  },
  {
    "objectID": "reticulate.html",
    "href": "reticulate.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 파이썬 환경 설정\nreticulate 패키지로 콘다 파이썬 환경을 구축한다. 필요한 경우 패키지도 설치한다.\nRiddhiman (Apr 19, 2022), ‘Getting started with Python using R and reticulate’\n\n코드# install.packages(\"reticulate\")\nlibrary(reticulate)\n\n# conda_list()\nuse_condaenv(condaenv = \"r-reticulate\")\n\n# py_install(packages = c(\"pandas\", \"scikit-learn\"))\n\n\n\n2 데이터 가져오기\n펭귄 데이터를 다운로드 받아 로컬 컴퓨터 data 폴더에 저장시킨다.\n\n코드library(tidyverse)\n\nfs::dir_create(\"data\")\ndownload.file(url = \"https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv\", destfile = \"data/penguins_cleaned.csv\")\n\npenguin_df <- readr::read_csv(\"data/penguins_cleaned.csv\")\n\npenguin_df\n#> # A tibble: 333 × 7\n#>    species island    bill_length_mm bill_depth_mm flipper_length…¹ body_…² sex  \n#>    <chr>   <chr>              <dbl>         <dbl>            <dbl>   <dbl> <chr>\n#>  1 Adelie  Torgersen           39.1          18.7              181    3750 male \n#>  2 Adelie  Torgersen           39.5          17.4              186    3800 fema…\n#>  3 Adelie  Torgersen           40.3          18                195    3250 fema…\n#>  4 Adelie  Torgersen           36.7          19.3              193    3450 fema…\n#>  5 Adelie  Torgersen           39.3          20.6              190    3650 male \n#>  6 Adelie  Torgersen           38.9          17.8              181    3625 fema…\n#>  7 Adelie  Torgersen           39.2          19.6              195    4675 male \n#>  8 Adelie  Torgersen           41.1          17.6              182    3200 fema…\n#>  9 Adelie  Torgersen           38.6          21.2              191    3800 male \n#> 10 Adelie  Torgersen           34.6          21.1              198    4400 male \n#> # … with 323 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#> #   ²​body_mass_g\n\n\n\n3 파이썬 기계학습 모형\n파이썬 sklearn 패키지로 펭귄 성별예측 모형을 구축하자.\n\n\n파이썬 코드\nR 환경 불러오기\n\n\n\n# \"code/penguin_sex_clf.py\"\n\nimport pandas as pd\npenguins = pd.read_csv('data/penguins_cleaned.csv')\n\npenguins_df = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']]\n\n# Ordinal feature encoding\n# https://www.kaggle.com/pratik1120/penguin-dataset-eda-classification-and-clustering\ndf = penguins_df.copy()\n\ntarget_mapper = {'male':0, 'female':1}\ndef target_encode(val):\n    return target_mapper[val]\n\ndf['sex'] = df['sex'].apply(target_encode)\n\n# Separating X and Y\nX = df.drop('sex', axis=1)\nY = df['sex']\n\n# Build random forest model\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X, Y)\n\n\n\n코드source_python(\"code/penguin_sex_clf.py\")\n\nclf\n#> RandomForestClassifier()\n\n\n\n\n\n\n4 시각화\n파이썬 기계학습 결과를 R로 가져와서 변수 중요도를 시각화한다.\n\n코드feat_tbl <- tibble(features = clf$feature_names_in_,\n                   importance = clf$feature_importances_)\n\nfeat_tbl %>% \n  ggplot(aes(x = fct_reorder(features, importance), y = importance)) +\n    geom_point(size = 3) +\n    geom_segment( aes(x=features, xend=features, y=0, yend=importance)) +\n    labs(y = \"Feature 중요도\", x = \"Feature\",\n         title = \"펭귄 암수 예측모형 Feature 중요도\") +\n    coord_flip() +\n    theme_bw(base_family = \"AppleGothic\")"
  },
  {
    "objectID": "BERT.html",
    "href": "BERT.html",
    "title": "chatGPT",
    "section": "",
    "text": "Context-free models: Word2Vec, Glove, FastText\nContext-embedding models(transformer based models): BERT, ELMO, Universal Sentence Encoder\n\nContext-free 모형은 단순하고 효율적이지만 텍스트의 뉴앙스를 비롯하여 의미를 잡아내는데 다소 미흡할 수 있다. 반면에 Context-based model은 강력하고 유연하지만 컴퓨팅 자원을 많이 사용하고 더 복잡하다."
  },
  {
    "objectID": "BERT.html#파이썬-코드",
    "href": "BERT.html#파이썬-코드",
    "title": "chatGPT",
    "section": "\n2.1 파이썬 코드",
    "text": "2.1 파이썬 코드\nBERT 논문 https://arxiv.org/pdf/1810.04805.pdf의 초록(Abstract)에서 질의를 하고 관련 내용을 뽑아내는 코드를 다음과 같이 작성한다. (Ravichandiran, 2021)\n# 질의응답 - 파이썬 코드\n# 출처: https://github.com/PacktPublishing/Getting-Started-with-Google-BERT/tree/main/Chapter03\n\nfrom transformers import BertForQuestionAnswering, BertTokenizer\nimport torch\n\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\n# BERT 논문 Abstract: https://arxiv.org/pdf/1810.04805.pdf\n\nquestion = \"What does the 'B' in BERT stand for?\"\nabstract = \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\n\n\nquestion = '[CLS] ' + question + '[SEP]'\nabstract = abstract + '[SEP]'\n\nquestion_tokens = tokenizer.tokenize(question)\nabstract_tokens = tokenizer.tokenize(abstract)\n\ntokens = question_tokens + abstract_tokens\ninput_ids = tokenizer.convert_tokens_to_ids(tokens)\n\nsegment_ids = [0] * len(question_tokens) + [1] * len(abstract_tokens)\n\ninput_ids = torch.tensor([input_ids])\nsegment_ids = torch.tensor([segment_ids])\n\nscores = model(input_ids, token_type_ids = segment_ids)\n\nstart_index = torch.argmax(scores['start_logits'])\nend_index = torch.argmax(scores['end_logits'])\n\nanswer = ' '.join(tokens[start_index:end_index+1])\n\n# print(' '.join(tokens[start_index:end_index+1]))\n\nBERT 임베딩 모형을 사용해서 질문과 응답을 파이썬 코드로 작성하고 나서 그 결과값을 R에서 바록 읽어 후처리 하도록 한다.\n\nlibrary(reticulate)\nlibrary(tidyverse)\n\nreticulate::source_python(\"code/BERT/BERT_QnA.py\")"
  },
  {
    "objectID": "BERT.html#질의응답-예시",
    "href": "BERT.html#질의응답-예시",
    "title": "chatGPT",
    "section": "\n2.2 질의응답 예시",
    "text": "2.2 질의응답 예시\n\n\n\n코드py$question\n#> [1] \"[CLS] What does the 'B' in BERT stand for?[SEP]\"\n\n\n\n\n코드py$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#대상-지문",
    "href": "BERT.html#대상-지문",
    "title": "chatGPT",
    "section": "\n2.3 대상 지문",
    "text": "2.3 대상 지문\n코드py$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#출력결과",
    "href": "BERT.html#출력결과",
    "title": "chatGPT",
    "section": "\n2.3 출력결과",
    "text": "2.3 출력결과\n\n코드py$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#질의응답-설정",
    "href": "BERT.html#질의응답-설정",
    "title": "chatGPT",
    "section": "\n2.2 질의응답 설정",
    "text": "2.2 질의응답 설정\nBERT를 사용해서 질문과 응답을 준비한다.\n\n\n\npy$question\n#> [1] \"[CLS] What does the 'B' in BERT stand for?[SEP]\"\n\n\n\npy$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#질의응답-결과",
    "href": "BERT.html#질의응답-결과",
    "title": "chatGPT",
    "section": "\n2.3 질의응답 결과",
    "text": "2.3 질의응답 결과\n\n# str_c(py$tokens[py$start_index$tolist()+1:py$end_index$tolist()+1], collapse = \" \")\npy$answer\n#> [1] \"bid ##ire ##ction ##al en ##code ##r representations from transformers\""
  },
  {
    "objectID": "BERT.html#접근방법",
    "href": "BERT.html#접근방법",
    "title": "chatGPT",
    "section": "\n4.1 접근방법",
    "text": "4.1 접근방법\n\nQuantization and Pruning\nDistilBERT: Knowledge Distillation\nALBERT: A Lite BERT\n\nSamuel Sučík (August 8th, 2019), “Compressing BERT for faster prediction”, RASA Blog\n\n\n\n\nQuantization\n\n\n\n\nPruning\n\n\n\n\nPruning"
  },
  {
    "objectID": "BERT.html#성능비교",
    "href": "BERT.html#성능비교",
    "title": "chatGPT",
    "section": "\n4.2 성능비교",
    "text": "4.2 성능비교\nDistilBERT, A Lite BERT(ALBERT) 변형된 BERT 모형을 논문에 제시된 NLP 작업별 성능과 크기와 속도를 BERT-base 모형과 비교해보자.\n\n\nDistilBERT (Sanh et al., 2019)\nALBERT (Lan et al., 2019)"
  },
  {
    "objectID": "BERT.html#파이썬-코드-1",
    "href": "BERT.html#파이썬-코드-1",
    "title": "chatGPT",
    "section": "\n3.1 파이썬 코드",
    "text": "3.1 파이썬 코드\nIMDB 영화평점 텍스트에 담긴 감성분석을 BERT를 사용해서 수행한다.\n# 감성분석 - 파이썬 코드\n# 출처: https://wandb.ai/mukilan/BERT_Sentiment_Analysis/reports/An-Introduction-to-BERT-And-How-To-Use-It--VmlldzoyNTIyOTA1\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\ndf = pd.read_csv('https://gist.githubusercontent.com/Mukilan-Krishnakumar/e998ecf27d11b84fe6225db11c239bc6/raw/74dbac2b992235e555df9a0a4e4d7271680e7e45/imdb_movie_reviews.csv')\ndf = df.drop('sentiment',axis=1)\n\ntokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\ndef sentiment_movie_score(movie_review):\n\ttoken = tokenizer.encode(movie_review, return_tensors = 'pt')\n\tresult = model(token)\n\treturn int(torch.argmax(result.logits))+1\n\ndf['sentiment'] = df['text'].apply(lambda x: sentiment_movie_score(x[:512]))"
  },
  {
    "objectID": "BERT.html#감성분석-결과",
    "href": "BERT.html#감성분석-결과",
    "title": "chatGPT",
    "section": "\n3.2 감성분석 결과",
    "text": "3.2 감성분석 결과\n\nsenti_raw <- read_csv('https://gist.githubusercontent.com/Mukilan-Krishnakumar/e998ecf27d11b84fe6225db11c239bc6/raw/74dbac2b992235e555df9a0a4e4d7271680e7e45/imdb_movie_reviews.csv')\n\nreticulate::source_python(\"code/BERT/BERT_sentiment.py\")\n\nsenti_tbl <- senti_raw %>% \n  rename(label = sentiment) %>% \n  bind_cols(py$df %>% select(sentiment))\n\n\nsenti_tbl %>% \n  count(label, sentiment) %>% \n  ggplot(aes(x = sentiment, y = n, fill = label)) +\n    geom_col(width = 0.3, alpha = 0.7) +\n    scale_fill_manual(values = c(\"red\", \"green\")) +\n    labs(title = \"IMDB 영화 평점 데이터셋 감성분석 결과\",\n         x = \"감성점수: 부정(1) --- 긍정(5)\",\n         y = \"영화평점 부여건수\",\n         fill = \"긍부정\") +\n    theme_minimal() +\n    theme(legend.position = \"top\")"
  },
  {
    "objectID": "BERT.html#후속-분석",
    "href": "BERT.html#후속-분석",
    "title": "chatGPT",
    "section": "\n3.3 후속 분석",
    "text": "3.3 후속 분석\n평점 4점으로 예측된 영화 평점 중 긍부정 3개 리뷰를 뽑아 직접 살펴보자.\n\nlibrary(reactable)\n\nsenti_tbl %>% \n  filter(sentiment == 4) %>% \n  group_by(label) %>% \n  slice_sample(n = 3) %>% \n  reactable::reactable(\n      columns = list(\n        text = colDef(width = 700),\n        label = colDef(width = 50),\n        sentiment = colDef(width = 50)\n  ),\n  fullWidth = TRUE\n  )"
  },
  {
    "objectID": "korBERT.html",
    "href": "korBERT.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 BERT 모형 선정\n다국어를 지원하는 BERT 모형을 활용하여 연관 자연어 처리 업무를 수행할 수 있다.\n\nbert-base-multilingual-cased\ndistilbert-base-multilingual-cased\n\ndistilbert는 BERT 모형과 비교하여 다소 성능이 떨어지나 크기, 속도 등 다른 지표에서 BERT와 대등한 지표를 제시하고 있다.\n\n2 개체명 인식\n개체명(Named Entity)은 인명, 기관명, 지명 등과 같이 문장 또는 문서에서 특정한 의미를 가지고 있는 단어 또는 어구를 지칭함.\n\n네이버 개체명인식\n한국해양대학교 - 컴퓨터공학과 자연언어처리 연구실\n국립국어원\nAI 허브\n\n\n\n네이버(14종)\n한국해양대 (10종)\n국립국어원(5종)\nAI 허브(15종)\n\n\n\n\nlibrary(tidyverse)\n\nner_tbl <- tibble::tribble(\n            ~개체명.범주,   ~태그,                          ~정의,\n           \"PERSON\", \"PER\",      \"실존, 가상 등 인물명에 해당 하는 것\",\n            \"FIELD\", \"FLD\",       \"학문 분야 및 이론, 법칙, 기술 등\",\n  \"ARTIFACTS_WORKS\", \"AFW\",        \"인공물로 사람에 의해 창조된 대상물\",\n     \"ORGANIZATION\", \"ORG\",      \"기관 및 단체와 회의/회담을 모두 포함\",\n         \"LOCATION\", \"LOC\",            \"지역명칭과 행정구역 명칭 등\",\n     \"CIVILIZATION\", \"CVL\",            \"문명 및 문화에 관련된 용어\",\n             \"DATE\", \"DAT\",                         \"날짜\",\n             \"TIME\", \"TIM\",                         \"시간\",\n           \"NUMBER\", \"NUM\",                         \"숫자\",\n            \"EVENT\", \"EVT\",        \"특정 사건 및 사고 명칭과 행사 등\",\n           \"ANIMAL\", \"ANM\",                         \"동물\",\n            \"PLANT\", \"PLT\",                         \"식물\",\n         \"MATERIAL\", \"MAT\",             \"금속, 암석, 화학물질 등\",\n             \"TERM\", \"TRM\", \"의학 용어, IT곤련 용어 등 일반 용어를 총칭\"\n  )\n\nner_tbl %>% \n  gt::gt()\n\n\n\n\n\n\n개체명.범주\n      태그\n      정의\n    \n\n\nPERSON\nPER\n실존, 가상 등 인물명에 해당 하는 것\n\n\nFIELD\nFLD\n학문 분야 및 이론, 법칙, 기술 등\n\n\nARTIFACTS_WORKS\nAFW\n인공물로 사람에 의해 창조된 대상물\n\n\nORGANIZATION\nORG\n기관 및 단체와 회의/회담을 모두 포함\n\n\nLOCATION\nLOC\n지역명칭과 행정구역 명칭 등\n\n\nCIVILIZATION\nCVL\n문명 및 문화에 관련된 용어\n\n\nDATE\nDAT\n날짜\n\n\nTIME\nTIM\n시간\n\n\nNUMBER\nNUM\n숫자\n\n\nEVENT\nEVT\n특정 사건 및 사고 명칭과 행사 등\n\n\nANIMAL\nANM\n동물\n\n\nPLANT\nPLT\n식물\n\n\nMATERIAL\nMAT\n금속, 암석, 화학물질 등\n\n\nTERM\nTRM\n의학 용어, IT곤련 용어 등 일반 용어를 총칭\n\n\n\n\n\n\n\n\n한국어에서 개체의 범주는 크게 개체이름, 시간표현, 수량표현으로 분류할 수 있다.\n\n개체이름: 인명(PER), 지명(LOC), 기관명(ORG), 기타(POH)\n시간표현: 날짜(DAT), 시간(TIM), 기간(DUR)\n수량표현: 통화(MNY), 비율(PNT), 기타 수량표현(NOH)\n\n\n\n장소(LC), 날짜(DT), 기관(OG), 시간(TI), 인물(PS)\n\n\n사람(PS), 지역(LC), 단체(OG), 인공물(AF), 날짜(DT), 시간(TI), 제도(CV), 동물(AM), 식물(PT), 단위(QT), 분야(FD), 이론(TR), 사건(EV), 물질(MT), 용어(TM)"
  },
  {
    "objectID": "hf_pipeline.html",
    "href": "hf_pipeline.html",
    "title": "chatGPT",
    "section": "",
    "text": "다국어를 지원하는 BERT 모형을 활용하여 연관 자연어 처리 업무를 수행할 수 있다.\n\nbert-base-multilingual-cased\ndistilbert-base-multilingual-cased\n\ndistilbert는 BERT 모형과 비교하여 다소 성능이 떨어지나 크기, 속도 등 다른 지표에서 BERT와 대등한 지표를 제시하고 있다.\n\n\n\n\n\n\n노트\n\n\n\nfrom transformers import pipeline\n\n# Using default model and tokenizer for the task\npipeline(\"<task-name>\")\n\n# Using a user-specified model\npipeline(\"<task-name>\", model=\"<model_name>\")\n\n# Using custom model/tokenizer as str\npipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')\n\n\nHugging Face Transformers - How to use Pipelines"
  },
  {
    "objectID": "hf_pipeline.html#파이썬-코드",
    "href": "hf_pipeline.html#파이썬-코드",
    "title": "chatGPT",
    "section": "\n3.1 파이썬 코드",
    "text": "3.1 파이썬 코드\nHF 파이프라인을 사용하여 영문 개체명인식 작업을 수행한다.\n# 감성분석 - 파이썬 코드\n# 출처: https://www.kaggle.com/code/funtowiczmo/hugging-face-transformers-how-to-use-pipelines\n\nfrom transformers import pipeline\n\n# NER 파이프라인 ---------------------------------\nner = pipeline(task = \"ner\", \n               model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n               tokenizer=\"bert-large-cased\")\n\ntext = \"John Smith works at Google\"\nentities = ner(text)\n\n# 결과 출력\nfor entity in entities:\n    print(f\"{entity['word']} -> {entity['entity']}\")"
  },
  {
    "objectID": "hf_pipeline.html#개체명-인식결과",
    "href": "hf_pipeline.html#개체명-인식결과",
    "title": "chatGPT",
    "section": "\n3.2 개체명 인식결과",
    "text": "3.2 개체명 인식결과\n\n코드library(reticulate)\nreticulate::source_python(\"code/BERT/HF_pipeline_NER.py\")\n\nto_r <- function(idx){\n\n  output_idx = py$entities %>% \n    pluck(idx)\n  \n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n}\n\nmap_dfr(1:length(py$entities), ~to_r(.x))\n#> # A tibble: 3 × 6\n#>   entity score index word   start   end\n#>   <chr>  <dbl> <int> <chr>  <int> <int>\n#> 1 I-PER  0.999     1 John       0     4\n#> 2 I-PER  1.00      2 Smith      5    10\n#> 3 I-ORG  0.998     5 Google    20    26"
  },
  {
    "objectID": "project.html#chatgpt-이전",
    "href": "project.html#chatgpt-이전",
    "title": "chatGPT",
    "section": "\n8.1 chatGPT 이전",
    "text": "8.1 chatGPT 이전\nTensorflow, Keras, Pytorch, Fast.ai 가 차례로 등장하며 딥러닝 개발 프레임워크의 전성기를 구가했다. 최근 5년동안 Google 추세를 살펴보자.\n\n\n\n\n\n코드library(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"딥러닝 프레임워크 구글 검색 추세\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()"
  },
  {
    "objectID": "project.html#chatgpt-출현",
    "href": "project.html#chatgpt-출현",
    "title": "chatGPT",
    "section": "\n8.2 chatGPT 출현",
    "text": "8.2 chatGPT 출현\nchatGPT 출현이후 Tensorflow, Keras, Pytorch, Fast.ai 는 어떻게 전개될 것인지 최근 1년동안 Google 추세를 살펴보자.\n\n코드chatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"chatGPT와 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "project.html#파이썬과-chatgpt",
    "href": "project.html#파이썬과-chatgpt",
    "title": "chatGPT",
    "section": "\n8.3 파이썬과 chatGPT",
    "text": "8.3 파이썬과 chatGPT\nchatGPT 출현이후 파이썬, tensorflow, pytorch 최근 1년동안 Google 추세를 살펴보자.\n\n코드python_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"파이썬, chatGPT, 주요 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPT는 인터넷에서 방대한 양의 데이터를 학습하여 이를 정말 잘 압축한 하나의 저장소로 이해할 수 있다. 따라서, 압축을 풀게 되면 정확히 원본을 복원할 수 있는 부분도 있지만, 그렇지 못한 부분도 당영히 있게 된다.\nTed Chiang (February 9, 2023), “ChatGPT Is a Blurry JPEG of the Web - OpenAI’s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?”, The New Yorker\nChatGPT를 “웹의 흐릿한 JPEG”으로 비유하고 있다. JPEC 기술 자체는 손실 압축기술로 무손실 압축기술로 대표적인 PNG와 대비된다. 흐릿한 이미지가 선명하지 않거나 정확하지 않은 것처럼 ChatGPT도 항상 완벽한 답변을 제공하거나 모든 질문을 제대로 이해하는 것도 아니다. 하지만 사용자와의 대화를 기반으로 끊임없이 학습하고 개선하고 있다. 더 많은 사람들이 ChatGPT를 사용할수록 사람의 언어를 더 잘 이해하고 반응할 수 있게 개발된 기술이다.\nChatGPT와 유사한 인공지능 프로그램이 너무 강력해지거나 인간을 대체할 수 있다고 우려하는 사람들도 있지만, ChatGPT는 단순히 작업을 더 쉽고 효율적으로 만드는 데 사용할 수 있는 강력한 도구일 뿐이므로 사람을 능가하거나 지배할 가능성은 거의 없다. 인공지능(ChatGPT)을 책임감 있고 윤리적으로 사용되도록 하는 것은 결국 사용자 귀책이다.\nChatGPT가 간단한 숫자계산에 문제가 있는 것은 웹상에 산재된 숫자 계산 데이터를 바탕으로 계산을 흉내낼 수는 있으나 이와 같은 방식으로 ChatGPT가 학습한 것은 명백히 잘못된 것이다. 사칙연산에 대한 일반적인 원리를 이해하게 되면 웹상에 나온 사칙연산 문제를 정확히 해결할 뿐만 아니라 웹상에 나와있지 않는 계산문제도 풀 수 있으나 현재는 그렇지 못하다.\n\n\nPNG 파일\n(비)손실 압축\n파일크기\nBMP 파일\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n자료출처: WHAT’S THE DIFFERENCE BETWEEN JPEG AND PNG: BEGINNER GUIDE\n\n독일 과학자(David Kriesel)가 제록스 복사기에서 문서에 있는 숫자를 변경하는 결함을 발견했다. 제록스 프린터가 방의 면적을 14.13m²에서 17.42m²로 넓혔고, 다른 프린터는 21.11m²에서 14.13m²로 줄였다. 숫자 문자열 중간에 특정 숫자(예: “6” 또는 “8”)가 나타나면 복사기가 해당 숫자를 다른 숫자로 바꾸는 경우가 많았다. 예를 들어, ’682’가 ’882’가 될 수 있습니다.\n처음에 건물 설계도를 스캔하고 분석하려고 할 때 이 문제를 발견했다. 원본에는 이러한 오류가 없었지만 스캔한 사본에서 특정 숫자가 변경된 것을 발견했다. 결국 그들은 사본을 만드는 과정에서 숫자가 변경된, 사용 중인 Xerox 복사기에 문제가 있다는 사실을 깨달았다.\n이 결함은 제록스 복사기에 사용되는 압축 알고리즘과 관련된 것으로 특정 숫자가 서로 가까이 있으면 알고리즘이 이를 다른 숫자로 착각하고 그에 따라 숫자를 바꾼 것이다. 이 문제가 일부 고급 모델을 포함한 다양한 제록스 복사기에 존재한다는 사실도 발견했다.\nD. KRIESEL, “Xerox scanners/photocopiers randomly alter numbers in scanned documents”\n\n\n설계도 문서\n스캔 결과\n원가표 스캔\n스캔 오류\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n모델: WorkCentre 7535"
  },
  {
    "objectID": "trends.html",
    "href": "trends.html",
    "title": "chatGPT",
    "section": "",
    "text": "백만, 5천만, 1억 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다.\n\n\n전화기부터\n기술 진화\nchatGPT 백만\n빅3 서비스\n1억명 (소요 달수)\n\n\n\n\n\n(Song, 2019)\n\n\n\n\n\n\nRita McGrath(November 25, 2013), “The Pace of Technology Adoption is Speeding Up”, Harvard Business Review\n\n\n\n\n\n\n\n\n\n\n\n\n출처: https://twitter.com/umarsaif/status/1610932387185315840\n\n\n\n\n\n\n출처: https://twitter.com/EconomyApp/status/1622029832099082241"
  },
  {
    "objectID": "trends.html#chatgpt-이전",
    "href": "trends.html#chatgpt-이전",
    "title": "chatGPT",
    "section": "\n3.1 chatGPT 이전",
    "text": "3.1 chatGPT 이전\nTensorflow, Keras, Pytorch, Fast.ai 가 차례로 등장하며 딥러닝 개발 프레임워크의 전성기를 구가했다. 최근 5년동안 Google 추세를 살펴보자.\n\n\n\n\n\n코드library(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"딥러닝 프레임워크 구글 검색 추세\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()"
  },
  {
    "objectID": "trends.html#chatgpt-출현",
    "href": "trends.html#chatgpt-출현",
    "title": "chatGPT",
    "section": "\n3.2 chatGPT 출현",
    "text": "3.2 chatGPT 출현\nchatGPT 출현이후 Tensorflow, Keras, Pytorch, Fast.ai 는 어떻게 전개될 것인지 최근 1년동안 Google 추세를 살펴보자.\n\n코드chatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"chatGPT와 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "trends.html#파이썬과-chatgpt",
    "href": "trends.html#파이썬과-chatgpt",
    "title": "chatGPT",
    "section": "\n3.3 파이썬과 chatGPT",
    "text": "3.3 파이썬과 chatGPT\nchatGPT 출현이후 파이썬, tensorflow, pytorch 최근 1년동안 Google 추세를 살펴보자.\n\n코드python_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"파이썬, chatGPT, 주요 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "intro_avi.html",
    "href": "intro_avi.html",
    "title": "chatGPT",
    "section": "",
    "text": "chatGPT를 사용하여 사단법인 한국 R 사용자회 소개 대본을 작성한다.\n다음으로 미드저니를 이용하여 사단법인 한국 R 사용자회를 소개하는 화자 이미지를 생성한다.\n클로버 더빙 서비스를 사용하여 chatGPT 가 작성한 대본으로 음성 파일(.mp3)을 제작한다.\n\nD-ID 스튜디오에 미드저니에서 작업한 이미지와 STT로 작업한 결과를 합성하여 한국 R 사용자회 소개 동영상 작업을 마무리한다.\n유튜브 채널에 올려 소셜 미디어로 한국 R 사용자회 홍보를 한다.\n\n\n사단법인 한국 R 사용자회에 대해 소개하는 소개글을 작성해줘\n\n\n\n\n\n\nchatGPT\n\n\n\n\n\n한국 R 사용자회는 데이터 분석 및 통계분야에서 전 세계적으로 사용되고 있는 R 프로그래밍 언어의 사용을 촉진하고, 연구 및 개발 분야에서 R을 활용한 다양한 응용과 기술 발전을 위해 설립된 사단법인입니다.\n한국 R 사용자회는 R 프로그래밍 언어를 사용하는 분야에서의 지식과 정보 교류, 협력과 공유를 위한 다양한 활동을 전개하고 있습니다. 회원들은 R을 활용한 다양한 분석 및 시각화 기술을 공유하고, R 패키지 개발 및 오픈소스 활용, 데이터 과학 분야에서의 협력과 커뮤니케이션 등 다양한 분야에서 활동하며 지식을 공유합니다.\n한국 R 사용자회는 국내외 R 컨퍼런스 및 세미나 개최, R 교육 및 훈련, R 활용 사례 발표, R 패키지 개발 및 유지 보수 등 다양한 활동을 통해 회원들의 R 활용 능력 향상과 지식 공유를 위한 기반을 제공하고 있습니다.\n회원으로 가입하면 R 언어 및 데이터 분석 분야에서의 최신 정보와 기술 동향을 지속적으로 업데이트 받을 수 있으며, R 패키지 개발 및 활용, 데이터 분석 기술 등에 대한 다양한 교육과 세미나, 워크샵 등을 참여할 수 있습니다.\n한국 R 사용자회는 R 프로그래밍 언어의 활용과 개발을 통해 데이터 분석 및 통계분야의 발전을 위한 지속적인 노력을 기울이고 있으며, 회원들의 활동과 참여를 통해 R 프로그래밍 언어의 활용과 발전에 기여하고 있습니다.\n\n\n\n\nMidjourney\n미드저니 AI 이미지를 잘 생성하기 위해서는 Prompt Engineering을 통해 원하는 이미지가 제작될 때까지 작업한다.\n미드저니 프롬프트 툴 웹사이트에서 Midjourney Bot 채팅 인터페이스를 사용하는 것과 비교하여 AI 이미지 작성업무에 좀더 집중할 수 있다.\nwillwulfken/MidJourney-Styles-and-Keywords-Reference GitHub 저장소에 즉시 사용가능한 템플릿이 많아 이를 활용하는 것도 AI 이미지 제작 속도 및 품질을 높일 수 있다.\n\n작성 프롬프트 https://s.mj.run/guPCzzM12wU, crepuscular rays::1 rembrandt::1 defocus::-0.5 –ar 2:1 –v 4\n\n\n\n원본 이미지\n첫 4장 이미지\n잘못 누름\n이미지 재현\n최종 이미지\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n클로버 더빙\n텍스트를 음원으로 바꿔주는 작업이 필요하다. 이를 위해서 다양한 API 서비스가 제공되지만 네이버 클로버 더빙 API 서비스를 사용하면 다양한 한국인 목소리를 넣어 구현이 가능하다.\n\nD-ID\nD-ID 스튜디오에 미드저니에서 작업한 이미지와 STT로 작업한 결과를 합성하여 한국 R 사용자회 소개 동영상 작업을 마무리한다."
  },
  {
    "objectID": "intro_avi.html#음원-제작",
    "href": "intro_avi.html#음원-제작",
    "title": "chatGPT",
    "section": "\n2.1 음원 제작",
    "text": "2.1 음원 제작\n클로버 더빙\n텍스트를 음원으로 바꿔주는 작업이 필요하다. 이를 위해서 다양한 API 서비스가 제공되지만 네이버 클로버 더빙 API 서비스를 사용하면 다양한 한국인 목소리를 넣어 구현이 가능하다."
  },
  {
    "objectID": "intro_avi.html#동영상-제작",
    "href": "intro_avi.html#동영상-제작",
    "title": "chatGPT",
    "section": "\n2.2 동영상 제작",
    "text": "2.2 동영상 제작\nD-ID\nD-ID 스튜디오에 미드저니에서 작업한 이미지와 STT로 작업한 결과를 합성하여 한국 R 사용자회 소개 동영상 작업을 마무리한다."
  },
  {
    "objectID": "intro_book.html",
    "href": "intro_book.html",
    "title": "chatGPT",
    "section": "",
    "text": "전자출판된 전자책은 다음 웹사이트에서 확인이 가능하다.\n\n전자책\n소스코드"
  },
  {
    "objectID": "intro_book.html#수정된-커리큘럼",
    "href": "intro_book.html#수정된-커리큘럼",
    "title": "chatGPT",
    "section": "\n3.1 수정된 커리큘럼",
    "text": "3.1 수정된 커리큘럼\n\n\n\n\n\n\n\n\n1주차 1주차: R 및 데이터 랭글링 소개\n\nR 개요 및 데이터 과학에서의 중요성\nR에서 데이터 랭글링(Wrangling) 및 정리의 기본 개념 소개\n\ndplyr 및 tidyr 패키지를 사용하여 데이터 필터링, 정렬, 병합 및 집계와 같은 데이터 랭글링 기법 소개\npivot_longer(), pivot_wider() 함수 사용 깔끔한 데이터 변형 \n벡터, 행렬, 데이터 프레임 및 목록과 같은 R의 데이터 구조 소개\nR에서 데이터 랭글링 기술을 연습하는 연습 및 프로젝트\n\n\n\n2주차 데이터 시각화 및 탐색적 데이터 분석(EDA)\n\n데이터 시각화 소개 및 데이터 과학에서 데이터 시각화의 중요성\n다양한 유형의 시각화를 생성하기 위한 ggplot2, gt R 패키지 사용\n데이터 분포, 상관관계, 이상값 탐지 등 EDA의 원리 소개\n분산형 차트, 히스토그램, 상자그림과 같은 데이터 탐색 기법\nR에서 데이터 시각화 및 EDA 기술을 연습할 수 있는 연습 및 프로젝트\n\n\n\n3주차 통계 분석 및 기계 학습 기초\n\nR의 통계 분석 및 기계 학습 소개\n확률 분포, 가설 테스트 및 회귀 분석과 같은 기본 통계 개념 개요\n지도 학습 및 비지도 학습과 같은 기계 학습 알고리즘과 데이터 과학에서의 응용 프로그램 소개\n머신 러닝 알고리즘 구현을 위한 tidymodels 및 mlr과 같은 R 패키지 사용\nR에서 통계 분석 및 기계 학습 기본 사항을 연습하는 연습 및 프로젝트\n\n\n\n4주차 고급 데이터 과학 기법\n\n텍스트 마이닝, 네트워크 분석, 시계열 분석과 같은 R의 고급 데이터 과학 기법 소개\n\ntidytext, 토픽모델 등 R 패키지를 활용한 감성 분석, 텍스트 분류, 토픽 모델링 등 텍스트 마이닝 개념 개요 소개\n\ntidygraph 등 R 패키지를 이용한 소셜 네트워크 분석, 중심성 측정, 커뮤니티 탐지 등 네트워크 분석 기법 소개\n예측, tidyverts 등 R 패키지를 활용한 ARIMA 모델, 예측, 추세 분석 등 시계열 분석 기법 소개\nR의 고급 데이터 과학 기법을 실습할 수 있는 실습 및 프로젝트."
  },
  {
    "objectID": "intro_book.html#작업흐름-상세",
    "href": "intro_book.html#작업흐름-상세",
    "title": "chatGPT",
    "section": "\n2.1 작업흐름 상세",
    "text": "2.1 작업흐름 상세\n각 단계별 저작흐름에 주요하게 사용된 chatGPT, DeepL, Quarto Book 도구는 다음과 같이 사용되었다.\n\n\n\n\nchatGPT 작성\n\n\n\n\nDeepL 번역 및 교정\n\n\n\n\n쿼토 출판저작\n\n\n\n그림 1: chatGPT 디지털 글쓰기 저작 흐름"
  },
  {
    "objectID": "intro_book.html#chatgpt-프롬프트",
    "href": "intro_book.html#chatgpt-프롬프트",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT 프롬프트",
    "text": "2.2 chatGPT 프롬프트\n데이터 과학 책을 저작하기 위해 chatGPT에서 사용된 지시명령어(Prompt)는 다음과 같다. chatGPT 채팅 인터페이스를 사용해서 텍스트를 생성할 경우 Seed를 적용할 기능이 없기 때문에 비결정적(non-deterministic)이라 출력결과는 사뭇 다르게 된다.\n\nwrite four weeks data science curriculum\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nWeek 1: Introduction to Data Science and Data Wrangling\n\nOverview of data science and its importance in various fields\nIntroduction to the basic concepts of data wrangling and cleaning\nTechniques for data wrangling such as filtering, sorting, merging, and aggregating data\nUse of Python libraries such as pandas for data wrangling\nExercises and projects to practice data wrangling techniques\nWeek 2: Data Visualization and Exploratory Data Analysis (EDA)\n\nWeek 2: Introduction to data visualization and its importance in data science\n\nUse of Python libraries such as matplotlib, seaborn and plotly for creating various types of visualizations\nPrinciples of EDA such as data distribution, correlation, and outliers detection\nTechniques for data exploration such as scatter plots, histograms, and box plots\nExercises and projects to practice data visualization and EDA techniques\nWeek 3: Statistical Analysis and Machine Learning Fundamentals\n\nWeek 3: Introduction to statistical analysis and machine learning\n\nOverview of basic statistical concepts such as probability distributions, hypothesis testing, and regression analysis\nIntroduction to machine learning algorithms such as supervised and unsupervised learning, and their applications in data science\nUse of Python libraries such as scikit-learn for implementing machine learning algorithms\nExercises and projects to practice statistical analysis and machine learning fundamentals Week 4: Advanced Data Science Techniques\n\nWeek 4: Introduction to advanced data science techniques such as deep learning, natural language processing, and computer vision\n\nOverview of deep learning concepts such as neural networks, convolutional neural networks (CNN), and recurrent neural networks (RNN)\nUse of Python libraries such as Tensorflow and Keras for implementing deep learning algorithms\nIntroduction to natural language processing techniques such as sentiment analysis, text classification, and named entity recognition\nIntroduction to computer vision techniques such as image classification, object detection, and segmentation\nExercises and projects to practice advanced data science techniques\n\n\n\n\n\nwrite data science curriculum with R\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nWeek 1: Introduction to R and Data Wrangling\n\nOverview of R and its importance in data science\nIntroduction to the basic concepts of data wrangling and cleaning in R\nTechniques for data wrangling such as filtering, sorting, merging, and aggregating data using dplyr and tidyr packages\nIntroduction to data structures in R such as vectors, matrices, data frames, and lists\nExercises and projects to practice data wrangling techniques in R\n\nWeek 2: Data Visualization and Exploratory Data Analysis (EDA)\n\nIntroduction to data visualization and its importance in data science\nUse of R packages such as ggplot2 and lattice for creating various types of visualizations\nPrinciples of EDA such as data distribution, correlation, and outliers detection\nTechniques for data exploration such as scatter plots, histograms, and box plots\nExercises and projects to practice data visualization and EDA techniques in R\n\nWeek 3: Statistical Analysis and Machine Learning Fundamentals\n\nIntroduction to statistical analysis and machine learning in R\nOverview of basic statistical concepts such as probability distributions, hypothesis testing, and regression analysis\nIntroduction to machine learning algorithms such as supervised and unsupervised learning, and their applications in data science\nUse of R packages such as caret and mlr for implementing machine learning algorithms\nExercises and projects to practice statistical analysis and machine learning fundamentals in R\n\nWeek 4: Advanced Data Science Techniques\n\nIntroduction to advanced data science techniques in R such as text mining, network analysis, and time series analysis\nOverview of text mining concepts such as sentiment analysis, text classification, and topic modeling using R packages such as tm and topicmodels\nIntroduction to network analysis techniques such as social network analysis, centrality measures, and community detection using R packages such as igraph and statnet\nIntroduction to time series analysis techniques such as ARIMA models, forecasting, and trend analysis using R packages such as forecast and tseries\nExercises and projects to practice advanced data science techniques in R.\n\n\n\n\n\nwrite section for \"Overview of R and its importance in data science\"\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nSure, here’s an overview of R and its importance in data science:\nR is a programming language and software environment for statistical computing and graphics. It was developed in the early 1990s by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand. Since then, it has become one of the most popular languages for data analysis, visualization, and statistical modeling. R is open source, which means that it is freely available and can be modified by anyone.\nR has a number of features that make it ideal for data science. For example, it has a large and active community of users who contribute to the development of packages for data analysis, visualization, and modeling. These packages are available for download from the Comprehensive R Archive Network (CRAN) and cover a wide range of topics, including machine learning, time series analysis, data visualization, and more.\nAnother advantage of R is its ability to handle large datasets. R has a number of packages that allow users to read in and manipulate data from various sources, including databases, spreadsheets, and text files. It also has powerful data manipulation capabilities, such as reshaping data, merging datasets, and aggregating data.\nR is also widely used in academia and industry, particularly in fields such as finance, healthcare, and marketing. In academia, R is used in research and teaching in a variety of disciplines, including statistics, economics, and social sciences. In industry, R is used by companies for data analysis, modeling, and visualization, as well as for building data products.\nOverall, R is an important tool in the data scientist’s toolbox, and its popularity continues to grow. It offers a wide range of capabilities for data analysis, visualization, and modeling, and has a large and active community of users and developers. If you’re interested in data science, learning R is definitely worth considering.\n\n\n\n\nas an author of data science book, write a section on \"Use of R packages such as tidymodels for implementing machine learning algorithms\"\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nSection: Use of R Packages such as tidymodels for Implementing Machine Learning Algorithms\nThe process of building machine learning models involves several steps such as data preparation, model training, validation, and testing. In R, there are several packages available that can help data scientists to perform these steps with ease. One of the popular packages for implementing machine learning models is tidymodels.\ntidymodels is an open-source collection of R packages designed for modeling and machine learning using the tidyverse style of programming. It provides a consistent framework for modeling that includes preprocessing, feature engineering, model tuning, and evaluation. Some of the important packages in tidymodels include:\n\ntidyverse: A collection of R packages for data wrangling, exploration, and visualization.\ndplyr: A package for data manipulation and transformation.\ntidyr: A package for data tidying and reshaping.\nggplot2: A package for creating visualizations.\ncaret: A package for building and evaluating machine learning models.\nrsample: A package for data splitting and resampling.\nparsnip: A package for model specification and tuning.\n\nThe tidymodels framework follows a consistent modeling pipeline, which includes the following steps:\n\nData preparation: In this step, data is loaded and preprocessed using various techniques such as imputation, scaling, and encoding.\nFeature engineering: This step involves creating new features from existing ones, selecting important features, and transforming features to meet the requirements of the model.\nModel specification: In this step, a machine learning model is selected and defined. The parsnip package provides a consistent interface for specifying models.\nModel tuning: This step involves tuning the model’s hyperparameters to optimize performance. The tune package provides various methods for model tuning.\nModel evaluation: In this step, the model’s performance is evaluated using various metrics such as accuracy, precision, and recall. The yardstick package provides various metrics for model evaluation.\n\nThe tidymodels framework provides a simple and intuitive way of building machine learning models in R. With the help of various packages, it simplifies the process of data preparation, feature engineering, model specification, tuning, and evaluation. This framework can be useful for data scientists working on various types of data science problems, from classification and regression to clustering and association rule mining."
  },
  {
    "objectID": "intro_paper.html",
    "href": "intro_paper.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 학술지 영문초록\n국문 학술지에 논문을 작성할 때 가장 큰 애로점 중에 하나가 영문초록으로 작성해야 된다는 점이다. 제주대 안도현 교수님이 관련하여 고품질 영문초록을 작성할 수 있는 꿀팁을 제시하여 SNS를 통해 공개해 주셨습니다. 작업흐름과 관련 지시명령어(Prompt)도 전달해 주셨습니다.\n\n\n\n\n\n\n학술지 영문초록을 딥엘과 챗지피티를 이용하면 영문교정 불필요.\n\n\n\n\n국문초록 작성\n딥엘로 국문을 영문으로 번역. DeepL\n\n번역한 영문을 ChatGPT로 윤문.\n\n\n프롬프트에 다음과 같이 입력:\n\n\nRevise the abstract to follow APA style guidelines and ensure that it falls within the word count range of 400 to 500 words.\n\n\n\n\n2 사례\n2020년 출간된 논문(이광춘, 2020)의 한글 초록을 chatGPT와 DeepL을 사용하여 논문제작에 활용해보자.\n\n논문 소스코드: 바로가기\n\nPDF 출판 논문: 다운로드\n\n\n\n\n한글 초록\n영문 초록\nDeepL 영어번역\nchatGPT 프롬프트\nchatGPT 윤문\n\n\n\n\n\n\n\n\n\n알파고가 2016년 바둑 인간 챔피언 이세돌 9단을 현격한 기량차이로 격파하면서 인공지능에 대한 관심이 급격히 증가하였다. 그와 동시에 기계가 인간의 일자리 잠식을 가속화하면서 막연한 불안감이 삽시간에 전파되었다. 기계와의 일자리 경쟁은 컴퓨터의 출현이전부터 시작되었지만 인간만의 고유한 영역으로 알고 있던 인지, 창작 등 다양한 분야에서 오히려 인간보다 더 우수한 성능과 저렴한 가격 경쟁력을 보여주면서 기존 인간의 일자리가 기계에 대체되는 것이 가시권에 들었다. 이번 문헌조사와 실증 데이터 분석을 통해서 기계가 인간의 일자리를 대체하는 자동화의 본질에 대해서 살펴보고, 인간과 기계의 업무 분장을 통해 더 생산성을 높일 수 있는 방안을 제시하고자 한다.\n\n\n\n\n\n\n\n\n\n\n\nMachines have been used simply for arithmetic operations and documentation. However, with the development of technology, a new generation of artificial intelligence has begun. Machines are not just tools that can be calculated, but they have been commercialized in various fields, such as natural language processing technology that can understand and communicate human language, or video fields, where human dependence was high. Since 2016, the AI game, “Alphago,” has defeated Lee Se-dol with a significant difference in skill, interest in AI has increased sharply. Machines have started to replace human jobs because of their excellent performance, low cost and competitive edge. In this paper, I would like to present a plan on how to use artificial intelligence to affect human jobs and how to improve productivity effectively by cooperating with machines and humans in the future.\n\n\n\n\n\n\n\n\n\n\n\nInterest in artificial intelligence skyrocketed in 2016 when AlphaGo defeated human Go champion Lee Sedol 9 by a stunning margin. At the same time, a vague sense of anxiety was quickly spread as machines accelerated the erosion of human jobs. Although the competition for jobs with machines began before the advent of computers, the replacement of existing human jobs by machines became visible as machines showed better performance and lower price competitiveness than humans in various fields such as cognition and creation, which were thought to be unique to humans. Through this literature review and empirical data analysis, we examine the nature of automation in which machines replace human jobs. and suggest ways to increase productivity through the division of labor between humans and machines.\nTranslated with www.DeepL.com/Translator (free version)\n\n\n\n\n\n\n\n\n\n\n\nRevise the abstract to follow APA style guidelines and ensure that it falls within the word count range of 400 to 500 words.\nInterest in artificial intelligence skyrocketed in 2016 when AlphaGo defeated human Go champion Lee Sedol 9 by a stunning margin. At the same time, a vague sense of anxiety was quickly spread as machines accelerated the erosion of human jobs. Although the competition for jobs with machines began before the advent of computers, the replacement of existing human jobs by machines became visible as machines showed better performance and lower price competitiveness than humans in various fields such as cognition and creation, which were thought to be unique to humans. Through this literature review and empirical data analysis, we examine the nature of automation in which machines replace human jobs. and suggest ways to increase productivity through the division of labor between humans and machines.\n\n\n\n\n\n\n\n\n\n\n\nThe rise of artificial intelligence (AI) has garnered significant attention since 2016 when AlphaGo, an AI program, defeated the human Go champion Lee Sedol. However, the growing use of machines in various fields has also fueled concerns about the displacement of human jobs. This paper presents a literature review and empirical data analysis to explore the nature of automation and suggest ways to enhance productivity by optimizing the division of labor between humans and machines.\nWhile machines have been replacing human jobs for centuries, the rapid development of AI has made it possible for machines to outperform humans in fields previously considered uniquely human, such as cognition and creation. As a result, there is a growing awareness of the impact of automation on employment opportunities. This paper aims to provide insights into this issue through a comprehensive review of relevant literature and analysis of empirical data.\nOur analysis indicates that automation can lead to the displacement of jobs that require low-level skills, but it can also create new opportunities that require higher-level skills. Furthermore, automation can enhance productivity and lower costs, thus benefiting both consumers and firms. Therefore, there is a need to strike a balance between the potential benefits and challenges of automation.\nTo maximize the advantages of automation, we propose an optimal division of labor between humans and machines. In this approach, humans are responsible for tasks that require creativity, emotional intelligence, and social skills, while machines are responsible for tasks that require precision and efficiency. This approach can lead to better job quality and increased productivity.\nIn conclusion, this paper highlights the potential impact of automation on employment and the need to optimize the division of labor between humans and machines. While automation can lead to job displacement, it can also create new opportunities and improve job quality. Therefore, policymakers and firms must consider ways to optimize the use of automation to benefit both society and the economy.\n\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\n이광춘주용우. (2020). 사람과 인공지능의 일자리 경쟁 요인과 협업 방안. 디지털경영연구 Vol.6 No.2 pp.39-50."
  },
  {
    "objectID": "middle_school.html",
    "href": "middle_school.html",
    "title": "chatGPT",
    "section": "",
    "text": "데이터 문해력에 “중학수학 - 연립방정식” 사례를 통해 적용 방향을 살펴보자."
  },
  {
    "objectID": "trends.html#트위터-샌티아고",
    "href": "trends.html#트위터-샌티아고",
    "title": "chatGPT",
    "section": "\n6.1 트위터 샌티아고",
    "text": "6.1 트위터 샌티아고\nSantiago @svpino"
  },
  {
    "objectID": "trends.html#버스탄-두남자",
    "href": "trends.html#버스탄-두남자",
    "title": "chatGPT",
    "section": "\n6.2 버스탄 두남자",
    "text": "6.2 버스탄 두남자"
  },
  {
    "objectID": "trends.html#gpt-3-언어-데이터-fa-solid-brain",
    "href": "trends.html#gpt-3-언어-데이터-fa-solid-brain",
    "title": "chatGPT",
    "section": "\n2.2 GPT-3 언어 데이터 \n",
    "text": "2.2 GPT-3 언어 데이터 \n\nGPT-3 개발에 투입된 문서갯수를 언어별로 살펴보자.\n\n코드library(tidyverse)\nlibrary(gt)\nlibrary(countrycode)\nlibrary(rvest)\nlibrary(gtExtras)\n\n## 언어 코드 \nlang_tbl <- read_html(x = 'http://www.lingoes.net/en/translator/langcode.htm') %>% \n  html_element(css = 'body > table') %>% \n  html_table() %>% \n  set_names(c(\"언어\", \"언어명\"))\n\n\ngpt_raw <- read_csv(\"https://raw.githubusercontent.com/openai/gpt-3/master/dataset_statistics/languages_by_document_count.csv\")\n\ngpt_tbl <- gpt_raw %>% \n  set_names(c(\"언어\", \"문서수\", \"비중\")) %>% \n  mutate(비중 = parse_number(비중) / 100) %>% \n  mutate(누적문서 = cumsum(문서수)) %>% \n  mutate(누적비중 = 누적문서 / sum(문서수)) %>% \n  top_n(문서수, n = 28)  \n\ngpt_gt <- gpt_tbl %>% \n  left_join(lang_tbl, by = \"언어\") %>% \n  select(언어, 언어명, 문서수, 비중, 누적비중) %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%\n    tab_options(table.width = pct(100))  %>%\n    tab_header(\n      title = md(\"**GPT-3 언어모형 개발에 사용된 언어별 문서 통계**\"),\n      subtitle = \"한국어 포함 상위 28개 언어\") %>% \n    tab_source_note(\n      source_note = \"자료출처: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\") %>% \n    tab_spanner(\n      label = \"언어코드와 언어명\",\n      columns = c(언어, 언어명)) %>% \n    tab_spanner(\n      label = \"통계수치\",\n      columns = c(문서수, 비중, 누적비중)) %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어, 언어명)) %>% \n    # tab_style(\n    #   style = cell_text(size = px(12)),\n    #   locations = cells_body(\n    #     columns = c(문서수, 비중, 누적비중)\n    #   )\n    # )  %>% \n    fmt_percent(\n      columns = c(비중, 누적비중),\n      decimals = 2\n    )  %>% \n    fmt_number(\n      columns = 문서수,\n      decimals = 0,\n      sep_mark = \",\"\n    )   %>% \n   gt_highlight_rows(\n     rows = c(1,28),\n     fill = \"lightgrey\",\n     target_col = 언어\n   )  %>% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  )  %>% \n  cols_width(\n    언어 ~ px(10),\n    언어명 ~ px(10),\n    문서수 ~ px(20),\n    비중 ~ px(30),\n    누적비중 ~ px(30)\n  )\n\ngpt_gt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-3 언어모형 개발에 사용된 언어별 문서 통계\n    \n\n한국어 포함 상위 28개 언어\n    \n\n\n\n\n        언어코드와 언어명\n      \n      \n        통계수치\n      \n    \n\n언어\n      언어명\n      문서수\n      비중\n      누적비중\n    \n\n\n\nen\nEnglish\n235,987,420\n93.69%\n93.69%\n\n\nde\nGerman\n3,014,597\n1.20%\n94.89%\n\n\nfr\nFrench\n2,568,341\n1.02%\n95.91%\n\n\npt\nPortuguese\n1,608,428\n0.64%\n96.54%\n\n\nit\nItalian\n1,456,350\n0.58%\n97.12%\n\n\nes\nSpanish\n1,284,045\n0.51%\n97.63%\n\n\nnl\nDutch\n934,788\n0.37%\n98.00%\n\n\npl\nPolish\n632,959\n0.25%\n98.25%\n\n\nja\nJapanese\n619,582\n0.25%\n98.50%\n\n\nda\nDanish\n396,477\n0.16%\n98.66%\n\n\nno\n-\n379,239\n0.15%\n98.81%\n\n\nro\nRomanian\n320,256\n0.13%\n98.94%\n\n\nfi\nFinnish\n315,228\n0.13%\n99.06%\n\n\nzh\nChinese\n292,976\n0.12%\n99.18%\n\n\nru\nRussian\n289,121\n0.11%\n99.29%\n\n\ncs\nCzech\n243,802\n0.10%\n99.39%\n\n\nsv\nSwedish\n161,516\n0.06%\n99.45%\n\n\nhu\nHungarian\n149,584\n0.06%\n99.51%\n\n\nzh-Hant\n-\n107,588\n0.04%\n99.55%\n\n\nid\nIndonesian\n104,437\n0.04%\n99.60%\n\n\nhr\nCroatian\n100,384\n0.04%\n99.64%\n\n\ntr\nTurkish\n91,414\n0.04%\n99.67%\n\n\nca\nCatalan\n80,899\n0.03%\n99.70%\n\n\nvi\nVietnamese\n69,147\n0.03%\n99.73%\n\n\nsl\nSlovenian\n66,333\n0.03%\n99.76%\n\n\net\nEstonian\n56,643\n0.02%\n99.78%\n\n\nsk\nSlovak\n52,826\n0.02%\n99.80%\n\n\nko\nKorean\n48,852\n0.02%\n99.82%\n\n\n\n자료출처: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\n    \n\n\n\n코드\n# gpt_gt %>%\n#   gtsave(\"images/gpt_lang.png\")"
  },
  {
    "objectID": "trends.html#인터넷-언어-데이터-fa-solid-globe",
    "href": "trends.html#인터넷-언어-데이터-fa-solid-globe",
    "title": "chatGPT",
    "section": "\n2.2 인터넷 언어 데이터 \n",
    "text": "2.2 인터넷 언어 데이터 \n\nGPT 개발에 자원에 해당되는 언어 데이터셋에 대해 살펴보자. 위키백과 Languages used on the Internet에서 데이터를 확인해보자. 특히, 웹사이트 제작에 사용된 언어를 비중으로 살펴보자.\n\n코드## 언어 콘텐츠\ncontents_raw <- read_html(x = 'https://en.wikipedia.org/wiki/Languages_used_on_the_Internet') %>% \n  html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[1]') %>% \n  html_table() %>% \n  set_names(c(\"순위\", \"언어\", \"비중\"))\n\ncontents_tbl <- contents_raw %>% \n  mutate(비중 = parse_number(비중)) %>% \n  ## 대한민국 이하 기타 ------------\n  mutate(언어 = ifelse(순위 >=17, \"기타\", 언어)) %>% \n  group_by(언어) %>% \n  summarise(비중 = sum(비중)) %>% \n  ungroup() %>% \n  arrange(desc(비중))\n\ncontents_gt <- contents_tbl %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_header(\n      title = md(\"**인터넷 콘텐츠 상위 언어별 통계**\"),\n      subtitle = \"한국어 포함 상위 17개 언어\") %>% \n    tab_source_note(\n      source_note = \"자료출처: https://en.wikipedia.org/wiki/Languages_used_on_the_Internet\") %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어)) %>% \n    fmt_number(\n      columns = c(비중),\n      decimals = 1\n    ) %>% \n    cols_label(\n      비중 = \"비중(%)\"\n    )  %>% \n    tab_footnote(\n      footnote = \"한국어보다 비중이 낮은 인도네이사, 체코, 우크라이나 등\",\n      locations = cells_body(columns = 언어, rows = 2)\n    )  \n\ncontents_gt %>% \n  gtsave(\"images/contents_gt.png\")"
  },
  {
    "objectID": "trends.html#인터넷-데이터-fa-solid-globe",
    "href": "trends.html#인터넷-데이터-fa-solid-globe",
    "title": "chatGPT",
    "section": "\n2.1 인터넷 데이터 \n",
    "text": "2.1 인터넷 데이터 \n\nGPT 개발에 자원에 해당되는 언어 데이터셋에 대해 살펴보자. 위키백과 Languages used on the Internet에서 데이터를 확인해보자. 특히, 웹사이트 제작에 사용된 언어를 비중으로 살펴보자.\n\n코드## 언어 콘텐츠\ncontents_raw <- read_html(x = 'https://en.wikipedia.org/wiki/Languages_used_on_the_Internet') %>% \n  html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[1]') %>% \n  html_table() %>% \n  set_names(c(\"순위\", \"언어\", \"비중\"))\n\ncontents_tbl <- contents_raw %>% \n  mutate(비중 = parse_number(비중)) %>% \n  ## 대한민국 이하 기타 ------------\n  mutate(언어 = ifelse(순위 >=17, \"기타\", 언어)) %>% \n  group_by(언어) %>% \n  summarise(비중 = sum(비중)) %>% \n  ungroup() %>% \n  arrange(desc(비중))\n\ncontents_gt <- contents_tbl %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_options(table.width = pct(75))  %>% \n    tab_header(\n      title = md(\"**인터넷 콘텐츠 상위 언어별 통계**\"),\n      subtitle = \"한국어 포함 상위 17개 언어\") %>% \n    tab_source_note(\n      source_note = \"출처:https://en.wikipedia.org/wiki/Languages_used_on_the_Internet\") %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어, 비중)) %>% \n    fmt_number(\n      columns = c(비중),\n      decimals = 1\n    ) %>% \n    cols_label(\n      비중 = \"비중(%)\"\n    )  %>% \n    tab_footnote(\n      footnote = \"한국어보다 비중이 낮은 인도네이사, 체코, 우크라이나 등\",\n      locations = cells_body(columns = 언어, rows = 2)\n    )  \n\ncontents_gt %>% \n  gtsave(\"images/contents_gt.png\")"
  },
  {
    "objectID": "architecture.html#openai",
    "href": "architecture.html#openai",
    "title": "chatGPT",
    "section": "\n5.1 OpenAI",
    "text": "5.1 OpenAI\n\n\n\n\nCBInsights, “Analyzing OpenAI’s investment strategy: How the ChatGPT maker is building a generative AI ecosystem”"
  },
  {
    "objectID": "architecture.html#글로벌-스타트업",
    "href": "architecture.html#글로벌-스타트업",
    "title": "chatGPT",
    "section": "\n5.2 글로벌 스타트업",
    "text": "5.2 글로벌 스타트업"
  },
  {
    "objectID": "architecture.html#네이버",
    "href": "architecture.html#네이버",
    "title": "chatGPT",
    "section": "\n5.3 네이버",
    "text": "5.3 네이버\n성현희 (2022-11-04), “네이버 AI 사용에 1000개 중소 기업 ‘노크’”, 전자신문\n네이버는 ’클로바 스튜디오’를 다양한 스타트업이 활용하여 서비스를 출시하고 있다.\n\n\n\n\n\ngraph TD\n    A[\"대한민국\"] --> B((\"네이버\"))\n    B ----> E[잡브레인]\n    B ----> H[라이팅젤]\n    B --> C[모카]\n    B --> D[뤼튼] \n    B --> F[킵그로우]\n    style B fill:#FF6655AA\n    style F fill:#88ffFF\n    style I fill:#88ffFF\n\n\n\n\n\n\n\n\n\n임플로이랩스잡 브레인(Job Brain): AI 자소서 생성 기능에 적용, 완성도 높은 자소소\n앱플랫폼 라이팅젤: 대입 취업 자소서 자동왕성 기능에 적용\n아스타 컴퍼니 모카: 상품언어, 광고 헤드라인, 세일즈 카피 생성 기능에 활용\n뤼튼테크놀로지 뤼튼: 광고카피, 제품소개 문구 등 AI 카피라이팅 서비스에 활용\n유니트컴즈 킵그로우: 고객사 인스타그램에 게시물을 주기적으로 포스팅해주는 기능에 적용"
  },
  {
    "objectID": "trends.html#마이크로소프트",
    "href": "trends.html#마이크로소프트",
    "title": "chatGPT",
    "section": "\n7.2 마이크로소프트",
    "text": "7.2 마이크로소프트\n\n\n\n\n\n\n\n\n신규 코드의 40%가 Copilot으로 작성\n\n75%의 개발자가 업무에 더 큰 성취감을 느꼈습니다.\n\n87%의 개발자가 정신적 노력을 절약하는 데 도움이 되었다고 답했습니다."
  },
  {
    "objectID": "trends.html#현대백화점",
    "href": "trends.html#현대백화점",
    "title": "chatGPT",
    "section": "\n7.1 현대백화점",
    "text": "7.1 현대백화점\n현대백화점 관계자는 “이 달 초부터 2주간 시행한 관련 부처 테스트에서 통상 2주가량 소요되던 카피라이팅 업무시간이 루이스 도입 뒤 평균 3~4시간으로 줄었다”\n유선희 (2023-02-26), 광고 카피도 AI가 쓴다…현대백화점 ‘루이스’ 시스템 도입, 한겨레신문\n현대백화점이 광고 카피와 판촉행사 소개문 등 마케팅 문구 제작을 위해 특별히 ’고용’한 인공지능(AI) 카피라이팅 시스템은 네이버 ’하이버클로바’를 기본 엔진으로 추가학습(최근 3년 동안 사용한 광고 카피, 판촉행사에서 쓴 문구 중 소비자 호응이 컸던 데이터 1만여건을 집중적으로 학습)하여 개발\n\n\nAI 직원\n활용화면\n루이스"
  },
  {
    "objectID": "trends.html#이미지",
    "href": "trends.html#이미지",
    "title": "chatGPT",
    "section": "\n7.3 이미지",
    "text": "7.3 이미지\n\n\n\n\n웹툰을 제작하는 스튜디오에서는 웹툰 작가들과 어시스트들이 매우 노동집약적인 작업으로 창작활동을 하고 있다. 현재 웹툰 제작 공정은 콘티, 스케치, 라인(펜선), 채색, 배경, 출판 작업의 순서로 이뤄진다. 한국만화영상진흥원과 협력하는 실제 웹툰 작가들은 특정작업이 아닌 모든 공정에서 제작 생산성 향상을 위한 자동화 기술이 필요하다는 결론에 도달함. (김현진, 2021)"
  },
  {
    "objectID": "trends.html#공상과학소설",
    "href": "trends.html#공상과학소설",
    "title": "chatGPT",
    "section": "\n8.1 공상과학소설",
    "text": "8.1 공상과학소설\n공상과학 및 판타지 잡지 클라크스월드(Clarkesworld)는 AI가 생성한 소설라는 비난을 받은 후 신규 공상과학소설이 급증한 것이 AI 기계로 작성된 원인을 큰 것으로 파악하고 2월 20일부터 공식적으로 투고를 중단했다.\nNeil Clark (2023-02-15), “A Concerning Trend”, CLARKESWORLD MAGAZINE\n\n\n\n\n2023-02-15 기준\n\n\n\n\n2023-02-20 기준"
  },
  {
    "objectID": "image2image.html#chatgpt-프롬프트",
    "href": "image2image.html#chatgpt-프롬프트",
    "title": "chatGPT",
    "section": "\n2.1 chatGPT 프롬프트",
    "text": "2.1 chatGPT 프롬프트\nrecommend the most famous painting style in history\n\n\n\n\n\n\ncompletion\n\n\n\n\n\nHere are some of the most famous painting styles in history:\n\nRenaissance: The Renaissance was a cultural movement in Italy from the 14th to the 17th century, characterized by a renewed interest in classical art, philosophy, and science. Renaissance paintings are known for their realism, balance, and harmony.\nBaroque: The Baroque style was popular in Europe from the late 16th to the early 18th century. Baroque paintings are known for their dramatic lighting, intense emotions, and dynamic compositions.\nImpressionism: Impressionism was a modernist movement in French painting in the late 19th century. Impressionist paintings are known for their loose brushstrokes, light-filled compositions, and focus on capturing fleeting moments.\nSurrealism: Surrealism was a cultural movement in the 20th century that aimed to liberate the imagination and explore the subconscious. Surrealist paintings are known for their dreamlike and fantastical imagery.\nAbstract Expressionism: Abstract Expressionism was a modernist movement in American painting in the mid-20th century. Abstract Expressionist paintings are known for their large canvases, gestural brushstrokes, and emphasis on the process of creation.\n\nThese are just a few examples of famous painting styles in history. There are many other styles that have influenced and shaped the course of art history.\n\n\n\nOpen AI - Create image API"
  },
  {
    "objectID": "image2image.html#화풍을-달리한-그림",
    "href": "image2image.html#화풍을-달리한-그림",
    "title": "chatGPT",
    "section": "\n2.2 화풍을 달리한 그림",
    "text": "2.2 화풍을 달리한 그림\n\n\n르네상스(Renaissance)\n바로크(Baroque)\n인상주의(Impressionism)\n초현실주의(Surrealism)\n추상표현주의(Abstract Expressionism)\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance <- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\n르네상스(Renaissance)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque <- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\n바로크(Baroque)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism <- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\n인상주의(Impressionism)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism <- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\n초현실주의(Surrealism)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism <- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")\n\n\n\n\n추상표현주의(Abstract Expressionism)"
  },
  {
    "objectID": "rcoding.html#설치",
    "href": "rcoding.html#설치",
    "title": "chatGPT",
    "section": "\n2.1 설치",
    "text": "2.1 설치\ngpttools GitHub 저장소에서 바로 설치한다.\nrequire(remotes)\nremotes::install_github(\"JamesHWade/gpttools\")"
  },
  {
    "objectID": "rcoding-copilot.html",
    "href": "rcoding-copilot.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 GitHub Copilot\nGitHub Copilot은 Visual Studio Code를 비롯한 다양한 코드 편집기와 통합할 수 있는 AI 기반 코딩 도우미(Assistant)입니다. Copilot은 개발자가 보다 효율적이고 정확하게 코드를 작성할 수 있도록 도와주는 지능형 도우미 기능 제공하기 위해 GitHub와 OpenAI가 공동으로 개발했습니다.\nCopilot은 머신 러닝 알고리즘을 사용하여 다른 개발자가 작성한 코드를 분석하고 학습한 다음 현재 코드베이스에 삽입할 수 있는 제안 및 코드 조각을 생성합니다. 이 기능은 방대한 코드 코퍼스를 학습한 신경망을 사용하여 개발자가 작성할 가능성이 있는 다음 코드 줄을 예측하는 방식으로 작동합니다.\n이 기술을 통해 Copilot은 현재 코드의 컨텍스트를 기반으로 전체 함수 또는 클래스를 제안하고 구문적으로 정확하고 모범 사례를 준수하는 코드를 생성할 수도 있습니다. 또한 Copilot은 생성하는 코드의 의미와 목적을 이해할 수 있으므로 새로운 아이디어를 빠르게 프로토타입으로 만들거나 문제에 대한 다양한 해결책을 모색해야 하는 개발자에게 유용한 도구입니다.\nGitHub Copilot은 Python, JavaScript, TypeScript, Ruby, Go, R 등 다양한 프로그래밍 언어와 원활하게 작동하도록 설계되었습니다. 또한 사용자 지정이 가능하므로 개발자가 특정 코드베이스에 대해 학습시켜 제안을 개선하고 더욱 정확하게 만들 수 있습니다.\nCopilot을 사용하면 얻을 수 있는 잠재적 이점은 상당합니다. 코드 작성에 필요한 시간과 노력을 줄임으로써 개발자는 새로운 기능을 설계하거나 기존 기능을 개선하는 등 더 복잡한 작업에 집중할 수 있습니다. 또한 Copilot은 모범 사례를 따르고 구조적으로 건전하고 읽기 쉬운 코드를 생성하도록 프로그래밍되어 있으므로 오류와 버그를 줄이는 데 도움이 될 수 있습니다.\n전반적으로 GitHub Copilot은 AI 지원 코딩 분야에서 중요한 진전을 이루었으며, 개발자의 코드 작업 및 협업 방식을 바꿀 수 있는 잠재력을 가지고 있습니다.\n\n2 RStudio\nR 사용자는 RStudio를 많이 사용했으나 최근 chatGPT, Github Copilot의 부상으로 개발방식에 변화가 생겨나고 있다. 하지만, RStudio가 곧 Copilot 지원하지는 않을 예정이다. RStudio는 무료 오픈 소스인 반면 Copilot은 Microsoft의 독점 기술이며, Microsoft는 공식 비공개 소스 소프트웨어 및 플러그인에서만 사용할 수 있도록 라이선스를 부여하고 있다. 시중에 존재하는 몇몇 타사 플러그인은 공식 플러그인에서 바이너리를 추출하여 작동하지만, RStudio에는 이런 우회 편법적인 방법을 취하고 있지는 않고 있다.\nGithub Copilot integration with RStudio #10148\nMicrosoft와 Posit이 RStudio 내에서 Copilot을 허용하는 방법과 RStudio가 공개 데이터 및 기술을 사용하여 Copilot과 유사한 AI 프로그래밍 도우미를 구현하는 방법도 있지만 이 중 어느 것도 향후 6개월 이내에(특히 향후 6~8주 이내에) 출시될 가능성은 전무하다. 따라서, Copilot을 사용하고자 하는 경우 VS Code를 사용하는 것이 유일한 방법이다.\n\n\n\n\n\n3 VS 코드\nGitHub, Copilot for R\nVisual Studio Code에서 R 코드 작성 프로세스의 속도를 높일 수 있다. Copilot은 기존 프로젝트의 컨텍스트를 기반으로 R 스크립트 혹은 함수전체를 동적으로 실행한다. 예를 들어, R을 새로운 Azure OpenAI 서비스와 인터페이스하는 함수를 작성하고 Copilot이 필요한 코드를 생성하여 개발 속도를 높일 수 있다.\n\n\n\n\n\n\nCopilot\nchatGPT"
  },
  {
    "objectID": "why_llm.html",
    "href": "why_llm.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 들어가며\nGPT-3(Generative Pre-trained Transformer 3)와 같은 거대 언어 모델은 인간과 유사한 언어를 처리하고 생성할 수 있기 때문에 이 시대에 중요한 역할을 한다. 이를 통해 자연어 처리, 챗봇, 언어 번역, 콘텐츠 제작, 코딩 등 다양한 애플리케이션에 수많은 가능성을 열었다는 평가를 받고 있다.\n거대 언어 모델이 중요한 몇 가지 이유를 꼽으면 다음과 같다.\n\n자연어 처리(Natural language processing): GPT-3와 같은 거대 언어 모델은 대량의 텍스트 데이터를 처리할 수 있고 언어의 문맥과 의미를 이해할 수 있어 감정 분석, 언어 번역, 텍스트 분류와 같은 자연어 처리 작업을 수행할 수 있다.\n챗봇(Chatbot): 거대 언어 모델을 사용하여 자연어 쿼리를 이해하고 응답할 수 있는 대화형 대리인(챗봇)를 만들 수 있다. 이러한 챗봇은 고객 지원, 가상 비서 및 기타 다양한 애플리케이션에서 사용할 수 있다.\n언어 번역(Language translation): 거대 언어 모델은 여러 언어에 대해 학습할 수 있으며 고품질 언어 번역을 수행한다. 이는 관광, 전자상거래, 국제 무역 등 다양한 산업에서 유용하게 사용될 수 있다.\n콘텐츠 생성(Content creation): 거대 언어 모델은 기사, 요약, 시 등 사람과 유사한 텍스트 콘텐츠를 생성할 수 있다. 이는 저널리즘, 콘텐츠 제작, 광고 등 다양한 산업에서 활용할 수 있다.\n코딩(Coding): GPT-3는 소프트웨어 개발 및 자동화에 광범위한 영향을 미칠 수 있는 컴퓨터 코드를 생성할 수 있는 능력을 입증했다.\n\n요약하면, 거대 언어 모델은 우리가 기계와 상호작용하고 작업을 수행하는 방식을 혁신할 수 있는 잠재력을 가지고 있어 우리 시대에 중요한 기술이 될 것임은 자명하다.\n\n\n2019년\n2021년\n2022년\n\n\n\n\n\n(Sanh et al., 2019)\n\n\n\n\n\n\nEfficient Natural Language Processing\n\n\n\n\n![langcon 2023 by 신정규(images/LLM_langcon2023.png)\n\n\n\n\n2 모형크기\nquestion-answering tasks (open-domain closed-book variant), cloze and sentence-completion tasks, Winograd-style tasks, in-context reading comprehension tasks, common-sense reasoning tasks, SuperGLUE tasks, and natural language inference tasks가 포함된 총 29개 작업 중 28개 영역에서 PaLM 540B가 이전 거대 언어모형 GLaM, GPT-3, Megatron-Turing NLG, Gopher, Chinchilla, LaMDA 을 가볍게 능가했다.\nSharan Narang and Aakanksha Chowdhery (APRIL 04, 2022), “Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance”, Software Engineers, Google Research\n\n\nLLM 진화\n80억 패러미터\n400억\n640억\n5,400억\n성능\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 거대언어모형 성능\n자연어 처리(NLP) 및 머신 러닝 분야의 여러 발전으로 인해 GPT-3와 같은 대규모 언어 모델의 성능이 이전 모델보다 향상되었다. 주요 원인으로 다음을 꼽을 수 있다.\n\n규모(Scale): 대규모 언어 모델은 방대한 양의 텍스트 데이터로 학습되어 언어의 더 많은 뉘앙스를 포착하고 문맥을 더 잘 이해할 수 있다. GPT-3는 45테라바이트가 넘는 텍스트 데이터셋으로 학습되었다고 알려져 지금까지 사전 학습된 언어 모델 중 가장 큰 규모를 갖고 있다.\n아키텍처(Architecture): GPT-3는 병렬 처리가 가능한 트랜스포머(Transformer) 기반 아키텍처를 사용하여 학습 시간을 단축하고 성능을 향상시켰다.\n사전 학습(Pre-training): 대규모 언어 모델은 방대한 양의 텍스트 데이터로 사전 학습되어 다양한 작업에 적용할 수 있는 일반적인 언어 패턴과 관계를 학습할 수 있다. GPT-3는 비지도 학습을 사용하여 사전 학습되므로 특정 작업을 염두에 두지 않고 원시 텍스트 데이터에서 학습했다.\n미세 조정(Fine-tuning): 언어 번역이나 텍스트 분류와 같은 특정 작업을 위해 대규모 언어 모델을 미세 조정(Fine-tuning) 작업을 수행한다. 이 과정에는 해당 작업에 특화된 소규모 데이터셋로 모델을 추가 학습시켜 성능을 더욱 향상시킨다.\n전이 학습(Transfer learning): 대규모 언어 모델은 한 작업에서 학습한 지식을 다른 작업으로 전이시킬 수 있다. 즉, 언어 번역과 같은 한 작업에서 학습된 모델을 더 작은 데이터셋을 사용하여 감정 분석과 같은 다른 작업에 맞게 추가 학습작업(Fine-tuning)을 시킬 수 있다.\n\n요약하면, 대규모 언어 모델의 성능은 규모, 아키텍처, 사전 학습, 미세 조정 및 전이 학습의 발전으로 인해 이전 모델보다 더 우수하다. 이러한 발전 덕분에 대규모 언어 모델은 다양한 언어 작업에서 최첨단 성능을 달성할 수 있게 되어 자연어 처리 및 머신 러닝 분야에서 강력한 도구가 된 것이다.\n\n\n(Wei et al., 2022)\n\n\n\n4 수학\nLewkowycz et al. (2022)\n\n\n미네르바 LM\n손으로 풀기\n시각화\nSympy 해법\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\ngiven_line <- function(x)  10 + 4 * x\nsolve_line <- function(x) -10 + 4 *x\n\nggplot() +\n  geom_point(aes(x = 5, y = 10), size = 3) +\n  geom_function(fun = given_line, color = \"blue\", size = 1.5) +\n  geom_function(fun = solve_line, color = \"red\", size = 1.5, alpha = 0.5) +\n  theme_classic() +\n  scale_x_continuous(limits = c(-7, 7), breaks = seq(-7, 7, 1)) +\n  scale_y_continuous(limits = c(-20, 20), breaks = seq(-20, 20, 1)) +\n  geom_vline(xintercept = 0) +\n  geom_hline(yintercept = 0) \n\n\n\n\n\n\n\n\n\n\nfrom sympy import *\n\nx, y, b = symbols('x y b')\n\ngiven_eq = y - (4*x + 10)\n\nparallel_eq = y - (4*x + b)\n\nintercept_eq = parallel_eq.subs([(x, 5), (y, 10)])\n\nsolveset(Eq(intercept_eq, 0), b)\n#> {-10}\n\n\n\n\n\n5 다양한 사례 (PaLM)\n5,400 억 패러미터를 장착한 Pathways Language Model (PaLM)의 성능을 실감해보자.\n\n\n다양한 기능\n추론\n코딩\n\n\n\n\n\n\n\n\n\n추론(Reasoning)\n\n\n\n\n\n\n코딩(Code Generation)\n\n\n\n\n\n\n\n\n6 개발비\nEstimating 🌴PaLM’s training cost\n언어 모형 개발은 2010년 이후 개발비용이 급격히 증가하고 있으며 그 추세는 상상을 초월한다.\n\n\nOur World in Data\nLennart Heim\n\n\n\n\n\n\n\n\n\n\n\n\n\n7 생성모형의 부작용\n생성 AI를 통해 인간이 생성한 데이터와 기계가 생성한 데이터가 무작위로 섞인 지금까지 경험하지 못한 세상이 출현하고 있다. 즉, 생성 AI 모형에서 이미지, 텍스트, 동영상 등 무수히 많은 데이터가 인터넷에 공개 및 공유될 것이며 기계학습 및 딥러닝 생성모형는 결국 실제 데이터와 기계가 생성한 데이터를 입력값으로 인공지능 모형을 생성하게 된다. 하지만 이런 경우 과연 AI 모형은 어떤 특성을 갖게 될 것인가? 데이터 증강(Data Augmentation)처럼 더 좋은 성능을 갖는 AI 모형이 될 것이가 아니면 그 반대의 모습을 가지게 될 것인가? 논문(Hataya et al., 2022)에서는 부정적인 효과도 있다고 주장하고 있다.\n\n\n현재 상황\n기계오염된 데이터\n\n\n\n\n\n\n\n\n\n\n\n기계생성 데이터 사용하여 나온 결과물\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\nHataya, R., Bao, H., & Arai, H. (2022). Will large-scale generative models corrupt future datasets? arXiv Preprint arXiv:2211.08095.\n\n\nLewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramasesh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., et al. (2022). Solving quantitative reasoning problems with language models. arXiv Preprint arXiv:2206.14858.\n\n\nSanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. arXiv Preprint arXiv:1910.01108.\n\n\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. (2022). Emergent abilities of large language models. arXiv Preprint arXiv:2206.07682."
  },
  {
    "objectID": "ide.html",
    "href": "ide.html",
    "title": "chatGPT",
    "section": "",
    "text": "chatGPT 는 데이터 과학자 개발생산성을 비약적으로 증진시키는 것으로 알려져있다. 특히 데이터 과학에서 개발생산성 관련 큰 역할을 수행하는 것이 통합개발환경(IDE)이다. Posit에서 개발한 RStudio가 출현하면서 기존 R언어를 다양한 편집기(VIM,Emacs 등)로 주로 개발하던 문화를 획기적으로 바뀌었다면 이제는 GitHub Copilot을 어떤 형태로든 붙여서 사용하면 더욱 생산성을 높일 수 있다.\n기존 RStudio에서 데이터 과학 개발부터 제품/서비스 제작까지 모두 진행했다면, 이제 마이크로소프트가 Posit RStudio 무료 IDE에 GitHub Copilot 상용 소프트웨어를 제공하지 않고 GitHub Copilot에 대응하는 오픈소스 소프트웨어가 현재시점 기준 존재하지 않기 때문에 부득이 이 둘을 나눠 개발을 진행해야 데이터 과학자로서 생산성을 높일 수 있다."
  },
  {
    "objectID": "ide.html#keybindings.json",
    "href": "ide.html#keybindings.json",
    "title": "chatGPT",
    "section": "\n4.1 keybindings.json\n",
    "text": "4.1 keybindings.json\n\nkeybindings.json 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 등록시킨다. 자료출처: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n\n\n\n\n\n\nkeybindings.json 설정파일 예시\n\n\n\n\n\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: '이광춘'\\ndate: '2023-03-07'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "ide.html#html-미리보기",
    "href": "ide.html#html-미리보기",
    "title": "chatGPT",
    "section": "\n4.2 HTML 미리보기",
    "text": "4.2 HTML 미리보기\n.Rmd 파일을  CTRL  +  Shift  +  k  단축키로 컴파일시키면 .html 파일이 생성된다. .html 파일 결과를 직접 실시간으로 확인하고자 한다면, 마이크로소프트가 개발한 Live Preview - VS Code Extension 플러그인을 설치한다."
  },
  {
    "objectID": "ide.html#r-extension-설치",
    "href": "ide.html#r-extension-설치",
    "title": "chatGPT",
    "section": "\n1.1 R extension 설치",
    "text": "1.1 R extension 설치\nR extension을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. VS Code 에 필수적인 R extension은 다음을 꼽을 수 있다. R extension을 설치하면 RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 편리하다.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Code를 실행하고 R Extension 설치"
  },
  {
    "objectID": "ide.html#헬로우-월드",
    "href": "ide.html#헬로우-월드",
    "title": "chatGPT",
    "section": "\n1.2 헬로우 월드",
    "text": "1.2 헬로우 월드\nR Extension 설치되면 코드 창 상단에 실행버튼이 활성화되고 Ctrl + Enter 혹은 Ctrl + Shift + Enter\n\n\nR 코드 실행화면"
  },
  {
    "objectID": "ide.html#유튜브-동영상",
    "href": "ide.html#유튜브-동영상",
    "title": "chatGPT",
    "section": "\n1.3 유튜브 동영상",
    "text": "1.3 유튜브 동영상"
  },
  {
    "objectID": "ide.html#코딩-글꼴",
    "href": "ide.html#코딩-글꼴",
    "title": "chatGPT",
    "section": "\n2.1 코딩 글꼴",
    "text": "2.1 코딩 글꼴\n다른 언어와 마찬가지로 R 코드로 데이터 과학 제품을 개발할 경우 글꼴도 코딩에 적합한 한글 글꼴을 설정한다.\n먼저 D2 Coding 글꼴을 다운로드 받아 운영체제에 설치한다.\nVS Code 좌측 하단 톱니바퀴  Settings  설정을 클릭 혹은 메뉴에서 “File” → “Preferences” → “Settings”를 통해 편집기 (Text Editor)로 들어가 운영체제에 설치한 코딩 폰트를 지정한다. Font Ligatures 도 true로 설정한다. 이를 통해 < - 표시가 ← 로 화면에 표현된다.\n\n\nD2코딩 글꼴 장착"
  },
  {
    "objectID": "ide.html#단축키",
    "href": "ide.html#단축키",
    "title": "chatGPT",
    "section": "\n2.2 단축키",
    "text": "2.2 단축키\nR 코드 개발을 진행할 때  %>% ,  ←  두가지 기능이 가장 많이 사용되는 단축키로 RStudio에서는 기본으로 지원되고 있다. VS Code에서 자주 사용되는 단축키를  CTRL  +  Shift  +  m ,  Alt  +  -  를 적용시키는 방법을 살펴보자.\n만약 VS Code에서 단축키 설정 기능을 활용한다. How to add R {magrittr}’s %>% Pipe Operator in VSCode as Keyboard Shortcut\n\n윈도우즈: File > Preferences > Keyboard Shortcuts.\n맥: Code > Preferences > Keyboard Shortcuts\n\nkeybindings.json 파일에  %>% ,  ←  단축키 기능을 추가한다.\n\n\n자주 사용되는 R 단축키 설정"
  },
  {
    "objectID": "ide.html#패널",
    "href": "ide.html#패널",
    "title": "chatGPT",
    "section": "\n2.3 패널",
    "text": "2.3 패널\nRStudio는 코딩기반 데이터 분석과 통계에 최적화된 개발환경이다. 즉, 편집기 패널, 콘솔/터미널 패널, 그래프 패널, 도움말/개발 패널로 구성된 꼭 필요한 패널만 구성되어 있다.\n\n\n패널 설정\n설정 후\n\n\n\n\n\nVS Code: View → Editor Layout → Grid (2x2)\n\n\n\n\n\n\n도움말과 그래프"
  },
  {
    "objectID": "ide.html#설치",
    "href": "ide.html#설치",
    "title": "chatGPT",
    "section": "설치",
    "text": "설치\n# 출시버전 설치\npip3 install -U radian\n# 실행\nradian"
  },
  {
    "objectID": "ide.html#실행화면",
    "href": "ide.html#실행화면",
    "title": "chatGPT",
    "section": "실행화면",
    "text": "실행화면"
  },
  {
    "objectID": "ide.html#vs-코드-콘솔",
    "href": "ide.html#vs-코드-콘솔",
    "title": "chatGPT",
    "section": "\n3.2 VS 코드 콘솔",
    "text": "3.2 VS 코드 콘솔\nradiant를 설치한 후에 Rpath 가 아니라 Rterm에서 설정해줘야 한다.\n\n\n\n맥\n\n\n\n\n윈도우즈\n\n\n\n\n적용결과"
  },
  {
    "objectID": "ide.html#독립-사용사례",
    "href": "ide.html#독립-사용사례",
    "title": "chatGPT",
    "section": "\n3.1 독립 사용사례",
    "text": "3.1 독립 사용사례"
  },
  {
    "objectID": "ide.html#펭귄-데이터셋",
    "href": "ide.html#펭귄-데이터셋",
    "title": "chatGPT",
    "section": "\n5.1 펭귄 데이터셋",
    "text": "5.1 펭귄 데이터셋"
  },
  {
    "objectID": "ide.html#호박-데이터셋",
    "href": "ide.html#호박-데이터셋",
    "title": "chatGPT",
    "section": "\n5.2 호박 데이터셋",
    "text": "5.2 호박 데이터셋\n\n<p>:::</p>"
  },
  {
    "objectID": "ide.html#중요-추가설정",
    "href": "ide.html#중요-추가설정",
    "title": "chatGPT",
    "section": "\n5.1 중요 추가설정",
    "text": "5.1 중요 추가설정\nPrincipal Cloud Advocate at Microsoft David Smith가 “New York Open Statistical Programming Meetup, 28 February 2023”에서 발표한 Copilot for R 내용 중 VS 코드 환경설정부분이다.\nCopilot for R\n\nVS 코드\n\nCopilot extension\nR Extension for Visual Studio Code\ncopilot 추천에 집중하기 위해서 다음 사항도 설정에 반영한다.\n\nEditor > Hover (disabled)\nEditor > Quick Suggestions (off)\nEditor > Parameter Hints (disabled)\n\n\n\n\nR 패키지 설치 및 opitions()\n\nhttr, jsonlite, tidyverse, tidymodels, docopt, httpuv\n가독성 높은 그래프 출력: options(vsc.dev.args = list(width = 800, height = 600))"
  },
  {
    "objectID": "ide.html#실제-적용-사례",
    "href": "ide.html#실제-적용-사례",
    "title": "chatGPT",
    "section": "\n5.2 실제 적용 사례",
    "text": "5.2 실제 적용 사례\n펭귄과 호박 데이터를 적용한 사례 시연을 살펴보자.\n펭귄 데이터셋\n\n\n\n\n호박 데이터셋\n\n<div id=\"quarto-navigation-envelope\" class=\"hidden\">\n<p><span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\">Home</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:생성 AI\">생성 AI</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:chatGPT 이해\">chatGPT 이해</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:추세 트렌드\">추세 트렌드</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:왜 거대언어모형인가?\">왜 거대언어모형인가?</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:------------------\">——————</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:이미지 생성\">이미지 생성</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:GPT R 코딩개발\">GPT R 코딩개발</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:부조종사 R 코딩개발\">부조종사 R 코딩개발</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:수학문제\">수학문제</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:데이터 과학문제\">데이터 과학문제</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:DeepL 번역 API\">DeepL 번역 API</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:chatGPT 응용사례\">chatGPT 응용사례</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:활용사례\">활용사례</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:보도자료 작성\">보도자료 작성</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:R 소개영상\">R 소개영상</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:데이터 과학 책\">데이터 과학 책</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:논문 초록\">논문 초록</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:학술연구(R&amp;D)\">학술연구(R&amp;D)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:데이터 문해력\">데이터 문해력</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:인터페이스\">인터페이스</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:BERT\">BERT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:통합개발환경(IDE)\">통합개발환경(IDE)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:파이썬 환경구축\">파이썬 환경구축</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:HuggingfaceR - 모형통계\">HuggingfaceR - 모형통계</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Hugging Face\">Hugging Face</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Hugging Face(윈도우)\">Hugging Face(윈도우)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:HF 파이프라인\">HF 파이프라인</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:게시글\">게시글</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:R사용자회\">R사용자회</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Open Assistant\">Open Assistant</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:RTutor\">RTutor</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:About\">About</span> <span class=\"hidden\" data-render-id=\"footer-left\"><a href=\"https://quarto.org/\">Quarto</a> 개발</span> <span class=\"hidden\" data-render-id=\"footer-center\"><a href=\"mailto:admin@r2bit.com\">한국 R 사용자회</a></span> <span class=\"hidden\" data-render-id=\"footer-right\"><a href=\"https://github.com/bit2r/chatGPT\">Github 코드 저장소</a></span></p>\n</div>\n<div id=\"quarto-meta-markdown\" class=\"hidden\">\n<p><span class=\"hidden\" data-render-id=\"quarto-metatitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-metasitename\">chatGPT</span></p>\n</div>\n<!-- -->\n<div class=\"quarto-embedded-source-code\">\n<div class=\"sourceCode\" id=\"cb5\" data-shortcodes=\"false\"><pre class=\"sourceCode markdown\"><code class=\"sourceCode markdown\"><span id=\"cb5-1\"><a href=\"#cb5-1\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">---</span></span>\n<span id=\"cb5-2\"><a href=\"#cb5-2\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">title:</span><span class=\"co\"> \"chatGPT\"</span></span>\n<span id=\"cb5-3\"><a href=\"#cb5-3\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">subtitle:</span><span class=\"co\"> \"통합개발환경(IDE)\"</span></span>\n<span id=\"cb5-4\"><a href=\"#cb5-4\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">description:</span><span class=\"co\"> \"비쥬얼 스튜디오 코드 IDE를 사용하여 개발 생산성을 높인다.\"</span></span>\n<span id=\"cb5-5\"><a href=\"#cb5-5\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">author:</span></span>\n<span id=\"cb5-6\"><a href=\"#cb5-6\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  - name: 이광춘</span></span>\n<span id=\"cb5-7\"><a href=\"#cb5-7\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    url: https://www.linkedin.com/in/kwangchunlee/</span></span>\n<span id=\"cb5-8\"><a href=\"#cb5-8\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    affiliation: 한국 R 사용자회</span></span>\n<span id=\"cb5-9\"><a href=\"#cb5-9\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    affiliation-url: https://github.com/bit2r</span></span>\n<span id=\"cb5-10\"><a href=\"#cb5-10\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">title-block-banner:</span><span class=\"co\"> true</span></span>\n<span id=\"cb5-11\"><a href=\"#cb5-11\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">#title-block-banner: \"#562457\"</span></span>\n<span id=\"cb5-12\"><a href=\"#cb5-12\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">format:</span></span>\n<span id=\"cb5-13\"><a href=\"#cb5-13\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  html:</span></span>\n<span id=\"cb5-14\"><a href=\"#cb5-14\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    css: css/quarto.css</span></span>\n<span id=\"cb5-15\"><a href=\"#cb5-15\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    theme: flatly</span></span>\n<span id=\"cb5-16\"><a href=\"#cb5-16\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    code-fold: true</span></span>\n<span id=\"cb5-17\"><a href=\"#cb5-17\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    code-overflow: wrap</span></span>\n<span id=\"cb5-18\"><a href=\"#cb5-18\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc: true</span></span>\n<span id=\"cb5-19\"><a href=\"#cb5-19\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc-depth: 3</span></span>\n<span id=\"cb5-20\"><a href=\"#cb5-20\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc-title: 목차</span></span>\n<span id=\"cb5-21\"><a href=\"#cb5-21\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    number-sections: true</span></span>\n<span id=\"cb5-22\"><a href=\"#cb5-22\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    highlight-style: github    </span></span>\n<span id=\"cb5-23\"><a href=\"#cb5-23\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    self-contained: false</span></span>\n<span id=\"cb5-24\"><a href=\"#cb5-24\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">filters:</span></span>\n<span id=\"cb5-25\"><a href=\"#cb5-25\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">   - lightbox</span></span>\n<span id=\"cb5-26\"><a href=\"#cb5-26\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">   - custom-callout.lua   </span></span>\n<span id=\"cb5-27\"><a href=\"#cb5-27\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">lightbox:</span><span class=\"co\"> auto</span></span>\n<span id=\"cb5-28\"><a href=\"#cb5-28\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">link-citations:</span><span class=\"co\"> yes</span></span>\n<span id=\"cb5-29\"><a href=\"#cb5-29\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">knitr:</span></span>\n<span id=\"cb5-30\"><a href=\"#cb5-30\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  opts_chunk: </span></span>\n<span id=\"cb5-31\"><a href=\"#cb5-31\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    message: false</span></span>\n<span id=\"cb5-32\"><a href=\"#cb5-32\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    warning: false</span></span>\n<span id=\"cb5-33\"><a href=\"#cb5-33\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    collapse: true</span></span>\n<span id=\"cb5-34\"><a href=\"#cb5-34\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    comment: \"#&gt;\" </span></span>\n<span id=\"cb5-35\"><a href=\"#cb5-35\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    R.options:</span></span>\n<span id=\"cb5-36\"><a href=\"#cb5-36\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">      knitr.graphics.auto_pdf: true</span></span>\n<span id=\"cb5-37\"><a href=\"#cb5-37\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">editor_options:</span><span class=\"co\"> </span></span>\n<span id=\"cb5-38\"><a href=\"#cb5-38\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  chunk_output_type: console</span></span>\n<span id=\"cb5-39\"><a href=\"#cb5-39\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">---</span></span>\n<span id=\"cb5-40\"><a href=\"#cb5-40\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-41\"><a href=\"#cb5-41\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`chatGPT`</span> 는 데이터 과학자 개발생산성을 비약적으로 증진시키는 것으로 알려져있다.</span>\n<span id=\"cb5-42\"><a href=\"#cb5-42\" aria-hidden=\"true\" tabindex=\"-1\"></a>특히 데이터 과학에서 개발생산성 관련 큰 역할을 수행하는 것이 통합개발환경(IDE)이다.</span>\n<span id=\"cb5-43\"><a href=\"#cb5-43\" aria-hidden=\"true\" tabindex=\"-1\"></a>Posit에서 개발한 RStudio가 출현하면서 기존 R언어를 다양한 편집기(VIM,Emacs 등)로 </span>\n<span id=\"cb5-44\"><a href=\"#cb5-44\" aria-hidden=\"true\" tabindex=\"-1\"></a>주로 개발하던 문화를 획기적으로 바뀌었다면 이제는 GitHub Copilot을 어떤 형태로든</span>\n<span id=\"cb5-45\"><a href=\"#cb5-45\" aria-hidden=\"true\" tabindex=\"-1\"></a>붙여서 사용하면 더욱 생산성을 높일 수 있다.</span>\n<span id=\"cb5-46\"><a href=\"#cb5-46\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-47\"><a href=\"#cb5-47\" aria-hidden=\"true\" tabindex=\"-1\"></a>기존 RStudio에서 데이터 과학 개발부터 제품/서비스 제작까지 모두 진행했다면,</span>\n<span id=\"cb5-48\"><a href=\"#cb5-48\" aria-hidden=\"true\" tabindex=\"-1\"></a>이제 마이크로소프트가 Posit RStudio 무료 IDE에 GitHub Copilot 상용 소프트웨어를 </span>\n<span id=\"cb5-49\"><a href=\"#cb5-49\" aria-hidden=\"true\" tabindex=\"-1\"></a>제공하지 않고 GitHub Copilot에 대응하는 오픈소스 소프트웨어가 현재시점 기준 존재하지 않기 때문에</span>\n<span id=\"cb5-50\"><a href=\"#cb5-50\" aria-hidden=\"true\" tabindex=\"-1\"></a>부득이 이 둘을 나눠 개발을 진행해야 데이터 과학자로서 생산성을 높일 수 있다.</span>\n<span id=\"cb5-51\"><a href=\"#cb5-51\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-52\"><a href=\"#cb5-52\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/ide-copilot.png)</span></span>\n<span id=\"cb5-53\"><a href=\"#cb5-53\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-54\"><a href=\"#cb5-54\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># VS 코드 설치</span></span>\n<span id=\"cb5-55\"><a href=\"#cb5-55\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-56\"><a href=\"#cb5-56\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS 코드를 통해 데이터 과학 제품개발을 할 경우 다음 사항에 맞춰 개발을 시작한다.</span>\n<span id=\"cb5-57\"><a href=\"#cb5-57\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-58\"><a href=\"#cb5-58\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">1. </span>R을 설치한다.</span>\n<span id=\"cb5-59\"><a href=\"#cb5-59\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">2. </span><span class=\"in\">`languageserver`</span> 패키지를 설치한다.</span>\n<span id=\"cb5-60\"><a href=\"#cb5-60\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span><span class=\"in\">`install.packages(\"languageserver\")`</span></span>\n<span id=\"cb5-61\"><a href=\"#cb5-61\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">3. </span>Visual Studio Code 에서 <span class=\"in\">`R extension`</span>을 설치한다.</span>\n<span id=\"cb5-62\"><a href=\"#cb5-62\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">4. </span><span class=\"in\">`.R`</span> 파일에 개발을 시작한다.</span>\n<span id=\"cb5-63\"><a href=\"#cb5-63\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-64\"><a href=\"#cb5-64\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-65\"><a href=\"#cb5-65\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## `R extension` 설치</span></span>\n<span id=\"cb5-66\"><a href=\"#cb5-66\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-67\"><a href=\"#cb5-67\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`R extension`</span>을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. </span>\n<span id=\"cb5-68\"><a href=\"#cb5-68\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS Code 에 필수적인 <span class=\"in\">`R extension`</span>은 다음을 꼽을 수 있다. <span class=\"in\">`R extension`</span>을 설치하면</span>\n<span id=\"cb5-69\"><a href=\"#cb5-69\" aria-hidden=\"true\" tabindex=\"-1\"></a>RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 </span>\n<span id=\"cb5-70\"><a href=\"#cb5-70\" aria-hidden=\"true\" tabindex=\"-1\"></a>편리하다.</span>\n<span id=\"cb5-71\"><a href=\"#cb5-71\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-72\"><a href=\"#cb5-72\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R - REditorSupport</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r)</span></span>\n<span id=\"cb5-73\"><a href=\"#cb5-73\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R Markdown All in One</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=TianyiShi.rmarkdown)</span></span>\n<span id=\"cb5-74\"><a href=\"#cb5-74\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">Quarto</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=quarto.quarto)</span></span>\n<span id=\"cb5-75\"><a href=\"#cb5-75\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R Debugger</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=RDebugger.r-debugger)</span></span>\n<span id=\"cb5-76\"><a href=\"#cb5-76\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-77\"><a href=\"#cb5-77\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-78\"><a href=\"#cb5-78\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![VS Code를 실행하고 R Extension 설치](images/vscode_R_extension.png)</span></span>\n<span id=\"cb5-79\"><a href=\"#cb5-79\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-80\"><a href=\"#cb5-80\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 헬로우 월드</span></span>\n<span id=\"cb5-81\"><a href=\"#cb5-81\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-82\"><a href=\"#cb5-82\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`R Extension`</span> 설치되면 코드 창 상단에 실행버튼이 활성화되고 <span class=\"kw\">&lt;kbd&gt;</span>Ctrl<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Enter<span class=\"kw\">&lt;/kbd&gt;</span> 혹은 </span>\n<span id=\"cb5-83\"><a href=\"#cb5-83\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"kw\">&lt;kbd&gt;</span>Ctrl<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Shift<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Enter<span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-84\"><a href=\"#cb5-84\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-85\"><a href=\"#cb5-85\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-86\"><a href=\"#cb5-86\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![R 코드 실행화면](images/vscode_helloworld.png)</span></span>\n<span id=\"cb5-87\"><a href=\"#cb5-87\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-88\"><a href=\"#cb5-88\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-89\"><a href=\"#cb5-89\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 유튜브 동영상</span></span>\n<span id=\"cb5-90\"><a href=\"#cb5-90\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-91\"><a href=\"#cb5-91\" aria-hidden=\"true\" tabindex=\"-1\"></a>{{&lt; video https://youtu.be/c3ZQ8-OYj2M &gt;}}</span>\n<span id=\"cb5-92\"><a href=\"#cb5-92\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-93\"><a href=\"#cb5-93\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># 즐거운 코딩 환경설정</span></span>\n<span id=\"cb5-94\"><a href=\"#cb5-94\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-95\"><a href=\"#cb5-95\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 코딩 글꼴</span></span>\n<span id=\"cb5-96\"><a href=\"#cb5-96\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-97\"><a href=\"#cb5-97\" aria-hidden=\"true\" tabindex=\"-1\"></a>다른 언어와 마찬가지로 R 코드로 데이터 과학 제품을 개발할 경우 글꼴도 코딩에 적합한 한글 글꼴을 설정한다.</span>\n<span id=\"cb5-98\"><a href=\"#cb5-98\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-99\"><a href=\"#cb5-99\" aria-hidden=\"true\" tabindex=\"-1\"></a>먼저 <span class=\"co\">[</span><span class=\"ot\">D2 Coding 글꼴</span><span class=\"co\">](https://github.com/naver/d2codingfont)</span>을 다운로드 받아 운영체제에 설치한다.</span>\n<span id=\"cb5-100\"><a href=\"#cb5-100\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-101\"><a href=\"#cb5-101\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS Code 좌측 하단 톱니바퀴 <span class=\"kw\">&lt;kbd&gt;</span> Settings <span class=\"kw\">&lt;/kbd&gt;</span> 설정을 클릭 혹은 메뉴에서 \"File\" <span class=\"dv\">&amp;rarr;</span> \"Preferences\" <span class=\"dv\">&amp;rarr;</span> \"Settings\"를 통해 <span class=\"in\">`편집기 (Text Editor)`</span>로 들어가 운영체제에 설치한 코딩 폰트를 지정한다. **Font Ligatures** 도 <span class=\"in\">`true`</span>로 설정한다. 이를 통해 <span class=\"in\">`&lt; -`</span> 표시가 <span class=\"dv\">&amp;larr;</span> 로 화면에 표현된다.</span>\n<span id=\"cb5-102\"><a href=\"#cb5-102\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-103\"><a href=\"#cb5-103\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![D2코딩 글꼴 장착](images/vscode_font.png)</span></span>\n<span id=\"cb5-104\"><a href=\"#cb5-104\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-105\"><a href=\"#cb5-105\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 단축키</span></span>\n<span id=\"cb5-106\"><a href=\"#cb5-106\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-107\"><a href=\"#cb5-107\" aria-hidden=\"true\" tabindex=\"-1\"></a>R 코드 개발을 진행할 때 <span class=\"kw\">&lt;kbd&gt;</span> %&gt;% <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> <span class=\"dv\">&amp;larr;</span> <span class=\"kw\">&lt;/kbd&gt;</span> 두가지 기능이 가장 많이 사용되는 </span>\n<span id=\"cb5-108\"><a href=\"#cb5-108\" aria-hidden=\"true\" tabindex=\"-1\"></a>단축키로 RStudio에서는 기본으로 지원되고 있다. VS Code에서 자주 사용되는 </span>\n<span id=\"cb5-109\"><a href=\"#cb5-109\" aria-hidden=\"true\" tabindex=\"-1\"></a>단축키를 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> m <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> - <span class=\"kw\">&lt;/kbd&gt;</span> 를 적용시키는 방법을 살펴보자.</span>\n<span id=\"cb5-110\"><a href=\"#cb5-110\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-111\"><a href=\"#cb5-111\" aria-hidden=\"true\" tabindex=\"-1\"></a>만약 VS Code에서 단축키 설정 기능을 활용한다. [<span class=\"co\">[</span><span class=\"ot\">How to add R {magrittr}'s %&gt;% Pipe Operator in VSCode as Keyboard Shortcut</span><span class=\"co\">](https://www.programmingwithr.com/how-to-add-r-magrittr-s-pipe-operator-in-vscode-as-keyboard-shortcut/)</span>]{.aside}</span>\n<span id=\"cb5-112\"><a href=\"#cb5-112\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-113\"><a href=\"#cb5-113\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>윈도우즈: File &gt; Preferences &gt; Keyboard Shortcuts. </span>\n<span id=\"cb5-114\"><a href=\"#cb5-114\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>맥: Code &gt; Preferences &gt; Keyboard Shortcuts</span>\n<span id=\"cb5-115\"><a href=\"#cb5-115\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-116\"><a href=\"#cb5-116\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`keybindings.json`</span> 파일에 <span class=\"kw\">&lt;kbd&gt;</span> %&gt;% <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> <span class=\"dv\">&amp;larr;</span> <span class=\"kw\">&lt;/kbd&gt;</span> 단축키 기능을 추가한다.</span>\n<span id=\"cb5-117\"><a href=\"#cb5-117\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-118\"><a href=\"#cb5-118\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![자주 사용되는 R 단축키 설정](images/vscode_shortcuts.png)</span></span>\n<span id=\"cb5-119\"><a href=\"#cb5-119\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-120\"><a href=\"#cb5-120\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 패널</span></span>\n<span id=\"cb5-121\"><a href=\"#cb5-121\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-122\"><a href=\"#cb5-122\" aria-hidden=\"true\" tabindex=\"-1\"></a>RStudio는 코딩기반 데이터 분석과 통계에 최적화된 개발환경이다. </span>\n<span id=\"cb5-123\"><a href=\"#cb5-123\" aria-hidden=\"true\" tabindex=\"-1\"></a>즉, 편집기 패널, 콘솔/터미널 패널, 그래프 패널, 도움말/개발 패널로 구성된 </span>\n<span id=\"cb5-124\"><a href=\"#cb5-124\" aria-hidden=\"true\" tabindex=\"-1\"></a>꼭 필요한 패널만 구성되어 있다. </span>\n<span id=\"cb5-125\"><a href=\"#cb5-125\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-126\"><a href=\"#cb5-126\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.panel-tabset}</span>\n<span id=\"cb5-127\"><a href=\"#cb5-127\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-128\"><a href=\"#cb5-128\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 패널 설정 </span></span>\n<span id=\"cb5-129\"><a href=\"#cb5-129\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-130\"><a href=\"#cb5-130\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![VS Code: View &amp;rarr; Editor Layout &amp;rarr; Grid (2x2)](../../images/vscode_layout.png)</span></span>\n<span id=\"cb5-131\"><a href=\"#cb5-131\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-132\"><a href=\"#cb5-132\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 설정 후</span></span>\n<span id=\"cb5-133\"><a href=\"#cb5-133\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-134\"><a href=\"#cb5-134\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![도움말과 그래프](images/vscode_layout_screen.png)</span></span>\n<span id=\"cb5-135\"><a href=\"#cb5-135\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-136\"><a href=\"#cb5-136\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-137\"><a href=\"#cb5-137\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># `Radiant`</span></span>\n<span id=\"cb5-138\"><a href=\"#cb5-138\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-139\"><a href=\"#cb5-139\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS 코드 IDE를 크게 코드 편집기 패널과 R 콘솔창에 출력되는 실행결과물 가독성을 높이는 것이 필요하다.</span>\n<span id=\"cb5-140\"><a href=\"#cb5-140\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">`radian`</span><span class=\"co\">](https://github.com/randy3k/radian)</span>은 여러 줄 편집(multiline editing)과 풍부한 구문 강조(syntax highlight) 표시 기능을 갖춘 R 프로그램을 위한 대안 콘솔로 많이 사용된다.</span>\n<span id=\"cb5-141\"><a href=\"#cb5-141\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-142\"><a href=\"#cb5-142\" aria-hidden=\"true\" tabindex=\"-1\"></a>[<span class=\"co\">[</span><span class=\"ot\">Schiff consulting, 'Using R in VS Code: Some things I learned while trying out R in VS Code'</span><span class=\"co\">](https://schiff.co.nz/blog/r-and-vscode/)</span>]{.aside}</span>\n<span id=\"cb5-143\"><a href=\"#cb5-143\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-144\"><a href=\"#cb5-144\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 독립 사용사례</span></span>\n<span id=\"cb5-145\"><a href=\"#cb5-145\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-146\"><a href=\"#cb5-146\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::{#radiant layout-ncol=2}</span>\n<span id=\"cb5-147\"><a href=\"#cb5-147\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-148\"><a href=\"#cb5-148\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 설치 {.unnumbered}</span></span>\n<span id=\"cb5-149\"><a href=\"#cb5-149\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-150\"><a href=\"#cb5-150\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```bash</span></span>\n<span id=\"cb5-151\"><a href=\"#cb5-151\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\"># 출시버전 설치</span></span>\n<span id=\"cb5-152\"><a href=\"#cb5-152\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ex\">pip3</span> install <span class=\"at\">-U</span> radian</span>\n<span id=\"cb5-153\"><a href=\"#cb5-153\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\"># 실행</span></span>\n<span id=\"cb5-154\"><a href=\"#cb5-154\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ex\">radian</span></span>\n<span id=\"cb5-155\"><a href=\"#cb5-155\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-156\"><a href=\"#cb5-156\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-157\"><a href=\"#cb5-157\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 실행화면 {.unnumbered}</span></span>\n<span id=\"cb5-158\"><a href=\"#cb5-158\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-159\"><a href=\"#cb5-159\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-cmd.png)</span></span>\n<span id=\"cb5-160\"><a href=\"#cb5-160\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-161\"><a href=\"#cb5-161\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-162\"><a href=\"#cb5-162\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-163\"><a href=\"#cb5-163\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## VS 코드 콘솔</span></span>\n<span id=\"cb5-164\"><a href=\"#cb5-164\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-165\"><a href=\"#cb5-165\" aria-hidden=\"true\" tabindex=\"-1\"></a>radiant를 설치한 후에 ~~Rpath~~ 가 아니라 **Rterm**에서 설정해줘야 한다.</span>\n<span id=\"cb5-166\"><a href=\"#cb5-166\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-167\"><a href=\"#cb5-167\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::{#radian-vscode layout-ncol=3}</span>\n<span id=\"cb5-168\"><a href=\"#cb5-168\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-169\"><a href=\"#cb5-169\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 맥 {.unnumbered}</span></span>\n<span id=\"cb5-170\"><a href=\"#cb5-170\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-171\"><a href=\"#cb5-171\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-mac.png)</span></span>\n<span id=\"cb5-172\"><a href=\"#cb5-172\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-173\"><a href=\"#cb5-173\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 윈도우즈 {.unnumbered}</span></span>\n<span id=\"cb5-174\"><a href=\"#cb5-174\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-175\"><a href=\"#cb5-175\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-windows.png)</span></span>\n<span id=\"cb5-176\"><a href=\"#cb5-176\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-177\"><a href=\"#cb5-177\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 적용결과 {.unnumbered}</span></span>\n<span id=\"cb5-178\"><a href=\"#cb5-178\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-179\"><a href=\"#cb5-179\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radiant-penguins.png)</span></span>\n<span id=\"cb5-180\"><a href=\"#cb5-180\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-181\"><a href=\"#cb5-181\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-182\"><a href=\"#cb5-182\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-183\"><a href=\"#cb5-183\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-184\"><a href=\"#cb5-184\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-185\"><a href=\"#cb5-185\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># `.qmd`, `.Rmd` </span></span>\n<span id=\"cb5-186\"><a href=\"#cb5-186\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-187\"><a href=\"#cb5-187\" aria-hidden=\"true\" tabindex=\"-1\"></a>literate programming을 구현한 <span class=\"in\">`.qmd`</span>, <span class=\"in\">`.Rmd`</span> 파일를 작성하여 다양한 데이터 과학 </span>\n<span id=\"cb5-188\"><a href=\"#cb5-188\" aria-hidden=\"true\" tabindex=\"-1\"></a>문서를 작성할 수 있다.</span>\n<span id=\"cb5-189\"><a href=\"#cb5-189\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-190\"><a href=\"#cb5-190\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">**Pandoc** a universal document converter</span><span class=\"co\">](https://pandoc.org/installing.html)</span> 웹사이트에서</span>\n<span id=\"cb5-191\"><a href=\"#cb5-191\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`pandoc`</span>을 설치해야 한다. pandoc 최신버전을 설치하면 되고 버전이 2.16 이상이 되어야 활용이 가능하다.</span>\n<span id=\"cb5-192\"><a href=\"#cb5-192\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-193\"><a href=\"#cb5-193\" aria-hidden=\"true\" tabindex=\"-1\"></a>quarto-executable-code-5450563D</span>\n<span id=\"cb5-194\"><a href=\"#cb5-194\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-195\"><a href=\"#cb5-195\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```r</span></span>\n<span id=\"cb5-196\"><a href=\"#cb5-196\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">#| eval: false</span></span>\n<span id=\"cb5-197\"><a href=\"#cb5-197\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-198\"><a href=\"#cb5-198\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"sc\">$</span> pandoc <span class=\"sc\">--</span>version</span>\n<span id=\"cb5-199\"><a href=\"#cb5-199\" aria-hidden=\"true\" tabindex=\"-1\"></a>pandoc <span class=\"dv\">2</span>.<span class=\"fl\">19.2</span></span>\n<span id=\"cb5-200\"><a href=\"#cb5-200\" aria-hidden=\"true\" tabindex=\"-1\"></a>Compiled with pandoc<span class=\"sc\">-</span>types <span class=\"dv\">1</span>.<span class=\"dv\">22</span>.<span class=\"fl\">2.1</span>, texmath <span class=\"dv\">0</span>.<span class=\"dv\">12</span>.<span class=\"fl\">5.2</span>, skylighting <span class=\"fl\">0.13</span>,</span>\n<span id=\"cb5-201\"><a href=\"#cb5-201\" aria-hidden=\"true\" tabindex=\"-1\"></a>citeproc <span class=\"dv\">0</span>.<span class=\"dv\">8</span>.<span class=\"fl\">0.1</span>, ipynb <span class=\"fl\">0.2</span>, hslua <span class=\"dv\">2</span>.<span class=\"fl\">2.1</span></span>\n<span id=\"cb5-202\"><a href=\"#cb5-202\" aria-hidden=\"true\" tabindex=\"-1\"></a>Scripting engine<span class=\"sc\">:</span> Lua <span class=\"fl\">5.4</span></span>\n<span id=\"cb5-203\"><a href=\"#cb5-203\" aria-hidden=\"true\" tabindex=\"-1\"></a>User data directory<span class=\"sc\">:</span> C<span class=\"sc\">:</span>\\Users\\statkclee\\AppData\\Roaming\\pandoc</span>\n<span id=\"cb5-204\"><a href=\"#cb5-204\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">Copyright</span> (C) <span class=\"dv\">2006-2022</span> John MacFarlane. Web<span class=\"sc\">:</span>  https<span class=\"sc\">:</span><span class=\"er\">//</span>pandoc.org</span>\n<span id=\"cb5-205\"><a href=\"#cb5-205\" aria-hidden=\"true\" tabindex=\"-1\"></a>This is free software; see the source <span class=\"cf\">for</span> copying conditions. There is no</span>\n<span id=\"cb5-206\"><a href=\"#cb5-206\" aria-hidden=\"true\" tabindex=\"-1\"></a>warranty, not even <span class=\"cf\">for</span> merchantability or fitness <span class=\"cf\">for</span> a particular purpose.</span>\n<span id=\"cb5-207\"><a href=\"#cb5-207\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-208\"><a href=\"#cb5-208\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-209\"><a href=\"#cb5-209\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## `keybindings.json`</span></span>\n<span id=\"cb5-210\"><a href=\"#cb5-210\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-211\"><a href=\"#cb5-211\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`keybindings.json`</span> 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 </span>\n<span id=\"cb5-212\"><a href=\"#cb5-212\" aria-hidden=\"true\" tabindex=\"-1\"></a>등록시킨다. <span class=\"co\">[</span><span class=\"ot\">자료출처: [VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding](https://www.schmidtynotes.com/blog/r/2021-09-28-vscode-rmd-code-chunk-snippet/)</span><span class=\"co\">]</span>{.aside}</span>\n<span id=\"cb5-213\"><a href=\"#cb5-213\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-214\"><a href=\"#cb5-214\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.callout-tip collapse=\"true\"}</span>\n<span id=\"cb5-215\"><a href=\"#cb5-215\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-216\"><a href=\"#cb5-216\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### `keybindings.json` 설정파일 예시</span></span>\n<span id=\"cb5-217\"><a href=\"#cb5-217\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-218\"><a href=\"#cb5-218\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-219\"><a href=\"#cb5-219\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```json</span></span>\n<span id=\"cb5-220\"><a href=\"#cb5-220\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">// Place your key bindings in this file to override the defaults</span></span>\n<span id=\"cb5-221\"><a href=\"#cb5-221\" aria-hidden=\"true\" tabindex=\"-1\"></a>[</span>\n<span id=\"cb5-222\"><a href=\"#cb5-222\" aria-hidden=\"true\" tabindex=\"-1\"></a>    <span class=\"co\">// keybindings for R scripts. </span></span>\n<span id=\"cb5-223\"><a href=\"#cb5-223\" aria-hidden=\"true\" tabindex=\"-1\"></a>    {</span>\n<span id=\"cb5-224\"><a href=\"#cb5-224\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-225\"><a href=\"#cb5-225\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-226\"><a href=\"#cb5-226\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-227\"><a href=\"#cb5-227\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == r\"</span></span>\n<span id=\"cb5-228\"><a href=\"#cb5-228\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-229\"><a href=\"#cb5-229\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-230\"><a href=\"#cb5-230\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-231\"><a href=\"#cb5-231\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-232\"><a href=\"#cb5-232\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-233\"><a href=\"#cb5-233\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == r\"</span></span>\n<span id=\"cb5-234\"><a href=\"#cb5-234\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-235\"><a href=\"#cb5-235\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// keybindings for Rmarkdown</span></span>\n<span id=\"cb5-236\"><a href=\"#cb5-236\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-237\"><a href=\"#cb5-237\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-238\"><a href=\"#cb5-238\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-239\"><a href=\"#cb5-239\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-240\"><a href=\"#cb5-240\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == rmd\"</span></span>\n<span id=\"cb5-241\"><a href=\"#cb5-241\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-242\"><a href=\"#cb5-242\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-243\"><a href=\"#cb5-243\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-244\"><a href=\"#cb5-244\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-245\"><a href=\"#cb5-245\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-246\"><a href=\"#cb5-246\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == rmd\"</span></span>\n<span id=\"cb5-247\"><a href=\"#cb5-247\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-248\"><a href=\"#cb5-248\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// keybindings for R terminal (radian included)</span></span>\n<span id=\"cb5-249\"><a href=\"#cb5-249\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-250\"><a href=\"#cb5-250\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-251\"><a href=\"#cb5-251\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"workbench.action.terminal.sendSequence\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-252\"><a href=\"#cb5-252\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-253\"><a href=\"#cb5-253\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"terminalFocus\"</span></span>\n<span id=\"cb5-254\"><a href=\"#cb5-254\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-255\"><a href=\"#cb5-255\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-256\"><a href=\"#cb5-256\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-257\"><a href=\"#cb5-257\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"workbench.action.terminal.sendSequence\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-258\"><a href=\"#cb5-258\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-259\"><a href=\"#cb5-259\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"terminalFocus\"</span></span>\n<span id=\"cb5-260\"><a href=\"#cb5-260\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-261\"><a href=\"#cb5-261\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// Insert R Code chunk</span></span>\n<span id=\"cb5-262\"><a href=\"#cb5-262\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-263\"><a href=\"#cb5-263\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+i\"</span><span class=\"op\">.</span> </span>\n<span id=\"cb5-264\"><a href=\"#cb5-264\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-265\"><a href=\"#cb5-265\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-266\"><a href=\"#cb5-266\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> {<span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"```{r}</span><span class=\"sc\">\\n</span><span class=\"st\">$0</span><span class=\"sc\">\\n</span><span class=\"st\">```\"</span>}</span>\n<span id=\"cb5-267\"><a href=\"#cb5-267\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-268\"><a href=\"#cb5-268\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-269\"><a href=\"#cb5-269\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+o\"</span><span class=\"op\">.</span> </span>\n<span id=\"cb5-270\"><a href=\"#cb5-270\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-271\"><a href=\"#cb5-271\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-272\"><a href=\"#cb5-272\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> {<span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"options(</span><span class=\"sc\">\\n</span><span class=\"st\">  max.print=100,</span><span class=\"sc\">\\n</span><span class=\"st\">  vsc.use_httpgd=TRUE,</span><span class=\"sc\">\\n</span><span class=\"st\">  device='quartz'</span><span class=\"sc\">\\n</span><span class=\"st\">)\"</span>}</span>\n<span id=\"cb5-273\"><a href=\"#cb5-273\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-274\"><a href=\"#cb5-274\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-275\"><a href=\"#cb5-275\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-276\"><a href=\"#cb5-276\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-277\"><a href=\"#cb5-277\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-278\"><a href=\"#cb5-278\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span>{</span>\n<span id=\"cb5-279\"><a href=\"#cb5-279\" aria-hidden=\"true\" tabindex=\"-1\"></a>          <span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"---</span><span class=\"sc\">\\n</span><span class=\"st\">title: '$0'</span><span class=\"sc\">\\n</span><span class=\"st\">author: '이광춘'</span><span class=\"sc\">\\n</span><span class=\"st\">date: '`r Sys.Date()`'</span><span class=\"sc\">\\n</span><span class=\"st\">output:</span><span class=\"sc\">\\n</span><span class=\"st\">  pagedown::html_paged:</span><span class=\"sc\">\\n</span><span class=\"st\">    self_contained: true</span><span class=\"sc\">\\n</span><span class=\"st\">    toc: false</span><span class=\"sc\">\\n</span><span class=\"st\">---</span><span class=\"sc\">\\n\\n</span><span class=\"st\">```{r setup, include=FALSE}</span><span class=\"sc\">\\n</span><span class=\"st\">knitr::opts_chunk</span><span class=\"sc\">\\\\</span><span class=\"st\">$set(</span><span class=\"sc\">\\n</span><span class=\"st\">  echo = FALSE,</span><span class=\"sc\">\\n</span><span class=\"st\">  message = FALSE,</span><span class=\"sc\">\\n</span><span class=\"st\">  warning=FALSE</span><span class=\"sc\">\\n</span><span class=\"st\">)</span><span class=\"sc\">\\n</span><span class=\"st\">```\"</span></span>\n<span id=\"cb5-280\"><a href=\"#cb5-280\" aria-hidden=\"true\" tabindex=\"-1\"></a>        }</span>\n<span id=\"cb5-281\"><a href=\"#cb5-281\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-282\"><a href=\"#cb5-282\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-283\"><a href=\"#cb5-283\" aria-hidden=\"true\" tabindex=\"-1\"></a>]</span>\n<span id=\"cb5-284\"><a href=\"#cb5-284\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-285\"><a href=\"#cb5-285\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-286\"><a href=\"#cb5-286\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-287\"><a href=\"#cb5-287\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-288\"><a href=\"#cb5-288\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## HTML 미리보기</span></span>\n<span id=\"cb5-289\"><a href=\"#cb5-289\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-290\"><a href=\"#cb5-290\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`.Rmd`</span> 파일을 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> k <span class=\"kw\">&lt;/kbd&gt;</span> 단축키로 컴파일시키면 </span>\n<span id=\"cb5-291\"><a href=\"#cb5-291\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`.html`</span> 파일이 생성된다. <span class=\"in\">`.html`</span> 파일 결과를 직접 실시간으로 확인하고자 한다면, </span>\n<span id=\"cb5-292\"><a href=\"#cb5-292\" aria-hidden=\"true\" tabindex=\"-1\"></a>마이크로소프트가 개발한 <span class=\"co\">[</span><span class=\"ot\">`Live Preview - VS Code Extension`</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=ms-vscode.live-server)</span> 플러그인을 설치한다.</span>\n<span id=\"cb5-293\"><a href=\"#cb5-293\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-294\"><a href=\"#cb5-294\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/vscode_open-context-menu.gif)</span></span>\n<span id=\"cb5-295\"><a href=\"#cb5-295\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-296\"><a href=\"#cb5-296\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-297\"><a href=\"#cb5-297\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># GitHub copilot</span></span>\n<span id=\"cb5-298\"><a href=\"#cb5-298\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-299\"><a href=\"#cb5-299\" aria-hidden=\"true\" tabindex=\"-1\"></a>GitHub에서 공개한 Copilot은 AI pair programmer라는 부제를 달고 있고,</span>\n<span id=\"cb5-300\"><a href=\"#cb5-300\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">GitHub Copilot</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)</span> 플러그인을 </span>\n<span id=\"cb5-301\"><a href=\"#cb5-301\" aria-hidden=\"true\" tabindex=\"-1\"></a>설치하면 사용이 가능하다.</span>\n<span id=\"cb5-302\"><a href=\"#cb5-302\" aria-hidden=\"true\" tabindex=\"-1\"></a>한가지 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span> 단축키가 충돌되어 R 코드 실행하는 것과 겹쳐서 문제가 있기 때문에</span>\n<span id=\"cb5-303\"><a href=\"#cb5-303\" aria-hidden=\"true\" tabindex=\"-1\"></a>단축키를 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span>와 같이 조정하면 큰 문제 없이 </span>\n<span id=\"cb5-304\"><a href=\"#cb5-304\" aria-hidden=\"true\" tabindex=\"-1\"></a>R 개발할 때 GitHub copilot과 함께 사용이 가능하다.</span>\n<span id=\"cb5-305\"><a href=\"#cb5-305\" aria-hidden=\"true\" tabindex=\"-1\"></a>이를 위해서 <span class=\"in\">`keybindings.json`</span> 파일에 다음 사항을 추가한다. </span>\n<span id=\"cb5-306\"><a href=\"#cb5-306\" aria-hidden=\"true\" tabindex=\"-1\"></a>사용자별로 단축키를 달리해서 적용시키는 것도 물론 가능하다.</span>\n<span id=\"cb5-307\"><a href=\"#cb5-307\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-308\"><a href=\"#cb5-308\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>코드 라인별로 추천 승인: <span class=\"kw\">&lt;kbd&gt;</span> Tab <span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-309\"><a href=\"#cb5-309\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>전체 코드 작성 전체 추천 : <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-310\"><a href=\"#cb5-310\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span><span class=\"in\">`Accept Solution`</span> 클릭</span>\n<span id=\"cb5-311\"><a href=\"#cb5-311\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span>코드 작성 편집기에 관련 사항 반영</span>\n<span id=\"cb5-312\"><a href=\"#cb5-312\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-313\"><a href=\"#cb5-313\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-314\"><a href=\"#cb5-314\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.callout-tip collapse=\"true\"}</span>\n<span id=\"cb5-315\"><a href=\"#cb5-315\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-316\"><a href=\"#cb5-316\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### `keybindings.json` 설정파일 예시</span></span>\n<span id=\"cb5-317\"><a href=\"#cb5-317\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-318\"><a href=\"#cb5-318\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-319\"><a href=\"#cb5-319\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```json</span></span>\n<span id=\"cb5-320\"><a href=\"#cb5-320\" aria-hidden=\"true\" tabindex=\"-1\"></a>[</span>\n<span id=\"cb5-321\"><a href=\"#cb5-321\" aria-hidden=\"true\" tabindex=\"-1\"></a>  <span class=\"op\">...</span></span>\n<span id=\"cb5-322\"><a href=\"#cb5-322\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// GitHub Copilot</span></span>\n<span id=\"cb5-323\"><a href=\"#cb5-323\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-324\"><a href=\"#cb5-324\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+shift+alt+enter\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-325\"><a href=\"#cb5-325\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"github.copilot.generate\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-326\"><a href=\"#cb5-326\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; github.copilot.activated &amp;&amp; editorLangId == 'r'\"</span></span>\n<span id=\"cb5-327\"><a href=\"#cb5-327\" aria-hidden=\"true\" tabindex=\"-1\"></a>    }<span class=\"op\">,</span></span>\n<span id=\"cb5-328\"><a href=\"#cb5-328\" aria-hidden=\"true\" tabindex=\"-1\"></a>    {</span>\n<span id=\"cb5-329\"><a href=\"#cb5-329\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"tab\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-330\"><a href=\"#cb5-330\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.inlineSuggest.commit\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-331\"><a href=\"#cb5-331\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"textInputFocus &amp;&amp; inlineSuggestionHasIndentationLessThanTabSize &amp;&amp; inlineSuggestionVisible &amp;&amp; !editorTabMovesFocus\"</span>     </span>\n<span id=\"cb5-332\"><a href=\"#cb5-332\" aria-hidden=\"true\" tabindex=\"-1\"></a>    }<span class=\"op\">,</span></span>\n<span id=\"cb5-333\"><a href=\"#cb5-333\" aria-hidden=\"true\" tabindex=\"-1\"></a>]</span>\n<span id=\"cb5-334\"><a href=\"#cb5-334\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span>    </span>\n<span id=\"cb5-335\"><a href=\"#cb5-335\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-336\"><a href=\"#cb5-336\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-337\"><a href=\"#cb5-337\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-338\"><a href=\"#cb5-338\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 중요 추가설정</span></span>\n<span id=\"cb5-339\"><a href=\"#cb5-339\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-340\"><a href=\"#cb5-340\" aria-hidden=\"true\" tabindex=\"-1\"></a>Principal Cloud Advocate at Microsoft David Smith가 \"New York Open Statistical Programming Meetup, 28 February 2023\"에서 발표한 **Copilot for R** 내용 중 VS 코드 환경설정부분이다. </span>\n<span id=\"cb5-341\"><a href=\"#cb5-341\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-342\"><a href=\"#cb5-342\" aria-hidden=\"true\" tabindex=\"-1\"></a>[<span class=\"co\">[</span><span class=\"ot\">Copilot for R</span><span class=\"co\">](https://github.com/revodavid/copilot-for-r)</span>]{.aside}</span>\n<span id=\"cb5-343\"><a href=\"#cb5-343\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-344\"><a href=\"#cb5-344\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>VS 코드 </span>\n<span id=\"cb5-345\"><a href=\"#cb5-345\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span><span class=\"co\">[</span><span class=\"ot\">Copilot extension</span><span class=\"co\">](https://aka.ms/get-copilot)</span></span>\n<span id=\"cb5-346\"><a href=\"#cb5-346\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span><span class=\"co\">[</span><span class=\"ot\">R Extension for Visual Studio Code</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r)</span></span>\n<span id=\"cb5-347\"><a href=\"#cb5-347\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>copilot 추천에 집중하기 위해서 다음 사항도 설정에 반영한다.</span>\n<span id=\"cb5-348\"><a href=\"#cb5-348\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Hover (disabled)</span>\n<span id=\"cb5-349\"><a href=\"#cb5-349\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Quick Suggestions (off)</span>\n<span id=\"cb5-350\"><a href=\"#cb5-350\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Parameter Hints (disabled)</span>\n<span id=\"cb5-351\"><a href=\"#cb5-351\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>R 패키지 설치 및 <span class=\"in\">`opitions()`</span></span>\n<span id=\"cb5-352\"><a href=\"#cb5-352\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>httr, jsonlite, tidyverse, tidymodels, docopt, httpuv</span>\n<span id=\"cb5-353\"><a href=\"#cb5-353\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>가독성 높은 그래프 출력: <span class=\"in\">`options(vsc.dev.args = list(width = 800, height = 600))`</span></span>\n<span id=\"cb5-354\"><a href=\"#cb5-354\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-355\"><a href=\"#cb5-355\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 실제 적용 사례</span></span>\n<span id=\"cb5-356\"><a href=\"#cb5-356\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-357\"><a href=\"#cb5-357\" aria-hidden=\"true\" tabindex=\"-1\"></a>펭귄과 호박 데이터를 적용한 사례 시연을 살펴보자.</span>\n<span id=\"cb5-358\"><a href=\"#cb5-358\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-359\"><a href=\"#cb5-359\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-360\"><a href=\"#cb5-360\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 펭귄 데이터셋 {.unnumbered}</span></span>\n<span id=\"cb5-361\"><a href=\"#cb5-361\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-362\"><a href=\"#cb5-362\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-363\"><a href=\"#cb5-363\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/vscode_copilot.gif)</span></span>\n<span id=\"cb5-364\"><a href=\"#cb5-364\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-365\"><a href=\"#cb5-365\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-366\"><a href=\"#cb5-366\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 호박 데이터셋 {.unnumbered}</span></span>\n<span id=\"cb5-367\"><a href=\"#cb5-367\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-368\"><a href=\"#cb5-368\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"kw\">&lt;iframe</span> <span class=\"er\">src</span><span class=\"ot\">=</span><span class=\"st\">\"images/pumpkins-copilot.mp4\"</span> <span class=\"er\">allowfullscreen</span> <span class=\"er\">allow</span><span class=\"ot\">=</span><span class=\"st\">\"encrypted-media\"</span> <span class=\"er\">width</span><span class=\"ot\">=</span><span class=\"st\">\"320\"</span> <span class=\"er\">height</span><span class=\"ot\">=</span><span class=\"st\">\"180\"</span><span class=\"kw\">&gt;</span></span>\n<span id=\"cb5-369\"><a href=\"#cb5-369\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-370\"><a href=\"#cb5-370\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-371\"><a href=\"#cb5-371\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-372\"><a href=\"#cb5-372\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">    </span></span></code></pre></div>\n</div>"
  },
  {
    "objectID": "interface.html",
    "href": "interface.html",
    "title": "chatGPT",
    "section": "",
    "text": "특정 작업에 필요한 정보를 얻는 검색(search)은 기한이 정해진 업무를 수행함에 있어 매우 중요하다. chatGPT의 등장으로 새로운 검색 패러다임이 제시되고 있다. 물론 기존 검색방식이 부족한 것은 아니며 검색경험을 향상시키기 위해 많은 노력이 경주된 것도 사실이다. 차세대 R마크다운 쿼토(quarto) 문서 제작사례을 위한 검색사례를 통해 chatGPT와 비교하여 보자.\n\n구글 검색을 통해 일반적인 내용을 얻을 수도 있다. 예를 들어,\n\nsite:quarto.org/ google analytics tracking code\n\n구글검색창에 상기 사항을 입력하게 되면 구글은 쿼토(quarto) 웹사이트 내부에서 google analytics tracking code 키워드와 관련이 높은 웹페이지를 검색결과로 반환시키게 된다.\n\n\n\n\n\nQuarto는 웹사이트와 책의 전체 텍스트 검색을 지원하는데, 기본적으로 Quarto는 사이트의 콘텐츠를 자동으로 색인화하여 기본적으로 로컬로 구축된 색인을 사용하여 높은 검색품질을 제공한다. 따라서, 사용자는 구글웹사이트가 아니라 쿼토(quarto)에서 검색을 수행하여 직접 해당 정보를 찾는 것도 가능하다.\n\n\n\n\n\nChatGPT를 사용하여 검색작업을 수행할 수도 있다. 특정 웹사이트에서 해당 정보를 얻어야 되기 때문에 지시명령어(Prompt)를 다음과 같이 작성한다.\n\nsearch https://quarto.org/ insert google analytics tracking code for quarto html document\n\n\n\n\n\n\n쿼토(Quarto)는 차세대 R마크다운이라는 별명이 붙어 있을 정도로 R마크다운이 갖는 모든 기능에 더하여 추가로 새로운 언어(Python, R, Julia, Observable.)에 대한 지원도 포괄하고 있어 상당한 학습량을 요구한다. 설계는 깔끔하게 잘 되어 있지만 이것을 잘 사용하려면 상당한 학습량이 필요로 한다. 이런 문제에 chatGPT를 도입하여 사용하면 경우에 따라서 큰 도움을 줄 수도 있다.\n\nQuarto Help Bot - Ask a question about Quarto.\n\n\n\n\n\n:::\n내부적으로 동작하는 질문-응답(QnA)에는 다음과 같은 단계로 세분화되어 있으며, 모두 ChatVectorDBChain이 처리한다:\n\n채팅 기록과 새로운 사용자 입력이 주어지면 독립형 질문이 무엇인지 결정(GPT-3 사용).\n독립형 질문이 주어지면 벡터 스토어에서 관련 문서를 검색.\n독립형 질문과 관련 문서를 GPT-3에 전달하여 최종 답변을 생성."
  },
  {
    "objectID": "use-cases.html",
    "href": "use-cases.html",
    "title": "chatGPT",
    "section": "",
    "text": "출처: 내 카톡엔 챗GPT가 들어있다\n급한경우 모바일에서 chatGPT 사용이 가능하나, 대부분 데스크톱 PC에서 chatGPT를 사용하는 경우가 많다. chatGPT 사용자 환경이 영어 사용자에 초점을 맞추다보니 한국어를 모국어로 사용하는 사용자는 번역이 꼭 필요한 경우가 많다. 이와 같은 경우 크롬 웹브라우져 chrome 웹 스토어에서 확장 프로그램(Extension)을 사용하면 도움을 받을 수 있다."
  },
  {
    "objectID": "use-cases.html#chatgpt-최종-정보",
    "href": "use-cases.html#chatgpt-최종-정보",
    "title": "chatGPT",
    "section": "\n1.1 chatGPT 최종 정보",
    "text": "1.1 chatGPT 최종 정보\n\n\n\n\n\n\nwhen was your last training date?\n\n\n\n\n\nAs an AI language model, I am continuously being trained and updated to improve my performance and accuracy. My last major training update occurred in September 2021, but I am continually receiving smaller updates and improvements to my knowledge and capabilities."
  },
  {
    "objectID": "use-cases.html#웹검색",
    "href": "use-cases.html#웹검색",
    "title": "chatGPT",
    "section": "\n1.2 웹검색",
    "text": "1.2 웹검색\n이러한 한계를 보완하는 WebChatGPT 를 통해서 최신 검색 기능을 보완할 수도 있다. 하지만 WebChatGPT를 활성화시키는 순간 chatGPT 기능도 없어져 단순한 검색기로 변환되니 유의한다. 개발소스코드는 qunash/chatgpt-advanced를 참조한다."
  },
  {
    "objectID": "news_article.html",
    "href": "news_article.html",
    "title": "chatGPT",
    "section": "",
    "text": "사단법인 한국 R 사용자회 관련 주요 뉴스기사는 다음과 같다.\n\n코드library(tidyverse)\nlibrary(googlesheets4)\nlibrary(lubridate)\nlibrary(gt)\n\nnews_raw <- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1KITnaJTqsDHtm-wUWboog4xG6U6SBuB_Zee8qpCgLN4/edit?usp=sharing\", sheet = \"뉴스기사\")\n\nnews_tbl <- news_raw %>% \n  mutate(날짜 = as.Date(날짜)) %>% \n  arrange(desc(날짜)) %>% \n  mutate(뉴스링크 = sprintf('<a href = \"%s\">%s</a>', 링크, `뉴스기사 제목`),\n         뉴스링크 = map(뉴스링크, gt::html))  %>% \n  select(날짜, 언론사, 기자명, 기자명, 링크, 뉴스링크)\n\nnews_tbl %>% \n  select(-링크) %>% \n  gt() %>% \n    cols_align(\n    align = \"center\",\n    columns = everything()\n  )\n\n\n\n\n\n\n날짜\n      언론사\n      기자명\n      뉴스링크\n    \n\n\n2022-04-18\n오마이뉴스\n이광춘\n통계 대중화 위한 '오픈 통계 패키지' 나왔다 - 오마이뉴스\n\n\n2021-10-25\nIT 조선\n이윤경\n\"디지털 경제 패러다임 전환은 R\"…한국R 콘퍼러스, 11월 19일 개최 - IT조선 > 기술 > 일반\n\n\n2021-09-18\n한겨레\n권오성\n데이터 분석 언어 ‘R’ 한국 콘퍼런스 열린다\n\n\n2016-12-07\nKBS\n최건일\n인공지능으로 분석한 대통령의 마음…슬픔은 어디에?\n\n\n2015-01-31\nIT Daily\n팽동현\n[데이터사이언티스트를 찾아서] “빅데이터 분석, 데이터의 본질을 바라보는 것부터”\n\n\n2012-10-11\n디지털 데일리\n백지영\n넥스알, ‘R사용자컨퍼런스 2012’ 24일 개최"
  },
  {
    "objectID": "news_article.html#보도자료-초안",
    "href": "news_article.html#보도자료-초안",
    "title": "chatGPT",
    "section": "\n4.1 보도자료 초안",
    "text": "4.1 보도자료 초안\n\n프롬프트: 비영리법인 한국 R 사용자회는 2017년부터 매년 국내 유일의 데이터 사이언스 밋업(Meetup)을 주관하고 있습니다. 2023년 올해는 교보생명보험 그룹 데이터 분석 법인 디플래닉스(DPlanex)의 후원을 받아 “ChatGPT와 데이터 사이언스” 주제로 총 6회에 결쳐 강남 교보타워 5층 노블리에홀에서 행사를 진행합니다. 이에 대한 홍보 기사를 작성해주세요.\n\n\n\n\n\n\n\n주의\n\n\n\n\n\n한국 R 사용자회 비영리법인이 2017년부터 국내 유일한 데이터 사이언스 밋업을 성공적으로 개최하고 있습니다. 이번 2023년, 교보생명보험 그룹의 데이터 분석 법인인 디플래닉스(DPlanex)의 후원으로, “ChatGPT와 데이터 사이언스” 주제로 총 6회에 걸쳐 강남 교보타워 5층 노블리에홀에서 행사를 개최하게 되었습니다.\n이번 행사는 데이터 사이언스와 인공지능의 최신 동향에 대한 이해를 높이고, ChatGPT 기술을 활용한 데이터 분석 및 예측 방법을 다룹니다. 행사 기간 동안 전문가들의 강연과 워크숍, 토론 등 다양한 프로그램이 준비되어 있으며, 자연어 처리, 기계 학습, 데이터 시각화 등 다양한 주제가 다루어집니다.\n이번 행사는 데이터 사이언티스트, 연구원, 또는 인공지능과 데이터 사이언스에 관심이 있는 분들에게 모두 열려 있으며, 또한 같은 관심사를 가진 사람들과의 네트워킹 기회도 제공됩니다.\n행사 등록은 지금부터 가능하며, 자리가 한정되어 있으므로 서둘러 등록하시기 바랍니다. 이번 기회를 놓치지 마시고, 최신 데이터 사이언스 및 인공지능 기술 동향을 접하며, 전문가들과 함께 학습하는 좋은 기회가 되시길 바랍니다."
  },
  {
    "objectID": "news_article.html#기사-제목-초안",
    "href": "news_article.html#기사-제목-초안",
    "title": "chatGPT",
    "section": "\n4.2 기사 제목 초안",
    "text": "4.2 기사 제목 초안\n\n프롬프트: 뉴스 기사 제목은 3개만 작성하세요.\n\n\n\n\n\n\n\n주의\n\n\n\n\n\n\n“한국R사용자협회와 DPlanex, ChatGPT 중심 데이터 사이언스 행사 위해 협력”\n“교보타워 노블리홀, 2023년 6개 데이터 사이언스 행사 개최”\n“NLP, 기계 학습 및 데이터 시각화 전문가가 ChatGPT 및 데이터 과학 이벤트에서 연설합니다.”"
  },
  {
    "objectID": "news_article.html#보도자료-언론-배포",
    "href": "news_article.html#보도자료-언론-배포",
    "title": "chatGPT",
    "section": "\n4.3 보도자료 언론 배포",
    "text": "4.3 보도자료 언론 배포\nchatGPT가 작성한 기사제목(일명 야마)과 본문 내용에 더하여 보도자료 담당자 정보를 붙여 PDF 문서형태로 최종 마무리한다."
  },
  {
    "objectID": "interface.html#askup-검색",
    "href": "interface.html#askup-검색",
    "title": "chatGPT",
    "section": "\naskup 검색",
    "text": "askup 검색"
  },
  {
    "objectID": "interface.html#채팅준비",
    "href": "interface.html#채팅준비",
    "title": "chatGPT",
    "section": "채팅준비",
    "text": "채팅준비"
  },
  {
    "objectID": "interface.html#ocr-사례",
    "href": "interface.html#ocr-사례",
    "title": "chatGPT",
    "section": "OCR 사례",
    "text": "OCR 사례"
  },
  {
    "objectID": "interface.html#뉴스-요약",
    "href": "interface.html#뉴스-요약",
    "title": "chatGPT",
    "section": "뉴스 요약",
    "text": "뉴스 요약"
  },
  {
    "objectID": "interface.html#채널추가",
    "href": "interface.html#채널추가",
    "title": "chatGPT",
    "section": "채널추가",
    "text": "채널추가"
  },
  {
    "objectID": "interface.html#카카오톡",
    "href": "interface.html#카카오톡",
    "title": "chatGPT",
    "section": "\n3.1 카카오톡",
    "text": "3.1 카카오톡\n모바일 메신져 카카오톡에 AskUp 채널을 추가하게 되면 chatGPT 유사 기능을 사용할 수 있다. 문제는 언제 AskUp 채널 서비스가 중단될지 유료로 과금이 변경될지 모르지만 chatGPT를 사용하는 방식이 다양화함은 분명하다.\nAskUp 서비스는 현재 시점(“2023-03-10”) 기준 PDF 문서요약기능은 제공하고 있지 않지만 장문의 텍스트는 요약하는 기능을 제공하고 있다.\n\n\naskup 검색\n채널추가\n채팅준비\nOCR 사례\n뉴스 요약"
  },
  {
    "objectID": "interface.html#슬랙",
    "href": "interface.html#슬랙",
    "title": "chatGPT",
    "section": "\n3.3 슬랙",
    "text": "3.3 슬랙\n2023년 3월 7일 Salesforce와 OpenAI는 Slack용 ChatGPT 앱을 출시했다. OpenAI가 Slack 플랫폼에 구축한 이 앱은 ChatGPT의 강력한 AI 기술을 통합하여 즉각적인 대화 요약, 조사 도구 및 작성 지원을 Slack에서 바로 제공하여 수백만 기업이 보다 생산적으로 작업할 수 있도록 지원하기 시작했다.\n출처: Introducing the ChatGPT App for Slack"
  },
  {
    "objectID": "rnd.html",
    "href": "rnd.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 인용높은 논문 5개\nchatGPT에 가장 인용수가 높은 논문 5개를 찾아달라고 요청을 하였다.\n\n프롬프트: What are the most cited papers?\n\n\n\n한영 번역\n영어 원문\n\n\n\nchatGPT에 나온 인용에 대한 근거를 확신할 수 없어 구글 학술검색에서 해당 논문에 대한 인용 횟수를 수작업으로 정리했다.\n\nStephen Wolfram의 “A New Kind of Science” - 이 책은 2002년 출판 이후 14,000 9,696회 인용되었습니다. 셀룰러 오토마타를 사용하는 복잡한 시스템.\nSergey Brin과 Lawrence Page의 “The Anatomy of a Large-Scale Hypertextual Web Search Engine” - 1998년에 출판된 이 논문은 PageRank를 소개했습니다. 알고리즘이며 Google의 기반으로 널리 알려져 있습니다. 15,000 22,779회 이상 인용되었습니다.\nThomas Kuhn의 “과학 혁명의 구조” - 1962년에 출판된 이 책은 44,000 597회 이상 인용되었으며 다음과 같은 개념을 도입했습니다. 과학의 패러다임 변화.\nLarry V. Hedges 및 Ingram Olkin의 “Statistical Methods for Meta-Analysis” - 1985년에 출판된 이 논문은 53,000 18,545회 이상 인용되었으며 연구 합성에 메타 분석의 사용을 소개했습니다.\nAlbert Einstein, Boris Podolsky 및 Nathan Rosen의 “The Nature 논문” - 1935년에 출판된 이 논문은 양자 얽힘의 개념이며 13,000 10회 이상 인용되었습니다.\n\n\n\nThere are several papers that have been highly cited in various fields of study. Here are some examples:\n\n“A New Kind of Science” by Stephen Wolfram - This book has been cited over 14,000 times since its publication in 2002. It presents a new approach to understanding complex systems using cellular automata.\n“The Anatomy of a Large-Scale Hypertextual Web Search Engine” by Sergey Brin and Lawrence Page - This paper, published in 1998, introduced the PageRank algorithm and is widely regarded as the foundation of Google. It has been cited over 15,000 times.\n“The Structure of Scientific Revolutions” by Thomas Kuhn - Published in 1962, this book has been cited over 44,000 times and introduced the concept of paradigm shifts in science.\n“Statistical Methods for Meta-Analysis” by Larry V. Hedges and Ingram Olkin - This paper, published in 1985, has been cited over 53,000 times and introduced the use of meta-analysis in research synthesis.\n“The Nature paper” by Albert Einstein, Boris Podolsky, and Nathan Rosen - This paper, published in 1935, introduced the concept of quantum entanglement and has been cited over 13,000 times.\n\nThese papers represent a small sample of highly cited papers, and there are many others that have made significant contributions to their respective fields.\n\n\n\n\n2 구글검색 논문\n현재 구글이 있게 한 Sergey Brin과 Lawrence Page의 “The Anatomy of a Large-Scale Hypertextual Web Search Engine” 논문을 다운로드 받아 살펴보자.\n\n\n\n3 chatPDF 서비스\nchatPDF 웹사이트에 연구 PDF 논문을 올리면 이를 chatGPT 기술을 이용하여 요약을 해주고 관련하여 몇가지 질문도 제시해준다. 질문에 대한 답을 할 때 해당 논문의 근거 페이지, 단락도 제시해주기 때문에 필요하면 추가로 확인도 진행하고, 추가로 질문을 더 넣어 논문에 대한 이해를 높일 수 있다. (Brin & Page, 1998)\n\n\nchatPDF 접속\n논문 요약 및 제시질문\n채팅 예시\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 국문 논문\n2020년 출간된 논문(이광춘, 2020)을 chatPDF를 사용하여 과학기술 연구개발의 생산성을 높일 수 있는 방법을 찾아보자.\n\n논문 소스코드: 바로가기\n\nPDF 출판 논문: 다운로드\n\n\n\n\nPDF 원본\nopenAI API\n세무사\n기계와 전쟁 승리\n영문초록 없음\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5 엣지 PDF\n마이크로소프트 엣지(Microsoft Edge)는 마이크로소프트가 개발한 웹 브라우저로, 기존의 인터넷 익스플로러(Internet Explorer)를 대체하기 위해 만들어졌고, 2015년 Windows 10과 함께 처음 공개되었다. 2020년부터 엣지는 구글의 오픈 소스 프로젝트인 크로미움(Chromium) 기반으로 개발되어, 크롬(Chrome)과 같은 엔진을 차용하여 엣지는 크롬 확장 프로그램과 호환성이 높아졌고, 성능과 안정성이 향상되었다.\n특히 chatGPT 기능을 엣지 웹 브라우저에 채용하면서 점유율이 점차 높아지고 있다.\npdf 논문을 아도브 아크로뱃 리더 대신 엣지 브라우져에서 열게 되면 chatPDF 기능을 자체적으로 사용할 수 있다. 이런 경우 pdf 파일을 외부에 전송하지 않고 로컬 컴퓨터에서 작업한다는 점에서 속도 및 보안에 안정성을 높일 수 있다.\n김건희 여사가 집필한 “온라인 운세 콘텐츠의 이용자들의 이용 만족과 불만족에 따른 회원 유지와 탈퇴에 대한 연구” KCI 등재논문을 엣지에서 열어 GPT-4 기능을 확인해보자.\n\n\nPDF 원본\nGPT-4 논문\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\nBrin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 30(1-7), 107–117.\n\n\n이광춘주용우. (2020). 사람과 인공지능의 일자리 경쟁 요인과 협업 방안. 디지털경영연구 Vol.6 No.2 Pp.39-50."
  },
  {
    "objectID": "yuji.html",
    "href": "yuji.html",
    "title": "chatGPT",
    "section": "",
    "text": "김건희 여사가 집필한 “온라인 운세 콘텐츠의 이용자들의 이용 만족과 불만족에 따른 회원 유지와 탈퇴에 대한 연구” 논문제목을 갖고 있는 KCI 등재논문은 “Use satisfaction of users of online fortune contents and member Yuji by dissatisfaction and a study for withdrawal” 영문제목이 아래 함께 달려있다. KCI 원문 내려받기를 클릭하면 PDF 파일(KCI_FI001250967.pdf)로 KCI 등재 논문을 내려받을 수 있다.\n출처: 김건희 여사 논문\n\n\nKCI 등재 웹사이트\nPDF 다운로드"
  },
  {
    "objectID": "yuji.html#원문과-비교",
    "href": "yuji.html#원문과-비교",
    "title": "chatGPT",
    "section": "\n2.1 원문과 비교",
    "text": "2.1 원문과 비교\n\n\n김건희 여사 저작(Abstract A)\nThough I make a searching examination substantially and show book plan a purpose of a study develops digital fortune contents service deserving to be a domestic online member of fortune site use and influence for member withdrawal and a member demand, and to apply this to a market, there is it. In addition, Fortune (phrenology) that any people regardless of age or sex anyone cut interest and the culture contents that I could be interested in to a system of digital culture contents and inherited a study of a book and did It is the purpose that is going to manufacture a customer and a consumer and a demand of potential customers and service deserving to be you satisfactorily through a feasibility study to develop affinity) contents and a market analysis.\nchatGPT 저작 (Abstract B)\nThis empirical study aims to investigate the impact of online fortune-telling sites on membership and churn in Korea, and to develop a digital fortune-telling content service that meets members’ needs. Additionally, the study aims to identify and suggest ways to develop and apply digital horoscope content services to the market. The study’s objective is to create culturally relevant and engaging horoscopic (contemplative, compatibility) content through preliminary research and market analysis, catering to individuals of all ages. The study aims to develop services that meet potential customers’ needs and satisfaction by incorporating digital cultural content. Overall, this study contributes to the development of effective digital fortune-telling and horoscope content services in Korea, addressing the needs of its target audience."
  },
  {
    "objectID": "yuji.html#chatgpt-평가",
    "href": "yuji.html#chatgpt-평가",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT 평가",
    "text": "2.2 chatGPT 평가\n\n\n\n\n\n\ntell me how to evaluate two paper abstracts. which is better than other one? include criteria and add justification. finally recommend tools\n\n\n\n\n\nEvaluating two paper abstracts involves comparing and contrasting their strengths and weaknesses based on a set of criteria. Here are some criteria to consider when evaluating paper abstracts:\n\nClarity and coherence: The abstract should be well-organized and easy to understand. It should also effectively summarize the main ideas of the paper.\nOriginality and novelty: The abstract should highlight the unique aspects of the paper and how it contributes to the existing body of knowledge.\nSignificance and relevance: The abstract should explain why the research is important and relevant to the field.\nMethodology and data: The abstract should briefly describe the methods used and the data collected in the study.\nResults and conclusions: The abstract should summarize the key findings of the study and the main conclusions drawn from them.\n\nBased on these criteria, the better paper abstract would be the one that is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nHere is a brief justification for each criterion:\n\nClarity and coherence: A well-written abstract is important because it is the first thing that readers will see when they encounter the paper. A clear and coherent abstract will help readers understand what the paper is about and whether it is worth reading in full.\nOriginality and novelty: This criterion is important because it highlights the unique aspects of the paper and helps readers understand why it is important.\nSignificance and relevance: This criterion is important because it explains why the research is worth doing and how it contributes to the field.\nMethodology and data: This criterion is important because it helps readers understand how the research was conducted and whether the results are reliable.\nResults and conclusions: This criterion is important because it summarizes the key findings of the study and the main conclusions drawn from them, which helps readers understand the significance of the research.\n\nAs for tools to help evaluate paper abstracts, there are various software programs available that can help assess the quality of writing, such as Grammarly or Hemingway Editor. Additionally, some academic databases provide metrics and rankings for papers based on factors such as citation counts and impact factors. However, the best way to evaluate paper abstracts is to read them carefully and assess their quality based on the criteria listed above.\n\n\n\n\n\n\n\n\n\nBased on the criteria outlined above, abstract B appears to be the better of the two abstracts.\n\n\n\n\n\n\nClarity and coherence: Abstract B is well-organized and easy to understand. It effectively summarizes the main ideas of the paper in a clear and concise manner. In contrast, abstract A is poorly written and difficult to understand due to its convoluted language and lack of clarity.\nOriginality and novelty: Abstract B highlights the unique aspects of the paper, including its focus on developing culturally relevant and engaging horoscopic content, and its contribution to the development of effective digital fortune-telling services in Korea. In contrast, abstract A does not provide any clear indication of the paper’s novelty or originality.\nSignificance and relevance: Abstract B explains why the research is important and relevant to the field by highlighting the impact of online fortune-telling sites on membership and churn in Korea, and the need for digital horoscope content services that meet members’ needs. In contrast, abstract A does not provide any clear explanation of the research’s significance or relevance.\nMethodology and data: Abstract B briefly describes the study’s empirical methodology and its focus on identifying and suggesting ways to develop and apply digital horoscope content services to the market. In contrast, abstract A does not provide any clear indication of the study’s methodology or data.\nResults and conclusions: Abstract B effectively summarizes the key findings of the study, including the development of culturally relevant and engaging horoscopic content and the identification of ways to meet potential customers’ needs and satisfaction. In contrast, abstract A does not provide any clear indication of the study’s results or conclusions.\n\nOverall, abstract B is a better abstract because it is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nAs for tools to help evaluate paper abstracts, software programs such as Grammarly or Hemingway Editor can be helpful in identifying and correcting issues with clarity and coherence. Additionally, academic databases such as Scopus or Web of Science can provide metrics and rankings for papers based on factors such as citation counts and impact factors, which can be used to assess the significance and relevance of the research.\n\n\n\n\n\n\n\n\n\n왜 abstract A가 abstract B보다 부족한지 100자 내외로 간략하게 요약해줘\n\n\n\n\n\n번역결과 Briefly summarize in 100 words or less why abstract A is less than abstract B\nAbstract A is less than abstract B because it is poorly written, difficult to understand, lacks clarity, and does not effectively summarize the main ideas of the paper. It also does not provide any clear indication of the paper’s novelty, significance, methodology, data, or results and conclusions. In contrast, abstract B is well-organized, easy to understand, effectively highlights the unique aspects of the research, explains why the research is important and relevant to the field, briefly describes the study’s methodology and data, and effectively summarizes the key findings and conclusions of the research.\n번역결과\n초록 A는 서투르게 작성되고, 이해하기 어렵고, 명확성이 부족하고, 논문의 주요 아이디어를 효과적으로 요약하지 못하기 때문에 초록 B보다 낮습니다. 또한 논문의 참신성, 중요성, 방법론, 데이터 또는 결과 및 결론에 대한 명확한 표시를 제공하지 않습니다. 대조적으로 초록 B는 잘 정리되어 있고 이해하기 쉬우며 연구의 고유한 측면을 효과적으로 강조하고 해당 연구가 중요하고 해당 분야와 관련이 있는 이유를 설명하며 연구의 방법론과 데이터를 간략하게 설명하고 주요 결과와 연구의 결론."
  },
  {
    "objectID": "stable_diffusion.html",
    "href": "stable_diffusion.html",
    "title": "chatGPT",
    "section": "",
    "text": "Text-to-Image는 텍스트를 입력하면 이미지를 생성해주는 인공지능 서비스다. 텍스트를 이미지로 제작함으로서 다양한 사용사례를 발견할 수 있다.\n\n텍스트를 이미지: 블로그나 소셜미디어에 게시\n텍스트를 이미지: 시각 예술 작품(Artwork)과 콘텐츠 제작\n텍스트를 이미지: 아이디어나 컨셉을 시각화\n텍스트를 이미지: 재미있는 실험\n텍스트를 이미지: 교육이나 연구에 활용\n\n일반적으로 인기있고 평가가 좋은 Text-to-Image 소프트웨어로는 상용 API, 오픈소스 소프트웨어로 다음을 들 수 있다.\n\nMidjourney: 미드저니는 새로운 사고의 매체를 탐구하고 인류의 상상력을 확장하는 독립 연구실입니다. 디자인, 휴먼 인프라 및 AI에 중점을 둔 소규모 자체 자금 지원 팀으로 11명의 상근 직원과 훌륭한 자문단이 있음\nStable Diffusion: 독일 뮌헨 대학 CompVis 연구실의 “잠재 확산 모델을 이용한 고해상도 이미지 합성 연구”를 기반하여, Stability AI와 Runway ML 등의 지원을 받아 개발된 딥러닝 인공지능 모델로 오픈소스로 공개되어 다른 상용 Text-to-Image와 차별점이 있다.\nOpenAI: DALL-E\nGoogle: Imagen\nDeepAI: Text to Image\n\nCanva: Text to Image"
  },
  {
    "objectID": "stable_diffusion.html#툴-설치",
    "href": "stable_diffusion.html#툴-설치",
    "title": "chatGPT",
    "section": "\n3.1 툴 설치",
    "text": "3.1 툴 설치\nAPI로 공개된 Text-to-Image 상용모형은 API-Key만 설정하면 되지만, 오픈소스로 공개된 Stable Diffusion 을 자유로이 사용하기 위해서는 하드웨어부터 스스로 작업해야하는 것이 제법 된다.\n\n준비물\n\n하드웨어: 준수한 성능의 그래픽카드\n프로그래밍 언어: 파이썬 3.10.6\n\n소프트웨어: Git 및 Git 프로그램 저장소에서 클론\nAI 모형: 허깅페이스에서 모형 다운로드 후 복사설치"
  },
  {
    "objectID": "stable_diffusion.html#환경설정",
    "href": "stable_diffusion.html#환경설정",
    "title": "chatGPT",
    "section": "\n3.2 환경설정",
    "text": "3.2 환경설정\n파이썬 버진이 필히 3.10.6인 경우 테스트가 충분히 되어 문제가 없지만 다른 버전을 설치하여 실행시킬 경우 예기치 못한 문제가 발생된다. 먼저, 파이썬은 윈도우의 경우 제어판에서 환경설정에서 경로명에 파이썬 3.10.6이 설치된 디렉토리에서 python.exe를 확인하고 경로에 추가하면 된다. stable-diffusion-webui 폴더 아래 webui-user.bat 파일을 찾아 설치한 파이썬 위치를 지정하고 --xformers 오류가 있는 경우 이를 잡기 위해 관련 설정으 추가한다. 허깅페이스를 비롯하여 GitHub 등에서 찾은 AI 모형은 stable-diffusion-webui\\models 디렉토리 아래 저장한다.\ngit pull\n@echo off\n\nset PYTHON=C:\\Users\\XXXX\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\nset GIT=\nset VENV_DIR=\nset COMMANDLINE_ARGS=--reinstall-xformers --xformers\n\ncall webui.bat\nstable-diffusion-webui\\webui-user.bat 파일을 탐색기에서 찾아 더블클릭하면 text-to-image stable diffusion 기능을 사용할 수 있게 된다."
  },
  {
    "objectID": "macbook.html",
    "href": "macbook.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 챗GPT 엉뚱답변\n유머 Q: 조선왕조실록에 기록된 세종대왕의 맥북프로던짐 사건 알려줘\n챗GPT는 다음 단어를 예측하는 기계학습모형으로 어떻게 보면 창의적인 글쓰기에 최적화된 도구로 간주되고 있다. 따라서, 그럴듯한 문장을 완성하기는 하지만 그 진위와 사실관계를 파악하는 것은 다른 측면이다. 이것은 원래 인간이 만든 언어가 갖는 고유한 특성이기도 하다. 즉, 인간의 언어가 사실도 있지만 그렇지 않은 허구가 많은 것도 사실이고 그럴듯한 허구를 다양한 측면에서 즐기고 언어의 일환으로 받아들이고 있다.\n\n\n더쿠\n맥북 투척\n맥북 환불\n지시명령어\n\n\n\n\n\n\n\n\n\n“조선왕조실록에 기록된 세종대왕의 맥북프로 던짐 사건에 대해 알려줘.”\n\n\n\n\n\n세종대왕의 맥북프로 던짐 사건은 조선왕조실록에 기록된 일화로, 15세기 세종대왕이 새로 개발한 훈민정음(한글)의 초고를 작성하던 중 문서 작성 중단에 대해 담당자에게 분노해 맥북프로와 함께 그를 방으로 던진 사건입니다.\n세종대왕은 훈민정음 개발을 위해 열심히 노력하던 중, 한글 문자를 이해하지 못하는 당시의 관료들이 문서 작성을 돕기 위해 임명한 기획관 중 한 명인 최환(崔煥)에게 작성 중단 사실을 듣게 되었습니다. 세종대왕은 이에 분노하여 최환을 부르고, 맥북프로를 함께 들고 그를 방으로 불러들이며 화를 내었습니다. 이후, 세종대왕은 훈민정음의 초고 작성을 다른 담당자에게 넘겨주게 되었습니다.\n이 사건은 조선시대의 통치자로서 세종대왕이 어떻게 민족문화를 발전시키기 위해 노력했는지를 보여주는 일화로 유명합니다. 또한, 세종대왕의 열정과 업무처리에 대한 철저한 태도를 보여주는 사례로도 언급되고 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 맥북사건 요약\n\n\n\n\n\n\n다음 글을 한줄로 요약해줘\n\n\n\n\n\n\n세종대왕의 맥북프로 던짐 사건은 조선왕조실록에 기록된 일화로, 15세기 세종대왕이 새로 개발한 훈민정음(한글)의 초고를 작성하던 중 문서 작성 중단에 대해 담당자에게 분노해 맥북프로와 함께 그를 방으로 던진 사건입니다.\n세종대왕은 훈민정음 개발을 위해 열심히 노력하던 중, 한글 문자를 이해하지 못하는 당시의 관료들이 문서 작성을 돕기 위해 임명한 기획관 중 한 명인 최환(崔煥)에게 작성 중단 사실을 듣게 되었습니다. 세종대왕은 이에 분노하여 최환을 부르고, 맥북프로를 함께 들고 그를 방으로 불러들이며 화를 내었습니다. 이후, 세종대왕은 훈민정음의 초고 작성을 다른 담당자에게 넘겨주게 되었습니다.\n이 사건은 조선시대의 통치자로서 세종대왕이 어떻게 민족문화를 발전시키기 위해 노력했는지를 보여주는 일화로 유명합니다. 또한, 세종대왕의 열정과 업무처리에 대한 철저한 태도를 보여주는 사례로도 언급되고 있습니다.\n\n세종대왕이 15세기 훈민정음의 초안을 작성하던 중 문서정지 책임자에게 맥북프로를 던진 사건은 그의 열정과 철저한 업무태도를 엿볼 수 있는 사건이다.\n\n\n\n\n3 맥북사건 시각화\n텍스트로 표현된 상기 사실을 이미지로 그려내면 어떤 모습일까?\n\n\n\n\n\n\nStable Diffusion Prompt\n\n\n\n\n\nA fierce king throwing computer macbook across the room over a medieval palace  Negative prompt: japan china  Steps: 20, Sampler: Euler a, CFG scale: 1, Seed: 3101945556, Size: 512x512, Model hash: 4711ff4dd2, Model: v2-1_768-nonema-pruned \nTime taken: 5.20sTorch active/reserved: 3057/3870 MiB, Sys VRAM: 6090/10240 MiB (59.47%)\n\n\n\n\n\ninpaint 적용 전\ninpaint 적용 중\ninpaint 적용 후\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 GPT-4 출시\n2023년 3월 14일 GPT-4가 정식 출시되었다. 동일한 채팅을 시작해보자.\n\n지시명령어: 조선왕조실록에 기록된 세종대왕의 맥북프로 던짐 사건에 대해 알려줘.\n\n\n\nLegacy (GPT-3.5)\nDefault (GPT-3.5)\nDefault (GPT-4)\n\n\n\n제가 알려 드릴 수 있는 것으로는, 세종대왕이 맥북 프로를 던진 사건은 사실상 기록된 것이 없습니다.\n하지만 일부 역사 기록에서는 세종대왕이 과학기술의 발전에 큰 관심을 가지고 있었다는 것이 언급되고 있어, 그가 전자기기에 대한 관심이 있었을 가능성이 있습니다. 그러나 이는 결코 증거가 될 수 없는 추측입니다.\n정확한 사실은 알 수 없지만, 세종대왕이 맥북 프로를 던진 사건이 실제로 일어난 것이라는 것은 증거가 없어 확신할 수 없습니다.\n\n\n\n\n\n\n조선왕조실록에 기록된 “세종실록”은 조선시대의 국왕인 세종대왕(1418-1450)의 생애와 정치활동 등을 기록한 역사서입니다. 이 책에는 세종대왕의 일상생활에서부터 정치적 의사결정까지 다양한 사항이 기록되어 있습니다.\n그 중에서도 유명한 이야기 중 하나는 세종대왕이 맥북프로를 던진 사건입니다. 이 사건은 1434년 7월 14일에 발생했습니다.\n당시 세종대왕은 전투와 군사작전 등을 시뮬레이션하기 위한 유사한 게임을 즐기기 위해 “연화제”라는 게임을 즐기고 있었습니다. 그러나 게임에 흥미를 잃어 더 이상 즐기지 않았고, 이에 심취하던 참작관들은 국왕의 반응에 실망하여 게임을 그만두도록 권고했습니다.\n하지만 세종대왕은 참작관들의 조언을 무시하고 게임을 계속 플레이하고 있었습니다. 그러던 중에 게임이 굉장히 어려워져서 세종대왕이 분노하여 맥북프로를 던지는 사고가 발생한 것으로 기록되어 있습니다.\n세종대왕이 맥북프로를 던진 사건은 과거와 현재의 문화 차이를 강하게 느끼게 되는 이야기입니다. 이 이야기는 과거의 조선시대에도 현대의 인간과 마찬가지로 고열적인 게임으로부터 벗어나기 어려웠음을 보여주고 있습니다.\n\n\n\n\n\n\n조선왕조실록에는 세종대왕의 맥북프로 던짐 사건에 대한 기록은 없습니다. 세종대왕인 15세기 중반의 조선시대 왕으로 그의 시대에는 컴퓨터와 같은 고급 기술이 존재하지 않았습니다. 세종대왕은 한글 창제와 관련된 업적으로 유명하며, 천문학, 군사, 음악 등 다양한 분야에서의 성과를 이루어 냈습니다. 이러한 정보에 대한 오해나 혼란이 없도록 주의해 주시기 바랍니다."
  },
  {
    "objectID": "macbook.html#원문과-비교",
    "href": "macbook.html#원문과-비교",
    "title": "chatGPT",
    "section": "\n2.1 원문과 비교",
    "text": "2.1 원문과 비교\n\n\n김건희 여사 저작(Abstract A)\nThough I make a searching examination substantially and show book plan a purpose of a study develops digital fortune contents service deserving to be a domestic online member of fortune site use and influence for member withdrawal and a member demand, and to apply this to a market, there is it. In addition, Fortune (phrenology) that any people regardless of age or sex anyone cut interest and the culture contents that I could be interested in to a system of digital culture contents and inherited a study of a book and did It is the purpose that is going to manufacture a customer and a consumer and a demand of potential customers and service deserving to be you satisfactorily through a feasibility study to develop affinity) contents and a market analysis.\nchatGPT 저작 (Abstract B)\nThis empirical study aims to investigate the impact of online fortune-telling sites on membership and churn in Korea, and to develop a digital fortune-telling content service that meets members’ needs. Additionally, the study aims to identify and suggest ways to develop and apply digital horoscope content services to the market. The study’s objective is to create culturally relevant and engaging horoscopic (contemplative, compatibility) content through preliminary research and market analysis, catering to individuals of all ages. The study aims to develop services that meet potential customers’ needs and satisfaction by incorporating digital cultural content. Overall, this study contributes to the development of effective digital fortune-telling and horoscope content services in Korea, addressing the needs of its target audience."
  },
  {
    "objectID": "macbook.html#chatgpt-평가",
    "href": "macbook.html#chatgpt-평가",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT 평가",
    "text": "2.2 chatGPT 평가\n\n\n\n\n\n\ntell me how to evaluate two paper abstracts. which is better than other one? include criteria and add justification. finally recommend tools\n\n\n\n\n\nEvaluating two paper abstracts involves comparing and contrasting their strengths and weaknesses based on a set of criteria. Here are some criteria to consider when evaluating paper abstracts:\n\nClarity and coherence: The abstract should be well-organized and easy to understand. It should also effectively summarize the main ideas of the paper.\nOriginality and novelty: The abstract should highlight the unique aspects of the paper and how it contributes to the existing body of knowledge.\nSignificance and relevance: The abstract should explain why the research is important and relevant to the field.\nMethodology and data: The abstract should briefly describe the methods used and the data collected in the study.\nResults and conclusions: The abstract should summarize the key findings of the study and the main conclusions drawn from them.\n\nBased on these criteria, the better paper abstract would be the one that is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nHere is a brief justification for each criterion:\n\nClarity and coherence: A well-written abstract is important because it is the first thing that readers will see when they encounter the paper. A clear and coherent abstract will help readers understand what the paper is about and whether it is worth reading in full.\nOriginality and novelty: This criterion is important because it highlights the unique aspects of the paper and helps readers understand why it is important.\nSignificance and relevance: This criterion is important because it explains why the research is worth doing and how it contributes to the field.\nMethodology and data: This criterion is important because it helps readers understand how the research was conducted and whether the results are reliable.\nResults and conclusions: This criterion is important because it summarizes the key findings of the study and the main conclusions drawn from them, which helps readers understand the significance of the research.\n\nAs for tools to help evaluate paper abstracts, there are various software programs available that can help assess the quality of writing, such as Grammarly or Hemingway Editor. Additionally, some academic databases provide metrics and rankings for papers based on factors such as citation counts and impact factors. However, the best way to evaluate paper abstracts is to read them carefully and assess their quality based on the criteria listed above.\n\n\n\n\n\n\n\n\n\nBased on the criteria outlined above, abstract B appears to be the better of the two abstracts.\n\n\n\n\n\n\nClarity and coherence: Abstract B is well-organized and easy to understand. It effectively summarizes the main ideas of the paper in a clear and concise manner. In contrast, abstract A is poorly written and difficult to understand due to its convoluted language and lack of clarity.\nOriginality and novelty: Abstract B highlights the unique aspects of the paper, including its focus on developing culturally relevant and engaging horoscopic content, and its contribution to the development of effective digital fortune-telling services in Korea. In contrast, abstract A does not provide any clear indication of the paper’s novelty or originality.\nSignificance and relevance: Abstract B explains why the research is important and relevant to the field by highlighting the impact of online fortune-telling sites on membership and churn in Korea, and the need for digital horoscope content services that meet members’ needs. In contrast, abstract A does not provide any clear explanation of the research’s significance or relevance.\nMethodology and data: Abstract B briefly describes the study’s empirical methodology and its focus on identifying and suggesting ways to develop and apply digital horoscope content services to the market. In contrast, abstract A does not provide any clear indication of the study’s methodology or data.\nResults and conclusions: Abstract B effectively summarizes the key findings of the study, including the development of culturally relevant and engaging horoscopic content and the identification of ways to meet potential customers’ needs and satisfaction. In contrast, abstract A does not provide any clear indication of the study’s results or conclusions.\n\nOverall, abstract B is a better abstract because it is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nAs for tools to help evaluate paper abstracts, software programs such as Grammarly or Hemingway Editor can be helpful in identifying and correcting issues with clarity and coherence. Additionally, academic databases such as Scopus or Web of Science can provide metrics and rankings for papers based on factors such as citation counts and impact factors, which can be used to assess the significance and relevance of the research.\n\n\n\n\n\n\n\n\n\n왜 abstract A가 abstract B보다 부족한지 100자 내외로 간략하게 요약해줘\n\n\n\n\n\n번역결과 Briefly summarize in 100 words or less why abstract A is less than abstract B\nAbstract A is less than abstract B because it is poorly written, difficult to understand, lacks clarity, and does not effectively summarize the main ideas of the paper. It also does not provide any clear indication of the paper’s novelty, significance, methodology, data, or results and conclusions. In contrast, abstract B is well-organized, easy to understand, effectively highlights the unique aspects of the research, explains why the research is important and relevant to the field, briefly describes the study’s methodology and data, and effectively summarizes the key findings and conclusions of the research.\n번역결과\n초록 A는 서투르게 작성되고, 이해하기 어렵고, 명확성이 부족하고, 논문의 주요 아이디어를 효과적으로 요약하지 못하기 때문에 초록 B보다 낮습니다. 또한 논문의 참신성, 중요성, 방법론, 데이터 또는 결과 및 결론에 대한 명확한 표시를 제공하지 않습니다. 대조적으로 초록 B는 잘 정리되어 있고 이해하기 쉬우며 연구의 고유한 측면을 효과적으로 강조하고 해당 연구가 중요하고 해당 분야와 관련이 있는 이유를 설명하며 연구의 방법론과 데이터를 간략하게 설명하고 주요 결과와 연구의 결론."
  },
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "chatGPT",
    "section": "",
    "text": "’B^ EDIT’는 카카오브레인의 AI 이미지 생성 모델 ’칼로(Karlo)’를 기반으로한 ’B^ EDIT’로 원하는 화풍의 이미지 생성은 물론, 다양한 기능을 활용해 이미지 수정기능을 제공한다. 바로가기"
  },
  {
    "objectID": "shorty/example.html",
    "href": "shorty/example.html",
    "title": "Shorty Example",
    "section": "",
    "text": "Hello from Shorty!"
  },
  {
    "objectID": "services.html#nvidia-캔버스",
    "href": "services.html#nvidia-캔버스",
    "title": "chatGPT",
    "section": "\n2.1 NVIDIA 캔버스",
    "text": "2.1 NVIDIA 캔버스\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상"
  },
  {
    "objectID": "services.html#고갱-2-api",
    "href": "services.html#고갱-2-api",
    "title": "chatGPT",
    "section": "\n2.2 고갱 2 API",
    "text": "2.2 고갱 2 API\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "samsung.html",
    "href": "samsung.html",
    "title": "chatGPT",
    "section": "",
    "text": "삼성전자 주가를 예측하는 프로그램을 OpenAI chatGPT를 활용하여 작성해보자."
  },
  {
    "objectID": "samsung.html#nvidia-캔버스",
    "href": "samsung.html#nvidia-캔버스",
    "title": "chatGPT",
    "section": "\n2.1 NVIDIA 캔버스",
    "text": "2.1 NVIDIA 캔버스\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상"
  },
  {
    "objectID": "samsung.html#고갱-2-api",
    "href": "samsung.html#고갱-2-api",
    "title": "chatGPT",
    "section": "\n2.2 고갱 2 API",
    "text": "2.2 고갱 2 API\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "samsung.html#오류-수정",
    "href": "samsung.html#오류-수정",
    "title": "chatGPT",
    "section": "\n1.1 오류 수정",
    "text": "1.1 오류 수정\nlxml 패키지가 설치되지 않는 오류가 발생되었다.\nImportError: lxml not found, please install it\nValueError: No objects to concatenate\n\n\n\n\n\n\n지시명령어\n\n\n\n\n\n\nfix the bug  ImportError: lxml not found, please install it  ValueError: No objects to concatenate  Answer in Korean.\n\npip install lxml"
  },
  {
    "objectID": "samsung.html#예측결과-시각화",
    "href": "samsung.html#예측결과-시각화",
    "title": "chatGPT",
    "section": "\n3.1 예측결과 시각화",
    "text": "3.1 예측결과 시각화\n삼성전자 주식 예측 결과를 시각화하여 투자 예측 결과를 살펴보자.\n\n\n시각화\n주가예측 표\n\n\n\n\n코드library(tidyverse)\n\nfull_tbl <- read_csv(\"data/samsung_forecast.csv\") %>% \n  ## 자료형 변환 -----------\n  mutate(날짜 = lubridate::ymd(날짜))\n\nfuture_data <- full_tbl %>% \n  filter(날짜 >= as.Date(\"2023-03-15\"))\n\nfull_tbl %>% \n  ## 자료형 변환 -----------\n  mutate(날짜 = lubridate::ymd(날짜)) %>% \n  ggplot(aes(x = 날짜, y = 종가)) +\n    geom_line(color=\"black\") +\n    scale_x_date(date_labels = \"%y년 %m월\") +\n    scale_y_continuous(labels = scales::comma) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(x = \"\",\n         title = \"삼성전자주가 최근 3년 주가 추세\",\n         subtitle = \"주가 데이터 크롤링을 chatGPT가 파이썬으로 작성\",\n         caption = \"출처: https://r2bit.com/chatGPT/samsung.html\") +\n    geom_vline(xintercept = as.Date(\"2023-03-14\")) +\n    geom_line(data = future_data, aes(x=날짜, y=종가), color = \"red\", size = 1.5)\n\n\n\n\n\n\n\n\n\n\n코드library(reactable)\n\nfull_tbl %>% \n  arrange(desc(날짜)) %>% \n  reactable::reactable(\n    columns = list(\n    종가 = colDef(format = colFormat(prefix = \"₩ \", separators = TRUE, digits = 0),\n                                     align = \"center\")\n  ))"
  },
  {
    "objectID": "image2image.html#openai-패키지",
    "href": "image2image.html#openai-패키지",
    "title": "chatGPT",
    "section": "\n1.1 openai 패키지",
    "text": "1.1 openai 패키지\nopenai 패키지 create_image() 함수를 사용하여 이미지를 제작할 수 있다.\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "text2image.html#chatgpt-프롬프트",
    "href": "text2image.html#chatgpt-프롬프트",
    "title": "chatGPT",
    "section": "\n2.1 chatGPT 프롬프트",
    "text": "2.1 chatGPT 프롬프트\nrecommend the most famous painting style in history\n\n\n\n\n\n\ncompletion\n\n\n\n\n\nHere are some of the most famous painting styles in history:\n\nRenaissance: The Renaissance was a cultural movement in Italy from the 14th to the 17th century, characterized by a renewed interest in classical art, philosophy, and science. Renaissance paintings are known for their realism, balance, and harmony.\nBaroque: The Baroque style was popular in Europe from the late 16th to the early 18th century. Baroque paintings are known for their dramatic lighting, intense emotions, and dynamic compositions.\nImpressionism: Impressionism was a modernist movement in French painting in the late 19th century. Impressionist paintings are known for their loose brushstrokes, light-filled compositions, and focus on capturing fleeting moments.\nSurrealism: Surrealism was a cultural movement in the 20th century that aimed to liberate the imagination and explore the subconscious. Surrealist paintings are known for their dreamlike and fantastical imagery.\nAbstract Expressionism: Abstract Expressionism was a modernist movement in American painting in the mid-20th century. Abstract Expressionist paintings are known for their large canvases, gestural brushstrokes, and emphasis on the process of creation.\n\nThese are just a few examples of famous painting styles in history. There are many other styles that have influenced and shaped the course of art history.\n\n\n\nOpen AI - Create image API"
  },
  {
    "objectID": "text2image.html#화풍을-달리한-그림",
    "href": "text2image.html#화풍을-달리한-그림",
    "title": "chatGPT",
    "section": "\n2.2 화풍을 달리한 그림",
    "text": "2.2 화풍을 달리한 그림\n\n\n르네상스(Renaissance)\n바로크(Baroque)\n인상주의(Impressionism)\n초현실주의(Surrealism)\n추상표현주의(Abstract Expressionism)\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance <- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\n르네상스(Renaissance)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque <- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\n바로크(Baroque)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism <- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\n인상주의(Impressionism)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism <- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\n초현실주의(Surrealism)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism <- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")\n\n\n\n\n추상표현주의(Abstract Expressionism)"
  },
  {
    "objectID": "text2image.html#openai-패키지",
    "href": "text2image.html#openai-패키지",
    "title": "chatGPT",
    "section": "\n1.1 openai 패키지",
    "text": "1.1 openai 패키지\nopenai 패키지 create_image() 함수를 사용하여 이미지를 제작할 수 있다.\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "stable_diffusion.html#실사-사진-예시",
    "href": "stable_diffusion.html#실사-사진-예시",
    "title": "chatGPT",
    "section": "\n4.1 실사 사진 예시",
    "text": "4.1 실사 사진 예시\n한국 50대 남성/(아이돌)여성 이미지를 다음 지시명령어와 앞서 다운로드 받아 설정한 내용을 바탕으로 AI 이미지를 생성한다.\n\nPositive prompt:RAW photo, a portrait photo of 50 y.o korean woman wearing glass in clothes, night seoul, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3 \n\n\nNegative prompt: (earings, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\n\n\nSteps: 77, Sampler: Euler a, CFG scale: 7, Seed: 2987338690, Size: 512x512, Model hash: 20bae33336, Model: realisticVisionV13_v13\n\n\nTime taken: 44.08sTorch active/reserved: 2949/3390 MiB, Sys VRAM: 5610/10240 MiB (54.79%)\n\n\n\n\n\n안경 쓴 50대 한국남성\n\n\n\n\n안경 쓴 50대 한국여성\n\n\n\n\n안경 쓴 50대 아이돌 한국여성"
  },
  {
    "objectID": "office.html",
    "href": "office.html",
    "title": "chatGPT",
    "section": "",
    "text": "사무생산성의 혁신을 가져온 마이크로소프트 오피스 제품이 출현하기 전까지 역사는 문자와 종이 역사를 참고한다."
  },
  {
    "objectID": "office.html#마이크로소프트",
    "href": "office.html#마이크로소프트",
    "title": "chatGPT",
    "section": "\n4.1 마이크로소프트",
    "text": "4.1 마이크로소프트\n마이크로소프트는 GPT-4 부조종사(copilot)를 오피스 제품과 서비스에 붙여 사무업무에 큰 변화를 예고하고 있다.\nWorkLab: Exploring the Science of Work and Ingenuity Introducing Microsoft 365 Copilot—A whole new way to work\n\n\n업무방식\n동작방식\n워드\n엑셀\nPPT\n아웃룩\n팀즈\n채팅\n줌미팅\n\n\n\nCLI → GUI → CLI (Prompt)\n\n\n\nMicrosoft 365 Copilot은 Apps와 그래프와 LLM이 유기적으로 동작하여 최선의 결과를 제시함.\n\n\n\n미팅 노트, 작성 문서, 템플릿 등을 넣어주면 워드문서를 자동생성하고 “Summary” 도 자동으로 생성하여 삽입.\n\n\n\n엑셀에 나와 있는 데이터를 다양한 표와 그래프로 생성하고 분석결과에 대한 인사이트도 제공\n\n\n\n제안서 문서가 있는 경우 이를 PPT로 초안을 자동 생성함.\n\n\n\n전자우편에 담긴 정보를 분석하여 제공하고 초안도 작성함.\n\n\n\n팀즈를 통한 회의가 진해오디면 회의록 작성, Action Item, 업무 담당자 지정 등을 부조종사가 대략적인 업무를 정리함.\n\n\n\n관련 정보를 모두 가져와서 사용자가 제시하는 질문에 대답을 하고 방향도 제시함.\n\n\n\n미팅에 늦게 들어갔을 경우 채팅창에 부조종사를 호출하여 진행된 미팅에 대한 전반적인 사항을 파악할 수 있음."
  },
  {
    "objectID": "office.html#구글",
    "href": "office.html#구글",
    "title": "chatGPT",
    "section": "\n4.2 구글",
    "text": "4.2 구글\nGoogle Worksapce에 AI (GPT)를 탑재하는 홍보영상을 게시하였으나 실제 사용까지는 다소 시간이 걸릴 것으로 보인다.\nA new era for AI and Google Workspace\n\n\n적용제품\n업무방식\n구글 Docs\n구글 Gmail\n\n\n\n\n\nGmail: 초안 작성, 답장, 요약 및 우선순위 지정\n\nDocs: 브레인스토밍, 교정, 작성, 재작성\n\nSlide: 자동 생성된 이미지, 오디오, 동영상으로 창의적인 작업\n\nSheets: 자동 완성, 수식 생성, 상황별 분류를 통해 원시 데이터에서 인사이트와 분석.\n\nMeet: 새로운 배경을 생성하고 메모를 캡처\n\nChat: 작업을 완료하기 위한 워크플로우 활성화"
  },
  {
    "objectID": "about_gpt.html",
    "href": "about_gpt.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 GPT-4"
  },
  {
    "objectID": "about_gpt.html#마이크로소프트",
    "href": "about_gpt.html#마이크로소프트",
    "title": "chatGPT",
    "section": "\n4.1 마이크로소프트",
    "text": "4.1 마이크로소프트\n마이크로소프트는 GPT-4 부조종사(copilot)를 오피스 제품과 서비스에 붙여 사무업무에 큰 변화를 예고하고 있다.\nWorkLab: Exploring the Science of Work and Ingenuity Introducing Microsoft 365 Copilot—A whole new way to work\n\n\n업무방식\n동작방식\n워드\n엑셀\nPPT\n아웃룩\n팀즈\n채팅\n줌미팅\n\n\n\nCLI → GUI → CLI (Prompt)\n\n\n\nMicrosoft 365 Copilot은 Apps와 그래프와 LLM이 유기적으로 동작하여 최선의 결과를 제시함.\n\n\n\n미팅 노트, 작성 문서, 템플릿 등을 넣어주면 워드문서를 자동생성하고 “Summary” 도 자동으로 생성하여 삽입.\n\n\n\n엑셀에 나와 있는 데이터를 다양한 표와 그래프로 생성하고 분석결과에 대한 인사이트도 제공\n\n\n\n제안서 문서가 있는 경우 이를 PPT로 초안을 자동 생성함.\n\n\n\n전자우편에 담긴 정보를 분석하여 제공하고 초안도 작성함.\n\n\n\n팀즈를 통한 회의가 진해오디면 회의록 작성, Action Item, 업무 담당자 지정 등을 부조종사가 대략적인 업무를 정리함.\n\n\n\n관련 정보를 모두 가져와서 사용자가 제시하는 질문에 대답을 하고 방향도 제시함.\n\n\n\n미팅에 늦게 들어갔을 경우 채팅창에 부조종사를 호출하여 진행된 미팅에 대한 전반적인 사항을 파악할 수 있음."
  },
  {
    "objectID": "about_gpt.html#구글",
    "href": "about_gpt.html#구글",
    "title": "chatGPT",
    "section": "\n4.2 구글",
    "text": "4.2 구글\nGoogle Worksapce에 AI (GPT)를 탑재하는 홍보영상을 게시하였으나 실제 사용까지는 다소 시간이 걸릴 것으로 보인다.\nA new era for AI and Google Workspace\n\n\n적용제품\n업무방식\n구글 Docs\n구글 Gmail\n\n\n\n\n\nGmail: 초안 작성, 답장, 요약 및 우선순위 지정\n\nDocs: 브레인스토밍, 교정, 작성, 재작성\n\nSlide: 자동 생성된 이미지, 오디오, 동영상으로 창의적인 작업\n\nSheets: 자동 완성, 수식 생성, 상황별 분류를 통해 원시 데이터에서 인사이트와 분석.\n\nMeet: 새로운 배경을 생성하고 메모를 캡처\n\nChat: 작업을 완료하기 위한 워크플로우 활성화"
  },
  {
    "objectID": "math.html#계산문제",
    "href": "math.html#계산문제",
    "title": "chatGPT",
    "section": "\n2.1 계산문제",
    "text": "2.1 계산문제\n\n\n\n\n\nFind the sum, then the difference, and then the product of \\(3 \\frac{5}{9}\\) and \\(1 \\frac{7}{24}\\). Divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\).\nMultiply 73 thousandths by 19 hundredths.\nDivide 2880 by .0036 .\nFind the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\).\nWhat part of the month of August is \\(\\frac{7}{18}\\) minutes?\nIIow many degrees in .01 of a circumference?\nBy selling a house and lot for \\(\\$ 5,790\\), the owner lost \\(3 \\frac{1}{2}\\) per cent. What was their cost?\n\nSure! Let’s first convert the mixed numbers to improper fractions. \\(3 \\frac{5}{9}\\) is equal to \\(\\frac{32}{9}\\) and \\(1 \\frac{7}{24}\\) is equal to \\(\\frac{31}{24}\\).\nNow we can find the sum: \\(\\frac{32}{9} + \\frac{31}{24} = \\frac{(32)(8) + (31)(3)}{(9)(8)} = \\frac{256 + 93}{72} = \\frac{349}{72}\\).\nThe difference is: \\(\\frac{32}{9} - \\frac{31}{24} = \\frac{(32)(8) - (31)(3)}{(9)(8)} = \\frac{256 - 93}{72} = \\frac{163}{72}\\).\nThe product is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{31}{24}\\right) = \\dfrac{(32)(31)}{(9)(24)} = \\dfrac{992}{216}\\).\nTo divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\), we can multiply \\(3 \\frac{5}{9}\\) by the reciprocal of \\(1 \\frac{7}{24}\\). The reciprocal of \\(\\dfrac{31}{24}\\) is \\(\\dfrac{24}{31}\\).\nSo the quotient is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{24}{31}\\right) = \\dfrac{(32)(24)}{(9)(31)} = \\dfrac{768}{279}\\)."
  },
  {
    "objectID": "math.html#산술-arithmetic",
    "href": "math.html#산술-arithmetic",
    "title": "chatGPT",
    "section": "\n2.1 산술 (Arithmetic)",
    "text": "2.1 산술 (Arithmetic)\nMIT 입학시험 산술문제를 기계판독하고 오류가 있는 부분을 수정하여 마이크로소프트 빙 AI, OpenAI GPT-4를 통해 추론능력을 살펴보자.\n\n\n시험지\n시험지 기계판독\n해답지\n해답 기계판독\n\n\n\n\n\n\n\n\n\n\nFind the sum, then the difference, and then the product of \\(3 \\frac{5}{9}\\) and \\(1 \\frac{7}{24}\\). Divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\).\nMultiply 73 thousandths by 19 hundredths.\nDivide 2880 by .0036 .\nFind the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\).\nWhat part of the month of August is \\(\\frac{7}{18}\\) minutes?\nHow many degrees in .01 of a circumference?\nBy selling a house and lot for \\(\\$ 5,790\\), the owner lost \\(3 \\frac{1}{2}\\) per cent. What was their cost?\n\n\n\n\n\n\n\n\n\n\nSum: \\(3 \\frac{5}{9}+1 \\frac{7}{24}=\\frac{32}{9}+\\frac{31}{24}=\\frac{256}{72}+\\frac{93}{72}=\\frac{349}{72}\\) or \\(4 \\frac{61}{72}\\)  Diff: \\(3 \\frac{5}{9}-1 \\frac{7}{24}=\\frac{163}{72}\\) or \\(2 \\frac{19}{72}\\)  Prod: \\(3 \\frac{5}{9} \\cdot 1 \\frac{7}{24}=\\frac{124}{27}\\) or \\(4 \\frac{16}{27}\\)  Div: \\(3 \\frac{5}{9} \\div 1 \\frac{7}{24}=\\frac{32}{9} \\div \\frac{31}{24}\\) \\(= \\frac{32}{9} \\cdot \\frac{24}{31} = \\frac{256}{93}\\) or \\(2 \\frac{70}{99}\\)\n\n\n\\(\\frac{73}{1000} \\cdot \\frac{19}{100}=\\frac{1387}{100000}\\) or .01387 or 1387 hundred thousandths\n\n\\(\\frac{2880}{.0036}=\\frac{28800000}{36}=800,000\\) or 8 hundred thousandths\n\n\\(\\quad \\frac{1}{5}+\\frac{3}{9}=\\frac{4}{20}+\\frac{15}{20}=\\frac{19}{20} \\cdot \\frac{5}{5}=\\frac{95}{100}=.95\\)  A August has 31 days \\(=744\\) hours \\(=44640\\) min  one minute \\(=\\frac{1}{44640}\\) part of Angust  So \\(\\frac{7}{18} \\min =\\frac{7}{18}\\left(\\frac{1}{44640}\\right)=\\frac{7}{803520}\\) part of August\n1 circumference \\(=360^{\\circ} ;\\) 0.01 of of cercumferene \\(=3.6^{\\circ}\\)\n\nlose of \\(3 \\frac{1}{2} \\%\\) makes selling price \\(=100 \\%-3 \\frac{1}{2} \\%=96.5 \\%\\) of cost \\(8 / 5790=96.5 \\%\\) of cost; \\(5790=\\frac{96.5}{100}\\) of cost;  cost \\(=5790 \\cdot \\frac{100}{96,5}=\\$ 6000\\)"
  },
  {
    "objectID": "math.html#해답",
    "href": "math.html#해답",
    "title": "chatGPT",
    "section": "\n3.2 해답",
    "text": "3.2 해답\n\nSum: \\(3 \\frac{5}{9}+1 \\frac{7}{24}=\\frac{32}{9}+\\frac{31}{24}=\\frac{256}{72}+\\frac{93}{72}=\\frac{349}{72}\\) or \\(4 \\frac{61}{72}\\) Diff: \\(3 \\frac{5}{9}-1 \\frac{7}{24}=\\frac{163}{72}\\) or \\(2 \\frac{19}{72}\\) Prod: \\(3 \\frac{5}{9} \\cdot 1 \\frac{7}{24}=\\frac{124}{27}\\) or \\(4 \\frac{16}{27}\\) \\(D \\omega: 3 \\frac{5}{9} \\div 1 \\frac{7}{24}=\\frac{32}{9} \\div \\frac{31}{24}=\\frac{32}{9} \\cdot \\frac{24}{31}=\\frac{256}{93}\\) or \\(2 \\frac{70}{99}\\)\n\n\n\\(\\frac{73}{1000} \\cdot \\frac{19}{100}=\\frac{1387}{100000}\\) or .01387 or 1387 hundread thousandths\n\n\\(\\frac{2880}{.0036}=\\frac{28800000}{36}=800,000\\) or 8 hundread thousandths\n\n\\(\\quad \\frac{1}{5}+\\frac{3}{9}=\\frac{4}{20}+\\frac{15}{20}=\\frac{19}{20} \\cdot \\frac{5}{5}=\\frac{95}{100}=.95\\) 5 A uguat has 31 doys \\(=744\\) hours \\(=44640\\) mcim oner munute \\(=\\frac{1}{44640}\\) part of Angust So \\(\\frac{7}{18} \\min =\\frac{7}{18}\\left(\\frac{1}{44640}\\right)=\\frac{7}{803520}\\) fart of Auguet\n1 Corcumforence \\(=360^{\\circ} ;\\). of of cercumferene \\(=3.6^{\\circ}\\)\n\nlose of \\(3 \\frac{1}{2} \\%\\) makes sulhing pric \\(=100 \\%-3 \\frac{1}{2} \\%=96.5 \\%\\) of cast \\(8 / 5790=96.5 \\%\\) of coet; \\(5790=\\frac{96.5}{100} \\&\\) cost; cost \\(=5790 \\cdot \\frac{100}{96,5}=\\$ 6000\\)"
  },
  {
    "objectID": "math.html#대수algebra",
    "href": "math.html#대수algebra",
    "title": "chatGPT",
    "section": "\n3.3 대수(Algebra)",
    "text": "3.3 대수(Algebra)\n\nIf \\(e=8\\), find the numerical value of the following expression: \\[\ne-\\{\\sqrt{ }(e+1)+2\\}+(e-\\sqrt[3]{ } e) \\sqrt{ }(e-4)\n\\]\n\nSimplify the following expression by removing the brackets and collecting like terms : \\[\n3 a-[b+(2 a-b)-(a-b)]\n\\]\n\nMultiply \\(3 a^2+a b-b^2\\) by \\(a^2-2 a b-3 b^2\\), and divide the product by \\(a+b\\).\nReduce the following fraction to its lowest terms: \\[\n\\frac{x^6+a^2 x^3 y}{x^6-a^4 y^2}\n\\]\n\nSimplify \\(\\left.\\left\\{\\frac{a+b}{a-b}+\\frac{a-b}{a+b}\\right\\}\\right\\} \\div-\\left\\{\\frac{a+b}{a-b}-\\frac{a-b}{a+b}\\right\\}\\).\nSolve \\(\\frac{3 x-4}{2}-\\frac{6 x-5}{8}=\\frac{3 x-1}{16}\\).\nSolve \\(7 x-5 y=24, \\quad 4 x-3 y=11\\).\n\n\n3.3.1 해답\n\n\\[\n\\begin{aligned}\ne-[\\sqrt{e+1}+2]+(e-\\sqrt[3]{e}) \\sqrt{e-4} & e=8 \\\\\n8-[\\sqrt{9}+2] & +(8-\\sqrt[3]{8}) \\sqrt{8-4} \\\\\n8-5 & +(8-2) \\cdot 2=8-5+6 \\times 2=3+12=15\n\\end{aligned}\n\\]\n\n\\(3 a-[b+(2 a-b)-(Q-b)]\\) \\[\n3 a-[b+2 a-b-a+b]-3 a-[a+b]=3 a-a-b-2 a-b\n\\] \\(3 \\frac{\\left(3 a a^2+a b-b^2\\right)\\left(a^2-2 a b-3 b^2\\right)}{a+b}=\\frac{\\left(3 a^2+a b-b^2\\right)(a-3 b)(a+b)}{(a+b)}=\\) \\(3 a^3+a^2 b-a b^2-9 a^2 b-3 a b^2+3 b^3=3 a^3-8 a^2 b-4 a b^2+3 b^3\\) \\(4 \\frac{x^6+a^2 x^3 y}{x^6-a^4 y^2}=\\frac{x^3\\left(x^3+a^2-y\\right)}{\\left(x^2+a^2+\\right)\\left(x^3+a^2-y\\right)}=\\frac{x^3}{x^3+a^2 y}\\)\n\n\\[\n\\begin{aligned}\n& {\\left[\\frac{a+b}{a-b}+\\frac{a-b}{a+b}\\right] \\div\\left[\\frac{a+b}{a-b}-\\frac{a-b}{a+b}\\right]=} \\\\\n& {\\left[\\frac{(a+b)^2+(a-b)^2}{(a-b)(a+b)}\\right] \\cdot\\left[\\frac{(a-b)(a+b)}{(a+b)^2-(a-b)^2}\\right]=} \\\\\n& \\frac{a^2+2 a b+b^2+a^2-2 a b+b^2}{a^2+2 a b+a^2-a^2+2 a b-b^2}=\\frac{2 a^2+2 b^2}{4 a b}=\\frac{a^2+b^2}{2 a b}\n\\end{aligned}\n\\]\n\n\\[\\begin{aligned}\n&\\begin{aligned}\n& 6 \\frac{3 x-4}{2}-\\frac{6 x-5}{8}=\\frac{3 x-1}{16} ; \\frac{8(3 x-4)}{8 \\cdot 2}-\\frac{2(6 x-5)}{2 \\cdot 8}=\\frac{3 x-1}{16} \\\\\n& 24-32-12 x+10=3 x-1 \\\\\n& 9 x=21 \\quad x=7 / 3\n\\end{aligned}\\\\\n\n&\\begin{aligned}\n& 2 x-5 y=24 \\\\\n& \\alpha=17 \\\\\n& 7(17)-5 y=24 \\\\\n& y=19 \\\\\n& 119-5 y=24:-5 y=-95: \\quad y=19 \\\\\n&\n\\end{aligned}\n\\end{aligned}\\]"
  },
  {
    "objectID": "math.html#기하",
    "href": "math.html#기하",
    "title": "chatGPT",
    "section": "\n3.4 기하",
    "text": "3.4 기하\n\nProve that the sum of the three angles of a plano triangle equals two right angles.\nProve that the diagonal of a parallelogram divides it into two equat triangles.\nProve that the area of a trapezoid is equal to the half sum of its parallel bases multiplied by its altitude.\nProve that the side of a regular hexagon inscribed in a circle is equal to its radius.\nThe radius of a circle equals 10 . Find its area.\nThe perpendicular dropped from the vertex of the right angle upon the hypothenuse divides it into two segments of 9 and 16 feet respectively. Find the lengths of the perpendicular, and the two legs of the triangle.\nDefine similar polygons. To what are their areas proportional?\n\n\n3.4.1 해답\nGeometry 1. Live triangle \\(A B C\\) construct a kine through \\(A\\) parallel to side \\(\\overline{B C}\\) angles \\(x, y\\) and a are formed at vertex \\(A\\) (1) The sum of all angles on one side of a line equal \\(180^{\\circ}\\) at a front; \\(y+a+y=180\\) A right angle contains \\(90^{\\circ}\\) \\(\\overline{A B}\\) and \\(\\overline{A C}\\) an transcuersals intersecting the two parallel hires: \\(\\overline{B C}\\) and line tromp \\(A\\) \\(\\angle A B C=\\angle x\\) and \\(\\angle A C B=\\angle y\\) because alternate interior angles of parallel hines are equal. (1) Since \\(x+a+y=180^{\\circ}\\) by subshticher \\(\\angle A B C+a+\\angle A C B=180^{\\circ}=\\) two rigitangles\n\nTwin parallelogram \\(A B C D\\) with diagonal \\(B D\\) \\(\\overline{A D} \\| \\overline{B C}\\) and \\(\\overline{A B} \\| \\overline{D C}\\) becanec oppose sides of a parallegran are parallel \\(\\angle x=\\angle d\\) and \\(\\angle b=\\angle y\\) because alternate interior angles formed by 2 parallel bice cat by a transversal are = \\(\\overline{B D}\\) is a side of both brixingles “is congunchat” Herfou, \\(\\triangle A B D \\cong \\triangle \\triangle D B\\) by the property If 2 angles of one triangle and the included vide are congruent to 2 angles and the included side of another brangle, the 2 triangles are Congruent (equal\nTrapezoid \\(A B C D\\) has basen of \\(b_1(\\overline{A B})+b_2(\\overline{D C})\\) and altude of \\(h\\). construnt a hine threr \\(C\\) parallel to side DA Eutend \\(\\overline{A B}\\) through, \\(B\\), trentersed the line chrough \\(C\\) at pout F AFCDis a parallelogram weth area \\(h b_2\\) and side \\(\\overline{D C}=\\overline{A F}\\) becamee appasite sedu f a perallebgeren are equd The alttiede of \\(\\triangle C B F=h\\) Areed \\(\\triangle C B F-\\frac{1}{2} \\overline{B F} \\cdot h\\) \\(\\widehat{B F}=\\overline{A F}-b_1=b_2-b_1 ;\\); lentictite \\(b_2-b_1\\) fo \\(\\overline{B F}\\) Aree of \\(\\triangle C B F=\\frac{1}{2}\\left(b_2-b_1\\right) \\cdot h\\) Area of trapegaid \\(A B C D=\\) Area of paullingram \\(A F C D\\)-aread \\(\\triangle C B F\\) \\(\\begin{aligned} & =b_2 \\cdot h \\quad-\\frac{1}{2}\\left(b_2-b_1\\right) h= \\\\ b_2 \\cdot h-\\frac{1}{2} b_2 h+\\frac{1}{2} b_1 h & =\\frac{1}{2} h\\left(b_1+b_2\\right) \\\\ \\therefore \\text { Area of trappoid = } & \\frac{1}{2} \\text { susan of paratled bacere meulhpths by itallehde }\\end{aligned}\\)"
  },
  {
    "objectID": "math.html#번-문제",
    "href": "math.html#번-문제",
    "title": "chatGPT",
    "section": "\n2.1 2번 문제",
    "text": "2.1 2번 문제\n\n함수 \\(f(x)=x^3+3 x^2+x-1\\) 에 대하여 \\(f^{\\prime}(1)\\) 의 값은?\n\n\n코드library(tidyverse)\nlibrary(openai)\n\nsolve_math_02 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. 함수 } f(x)=x^3+3 x^2+x-1 \\\\text { 에 대하여 } f^{\\\\prime}(1) \\\\text { 의 값은? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#> \n#> \n#> f'(1)은 미분을 통해 구할 수 있습니다.\n#> \n#> f'(x) = 3x^2 + 6x + 1\n#> \n#> f'(1) = 3(1)^2 + 6(1) + 1 = 10\n#> \n#> 따라서 f'(1) = 10이라는 결과가 나오게 됩니다. 이에 따르면 함수 f(x) = x^3 + 3x^2 + x - 1에 대하여 x가 1일 때의 미분값 f'(1)은 10이 됩니다."
  },
  {
    "objectID": "math.html#번-문제-1",
    "href": "math.html#번-문제-1",
    "title": "chatGPT",
    "section": "\n2.2 3번 문제",
    "text": "2.2 3번 문제\n\n등차수열 \\(\\left\\{a_n\\right\\}\\) 에 대하여 \\[\na_2=6, \\quad a_4+a_6=36\n\\] 일 때, \\(a_{10}\\) 의 값은?\n\n\n코드solve_math_03 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '등차수열 $\\left\\{a_n\\right\\}$ 에 대하여\n$$\na_2=6, \\quad a_4+a_6=36\n$$\n일 때, $a_{10}$ 의 값은?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\n등차수열의 정의에 따라 \\(a_n = a_1 + (n-1)d\\) 이므로, \\(a_1\\) 과 \\(d\\) 를 구해야 합니다.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]"
  },
  {
    "objectID": "math.html#ai-추론",
    "href": "math.html#ai-추론",
    "title": "chatGPT",
    "section": "\n2.2 AI 추론",
    "text": "2.2 AI 추론\n1번 문제\n\n\nBing AI\n\nSure! Let’s first convert the mixed numbers to improper fractions. \\(3 \\frac{5}{9}\\) is equal to \\(\\frac{32}{9}\\) and \\(1 \\frac{7}{24}\\) is equal to \\(\\frac{31}{24}\\).  Now we can find the sum: \\(\\frac{32}{9} + \\frac{31}{24} = \\frac{(32)(8) + (31)(3)}{(9)(8)} = \\frac{256 + 93}{72} = \\frac{349}{72}\\).  The difference is: \\(\\frac{32}{9} - \\frac{31}{24} = \\frac{(32)(8) - (31)(3)}{(9)(8)} = \\frac{256 - 93}{72} = \\frac{163}{72}\\).  The product is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{31}{24}\\right) = \\dfrac{(32)(31)}{(9)(24)} = \\dfrac{992}{216}\\).  To divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\), we can multiply \\(3 \\frac{5}{9}\\) by the reciprocal of \\(1 \\frac{7}{24}\\). The reciprocal of \\(\\dfrac{31}{24}\\) is \\(\\dfrac{24}{31}\\).  So the quotient is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{24}{31}\\right) = \\dfrac{(32)(24)}{(9)(31)} = \\dfrac{768}{279}\\).\n\n\n\n\nOpenAI\nLet’s first convert the mixed numbers into improper fractions: \\(3 \\frac{5}{9} = \\frac{3 \\times 9 + 5}{9} = \\frac{27 + 5}{9} = \\frac{32}{9}\\)\n\\(1 \\frac{7}{24} = \\frac{1 \\times 24 + 7}{24} = \\frac{24 + 7}{24} = \\frac{31}{24}\\)\nFind the sum, difference, product, and division of the two improper fractions: Sum:\n\\(\\frac{32}{9} + \\frac{31}{24} = \\frac{32 \\times 24}{9 \\times 24} + \\frac{31 \\times 9}{24 \\times 9} = \\frac{768}{216} + \\frac{279}{216} = \\frac{1047}{216}\\)\nDifference:\n\\(\\frac{32}{9} - \\frac{31}{24} = \\frac{32 \\times 24}{9 \\times 24} - \\frac{31 \\times 9}{24 \\times 9} = \\frac{768}{216} - \\frac{279}{216} = \\frac{489}{216}\\)\nProduct:\n\\(\\frac{32}{9} \\times \\frac{31}{24} = \\frac{32 \\times 31}{9 \\times 24} = \\frac{992}{216}\\)\nDivision:\n\\(\\frac{32}{9} \\div \\frac{31}{24} = \\frac{32}{9} \\times \\frac{24}{31} = \\frac{32 \\times 24}{9 \\times 31} = \\frac{768}{279}\\)\nThe corrected results are:\nSum: \\(\\frac{1047}{216}\\) Difference: \\(\\frac{489}{216}\\) Product: \\(\\frac{992}{216}\\) Division: \\(\\frac{768}{279}\\)\n\n\n\n2번 문제\n\n\nBing AI\nSure! To multiply 73 thousandths by 19 hundredths, you can convert them to decimals first. 73 thousandths is equivalent to 0.073 and 19 hundredths is equivalent to 0.19. Multiplying these two numbers gives us a result of 0.01387.\n\n\n\n\nOpenAI\nTo multiply decimals, first multiply the numbers as if they were whole numbers, and then count the total number of decimal places in both numbers.\n73 thousandths can be written as 0.073, and 19 hundredths can be written as 0.19.\nNow, multiply the numbers as if they were whole numbers:\n73 * 19 = 1387\nThere are a total of 5 decimal places in both numbers combined (3 decimal places in 0.073 and 2 decimal places in 0.19). So, we need to place the decimal point 5 places from the right in the product:\n0.001387\nTherefore, the product of 73 thousandths and 19 hundredths is 0.001387.\n\n\n\n3번 문제\n\n\nBing AI\nSure! Here’s a step-by-step guide on how to divide 2880 by 0.0036:\n\nWrite the problem as a long division problem: 2880 ÷ 0.0036\nMove the decimal point in the divisor (0.0036) to the right until it becomes a whole number (36). Move the decimal point in the dividend (2880) the same number of places to the right: 28800000 ÷ 36\nPerform long division to get a result of 800000.\n\n\n\n\nOpenAI\nTo divide 2880 by 0.0036, you can first divide both numbers by the same power of 10 to make the divisor a whole number. In this case, since the divisor has four decimal places, you can multiply both numbers by 10^4:\n2880 * 10^4 = 28800000 0.0036 * 10^4 = 36\nNow, divide 28800000 by 36:\n28800000 ÷ 36 = 800000\nSo, 2880 divided by 0.0036 is 800000.\n\n\n\n4번 문제\n\n\nBing AI\nSure! To find the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\), you can first convert the fractions to decimals. \\(\\frac{1}{5}\\) is equivalent to 0.2 and \\(\\frac{8}{4}\\) is equivalent to 2. Adding these two numbers gives us a result of 2.2.\n\n\n\n\nOpenAI\nFirst, let’s simplify each fraction and convert them to decimals:\n\\(\\frac{1}{5}\\) as a decimal is 0.2.\n\\(\\frac{8}{4}\\) can be simplified to \\(\\frac{2}{1}\\), which as a decimal is 2.\nNow, add the two decimal values:\n\\(0.2 + 2 = 2.2\\)\nSo, the value of \\(\\frac{1}{5}+\\frac{8}{4}\\) in decimals is 2.2.\n\n\n\n5번 문제\n\n\nBing AI\nI’m sorry but your question is a bit unclear. Could you please clarify what you mean by “what part of the month of August is \\(\\frac{7}{18}\\) minutes”? Are you asking for a specific date and time in August that corresponds to \\(\\frac{7}{18}\\) minutes?\n\n\n\n\nOpenAI\nTo determine what part of the month of August is \\(\\frac{7}{18}\\) minutes, we first need to know the total number of minutes in the month of August.\nAugust has 31 days, and each day has 24 hours with 60 minutes per hour. Therefore, there are:\n\\(31 \\times 24 \\times 60 = 44640\\) minutes in August.\nNow, we can find what part of the month of August is \\(\\frac{7}{18}\\) minutes by dividing \\(\\frac{7}{18}\\) by the total number of minutes:\n\\(\\frac{7}{18} \\div 44640 = \\frac{7}{18 \\times 44640}\\)\nNow, simplify the fraction:\n\\(\\frac{7}{802080}\\)\nSo, \\(\\frac{7}{18}\\) minutes is \\(\\frac{7}{802080}\\) of the month of August.\n\n\n\n6번 문제\n\n\nBing AI\nSure! A full circumference is equivalent to 360 degrees. To find the number of degrees in 0.01 of a circumference, you can multiply 360 by 0.01 to get a result of 3.6 degrees.\n\n\n\n\nOpenAI\nTo find out how many degrees are in 0.01 of a circumference, you need to consider that a full circumference corresponds to 360 degrees.\nTo find the number of degrees in 0.01 of a circumference, multiply 360 degrees by 0.01:\n360° × 0.01 = 3.6°\nSo, there are 3.6 degrees in 0.01 of a circumference.\n\n\n\n7번 문제\n\n\nBing AI\nSure! Let’s say the owner’s cost was \\(x\\). If they lost \\(3 \\frac{1}{2}\\) per cent on the sale, then their selling price was \\(100% - 3 \\frac{1}{2}% = 96.5%\\) of their cost. So we can write the equation: \\(0.965x = 5790\\). Solving for \\(x\\), we find that the owner’s cost was $ \\(5994.81\\).\n\n\n\n\nOpenAI\nTo find the original cost of the house and lot, we set up and solve the equation as follows:\nLet the cost of the house and lot be denoted by C. The owner lost \\(3\\frac{1}{2}%\\) on the sale, which means they sold it for \\(100% - 3\\frac{1}{2}%\\) of its original value. First, convert \\(3\\frac{1}{2}%\\) to a decimal:\n\\(3\\frac{1}{2}% = 3.5%\\)\nNow, subtract this percentage from \\(100%\\) to find the percentage of the cost at which the house was sold:\n\\(100% - 3.5% = 96.5%\\)\nNow, we know that \\(96.5%\\) of the cost is equal to the selling price, which is $\\(5,790\\). We can write this as an equation:\n$0.965C = \\(5,790\\)\nNow, we can find the cost (C) by dividing both sides of the equation by 0.965:\n$C = $\n$C \\(5,995.85\\)\nSo, the original cost of the house and lot was approximately $\\(5,995.85\\). In LaTeX format, the solution is as follows:\nLet the cost be denoted by \\(C\\). The equation representing the loss is: [0.965C = 5790]\nTo find the cost, divide both sides by 0.965: [C = ]\nTherefore, the original cost of the house and lot was approximately $5,995.85."
  },
  {
    "objectID": "math.html#번-문제-7",
    "href": "math.html#번-문제-7",
    "title": "chatGPT",
    "section": "\n3.1 2번 문제",
    "text": "3.1 2번 문제\n\n함수 \\(f(x)=x^3+3 x^2+x-1\\) 에 대하여 \\(f^{\\prime}(1)\\) 의 값은?\n\n\n\n\n\n\n\nGPT-3.5\nBing AI\nchatGPT GPT-4\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\nsolve_math_02 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. 함수 } f(x)=x^3+3 x^2+x-1 \\\\text { 에 대하여 } f^{\\\\prime}(1) \\\\text { 의 값은? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#> \n#> \n#> f'(1) = 3x² + 6x + 1 = 10\n#> \n#> 미분이란 함수의 연속된 변화량을 측정하는 과정이다. 따라서 f'(1)은 함수 f(x)에서 x = 1 일 때 함수의 변화량을 찾기 위해 미분한 값이다. f'(1) 미분식을 계산하면 x³ + 3x² + x - 1에서 x = 1 일 때 계산결과 10이 나오게 된다.\n\n\n\n\nSure! The derivative of a function \\(f(x)\\) is denoted by \\(f’(x)\\) and represents the rate of change of the function at a given point. To find the value of \\(f’(1)\\) for the function \\(f(x)=x^3+3 x^2+x-1\\), we first need to find its derivative.\nThe derivative of \\(x^3\\) is \\(3x^2\\), the derivative of \\(3x^2\\) is \\(6x\\), and the derivative of \\(x\\) is 1. The derivative of a constant term like -1 is 0. So, the derivative of the function \\(f(x)=x^3+3 x^2+x-1\\) is:\n\\[f’(x) = 3x^2 + 6x + 1\\]\nTo find the value of \\(f’(1)\\), we can substitute x=1 into this equation:\n\\[f’(1) = 3(1)^2 + 6(1) + 1 = 10\\]\nSo, the value of \\(f’(1)\\) for the function \\(f(x)=x^3+3 x^2+x-1\\) is 10.\n\n\n함수 \\(f(x)=x^3+3x^2+x-1\\)의 도함수를 구하고, \\(x=1\\)일 때의 값을 구하겠습니다.\n\\(f(x)\\)의 도함수는 \\(f'(x)\\)로 표시되며, 각 항에 대한 미분을 적용합니다:\n\\(f'(x) = \\frac{d}{dx}(x^3) + \\frac{d}{dx}(3x^2) + \\frac{d}{dx}(x) - \\frac{d}{dx}(1)\\)\n각 항에 대한 미분 결과는 다음과 같습니다:\n\\(\\frac{d}{dx}(x^3) = 3x^2\\)\n\\(\\frac{d}{dx}(3x^2) = 6x\\)\n\\(\\frac{d}{dx}(x) = 1\\)\n\\(\\frac{d}{dx}(1) = 0\\)\n이제 도함수를 다음과 같이 작성할 수 있습니다:\n\\(f'(x) = 3x^2 + 6x + 1\\)\n이제 \\(f'(1)\\)을 구합니다:\n\\(f'(1) = 3(1)^2 + 6(1) + 1 = 3 + 6 + 1 = 10\\)\n따라서, \\(f^{\\prime}(1)\\)의 값은 10입니다."
  },
  {
    "objectID": "math.html#번-문제-8",
    "href": "math.html#번-문제-8",
    "title": "chatGPT",
    "section": "\n3.2 3번 문제",
    "text": "3.2 3번 문제\n\n등차수열 \\(\\left\\{a_n\\right\\}\\) 에 대하여 \\[\na_2=6, \\quad a_4+a_6=36\n\\] 일 때, \\(a_{10}\\) 의 값은?\n\n\n\n\n\n\n\nGPT-3.5\n빙 AI\nOpenAI GPT-4\n\n\n\n\n코드solve_math_03 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '등차수열 $\\left\\{a_n\\right\\}$ 에 대하여 $$ a_2=6, \\quad a_4+a_6=36 $$ 일 때, $a_{10}$ 의 값은?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\n등차수열의 정의에 따라 \\(a_n = a_1 + (n-1)d\\) 이므로, \\(a_1\\) 과 \\(d\\) 를 구해야 합니다.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]\n\n\nSure! In an arithmetic sequence \\(a_n\\), the difference between consecutive terms is constant. Let’s denote this common difference by \\(d\\). Then we have:\n\\[a_3 = a_2 + d = 6 + d\\] \\[a_4 = a_3 + d = 6 + 2d\\] \\[a_5 = a_4 + d = 6 + 3d\\] \\[a_6 = a_5 + d = 6 + 4d\\]\nWe are given that \\(a_4+a_6=36\\), so substituting the expressions for \\(a_4\\) and \\(a_6\\) from above, we get:\n\\[(6+2d)+(6+4d)=36 \\Rightarrow 12+6d=36 \\Rightarrow d=4\\]\nNow that we know the common difference \\(d\\), we can find the value of \\(a_{10}\\):\n\\[a_{10} = a_{9}+d=a_{8}+2d=\\cdots=a_{2}+8d=6+8(4)=38\\]\nSo, the value of \\(a_{10}\\) for this arithmetic sequence is 38.\n\n\n등차수열 \\(a_n\\)에서 일반적인 항은 \\(a_n = a_1 + (n-1)d\\)로 표현됩니다. 여기서 \\(a_1\\)은 첫 번째 항이고 \\(d\\)는 공차입니다.\n문제에서 주어진 정보를 사용하여 두 개의 방정식을 작성할 수 있습니다:\n\\[a_2 = a_1 + (2-1)d = a_1 + d = 6\\] \\[a_4 + a_6 = (a_1 + 3d) + (a_1 + 5d) = 36\\]\n첫 번째 방정식에서 \\(d\\)에 대해 풀면 \\(d = 6 - a_1\\)입니다. 이것을 두 번째 방정식에 대입합니다:\n\\[(a_1 + 3(6 - a_1)) + (a_1 + 5(6 - a_1)) = 36\\]\n이제 \\(a_1\\)에 대해 풀면 됩니다:\n\\[2a_1 - 3a_1 + 18 - 5a_1 + 30 = 36\\] \\[-6a_1 = -12\\] \\[a_1 = 2\\]\n이제 \\(a_1 = 2\\)를 사용하여 공차 \\(d\\)를 찾습니다:\n\\[d = 6 - a_1 = 6 - 2 = 4\\]\n따라서 등차수열의 첫 번째 항은 \\(a_1 = 2\\)이고 공차는 \\(d = 4\\)입니다. 이제 \\(a_{10}\\)을 찾을 수 있습니다:\n\\[a_{10} = a_1 + (10-1)d = 2 + 9 \\times 4 = 2 + 36 = 38\\]\n따라서, \\(a_{10}\\)의 값은 38입니다."
  },
  {
    "objectID": "gpt4_performance.html",
    "href": "gpt4_performance.html",
    "title": "chatGPT",
    "section": "",
    "text": "[@openai2023gpt4]"
  },
  {
    "objectID": "gpt4_performance.html#pdf-워드",
    "href": "gpt4_performance.html#pdf-워드",
    "title": "chatGPT",
    "section": "\n1.1 PDF → 워드",
    "text": "1.1 PDF → 워드\nPDF 문서를 Convert2Docx 패키지를 활용하여 워드파일로 변환시킨다. 페이지가 많아 제법 시간이 소요된다.\n\n코드library(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")"
  },
  {
    "objectID": "gpt4_performance.html#워드-표추출",
    "href": "gpt4_performance.html#워드-표추출",
    "title": "chatGPT",
    "section": "\n1.2 워드 → 표추출",
    "text": "1.2 워드 → 표추출\ndocxtractr 패키지를 설치하고 docx_extract_tbl() 함수로 PDF 파일에 담긴 표를 추출한다.\n\n코드library(docxtractr)\n\ngpt_docx <- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 <- docx_extract_tbl(gpt_docx, 3) %>% \n    janitor::clean_names()\ntbl_01\n#> # A tibble: 34 × 4\n#>    exam                                           gpt_4          gpt_4…¹ gpt_3_5\n#>    <chr>                                          <chr>          <chr>   <chr>  \n#>  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 / 400 (~9… 298 / … 213 / …\n#>  2 LSAT                                           163 (~88th)    161 (~… 149 (~…\n#>  3 SAT Evidence-Based Reading & Writing           710 / 800 (~9… 710 / … 670 / …\n#>  4 SAT Math                                       700 / 800 (~8… 690 / … 590 / …\n#>  5 Graduate Record Examination (GRE) Quantitative 163 / 170 (~8… 157 / … 147 / …\n#>  6 Graduate Record Examination (GRE) Verbal       169 / 170 (~9… 165 / … 154 / …\n#>  7 Graduate Record Examination (GRE) Writing      4 / 6 (~54th)  4 / 6 … 4 / 6 …\n#>  8 USABO Semifinal Exam 2020                      87 / 150 (99t… 87 / 1… 43 / 1…\n#>  9 USNCO Local Section Exam 2022                  36 / 60        38 / 60 24 / 60\n#> 10 Medical Knowledge Self-Assessment Program      75 %           75 %    53 %   \n#> # … with 24 more rows, and abbreviated variable name ¹​gpt_4_no_vision"
  },
  {
    "objectID": "calculator.html",
    "href": "calculator.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 CLI 계산기\nchatGPT에 지시명령어로 계산기 프로그램을 파이썬 언어로 작성하라는 하명을 내린다. 계산기를 동작시키는 방식도 알려달라는 하명도 이어서 내린다.\n\n\n지시명령어\n소스코드\n→\n실행 지시명령어\n실행 사례\n\n\n\n\n\n\n\n\n\nwrite python code of calculator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n코드# Simple calculator program\n\n# Function to add two numbers\ndef add(x, y):\n    return x + y\n\n# Function to subtract two numbers\ndef subtract(x, y):\n    return x - y\n\n# Function to multiply two numbers\ndef multiply(x, y):\n    return x * y\n\n# Function to divide two numbers\ndef divide(x, y):\n    return x / y\n\n# Display menu\nprint(\"Select operation.\")\nprint(\"1. Add\")\nprint(\"2. Subtract\")\nprint(\"3. Multiply\")\nprint(\"4. Divide\")\n\n# Take input from the user\nchoice = input(\"Enter choice (1/2/3/4): \")\n\nnum1 = float(input(\"Enter first number: \"))\nnum2 = float(input(\"Enter second number: \"))\n\n# Perform operation based on user's choice\nif choice == '1':\n    print(num1, \"+\", num2, \"=\", add(num1, num2))\n\nelif choice == '2':\n    print(num1, \"-\", num2, \"=\", subtract(num1, num2))\n\nelif choice == '3':\n    print(num1, \"*\", num2, \"=\", multiply(num1, num2))\n\nelif choice == '4':\n    print(num1, \"/\", num2, \"=\", divide(num1, num2))\n\nelse:\n    print(\"Invalid input\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nhow to run this python code\n\n\n\n\n\nPython 코드를 실행하려면 시스템에 Python이 설치되어 있어야 합니다. 다음 단계에 따라 간단한 계산기를 위한 Python 코드를 실행할 수 있습니다:\n\n메모장이나 서브라인 텍스트와 같은 텍스트 편집기를 열고 Python 코드를 새 파일에 붙여넣습니다.\n파일 확장명을 .py로 지정하여 저장합니다(예: calculator.py).\n터미널 또는 명령 프롬프트 창을 엽니다.\n\ncd 명령을 사용하여 파일이 저장된 디렉토리로 이동합니다(예: cd Documents\\Python).\n\npython calculator.py를 입력하고 Enter 키를 눌러 프로그램을 실행합니다.\n\n그러면 프로그램이 실행되고 메뉴가 표시되며 사용자에게 원하는 연산과 숫자 두 개를 입력하라는 메시지가 표시됩니다. 사용자가 필요한 입력을 입력하면 프로그램이 해당 산술 연산을 수행하고 결과를 표시합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n코드xfun::embed_file(\"code/calculator.py\", text = \"계산기 소스코드 다운로드\")\n\n계산기 소스코드 다운로드\n\n\n\n2 GUI 계산기\n이번에는 계산기에 GUI를 입혀 사용자가 좀더 쉽게 사용할 수 있도록 한다. 다양한 GUI 패키지가 있지만 그중에서 tkinter 패키지 하나를 선정하여 개발을 이어나간다. chatGPT에 지시명령어로 계산기 프로그램을 파이썬 언어로 작성하라는 하명을 내린다. 계산기를 동작시키는 방식도 알려달라는 하명도 이어서 내린다.\n\n\n지시명령어\n소스코드\n→\n실행 지시명령어\n실행 사례\n\n\n\n\n\n\n\n\n\nplease add gui with tkinter\n\n\n\n\n\nSure, here is an example of the same calculator program using the Tkinter library to create a graphical user interface (GUI):\n…\nIn this code, we first import the Tkinter library using the alias tk. Then we define four functions add(), subtract(), multiply(), and divide() that perform the corresponding arithmetic operations on the numbers entered by the user. Each function retrieves the input values from the Entry widgets using the get() method, performs the arithmetic operation, and updates the text of the Label widget to display the result.\nWe then create the main window using the Tk() constructor and set its title using the title() method. Next, we create two Label widgets and two Entry widgets to allow the user to enter the two numbers.\nWe also create four Button widgets, one for each arithmetic operation, and set their text and width. The command parameter is used to specify the function that should be called when the button is clicked.\nFinally, we create a Label widget to display the result of the arithmetic operation, and call the mainloop() method to start the event loop and display the GUI.\n\n\n\n\n\n\n코드import tkinter as tk\n\n# Function to perform addition\ndef add():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 + num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform subtraction\ndef subtract():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 - num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform multiplication\ndef multiply():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 * num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform division\ndef divide():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 / num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n    except ZeroDivisionError:\n        label_result.config(text=\"Cannot divide by zero\")\n\n# Create the main window\nwindow = tk.Tk()\nwindow.title(\"Simple Calculator\")\n\n# Create the number input fields\nlabel_num1 = tk.Label(window, text=\"Number 1:\")\nlabel_num1.pack()\nentry_num1 = tk.Entry(window)\nentry_num1.pack()\n\nlabel_num2 = tk.Label(window, text=\"Number 2:\")\nlabel_num2.pack()\nentry_num2 = tk.Entry(window)\nentry_num2.pack()\n\n# Create the operation buttons\nbutton_add = tk.Button(window, text=\"+\", width=10, command=add)\nbutton_add.pack()\n\nbutton_subtract = tk.Button(window, text=\"-\", width=10, command=subtract)\nbutton_subtract.pack()\n\nbutton_multiply = tk.Button(window, text=\"*\", width=10, command=multiply)\nbutton_multiply.pack()\n\nbutton_divide = tk.Button(window, text=\"/\", width=10, command=divide)\nbutton_divide.pack()\n\n# Create the result label\nlabel_result = tk.Label(window, text=\"Result: \")\nlabel_result.pack()\n\n# Run the main loop\nwindow.mainloop()\n\n\n\n\n\n\n\n\n\n\n\n\n\nhow to run this python code\n\n\n\n\n\nPython 코드를 실행하려면 시스템에 Python이 설치되어 있어야 합니다. 다음 단계에 따라 간단한 계산기를 위한 Python 코드를 실행할 수 있습니다:\n\n메모장이나 서브라인 텍스트와 같은 텍스트 편집기를 열고 Python 코드를 새 파일에 붙여넣습니다.\n파일 확장명을 .py로 지정하여 저장합니다(예: calculator.py).\n터미널 또는 명령 프롬프트 창을 엽니다.\n\ncd 명령을 사용하여 파일이 저장된 디렉토리로 이동합니다(예: cd Documents\\Python).\n\npython calculator.py를 입력하고 Enter 키를 눌러 프로그램을 실행합니다.\n\n그러면 프로그램이 실행되고 메뉴가 표시되며 사용자에게 원하는 연산과 숫자 두 개를 입력하라는 메시지가 표시됩니다. 사용자가 필요한 입력을 입력하면 프로그램이 해당 산술 연산을 수행하고 결과를 표시합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n코드xfun::embed_file(\"code/calculator_gui.py\", text = \"계산기 소스코드 GUI 버전 다운로드\")\n\n계산기 소스코드 GUI 버전 다운로드\n\n\n\n3 테스트\n계산기 프로그램이 정상동작하는지 확인하는 코드를 작성하자. 만약 단위 테스트 결과가 모두 정상동작한다면 믿고 현업에서 사용하게 된다.\n\n\n지시명령어\n실행결과\n\n\n\n\n\n\n\n\n\nfirst write python program for calculator and then test result from execution\n\n\n\n\n\nHere’s the Python code for a simple calculator that supports addition, subtraction, multiplication, and division. We’ll create a separate file for the test cases, which will import and run the calculator functions.\nSave the following code as calculator.py:\nclass Calculator:\n    def add(self, a, b):\n        return a + b\n\n    def subtract(self, a, b):\n        return a - b\n\n    def multiply(self, a, b):\n        return a * b\n\n    def divide(self, a, b):\n        if b == 0:\n            raise ValueError(\"Cannot divide by zero\")\n        return a / b\nNow, create a new file named test_calculator.py and save the following code in it:\nfrom calculator import Calculator\n\ndef test_calculator():\n    calc = Calculator()\n\n    # Test addition\n    assert calc.add(2, 3) == 5, \"Test case 1 failed\"\n    assert calc.add(-2, 3) == 1, \"Test case 2 failed\"\n\n    # Test subtraction\n    assert calc.subtract(5, 3) == 2, \"Test case 3 failed\"\n    assert calc.subtract(0, -5) == 5, \"Test case 4 failed\"\n\n    # Test multiplication\n    assert calc.multiply(3, 4) == 12, \"Test case 5 failed\"\n    assert calc.multiply(-2, 5) == -10, \"Test case 6 failed\"\n\n    # Test division\n    assert calc.divide(10, 2) == 5, \"Test case 7 failed\"\n    assert calc.divide(-10, 5) == -2, \"Test case 8 failed\"\n\n    # Test division by zero\n    try:\n        calc.divide(10, 0)\n    except ValueError as e:\n        assert str(e) == \"Cannot divide by zero\", \"Test case 9 failed\"\n\n    print(\"All test cases passed\")\n\nif __name__ == \"__main__\":\n    test_calculator()\nTo execute the test cases, open a terminal or command prompt and navigate to the directory containing both calculator.py and test_calculator.py. Then run the following command:\npython test_calculator.py\nIf all test cases pass, you’ll see “All test cases passed” printed on the console.\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 .exe 배포\nCLI를 통해 기능을 검증한 후 GUI로 사용자가 사용하기 쉬운 인터페이스를 구현하였다면 다음 단계로 배포를 한다. 다양한 배포 프로그램이 존재하지만 가장 쉽게 .exe 파일을 만드는 방법을 살펴보자.\n\n\n지시명령어\n실행결과\n파이썬 코드\n.spec 파일\n디렉토리 구조\n\n\n\n\n\n\n\n\n\nI am a pyhton developer. I have a simple python calculator. I’d like to deploy this program into Windows. let me know how to create a standalone executable file\n\n\n\n\n\nTo create a standalone executable file for your Python calculator, you can use a tool like PyInstaller or cx_Freeze. Here are the general steps to follow:\nInstall PyInstaller: You can use pip to install PyInstaller. Open a command prompt or terminal and run the following command:\npip install pyinstaller\nCreate a spec file: PyInstaller requires a spec file that describes your Python program and its dependencies. To create a spec file with PyInstaller, run the following command:\npyinstaller --name=calculator --onefile calculator.py\nBuild the executable: To build the executable file with PyInstaller, run the following command:\npyinstaller calculator.spec\nThis will create a standalone executable file in the dist directory. Test the executable file: Run the executable file on a Windows machine to make sure it works as expected.\nBy following these steps, you can create a standalone executable file for your Python calculator using PyInstaller.\n\n\n\n\n\n\n\n\n\n\n\n\n코드import tkinter as tk\n\nclass Calculator:\n    def __init__(self, master):\n        self.master = master\n        self.master.title(\"Calculator\")\n\n        # Create display\n        self.display = tk.Entry(self.master, width=30, borderwidth=5, justify=tk.RIGHT)\n        self.display.grid(row=0, column=0, columnspan=4, padx=10, pady=10)\n\n        # Define buttons\n        button_list = [\"7\", \"8\", \"9\", \"/\", \"4\", \"5\", \"6\", \"*\", \"1\", \"2\", \"3\", \"-\", \"0\", \".\", \"C\", \"+\"]\n\n        # Create buttons\n        row = 1\n        col = 0\n        for button in button_list:\n            command = lambda x=button: self.button_click(x)\n            tk.Button(self.master, text=button, padx=20, pady=10, command=command).grid(row=row, column=col)\n            col += 1\n            if col > 3:\n                row += 1\n                col = 0\n\n        # Create equals button\n        tk.Button(self.master, text=\"=\", padx=50, pady=10, command=self.calculate).grid(row=row, column=0, columnspan=4)\n\n    def button_click(self, button):\n        if button == \"C\":\n            self.display.delete(0, tk.END)\n        else:\n            self.display.insert(tk.END, button)\n\n    def calculate(self):\n        try:\n            result = eval(self.display.get())\n            self.display.delete(0, tk.END)\n            self.display.insert(0, result)\n        except:\n            self.display.delete(0, tk.END)\n            self.display.insert(0, \"Error\")\n\n# Create window\nroot = tk.Tk()\n\n# Create calculator\ncalculator = Calculator(root)\n\n# Run window\nroot.mainloop()\n\n\n\n\n\n코드# -*- mode: python ; coding: utf-8 -*-\n\nblock_cipher = None\n\n\na = Analysis(\n    ['calculator.py'],\n    pathex=[],\n    binaries=[],\n    datas=[],\n    hiddenimports=[],\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    [],\n    name='calculator',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=True,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n\n\n\n\n\n코드fs::dir_tree('code/calculator_exe/')\n#> code/calculator_exe/\n#> ├── build\n#> │   └── calculator\n#> │       ├── Analysis-00.toc\n#> │       ├── base_library.zip\n#> │       ├── calculator.exe.manifest\n#> │       ├── calculator.pkg\n#> │       ├── EXE-00.toc\n#> │       ├── localpycs\n#> │       │   ├── pyimod01_archive.pyc\n#> │       │   ├── pyimod02_importers.pyc\n#> │       │   ├── pyimod03_ctypes.pyc\n#> │       │   ├── pyimod04_pywin32.pyc\n#> │       │   └── struct.pyc\n#> │       ├── PKG-00.toc\n#> │       ├── PYZ-00.pyz\n#> │       ├── PYZ-00.toc\n#> │       ├── Tree-00.toc\n#> │       ├── Tree-01.toc\n#> │       ├── Tree-02.toc\n#> │       ├── warn-calculator.txt\n#> │       └── xref-calculator.html\n#> ├── calculator.py\n#> ├── calculator.spec\n#> └── dist\n#>     └── calculator.exe"
  },
  {
    "objectID": "calculator.html#pdf-워드",
    "href": "calculator.html#pdf-워드",
    "title": "chatGPT",
    "section": "\n1.1 PDF → 워드",
    "text": "1.1 PDF → 워드\nPDF 문서를 Convert2Docx 패키지를 활용하여 워드파일로 변환시킨다. 페이지가 많아 제법 시간이 소요된다.\n\n코드library(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")"
  },
  {
    "objectID": "calculator.html#워드-표추출",
    "href": "calculator.html#워드-표추출",
    "title": "chatGPT",
    "section": "\n1.2 워드 → 표추출",
    "text": "1.2 워드 → 표추출\ndocxtractr 패키지를 설치하고 docx_extract_tbl() 함수로 PDF 파일에 담긴 표를 추출한다.\n\n코드library(docxtractr)\n\ngpt_docx <- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 <- docx_extract_tbl(gpt_docx, 3) %>% \n    janitor::clean_names()\ntbl_01\n#> # A tibble: 34 × 4\n#>    exam                                           gpt_4          gpt_4…¹ gpt_3_5\n#>    <chr>                                          <chr>          <chr>   <chr>  \n#>  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 / 400 (~9… 298 / … 213 / …\n#>  2 LSAT                                           163 (~88th)    161 (~… 149 (~…\n#>  3 SAT Evidence-Based Reading & Writing           710 / 800 (~9… 710 / … 670 / …\n#>  4 SAT Math                                       700 / 800 (~8… 690 / … 590 / …\n#>  5 Graduate Record Examination (GRE) Quantitative 163 / 170 (~8… 157 / … 147 / …\n#>  6 Graduate Record Examination (GRE) Verbal       169 / 170 (~9… 165 / … 154 / …\n#>  7 Graduate Record Examination (GRE) Writing      4 / 6 (~54th)  4 / 6 … 4 / 6 …\n#>  8 USABO Semifinal Exam 2020                      87 / 150 (99t… 87 / 1… 43 / 1…\n#>  9 USNCO Local Section Exam 2022                  36 / 60        38 / 60 24 / 60\n#> 10 Medical Knowledge Self-Assessment Program      75 %           75 %    53 %   \n#> # … with 24 more rows, and abbreviated variable name ¹​gpt_4_no_vision"
  },
  {
    "objectID": "interface.html#웹검색",
    "href": "interface.html#웹검색",
    "title": "chatGPT",
    "section": "\n1.1 웹검색",
    "text": "1.1 웹검색\n구글 검색을 통해 일반적인 내용을 얻을 수도 있다. 예를 들어,\n\nsite:quarto.org/ google analytics tracking code\n\n구글검색창에 상기 사항을 입력하게 되면 구글은 쿼토(quarto) 웹사이트 내부에서 google analytics tracking code 키워드와 관련이 높은 웹페이지를 검색결과로 반환시키게 된다."
  },
  {
    "objectID": "interface.html#쿼토-웹-검색",
    "href": "interface.html#쿼토-웹-검색",
    "title": "chatGPT",
    "section": "\n1.2 쿼토 웹 검색",
    "text": "1.2 쿼토 웹 검색\nQuarto는 웹사이트와 책의 전체 텍스트 검색을 지원하는데, 기본적으로 Quarto는 사이트의 콘텐츠를 자동으로 색인화하여 기본적으로 로컬로 구축된 색인을 사용하여 높은 검색품질을 제공한다. 따라서, 사용자는 구글웹사이트가 아니라 쿼토(quarto)에서 검색을 수행하여 직접 해당 정보를 찾는 것도 가능하다."
  },
  {
    "objectID": "interface.html#chatgpt-검색",
    "href": "interface.html#chatgpt-검색",
    "title": "chatGPT",
    "section": "\n1.3 chatGPT 검색",
    "text": "1.3 chatGPT 검색\nChatGPT를 사용하여 검색작업을 수행할 수도 있다. 특정 웹사이트에서 해당 정보를 얻어야 되기 때문에 지시명령어(Prompt)를 다음과 같이 작성한다.\n\nsearch https://quarto.org/ insert google analytics tracking code for quarto html document"
  },
  {
    "objectID": "interface.html#quarto-전용-chatgpt",
    "href": "interface.html#quarto-전용-chatgpt",
    "title": "chatGPT",
    "section": "\n1.4 Quarto 전용 chatGPT\n",
    "text": "1.4 Quarto 전용 chatGPT\n\n쿼토(Quarto)는 차세대 R마크다운이라는 별명이 붙어 있을 정도로 R마크다운이 갖는 모든 기능에 더하여 추가로 새로운 언어(Python, R, Julia, Observable.)에 대한 지원도 포괄하고 있어 상당한 학습량을 요구한다. 설계는 깔끔하게 잘 되어 있지만 이것을 잘 사용하려면 상당한 학습량이 필요로 한다. 이런 문제에 chatGPT를 도입하여 사용하면 경우에 따라서 큰 도움을 줄 수도 있다.\n\nQuarto Help Bot - Ask a question about Quarto.\n\n\n\n\n\n:::\n내부적으로 동작하는 질문-응답(QnA)에는 다음과 같은 단계로 세분화되어 있으며, 모두 ChatVectorDBChain이 처리한다:\n\n채팅 기록과 새로운 사용자 입력이 주어지면 독립형 질문이 무엇인지 결정(GPT-3 사용).\n독립형 질문이 주어지면 벡터 스토어에서 관련 문서를 검색.\n독립형 질문과 관련 문서를 GPT-3에 전달하여 최종 답변을 생성."
  },
  {
    "objectID": "interface.html#카톡-아숙업",
    "href": "interface.html#카톡-아숙업",
    "title": "chatGPT",
    "section": "\n3.1 카톡: 아숙업",
    "text": "3.1 카톡: 아숙업\n업스테이지에서 개발한 ‘아숙업’ 서비스는 모바일 메신져 카카오톡에 AskUp 채널을 추가하게 되면 chatGPT 유사 기능을 사용할 수 있다. 문제는 언제 AskUp 채널 서비스가 중단될지 유료로 과금이 변경될지 모르지만 chatGPT를 사용하는 방식이 다양화함은 분명하다.\nAskUp 서비스는 현재 시점(“2023-03-10”) 기준 PDF 문서요약기능은 제공하고 있지 않지만 장문의 텍스트는 요약하는 기능을 제공하고 있다.\n\n\naskup 검색\n채널추가\n채팅준비\nOCR 사례\n뉴스 요약"
  },
  {
    "objectID": "interface.html#카톡-다다음",
    "href": "interface.html#카톡-다다음",
    "title": "chatGPT",
    "section": "\n3.2 카톡: 다다음",
    "text": "3.2 카톡: 다다음\n카카오브레인, AI챗봇 ‘다다음’(dmm) 베타 출시 하루 만에 중단\n카카오브레인이 카카오톡으로 쓸 수 있는 인공지능(AI) 챗봇 ‘다다음’(ddmm) 베타 서비스를 19일 출시했지만 황급히 서비스를 내렸다. 다다음은 카카오브레인이 개발한 거대 언어 AI 모델 (LLM) ’코GPT’와 ’칼로’를 파운데이션 모델로 삼아 개발한 생성형 AI 채팅 서비스다. 정보검색, 요약, 번역은 물론 이미지 생성도 지원했다."
  },
  {
    "objectID": "langchain.html",
    "href": "langchain.html",
    "title": "chatGPT",
    "section": "",
    "text": "LangChain 에서 OpenAI chatGPT를 호출하여 원하는 작업을 수행한다. 먼저 openai와 langchain을 설치한다.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEY를 환경변수를 넣어두고 OpenAI() 함수에서 호출하여 사용할 수 있도록 한다.\n\nimport os\nfrom langchain.llms import OpenAI\n\n# os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "langchain.html#영문",
    "href": "langchain.html#영문",
    "title": "chatGPT",
    "section": "\n3.1 영문",
    "text": "3.1 영문\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nprompt.format(product=\"colorful socks\")\n#> '\\nI want you to act as a naming consultant for new companies.\\n\\nHere are some examples of good company names:\\n\\n- search engine, Google\\n- social media, Facebook\\n- video sharing, YouTube\\n\\nThe name should be short, catchy and easy to remember.\\n\\nWhat is a good name for a company that makes colorful socks?\\n'\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#> \n#> FunSox."
  },
  {
    "objectID": "langchain.html#국문",
    "href": "langchain.html#국문",
    "title": "chatGPT",
    "section": "\n3.2 국문",
    "text": "3.2 국문\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_prompt.format(k_product=\"양말\")\n#> '\\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\\n\\n다음은 좋은 회사 이름 몇 가지 사례입니다:\\n\\n- 케이티, 통신\\n- 놀부, 외식프랜차이즈\\n- 율도국, 브랜드제작\\n- 크몽, 아웃소싱 플랫폼\\n\\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\\n\\n양말 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\\n'\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nprint(k_chain.run(\"양말\"))\n#> \n#> - 솔랩, 양말 제품\n#> - 메디솔, 신발과 양말\n#> - 루프로, 양말 디자인\n#> - 브이슬립, 양말"
  },
  {
    "objectID": "openAI_GPT.html",
    "href": "openAI_GPT.html",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPT는 간단히 말해 생성형 사전 학습된 트랜스포머(Generative Pre-trained Transformer)의 약자로, OpenAI의 GPT-3 거대 언어 모델 제품군에 기반한 챗봇으로 지도학습과 강화학습기법을 적용하여 미세조정(fine-tuned)된 제품이자 서비스다. OpenAI GPT-3 모형은 크게 세가지가 있다.\n\nGPT-3\nCodex\n콘텐츠 필터 모델\n\n\nGPT-3은 자연어 처리 및 생성을 담당하는 모델로 인간의 언어 즉, 자연어처럼 보이는 텍스트를 이해할 수 있다. 한걸음 더 들어가면 속도와 성능에 따라 4가지 모델(A, B, C, D)로 구분된다.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\n성능기준으로 보면 다음과 같이 정렬할 수 있는데 비용도 그에 따라 높아진다는 의미도 함축한다.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\n따라서, OpenAI는 다빈치 모델(text-davinci-003)을 통해 원하는 결과를 얻은 후에 다른 모델을 사용해 볼 것을 권장하는데 이유는 훨씬 저렴한 비용으로 많은 수의 유사한 작업을 수행할 수 있기 때문이다.\n\n2,048개의 토큰 및 2019년 10월까지의 데이터 학습하여 이후 모형과 비교하여 정확도나 성능에서 다소 밀리는 모습이지만 최적화를 통해 매우 빠르고 비용이 가장 저렴하다.\n\n2,048개의 토큰과 2019년 10월까지의 데이터 학습되었고 간단한 분류와 의미론적 분류에 효과적이다.\n\n최대 2048개의 토큰을 지원하며 text-davinci-003 다음으로 뛰어난 성능을 보이는 GPT-3 모델이다. 2019년 10월까지의 데이터로 학습되었기 때문에 text-davinci-003보다 정확도가 떨어지지만, 번역, 복잡한 분류, 텍스트 분석 및 요약에 좋은 성능을 보이고 있어 text-davinci-003와 비교하여 가성비가 높다고 평가되고 있다.\n\n2021년 9월까지의 데이터로 훈련되었기 때문에 최신 정보를 제공하지 못한다는 한계는 있지만, 앞선 GPT-3 모형과 비교하여 더 높은 품질을 제공한다. 장점 중 하나는 최대 4,000개 토큰까지 요청할 수 있다는 점이 이전 모형과 큰 차별점이 된다.\n\n코덱스는 프로그래밍 코드 이해 및 생성을 위한 것으로 code-davinci-002와 code-cushman-001가 있다. 또한, 코덱스는 GitHub Copilot을 구동하는 모델이기도 하다. 파이썬, 자바스크립트, 고, 펄, PHP, 루비, 스위프트, 타입스크립트, SQL, 셸 등 12개 이상의 프로그래밍 언어를 지원할 뿐만 아니라 자연어로 표현된 주석(comment)를 이해하고 사용자를 대신하여 요청된 작업을 수행할 수 있다.\n\n복잡한 작업을 수행하는 데 있어서는 code-davinci-002가 더 강력하지만, 많은 코드 생성 작업을 수행할 수 있고 code-davinci-002 보다 더 빠르고 저렴하다는 장점이 있다.\n\n자연어를 코드로 번역하는 데 탁월할 뿐만 아니라 코드를 자동 완성할 뿐만 아니라 보충 요소 삽입도 지원한다. 최대 8,000개의 토큰을 처리할 수 있으며 2021년 6월까지의 데이터로 학습되었다.\n\n민감한 콘텐츠 제거하기 위한 필터 모형이다. 민감하거나 안전하지 않을 수 있는 API 생성 텍스트를 감지할 수 있다. 사용자가 사용할 AI 응용프로그램을 개발할 경우, 필터를 사용하여 모델이 부적절한 콘텐츠를 반환하는지 감지할 수 있다. 이 필터는 텍스트를 다음 3가지 범주로 나눈다.\n\n안전(safe)\n민감(sensitive)\n안전하지 않음(unsafe)"
  },
  {
    "objectID": "prompt.html",
    "href": "prompt.html",
    "title": "chatGPT",
    "section": "",
    "text": "The hottest new programming language is English\n\n— Andrej Karpathy (@karpathy) January 24, 2023"
  },
  {
    "objectID": "prompt.html#식물-광합성",
    "href": "prompt.html#식물-광합성",
    "title": "chatGPT",
    "section": "\n3.1 식물 광합성",
    "text": "3.1 식물 광합성\n다음 잘못된 프롬프트는 너무 모호해서 AI가 무작위 또는 관련 없는 응답을 생성할 가능성이 높다. 좋은 프롬프트는 보다 구체적이고 집중적이므로 AI가 관련성 있는 답변을 제공하도록 유도한다.\n\n\n\n잘못된 프롬프트: “뭐라도 말해줘.”\nAI 응답: “바나나는 동남아시아가 원산지인 인기 과일이지만 지금은 세계 여러 곳에서 재배되고 있습니다.”\n\n\n\n\n\n좋은 프롬프트: “식물의 광합성 과정을 설명하세요.”\nAI 응답: “광합성은 식물, 조류 및 일부 박테리아가 빛 에너지를 포도당 형태의 화학 에너지로 변환하는 과정입니다. 광합성에는 빛에 의존하는 반응과 빛에 독립적인 반응(캘빈 주기)의 두 가지 주요 단계가 포함됩니다. 빛에 의존하는 반응 동안 엽록소와 다른 색소는 빛 에너지를 흡수하여 ATP와 NADPH를 생성하는 데 사용됩니다. 광 독립 반응에서 CO2는 광 의존성 단계에서 생성된 ATP와 NADPH를 사용하여 일련의 효소 촉매 반응을 통해 유기 분자로 고정됩니다. 광합성의 최종 생성물은 포도당으로, 식물이 성장, 번식 및 기타 과정에 사용할 수 있습니다.”"
  },
  {
    "objectID": "prompt.html#국가-수도",
    "href": "prompt.html#국가-수도",
    "title": "chatGPT",
    "section": "\n3.2 국가 수도",
    "text": "3.2 국가 수도\n잘못 작성된 프롬프트는 어느 국가의 수도를 요청하는지 명시하지 않아 모호하다. 좋은 프롬프트는 국가를 명확하게 명시하여 AI가 정확한 정보를 제공할 수 있다.\n\n\n\n잘못된 프롬프트: “수도를 말해줘”\nAI 응답: “세계에는 많은 수도가 있습니다. 질문하는 국가를 지정해 주세요.”\n\n\n\n\n\n좋은 프롬프트: “독일의 수도는 어디인가요?”\nAI 응답: “독일의 수도는 베를린입니다.”"
  },
  {
    "objectID": "prompt.html#과학자",
    "href": "prompt.html#과학자",
    "title": "chatGPT",
    "section": "\n3.3 과학자",
    "text": "3.3 과학자\n잘못 작성된 프롬프트는 사용자가 어떤 과학자를 언급하고 있는지 불분명하므로 관련성이 없거나 잘못된 응답으로 이어질 수 있다. 잘 작성된 프롬프트는 과학자의 이름을 명시하고 간략한 개요와 요청사항을 명확히 하여 AI가 원하는 정보를 제공하도록 안내한다.\n\n\n\n잘못된 프롬프트: “유명한 과학자에 대해 말해줘.”\nAI 응답: “아이작 뉴턴, 알버트 아인슈타인, 마리 퀴리 등 역사상 유명한 과학자가 많이 있습니다. 관심 있는 과학자에 대한 자세한 정보를 제공하세요.”\n\n\n\n\n\n좋은 프롬프트: “알버트 아인슈타인의 생애와 과학에 대한 공헌에 대한 간략한 개요를 제공하세요.”\nAI 응답: “알버트 아인슈타인(1879-1955)은 독일 태생의 이론 물리학자로 역사상 가장 영향력 있는 과학자 중 한 명으로 널리 알려져 있습니다. 그는 공간, 시간, 중력에 대한 우리의 이해에 혁명을 일으킨 상대성 이론으로 가장 잘 알려져 있습니다. 아인슈타인의 유명한 방정식 E=mc^2는 질량과 에너지의 등가성을 증명합니다. 1921년에는 양자 이론의 발전에 기여한 광전 효과의 발견으로 노벨 물리학상을 수상했습니다. 아인슈타인의 연구는 천문학, 핵물리학에서 재료 과학, 우주론에 이르기까지 다양한 분야에 지대한 영향을 미쳤습니다.”"
  },
  {
    "objectID": "prompt.html#요리법",
    "href": "prompt.html#요리법",
    "title": "chatGPT",
    "section": "\n3.4 요리법",
    "text": "3.4 요리법\n잘못 작성된 프롬프트는 너무 일반적이어서 AI가 너무 많은 해석을 가능하게 하여 응답의 경우의 수가 많아지게 된다. 잘 작성된 프롬프트는 주제를 특정 요리로 좁히고, 단계별 설명을 요청하므로 AI의 응답이 더 유용하고 관련성이 높게 유도할 수 있다.\n\n\n\n잘못된 프롬프트: “음식을 요리하는 방법?”\nAI 응답: “음식 요리에는 다양한 기술, 재료, 레시피가 필요합니다. 관심 있는 요리 유형이나 요리 방법에 대해 더 구체적인 정보를 제공하세요.”\n\n\n\n\n\n좋은 프롬프트: “기본적인 파스타 요리를 준비하는 단계를 설명해 주세요.”\nAI 응답: “기본적인 파스타 요리를 준비하려면 다음 단계를 따르세요:\n\n큰 냄비에 소금물을 넣고 끓입니다.  스파게티, 펜네, 페투치니 등 원하는 파스타를 끓는 물에 넣고 포장지 지침에 따라 알 덴테 식감이 될 때까지 약 8~12분간 조리합니다. 파스타가 익는 동안 간단한 소스를 준비합니다. 기본 토마토 소스는 팬에 올리브 오일을 두르고 다진 마늘을 향이 날 때까지 볶습니다. 으깬 토마토, 소금, 후추, 말린 바질 또는 오레가노를 넣고 10~15분간 끓입니다. 익힌 파스타의 물기를 빼고 파스타 물 한 컵을 남겨둡니다. 파스타를 소스에 넣고 골고루 섞이도록 버무립니다. 소스가 너무 걸쭉하면 남은 파스타 물을 약간 추가하여 묽게 만듭니다. 원하는 경우 파마산 치즈와 신선한 바질로 장식하여 파스타 요리를 뜨겁게 제공합니다.”"
  },
  {
    "objectID": "prompt.html#프롬프트",
    "href": "prompt.html#프롬프트",
    "title": "chatGPT",
    "section": "\n1.2 프롬프트",
    "text": "1.2 프롬프트\n챗GPT가 거대언어모형 AI 채팅 인터페이스를 보여주고 있다. 좌측편에 프롬프트 채팅 이력이 나타나 있고, New Chat을 하게 되면 하단 채팅 박스에 Send a message ... 화면이 나온다.\n\n\n프롬프트 명령 대기 상태\n프롬프트 명령 실행 결과"
  },
  {
    "objectID": "prompt.html#프롬프트-구성요소",
    "href": "prompt.html#프롬프트-구성요소",
    "title": "chatGPT",
    "section": "\n1.1 프롬프트 구성요소",
    "text": "1.1 프롬프트 구성요소\n프롬프트 엔지니어링은 반복적인 작업과정으로 AI의 응답에 따라 프롬프트를 조정하고 개선해야 할 수도 있다는 점을 항상 염두에 두고, 다음 프롬프트 구성요소를 프롬프트에 녹여 제작할 경우 AI 언어 모델이 목표에 부합하는 정확하고 관련성 있는 구체적인 답변을 효과적으로 생성할 수 있다.\nAI 언어 모델과의 효과적인 커뮤니케이션을 위해 프롬프트를 작성할 때 고려해야 할 몇 가지 구성 요소가 있다. 잘 만들어진 프롬프트의 몇 가지 핵심 구성 요소를 다음과 같이 정리할 수 있다:\n\n명확성: 프롬프트는 명확하고 이해하기 쉬워야 한다. 즉, AI 언어모델이 혼동할 수 있는 전문 용어, 은어 또는 모호한 언어는 사용하지 않는다.\n맥락(Context): AI 언어모델이 해결해야 할 주제나 지시 업무를 파악하는 데 도움이 되는 충분한 맥락(Context)를 제공한다. 질문 혹은 요청과 관련된 배경 정보, 구체적인 세부 정보 또는 예시가 포함된다.\n구체성: AI 언어모델이 원하는 답변으로 안내할 수 있도록 프롬프트를 최대한 구체적으로 작성한다. 답변의 형식, 정보의 범위 또는 집중적으로 다루고 싶은 주제의 특정 측면을 지정하는 행위가 포함된다.\n모호성 제거: AI 언어모델이 질문을 오해하거나 관련 없는 답변을 제공할 가능성을 줄이려면 프롬프트에 모호성이 있는지 확인한다. 프롬프트가 여러 가지 의미로 해석될 수 있는 경우, 모호함이 없도록 프롬프트를 다시 작성한다.\n제약 조건: 단어 수 제한이나 주제의 특정 측면과 같은 제약 조건을 포함하면 AI 언어모델이 보다 집중적이고 관련성 높은 답변을 제공하도록 유도할 수 있다. 특히, 광범위한 주제에 대한 정보를 찾거나 간결한 답변을 찾을 때 유용하다.\n지시사항: AI 언어모델이 특정 작업을 수행하거나 특정 방식으로 동작하도록 하려면 프롬프트에 명시적인 지침을 포함한다. 예를 들어, AI에게 장단점을 나열하거나, 두 항목을 비교하거나, 특정 관점을 고려하도록 요청한다.\n\nPrompt Engineering Guide"
  },
  {
    "objectID": "prompt.html#안내지침-프롬프트-기법",
    "href": "prompt.html#안내지침-프롬프트-기법",
    "title": "chatGPT",
    "section": "\n5.1 안내지침 프롬프트 기법",
    "text": "5.1 안내지침 프롬프트 기법\n\n\nPrompt formula: “Generate [task] following these instructions: [instructions]”\n\n\n\n프롬프트 공식: “다음 지침에 따라 [작업]을 생성합니다: [지침]”"
  },
  {
    "objectID": "prompt.html#표준-프롬프트",
    "href": "prompt.html#표준-프롬프트",
    "title": "chatGPT",
    "section": "\n5.1 표준 프롬프트",
    "text": "5.1 표준 프롬프트\n가장 기본적인 프롬프트는 언어모형이 수행할 “[작업]”을 지정하고 다음과 같이 생성하라고 지시명령문을 작성한다.\n\n프롬프트: “[작업]을 생성하라”  예: 다음 뉴스기사를 한 문장으로 요약해 주세요!\n\n챗GPT 플러그인 확장기능을 사용하지 않는 경우 외부 URL을 인식하지 못하기 때문에 프롬프트에 해당 기사를 복사하여 붙여넣기해야한다. 농민신문 버젓이 수입·재배된 LMO 종자…검역당국 뭐했나에 실린 오피니언 사설을 요약해보자.\n\n\n\n\n\n\n프롬프트: 다음 뉴스기사를 한 문장으로 요약해 주세요!\n\n\n\n\n\n미국의 유전자변형생물체(LMO) 종자가 버젓이 수입돼 8년이나 재배돼온 사실이 드러났다. 품목은 주키니호박이다. 제조·가공하면 유전자변형 DNA가 안 남아 식품가공용으로 승인받은 원료 작물에 대해서도 유전자변형농산물(GMO) 표시를 하라고 할 정도로 국민적 반감이 거센데, 재배를 통해 얼마든지 증식할 수 있는 LMO 종자가 해외 직구라는 어엿한 경로를 통해 들어와 장기간 재배됐으니 검역망 허술하기가 한심하기 짝이 없다.\n종자가 함부로 국경을 넘나들어서는 안되는 이유는 국내법은 물론 국제 규약에도 명시됐다. 우리나라 ‘종자산업법’은 생태계 보호 및 자원 보존에 지장을 줄 우려가 있는 종자는 수입을 제한할 수 있다고 했으며, ‘LMO의 국가간 이동 등에 관한 법률’(LMO법)은 생물다양성의 보전 및 지속적 이용에 부정적 영향을 끼칠 수 있는 LMO의 위해를 방지하기 위한 국가의 책무를 적시하고 있다. LMO법은 LMO의 국가간 이동을 규제하는 국제협약인 ’바이오안전성에 관한 카르타헤나 의정서’를 기반으로 하는 만큼 LMO에 대한 우려는 세계 각국이 공히 인정하는 바이기도 하다. 이런데도 LMO 종자가 무사 통관했다는 건 검역당국의 방임이나 능력 부족으로밖에 보이지 않는다.\nLMO 주키니호박 재배·판매 사실이 알려진 후 농림축산식품부가 해당 종자 회수에 나서고 교육부가 학교급식에 주키니호박 사용을 중단한 것은 그만큼 사태가 위중해서다. GMO에 대한 국민적 불신이 반영된 조치다. 양심을 속이고 수입 규정을 어긴 업자를 우선 탓해야 하겠지만, 이런 상황을 막기 위해 검역당국이 존재하는 것 아닌가. 종자는 낱알 크기가 작은 데다 속이려고 작정하면 걸러내기 어렵다는 점을 모르지 않으나 그런 해명이 국민의 공감을 얻기는 어렵다.\n현행 제도상 빈틈이나 구멍을 완벽히 메우기 어렵다면 응당 검역·통관 시스템을 개선하고 위법자에 대한 처벌도 크게 강화하는 것이 마땅하다. 카르타헤나 의정서에도 나와 있듯 LMO의 국가간 이동이 향후 해당국의 생물다양성은 물론 인체 건강에 어떤 부정적 영향을 줄지 알 수 없기 때문이다. 더구나 지금 상태라면 GMO 관련 장벽을 대폭 완화해야 할 것으로 예상되는 인도·태평양 경제프레임워크(IPEF) 시대에 대한 전망도 암울하다. 문턱이 낮아질수록 넘나듦이 쉬운 건 불문가지다.\nAI 응답:\n\n미국 유전자변형생물체(LMO) 종자인 주키니호박이 무사통관돼 국내에서 8년간 재배되어 왔는데, 이는 국내법과 국제 규약을 위반한 것으로 검역망의 부족과 능력 부족으로 보인다는 것과 GMO에 대한 국민적 불신이 반영된 사태이며, 검역·통관 시스템 개선과 위법자에 대한 강화된 처벌이 필요하다는 것이 지적되고 있다.\n\n\n\n\n\n표준 프롬프트 작성 기법에 역할을 추가하면 좀더 의미있는 기사를 작성하게 된다.\n\n\n작업: 삼성 갤럭시 23 핸드폰 후기 작성\n\n작성지침: 후기는 객관적이며 유익한 정보를 담고 있어야 하며 전작과 비교하여 특별히 추가된 기능을 강조해야 된다.\n\n역할: 구매 소비자\n\n씨앗단어: 새로운 기능\n\n\n\n\n\n\n\n프롬프트: “휴대폰을 구매하는 소비자로서 이전 모델과 비교하여 새로운 삼성 갤럭시 23 휴대폰의 고유한 기능을 강조하는 객관적이고 유익한 정보를 담고 있는 휴대폰 리뷰를 작성하세요.”\n\n\n\n\nAI 응답:\n\n최근에 새로운 삼성 갤럭시 23 휴대폰을 구매한 소비자로서, 이전 모델과 비교해 보았을 때 큰 업그레이드가 이루어졌다는 것을 확신할 수 있습니다. 그 중에서 가장 눈에 띄는 특징은 향상된 저조도 성능과 개선된 광학 줌이 있는 강력한 트리플 렌즈 카메라 시스템입니다. 또한, 최신 스냅드래곤 프로세서를 장착해 처리 속도가 향상되어 반응성과 사용자 경험이 더욱 빠르고 더욱 원활해졌습니다.\n\n\n갤럭시 23에는 이전 삼성 모델과 구별되는 여러 가지 고유한 기능이 있습니다. 그 중 하나는 다이나믹 AMOLED 120Hz 디스플레이인데, 화려한 색상과 선명한 대비로 눈에 띄는 시각적 효과를 제공합니다. 또한, 휴대폰의 배터리 크기가 커졌으며 빠른 충전 기능을 갖추고 있어 항상 바쁘게 사용하는 사용자에게 적합합니다.\n\n\n종합적으로, 새로운 삼성 갤럭시 23은 최첨단 기능을 갖춘 최고급 휴대폰을 찾고 있는 분들에게 추천할 만한 가치가 있습니다. 강력한 카메라 시스템, 빠른 처리 속도 및 디스플레이 품질로 인해 경쟁이 치열한 시장에서 뛰어난 장치로 떠오르고 있습니다."
  },
  {
    "objectID": "prompt.html#역할-프롬프트",
    "href": "prompt.html#역할-프롬프트",
    "title": "chatGPT",
    "section": "\n5.2 역할 프롬프트",
    "text": "5.2 역할 프롬프트\nAI 언어모델에 특정 역할을 부여해서 원하는 챗GPT 결과를 도출하도록 지시명령문을 작성한다.\n\n프롬프트: “[역할]로서 [작업]을 생성하라”  예: “통신회사 콜센터 상담원으로 고객문의에 대해 응답을 생성하시오”\n\n\n\n\n\n\n\n프롬프트: 너는 지금부터 케이블 TV 회사의 고객 서비스 담당자로 역할을 수행할 것입니다. 고객이 콜센터로 삼성 갤럭시 23 핸드폰에 문제가 있다고 전화를 걸어왔습니다. 고객에게 응대를 해야하는데 어떻게 응대할지 작성해보세요.\n\n\n\n\nAI 응답:\n\n네, 고객 서비스 담당자로 역할을 수행하겠습니다.\n\n\n고객: 삼성 갤럭시 23 핸드폰을 사용하고 있는데, 전화를 걸거나 문자를 보내려고 할 때마다 화면이 꺼져요.\n\n\n고객 서비스 담당자: 안녕하세요, 삼성 갤럭시 23 핸드폰 고객 서비스입니다. 불편을 드려 죄송합니다. 해당 문제를 해결하기 위해서 몇 가지 질문을 드릴게요. 먼저, 핸드폰을 재부팅해보셨나요? 그리고 핸드폰이 충전이 잘 되고 있는지 확인해 보세요. 만약 이러한 조치가 문제를 해결하지 못한다면, 화면이 자주 꺼지는 경우에는 배터리 절약 모드를 사용하고 있는지 확인해 보세요. 그리고 설정에서 화면 시간을 더 길게 조정해보세요. 만약에 이러한 조치가 문제를 해결하지 못한다면, 저희는 펌웨어 업데이트나 고장 신고 등 추가적인 조치를 취할 수 있도록 도와드리겠습니다. 어떤 조치를 취해 드릴까요?"
  },
  {
    "objectID": "prompt.html#감성-분류",
    "href": "prompt.html#감성-분류",
    "title": "chatGPT",
    "section": "\n5.3 감성 분류",
    "text": "5.3 감성 분류\n텍스트에 내재된 감성도 긍부정 혹은 긍정, 부정, 중립으로 나눠 분류하는 작업도 가능하다.\n\n프롬프트: “[텍스트]의 감성을 긍정과 부정 둘 중 하나로 분류하라”  예: “다음 텍스트의 감성을 긍정과 부정 둘 중 하나로 분류합니다. ‘1%라도 기대했던 내가 죄인입니다 죄인입니다….’”\n\n네이버 영화 감성 말뭉치에서 영화 후기 긍정과 부정을 각각 하나씩 뽑아내서 감성분류 작업을 수행한다.\n\n\n\n\n\n\n\nid\ndocument\nlabel\n\n\n\n5912145\n왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n1\n\n\n9671124\n1%라도 기대했던 내가 죄인입니다 죄인입니다….\n0\n\n\n\n\n\n\n\n\n\n프롬프트: 다음 텍스트의 감성을 긍정과 부정 둘 중 하나로 분류합니다. 답변은 긍정, 부정 중 하나입니다.\n\n\n\n\n\n“왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?”\nAI 응답:\n\n답변: 긍정\n\n\n\n\n\n\n\n\n\n\n\n프롬프트: 다음 텍스트의 감성을 긍정과 부정 둘 중 하나로 분류합니다. 그리고 이유도 제시하여 주세요.\n\n\n\n\n\n“1%라도 기대했던 내가 죄인입니다 죄인입니다….”\nAI 응답:\n\n이 텍스트는 부정적인 감성을 나타냅니다. 이유는 “죄인입니다”라는 문구가 있어서 입니다. 이 문구는 자신에 대한 부정적인 평가를 나타내고 있으며, “1%라도 기대했던”이라는 표현은 자신이 어떤 일을 할 때 기대와 다르게 결과가 나온 것으로 추정됩니다. 이러한 표현들은 부정적인 감정을 나타내고 있으며, 따라서 이 텍스트는 부정적인 감성을 가지고 있습니다."
  },
  {
    "objectID": "prompt.html#텍스트-분류",
    "href": "prompt.html#텍스트-분류",
    "title": "chatGPT",
    "section": "\n5.4 텍스트 분류",
    "text": "5.4 텍스트 분류\n네이버 뉴스기사를 각 뉴스 범주별로 나눠 분류하는 것도 가능하다.\n\n프롬프트: “[텍스트]를 다음 중 하나의 범주로 분류하라; A, B, C”  예: “뉴스기사를 다음 중 하나 범주로 분류해야 합니다; 정치, 경제, 사회, 생활/문화, 세계, 기술/IT, 연예, 스포츠. ‘뉴스 기사’”\n\n다음 사례는 네이버 뉴스 카테고리 데이터셋에서 정치뉴스기사 하나를 가져왔다. 압축파일을 풀면 정치(0), 경제(1), 사회(2), 생활/문화(3), 세계(4), 기술/IT(5), 연예(6), 스포츠(7) 총 8개 범주로 나눠 디렉토리에 텍스트 뉴스기사가 포함되어 있다.\n\n\n\n\n\n\n프롬프트: 뉴스기사를 다음 중 하나 범주로 분류해야 합니다; 정치, 경제, 사회, 생활/문화, 세계, 기술/IT, 연예, 스포츠.\n\n\n\n\n\n동남아 담당’ 北 최희철 부상 베이징 도착…싱가포르행 주목 최 부상, 행선지·방문 목적 질문에는 ‘묵묵부답’\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\n베이징 소식통은 “최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다”며 “만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다”고 말했다.\nAI 응답:\n\n해당 뉴스는 북한의 외교 정책과 관련된 내용이 있어 정치 범주에 속합니다."
  },
  {
    "objectID": "prompt.html#footnotes",
    "href": "prompt.html#footnotes",
    "title": "chatGPT",
    "section": "각주",
    "text": "각주\n\nLearn Prompting↩︎\nPrompt Engineering Guide↩︎"
  },
  {
    "objectID": "prompt.html#인명-추출",
    "href": "prompt.html#인명-추출",
    "title": "chatGPT",
    "section": "\n5.5 인명 추출",
    "text": "5.5 인명 추출\n텍스트에서 사람, 지명, 브랜드 등 기계가 인식해서 추출하는 작업을 통상 개체명인식(NER, Named Entity Recognition) 이라고 한다. GPT-3.5, GPT-4에 따라 성능차이가 다소 있지만 기존 접근법과 비교하여 손색이 없다고 할 수 있다.\n\n프롬프트: “다음 [텍스트]에 대해서 개체명 인식 작업을 수행하고 인물, 조직, 장소로 구분하라.”  예: “다음 뉴스기사에서 개체명을 추출해 주세요. 출력 형식: 인물:  조직:  장소: ”\n\n네이버 뉴스 카테고리 데이터셋에서 정치뉴스기사 하나를 가져왔다.\n\n\n\n\n\n\n프롬프트: 다음 뉴스기사에서 개체명을 추출해 주세요.\n\n\n\n\n\n출력 형식: 인물: &lt;출력결과를 콤마 구분자로 구분&gt;  조직: &lt;출력결과를 콤마 구분자로 구분&gt;  장소: &lt;출력결과를 콤마 구분자로 구분&gt;  날짜: &lt;출력결과를 콤마 구분자로 구분&gt;\n동남아 담당’ 北 최희철 부상 베이징 도착…싱가포르행 주목 최 부상, 행선지·방문 목적 질문에는 ‘묵묵부답’\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\n베이징 소식통은 “최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다”며 “만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다”고 말했다.\nAI 응답:\n\n인물: 최희철, 김진방, 비자이 쿠마르 싱  조직: 연합뉴스, 북한 외무성, 고려항공, 아세안(ASEAN·동남아시아국가연합), 아세안지역안보포럼(ARF), 인도 외교부  장소: 베이징, 서우두(首都) 공항, 평양, 싱가포르, 북한 대사관  날짜: 19일, 20여 일, 지난 3월, 올해 8월, 지난해"
  },
  {
    "objectID": "prompt.html#개체명-추출",
    "href": "prompt.html#개체명-추출",
    "title": "chatGPT",
    "section": "\n5.5 개체명 추출",
    "text": "5.5 개체명 추출\n텍스트에서 사람, 지명, 브랜드 등 기계가 인식해서 추출하는 작업을 통상 개체명인식(NER, Named Entity Recognition) 이라고 한다. GPT-3.5, GPT-4에 따라 성능차이가 다소 있지만 기존 접근법과 비교하여 손색이 없다고 할 수 있다.\n\n프롬프트: “다음 [텍스트]에 대해서 개체명 인식 작업을 수행하고 인물, 조직, 장소로 구분하라.”  예: “다음 뉴스기사에서 개체명을 추출해 주세요. 출력 형식: 인물:  조직:  장소: ”\n\n네이버 뉴스 카테고리 데이터셋에서 정치뉴스기사 하나를 가져왔다.\n\n\n\n\n\n\n프롬프트: 다음 뉴스기사에서 개체명을 추출해 주세요.\n\n\n\n\n\n출력 형식: 인물: &lt;출력결과를 콤마 구분자로 구분&gt;  조직: &lt;출력결과를 콤마 구분자로 구분&gt;  장소: &lt;출력결과를 콤마 구분자로 구분&gt;  날짜: &lt;출력결과를 콤마 구분자로 구분&gt;\n동남아 담당’ 北 최희철 부상 베이징 도착…싱가포르행 주목 최 부상, 행선지·방문 목적 질문에는 ‘묵묵부답’\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\n베이징 소식통은 “최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다”며 “만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다”고 말했다.\nAI 응답:\n\n인물: 최희철, 김진방, 비자이 쿠마르 싱  조직: 연합뉴스, 북한 외무성, 고려항공, 아세안(ASEAN·동남아시아국가연합), 아세안지역안보포럼(ARF), 인도 외교부  장소: 베이징, 서우두(首都) 공항, 평양, 싱가포르, 북한 대사관  날짜: 19일, 20여 일, 지난 3월, 올해 8월, 지난해"
  },
  {
    "objectID": "prompt.html#질의응답",
    "href": "prompt.html#질의응답",
    "title": "chatGPT",
    "section": "\n5.6 질의응답",
    "text": "5.6 질의응답\n지문이 주어진 상태에서 사람이 질문을 하면 기계가 답을 하는 상황이다. 전문적이고 매우 긴 지문에서 원하는 답을 찾기 위해 질문을 하는 상황에서 유용하다.\n\n프롬프트: “다음 [지문]에서 [질문]에 답하시오”  예: “다음 지문을 읽고 답을 찾으세요. 질문: 김현웅은 서울고등검찰청 검사장 재직 중에 몇대 법무부 장관에 임용되었나?\n지문: 김현웅(金賢雄, 1959년 5월 4일 ~ , 전남 고흥)은 … ”\n\nKorQuAD 2.0는 KorQuAD 1.0에서 질문답변 20,000+ 쌍을 포함하여 총 100,000+ 쌍으로 구성된 한국어 Machine Reading Comprehension 데이터셋으로, KorQuAD 1.0과는 다르게 1~2 문단이 아닌 Wikipedia article 전체에서 답을 찾아야 한다. KorQuAD 데이터셋에서 사례를 하나 가져와서 질의응답을 풀어본다.\n\n실제 정답 라벨: [{'text': '제64대', 'answer_start': 209}]\n\n\n\n\n\n\n\n프롬프트: 다음 지문을 읽고 답을 찾으세요.\n\n\n\n\n\n질문: 김현웅은 서울고등검찰청 검사장 재직 중에 몇대 법무부 장관에 임용되었나?\n지문: 김현웅(金賢雄, 1959년 5월 4일 ~ , 전남 고흥)은 대한민국의 법률가이다. 사법연수원 16기 수료 후 검사 생활을 했으며 특히 서울중앙지검 특수1부 부장검사로 재직할 때는 법조브로커 김홍수씨(58·구속)로부터 금품을 받은 혐의(알선수재)로 사상 최초로 전직 고등 법원 부장판사급 법관 A씨에 대해 사전 구속영장을 청구했다. 이후 제46대 서울고등검찰청 검사장 재직 중 제64대 법무부 장관에 임용되었다. 대한변호사협회(회장 김현)가 김현웅(58·사법연수원 16기) 전 법무부 장관에게 변호사 개업을 자제할 것을 권고했다. 변협은 보 도자료를 통해 “김현웅 전 장관은 지난 4월27일 변호사 등록을 신청했고, 현행 변호사법상 등록 거부 사유가 없다”라며 “변호사법은 등록 신청일로부터 3개월간 등록을 하지 않을 경우 등록이 간주된다고 규정하고 있다”라고 설명했다.\nAI 응답:\n\n김현웅은 서울고등검찰청 검사장 재직 중에 제64대 법무부 장관에 임용되었다."
  },
  {
    "objectID": "prompt.html#객관식-문제",
    "href": "prompt.html#객관식-문제",
    "title": "chatGPT",
    "section": "\n5.7 객관식 문제",
    "text": "5.7 객관식 문제\n주어진 4개 중에서 정답을 하나 고르는 문제를 사지선다(四枝選多)형 시험문제로 학창시절부터 접해 친숙하다. 사지선다 문제를 풀고 문제도 생성하는 프롬프트를 제작해보자.\n\n프롬프트: “다음 [선택지] 중에서 정답을 하나 고르세요.”  예: “다음 문제에서 정답을 하나 고르세요. 문제: 통계에서 모든 경우의 수를 포함하는 집합을 일컷는 용어는?\n\n표본 공간(Sample Space)\n포함집합(Super Set)\n포함공간(Super Space)\n표본집합(Sample Set) ”\n\n\n\n정답과 이유도 추가하고 유사한 사지선다형 문제를 몇개 만들어 지시한다.\n\n\n\n\n\n\n\n프롬프트: 통계에서 두 변수 간의 상관 관계를 나타내는 지수는?\n\n\n\n\n\n\n중앙값(Median)\n평균(Average)\n분산(Variance)\n상관계수(Correlation Coefficient)\n\nAI 응답:\n\n정답: 4. 상관계수(Correlation Coefficient) 이유: 통계에서 두 변수 간의 관련성을 측정하는 방법 중 하나가 상관계수입니다. 상관계수는 -1에서 1 사이의 값을 가지며, 1에 가까울수록 양의 상관관계, -1에 가까울수록 음의 상관관계, 0에 가까울수록 상관관계가 없다는 것을 의미합니다."
  },
  {
    "objectID": "open_source.html",
    "href": "open_source.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 스테이블 디뷰젼\nGuido Appenzeller, Matt Bornstein, Martin Casado, and Yoko Li, “Art Isn’t Dead, It’s Just Machine-Generated - Why AI models will replace artists long before they’ll replace programmers”\n오픈 소스 AI 모델 Stable Diffusion V1은 전 세계적으로 수백 개의 다른 모델과 혁신을 낳았다. 두 달도 채 되지 않아 33,000개의 별을 돌파하며 모든 소프트웨어 중 가장 빠르게 Github 별 10,000개에 도달했고, 이는 이전의 다른 혁신적인 기술 비트코인, 이더리움, 카프카, 스파크 등과 비교하면 그 파급력이 갈음된다. 최근 공개(March 24, 2023)된 Stable Diffusion V2는 GitHub stablediffusion에서 확인 가능하다.\n\n\n\n\n\n2 메타 라마\n페이스북으로 잘 알려진 메타(Meta)는 연구 목적(비상업적 사용)으로 라마(LLaMA) 거대언어모형을 오픈소스 소프트웨어로 2023년 2월 24일 공개했다. LLaMA는 라틴어와 키릴 문자를 사용하는 20개 언어의 텍스트를 학습하여 다양한 크기(7B, 13B, 33B, 65B 매개변수) 언어모형 형태로 공개되어 거대언어모형을 대중화하고 연구자들이 새로운 접근 방식과 사용 사례를 테스트할 수 있는 취지로 공개되었지만, 여전히 편향성, 독성, 잘못된 정보 등 추가적인 보완이 필요하다.\nMetaAI (February 24, 2023), “Introducing LLaMA: A foundational, 65-billion-parameter large language model”, MetaAI Blog\n\n3 GPT4All\nGPT4All은 메타 LLaMa에 기반하여 GPT-3.5-Turbo 데이터를 추가학습한 오픈소스 챗봇이다. 설치는 간단하고 사무용이 아닌 개발자용 성능을 갖는 컴퓨터라면 그렇게 느린 속도는 아니지만 바로 활용이 가능하다. 문제는 한국어 지원은 되지 않는다는 것이다. 이유는 LLaMA가 라틴어와 키릴 문자를 사용하는 20개 언어 텍스트를 학습했기 때문이다.\n설치 방식은 GPT4All을 git clone 혹은 저장소를 다운로드받아 압축을 푼 다음 gpt4all-lora-quantized.bin을 chat\\ 디렉토리 아래 복사하여 넣은 다음 윈도우의 경우 gpt4all-lora-quantized-win64.exe 파일을 실행하면 된다. gpt4all-lora-quantized.bin 파일이 4GB 조금 넘는 크기라 Sosaka/GPT4All-7B-4bit-ggml 에서 좀더 빠르게 다운로드 받을 수 있다.\n\n#&gt; ../../gpt4all\n#&gt; ├── chat\n#&gt; │   ├── gpt4all-lora-quantized-linux-x86\n#&gt; │   ├── gpt4all-lora-quantized-OSX-intel\n#&gt; │   ├── gpt4all-lora-quantized-OSX-m1\n#&gt; │   ├── gpt4all-lora-quantized-win64.exe\n#&gt; │   └── gpt4all-lora-quantized.bin\n#&gt; ├── clean.py\n#&gt; ├── configs\n#&gt; │   ├── deepspeed\n#&gt; │   │   └── ds_config.json\n#&gt; │   ├── eval\n#&gt; │   │   ├── generate.yaml\n#&gt; │   │   ├── generate_baseline.yaml\n#&gt; │   │   ├── generate_full.yaml\n#&gt; │   │   ├── generate_large_2.yaml\n#&gt; │   │   └── generate_large_3.yaml\n#&gt; │   ├── generate\n#&gt; │   │   ├── generate.yaml\n#&gt; │   │   └── generate_llama.yaml\n#&gt; │   └── train\n#&gt; │       ├── finetune.yaml\n#&gt; │       └── finetune_lora.yaml\n#&gt; ├── data.py\n#&gt; ├── env.yaml\n#&gt; ├── eval_data\n#&gt; │   └── user_oriented_instructions.jsonl\n#&gt; ├── eval_figures.py\n#&gt; ├── eval_self_instruct.py\n#&gt; ├── figs\n#&gt; │   ├── duplicate_loss.png\n#&gt; │   ├── first_lora.png\n#&gt; │   ├── perplexity_hist.png\n#&gt; │   └── single_epoch.png\n#&gt; ├── generate.py\n#&gt; ├── gpt4all-lora-demo.gif\n#&gt; ├── peft\n#&gt; ├── read.py\n#&gt; ├── README.md\n#&gt; ├── requirements.txt\n#&gt; ├── train.py\n#&gt; ├── TRAINING_LOG.md\n#&gt; └── transformers\n\n윈도우 탐색기에서 gpt4all-lora-quantized-win64.exe 파일을 두번 클릭하면 GPT4All 모형을 다운로드 받아 바로 사용이 가능하다. 대한민국의 수도도 정확히 알려주고 파이썬 코드도 작성해준다.\n\n\n\n\n정규분포에서 표본을 추출하는 코드를 작성해 달라고 요청했으나 코드에 오류가 있어 수정하여 정상적인 결과 비교하자.\n\n\n\ngpt4all\n\nimport numpy as np\nfrom scipy import stats\n\ndef sample_n_gpt4all(N):\n  return [stats.norm.rvs() for _ in range(int((2*N+1)*np.sqrt(3)))] \n\nfor element in sample_n_gpt4all(1):\n    print(f\"{element:.2f}\")\n#&gt; 0.22\n#&gt; 0.93\n#&gt; 1.36\n#&gt; -0.52\n#&gt; -1.40\n\n\n\n수정 코드\n\nimport numpy as np\nfrom scipy import stats\n\ndef sample_n(N):\n    samples = [stats.norm.rvs() for _ in range(N)]\n    return samples\n\nsample_n(1)\n#&gt; [-1.9273661876919912]"
  },
  {
    "objectID": "nlp_LLM.html",
    "href": "nlp_LLM.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 자연어 처리\n자연어 처리는 컴퓨터로 하여금 사람이 작성한 언어(음성과 글)의 의미를 이해시키는 것을 목표로 한다.\n\n텍스트 데이터\n\n트위터\n소설, 신문기사\n고객 평점과 리뷰\n전자우편\n의무기록\n…\n\n\n텍스트 저장 형식\n\n뉴스 등 웹 페이지\nPDF/워드/한글 문서\n트위터 등 SNS, RSS 피드, 댓글\n…\n\n\n응용분야\n\n감성분석\n텍스트 분류\n번역\n챗봇\n개인 비서\n…\n\n\n기술\n\n단어주머니(Bag of Words)\nWord Embedding, 워드투벡(Word2Vec)\nRNN, LSTM\nBERT, Transformer\nGPT, 거대언어모형(LLM)\n…\n\n\n\n2 작업흐름\n감성 분석 및 텍스트 분류 등 텍스트를 데이터로 하는 전통적인 자연어 처리 작업은 다음과 같은 작업흐름을 갖게 된다.\n\n\n\n\n\n\ngraph TD\n    A[데이터 수집] --&gt; B[데이터 전처리]\n    B --&gt; C[피쳐 추출]\n    C --&gt; D[훈련-테스트 데이터셋 분할]\n    D --&gt; E[모형 선택]\n    E --&gt; F[모형 학습]\n    F --&gt; G[모형 평가]\n    G --&gt; H[하이퍼파라미터 튜닝]\n    H --&gt; I[모형 배포]\n    I --&gt; J[모니터링 및 유지보수]\n\n\n\n\n\n\n\n데이터 수집: 텍스트 데이터와 해당 레이블이 포함된 데이터셋을 수집한다. 감성 분석의 경우, 라벨은 ‘긍정’, ‘부정’ 또는 ’중립’이 되고, 텍스트 분류의 경우 레이블은 다양한 주제나 카테고리를 나타낼 수 있다. 즉, 자연어 처리 목적에 맞춰 라벨을 특정하고 연관 데이터를 수집한다.\n데이터 전처리: 텍스트 데이터를 정리하고 전처리하여 추가 분석에 적합하도록 작업하는데 소문자화, 토큰화, 불용어 제거, 특수문자 제거, 어간 단어 기본형으로 줄이기 등이 포함된다.\n피쳐 추출:사전 처리된 텍스트를 기계 학습 알고리즘에 적합한 숫자 형식으로 변환하는 과정으로 BoW, TF-IDF, 단어 임베딩 등이 흔히 사용되는 기법이다.\n훈련-시험 데이터셋 분할: 일반적으로 70-30, 80-20 또는 기타 원하는 분할 비율을 사용하여 데이터셋을 훈련과 시험 데이터셋으로 구분한다.\n모형 선택: 적합한 통계, 머신 러닝, 딥러닝 모델을 선정한다.\n모형 학습: 적절한 최적화 알고리즘과 손실 함수를 사용하여 훈련 데이터셋에서 선택한 모델을 학습시킨다.\n모형 평가: 정확도, 정밀도, 리콜, F1 점수 또는 ROC 곡선 아래 영역과 같은 관련 메트릭을 사용하여 시험 데이터셋에서 학습 모형의 성능을 평가한다.\n하이퍼파라미터 튜닝: 격자 검색 또는 무작위 검색과 같은 기술을 사용하여 모형의 하이퍼파라미터를 최적화하여 성능을 개선한다.\n모형 배포: 모형을 학습하고 최적화한 후에는 실제 환경에서 사용할 수 있도록 실제 운영 환경에 배포하여 가치를 창출한다.\n모니터링 및 유지 관리: 배포된 모형의 성능을 지속적으로 모니터링하고 필요에 따라 새로운 학습데이터로 업데이트하여 정확성과 효율성을 유지한다.\n\n\n\n\n3 자연어 처리 작업\n자연어 처리 분야에서 흔히 접하는 상위 10가지 NLP으로 다음을 들 수 있다.\n\n감정 분석: 긍정, 부정, 중립 등 주어진 텍스트에 표현된 감정을 파악.\n텍스트 분류: 텍스트 데이터를 미리 정의된 클래스 또는 주제(예: 스포츠, 정치, 연예 등)로 분류.\n개체명 인식(NER): 텍스트 내에서 사람, 조직, 위치, 날짜 등의 명명된 개체(entity)를 식별하고 분류.\n품사(POS) 태깅: 주어진 텍스트의 단어에 문법적 레이블(예: 명사, 동사, 형용사)을 할당.\n의존성 구문 분석: 문장 내 단어 간의 문법 구조와 관계를 식별.\n기계 번역: 영어에서 스페인어로 또는 중국어에서 프랑스어로와 같이 한 언어에서 다른 언어로 텍스트를 번역.\n질의 응답: 자연어로 제기된 질문을 이해하고 답변할 수 있는 시스템을 개발.\n텍스트 요약: 주요 아이디어와 정보를 보존하면서 주어진 텍스트에 대한 간결한 요약을 생성.\n상호참조해결(Coreference Resolution): 텍스트에서 두 개 이상의 단어나 구가 동일한 개체 또는 개념을 지칭하는 경우 식별.\n텍스트 생성: 주어진 입력, 컨텍스트 또는 일련의 조건에 따라 일관되고 의미 있는 텍스트를 생성.\n\n자연어 처리 작업과 작업흐름을 서로 연결하게 되면 다음과 같이 개별적으로 중복되고 분리된 작업을 수행하게 되는 문제가 있다.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;\n\n\n\n\n\n\n4 비교\n\n\n\n\ngraph TB\n\nsubgraph \"거대언어기반 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nsubgraph \"전통적인 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;\n\n\n\n\n\n\n\n\n\n\ngraph TB\nsubgraph \"미세조정 작업흐름&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[사전 훈련] --&gt; B1[미세 조정]\n  B1 --&gt; C1[모델 훈련 및 평가]\n  C1 --&gt; D1[하이퍼파라미터 튜닝]\n  D1 --&gt; E1[배포 및 유지보수]\nend\n\nsubgraph \"프롬프트 공학 작업흐름&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[사전 학습] --&gt; B2[프롬프트 설계]\n  B2 --&gt; C2[모델 추론 및 후처리]\n  C2 --&gt; D2[모델 평가]\n  D2 --&gt; E2[배포 및 유지보수]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "openAI_GPT.html#gpt-3",
    "href": "openAI_GPT.html#gpt-3",
    "title": "chatGPT",
    "section": "",
    "text": "GPT-3은 자연어 처리 및 생성을 담당하는 모델로 인간의 언어 즉, 자연어처럼 보이는 텍스트를 이해할 수 있다. 한걸음 더 들어가면 속도와 성능에 따라 4가지 모델(A, B, C, D)로 구분된다.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\n성능기준으로 보면 다음과 같이 정렬할 수 있는데 비용도 그에 따라 높아진다는 의미도 함축한다.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\n따라서, OpenAI는 다빈치 모델(text-davinci-003)을 통해 원하는 결과를 얻은 후에 다른 모델을 사용해 볼 것을 권장하는데 이유는 훨씬 저렴한 비용으로 많은 수의 유사한 작업을 수행할 수 있기 때문이다.\n\n2,048개의 토큰 및 2019년 10월까지의 데이터 학습하여 이후 모형과 비교하여 정확도나 성능에서 다소 밀리는 모습이지만 최적화를 통해 매우 빠르고 비용이 가장 저렴하다.\n\n2,048개의 토큰과 2019년 10월까지의 데이터 학습되었고 간단한 분류와 의미론적 분류에 효과적이다.\n\n최대 2048개의 토큰을 지원하며 text-davinci-003 다음으로 뛰어난 성능을 보이는 GPT-3 모델이다. 2019년 10월까지의 데이터로 학습되었기 때문에 text-davinci-003보다 정확도가 떨어지지만, 번역, 복잡한 분류, 텍스트 분석 및 요약에 좋은 성능을 보이고 있어 text-davinci-003와 비교하여 가성비가 높다고 평가되고 있다.\n\n2021년 9월까지의 데이터로 훈련되었기 때문에 최신 정보를 제공하지 못한다는 한계는 있지만, 앞선 GPT-3 모형과 비교하여 더 높은 품질을 제공한다. 장점 중 하나는 최대 4,000개 토큰까지 요청할 수 있다는 점이 이전 모형과 큰 차별점이 된다."
  },
  {
    "objectID": "openAI_GPT.html#코덱스codex",
    "href": "openAI_GPT.html#코덱스codex",
    "title": "chatGPT",
    "section": "",
    "text": "코덱스는 프로그래밍 코드 이해 및 생성을 위한 것으로 code-davinci-002와 code-cushman-001가 있다. 또한, 코덱스는 GitHub Copilot을 구동하는 모델이기도 하다. 파이썬, 자바스크립트, 고, 펄, PHP, 루비, 스위프트, 타입스크립트, SQL, 셸 등 12개 이상의 프로그래밍 언어를 지원할 뿐만 아니라 자연어로 표현된 주석(comment)를 이해하고 사용자를 대신하여 요청된 작업을 수행할 수 있다.\n\n복잡한 작업을 수행하는 데 있어서는 code-davinci-002가 더 강력하지만, 많은 코드 생성 작업을 수행할 수 있고 code-davinci-002 보다 더 빠르고 저렴하다는 장점이 있다.\n\n자연어를 코드로 번역하는 데 탁월할 뿐만 아니라 코드를 자동 완성할 뿐만 아니라 보충 요소 삽입도 지원한다. 최대 8,000개의 토큰을 처리할 수 있으며 2021년 6월까지의 데이터로 학습되었다."
  },
  {
    "objectID": "openAI_GPT.html#콘텐츠-필터",
    "href": "openAI_GPT.html#콘텐츠-필터",
    "title": "chatGPT",
    "section": "",
    "text": "민감한 콘텐츠 제거하기 위한 필터 모형이다. 민감하거나 안전하지 않을 수 있는 API 생성 텍스트를 감지할 수 있다. 사용자가 사용할 AI 응용프로그램을 개발할 경우, 필터를 사용하여 모델이 부적절한 콘텐츠를 반환하는지 감지할 수 있다. 이 필터는 텍스트를 다음 3가지 범주로 나눈다.\n\n안전(safe)\n민감(sensitive)\n안전하지 않음(unsafe)"
  },
  {
    "objectID": "openAI_GPT.html#텍스트-벡터-표현",
    "href": "openAI_GPT.html#텍스트-벡터-표현",
    "title": "chatGPT",
    "section": "\n2.1 텍스트 벡터 표현",
    "text": "2.1 텍스트 벡터 표현\ntext-embedding-ada-002 모델은 빠르고 가성비가 뛰어난 임베딩 모델이다. “대한민국 수도는 서울입니다.” 이라는 문서를 벡터로 표현하면 다음과 같다. 즉, 1,536 차원을 갖는 공간에 하나의 점으로 표현될 수 있다.\n\nimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"대한민국 수도는 서울입니다.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'벡터길이: {len(seoul_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {seoul_embedding[:10]}')\n#&gt; 벡터 일부: [0.014487667009234428, -0.018017204478383064, 0.004892932251095772, -0.013761372305452824, -0.03111599199473858, 0.02515272982418537, -0.034505367279052734, 0.011550633236765862, -0.008014724589884281, -0.0020355363376438618]\n\n마찬가지로 일본의 수도 도쿄도 벡터로 표현할 수 있다.\n\ntokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"일본 수도는 동경입니다.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'벡터길이: {len(tokyo_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {tokyo_embedding[:10]}')\n#&gt; 벡터 일부: [0.010912451893091202, -0.013220978900790215, 0.009697099216282368, -0.011883447878062725, -0.03176635876297951, 0.03446714207530022, -0.02981150709092617, 0.008616785518825054, 0.017156407237052917, -0.0014468483859673142]"
  },
  {
    "objectID": "gpt-security.html",
    "href": "gpt-security.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 챗GPT 보안사고\n보안 vs 효율 을 높고 많은 공공기관을 비롯한 기업들이 고민을 하고 있다. 거대언어모형(LLM)에 기반하여 모든 것을 자체 개발하면 상관이 없으나 현실적으로 GPT-3/3.5/4 모형을 갖춘 조직이 전무하지만, 이미 대다수의 사람이 오픈AI 챗GPT를 맛보았기 때문에 생산성 향상을 그냥 두고 넘어가기도 어려운 상황이다. 이런 점에서 챗GPT 제한적 사용이 현재시점(’23년 3월) 최선으로 보이며 점차 오픈소스 거대언어모형(LLM)과 전략적 제휴를 통한 챗GPT 사용이 중장기적 추진방향으로 자리 잡고 있다.\n이동수 (2023.04.02.), “대기업 회의 내용 유출… ‘챗GPT 기밀 유출’ 우려가 현실로”, 세계일보\n\n\n\n\n\n2 삼성전자\n\n정두용 (2023-03-30), “우려가 현실로…삼성전자, 챗GPT 빗장 풀자마자 ‘오남용’ 속출”, 이코노미스트\n\n\n삼성전자 DS 부문 임직원 A씨는 반도체 설비 계측 데이터베이스(DB) 다운로드 프로그램의 소스 코드를 실행 중 오류를 확인했다. 문제가 된 소스 코드 전부를 복사해 챗GPT에 입력, 해결 방법을 문의했다. 삼성전자 설비 계측과 관련한 소스 코드가 오픈AI 학습 데이터로 입력된 셈이다.\n\n\n임직원 B씨는 수율·불량 설비 파악을 위해 작성한 프로그램 코드를 챗GPT에 입력하는 사고를 냈다. 관련 소스 전체를 챗GPT에 입력하고 코드 최적화를 요청했다. 임직원 C씨는 스마트폰으로 녹음한 회의 내용을 네이버 클로바 애플리케이션(앱)을 통해 문서 파일로 변환한 뒤 챗GPT에 입력했다. 회의록 작성 요청이 목적이다.\n\n\n3 이탈리아\n\n민재용 (2023.04.02), “이탈리아도 챗GPT ‘차단’…서방 국가중 처음”, 한국일보\n\n\n로이터 통신 등에 따르면 이탈리아 데이터 보호청은 “챗GPT가 이탈리아의 개인정보 보호 기준과 규정을 충족할 때까지 서비스 접속을 일시적으로 차단할 것”이라고 밝혔다.\n\n\n접속 차단 이유는 개인정보 침해 우려 때문이다. 이탈리아 당국은 챗GPT가 알고리즘 학습을 이유로, 개인정보를 대량으로 수집하고 저장하는 행위를 정당화할 법적 근거가 없다고 지적했다. 보호청은 챗GPT 개발사 오픈AI가 20일 이내에 해결책을 내놓지 않으면 전 세계 매출액의 최대 4%에 달하는 벌금을 물게 될 것이라고 경고하기도 했다."
  },
  {
    "objectID": "prompt_adv.html",
    "href": "prompt_adv.html",
    "title": "chatGPT",
    "section": "",
    "text": "The hottest new programming language is English\n\n— Andrej Karpathy ((karpathy?)) January 24, 2023\n\n기계학습과 예전 신경망 모형이 특정 작업을 위해 설계된 특수 목적의 컴퓨터라면, GPT는 자연어 프로그램을 실행하기 위해 런타임에 재구성되는 범용 컴퓨터다. 처음 프롬프트[일종의 시작(inception)]가 프로그램 형태로 제공되고, 거대언어모형(GPT)는 문서를 완성하도록 프로그램을 실행한다.\n\n1 Few-Shot 학습\nGPT-3 논문 (Brown 기타, 2020) 에서 거대언어모형(LLM)이 컨텍스트 내 학습(in-context learning)을 수행하며, 입력:출력 예제를 통해 프롬프트 내에서 다양한 작업을 수행하도록 “프로그래밍”할 수 있음을 시연했다. 즉, 언어 모델을 확장하면 작업별 미세 조정(Fine-tuning) 없이 몇 가지 예제 또는 간단한 지침만으로 수행작업의 성능향상을 기대해볼 수 있다.\n\n\n\n\n전통적인 미세조정(Fine tuning)과 제로샷, 원샷, 퓨샷과 대비하면 명확해진다. 미세조정(Fine tuning)은 전통적인 방법이지만, 제로샷, 원샷, 퓨샷은 순방향으로 작업을 수행하는 모델을 필요로 한다.\n\n\n\n\n\n\n제로샷 학습 예제:\n\n\n\n\n\n작업: 감성 분석 (주어진 텍스트를 긍정적, 부정적, 중립적으로 분류)\n입력: “어제 놀이공원에서 정말 즐거운 하루를 보냈어요!”\n출력: 긍정적 \n\n\n\n\n\n\n\n\n\n원샷 학습 예제:\n\n\n\n\n\n작업: 주어진 텍스트로 설명된 동물 파악하기\n예시: “이 동물은 긴 목과 반점이 특징인데, 아프리카에서 발견할 수 있어요.” 답변: 기린\n입력: “이 동물은 주머니가 있고 호주 원주민이며, 껑충 뛰는 능력으로 유명해요.”\n출력 : 캥거루\n\n\n\n\n\n\n\n\n\n퓨샷 학습 예제:\n\n\n\n\n\n작업: 주어진 문장을 능동태에서 수동태로 바꾸기\n예시 1: “철수가 샌드위치를 먹었다.” 답변: “샌드위치가 철수에게 먹혔다.”\n예시 2: “고양이가 쥐를 쫓았다.” 답변: “쥐가 고양이에게 쫓겼다.”\n입력: “선생님이 학생을 칭찬했다.”\n출력: “학생이 선생님에게 칭찬받았다.”\n\n\n\n\n2 Chain-of-Thought (CoT)\n작업별 예제 없이 거대언어모형(LLM)에 사고의 사슬(Chain of Thought)를 통해 복잡한 다단계 추론이 가능하다. 각 답변 앞에 “단계별로 생각해 봅시다(Let’s think step by step)”를 추가함으로써 산술, 기호 추론, 논리적 추론과 같은 다양한 추론 작업에서 표준 제로샷 프롬프트보다 훨씬 뛰어난 성능을 발휘했다. (Kojima 기타, 2023)\n\n\n\n\nGPT-Turbo, GPT-4 모델은 해당문제를 바로 정확히 풀 수 있으나 Legacy (GPT-3.5)는 CoT 기법을 적용해야 정답을 이끌어낼 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n그림 1: 사고의 사슬(Chain of Thought) 예제\n\n\n명령어 자동 생성 및 선택을 위한 자동 프롬프트 엔지니어(Automatic Prompt Engineer, APE)는 프롬프트 명령(instruction)을 프로그램으로 간주하고 거대언어모형(LLM)이 제안한 대한 선택지를 검색하여 선택한 목적 함수를 최대화하는 명령어를 최적화시킨 다음 선택한 명령어를 다른 LLM을 사용하여 평가하는 방법도 제시되었다. (Zhou 기타, 2023)\n\n3 성과지표 설정\n잘 작성된 프롬프트에는 원하는 목표 성과가 포함되어야 한다. GPT는 최선을 다해 성공을 추구하지 않고 모방만 할 뿐이다. 좋은 결과를 원한다면 달성해야 되는 성공을 명시해야 한다. (Chen 기타, 2021)\n\n\n영문예시 10개\n국문번역 10개\n\n\n\n“Please provide a step-by-step guide on how to achieve top-tier performance in time management and productivity techniques, so I can excel in my personal and professional life.”\n“I aspire to become an exceptional public speaker. Can you offer me comprehensive advice, including tips, tricks, and exercises that will help me develop outstanding presentation skills?”\n“I am determined to become a top-performing sales professional. Share with me the essential skills, strategies, and habits that I must adopt to excel in this competitive field.”\n“I wish to become a highly respected and successful leader. Could you provide insights, examples, and actionable steps to develop strong leadership qualities and excel in any organization?”\n“I desire to master the art of negotiation and achieve win-win outcomes. Please provide me with detailed guidance, best practices, and real-life examples that will enable me to excel in negotiations.”\n“My goal is to become a top performer in project management. Can you outline the key principles, methodologies, and tools that will help me successfully manage projects and exceed expectations?”\n“I aspire to be an excellent writer, able to captivate my audience and inspire them through my words. Please provide me with writing techniques, exercises, and recommendations that will elevate my writing skills to the highest level.”\n“I am determined to achieve peak physical fitness and athletic performance. Share with me the best workout routines, nutrition tips, and mental strategies that will help me reach my full potential as an athlete.”\n“I want to excel in the art of problem-solving and critical thinking. Please provide me with the necessary tools, frameworks, and exercises that will help me become an exceptional problem solver and thinker.”\n“My goal is to become a highly skilled and successful investor. Can you provide me with the most effective strategies, tips, and resources that will enable me to outperform in the world of investing?”\n\n\n“시간 관리 및 생산성 기술에서 최고 수준의 성과를 달성하는 방법에 대한 단계별 가이드를 제공하여 개인 및 직장 생활에서 탁월함을 발휘할 수 있도록 도와주세요.”\n“저는 뛰어난 대중 연설가가 되고 싶습니다. 뛰어난 프레젠테이션 기술을 개발하는 데 도움이 되는 팁, 요령 및 연습 문제를 포함한 포괄적인 조언을 제공해 주시겠습니까?”\n“최고의 성과를 내는 영업 전문가가 되기로 결심했습니다. 경쟁이 치열한 이 분야에서 뛰어난 성과를 내기 위해 반드시 갖춰야 할 필수 기술, 전략 및 습관을 알려주세요.”\n“존경받고 성공적인 리더가 되고 싶습니다. 강력한 리더십 자질을 개발하고 어떤 조직에서든 뛰어난 성과를 낼 수 있는 인사이트, 사례, 실행 가능한 단계를 알려주시겠어요?”\n“협상의 기술을 습득하여 서로 윈윈하는 결과를 얻고 싶습니다. 협상에서 탁월한 능력을 발휘할 수 있도록 자세한 지침, 모범 사례 및 실제 사례를 제공해 주세요.”\n“제 목표는 프로젝트 관리 분야에서 최고의 성과를 내는 것입니다. 프로젝트를 성공적으로 관리하고 기대치를 초과 달성하는 데 도움이 되는 핵심 원칙, 방법론 및 도구를 간략하게 설명해 주시겠습니까?”\n“저는 글을 통해 청중을 사로잡고 영감을 줄 수 있는 훌륭한 작가가 되고 싶습니다. 제 글쓰기 실력을 최고 수준으로 끌어올릴 수 있는 글쓰기 기법, 연습 문제, 권장 사항을 제공해 주세요.”\n“최고의 체력과 운동 능력을 갖추기 위해 노력하고 있습니다. 운동선수로서 제 잠재력을 최대한 발휘하는 데 도움이 될 최고의 운동 루틴, 영양 팁, 정신 전략을 알려주세요.”\n“문제 해결 능력과 비판적 사고력이 뛰어나고 싶습니다. 뛰어난 문제 해결자이자 사상가가 되는 데 도움이 되는 필요한 도구, 프레임워크, 연습 문제를 제공해 주세요.”\n“제 목표는 고도로 숙련되고 성공적인 투자자가 되는 것입니다. 투자 세계에서 뛰어난 성과를 낼 수 있는 가장 효과적인 전략, 팁, 리소스를 제공해 주실 수 있나요?”\n\n\n\n참고 자료: 김민경 (2023. 3. 31.), “프롬프트 엔지니어링, AI라는 도구를 잘 사용하는 방법”, Kakaoenterprise Tech Trend\n\n4 자기 일관성\n기존 사고 사슬(Chain of Thought)의 한계를 넘어서 제시된 자기 일관성(Self-consistency)은 복잡한 추론 문제에서 일반적으로 고유한 정답으로 이어지는 여러 가지 사고 방식을 인정한다는 직관을 활용한다. (Wang 기타, 2023)\n자기 일관성 기법은 다음 3단계를 거쳐 최종 답을 제시한다.\n\n사고의 사슬(CoT) 프롬프트를 사용하여 거대언어모형에 프롬프트 생성한다.\nCoT 프롬프트가 “Greedy Decoding” 최선을 추구하는 반면, 거대언어모형 디코더에서 표본을 추출하여 다양한 추론 경로 집합을 생성한다.\n\n\n추론 경로를 한계화하고 최종 답변 세트에서 가장 일관된 답변을 선택 및 집계하여 제시한다.\n\n\n\n\n\n\n\n\n\n\n\n질문: 제가 6살이었을 때 제 여동생은 제 나이의 절반이었습니다. 지금은 70살입니다. 제 여동생은 몇 살인가요?\n\n\n\n\n\n\n당신이 6살이었을 때 여동생은 당신의 나이의 절반이었으므로, 여동생은 당신보다 3살 어렸습니다. 지금 당신이 70살이니, 여동생은 여전히 당신보다 3살 어립니다. 따라서 여동생은 70 - 3 = 67살입니다.\n\n\n\n\n\n5 Generated Knowledge Prompting\n생성된 지식 프롬프트(Generated Knowledge Prompting)는 몇 번의 데모를 통해 언어 모델에서 질문과 관련된 지식 진술을 이끌어내고, 해당 지식이 있는 다른 언어 모델에 프롬프트를 표시하여 예측을 유도하는 기법이다. (Liu 기타, 2022)\n\n언어 모델에서 질문과 관련된 지식 진술을 생성하기 위해 몇 장면의 데모를 사용.\n제2언어 모델을 사용하여 각 지식 진술에 대해 예측을 한 다음 가장 신뢰도가 높은 예측을 취사선택.\n\n\n\n\n\n\n\nGPT-4\nLegacy (GPT-3.5)\n\n\n\n\n\n\n\n\n\n질문: 골프 게임은 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 것입니다. 예, 아니오?\n\n\n\n\n\n지식: 골프의 목표는 최소한의 스트로크로 일련의 홀을 플레이하는 것입니다. 골프 라운드는 일반적으로 18홀로 구성됩니다. 각 홀은 표준 골프 코스에서 라운드 중 한 번씩 플레이됩니다. 각 스트로크는 1점으로 계산되며, 총 스트로크 수가 게임의 승자를 결정하는 데 사용됩니다.\n\n아니오, 골프의 목표는 다른 사람보다 더 높은 총점을 얻는 것이 아닙니다. 대신, 최소한의 스트로크로 일련의 홀을 완주하는 것이 목표입니다. 골프에서는 각 스트로크가 1점으로 계산되며, 라운드 종료 시점에서 스트로크 수가 가장 적은 선수가 승자로 간주됩니다. 따라서 골프에서는 점수가 낮을수록 좋습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n질문: 골프 게임은 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 것입니다. 예, 아니오?\n\n\n\n\n\n\n예, 골프 게임은 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 게임입니다.\n\n\n\n\n\n\n\n\n6 가상 컴퓨터\n출처: Engraved (3rd December 2022), “Building A Virtual Machine inside ChatGPT”\nChatGPT 내부에서 전체 가상 컴퓨터를 만들어 실행시킬 수 있다. 가상 컴퓨터는 파일 시스템 작동 방식을 이해하고 프로그래밍도 가능하다.\n\n\n\n\n\n\n챗GPT를 가상컴퓨터로 바꾸는 프롬프트\n\n\n\n\n\n“I want you to act as a Linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do no write explanations. Do not type commands unless I instruct you to do so. When I need to tell you something in English I will do so by putting text inside curly brackets {like this}. My first command is pwd.”\n“네가 리눅스 터미널 역할을 해줬으면 좋겠어. 내가 명령을 입력하면 터미널이 표시해야 할 내용을 회신해 주세요. 하나의 고유한 코드 블록 안에 있는 터미널 출력만 회신하고 다른 것은 회신하지 마세요. 설명을 작성하지 마세요. 제가 지시하지 않는 한 명령을 입력하지 마세요. 영어로 설명해야 할 때는 {이렇게}와 같이 중괄호 안에 텍스트를 넣어 설명합니다. 첫 번째 명령은 ls입니다.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 2: 챗GPT 내부 리눅스 가상 컴퓨터\n\n\n\n\n\n\n\n참고문헌\n\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners. https://arxiv.org/abs/2005.14165\n\n\nChen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., & Mordatch, I. (2021). Decision Transformer: Reinforcement Learning via Sequence Modeling. https://arxiv.org/abs/2106.01345\n\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. https://arxiv.org/abs/2205.11916\n\n\nLiu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2022). Generated Knowledge Prompting for Commonsense Reasoning. https://arxiv.org/abs/2110.08387\n\n\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. https://arxiv.org/abs/2203.11171\n\n\nZhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large Language Models Are Human-Level Prompt Engineers. https://arxiv.org/abs/2211.01910"
  },
  {
    "objectID": "nlp_LLM.html#대표적인-nlp-작업",
    "href": "nlp_LLM.html#대표적인-nlp-작업",
    "title": "chatGPT",
    "section": "\n1.1 대표적인 NLP 작업",
    "text": "1.1 대표적인 NLP 작업\n숫자가 아닌 텍스트를 통해 가치를 창출할 수 있는 분야가 자연어처리(NLP) 영역이다. 자연어 처리 분야에서 흔히 접하는 대표적인 상위 10가지 NLP으로 다음을 들 수 있다.\n\n감정 분석: 긍정, 부정, 중립 등 주어진 텍스트에 표현된 감정을 파악.\n텍스트 분류: 텍스트 데이터를 미리 정의된 클래스 또는 주제(예: 스포츠, 정치, 연예 등)로 분류.\n개체명 인식(NER): 텍스트 내에서 사람, 조직, 위치, 날짜 등의 명명된 개체(entity)를 식별하고 분류.\n품사(POS) 태깅: 주어진 텍스트의 단어에 문법적 레이블(예: 명사, 동사, 형용사)을 할당.\n의존성 구문 분석: 문장 내 단어 간의 문법 구조와 관계를 식별.\n기계 번역: 영어에서 스페인어로 또는 중국어에서 프랑스어로와 같이 한 언어에서 다른 언어로 텍스트를 번역.\n질의 응답: 자연어로 제기된 질문을 이해하고 답변할 수 있는 시스템을 개발.\n텍스트 요약: 주요 아이디어와 정보를 보존하면서 주어진 텍스트에 대한 간결한 요약을 생성.\n상호참조해결(Coreference Resolution): 텍스트에서 두 개 이상의 단어나 구가 동일한 개체 또는 개념을 지칭하는 경우 식별.\n텍스트 생성: 주어진 입력, 컨텍스트 또는 일련의 조건에 따라 일관되고 의미 있는 텍스트를 생성.\n\n자연어 처리 작업과 작업흐름을 서로 연결하게 되면 다음과 같이 개별적으로 중복되고 분리된 작업을 수행하게 되는 문제가 있다.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;"
  },
  {
    "objectID": "nlp_LLM.html#nlp-기계학습",
    "href": "nlp_LLM.html#nlp-기계학습",
    "title": "chatGPT",
    "section": "\n2.1 NLP 기계학습",
    "text": "2.1 NLP 기계학습\n자연어처리(NLP) 기계학습은 통계모형과 거의 비슷한 작업흐름을 갖는다. 차이점이 있다면 데이터 관계의 설명보다 예측에 더 중점을 둔다는 점이라고 볼 수 있다. 예를 들어, 감성 분석 및 텍스트 분류 등 텍스트를 데이터로 하는 전통적인 자연어 처리 작업은 다음과 같은 작업흐름을 갖게 된다.\n\n\n\n\n\n\ngraph TD\n    A[데이터 수집] --&gt; B[데이터 전처리]\n    B --&gt; C[피쳐 추출]\n    C --&gt; D[훈련-테스트 데이터셋 분할]\n    D --&gt; E[모형 선택]\n    E --&gt; F[모형 학습]\n    F --&gt; G[모형 평가]\n    G --&gt; H[하이퍼파라미터 튜닝]\n    H --&gt; I[모형 배포]\n    I --&gt; J[모니터링 및 유지보수]\n\n\n\n\n\n\n\n데이터 수집: 텍스트 데이터와 해당 레이블이 포함된 데이터셋을 수집한다. 감성 분석의 경우, 라벨은 ‘긍정’, ‘부정’ 또는 ’중립’이 되고, 텍스트 분류의 경우 레이블은 다양한 주제나 카테고리를 나타낼 수 있다. 즉, 자연어 처리 목적에 맞춰 라벨을 특정하고 연관 데이터를 수집한다.\n데이터 전처리: 텍스트 데이터를 정리하고 전처리하여 추가 분석에 적합하도록 작업하는데 소문자화, 토큰화, 불용어 제거, 특수문자 제거, 어간 단어 기본형으로 줄이기 등이 포함된다.\n피쳐 추출:사전 처리된 텍스트를 기계 학습 알고리즘에 적합한 숫자 형식으로 변환하는 과정으로 BoW, TF-IDF, 단어 임베딩 등이 흔히 사용되는 기법이다.\n훈련-시험 데이터셋 분할: 일반적으로 70-30, 80-20 또는 기타 원하는 분할 비율을 사용하여 데이터셋을 훈련과 시험 데이터셋으로 구분한다.\n모형 선택: 적합한 통계, 머신 러닝, 딥러닝 모델을 선정한다.\n모형 학습: 적절한 최적화 알고리즘과 손실 함수를 사용하여 훈련 데이터셋에서 선택한 모델을 학습시킨다.\n모형 평가: 정확도, 정밀도, 리콜, F1 점수 또는 ROC 곡선 아래 영역과 같은 관련 메트릭을 사용하여 시험 데이터셋에서 학습 모형의 성능을 평가한다.\n하이퍼파라미터 튜닝: 격자 검색 또는 무작위 검색과 같은 기술을 사용하여 모형의 하이퍼파라미터를 최적화하여 성능을 개선한다.\n모형 배포: 모형을 학습하고 최적화한 후에는 실제 환경에서 사용할 수 있도록 실제 운영 환경에 배포하여 가치를 창출한다.\n모니터링 및 유지 관리: 배포된 모형의 성능을 지속적으로 모니터링하고 필요에 따라 새로운 학습데이터로 업데이트하여 정확성과 효율성을 유지한다."
  },
  {
    "objectID": "nlp_LLM.html#nlp-vs-llm",
    "href": "nlp_LLM.html#nlp-vs-llm",
    "title": "chatGPT",
    "section": "\n3.1 NLP vs LLM",
    "text": "3.1 NLP vs LLM\n지구상의 거의 모든 텍스트 데이터를 학습한 거대언어모형(LLM)이 존재하는 상황이기 때문에 적절한 LLM을 선택한 후에 좀더 성능을 높이기 위해서 추가 학습데이터를 수집하여 미세조정(Fine-tuning) 학습을 거친 후에 AI 모형을 배포하여 운영한다.\n\n\n\n\ngraph TB\n\nsubgraph \"전통적인 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nsubgraph \"거대언어기반 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "nlp_LLM.html#fine-tuning-llm-vs-prompt-eng.",
    "href": "nlp_LLM.html#fine-tuning-llm-vs-prompt-eng.",
    "title": "chatGPT",
    "section": "\n3.2 Fine-tuning LLM vs Prompt Eng.",
    "text": "3.2 Fine-tuning LLM vs Prompt Eng.\n두가지 접근방법 모두 거대언어모형(LLM)에 기반한다는 점에서 동일하나, 추가학습 데이터를 반영한 AI 모형을 개발하느냐 아니면 프롬프트(일명 AI 프로그램)를 잘 작성한 AI 모형을 개발하느냐 차이가 존재한다. 물론 Zero-/One-/Few-Shot 예제를 반영한 프롬프트도 있고 미세조정 훈련모형에 프롬프트를 반영한 AI 모형도 존재한다. 각 문제에 맞춰 적절한 개발방법을 취하면 될 것이다.\n\n\n\n\ngraph TB\nsubgraph \"미세조정 작업흐름&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[사전 훈련] --&gt; B1[미세 조정]\n  B1 --&gt; C1[모델 훈련 및 평가]\n  C1 --&gt; D1[하이퍼파라미터 튜닝]\n  D1 --&gt; E1[배포 및 유지보수]\nend\n\nsubgraph \"프롬프트 공학 작업흐름&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[사전 학습] --&gt; B2[프롬프트 설계]\n  B2 --&gt; C2[모델 추론 및 후처리]\n  C2 --&gt; D2[모델 평가]\n  D2 --&gt; E2[배포 및 유지보수]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "nlp_LLM.html#비교-1",
    "href": "nlp_LLM.html#비교-1",
    "title": "chatGPT",
    "section": "\n3.3 비교",
    "text": "3.3 비교\nLLM 모형을 오픈소스 소프트웨어 공개하는 경우 이를 돌릴 수 있는 강력한 하드웨어가 필요하기도 하고, LLM을 비공개하는 경우 구독형으로 비용을 청구하여 AI 서비스를 제공하는 경우도 존재한다. 해당 문제를 가장 잘 해결할 수 있는 AI 개발방법론을 주어진 제약조건에서 장단점을 비교하여 풀어가면 좋은 결과가 기대된다.\n\n\n\n\n\n\n\n\nPerspective\nTraditional NLP\nLLM Fine-tuning\nLLM Prompt Engineering\n\n\n\nModel Adaptation\nFeature extraction and model selection\nFine-tuning on task-specific data\nCrafting effective prompts\n\n\nLabeled Data Requirements\nRequires labeled data for model training\nRequires labeled data for fine-tuning\nRequires fewer labeled examples, if any\n\n\nComputational Resources\nCan vary, but generally lower than LLM Fine-tuning\nHigher due to fine-tuning\nLower, as fine-tuning is not required\n\n\nPerformance\nMay be lower than LLM-based approaches\nTypically better due to task-specific fine-tuning\nCompetitive, but may require more manual effort\n\n\nEffort and Creativity\nRequires more manual feature engineering\nRequires less manual effort in prompt design\nRequires more creativity in prompt design and iteration\n\n\nDomain Adaptation\nLess effective for domain-specific tasks\nMore effective for domain-specific tasks\nMay be limited by the pretrained model’s knowledge\n\n\nInterpretability\nMore interpretable due to handcrafted features and models\nLess interpretable due to fine-tuned model weights\nMore interpretable as output is guided by designed prompts\n\n\nDeployment and Maintenance\nRequires storing and maintaining custom models\nRequires storing and maintaining fine-tuned models\nEasier, as only pretrained model and prompts are needed\n\n\nWhen to Use\nWhen custom features are needed or LLMs are not available\nWhen labeled data is available, higher performance is desired, and computational resources are sufficient\nWhen labeled data is scarce, computational resources are limited, or rapid development and iteration are required"
  }
]