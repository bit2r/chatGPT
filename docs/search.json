[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 근간모형 개발자\n\n\n\n\n\n2 AI 응용제품 개발자\n\n\n\n\n\n3 AI 제품 사용자"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "chatGPT가 연 새로운 시대를 데이터 과학자와 함께 합니다."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "블로그",
    "section": "",
    "text": "AI가 쏘아올린 작은 공\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAI가 기존 데이터 과학 패러다임을 바꾸고 있습니다.\n\n\n\n\n\n\n2023년 04월 20일\n\n\n이광춘\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\n비쥬얼 스튜디오 코드 IDE를 사용하여 개발 생산성을 높인다.\n\n\n\n\n\n\n2023년 01월 26일\n\n\n이광춘\n\n\n\n\n\n\n일치 없음"
  },
  {
    "objectID": "codex.html",
    "href": "codex.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 Codex\nLow-code and GPT-3: easier said than done with OpenAI Codex\n\n주석을 코드로 전환\n맥락을 보고 다음 코드를 자동 작성\n라이브러리, API 등 추천을 통해 새로운 지식 전달\n주석 자동 추가\n동일한 기능을 갖지면 효율성 좋은 코드로 변환\n\n2 이미지 생성\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nastronaut <- image_read(response$data$url)\nprint(astronaut)\n#> # A tibble: 1 × 7\n#>   format width height colorspace matte filesize density\n#>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n#> 1 PNG      256    256 sRGB       FALSE   197109 72x72\n\n\n\n\n\n\n\n\n3 예측모형\n\n코드penguins_classification_instruction <- \n  glue::glue(\"# R language\\n\",\n             \"Build sex classification machine learning model withe palmer penguin datatset\\n\",\n             \"Use palmer penguins data package for dataset\\n\",\n             \"Use tidymodels framework\\n\",\n             \"Use random forest model\\n\",\n             \"Include evaluation metrics including accruacy, precision, reall\")\n\nbuild_model <- create_completion(\n    model=\"code-davinci-002\",\n    prompt = penguins_classification_instruction,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\n\n\n코드\nparsed_code <- str_split(build_model$choices$text, \"\\n\")[[1]]\n\nwrite_lines(parsed_code, \"palmer_penguins.Rmd\")"
  },
  {
    "objectID": "deepL.html",
    "href": "deepL.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 deeplR 패키지\n한국에서는 서비스가 되지 않아 API를 사용할 수 없어요… 근데 일본은 ㅎㅎ\n\n코드library(deeplr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "hf.html",
    "href": "hf.html",
    "title": "chatGPT",
    "section": "",
    "text": "파이썬을 계속 사용하다보니 무조건 가상환경을 사용해야 한다는 걸 절실히 느끼게 된다. 시간이 지나면 어떤 패키지들을 설치했었는지 확인이 되지 않고 어떤 것이 문제가 되어 잘 돌던 코드가 제대로 실행되지 않는지 파악이 힘드는 지경에 이르게 된다.\n파이썬3에서 venv, virtualenv 두가지 가상환경 팩키지가 제공되는데 선택을 해야한다. 결론은 파이썬3에서 venv가 지원되니 별도 패키지 설치없이 venv로 가는 것이 좋다.\n\npython3 -m venv &lt;가상환경 명칭&gt;\nsource &lt;가상환경 명칭&gt;/bin/activate\npip install -U pip\npip install pandas\npip freeze &gt; requirements.txt\n\n가상환경 생성부터 주요한 가상환경 설정 방법을 순차적으로 파악해보자.\n\n\n생성\n활성화\n파이썬\npip 설치\n판다스 설치\nfreeze\nrequirements.txt\n가상환경 구조\ndeactivate\n\n\n\npy-3.10.9 tidyverse in ~/venv\n○ → python3 -m venv venv\n\n\npy-3.10.9 tidyverse in ~/venv\n○ → source venv/bin/activate\n\n## .\\venv\\Scripts\\activate ## 윈도우즈\n\n\n○ → which python\n/Users/tidyverse/venv/venv/bin/python\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install -U pip\nRequirement already satisfied: pip in ./venv/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Using cached pip-23.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install pandas\nCollecting pandas\n  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 5.7 MB/s eta 0:00:00\nCollecting pytz&gt;=2020.1\n  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\nCollecting numpy&gt;=1.20.3\n  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.8/19.8 MB 4.3 MB/s eta 0:00:00\nCollecting python-dateutil&gt;=2.8.1\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting six&gt;=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, six, numpy, python-dateutil, pandas\nSuccessfully installed numpy-1.24.2 pandas-1.5.3 python-dateutil-2.8.2 pytz-2022.7.1 six-1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze\nnumpy==1.24.2\npandas==1.5.3\npython-dateutil==2.8.2\npytz==2022.7.1\nsix==1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze &gt; requirements.txt\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → tree -L 2\n.\n├── requirements.txt\n└── venv\n    ├── bin\n    ├── include\n    ├── lib\n    └── pyvenv.cfg\n\n4 directories, 2 files\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → deactivate\n\npy-3.10.9 tidyverse in ~/venv\n○ →"
  },
  {
    "objectID": "hf.html#환경-설정",
    "href": "hf.html#환경-설정",
    "title": "chatGPT",
    "section": "환경 설정",
    "text": "환경 설정\n파이썬 가상환경을 준비하고 transformers 및 연관 패키지를 설치한다.\n\n코드library(reticulate)\n\nuse_python(\"~/venv/venv/bin/python\")\nreticulate::py_config()\nreticulate::py_available()\n\nreticulate::py_install(\"transformers\", pip = TRUE)\nreticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)"
  },
  {
    "objectID": "hf.html#감정-분류",
    "href": "hf.html#감정-분류",
    "title": "chatGPT",
    "section": "\n3.1 감정 분류",
    "text": "3.1 감정 분류\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n코드library(reticulate)\nlibrary(tidyverse)\n\nuse_python(\"~/venv/venv/bin/python\")\n\ntext &lt;- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers &lt;- reticulate::import(\"transformers\")\n\n# model_name &lt;- \"bert-base-uncased\"\n# model &lt;- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier &lt;- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs &lt;- classifier(text)\n\n# Convert predictions to tibble\noutputs %&gt;% \n  pluck(1) %&gt;% \n  as_tibble()"
  },
  {
    "objectID": "hf.html#ner",
    "href": "hf.html#ner",
    "title": "chatGPT",
    "section": "\n3.2 NER",
    "text": "3.2 NER\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n코드# Download model for ner task\nner_tagger &lt;- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs &lt;- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r &lt;- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %&gt;% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %&gt;% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))"
  },
  {
    "objectID": "hf.html#질의응답",
    "href": "hf.html#질의응답",
    "title": "chatGPT",
    "section": "\n3.3 질의응답",
    "text": "3.3 질의응답\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n코드# Specify task\nreader &lt;- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion &lt;-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs &lt;- reader(question = question, context = text)\noutputs %&gt;% \n  as_tibble()"
  },
  {
    "objectID": "hf.html#요약",
    "href": "hf.html#요약",
    "title": "chatGPT",
    "section": "\n3.4 요약",
    "text": "3.4 요약\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n코드summarizer &lt;- transformers$pipeline(\"summarization\")\noutputs &lt;- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs"
  },
  {
    "objectID": "hf.html#번역",
    "href": "hf.html#번역",
    "title": "chatGPT",
    "section": "\n3.5 번역",
    "text": "3.5 번역\nLanguage Technology Research Group at the University of Helsinki 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n코드# This requires python package sentencepiece\nsentencepiece &lt;- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator &lt;- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs &lt;- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs"
  },
  {
    "objectID": "hf.html#텍스트-생성",
    "href": "hf.html#텍스트-생성",
    "title": "chatGPT",
    "section": "\n3.6 텍스트 생성",
    "text": "3.6 텍스트 생성\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가 반응을 자동생성시켜 답신을 작성할 수 있다.\n\n코드generator &lt;- transformers$pipeline(\"text-generation\")\nresponse &lt;- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt &lt;- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs &lt;- generator(prompt, max_length = 200L)\n\noutputs %&gt;% \n  pluck(1, \"generated_text\") %&gt;% \n  cat()"
  },
  {
    "objectID": "hf.html#참고문헌",
    "href": "hf.html#참고문헌",
    "title": "chatGPT",
    "section": "\n3.7 참고문헌",
    "text": "3.7 참고문헌\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "hf_windows.html",
    "href": "hf_windows.html",
    "title": "chatGPT",
    "section": "",
    "text": "reticulate, “Installing Python Packages”\n\n\n생성\n환경 확인\n사용시작\n\n\n\nreticulate 패키지 conda_create() 함수로 새로운 환경을 생성한다.\n\n코드library(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n\n\n\n\nreticulate::py_available() 명령어로 파이썬 환경을 활용가능한지 확인하고 reticulate::py_config() 상세한 위치를 파악한다.\n\n코드library(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n\n\n\n\nuse_python() 함수로 파이썬 위치를 특정하고 관련 패키지 설치를 시작한다. 준비된 파이썬 가상환경에 transformers 및 연관 패키지를 설치한다.\n\n코드\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)"
  },
  {
    "objectID": "hf_windows.html#감정-분류",
    "href": "hf_windows.html#감정-분류",
    "title": "chatGPT",
    "section": "\n2.1 감정 분류",
    "text": "2.1 감정 분류\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n코드library(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf_windows.html#ner",
    "href": "hf_windows.html#ner",
    "title": "chatGPT",
    "section": "\n2.2 NER",
    "text": "2.2 NER\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n코드# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf_windows.html#질의응답",
    "href": "hf_windows.html#질의응답",
    "title": "chatGPT",
    "section": "\n2.3 질의응답",
    "text": "2.3 질의응답\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n코드# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf_windows.html#요약",
    "href": "hf_windows.html#요약",
    "title": "chatGPT",
    "section": "\n2.4 요약",
    "text": "2.4 요약\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n코드summarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf_windows.html#번역",
    "href": "hf_windows.html#번역",
    "title": "chatGPT",
    "section": "\n2.5 번역",
    "text": "2.5 번역\nLanguage Technology Research Group at the University of Helsinki 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n코드# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\""
  },
  {
    "objectID": "hf_windows.html#텍스트-생성",
    "href": "hf_windows.html#텍스트-생성",
    "title": "chatGPT",
    "section": "\n2.6 텍스트 생성",
    "text": "2.6 텍스트 생성\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가 반응을 자동생성시켜 답신을 작성할 수 있다.\n\n코드generator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you"
  },
  {
    "objectID": "hf_windows.html#참고문헌",
    "href": "hf_windows.html#참고문헌",
    "title": "chatGPT",
    "section": "\n2.7 참고문헌",
    "text": "2.7 참고문헌\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "image2image.html",
    "href": "image2image.html",
    "title": "chatGPT",
    "section": "",
    "text": "openai 패키지 create_image() 함수를 사용하여 이미지를 제작할 수 있다.\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "interview.html",
    "href": "interview.html",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n기계학습 분류모형개발할 때 클래스 불균형(class imbalance) 문제를 어떻게 처리하나요?\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n기계학습모형에서 bias 와 variance trade-off에서 존재합니다. 어떤 기계학습 모형이 bias 와 variance를 줄이는데 효과적으로 알려져 있나요?\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n리스트와 데이터프레임 자료구조의 차이점에 대해서 말씀해 주세요.\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansing이 어떻게 다른지 설명하세요.\n\n\n\n\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n제품 설명 등 텍스트 필드 칼럼이 있습니다. 기계학습 알고리즘 분류나 예측 모형에 적용시킬 수 있는 방법을 설명해주세요."
  },
  {
    "objectID": "interview.html#visualization",
    "href": "interview.html#visualization",
    "title": "chatGPT",
    "section": "\n2.1 Visualization",
    "text": "2.1 Visualization\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\nData Analytics에서 시각화는 매우 중요합니다. 어떻게 가르칠것인지 커러큘럼, 교수방법, 프로젝트 진행방법, 평가방법에 대해서 말씀해주세요. (5분)"
  },
  {
    "objectID": "interview.html#eda",
    "href": "interview.html#eda",
    "title": "chatGPT",
    "section": "\n2.2 EDA",
    "text": "2.2 EDA\n\n\n\n\n\n\n질문/과제\n\n\n\n\n\n탐색적 데이터 분석(EDA)가 훌륭한 기계학습 알고리즘 개발과 함께 매우 중요합니다. 어떻게 가르칠것인지 커러큘럼, 교수방법, 프로젝트 진행방법, 평가방법에 대해서 말씀해주세요. (5분)"
  },
  {
    "objectID": "koGPT.html",
    "href": "koGPT.html",
    "title": "chatGPT",
    "section": "",
    "text": "R 패키지\n\nhuggingfaceR\ntext\n\n\n블로그\n\nR, Reticulate, and Hugging Face Models\nHello Transformers from R\n\n\n\n\nreticulate 최신버전을 설치하고 나서, miniconda를 설치한다. 기존 설치된 경우 install_miniconda(force = TRUE) 인자를 넣어 재설치한다.\n\n코드remotes::install_github(\"rstudio/reticulate\")\nreticulate::install_miniconda(force = TRUE)\n\n\n\n\n\n\n\n\n노트\n\n\n\nminiconda 설치에 어려움이 생긴경우 rminiconda가 대안이 될 수 있다.\n\nrminiconda\n\n\n\n\n\n코드devtools::install_github(\"farach/huggingfaceR\")\n\n\n\nhuggingfaceR README.md 파일에 실린 헬로월드 텍스트 분류 모형을 돌려보자.\n\n코드library(huggingfaceR)\nlibrary(reticulate)\n\nuse_python(\"C:/Users/statkclee/AppData/Local/r-miniconda/envs/huggingfaceR/python.exe\")\n# hf_python_depends('transformers') # 빠진 라이브러리 설치\n\ndistilBERT <- hf_load_pipeline(\n  model_id = \"distilbert-base-uncased-finetuned-sst-2-english\", \n  task = \"text-classification\")\n\ndistilBERT(\"I like you. I love you\")\n#> [[1]]\n#> [[1]]$label\n#> [1] \"POSITIVE\"\n#> \n#> [[1]]$score\n#> [1] 0.9998739"
  },
  {
    "objectID": "koGPT.html#인기-모형",
    "href": "koGPT.html#인기-모형",
    "title": "chatGPT",
    "section": "\n2.1 인기 모형",
    "text": "2.1 인기 모형\n다운로드 횟수가 많은 hugginface 모형은 다음과 같다.\n\n코드library(reactable)\nmodels %>% \n  select(-private, -sha) %>% \n  reactable::reactable(\n    searchable = TRUE, minRows = 10,\n    columns = list(downloads = colDef(format = colFormat(separators  = TRUE)),\n                   model = colDef(align = \"center\"),\n                   task = colDef(align = \"center\")))"
  },
  {
    "objectID": "math.html",
    "href": "math.html",
    "title": "chatGPT",
    "section": "",
    "text": "GPT-4의 구체적인 기능이나 개선 사항은 아직 공개되지 않았지만, 일반적으로 후속 모델은 이전 모델보다 성능이 개선되는 것이 대부분이다. GPT-4의 추론능력이 GPT-3.5와 비교하여 어떤 부분이 개선되었는지 다음과 같이 예측해볼 수 있다:\n특히, GPT-4는 추론역량(Reasoning)이 이전 모델과 비교하여 향상된 것이 확인된다."
  },
  {
    "objectID": "middle_school.html#한글질문-준비",
    "href": "middle_school.html#한글질문-준비",
    "title": "chatGPT",
    "section": "\n2.1 한글질문 준비",
    "text": "2.1 한글질문 준비\n\nlibrary(tidyverse)\nlibrary(openai)\n\nkorean_question <- \"중학교에서 수학에서 나오는 연립방정식을 설명해줘\"\nkorean_question\n#> [1] \"중학교에서 수학에서 나오는 연립방정식을 설명해줘\""
  },
  {
    "objectID": "middle_school.html#질문번역",
    "href": "middle_school.html#질문번역",
    "title": "chatGPT",
    "section": "\n2.2 질문번역",
    "text": "2.2 질문번역\n\n\nkorean_question_input <- glue::glue(\"translate it into English: {korean_question}\")\n\nquestion_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = korean_question_input,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ntranslated_questions <- str_extract(question_model$choices$text, \"\\\\b[^\\\\W].+\\\\b\")\n\ntranslated_questions\n#> [1] \"Explain the system of linear equations that comes from middle school math\""
  },
  {
    "objectID": "middle_school.html#chatgpt-영문-답변",
    "href": "middle_school.html#chatgpt-영문-답변",
    "title": "chatGPT",
    "section": "\n2.3 chatGPT 영문 답변",
    "text": "2.3 chatGPT 영문 답변\n\n\nanswer_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = translated_questions,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nchatGPT_answer <- answer_model$choices$text\ncat(chatGPT_answer)\n#> \n#> \n#> A system of linear equations is a set of two or more linear equations that contains the same variables. The equations are usually referred to as simultaneous equations, as they are usually solved together.\n#> \n#> In the context of middle school math, a linear equation generally consists of two variables, and the equations are primarily used to solve problems involving rate, distance, and time. The general form of a linear equation is y=mx+b, where m is the slope of the line, x is the independent variable, and b is the y-intercept. The slope and y-intercept can be found by plotting the points that make up the equation on a graph. \n#> \n#> Once the slope and y-intercept have been determined, other linear equations can be written by substituting different values for the slope and y-intercept. For example, if the slope of a linear equation is m=5 and the y-intercept is b=3, then the equation can be written as y=5x+3. Different values can also be plugged into the equation to solve for either x or y.\n#> \n#> In a system of linear equations, two equations are combined to form one equation. By solving both equations simultaneously, a more general solution can be found. This process is usually done by using elimination, substitution, or graphing. Once the solution has been found, it can be used to answer questions about the relationships between the variables."
  },
  {
    "objectID": "middle_school.html#chatgpt-답변-번역",
    "href": "middle_school.html#chatgpt-답변-번역",
    "title": "chatGPT",
    "section": "\n2.4 chatGPT 답변 번역",
    "text": "2.4 chatGPT 답변 번역\n\n\nchatGPT_answer_request <- glue::glue(\"한국어로 번역해주세요: {chatGPT_answer}\")\n\nreturn_model <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = chatGPT_answer_request,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(return_model$choices$text)\n#> \n#> \n#> 회귀방정식은 동일한 변수를 포함하는 두 개 이상의 선형방정식들의 시스템입니다. 이 방정식들은 일반적으로 동시 방정식으로 불리며, 같이 풀릴 때가 많습니다.\n#> \n#> 중학교 수학에서의 선형방정식은 일반적으로 두 개의 변수를 가지며, 이 방정식들은 비율이나 거리, 시간 등 문제를 풀때 많이 사용됩니다. 선형방정식의 일반적인 형태는 y=mx+b 입니다. 여기서 m은 선의 기울기, x는 독립변수, b는 y절편입니다. 기울기와 y절편은 방정식의 점들을 그래프에 그려 구할 수 있습니다.\n#> \n#> 기울기와 y절편이 결정되면 다른 값들로 선형방정식을 작성할 수도 있습니다. 예를 들어, 선형 방정식의 기울기가 m=5이고 y절편이 b=3인 경우, y=5x+3으로 방정식을 작성할 수 있습니다. 또한 다른 값들을 방정식에 대입하여 x값 또는 y값을 구할 수도 있습니다.\n#> \n#> 회귀방정식 시스템들은 두 개의 방정식을 하나의 방정식으로 결합합니다. 두 방정식을 동시에 풀게 되어 상대적으로 더 일반적인 해답을 구할 수 있습니다."
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html",
    "href": "posts/20230126-vscode/ide_vscode.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "R을 설치한다.\n\nlanguageserver 패키지를 설치한다.\n\n\ninstall.packages(\"languageserver\")\n\n\nVisual Studio Code 에서 R extension을 설치한다.\n\n.R 파일에 개발을 시작한다.\n\n\nR extension을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. VS Code 에 필수적인 R extension은 다음을 꼽을 수 있다. R extension을 설치하면 RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 편리하다.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Code를 실행하고 R Extension 설치\n\n\n\nR Extension 설치되면 코드 창 상단에 실행버튼이 활성화되고 Ctrl + Enter 혹은 Ctrl + Shift + Enter\n\n\nR 코드 실행화면"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "href": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "title": "Visual Studio Code",
    "section": "keybindings.json",
    "text": "keybindings.json\nkeybindings.json 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 등록시킨다. 자료출처: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: '이광춘'\\ndate: '2023-01-31'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#html-미리보기",
    "href": "posts/20230126-vscode/ide_vscode.html#html-미리보기",
    "title": "Visual Studio Code",
    "section": "HTML 미리보기",
    "text": "HTML 미리보기\n.Rmd 파일을  CTRL  +  Shift  +  k  단축키로 컴파일시키면 .html 파일이 생성된다. .html 파일 결과를 직접 실시간으로 확인하고자 한다면, 마이크로소프트가 개발한 Live Preview - VS Code Extension 플러그인을 설치한다."
  },
  {
    "objectID": "posts/20230127-ide/ide_war.html",
    "href": "posts/20230127-ide/ide_war.html",
    "title": "AI가 쏘아올린 작은 공",
    "section": "",
    "text": "데이터 과학 편집기\n데이터 과학 제품과 서비스 개발을 위해서 IDE(통합개발환경)을 두고 RStudio와 Jupyter 두 진영으로 나눠 치열한 경쟁을 펼쳤다. 각자 장점을 두고 범위를 확대하면서 진정한 데이터 과학 패자가 되고자 한편의 드라마를 펼쳤다.\n그 중심에는 RStudio와 아나콘다가 있으며 마치 현대차와 기아차처럼 동일한 자동차인데 세부 구성과 디자인에 차이만 있을 뿐 어느 것이 더 우월하고 좋다는 마케팅을 펼쳤다.\n\n\n\n마이크로소프트의 등장\n데이터 과학 편집기에 Visual Studio Code가 등장하면서 큰 변화가 일어나고 있다. 특히 인공지능 기능을 탑재한 Extension이 VS Code에 추가되면서 기존 RStudio와 쥬피터 IDE가 하던 기능을 넘어 새로운 지평을 열어가고 있다.\n그 중심에는 GitHub을 마이크로소프트가 인수하면서 새로 출시한 부조종사(Copilot)이 있고 조만간 CodeGPT도 도입되면 기존 RStudio와 Jupyter는 기존과 전혀 다른 위상을 가지게 될 것으로 보인다."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 백만 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다."
  },
  {
    "objectID": "rcoding.html",
    "href": "rcoding.html",
    "title": "chatGPT",
    "section": "",
    "text": "Low-code and GPT-3: easier said than done with OpenAI Codex\n코덱스(Codex)는 OpenAI에서 개발한 획기적인 AI 기술로, 사용자가 입력한 질문에 응답하여 사람과 유사한 텍스트를 생성할 수 있다. 딥러닝 알고리즘을 사용하여 책, 기사 및 기타 형태의 서면 콘텐츠를 포함한 방대한 양의 텍스트 데이터를 분석하여 언어와 문맥에 대한 포괄적인 이해를 바탕으로 텍스트를 생성한다.코덱스는 챗봇, 가상 비서, 글쓰기 도구 등 다양한 애플리케이션과 통합하여 사용자에게 자연스럽고 유창한 텍스트 응답을 제공한다.\n코덱스의 프로그래밍 기능은 가장 강력한 애플리케이션 중 하나로 방대한 양의 코드와 문서를 분석하여 사용자가 제공한 지시명령어(Prompt)에 응답하여 코드 스니펫(Snippet)을 생성할 수 있으므로 코드를 보다 효율적이고 정확하게 작성해야 하는 개발자에게 매우 유용한 도구로 자리잡아가고 있다.\n코덱스는 파이썬, 자바, C++, R 등 다양한 프로그래밍 언어와 함께 사용할 수 있으며, 현재 코드 맥락(Context)에 따라 전체 함수나 클래스를 생성할 수 있으며, 구문적으로 정확하고 모범 사례(Best Practice)를 따르는 코드를 제안함으로써 코드 작성에 필요한 시간과 노력을 줄여 개발자가 새로운 기능을 설계하거나 기존 기능을 개선하는 등 보다 복잡한 작업에 집중할 수 있게 한다.\n코덱스의 프로그래밍 기능의 주요 이점 중 하나는 생성하는 코드의 의미와 목적을 이해한다는 점이다. 즉, 작동할 뿐만 아니라 구조적으로 강건하고 읽기 쉬운 코드를 제안하여 오류를 줄이고 코드베이스의 전반적인 품질을 개선하는 데 도움을 준다. 전반적으로 코덱스의 프로그래밍 기능은 개발자의 코드 작성 방식에 혁신을 가져올 잠재력을 가지고 있다.\n\n주석을 코드로 전환\n맥락을 보고 다음 코드를 자동 작성\n라이브러리, API 등 추천을 통해 새로운 지식 전달\n주석 자동 추가\n동일한 기능을 갖지면 효율성 좋은 코드로 변환"
  },
  {
    "objectID": "rcoding.html#주석달기",
    "href": "rcoding.html#주석달기",
    "title": "chatGPT",
    "section": "\n5.1 주석달기",
    "text": "5.1 주석달기"
  },
  {
    "objectID": "rcoding.html#roxygen-추가",
    "href": "rcoding.html#roxygen-추가",
    "title": "chatGPT",
    "section": "\n5.2 Roxygen 추가",
    "text": "5.2 Roxygen 추가"
  },
  {
    "objectID": "rcoding.html#스크립트-함수",
    "href": "rcoding.html#스크립트-함수",
    "title": "chatGPT",
    "section": "\n5.3 스크립트 → 함수",
    "text": "5.3 스크립트 → 함수"
  },
  {
    "objectID": "rcoding.html#함수에-단위-테스트-추천",
    "href": "rcoding.html#함수에-단위-테스트-추천",
    "title": "chatGPT",
    "section": "\n5.4 함수에 단위 테스트 추천",
    "text": "5.4 함수에 단위 테스트 추천"
  },
  {
    "objectID": "reticulate.html",
    "href": "reticulate.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 파이썬 환경 설정\nreticulate 패키지로 콘다 파이썬 환경을 구축한다. 필요한 경우 패키지도 설치한다.\nRiddhiman (Apr 19, 2022), ‘Getting started with Python using R and reticulate’\n\n코드# install.packages(\"reticulate\")\nlibrary(reticulate)\n\n# conda_list()\nuse_condaenv(condaenv = \"r-reticulate\")\n\n# py_install(packages = c(\"pandas\", \"scikit-learn\"))\n\n\n\n2 데이터 가져오기\n펭귄 데이터를 다운로드 받아 로컬 컴퓨터 data 폴더에 저장시킨다.\n\n코드library(tidyverse)\n\nfs::dir_create(\"data\")\ndownload.file(url = \"https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv\", destfile = \"data/penguins_cleaned.csv\")\n\npenguin_df <- readr::read_csv(\"data/penguins_cleaned.csv\")\n\npenguin_df\n#> # A tibble: 333 × 7\n#>    species island    bill_length_mm bill_depth_mm flipper_length…¹ body_…² sex  \n#>    <chr>   <chr>              <dbl>         <dbl>            <dbl>   <dbl> <chr>\n#>  1 Adelie  Torgersen           39.1          18.7              181    3750 male \n#>  2 Adelie  Torgersen           39.5          17.4              186    3800 fema…\n#>  3 Adelie  Torgersen           40.3          18                195    3250 fema…\n#>  4 Adelie  Torgersen           36.7          19.3              193    3450 fema…\n#>  5 Adelie  Torgersen           39.3          20.6              190    3650 male \n#>  6 Adelie  Torgersen           38.9          17.8              181    3625 fema…\n#>  7 Adelie  Torgersen           39.2          19.6              195    4675 male \n#>  8 Adelie  Torgersen           41.1          17.6              182    3200 fema…\n#>  9 Adelie  Torgersen           38.6          21.2              191    3800 male \n#> 10 Adelie  Torgersen           34.6          21.1              198    4400 male \n#> # … with 323 more rows, and abbreviated variable names ¹​flipper_length_mm,\n#> #   ²​body_mass_g\n\n\n\n3 파이썬 기계학습 모형\n파이썬 sklearn 패키지로 펭귄 성별예측 모형을 구축하자.\n\n\n파이썬 코드\nR 환경 불러오기\n\n\n\n# \"code/penguin_sex_clf.py\"\n\nimport pandas as pd\npenguins = pd.read_csv('data/penguins_cleaned.csv')\n\npenguins_df = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']]\n\n# Ordinal feature encoding\n# https://www.kaggle.com/pratik1120/penguin-dataset-eda-classification-and-clustering\ndf = penguins_df.copy()\n\ntarget_mapper = {'male':0, 'female':1}\ndef target_encode(val):\n    return target_mapper[val]\n\ndf['sex'] = df['sex'].apply(target_encode)\n\n# Separating X and Y\nX = df.drop('sex', axis=1)\nY = df['sex']\n\n# Build random forest model\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X, Y)\n\n\n\n코드source_python(\"code/penguin_sex_clf.py\")\n\nclf\n#> RandomForestClassifier()\n\n\n\n\n\n\n4 시각화\n파이썬 기계학습 결과를 R로 가져와서 변수 중요도를 시각화한다.\n\n코드feat_tbl <- tibble(features = clf$feature_names_in_,\n                   importance = clf$feature_importances_)\n\nfeat_tbl %>% \n  ggplot(aes(x = fct_reorder(features, importance), y = importance)) +\n    geom_point(size = 3) +\n    geom_segment( aes(x=features, xend=features, y=0, yend=importance)) +\n    labs(y = \"Feature 중요도\", x = \"Feature\",\n         title = \"펭귄 암수 예측모형 Feature 중요도\") +\n    coord_flip() +\n    theme_bw(base_family = \"AppleGothic\")"
  },
  {
    "objectID": "BERT.html",
    "href": "BERT.html",
    "title": "chatGPT",
    "section": "",
    "text": "Context-free models: Word2Vec, Glove, FastText\nContext-embedding models(transformer based models): BERT, ELMO, Universal Sentence Encoder\n\nContext-free 모형은 단순하고 효율적이지만 텍스트의 뉴앙스를 비롯하여 의미를 잡아내는데 다소 미흡할 수 있다. 반면에 Context-based model은 강력하고 유연하지만 컴퓨팅 자원을 많이 사용하고 더 복잡하다."
  },
  {
    "objectID": "BERT.html#파이썬-코드",
    "href": "BERT.html#파이썬-코드",
    "title": "chatGPT",
    "section": "\n2.1 파이썬 코드",
    "text": "2.1 파이썬 코드\nBERT 논문 https://arxiv.org/pdf/1810.04805.pdf의 초록(Abstract)에서 질의를 하고 관련 내용을 뽑아내는 코드를 다음과 같이 작성한다. (Ravichandiran, 2021)\n# 질의응답 - 파이썬 코드\n# 출처: https://github.com/PacktPublishing/Getting-Started-with-Google-BERT/tree/main/Chapter03\n\nfrom transformers import BertForQuestionAnswering, BertTokenizer\nimport torch\n\nmodel = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n\n# BERT 논문 Abstract: https://arxiv.org/pdf/1810.04805.pdf\n\nquestion = \"What does the 'B' in BERT stand for?\"\nabstract = \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\"\n\n\nquestion = '[CLS] ' + question + '[SEP]'\nabstract = abstract + '[SEP]'\n\nquestion_tokens = tokenizer.tokenize(question)\nabstract_tokens = tokenizer.tokenize(abstract)\n\ntokens = question_tokens + abstract_tokens\ninput_ids = tokenizer.convert_tokens_to_ids(tokens)\n\nsegment_ids = [0] * len(question_tokens) + [1] * len(abstract_tokens)\n\ninput_ids = torch.tensor([input_ids])\nsegment_ids = torch.tensor([segment_ids])\n\nscores = model(input_ids, token_type_ids = segment_ids)\n\nstart_index = torch.argmax(scores['start_logits'])\nend_index = torch.argmax(scores['end_logits'])\n\nanswer = ' '.join(tokens[start_index:end_index+1])\n\n# print(' '.join(tokens[start_index:end_index+1]))\n\nBERT 임베딩 모형을 사용해서 질문과 응답을 파이썬 코드로 작성하고 나서 그 결과값을 R에서 바록 읽어 후처리 하도록 한다.\n\nlibrary(reticulate)\nlibrary(tidyverse)\n\nreticulate::source_python(\"code/BERT/BERT_QnA.py\")"
  },
  {
    "objectID": "BERT.html#질의응답-예시",
    "href": "BERT.html#질의응답-예시",
    "title": "chatGPT",
    "section": "\n2.2 질의응답 예시",
    "text": "2.2 질의응답 예시\n\n\n\n코드py$question\n#> [1] \"[CLS] What does the 'B' in BERT stand for?[SEP]\"\n\n\n\n\n코드py$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#대상-지문",
    "href": "BERT.html#대상-지문",
    "title": "chatGPT",
    "section": "\n2.3 대상 지문",
    "text": "2.3 대상 지문\n코드py$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#출력결과",
    "href": "BERT.html#출력결과",
    "title": "chatGPT",
    "section": "\n2.3 출력결과",
    "text": "2.3 출력결과\n\n코드py$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#질의응답-설정",
    "href": "BERT.html#질의응답-설정",
    "title": "chatGPT",
    "section": "\n2.2 질의응답 설정",
    "text": "2.2 질의응답 설정\nBERT를 사용해서 질문과 응답을 준비한다.\n\n\n\npy$question\n#> [1] \"[CLS] What does the 'B' in BERT stand for?[SEP]\"\n\n\n\npy$abstract\n#> [1] \"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).[SEP]\""
  },
  {
    "objectID": "BERT.html#질의응답-결과",
    "href": "BERT.html#질의응답-결과",
    "title": "chatGPT",
    "section": "\n2.3 질의응답 결과",
    "text": "2.3 질의응답 결과\n\n# str_c(py$tokens[py$start_index$tolist()+1:py$end_index$tolist()+1], collapse = \" \")\npy$answer\n#> [1] \"bid ##ire ##ction ##al en ##code ##r representations from transformers\""
  },
  {
    "objectID": "BERT.html#접근방법",
    "href": "BERT.html#접근방법",
    "title": "chatGPT",
    "section": "\n4.1 접근방법",
    "text": "4.1 접근방법\n\nQuantization and Pruning\nDistilBERT: Knowledge Distillation\nALBERT: A Lite BERT\n\nSamuel Sučík (August 8th, 2019), “Compressing BERT for faster prediction”, RASA Blog\n\n\n\n\nQuantization\n\n\n\n\nPruning\n\n\n\n\nPruning"
  },
  {
    "objectID": "BERT.html#성능비교",
    "href": "BERT.html#성능비교",
    "title": "chatGPT",
    "section": "\n4.2 성능비교",
    "text": "4.2 성능비교\nDistilBERT, A Lite BERT(ALBERT) 변형된 BERT 모형을 논문에 제시된 NLP 작업별 성능과 크기와 속도를 BERT-base 모형과 비교해보자.\n\n\nDistilBERT (Sanh et al., 2019)\nALBERT (Lan et al., 2019)"
  },
  {
    "objectID": "BERT.html#파이썬-코드-1",
    "href": "BERT.html#파이썬-코드-1",
    "title": "chatGPT",
    "section": "\n3.1 파이썬 코드",
    "text": "3.1 파이썬 코드\nIMDB 영화평점 텍스트에 담긴 감성분석을 BERT를 사용해서 수행한다.\n# 감성분석 - 파이썬 코드\n# 출처: https://wandb.ai/mukilan/BERT_Sentiment_Analysis/reports/An-Introduction-to-BERT-And-How-To-Use-It--VmlldzoyNTIyOTA1\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\ndf = pd.read_csv('https://gist.githubusercontent.com/Mukilan-Krishnakumar/e998ecf27d11b84fe6225db11c239bc6/raw/74dbac2b992235e555df9a0a4e4d7271680e7e45/imdb_movie_reviews.csv')\ndf = df.drop('sentiment',axis=1)\n\ntokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\ndef sentiment_movie_score(movie_review):\n\ttoken = tokenizer.encode(movie_review, return_tensors = 'pt')\n\tresult = model(token)\n\treturn int(torch.argmax(result.logits))+1\n\ndf['sentiment'] = df['text'].apply(lambda x: sentiment_movie_score(x[:512]))"
  },
  {
    "objectID": "BERT.html#감성분석-결과",
    "href": "BERT.html#감성분석-결과",
    "title": "chatGPT",
    "section": "\n3.2 감성분석 결과",
    "text": "3.2 감성분석 결과\n\nsenti_raw <- read_csv('https://gist.githubusercontent.com/Mukilan-Krishnakumar/e998ecf27d11b84fe6225db11c239bc6/raw/74dbac2b992235e555df9a0a4e4d7271680e7e45/imdb_movie_reviews.csv')\n\nreticulate::source_python(\"code/BERT/BERT_sentiment.py\")\n\nsenti_tbl <- senti_raw %>% \n  rename(label = sentiment) %>% \n  bind_cols(py$df %>% select(sentiment))\n\n\nsenti_tbl %>% \n  count(label, sentiment) %>% \n  ggplot(aes(x = sentiment, y = n, fill = label)) +\n    geom_col(width = 0.3, alpha = 0.7) +\n    scale_fill_manual(values = c(\"red\", \"green\")) +\n    labs(title = \"IMDB 영화 평점 데이터셋 감성분석 결과\",\n         x = \"감성점수: 부정(1) --- 긍정(5)\",\n         y = \"영화평점 부여건수\",\n         fill = \"긍부정\") +\n    theme_minimal() +\n    theme(legend.position = \"top\")"
  },
  {
    "objectID": "BERT.html#후속-분석",
    "href": "BERT.html#후속-분석",
    "title": "chatGPT",
    "section": "\n3.3 후속 분석",
    "text": "3.3 후속 분석\n평점 4점으로 예측된 영화 평점 중 긍부정 3개 리뷰를 뽑아 직접 살펴보자.\n\nlibrary(reactable)\n\nsenti_tbl %>% \n  filter(sentiment == 4) %>% \n  group_by(label) %>% \n  slice_sample(n = 3) %>% \n  reactable::reactable(\n      columns = list(\n        text = colDef(width = 700),\n        label = colDef(width = 50),\n        sentiment = colDef(width = 50)\n  ),\n  fullWidth = TRUE\n  )"
  },
  {
    "objectID": "korBERT.html",
    "href": "korBERT.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 BERT 모형 선정\n다국어를 지원하는 BERT 모형을 활용하여 연관 자연어 처리 업무를 수행할 수 있다.\n\nbert-base-multilingual-cased\ndistilbert-base-multilingual-cased\n\ndistilbert는 BERT 모형과 비교하여 다소 성능이 떨어지나 크기, 속도 등 다른 지표에서 BERT와 대등한 지표를 제시하고 있다.\n\n2 개체명 인식\n개체명(Named Entity)은 인명, 기관명, 지명 등과 같이 문장 또는 문서에서 특정한 의미를 가지고 있는 단어 또는 어구를 지칭함.\n\n네이버 개체명인식\n한국해양대학교 - 컴퓨터공학과 자연언어처리 연구실\n국립국어원\nAI 허브\n\n\n\n네이버(14종)\n한국해양대 (10종)\n국립국어원(5종)\nAI 허브(15종)\n\n\n\n\nlibrary(tidyverse)\n\nner_tbl <- tibble::tribble(\n            ~개체명.범주,   ~태그,                          ~정의,\n           \"PERSON\", \"PER\",      \"실존, 가상 등 인물명에 해당 하는 것\",\n            \"FIELD\", \"FLD\",       \"학문 분야 및 이론, 법칙, 기술 등\",\n  \"ARTIFACTS_WORKS\", \"AFW\",        \"인공물로 사람에 의해 창조된 대상물\",\n     \"ORGANIZATION\", \"ORG\",      \"기관 및 단체와 회의/회담을 모두 포함\",\n         \"LOCATION\", \"LOC\",            \"지역명칭과 행정구역 명칭 등\",\n     \"CIVILIZATION\", \"CVL\",            \"문명 및 문화에 관련된 용어\",\n             \"DATE\", \"DAT\",                         \"날짜\",\n             \"TIME\", \"TIM\",                         \"시간\",\n           \"NUMBER\", \"NUM\",                         \"숫자\",\n            \"EVENT\", \"EVT\",        \"특정 사건 및 사고 명칭과 행사 등\",\n           \"ANIMAL\", \"ANM\",                         \"동물\",\n            \"PLANT\", \"PLT\",                         \"식물\",\n         \"MATERIAL\", \"MAT\",             \"금속, 암석, 화학물질 등\",\n             \"TERM\", \"TRM\", \"의학 용어, IT곤련 용어 등 일반 용어를 총칭\"\n  )\n\nner_tbl %>% \n  gt::gt()\n\n\n\n\n\n\n개체명.범주\n      태그\n      정의\n    \n\n\nPERSON\nPER\n실존, 가상 등 인물명에 해당 하는 것\n\n\nFIELD\nFLD\n학문 분야 및 이론, 법칙, 기술 등\n\n\nARTIFACTS_WORKS\nAFW\n인공물로 사람에 의해 창조된 대상물\n\n\nORGANIZATION\nORG\n기관 및 단체와 회의/회담을 모두 포함\n\n\nLOCATION\nLOC\n지역명칭과 행정구역 명칭 등\n\n\nCIVILIZATION\nCVL\n문명 및 문화에 관련된 용어\n\n\nDATE\nDAT\n날짜\n\n\nTIME\nTIM\n시간\n\n\nNUMBER\nNUM\n숫자\n\n\nEVENT\nEVT\n특정 사건 및 사고 명칭과 행사 등\n\n\nANIMAL\nANM\n동물\n\n\nPLANT\nPLT\n식물\n\n\nMATERIAL\nMAT\n금속, 암석, 화학물질 등\n\n\nTERM\nTRM\n의학 용어, IT곤련 용어 등 일반 용어를 총칭\n\n\n\n\n\n\n\n\n한국어에서 개체의 범주는 크게 개체이름, 시간표현, 수량표현으로 분류할 수 있다.\n\n개체이름: 인명(PER), 지명(LOC), 기관명(ORG), 기타(POH)\n시간표현: 날짜(DAT), 시간(TIM), 기간(DUR)\n수량표현: 통화(MNY), 비율(PNT), 기타 수량표현(NOH)\n\n\n\n장소(LC), 날짜(DT), 기관(OG), 시간(TI), 인물(PS)\n\n\n사람(PS), 지역(LC), 단체(OG), 인공물(AF), 날짜(DT), 시간(TI), 제도(CV), 동물(AM), 식물(PT), 단위(QT), 분야(FD), 이론(TR), 사건(EV), 물질(MT), 용어(TM)"
  },
  {
    "objectID": "hf_pipeline.html",
    "href": "hf_pipeline.html",
    "title": "chatGPT",
    "section": "",
    "text": "다국어를 지원하는 BERT 모형을 활용하여 연관 자연어 처리 업무를 수행할 수 있다.\n\nbert-base-multilingual-cased\ndistilbert-base-multilingual-cased\n\ndistilbert는 BERT 모형과 비교하여 다소 성능이 떨어지나 크기, 속도 등 다른 지표에서 BERT와 대등한 지표를 제시하고 있다.\n\n\n\n\n\n\n노트\n\n\n\nfrom transformers import pipeline\n\n# Using default model and tokenizer for the task\npipeline(\"<task-name>\")\n\n# Using a user-specified model\npipeline(\"<task-name>\", model=\"<model_name>\")\n\n# Using custom model/tokenizer as str\npipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')\n\n\nHugging Face Transformers - How to use Pipelines"
  },
  {
    "objectID": "hf_pipeline.html#파이썬-코드",
    "href": "hf_pipeline.html#파이썬-코드",
    "title": "chatGPT",
    "section": "\n3.1 파이썬 코드",
    "text": "3.1 파이썬 코드\nHF 파이프라인을 사용하여 영문 개체명인식 작업을 수행한다.\n# 감성분석 - 파이썬 코드\n# 출처: https://www.kaggle.com/code/funtowiczmo/hugging-face-transformers-how-to-use-pipelines\n\nfrom transformers import pipeline\n\n# NER 파이프라인 ---------------------------------\nner = pipeline(task = \"ner\", \n               model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n               tokenizer=\"bert-large-cased\")\n\ntext = \"John Smith works at Google\"\nentities = ner(text)\n\n# 결과 출력\nfor entity in entities:\n    print(f\"{entity['word']} -> {entity['entity']}\")"
  },
  {
    "objectID": "hf_pipeline.html#개체명-인식결과",
    "href": "hf_pipeline.html#개체명-인식결과",
    "title": "chatGPT",
    "section": "\n3.2 개체명 인식결과",
    "text": "3.2 개체명 인식결과\n\n코드library(reticulate)\nreticulate::source_python(\"code/BERT/HF_pipeline_NER.py\")\n\nto_r <- function(idx){\n\n  output_idx = py$entities %>% \n    pluck(idx)\n  \n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n}\n\nmap_dfr(1:length(py$entities), ~to_r(.x))\n#> # A tibble: 3 × 6\n#>   entity score index word   start   end\n#>   <chr>  <dbl> <int> <chr>  <int> <int>\n#> 1 I-PER  0.999     1 John       0     4\n#> 2 I-PER  1.00      2 Smith      5    10\n#> 3 I-ORG  0.998     5 Google    20    26"
  },
  {
    "objectID": "project.html#chatgpt-이전",
    "href": "project.html#chatgpt-이전",
    "title": "chatGPT",
    "section": "\n8.1 chatGPT 이전",
    "text": "8.1 chatGPT 이전\nTensorflow, Keras, Pytorch, Fast.ai 가 차례로 등장하며 딥러닝 개발 프레임워크의 전성기를 구가했다. 최근 5년동안 Google 추세를 살펴보자.\n\n\n\n\n\n코드library(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"딥러닝 프레임워크 구글 검색 추세\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()"
  },
  {
    "objectID": "project.html#chatgpt-출현",
    "href": "project.html#chatgpt-출현",
    "title": "chatGPT",
    "section": "\n8.2 chatGPT 출현",
    "text": "8.2 chatGPT 출현\nchatGPT 출현이후 Tensorflow, Keras, Pytorch, Fast.ai 는 어떻게 전개될 것인지 최근 1년동안 Google 추세를 살펴보자.\n\n코드chatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"chatGPT와 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "project.html#파이썬과-chatgpt",
    "href": "project.html#파이썬과-chatgpt",
    "title": "chatGPT",
    "section": "\n8.3 파이썬과 chatGPT",
    "text": "8.3 파이썬과 chatGPT\nchatGPT 출현이후 파이썬, tensorflow, pytorch 최근 1년동안 Google 추세를 살펴보자.\n\n코드python_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"파이썬, chatGPT, 주요 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPT는 인터넷에서 방대한 양의 데이터를 학습하여 이를 정말 잘 압축한 하나의 저장소로 이해할 수 있다. 따라서, 압축을 풀게 되면 정확히 원본을 복원할 수 있는 부분도 있지만, 그렇지 못한 부분도 당영히 있게 된다.\nTed Chiang (February 9, 2023), “ChatGPT Is a Blurry JPEG of the Web - OpenAI’s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?”, The New Yorker\nChatGPT를 “웹의 흐릿한 JPEG”으로 비유하고 있다. JPEC 기술 자체는 손실 압축기술로 무손실 압축기술로 대표적인 PNG와 대비된다. 흐릿한 이미지가 선명하지 않거나 정확하지 않은 것처럼 ChatGPT도 항상 완벽한 답변을 제공하거나 모든 질문을 제대로 이해하는 것도 아니다. 하지만 사용자와의 대화를 기반으로 끊임없이 학습하고 개선하고 있다. 더 많은 사람들이 ChatGPT를 사용할수록 사람의 언어를 더 잘 이해하고 반응할 수 있게 개발된 기술이다.\nChatGPT와 유사한 인공지능 프로그램이 너무 강력해지거나 인간을 대체할 수 있다고 우려하는 사람들도 있지만, ChatGPT는 단순히 작업을 더 쉽고 효율적으로 만드는 데 사용할 수 있는 강력한 도구일 뿐이므로 사람을 능가하거나 지배할 가능성은 거의 없다. 인공지능(ChatGPT)을 책임감 있고 윤리적으로 사용되도록 하는 것은 결국 사용자 귀책이다.\nChatGPT가 간단한 숫자계산에 문제가 있는 것은 웹상에 산재된 숫자 계산 데이터를 바탕으로 계산을 흉내낼 수는 있으나 이와 같은 방식으로 ChatGPT가 학습한 것은 명백히 잘못된 것이다. 사칙연산에 대한 일반적인 원리를 이해하게 되면 웹상에 나온 사칙연산 문제를 정확히 해결할 뿐만 아니라 웹상에 나와있지 않는 계산문제도 풀 수 있으나 현재는 그렇지 못하다.\n\n\nPNG 파일\n(비)손실 압축\n파일크기\nBMP 파일\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n자료출처: WHAT’S THE DIFFERENCE BETWEEN JPEG AND PNG: BEGINNER GUIDE\n\n독일 과학자(David Kriesel)가 제록스 복사기에서 문서에 있는 숫자를 변경하는 결함을 발견했다. 제록스 프린터가 방의 면적을 14.13m²에서 17.42m²로 넓혔고, 다른 프린터는 21.11m²에서 14.13m²로 줄였다. 숫자 문자열 중간에 특정 숫자(예: “6” 또는 “8”)가 나타나면 복사기가 해당 숫자를 다른 숫자로 바꾸는 경우가 많았다. 예를 들어, ’682’가 ’882’가 될 수 있습니다.\n처음에 건물 설계도를 스캔하고 분석하려고 할 때 이 문제를 발견했다. 원본에는 이러한 오류가 없었지만 스캔한 사본에서 특정 숫자가 변경된 것을 발견했다. 결국 그들은 사본을 만드는 과정에서 숫자가 변경된, 사용 중인 Xerox 복사기에 문제가 있다는 사실을 깨달았다.\n이 결함은 제록스 복사기에 사용되는 압축 알고리즘과 관련된 것으로 특정 숫자가 서로 가까이 있으면 알고리즘이 이를 다른 숫자로 착각하고 그에 따라 숫자를 바꾼 것이다. 이 문제가 일부 고급 모델을 포함한 다양한 제록스 복사기에 존재한다는 사실도 발견했다.\nD. KRIESEL, “Xerox scanners/photocopiers randomly alter numbers in scanned documents”\n\n\n설계도 문서\n스캔 결과\n원가표 스캔\n스캔 오류\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n모델: WorkCentre 7535"
  },
  {
    "objectID": "trends.html",
    "href": "trends.html",
    "title": "chatGPT",
    "section": "",
    "text": "백만, 5천만, 1억 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다.\n\n\n전화기부터\n기술 진화\nchatGPT 백만\n빅3 서비스\n1억명 (소요 달수)\n\n\n\n\n\n(Song, 2019)\n\n\n\n\n\n\nRita McGrath(November 25, 2013), “The Pace of Technology Adoption is Speeding Up”, Harvard Business Review\n\n\n\n\n\n\n\n\n\n\n\n\n출처: https://twitter.com/umarsaif/status/1610932387185315840\n\n\n\n\n\n\n출처: https://twitter.com/EconomyApp/status/1622029832099082241"
  },
  {
    "objectID": "trends.html#chatgpt-이전",
    "href": "trends.html#chatgpt-이전",
    "title": "chatGPT",
    "section": "\n3.1 chatGPT 이전",
    "text": "3.1 chatGPT 이전\nTensorflow, Keras, Pytorch, Fast.ai 가 차례로 등장하며 딥러닝 개발 프레임워크의 전성기를 구가했다. 최근 5년동안 Google 추세를 살펴보자.\n\n\n\n\n\n코드library(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"딥러닝 프레임워크 구글 검색 추세\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()"
  },
  {
    "objectID": "trends.html#chatgpt-출현",
    "href": "trends.html#chatgpt-출현",
    "title": "chatGPT",
    "section": "\n3.2 chatGPT 출현",
    "text": "3.2 chatGPT 출현\nchatGPT 출현이후 Tensorflow, Keras, Pytorch, Fast.ai 는 어떻게 전개될 것인지 최근 1년동안 Google 추세를 살펴보자.\n\n코드chatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"chatGPT와 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "trends.html#파이썬과-chatgpt",
    "href": "trends.html#파이썬과-chatgpt",
    "title": "chatGPT",
    "section": "\n3.3 파이썬과 chatGPT",
    "text": "3.3 파이썬과 chatGPT\nchatGPT 출현이후 파이썬, tensorflow, pytorch 최근 1년동안 Google 추세를 살펴보자.\n\n코드python_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"파이썬, chatGPT, 주요 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()"
  },
  {
    "objectID": "intro_avi.html",
    "href": "intro_avi.html",
    "title": "chatGPT",
    "section": "",
    "text": "chatGPT를 사용하여 사단법인 한국 R 사용자회 소개 대본을 작성한다.\n다음으로 미드저니를 이용하여 사단법인 한국 R 사용자회를 소개하는 화자 이미지를 생성한다.\n클로버 더빙 서비스를 사용하여 chatGPT 가 작성한 대본으로 음성 파일(.mp3)을 제작한다.\n\nD-ID 스튜디오에 미드저니에서 작업한 이미지와 STT로 작업한 결과를 합성하여 한국 R 사용자회 소개 동영상 작업을 마무리한다.\n유튜브 채널에 올려 소셜 미디어로 한국 R 사용자회 홍보를 한다.\n\n\n사단법인 한국 R 사용자회에 대해 소개하는 소개글을 작성해줘\n\n\n\n\n\n\nchatGPT\n\n\n\n\n\n한국 R 사용자회는 데이터 분석 및 통계분야에서 전 세계적으로 사용되고 있는 R 프로그래밍 언어의 사용을 촉진하고, 연구 및 개발 분야에서 R을 활용한 다양한 응용과 기술 발전을 위해 설립된 사단법인입니다.\n한국 R 사용자회는 R 프로그래밍 언어를 사용하는 분야에서의 지식과 정보 교류, 협력과 공유를 위한 다양한 활동을 전개하고 있습니다. 회원들은 R을 활용한 다양한 분석 및 시각화 기술을 공유하고, R 패키지 개발 및 오픈소스 활용, 데이터 과학 분야에서의 협력과 커뮤니케이션 등 다양한 분야에서 활동하며 지식을 공유합니다.\n한국 R 사용자회는 국내외 R 컨퍼런스 및 세미나 개최, R 교육 및 훈련, R 활용 사례 발표, R 패키지 개발 및 유지 보수 등 다양한 활동을 통해 회원들의 R 활용 능력 향상과 지식 공유를 위한 기반을 제공하고 있습니다.\n회원으로 가입하면 R 언어 및 데이터 분석 분야에서의 최신 정보와 기술 동향을 지속적으로 업데이트 받을 수 있으며, R 패키지 개발 및 활용, 데이터 분석 기술 등에 대한 다양한 교육과 세미나, 워크샵 등을 참여할 수 있습니다.\n한국 R 사용자회는 R 프로그래밍 언어의 활용과 개발을 통해 데이터 분석 및 통계분야의 발전을 위한 지속적인 노력을 기울이고 있으며, 회원들의 활동과 참여를 통해 R 프로그래밍 언어의 활용과 발전에 기여하고 있습니다.\n\n\n\n\nMidjourney\n미드저니 AI 이미지를 잘 생성하기 위해서는 Prompt Engineering을 통해 원하는 이미지가 제작될 때까지 작업한다.\n미드저니 프롬프트 툴 웹사이트에서 Midjourney Bot 채팅 인터페이스를 사용하는 것과 비교하여 AI 이미지 작성업무에 좀더 집중할 수 있다.\nwillwulfken/MidJourney-Styles-and-Keywords-Reference GitHub 저장소에 즉시 사용가능한 템플릿이 많아 이를 활용하는 것도 AI 이미지 제작 속도 및 품질을 높일 수 있다.\n\n작성 프롬프트 https://s.mj.run/guPCzzM12wU, crepuscular rays::1 rembrandt::1 defocus::-0.5 –ar 2:1 –v 4\n\n\n\n원본 이미지\n첫 4장 이미지\n잘못 누름\n이미지 재현\n최종 이미지\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n클로버 더빙\n텍스트를 음원으로 바꿔주는 작업이 필요하다. 이를 위해서 다양한 API 서비스가 제공되지만 네이버 클로버 더빙 API 서비스를 사용하면 다양한 한국인 목소리를 넣어 구현이 가능하다.\n\nD-ID\nD-ID 스튜디오에 미드저니에서 작업한 이미지와 STT로 작업한 결과를 합성하여 한국 R 사용자회 소개 동영상 작업을 마무리한다."
  },
  {
    "objectID": "intro_avi.html#음원-제작",
    "href": "intro_avi.html#음원-제작",
    "title": "chatGPT",
    "section": "\n2.1 음원 제작",
    "text": "2.1 음원 제작\n클로버 더빙\n텍스트를 음원으로 바꿔주는 작업이 필요하다. 이를 위해서 다양한 API 서비스가 제공되지만 네이버 클로버 더빙 API 서비스를 사용하면 다양한 한국인 목소리를 넣어 구현이 가능하다."
  },
  {
    "objectID": "intro_avi.html#동영상-제작",
    "href": "intro_avi.html#동영상-제작",
    "title": "chatGPT",
    "section": "\n2.2 동영상 제작",
    "text": "2.2 동영상 제작\nD-ID\nD-ID 스튜디오에 미드저니에서 작업한 이미지와 STT로 작업한 결과를 합성하여 한국 R 사용자회 소개 동영상 작업을 마무리한다."
  },
  {
    "objectID": "intro_book.html",
    "href": "intro_book.html",
    "title": "chatGPT",
    "section": "",
    "text": "전자출판된 전자책은 다음 웹사이트에서 확인이 가능하다.\n\n전자책\n소스코드"
  },
  {
    "objectID": "intro_book.html#수정된-커리큘럼",
    "href": "intro_book.html#수정된-커리큘럼",
    "title": "chatGPT",
    "section": "\n3.1 수정된 커리큘럼",
    "text": "3.1 수정된 커리큘럼\n\n\n\n\n\n\n\n\n1주차 1주차: R 및 데이터 랭글링 소개\n\nR 개요 및 데이터 과학에서의 중요성\nR에서 데이터 랭글링(Wrangling) 및 정리의 기본 개념 소개\n\ndplyr 및 tidyr 패키지를 사용하여 데이터 필터링, 정렬, 병합 및 집계와 같은 데이터 랭글링 기법 소개\npivot_longer(), pivot_wider() 함수 사용 깔끔한 데이터 변형 \n벡터, 행렬, 데이터 프레임 및 목록과 같은 R의 데이터 구조 소개\nR에서 데이터 랭글링 기술을 연습하는 연습 및 프로젝트\n\n\n\n2주차 데이터 시각화 및 탐색적 데이터 분석(EDA)\n\n데이터 시각화 소개 및 데이터 과학에서 데이터 시각화의 중요성\n다양한 유형의 시각화를 생성하기 위한 ggplot2, gt R 패키지 사용\n데이터 분포, 상관관계, 이상값 탐지 등 EDA의 원리 소개\n분산형 차트, 히스토그램, 상자그림과 같은 데이터 탐색 기법\nR에서 데이터 시각화 및 EDA 기술을 연습할 수 있는 연습 및 프로젝트\n\n\n\n3주차 통계 분석 및 기계 학습 기초\n\nR의 통계 분석 및 기계 학습 소개\n확률 분포, 가설 테스트 및 회귀 분석과 같은 기본 통계 개념 개요\n지도 학습 및 비지도 학습과 같은 기계 학습 알고리즘과 데이터 과학에서의 응용 프로그램 소개\n머신 러닝 알고리즘 구현을 위한 tidymodels 및 mlr과 같은 R 패키지 사용\nR에서 통계 분석 및 기계 학습 기본 사항을 연습하는 연습 및 프로젝트\n\n\n\n4주차 고급 데이터 과학 기법\n\n텍스트 마이닝, 네트워크 분석, 시계열 분석과 같은 R의 고급 데이터 과학 기법 소개\n\ntidytext, 토픽모델 등 R 패키지를 활용한 감성 분석, 텍스트 분류, 토픽 모델링 등 텍스트 마이닝 개념 개요 소개\n\ntidygraph 등 R 패키지를 이용한 소셜 네트워크 분석, 중심성 측정, 커뮤니티 탐지 등 네트워크 분석 기법 소개\n예측, tidyverts 등 R 패키지를 활용한 ARIMA 모델, 예측, 추세 분석 등 시계열 분석 기법 소개\nR의 고급 데이터 과학 기법을 실습할 수 있는 실습 및 프로젝트."
  },
  {
    "objectID": "intro_book.html#작업흐름-상세",
    "href": "intro_book.html#작업흐름-상세",
    "title": "chatGPT",
    "section": "\n2.1 작업흐름 상세",
    "text": "2.1 작업흐름 상세\n각 단계별 저작흐름에 주요하게 사용된 chatGPT, DeepL, Quarto Book 도구는 다음과 같이 사용되었다.\n\n\n\n\nchatGPT 작성\n\n\n\n\nDeepL 번역 및 교정\n\n\n\n\n쿼토 출판저작\n\n\n\n그림 1: chatGPT 디지털 글쓰기 저작 흐름"
  },
  {
    "objectID": "intro_book.html#chatgpt-프롬프트",
    "href": "intro_book.html#chatgpt-프롬프트",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT 프롬프트",
    "text": "2.2 chatGPT 프롬프트\n데이터 과학 책을 저작하기 위해 chatGPT에서 사용된 지시명령어(Prompt)는 다음과 같다. chatGPT 채팅 인터페이스를 사용해서 텍스트를 생성할 경우 Seed를 적용할 기능이 없기 때문에 비결정적(non-deterministic)이라 출력결과는 사뭇 다르게 된다.\n\nwrite four weeks data science curriculum\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nWeek 1: Introduction to Data Science and Data Wrangling\n\nOverview of data science and its importance in various fields\nIntroduction to the basic concepts of data wrangling and cleaning\nTechniques for data wrangling such as filtering, sorting, merging, and aggregating data\nUse of Python libraries such as pandas for data wrangling\nExercises and projects to practice data wrangling techniques\nWeek 2: Data Visualization and Exploratory Data Analysis (EDA)\n\nWeek 2: Introduction to data visualization and its importance in data science\n\nUse of Python libraries such as matplotlib, seaborn and plotly for creating various types of visualizations\nPrinciples of EDA such as data distribution, correlation, and outliers detection\nTechniques for data exploration such as scatter plots, histograms, and box plots\nExercises and projects to practice data visualization and EDA techniques\nWeek 3: Statistical Analysis and Machine Learning Fundamentals\n\nWeek 3: Introduction to statistical analysis and machine learning\n\nOverview of basic statistical concepts such as probability distributions, hypothesis testing, and regression analysis\nIntroduction to machine learning algorithms such as supervised and unsupervised learning, and their applications in data science\nUse of Python libraries such as scikit-learn for implementing machine learning algorithms\nExercises and projects to practice statistical analysis and machine learning fundamentals Week 4: Advanced Data Science Techniques\n\nWeek 4: Introduction to advanced data science techniques such as deep learning, natural language processing, and computer vision\n\nOverview of deep learning concepts such as neural networks, convolutional neural networks (CNN), and recurrent neural networks (RNN)\nUse of Python libraries such as Tensorflow and Keras for implementing deep learning algorithms\nIntroduction to natural language processing techniques such as sentiment analysis, text classification, and named entity recognition\nIntroduction to computer vision techniques such as image classification, object detection, and segmentation\nExercises and projects to practice advanced data science techniques\n\n\n\n\n\nwrite data science curriculum with R\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nWeek 1: Introduction to R and Data Wrangling\n\nOverview of R and its importance in data science\nIntroduction to the basic concepts of data wrangling and cleaning in R\nTechniques for data wrangling such as filtering, sorting, merging, and aggregating data using dplyr and tidyr packages\nIntroduction to data structures in R such as vectors, matrices, data frames, and lists\nExercises and projects to practice data wrangling techniques in R\n\nWeek 2: Data Visualization and Exploratory Data Analysis (EDA)\n\nIntroduction to data visualization and its importance in data science\nUse of R packages such as ggplot2 and lattice for creating various types of visualizations\nPrinciples of EDA such as data distribution, correlation, and outliers detection\nTechniques for data exploration such as scatter plots, histograms, and box plots\nExercises and projects to practice data visualization and EDA techniques in R\n\nWeek 3: Statistical Analysis and Machine Learning Fundamentals\n\nIntroduction to statistical analysis and machine learning in R\nOverview of basic statistical concepts such as probability distributions, hypothesis testing, and regression analysis\nIntroduction to machine learning algorithms such as supervised and unsupervised learning, and their applications in data science\nUse of R packages such as caret and mlr for implementing machine learning algorithms\nExercises and projects to practice statistical analysis and machine learning fundamentals in R\n\nWeek 4: Advanced Data Science Techniques\n\nIntroduction to advanced data science techniques in R such as text mining, network analysis, and time series analysis\nOverview of text mining concepts such as sentiment analysis, text classification, and topic modeling using R packages such as tm and topicmodels\nIntroduction to network analysis techniques such as social network analysis, centrality measures, and community detection using R packages such as igraph and statnet\nIntroduction to time series analysis techniques such as ARIMA models, forecasting, and trend analysis using R packages such as forecast and tseries\nExercises and projects to practice advanced data science techniques in R.\n\n\n\n\n\nwrite section for \"Overview of R and its importance in data science\"\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nSure, here’s an overview of R and its importance in data science:\nR is a programming language and software environment for statistical computing and graphics. It was developed in the early 1990s by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand. Since then, it has become one of the most popular languages for data analysis, visualization, and statistical modeling. R is open source, which means that it is freely available and can be modified by anyone.\nR has a number of features that make it ideal for data science. For example, it has a large and active community of users who contribute to the development of packages for data analysis, visualization, and modeling. These packages are available for download from the Comprehensive R Archive Network (CRAN) and cover a wide range of topics, including machine learning, time series analysis, data visualization, and more.\nAnother advantage of R is its ability to handle large datasets. R has a number of packages that allow users to read in and manipulate data from various sources, including databases, spreadsheets, and text files. It also has powerful data manipulation capabilities, such as reshaping data, merging datasets, and aggregating data.\nR is also widely used in academia and industry, particularly in fields such as finance, healthcare, and marketing. In academia, R is used in research and teaching in a variety of disciplines, including statistics, economics, and social sciences. In industry, R is used by companies for data analysis, modeling, and visualization, as well as for building data products.\nOverall, R is an important tool in the data scientist’s toolbox, and its popularity continues to grow. It offers a wide range of capabilities for data analysis, visualization, and modeling, and has a large and active community of users and developers. If you’re interested in data science, learning R is definitely worth considering.\n\n\n\n\nas an author of data science book, write a section on \"Use of R packages such as tidymodels for implementing machine learning algorithms\"\n\n\n\n\n\n\n\nchatGPT 답변:\n\n\n\n\n\nSection: Use of R Packages such as tidymodels for Implementing Machine Learning Algorithms\nThe process of building machine learning models involves several steps such as data preparation, model training, validation, and testing. In R, there are several packages available that can help data scientists to perform these steps with ease. One of the popular packages for implementing machine learning models is tidymodels.\ntidymodels is an open-source collection of R packages designed for modeling and machine learning using the tidyverse style of programming. It provides a consistent framework for modeling that includes preprocessing, feature engineering, model tuning, and evaluation. Some of the important packages in tidymodels include:\n\ntidyverse: A collection of R packages for data wrangling, exploration, and visualization.\ndplyr: A package for data manipulation and transformation.\ntidyr: A package for data tidying and reshaping.\nggplot2: A package for creating visualizations.\ncaret: A package for building and evaluating machine learning models.\nrsample: A package for data splitting and resampling.\nparsnip: A package for model specification and tuning.\n\nThe tidymodels framework follows a consistent modeling pipeline, which includes the following steps:\n\nData preparation: In this step, data is loaded and preprocessed using various techniques such as imputation, scaling, and encoding.\nFeature engineering: This step involves creating new features from existing ones, selecting important features, and transforming features to meet the requirements of the model.\nModel specification: In this step, a machine learning model is selected and defined. The parsnip package provides a consistent interface for specifying models.\nModel tuning: This step involves tuning the model’s hyperparameters to optimize performance. The tune package provides various methods for model tuning.\nModel evaluation: In this step, the model’s performance is evaluated using various metrics such as accuracy, precision, and recall. The yardstick package provides various metrics for model evaluation.\n\nThe tidymodels framework provides a simple and intuitive way of building machine learning models in R. With the help of various packages, it simplifies the process of data preparation, feature engineering, model specification, tuning, and evaluation. This framework can be useful for data scientists working on various types of data science problems, from classification and regression to clustering and association rule mining."
  },
  {
    "objectID": "intro_paper.html",
    "href": "intro_paper.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 학술지 영문초록\n국문 학술지에 논문을 작성할 때 가장 큰 애로점 중에 하나가 영문초록으로 작성해야 된다는 점이다. 제주대 안도현 교수님이 관련하여 고품질 영문초록을 작성할 수 있는 꿀팁을 제시하여 SNS를 통해 공개해 주셨습니다. 작업흐름과 관련 지시명령어(Prompt)도 전달해 주셨습니다.\n\n\n\n\n\n\n학술지 영문초록을 딥엘과 챗지피티를 이용하면 영문교정 불필요.\n\n\n\n\n국문초록 작성\n딥엘로 국문을 영문으로 번역. DeepL\n\n번역한 영문을 ChatGPT로 윤문.\n\n\n프롬프트에 다음과 같이 입력:\n\n\nRevise the abstract to follow APA style guidelines and ensure that it falls within the word count range of 400 to 500 words.\n\n\n\n\n2 사례\n2020년 출간된 논문(이광춘, 2020)의 한글 초록을 chatGPT와 DeepL을 사용하여 논문제작에 활용해보자.\n\n논문 소스코드: 바로가기\n\nPDF 출판 논문: 다운로드\n\n\n\n\n한글 초록\n영문 초록\nDeepL 영어번역\nchatGPT 프롬프트\nchatGPT 윤문\n\n\n\n\n\n\n\n\n\n알파고가 2016년 바둑 인간 챔피언 이세돌 9단을 현격한 기량차이로 격파하면서 인공지능에 대한 관심이 급격히 증가하였다. 그와 동시에 기계가 인간의 일자리 잠식을 가속화하면서 막연한 불안감이 삽시간에 전파되었다. 기계와의 일자리 경쟁은 컴퓨터의 출현이전부터 시작되었지만 인간만의 고유한 영역으로 알고 있던 인지, 창작 등 다양한 분야에서 오히려 인간보다 더 우수한 성능과 저렴한 가격 경쟁력을 보여주면서 기존 인간의 일자리가 기계에 대체되는 것이 가시권에 들었다. 이번 문헌조사와 실증 데이터 분석을 통해서 기계가 인간의 일자리를 대체하는 자동화의 본질에 대해서 살펴보고, 인간과 기계의 업무 분장을 통해 더 생산성을 높일 수 있는 방안을 제시하고자 한다.\n\n\n\n\n\n\n\n\n\n\n\nMachines have been used simply for arithmetic operations and documentation. However, with the development of technology, a new generation of artificial intelligence has begun. Machines are not just tools that can be calculated, but they have been commercialized in various fields, such as natural language processing technology that can understand and communicate human language, or video fields, where human dependence was high. Since 2016, the AI game, “Alphago,” has defeated Lee Se-dol with a significant difference in skill, interest in AI has increased sharply. Machines have started to replace human jobs because of their excellent performance, low cost and competitive edge. In this paper, I would like to present a plan on how to use artificial intelligence to affect human jobs and how to improve productivity effectively by cooperating with machines and humans in the future.\n\n\n\n\n\n\n\n\n\n\n\nInterest in artificial intelligence skyrocketed in 2016 when AlphaGo defeated human Go champion Lee Sedol 9 by a stunning margin. At the same time, a vague sense of anxiety was quickly spread as machines accelerated the erosion of human jobs. Although the competition for jobs with machines began before the advent of computers, the replacement of existing human jobs by machines became visible as machines showed better performance and lower price competitiveness than humans in various fields such as cognition and creation, which were thought to be unique to humans. Through this literature review and empirical data analysis, we examine the nature of automation in which machines replace human jobs. and suggest ways to increase productivity through the division of labor between humans and machines.\nTranslated with www.DeepL.com/Translator (free version)\n\n\n\n\n\n\n\n\n\n\n\nRevise the abstract to follow APA style guidelines and ensure that it falls within the word count range of 400 to 500 words.\nInterest in artificial intelligence skyrocketed in 2016 when AlphaGo defeated human Go champion Lee Sedol 9 by a stunning margin. At the same time, a vague sense of anxiety was quickly spread as machines accelerated the erosion of human jobs. Although the competition for jobs with machines began before the advent of computers, the replacement of existing human jobs by machines became visible as machines showed better performance and lower price competitiveness than humans in various fields such as cognition and creation, which were thought to be unique to humans. Through this literature review and empirical data analysis, we examine the nature of automation in which machines replace human jobs. and suggest ways to increase productivity through the division of labor between humans and machines.\n\n\n\n\n\n\n\n\n\n\n\nThe rise of artificial intelligence (AI) has garnered significant attention since 2016 when AlphaGo, an AI program, defeated the human Go champion Lee Sedol. However, the growing use of machines in various fields has also fueled concerns about the displacement of human jobs. This paper presents a literature review and empirical data analysis to explore the nature of automation and suggest ways to enhance productivity by optimizing the division of labor between humans and machines.\nWhile machines have been replacing human jobs for centuries, the rapid development of AI has made it possible for machines to outperform humans in fields previously considered uniquely human, such as cognition and creation. As a result, there is a growing awareness of the impact of automation on employment opportunities. This paper aims to provide insights into this issue through a comprehensive review of relevant literature and analysis of empirical data.\nOur analysis indicates that automation can lead to the displacement of jobs that require low-level skills, but it can also create new opportunities that require higher-level skills. Furthermore, automation can enhance productivity and lower costs, thus benefiting both consumers and firms. Therefore, there is a need to strike a balance between the potential benefits and challenges of automation.\nTo maximize the advantages of automation, we propose an optimal division of labor between humans and machines. In this approach, humans are responsible for tasks that require creativity, emotional intelligence, and social skills, while machines are responsible for tasks that require precision and efficiency. This approach can lead to better job quality and increased productivity.\nIn conclusion, this paper highlights the potential impact of automation on employment and the need to optimize the division of labor between humans and machines. While automation can lead to job displacement, it can also create new opportunities and improve job quality. Therefore, policymakers and firms must consider ways to optimize the use of automation to benefit both society and the economy.\n\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\n이광춘주용우. (2020). 사람과 인공지능의 일자리 경쟁 요인과 협업 방안. 디지털경영연구 Vol.6 No.2 pp.39-50."
  },
  {
    "objectID": "middle_school.html",
    "href": "middle_school.html",
    "title": "chatGPT",
    "section": "",
    "text": "데이터 문해력에 “중학수학 - 연립방정식” 사례를 통해 적용 방향을 살펴보자."
  },
  {
    "objectID": "trends.html#트위터-샌티아고",
    "href": "trends.html#트위터-샌티아고",
    "title": "chatGPT",
    "section": "\n6.1 트위터 샌티아고",
    "text": "6.1 트위터 샌티아고\nSantiago @svpino"
  },
  {
    "objectID": "trends.html#버스탄-두남자",
    "href": "trends.html#버스탄-두남자",
    "title": "chatGPT",
    "section": "\n6.2 버스탄 두남자",
    "text": "6.2 버스탄 두남자"
  },
  {
    "objectID": "trends.html#gpt-3-언어-데이터-fa-solid-brain",
    "href": "trends.html#gpt-3-언어-데이터-fa-solid-brain",
    "title": "chatGPT",
    "section": "\n2.2 GPT-3 언어 데이터 \n",
    "text": "2.2 GPT-3 언어 데이터 \n\nGPT-3 개발에 투입된 문서갯수를 언어별로 살펴보자.\n\n코드library(tidyverse)\nlibrary(gt)\nlibrary(countrycode)\nlibrary(rvest)\nlibrary(gtExtras)\n\n## 언어 코드 \nlang_tbl <- read_html(x = 'http://www.lingoes.net/en/translator/langcode.htm') %>% \n  html_element(css = 'body > table') %>% \n  html_table() %>% \n  set_names(c(\"언어\", \"언어명\"))\n\n\ngpt_raw <- read_csv(\"https://raw.githubusercontent.com/openai/gpt-3/master/dataset_statistics/languages_by_document_count.csv\")\n\ngpt_tbl <- gpt_raw %>% \n  set_names(c(\"언어\", \"문서수\", \"비중\")) %>% \n  mutate(비중 = parse_number(비중) / 100) %>% \n  mutate(누적문서 = cumsum(문서수)) %>% \n  mutate(누적비중 = 누적문서 / sum(문서수)) %>% \n  top_n(문서수, n = 28)  \n\ngpt_gt <- gpt_tbl %>% \n  left_join(lang_tbl, by = \"언어\") %>% \n  select(언어, 언어명, 문서수, 비중, 누적비중) %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%\n    tab_options(table.width = pct(100))  %>%\n    tab_header(\n      title = md(\"**GPT-3 언어모형 개발에 사용된 언어별 문서 통계**\"),\n      subtitle = \"한국어 포함 상위 28개 언어\") %>% \n    tab_source_note(\n      source_note = \"자료출처: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\") %>% \n    tab_spanner(\n      label = \"언어코드와 언어명\",\n      columns = c(언어, 언어명)) %>% \n    tab_spanner(\n      label = \"통계수치\",\n      columns = c(문서수, 비중, 누적비중)) %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어, 언어명)) %>% \n    # tab_style(\n    #   style = cell_text(size = px(12)),\n    #   locations = cells_body(\n    #     columns = c(문서수, 비중, 누적비중)\n    #   )\n    # )  %>% \n    fmt_percent(\n      columns = c(비중, 누적비중),\n      decimals = 2\n    )  %>% \n    fmt_number(\n      columns = 문서수,\n      decimals = 0,\n      sep_mark = \",\"\n    )   %>% \n   gt_highlight_rows(\n     rows = c(1,28),\n     fill = \"lightgrey\",\n     target_col = 언어\n   )  %>% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  )  %>% \n  cols_width(\n    언어 ~ px(10),\n    언어명 ~ px(10),\n    문서수 ~ px(20),\n    비중 ~ px(30),\n    누적비중 ~ px(30)\n  )\n\ngpt_gt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPT-3 언어모형 개발에 사용된 언어별 문서 통계\n    \n\n한국어 포함 상위 28개 언어\n    \n\n\n\n\n        언어코드와 언어명\n      \n      \n        통계수치\n      \n    \n\n언어\n      언어명\n      문서수\n      비중\n      누적비중\n    \n\n\n\nen\nEnglish\n235,987,420\n93.69%\n93.69%\n\n\nde\nGerman\n3,014,597\n1.20%\n94.89%\n\n\nfr\nFrench\n2,568,341\n1.02%\n95.91%\n\n\npt\nPortuguese\n1,608,428\n0.64%\n96.54%\n\n\nit\nItalian\n1,456,350\n0.58%\n97.12%\n\n\nes\nSpanish\n1,284,045\n0.51%\n97.63%\n\n\nnl\nDutch\n934,788\n0.37%\n98.00%\n\n\npl\nPolish\n632,959\n0.25%\n98.25%\n\n\nja\nJapanese\n619,582\n0.25%\n98.50%\n\n\nda\nDanish\n396,477\n0.16%\n98.66%\n\n\nno\n-\n379,239\n0.15%\n98.81%\n\n\nro\nRomanian\n320,256\n0.13%\n98.94%\n\n\nfi\nFinnish\n315,228\n0.13%\n99.06%\n\n\nzh\nChinese\n292,976\n0.12%\n99.18%\n\n\nru\nRussian\n289,121\n0.11%\n99.29%\n\n\ncs\nCzech\n243,802\n0.10%\n99.39%\n\n\nsv\nSwedish\n161,516\n0.06%\n99.45%\n\n\nhu\nHungarian\n149,584\n0.06%\n99.51%\n\n\nzh-Hant\n-\n107,588\n0.04%\n99.55%\n\n\nid\nIndonesian\n104,437\n0.04%\n99.60%\n\n\nhr\nCroatian\n100,384\n0.04%\n99.64%\n\n\ntr\nTurkish\n91,414\n0.04%\n99.67%\n\n\nca\nCatalan\n80,899\n0.03%\n99.70%\n\n\nvi\nVietnamese\n69,147\n0.03%\n99.73%\n\n\nsl\nSlovenian\n66,333\n0.03%\n99.76%\n\n\net\nEstonian\n56,643\n0.02%\n99.78%\n\n\nsk\nSlovak\n52,826\n0.02%\n99.80%\n\n\nko\nKorean\n48,852\n0.02%\n99.82%\n\n\n\n자료출처: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\n    \n\n\n\n코드\n# gpt_gt %>%\n#   gtsave(\"images/gpt_lang.png\")"
  },
  {
    "objectID": "trends.html#인터넷-언어-데이터-fa-solid-globe",
    "href": "trends.html#인터넷-언어-데이터-fa-solid-globe",
    "title": "chatGPT",
    "section": "\n2.2 인터넷 언어 데이터 \n",
    "text": "2.2 인터넷 언어 데이터 \n\nGPT 개발에 자원에 해당되는 언어 데이터셋에 대해 살펴보자. 위키백과 Languages used on the Internet에서 데이터를 확인해보자. 특히, 웹사이트 제작에 사용된 언어를 비중으로 살펴보자.\n\n코드## 언어 콘텐츠\ncontents_raw <- read_html(x = 'https://en.wikipedia.org/wiki/Languages_used_on_the_Internet') %>% \n  html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[1]') %>% \n  html_table() %>% \n  set_names(c(\"순위\", \"언어\", \"비중\"))\n\ncontents_tbl <- contents_raw %>% \n  mutate(비중 = parse_number(비중)) %>% \n  ## 대한민국 이하 기타 ------------\n  mutate(언어 = ifelse(순위 >=17, \"기타\", 언어)) %>% \n  group_by(언어) %>% \n  summarise(비중 = sum(비중)) %>% \n  ungroup() %>% \n  arrange(desc(비중))\n\ncontents_gt <- contents_tbl %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_header(\n      title = md(\"**인터넷 콘텐츠 상위 언어별 통계**\"),\n      subtitle = \"한국어 포함 상위 17개 언어\") %>% \n    tab_source_note(\n      source_note = \"자료출처: https://en.wikipedia.org/wiki/Languages_used_on_the_Internet\") %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어)) %>% \n    fmt_number(\n      columns = c(비중),\n      decimals = 1\n    ) %>% \n    cols_label(\n      비중 = \"비중(%)\"\n    )  %>% \n    tab_footnote(\n      footnote = \"한국어보다 비중이 낮은 인도네이사, 체코, 우크라이나 등\",\n      locations = cells_body(columns = 언어, rows = 2)\n    )  \n\ncontents_gt %>% \n  gtsave(\"images/contents_gt.png\")"
  },
  {
    "objectID": "trends.html#인터넷-데이터-fa-solid-globe",
    "href": "trends.html#인터넷-데이터-fa-solid-globe",
    "title": "chatGPT",
    "section": "\n2.1 인터넷 데이터 \n",
    "text": "2.1 인터넷 데이터 \n\nGPT 개발에 자원에 해당되는 언어 데이터셋에 대해 살펴보자. 위키백과 Languages used on the Internet에서 데이터를 확인해보자. 특히, 웹사이트 제작에 사용된 언어를 비중으로 살펴보자.\n\n코드## 언어 콘텐츠\ncontents_raw <- read_html(x = 'https://en.wikipedia.org/wiki/Languages_used_on_the_Internet') %>% \n  html_element(xpath = '//*[@id=\"mw-content-text\"]/div[1]/table[1]') %>% \n  html_table() %>% \n  set_names(c(\"순위\", \"언어\", \"비중\"))\n\ncontents_tbl <- contents_raw %>% \n  mutate(비중 = parse_number(비중)) %>% \n  ## 대한민국 이하 기타 ------------\n  mutate(언어 = ifelse(순위 >=17, \"기타\", 언어)) %>% \n  group_by(언어) %>% \n  summarise(비중 = sum(비중)) %>% \n  ungroup() %>% \n  arrange(desc(비중))\n\ncontents_gt <- contents_tbl %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_options(table.width = pct(75))  %>% \n    tab_header(\n      title = md(\"**인터넷 콘텐츠 상위 언어별 통계**\"),\n      subtitle = \"한국어 포함 상위 17개 언어\") %>% \n    tab_source_note(\n      source_note = \"출처:https://en.wikipedia.org/wiki/Languages_used_on_the_Internet\") %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어, 비중)) %>% \n    fmt_number(\n      columns = c(비중),\n      decimals = 1\n    ) %>% \n    cols_label(\n      비중 = \"비중(%)\"\n    )  %>% \n    tab_footnote(\n      footnote = \"한국어보다 비중이 낮은 인도네이사, 체코, 우크라이나 등\",\n      locations = cells_body(columns = 언어, rows = 2)\n    )  \n\ncontents_gt %>% \n  gtsave(\"images/contents_gt.png\")"
  },
  {
    "objectID": "architecture.html#openai",
    "href": "architecture.html#openai",
    "title": "chatGPT",
    "section": "\n5.1 OpenAI",
    "text": "5.1 OpenAI\n\n\n\n\nCBInsights, “Analyzing OpenAI’s investment strategy: How the ChatGPT maker is building a generative AI ecosystem”"
  },
  {
    "objectID": "architecture.html#글로벌-스타트업",
    "href": "architecture.html#글로벌-스타트업",
    "title": "chatGPT",
    "section": "\n5.2 글로벌 스타트업",
    "text": "5.2 글로벌 스타트업"
  },
  {
    "objectID": "architecture.html#네이버",
    "href": "architecture.html#네이버",
    "title": "chatGPT",
    "section": "\n5.3 네이버",
    "text": "5.3 네이버\n성현희 (2022-11-04), “네이버 AI 사용에 1000개 중소 기업 ‘노크’”, 전자신문\n네이버는 ’클로바 스튜디오’를 다양한 스타트업이 활용하여 서비스를 출시하고 있다.\n\n\n\n\n\ngraph TD\n    A[\"대한민국\"] --> B((\"네이버\"))\n    B ----> E[잡브레인]\n    B ----> H[라이팅젤]\n    B --> C[모카]\n    B --> D[뤼튼] \n    B --> F[킵그로우]\n    style B fill:#FF6655AA\n    style F fill:#88ffFF\n    style I fill:#88ffFF\n\n\n\n\n\n\n\n\n\n임플로이랩스잡 브레인(Job Brain): AI 자소서 생성 기능에 적용, 완성도 높은 자소소\n앱플랫폼 라이팅젤: 대입 취업 자소서 자동왕성 기능에 적용\n아스타 컴퍼니 모카: 상품언어, 광고 헤드라인, 세일즈 카피 생성 기능에 활용\n뤼튼테크놀로지 뤼튼: 광고카피, 제품소개 문구 등 AI 카피라이팅 서비스에 활용\n유니트컴즈 킵그로우: 고객사 인스타그램에 게시물을 주기적으로 포스팅해주는 기능에 적용"
  },
  {
    "objectID": "trends.html#마이크로소프트",
    "href": "trends.html#마이크로소프트",
    "title": "chatGPT",
    "section": "\n7.2 마이크로소프트",
    "text": "7.2 마이크로소프트\n\n\n\n\n\n\n\n\n신규 코드의 40%가 Copilot으로 작성\n\n75%의 개발자가 업무에 더 큰 성취감을 느꼈습니다.\n\n87%의 개발자가 정신적 노력을 절약하는 데 도움이 되었다고 답했습니다."
  },
  {
    "objectID": "trends.html#현대백화점",
    "href": "trends.html#현대백화점",
    "title": "chatGPT",
    "section": "\n7.1 현대백화점",
    "text": "7.1 현대백화점\n현대백화점 관계자는 “이 달 초부터 2주간 시행한 관련 부처 테스트에서 통상 2주가량 소요되던 카피라이팅 업무시간이 루이스 도입 뒤 평균 3~4시간으로 줄었다”\n유선희 (2023-02-26), 광고 카피도 AI가 쓴다…현대백화점 ‘루이스’ 시스템 도입, 한겨레신문\n현대백화점이 광고 카피와 판촉행사 소개문 등 마케팅 문구 제작을 위해 특별히 ’고용’한 인공지능(AI) 카피라이팅 시스템은 네이버 ’하이버클로바’를 기본 엔진으로 추가학습(최근 3년 동안 사용한 광고 카피, 판촉행사에서 쓴 문구 중 소비자 호응이 컸던 데이터 1만여건을 집중적으로 학습)하여 개발\n\n\nAI 직원\n활용화면\n루이스"
  },
  {
    "objectID": "trends.html#이미지",
    "href": "trends.html#이미지",
    "title": "chatGPT",
    "section": "\n7.3 이미지",
    "text": "7.3 이미지\n\n\n\n\n웹툰을 제작하는 스튜디오에서는 웹툰 작가들과 어시스트들이 매우 노동집약적인 작업으로 창작활동을 하고 있다. 현재 웹툰 제작 공정은 콘티, 스케치, 라인(펜선), 채색, 배경, 출판 작업의 순서로 이뤄진다. 한국만화영상진흥원과 협력하는 실제 웹툰 작가들은 특정작업이 아닌 모든 공정에서 제작 생산성 향상을 위한 자동화 기술이 필요하다는 결론에 도달함. (김현진, 2021)"
  },
  {
    "objectID": "trends.html#공상과학소설",
    "href": "trends.html#공상과학소설",
    "title": "chatGPT",
    "section": "\n8.1 공상과학소설",
    "text": "8.1 공상과학소설\n공상과학 및 판타지 잡지 클라크스월드(Clarkesworld)는 AI가 생성한 소설라는 비난을 받은 후 신규 공상과학소설이 급증한 것이 AI 기계로 작성된 원인을 큰 것으로 파악하고 2월 20일부터 공식적으로 투고를 중단했다.\nNeil Clark (2023-02-15), “A Concerning Trend”, CLARKESWORLD MAGAZINE\n\n\n\n\n2023-02-15 기준\n\n\n\n\n2023-02-20 기준"
  },
  {
    "objectID": "image2image.html#chatgpt-프롬프트",
    "href": "image2image.html#chatgpt-프롬프트",
    "title": "chatGPT",
    "section": "\n2.1 chatGPT 프롬프트",
    "text": "2.1 chatGPT 프롬프트\nrecommend the most famous painting style in history\n\n\n\n\n\n\ncompletion\n\n\n\n\n\nHere are some of the most famous painting styles in history:\n\nRenaissance: The Renaissance was a cultural movement in Italy from the 14th to the 17th century, characterized by a renewed interest in classical art, philosophy, and science. Renaissance paintings are known for their realism, balance, and harmony.\nBaroque: The Baroque style was popular in Europe from the late 16th to the early 18th century. Baroque paintings are known for their dramatic lighting, intense emotions, and dynamic compositions.\nImpressionism: Impressionism was a modernist movement in French painting in the late 19th century. Impressionist paintings are known for their loose brushstrokes, light-filled compositions, and focus on capturing fleeting moments.\nSurrealism: Surrealism was a cultural movement in the 20th century that aimed to liberate the imagination and explore the subconscious. Surrealist paintings are known for their dreamlike and fantastical imagery.\nAbstract Expressionism: Abstract Expressionism was a modernist movement in American painting in the mid-20th century. Abstract Expressionist paintings are known for their large canvases, gestural brushstrokes, and emphasis on the process of creation.\n\nThese are just a few examples of famous painting styles in history. There are many other styles that have influenced and shaped the course of art history.\n\n\n\nOpen AI - Create image API"
  },
  {
    "objectID": "image2image.html#화풍을-달리한-그림",
    "href": "image2image.html#화풍을-달리한-그림",
    "title": "chatGPT",
    "section": "\n2.2 화풍을 달리한 그림",
    "text": "2.2 화풍을 달리한 그림\n\n\n르네상스(Renaissance)\n바로크(Baroque)\n인상주의(Impressionism)\n초현실주의(Surrealism)\n추상표현주의(Abstract Expressionism)\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance <- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\n르네상스(Renaissance)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque <- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\n바로크(Baroque)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism <- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\n인상주의(Impressionism)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism <- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\n초현실주의(Surrealism)\n\n\n\n\n\n코드response <- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism <- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")\n\n\n\n\n추상표현주의(Abstract Expressionism)"
  },
  {
    "objectID": "rcoding.html#설치",
    "href": "rcoding.html#설치",
    "title": "chatGPT",
    "section": "\n2.1 설치",
    "text": "2.1 설치\ngpttools GitHub 저장소에서 바로 설치한다.\nrequire(remotes)\nremotes::install_github(\"JamesHWade/gpttools\")"
  },
  {
    "objectID": "rcoding-copilot.html",
    "href": "rcoding-copilot.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 GitHub Copilot\nGitHub Copilot은 Visual Studio Code를 비롯한 다양한 코드 편집기와 통합할 수 있는 AI 기반 코딩 도우미(Assistant)입니다. Copilot은 개발자가 보다 효율적이고 정확하게 코드를 작성할 수 있도록 도와주는 지능형 도우미 기능 제공하기 위해 GitHub와 OpenAI가 공동으로 개발했습니다.\nCopilot은 머신 러닝 알고리즘을 사용하여 다른 개발자가 작성한 코드를 분석하고 학습한 다음 현재 코드베이스에 삽입할 수 있는 제안 및 코드 조각을 생성합니다. 이 기능은 방대한 코드 코퍼스를 학습한 신경망을 사용하여 개발자가 작성할 가능성이 있는 다음 코드 줄을 예측하는 방식으로 작동합니다.\n이 기술을 통해 Copilot은 현재 코드의 컨텍스트를 기반으로 전체 함수 또는 클래스를 제안하고 구문적으로 정확하고 모범 사례를 준수하는 코드를 생성할 수도 있습니다. 또한 Copilot은 생성하는 코드의 의미와 목적을 이해할 수 있으므로 새로운 아이디어를 빠르게 프로토타입으로 만들거나 문제에 대한 다양한 해결책을 모색해야 하는 개발자에게 유용한 도구입니다.\nGitHub Copilot은 Python, JavaScript, TypeScript, Ruby, Go, R 등 다양한 프로그래밍 언어와 원활하게 작동하도록 설계되었습니다. 또한 사용자 지정이 가능하므로 개발자가 특정 코드베이스에 대해 학습시켜 제안을 개선하고 더욱 정확하게 만들 수 있습니다.\nCopilot을 사용하면 얻을 수 있는 잠재적 이점은 상당합니다. 코드 작성에 필요한 시간과 노력을 줄임으로써 개발자는 새로운 기능을 설계하거나 기존 기능을 개선하는 등 더 복잡한 작업에 집중할 수 있습니다. 또한 Copilot은 모범 사례를 따르고 구조적으로 건전하고 읽기 쉬운 코드를 생성하도록 프로그래밍되어 있으므로 오류와 버그를 줄이는 데 도움이 될 수 있습니다.\n전반적으로 GitHub Copilot은 AI 지원 코딩 분야에서 중요한 진전을 이루었으며, 개발자의 코드 작업 및 협업 방식을 바꿀 수 있는 잠재력을 가지고 있습니다.\n\n2 RStudio\nR 사용자는 RStudio를 많이 사용했으나 최근 chatGPT, Github Copilot의 부상으로 개발방식에 변화가 생겨나고 있다. 하지만, RStudio가 곧 Copilot 지원하지는 않을 예정이다. RStudio는 무료 오픈 소스인 반면 Copilot은 Microsoft의 독점 기술이며, Microsoft는 공식 비공개 소스 소프트웨어 및 플러그인에서만 사용할 수 있도록 라이선스를 부여하고 있다. 시중에 존재하는 몇몇 타사 플러그인은 공식 플러그인에서 바이너리를 추출하여 작동하지만, RStudio에는 이런 우회 편법적인 방법을 취하고 있지는 않고 있다.\nGithub Copilot integration with RStudio #10148\nMicrosoft와 Posit이 RStudio 내에서 Copilot을 허용하는 방법과 RStudio가 공개 데이터 및 기술을 사용하여 Copilot과 유사한 AI 프로그래밍 도우미를 구현하는 방법도 있지만 이 중 어느 것도 향후 6개월 이내에(특히 향후 6~8주 이내에) 출시될 가능성은 전무하다. 따라서, Copilot을 사용하고자 하는 경우 VS Code를 사용하는 것이 유일한 방법이다.\n\n\n\n\n\n3 VS 코드\nGitHub, Copilot for R\nVisual Studio Code에서 R 코드 작성 프로세스의 속도를 높일 수 있다. Copilot은 기존 프로젝트의 컨텍스트를 기반으로 R 스크립트 혹은 함수전체를 동적으로 실행한다. 예를 들어, R을 새로운 Azure OpenAI 서비스와 인터페이스하는 함수를 작성하고 Copilot이 필요한 코드를 생성하여 개발 속도를 높일 수 있다.\n\n\n\n\n\n\nCopilot\nchatGPT"
  },
  {
    "objectID": "why_llm.html",
    "href": "why_llm.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 들어가며\nGPT-3(Generative Pre-trained Transformer 3)와 같은 거대 언어 모델은 인간과 유사한 언어를 처리하고 생성할 수 있기 때문에 이 시대에 중요한 역할을 한다. 이를 통해 자연어 처리, 챗봇, 언어 번역, 콘텐츠 제작, 코딩 등 다양한 애플리케이션에 수많은 가능성을 열었다는 평가를 받고 있다.\n거대 언어 모델이 중요한 몇 가지 이유를 꼽으면 다음과 같다.\n\n자연어 처리(Natural language processing): GPT-3와 같은 거대 언어 모델은 대량의 텍스트 데이터를 처리할 수 있고 언어의 문맥과 의미를 이해할 수 있어 감정 분석, 언어 번역, 텍스트 분류와 같은 자연어 처리 작업을 수행할 수 있다.\n챗봇(Chatbot): 거대 언어 모델을 사용하여 자연어 쿼리를 이해하고 응답할 수 있는 대화형 대리인(챗봇)를 만들 수 있다. 이러한 챗봇은 고객 지원, 가상 비서 및 기타 다양한 애플리케이션에서 사용할 수 있다.\n언어 번역(Language translation): 거대 언어 모델은 여러 언어에 대해 학습할 수 있으며 고품질 언어 번역을 수행한다. 이는 관광, 전자상거래, 국제 무역 등 다양한 산업에서 유용하게 사용될 수 있다.\n콘텐츠 생성(Content creation): 거대 언어 모델은 기사, 요약, 시 등 사람과 유사한 텍스트 콘텐츠를 생성할 수 있다. 이는 저널리즘, 콘텐츠 제작, 광고 등 다양한 산업에서 활용할 수 있다.\n코딩(Coding): GPT-3는 소프트웨어 개발 및 자동화에 광범위한 영향을 미칠 수 있는 컴퓨터 코드를 생성할 수 있는 능력을 입증했다.\n\n요약하면, 거대 언어 모델은 우리가 기계와 상호작용하고 작업을 수행하는 방식을 혁신할 수 있는 잠재력을 가지고 있어 우리 시대에 중요한 기술이 될 것임은 자명하다.\n\n\n2019년\n2021년\n2022년\n\n\n\n\n\n(Sanh et al., 2019)\n\n\n\n\n\n\nEfficient Natural Language Processing\n\n\n\n\n![langcon 2023 by 신정규(images/LLM_langcon2023.png)\n\n\n\n\n2 모형크기\nquestion-answering tasks (open-domain closed-book variant), cloze and sentence-completion tasks, Winograd-style tasks, in-context reading comprehension tasks, common-sense reasoning tasks, SuperGLUE tasks, and natural language inference tasks가 포함된 총 29개 작업 중 28개 영역에서 PaLM 540B가 이전 거대 언어모형 GLaM, GPT-3, Megatron-Turing NLG, Gopher, Chinchilla, LaMDA 을 가볍게 능가했다.\nSharan Narang and Aakanksha Chowdhery (APRIL 04, 2022), “Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance”, Software Engineers, Google Research\n\n\nLLM 진화\n80억 패러미터\n400억\n640억\n5,400억\n성능\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 거대언어모형 성능\n자연어 처리(NLP) 및 머신 러닝 분야의 여러 발전으로 인해 GPT-3와 같은 대규모 언어 모델의 성능이 이전 모델보다 향상되었다. 주요 원인으로 다음을 꼽을 수 있다.\n\n규모(Scale): 대규모 언어 모델은 방대한 양의 텍스트 데이터로 학습되어 언어의 더 많은 뉘앙스를 포착하고 문맥을 더 잘 이해할 수 있다. GPT-3는 45테라바이트가 넘는 텍스트 데이터셋으로 학습되었다고 알려져 지금까지 사전 학습된 언어 모델 중 가장 큰 규모를 갖고 있다.\n아키텍처(Architecture): GPT-3는 병렬 처리가 가능한 트랜스포머(Transformer) 기반 아키텍처를 사용하여 학습 시간을 단축하고 성능을 향상시켰다.\n사전 학습(Pre-training): 대규모 언어 모델은 방대한 양의 텍스트 데이터로 사전 학습되어 다양한 작업에 적용할 수 있는 일반적인 언어 패턴과 관계를 학습할 수 있다. GPT-3는 비지도 학습을 사용하여 사전 학습되므로 특정 작업을 염두에 두지 않고 원시 텍스트 데이터에서 학습했다.\n미세 조정(Fine-tuning): 언어 번역이나 텍스트 분류와 같은 특정 작업을 위해 대규모 언어 모델을 미세 조정(Fine-tuning) 작업을 수행한다. 이 과정에는 해당 작업에 특화된 소규모 데이터셋로 모델을 추가 학습시켜 성능을 더욱 향상시킨다.\n전이 학습(Transfer learning): 대규모 언어 모델은 한 작업에서 학습한 지식을 다른 작업으로 전이시킬 수 있다. 즉, 언어 번역과 같은 한 작업에서 학습된 모델을 더 작은 데이터셋을 사용하여 감정 분석과 같은 다른 작업에 맞게 추가 학습작업(Fine-tuning)을 시킬 수 있다.\n\n요약하면, 대규모 언어 모델의 성능은 규모, 아키텍처, 사전 학습, 미세 조정 및 전이 학습의 발전으로 인해 이전 모델보다 더 우수하다. 이러한 발전 덕분에 대규모 언어 모델은 다양한 언어 작업에서 최첨단 성능을 달성할 수 있게 되어 자연어 처리 및 머신 러닝 분야에서 강력한 도구가 된 것이다.\n\n\n(Wei et al., 2022)\n\n\n\n4 수학\nLewkowycz et al. (2022)\n\n\n미네르바 LM\n손으로 풀기\n시각화\nSympy 해법\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\ngiven_line <- function(x)  10 + 4 * x\nsolve_line <- function(x) -10 + 4 *x\n\nggplot() +\n  geom_point(aes(x = 5, y = 10), size = 3) +\n  geom_function(fun = given_line, color = \"blue\", size = 1.5) +\n  geom_function(fun = solve_line, color = \"red\", size = 1.5, alpha = 0.5) +\n  theme_classic() +\n  scale_x_continuous(limits = c(-7, 7), breaks = seq(-7, 7, 1)) +\n  scale_y_continuous(limits = c(-20, 20), breaks = seq(-20, 20, 1)) +\n  geom_vline(xintercept = 0) +\n  geom_hline(yintercept = 0) \n\n\n\n\n\n\n\n\n\n\nfrom sympy import *\n\nx, y, b = symbols('x y b')\n\ngiven_eq = y - (4*x + 10)\n\nparallel_eq = y - (4*x + b)\n\nintercept_eq = parallel_eq.subs([(x, 5), (y, 10)])\n\nsolveset(Eq(intercept_eq, 0), b)\n#> {-10}\n\n\n\n\n\n5 다양한 사례 (PaLM)\n5,400 억 패러미터를 장착한 Pathways Language Model (PaLM)의 성능을 실감해보자.\n\n\n다양한 기능\n추론\n코딩\n\n\n\n\n\n\n\n\n\n추론(Reasoning)\n\n\n\n\n\n\n코딩(Code Generation)\n\n\n\n\n\n\n\n\n6 개발비\nEstimating 🌴PaLM’s training cost\n언어 모형 개발은 2010년 이후 개발비용이 급격히 증가하고 있으며 그 추세는 상상을 초월한다.\n\n\nOur World in Data\nLennart Heim\n\n\n\n\n\n\n\n\n\n\n\n\n\n7 생성모형의 부작용\n생성 AI를 통해 인간이 생성한 데이터와 기계가 생성한 데이터가 무작위로 섞인 지금까지 경험하지 못한 세상이 출현하고 있다. 즉, 생성 AI 모형에서 이미지, 텍스트, 동영상 등 무수히 많은 데이터가 인터넷에 공개 및 공유될 것이며 기계학습 및 딥러닝 생성모형는 결국 실제 데이터와 기계가 생성한 데이터를 입력값으로 인공지능 모형을 생성하게 된다. 하지만 이런 경우 과연 AI 모형은 어떤 특성을 갖게 될 것인가? 데이터 증강(Data Augmentation)처럼 더 좋은 성능을 갖는 AI 모형이 될 것이가 아니면 그 반대의 모습을 가지게 될 것인가? 논문(Hataya et al., 2022)에서는 부정적인 효과도 있다고 주장하고 있다.\n\n\n현재 상황\n기계오염된 데이터\n\n\n\n\n\n\n\n\n\n\n\n기계생성 데이터 사용하여 나온 결과물\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\nHataya, R., Bao, H., & Arai, H. (2022). Will large-scale generative models corrupt future datasets? arXiv Preprint arXiv:2211.08095.\n\n\nLewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramasesh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., et al. (2022). Solving quantitative reasoning problems with language models. arXiv Preprint arXiv:2206.14858.\n\n\nSanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. arXiv Preprint arXiv:1910.01108.\n\n\nWei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. (2022). Emergent abilities of large language models. arXiv Preprint arXiv:2206.07682."
  },
  {
    "objectID": "ide.html",
    "href": "ide.html",
    "title": "chatGPT",
    "section": "",
    "text": "chatGPT 는 데이터 과학자 개발생산성을 비약적으로 증진시키는 것으로 알려져있다. 특히 데이터 과학에서 개발생산성 관련 큰 역할을 수행하는 것이 통합개발환경(IDE)이다. Posit에서 개발한 RStudio가 출현하면서 기존 R언어를 다양한 편집기(VIM,Emacs 등)로 주로 개발하던 문화를 획기적으로 바뀌었다면 이제는 GitHub Copilot을 어떤 형태로든 붙여서 사용하면 더욱 생산성을 높일 수 있다.\n기존 RStudio에서 데이터 과학 개발부터 제품/서비스 제작까지 모두 진행했다면, 이제 마이크로소프트가 Posit RStudio 무료 IDE에 GitHub Copilot 상용 소프트웨어를 제공하지 않고 GitHub Copilot에 대응하는 오픈소스 소프트웨어가 현재시점 기준 존재하지 않기 때문에 부득이 이 둘을 나눠 개발을 진행해야 데이터 과학자로서 생산성을 높일 수 있다."
  },
  {
    "objectID": "ide.html#keybindings.json",
    "href": "ide.html#keybindings.json",
    "title": "chatGPT",
    "section": "\n4.1 keybindings.json\n",
    "text": "4.1 keybindings.json\n\nkeybindings.json 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 등록시킨다. 자료출처: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n\n\n\n\n\n\nkeybindings.json 설정파일 예시\n\n\n\n\n\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: '이광춘'\\ndate: '2023-03-07'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "ide.html#html-미리보기",
    "href": "ide.html#html-미리보기",
    "title": "chatGPT",
    "section": "\n4.2 HTML 미리보기",
    "text": "4.2 HTML 미리보기\n.Rmd 파일을  CTRL  +  Shift  +  k  단축키로 컴파일시키면 .html 파일이 생성된다. .html 파일 결과를 직접 실시간으로 확인하고자 한다면, 마이크로소프트가 개발한 Live Preview - VS Code Extension 플러그인을 설치한다."
  },
  {
    "objectID": "ide.html#r-extension-설치",
    "href": "ide.html#r-extension-설치",
    "title": "chatGPT",
    "section": "\n1.1 R extension 설치",
    "text": "1.1 R extension 설치\nR extension을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. VS Code 에 필수적인 R extension은 다음을 꼽을 수 있다. R extension을 설치하면 RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 편리하다.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Code를 실행하고 R Extension 설치"
  },
  {
    "objectID": "ide.html#헬로우-월드",
    "href": "ide.html#헬로우-월드",
    "title": "chatGPT",
    "section": "\n1.2 헬로우 월드",
    "text": "1.2 헬로우 월드\nR Extension 설치되면 코드 창 상단에 실행버튼이 활성화되고 Ctrl + Enter 혹은 Ctrl + Shift + Enter\n\n\nR 코드 실행화면"
  },
  {
    "objectID": "ide.html#유튜브-동영상",
    "href": "ide.html#유튜브-동영상",
    "title": "chatGPT",
    "section": "\n1.3 유튜브 동영상",
    "text": "1.3 유튜브 동영상"
  },
  {
    "objectID": "ide.html#코딩-글꼴",
    "href": "ide.html#코딩-글꼴",
    "title": "chatGPT",
    "section": "\n2.1 코딩 글꼴",
    "text": "2.1 코딩 글꼴\n다른 언어와 마찬가지로 R 코드로 데이터 과학 제품을 개발할 경우 글꼴도 코딩에 적합한 한글 글꼴을 설정한다.\n먼저 D2 Coding 글꼴을 다운로드 받아 운영체제에 설치한다.\nVS Code 좌측 하단 톱니바퀴  Settings  설정을 클릭 혹은 메뉴에서 “File” → “Preferences” → “Settings”를 통해 편집기 (Text Editor)로 들어가 운영체제에 설치한 코딩 폰트를 지정한다. Font Ligatures 도 true로 설정한다. 이를 통해 < - 표시가 ← 로 화면에 표현된다.\n\n\nD2코딩 글꼴 장착"
  },
  {
    "objectID": "ide.html#단축키",
    "href": "ide.html#단축키",
    "title": "chatGPT",
    "section": "\n2.2 단축키",
    "text": "2.2 단축키\nR 코드 개발을 진행할 때  %>% ,  ←  두가지 기능이 가장 많이 사용되는 단축키로 RStudio에서는 기본으로 지원되고 있다. VS Code에서 자주 사용되는 단축키를  CTRL  +  Shift  +  m ,  Alt  +  -  를 적용시키는 방법을 살펴보자.\n만약 VS Code에서 단축키 설정 기능을 활용한다. How to add R {magrittr}’s %>% Pipe Operator in VSCode as Keyboard Shortcut\n\n윈도우즈: File > Preferences > Keyboard Shortcuts.\n맥: Code > Preferences > Keyboard Shortcuts\n\nkeybindings.json 파일에  %>% ,  ←  단축키 기능을 추가한다.\n\n\n자주 사용되는 R 단축키 설정"
  },
  {
    "objectID": "ide.html#패널",
    "href": "ide.html#패널",
    "title": "chatGPT",
    "section": "\n2.3 패널",
    "text": "2.3 패널\nRStudio는 코딩기반 데이터 분석과 통계에 최적화된 개발환경이다. 즉, 편집기 패널, 콘솔/터미널 패널, 그래프 패널, 도움말/개발 패널로 구성된 꼭 필요한 패널만 구성되어 있다.\n\n\n패널 설정\n설정 후\n\n\n\n\n\nVS Code: View → Editor Layout → Grid (2x2)\n\n\n\n\n\n\n도움말과 그래프"
  },
  {
    "objectID": "ide.html#설치",
    "href": "ide.html#설치",
    "title": "chatGPT",
    "section": "설치",
    "text": "설치\n# 출시버전 설치\npip3 install -U radian\n# 실행\nradian"
  },
  {
    "objectID": "ide.html#실행화면",
    "href": "ide.html#실행화면",
    "title": "chatGPT",
    "section": "실행화면",
    "text": "실행화면"
  },
  {
    "objectID": "ide.html#vs-코드-콘솔",
    "href": "ide.html#vs-코드-콘솔",
    "title": "chatGPT",
    "section": "\n3.2 VS 코드 콘솔",
    "text": "3.2 VS 코드 콘솔\nradiant를 설치한 후에 Rpath 가 아니라 Rterm에서 설정해줘야 한다.\n\n\n\n맥\n\n\n\n\n윈도우즈\n\n\n\n\n적용결과"
  },
  {
    "objectID": "ide.html#독립-사용사례",
    "href": "ide.html#독립-사용사례",
    "title": "chatGPT",
    "section": "\n3.1 독립 사용사례",
    "text": "3.1 독립 사용사례"
  },
  {
    "objectID": "ide.html#펭귄-데이터셋",
    "href": "ide.html#펭귄-데이터셋",
    "title": "chatGPT",
    "section": "\n5.1 펭귄 데이터셋",
    "text": "5.1 펭귄 데이터셋"
  },
  {
    "objectID": "ide.html#호박-데이터셋",
    "href": "ide.html#호박-데이터셋",
    "title": "chatGPT",
    "section": "\n5.2 호박 데이터셋",
    "text": "5.2 호박 데이터셋\n\n<p>:::</p>"
  },
  {
    "objectID": "ide.html#중요-추가설정",
    "href": "ide.html#중요-추가설정",
    "title": "chatGPT",
    "section": "\n5.1 중요 추가설정",
    "text": "5.1 중요 추가설정\nPrincipal Cloud Advocate at Microsoft David Smith가 “New York Open Statistical Programming Meetup, 28 February 2023”에서 발표한 Copilot for R 내용 중 VS 코드 환경설정부분이다.\nCopilot for R\n\nVS 코드\n\nCopilot extension\nR Extension for Visual Studio Code\ncopilot 추천에 집중하기 위해서 다음 사항도 설정에 반영한다.\n\nEditor > Hover (disabled)\nEditor > Quick Suggestions (off)\nEditor > Parameter Hints (disabled)\n\n\n\n\nR 패키지 설치 및 opitions()\n\nhttr, jsonlite, tidyverse, tidymodels, docopt, httpuv\n가독성 높은 그래프 출력: options(vsc.dev.args = list(width = 800, height = 600))"
  },
  {
    "objectID": "ide.html#실제-적용-사례",
    "href": "ide.html#실제-적용-사례",
    "title": "chatGPT",
    "section": "\n5.2 실제 적용 사례",
    "text": "5.2 실제 적용 사례\n펭귄과 호박 데이터를 적용한 사례 시연을 살펴보자.\n펭귄 데이터셋\n\n\n\n\n호박 데이터셋\n\n<div id=\"quarto-navigation-envelope\" class=\"hidden\">\n<p><span class=\"hidden\" data-render-id=\"quarto-int-sidebar-title\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar-title\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Home\">Home</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:생성 AI\">생성 AI</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:chatGPT 이해\">chatGPT 이해</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:추세 트렌드\">추세 트렌드</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:왜 거대언어모형인가?\">왜 거대언어모형인가?</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:------------------\">——————</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:이미지 생성\">이미지 생성</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:GPT R 코딩개발\">GPT R 코딩개발</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:부조종사 R 코딩개발\">부조종사 R 코딩개발</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:수학문제\">수학문제</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:데이터 과학문제\">데이터 과학문제</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:DeepL 번역 API\">DeepL 번역 API</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:chatGPT 응용사례\">chatGPT 응용사례</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:활용사례\">활용사례</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:보도자료 작성\">보도자료 작성</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:R 소개영상\">R 소개영상</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:데이터 과학 책\">데이터 과학 책</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:논문 초록\">논문 초록</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:학술연구(R&amp;D)\">학술연구(R&amp;D)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:데이터 문해력\">데이터 문해력</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:인터페이스\">인터페이스</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:BERT\">BERT</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:통합개발환경(IDE)\">통합개발환경(IDE)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:파이썬 환경구축\">파이썬 환경구축</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:HuggingfaceR - 모형통계\">HuggingfaceR - 모형통계</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Hugging Face\">Hugging Face</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Hugging Face(윈도우)\">Hugging Face(윈도우)</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:HF 파이프라인\">HF 파이프라인</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:게시글\">게시글</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:R사용자회\">R사용자회</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:Open Assistant\">Open Assistant</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:RTutor\">RTutor</span> <span class=\"hidden\" data-render-id=\"quarto-int-navbar:About\">About</span> <span class=\"hidden\" data-render-id=\"footer-left\"><a href=\"https://quarto.org/\">Quarto</a> 개발</span> <span class=\"hidden\" data-render-id=\"footer-center\"><a href=\"mailto:admin@r2bit.com\">한국 R 사용자회</a></span> <span class=\"hidden\" data-render-id=\"footer-right\"><a href=\"https://github.com/bit2r/chatGPT\">Github 코드 저장소</a></span></p>\n</div>\n<div id=\"quarto-meta-markdown\" class=\"hidden\">\n<p><span class=\"hidden\" data-render-id=\"quarto-metatitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\">chatGPT</span> <span class=\"hidden\" data-render-id=\"quarto-metasitename\">chatGPT</span></p>\n</div>\n<!-- -->\n<div class=\"quarto-embedded-source-code\">\n<div class=\"sourceCode\" id=\"cb5\" data-shortcodes=\"false\"><pre class=\"sourceCode markdown\"><code class=\"sourceCode markdown\"><span id=\"cb5-1\"><a href=\"#cb5-1\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">---</span></span>\n<span id=\"cb5-2\"><a href=\"#cb5-2\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">title:</span><span class=\"co\"> \"chatGPT\"</span></span>\n<span id=\"cb5-3\"><a href=\"#cb5-3\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">subtitle:</span><span class=\"co\"> \"통합개발환경(IDE)\"</span></span>\n<span id=\"cb5-4\"><a href=\"#cb5-4\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">description:</span><span class=\"co\"> \"비쥬얼 스튜디오 코드 IDE를 사용하여 개발 생산성을 높인다.\"</span></span>\n<span id=\"cb5-5\"><a href=\"#cb5-5\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">author:</span></span>\n<span id=\"cb5-6\"><a href=\"#cb5-6\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  - name: 이광춘</span></span>\n<span id=\"cb5-7\"><a href=\"#cb5-7\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    url: https://www.linkedin.com/in/kwangchunlee/</span></span>\n<span id=\"cb5-8\"><a href=\"#cb5-8\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    affiliation: 한국 R 사용자회</span></span>\n<span id=\"cb5-9\"><a href=\"#cb5-9\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    affiliation-url: https://github.com/bit2r</span></span>\n<span id=\"cb5-10\"><a href=\"#cb5-10\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">title-block-banner:</span><span class=\"co\"> true</span></span>\n<span id=\"cb5-11\"><a href=\"#cb5-11\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">#title-block-banner: \"#562457\"</span></span>\n<span id=\"cb5-12\"><a href=\"#cb5-12\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">format:</span></span>\n<span id=\"cb5-13\"><a href=\"#cb5-13\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  html:</span></span>\n<span id=\"cb5-14\"><a href=\"#cb5-14\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    css: css/quarto.css</span></span>\n<span id=\"cb5-15\"><a href=\"#cb5-15\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    theme: flatly</span></span>\n<span id=\"cb5-16\"><a href=\"#cb5-16\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    code-fold: true</span></span>\n<span id=\"cb5-17\"><a href=\"#cb5-17\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    code-overflow: wrap</span></span>\n<span id=\"cb5-18\"><a href=\"#cb5-18\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc: true</span></span>\n<span id=\"cb5-19\"><a href=\"#cb5-19\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc-depth: 3</span></span>\n<span id=\"cb5-20\"><a href=\"#cb5-20\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    toc-title: 목차</span></span>\n<span id=\"cb5-21\"><a href=\"#cb5-21\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    number-sections: true</span></span>\n<span id=\"cb5-22\"><a href=\"#cb5-22\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    highlight-style: github    </span></span>\n<span id=\"cb5-23\"><a href=\"#cb5-23\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    self-contained: false</span></span>\n<span id=\"cb5-24\"><a href=\"#cb5-24\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">filters:</span></span>\n<span id=\"cb5-25\"><a href=\"#cb5-25\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">   - lightbox</span></span>\n<span id=\"cb5-26\"><a href=\"#cb5-26\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">   - custom-callout.lua   </span></span>\n<span id=\"cb5-27\"><a href=\"#cb5-27\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">lightbox:</span><span class=\"co\"> auto</span></span>\n<span id=\"cb5-28\"><a href=\"#cb5-28\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">link-citations:</span><span class=\"co\"> yes</span></span>\n<span id=\"cb5-29\"><a href=\"#cb5-29\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">knitr:</span></span>\n<span id=\"cb5-30\"><a href=\"#cb5-30\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  opts_chunk: </span></span>\n<span id=\"cb5-31\"><a href=\"#cb5-31\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    message: false</span></span>\n<span id=\"cb5-32\"><a href=\"#cb5-32\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    warning: false</span></span>\n<span id=\"cb5-33\"><a href=\"#cb5-33\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    collapse: true</span></span>\n<span id=\"cb5-34\"><a href=\"#cb5-34\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    comment: \"#&gt;\" </span></span>\n<span id=\"cb5-35\"><a href=\"#cb5-35\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">    R.options:</span></span>\n<span id=\"cb5-36\"><a href=\"#cb5-36\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">      knitr.graphics.auto_pdf: true</span></span>\n<span id=\"cb5-37\"><a href=\"#cb5-37\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"an\">editor_options:</span><span class=\"co\"> </span></span>\n<span id=\"cb5-38\"><a href=\"#cb5-38\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">  chunk_output_type: console</span></span>\n<span id=\"cb5-39\"><a href=\"#cb5-39\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">---</span></span>\n<span id=\"cb5-40\"><a href=\"#cb5-40\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-41\"><a href=\"#cb5-41\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`chatGPT`</span> 는 데이터 과학자 개발생산성을 비약적으로 증진시키는 것으로 알려져있다.</span>\n<span id=\"cb5-42\"><a href=\"#cb5-42\" aria-hidden=\"true\" tabindex=\"-1\"></a>특히 데이터 과학에서 개발생산성 관련 큰 역할을 수행하는 것이 통합개발환경(IDE)이다.</span>\n<span id=\"cb5-43\"><a href=\"#cb5-43\" aria-hidden=\"true\" tabindex=\"-1\"></a>Posit에서 개발한 RStudio가 출현하면서 기존 R언어를 다양한 편집기(VIM,Emacs 등)로 </span>\n<span id=\"cb5-44\"><a href=\"#cb5-44\" aria-hidden=\"true\" tabindex=\"-1\"></a>주로 개발하던 문화를 획기적으로 바뀌었다면 이제는 GitHub Copilot을 어떤 형태로든</span>\n<span id=\"cb5-45\"><a href=\"#cb5-45\" aria-hidden=\"true\" tabindex=\"-1\"></a>붙여서 사용하면 더욱 생산성을 높일 수 있다.</span>\n<span id=\"cb5-46\"><a href=\"#cb5-46\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-47\"><a href=\"#cb5-47\" aria-hidden=\"true\" tabindex=\"-1\"></a>기존 RStudio에서 데이터 과학 개발부터 제품/서비스 제작까지 모두 진행했다면,</span>\n<span id=\"cb5-48\"><a href=\"#cb5-48\" aria-hidden=\"true\" tabindex=\"-1\"></a>이제 마이크로소프트가 Posit RStudio 무료 IDE에 GitHub Copilot 상용 소프트웨어를 </span>\n<span id=\"cb5-49\"><a href=\"#cb5-49\" aria-hidden=\"true\" tabindex=\"-1\"></a>제공하지 않고 GitHub Copilot에 대응하는 오픈소스 소프트웨어가 현재시점 기준 존재하지 않기 때문에</span>\n<span id=\"cb5-50\"><a href=\"#cb5-50\" aria-hidden=\"true\" tabindex=\"-1\"></a>부득이 이 둘을 나눠 개발을 진행해야 데이터 과학자로서 생산성을 높일 수 있다.</span>\n<span id=\"cb5-51\"><a href=\"#cb5-51\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-52\"><a href=\"#cb5-52\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/ide-copilot.png)</span></span>\n<span id=\"cb5-53\"><a href=\"#cb5-53\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-54\"><a href=\"#cb5-54\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># VS 코드 설치</span></span>\n<span id=\"cb5-55\"><a href=\"#cb5-55\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-56\"><a href=\"#cb5-56\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS 코드를 통해 데이터 과학 제품개발을 할 경우 다음 사항에 맞춰 개발을 시작한다.</span>\n<span id=\"cb5-57\"><a href=\"#cb5-57\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-58\"><a href=\"#cb5-58\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">1. </span>R을 설치한다.</span>\n<span id=\"cb5-59\"><a href=\"#cb5-59\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">2. </span><span class=\"in\">`languageserver`</span> 패키지를 설치한다.</span>\n<span id=\"cb5-60\"><a href=\"#cb5-60\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span><span class=\"in\">`install.packages(\"languageserver\")`</span></span>\n<span id=\"cb5-61\"><a href=\"#cb5-61\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">3. </span>Visual Studio Code 에서 <span class=\"in\">`R extension`</span>을 설치한다.</span>\n<span id=\"cb5-62\"><a href=\"#cb5-62\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">4. </span><span class=\"in\">`.R`</span> 파일에 개발을 시작한다.</span>\n<span id=\"cb5-63\"><a href=\"#cb5-63\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-64\"><a href=\"#cb5-64\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-65\"><a href=\"#cb5-65\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## `R extension` 설치</span></span>\n<span id=\"cb5-66\"><a href=\"#cb5-66\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-67\"><a href=\"#cb5-67\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`R extension`</span>을 설치하게 되면 VS Code에서 R 코드 개발을 원활히 할 수 있도록 지원한다. </span>\n<span id=\"cb5-68\"><a href=\"#cb5-68\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS Code 에 필수적인 <span class=\"in\">`R extension`</span>은 다음을 꼽을 수 있다. <span class=\"in\">`R extension`</span>을 설치하면</span>\n<span id=\"cb5-69\"><a href=\"#cb5-69\" aria-hidden=\"true\" tabindex=\"-1\"></a>RStudio에서 기본설정으로 지정된 단축키를 별도 설정없이 자동 지정되기 때문에 </span>\n<span id=\"cb5-70\"><a href=\"#cb5-70\" aria-hidden=\"true\" tabindex=\"-1\"></a>편리하다.</span>\n<span id=\"cb5-71\"><a href=\"#cb5-71\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-72\"><a href=\"#cb5-72\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R - REditorSupport</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r)</span></span>\n<span id=\"cb5-73\"><a href=\"#cb5-73\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R Markdown All in One</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=TianyiShi.rmarkdown)</span></span>\n<span id=\"cb5-74\"><a href=\"#cb5-74\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">Quarto</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=quarto.quarto)</span></span>\n<span id=\"cb5-75\"><a href=\"#cb5-75\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span><span class=\"co\">[</span><span class=\"ot\">R Debugger</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=RDebugger.r-debugger)</span></span>\n<span id=\"cb5-76\"><a href=\"#cb5-76\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-77\"><a href=\"#cb5-77\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-78\"><a href=\"#cb5-78\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![VS Code를 실행하고 R Extension 설치](images/vscode_R_extension.png)</span></span>\n<span id=\"cb5-79\"><a href=\"#cb5-79\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-80\"><a href=\"#cb5-80\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 헬로우 월드</span></span>\n<span id=\"cb5-81\"><a href=\"#cb5-81\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-82\"><a href=\"#cb5-82\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`R Extension`</span> 설치되면 코드 창 상단에 실행버튼이 활성화되고 <span class=\"kw\">&lt;kbd&gt;</span>Ctrl<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Enter<span class=\"kw\">&lt;/kbd&gt;</span> 혹은 </span>\n<span id=\"cb5-83\"><a href=\"#cb5-83\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"kw\">&lt;kbd&gt;</span>Ctrl<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Shift<span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span>Enter<span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-84\"><a href=\"#cb5-84\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-85\"><a href=\"#cb5-85\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-86\"><a href=\"#cb5-86\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![R 코드 실행화면](images/vscode_helloworld.png)</span></span>\n<span id=\"cb5-87\"><a href=\"#cb5-87\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-88\"><a href=\"#cb5-88\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-89\"><a href=\"#cb5-89\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 유튜브 동영상</span></span>\n<span id=\"cb5-90\"><a href=\"#cb5-90\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-91\"><a href=\"#cb5-91\" aria-hidden=\"true\" tabindex=\"-1\"></a>{{&lt; video https://youtu.be/c3ZQ8-OYj2M &gt;}}</span>\n<span id=\"cb5-92\"><a href=\"#cb5-92\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-93\"><a href=\"#cb5-93\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># 즐거운 코딩 환경설정</span></span>\n<span id=\"cb5-94\"><a href=\"#cb5-94\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-95\"><a href=\"#cb5-95\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 코딩 글꼴</span></span>\n<span id=\"cb5-96\"><a href=\"#cb5-96\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-97\"><a href=\"#cb5-97\" aria-hidden=\"true\" tabindex=\"-1\"></a>다른 언어와 마찬가지로 R 코드로 데이터 과학 제품을 개발할 경우 글꼴도 코딩에 적합한 한글 글꼴을 설정한다.</span>\n<span id=\"cb5-98\"><a href=\"#cb5-98\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-99\"><a href=\"#cb5-99\" aria-hidden=\"true\" tabindex=\"-1\"></a>먼저 <span class=\"co\">[</span><span class=\"ot\">D2 Coding 글꼴</span><span class=\"co\">](https://github.com/naver/d2codingfont)</span>을 다운로드 받아 운영체제에 설치한다.</span>\n<span id=\"cb5-100\"><a href=\"#cb5-100\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-101\"><a href=\"#cb5-101\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS Code 좌측 하단 톱니바퀴 <span class=\"kw\">&lt;kbd&gt;</span> Settings <span class=\"kw\">&lt;/kbd&gt;</span> 설정을 클릭 혹은 메뉴에서 \"File\" <span class=\"dv\">&amp;rarr;</span> \"Preferences\" <span class=\"dv\">&amp;rarr;</span> \"Settings\"를 통해 <span class=\"in\">`편집기 (Text Editor)`</span>로 들어가 운영체제에 설치한 코딩 폰트를 지정한다. **Font Ligatures** 도 <span class=\"in\">`true`</span>로 설정한다. 이를 통해 <span class=\"in\">`&lt; -`</span> 표시가 <span class=\"dv\">&amp;larr;</span> 로 화면에 표현된다.</span>\n<span id=\"cb5-102\"><a href=\"#cb5-102\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-103\"><a href=\"#cb5-103\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![D2코딩 글꼴 장착](images/vscode_font.png)</span></span>\n<span id=\"cb5-104\"><a href=\"#cb5-104\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-105\"><a href=\"#cb5-105\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 단축키</span></span>\n<span id=\"cb5-106\"><a href=\"#cb5-106\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-107\"><a href=\"#cb5-107\" aria-hidden=\"true\" tabindex=\"-1\"></a>R 코드 개발을 진행할 때 <span class=\"kw\">&lt;kbd&gt;</span> %&gt;% <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> <span class=\"dv\">&amp;larr;</span> <span class=\"kw\">&lt;/kbd&gt;</span> 두가지 기능이 가장 많이 사용되는 </span>\n<span id=\"cb5-108\"><a href=\"#cb5-108\" aria-hidden=\"true\" tabindex=\"-1\"></a>단축키로 RStudio에서는 기본으로 지원되고 있다. VS Code에서 자주 사용되는 </span>\n<span id=\"cb5-109\"><a href=\"#cb5-109\" aria-hidden=\"true\" tabindex=\"-1\"></a>단축키를 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> m <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> - <span class=\"kw\">&lt;/kbd&gt;</span> 를 적용시키는 방법을 살펴보자.</span>\n<span id=\"cb5-110\"><a href=\"#cb5-110\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-111\"><a href=\"#cb5-111\" aria-hidden=\"true\" tabindex=\"-1\"></a>만약 VS Code에서 단축키 설정 기능을 활용한다. [<span class=\"co\">[</span><span class=\"ot\">How to add R {magrittr}'s %&gt;% Pipe Operator in VSCode as Keyboard Shortcut</span><span class=\"co\">](https://www.programmingwithr.com/how-to-add-r-magrittr-s-pipe-operator-in-vscode-as-keyboard-shortcut/)</span>]{.aside}</span>\n<span id=\"cb5-112\"><a href=\"#cb5-112\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-113\"><a href=\"#cb5-113\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>윈도우즈: File &gt; Preferences &gt; Keyboard Shortcuts. </span>\n<span id=\"cb5-114\"><a href=\"#cb5-114\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>맥: Code &gt; Preferences &gt; Keyboard Shortcuts</span>\n<span id=\"cb5-115\"><a href=\"#cb5-115\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-116\"><a href=\"#cb5-116\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`keybindings.json`</span> 파일에 <span class=\"kw\">&lt;kbd&gt;</span> %&gt;% <span class=\"kw\">&lt;/kbd&gt;</span>, <span class=\"kw\">&lt;kbd&gt;</span> <span class=\"dv\">&amp;larr;</span> <span class=\"kw\">&lt;/kbd&gt;</span> 단축키 기능을 추가한다.</span>\n<span id=\"cb5-117\"><a href=\"#cb5-117\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-118\"><a href=\"#cb5-118\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![자주 사용되는 R 단축키 설정](images/vscode_shortcuts.png)</span></span>\n<span id=\"cb5-119\"><a href=\"#cb5-119\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-120\"><a href=\"#cb5-120\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 패널</span></span>\n<span id=\"cb5-121\"><a href=\"#cb5-121\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-122\"><a href=\"#cb5-122\" aria-hidden=\"true\" tabindex=\"-1\"></a>RStudio는 코딩기반 데이터 분석과 통계에 최적화된 개발환경이다. </span>\n<span id=\"cb5-123\"><a href=\"#cb5-123\" aria-hidden=\"true\" tabindex=\"-1\"></a>즉, 편집기 패널, 콘솔/터미널 패널, 그래프 패널, 도움말/개발 패널로 구성된 </span>\n<span id=\"cb5-124\"><a href=\"#cb5-124\" aria-hidden=\"true\" tabindex=\"-1\"></a>꼭 필요한 패널만 구성되어 있다. </span>\n<span id=\"cb5-125\"><a href=\"#cb5-125\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-126\"><a href=\"#cb5-126\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.panel-tabset}</span>\n<span id=\"cb5-127\"><a href=\"#cb5-127\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-128\"><a href=\"#cb5-128\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 패널 설정 </span></span>\n<span id=\"cb5-129\"><a href=\"#cb5-129\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-130\"><a href=\"#cb5-130\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![VS Code: View &amp;rarr; Editor Layout &amp;rarr; Grid (2x2)](../../images/vscode_layout.png)</span></span>\n<span id=\"cb5-131\"><a href=\"#cb5-131\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-132\"><a href=\"#cb5-132\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 설정 후</span></span>\n<span id=\"cb5-133\"><a href=\"#cb5-133\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-134\"><a href=\"#cb5-134\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![도움말과 그래프](images/vscode_layout_screen.png)</span></span>\n<span id=\"cb5-135\"><a href=\"#cb5-135\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-136\"><a href=\"#cb5-136\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-137\"><a href=\"#cb5-137\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># `Radiant`</span></span>\n<span id=\"cb5-138\"><a href=\"#cb5-138\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-139\"><a href=\"#cb5-139\" aria-hidden=\"true\" tabindex=\"-1\"></a>VS 코드 IDE를 크게 코드 편집기 패널과 R 콘솔창에 출력되는 실행결과물 가독성을 높이는 것이 필요하다.</span>\n<span id=\"cb5-140\"><a href=\"#cb5-140\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">`radian`</span><span class=\"co\">](https://github.com/randy3k/radian)</span>은 여러 줄 편집(multiline editing)과 풍부한 구문 강조(syntax highlight) 표시 기능을 갖춘 R 프로그램을 위한 대안 콘솔로 많이 사용된다.</span>\n<span id=\"cb5-141\"><a href=\"#cb5-141\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-142\"><a href=\"#cb5-142\" aria-hidden=\"true\" tabindex=\"-1\"></a>[<span class=\"co\">[</span><span class=\"ot\">Schiff consulting, 'Using R in VS Code: Some things I learned while trying out R in VS Code'</span><span class=\"co\">](https://schiff.co.nz/blog/r-and-vscode/)</span>]{.aside}</span>\n<span id=\"cb5-143\"><a href=\"#cb5-143\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-144\"><a href=\"#cb5-144\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 독립 사용사례</span></span>\n<span id=\"cb5-145\"><a href=\"#cb5-145\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-146\"><a href=\"#cb5-146\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::{#radiant layout-ncol=2}</span>\n<span id=\"cb5-147\"><a href=\"#cb5-147\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-148\"><a href=\"#cb5-148\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 설치 {.unnumbered}</span></span>\n<span id=\"cb5-149\"><a href=\"#cb5-149\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-150\"><a href=\"#cb5-150\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```bash</span></span>\n<span id=\"cb5-151\"><a href=\"#cb5-151\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\"># 출시버전 설치</span></span>\n<span id=\"cb5-152\"><a href=\"#cb5-152\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ex\">pip3</span> install <span class=\"at\">-U</span> radian</span>\n<span id=\"cb5-153\"><a href=\"#cb5-153\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\"># 실행</span></span>\n<span id=\"cb5-154\"><a href=\"#cb5-154\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ex\">radian</span></span>\n<span id=\"cb5-155\"><a href=\"#cb5-155\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-156\"><a href=\"#cb5-156\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-157\"><a href=\"#cb5-157\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 실행화면 {.unnumbered}</span></span>\n<span id=\"cb5-158\"><a href=\"#cb5-158\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-159\"><a href=\"#cb5-159\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-cmd.png)</span></span>\n<span id=\"cb5-160\"><a href=\"#cb5-160\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-161\"><a href=\"#cb5-161\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-162\"><a href=\"#cb5-162\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-163\"><a href=\"#cb5-163\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## VS 코드 콘솔</span></span>\n<span id=\"cb5-164\"><a href=\"#cb5-164\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-165\"><a href=\"#cb5-165\" aria-hidden=\"true\" tabindex=\"-1\"></a>radiant를 설치한 후에 ~~Rpath~~ 가 아니라 **Rterm**에서 설정해줘야 한다.</span>\n<span id=\"cb5-166\"><a href=\"#cb5-166\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-167\"><a href=\"#cb5-167\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::{#radian-vscode layout-ncol=3}</span>\n<span id=\"cb5-168\"><a href=\"#cb5-168\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-169\"><a href=\"#cb5-169\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 맥 {.unnumbered}</span></span>\n<span id=\"cb5-170\"><a href=\"#cb5-170\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-171\"><a href=\"#cb5-171\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-mac.png)</span></span>\n<span id=\"cb5-172\"><a href=\"#cb5-172\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-173\"><a href=\"#cb5-173\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 윈도우즈 {.unnumbered}</span></span>\n<span id=\"cb5-174\"><a href=\"#cb5-174\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-175\"><a href=\"#cb5-175\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radian-windows.png)</span></span>\n<span id=\"cb5-176\"><a href=\"#cb5-176\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-177\"><a href=\"#cb5-177\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 적용결과 {.unnumbered}</span></span>\n<span id=\"cb5-178\"><a href=\"#cb5-178\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-179\"><a href=\"#cb5-179\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/radiant-penguins.png)</span></span>\n<span id=\"cb5-180\"><a href=\"#cb5-180\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-181\"><a href=\"#cb5-181\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-182\"><a href=\"#cb5-182\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-183\"><a href=\"#cb5-183\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-184\"><a href=\"#cb5-184\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-185\"><a href=\"#cb5-185\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># `.qmd`, `.Rmd` </span></span>\n<span id=\"cb5-186\"><a href=\"#cb5-186\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-187\"><a href=\"#cb5-187\" aria-hidden=\"true\" tabindex=\"-1\"></a>literate programming을 구현한 <span class=\"in\">`.qmd`</span>, <span class=\"in\">`.Rmd`</span> 파일를 작성하여 다양한 데이터 과학 </span>\n<span id=\"cb5-188\"><a href=\"#cb5-188\" aria-hidden=\"true\" tabindex=\"-1\"></a>문서를 작성할 수 있다.</span>\n<span id=\"cb5-189\"><a href=\"#cb5-189\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-190\"><a href=\"#cb5-190\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">**Pandoc** a universal document converter</span><span class=\"co\">](https://pandoc.org/installing.html)</span> 웹사이트에서</span>\n<span id=\"cb5-191\"><a href=\"#cb5-191\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`pandoc`</span>을 설치해야 한다. pandoc 최신버전을 설치하면 되고 버전이 2.16 이상이 되어야 활용이 가능하다.</span>\n<span id=\"cb5-192\"><a href=\"#cb5-192\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-193\"><a href=\"#cb5-193\" aria-hidden=\"true\" tabindex=\"-1\"></a>quarto-executable-code-5450563D</span>\n<span id=\"cb5-194\"><a href=\"#cb5-194\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-195\"><a href=\"#cb5-195\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```r</span></span>\n<span id=\"cb5-196\"><a href=\"#cb5-196\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">#| eval: false</span></span>\n<span id=\"cb5-197\"><a href=\"#cb5-197\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-198\"><a href=\"#cb5-198\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"sc\">$</span> pandoc <span class=\"sc\">--</span>version</span>\n<span id=\"cb5-199\"><a href=\"#cb5-199\" aria-hidden=\"true\" tabindex=\"-1\"></a>pandoc <span class=\"dv\">2</span>.<span class=\"fl\">19.2</span></span>\n<span id=\"cb5-200\"><a href=\"#cb5-200\" aria-hidden=\"true\" tabindex=\"-1\"></a>Compiled with pandoc<span class=\"sc\">-</span>types <span class=\"dv\">1</span>.<span class=\"dv\">22</span>.<span class=\"fl\">2.1</span>, texmath <span class=\"dv\">0</span>.<span class=\"dv\">12</span>.<span class=\"fl\">5.2</span>, skylighting <span class=\"fl\">0.13</span>,</span>\n<span id=\"cb5-201\"><a href=\"#cb5-201\" aria-hidden=\"true\" tabindex=\"-1\"></a>citeproc <span class=\"dv\">0</span>.<span class=\"dv\">8</span>.<span class=\"fl\">0.1</span>, ipynb <span class=\"fl\">0.2</span>, hslua <span class=\"dv\">2</span>.<span class=\"fl\">2.1</span></span>\n<span id=\"cb5-202\"><a href=\"#cb5-202\" aria-hidden=\"true\" tabindex=\"-1\"></a>Scripting engine<span class=\"sc\">:</span> Lua <span class=\"fl\">5.4</span></span>\n<span id=\"cb5-203\"><a href=\"#cb5-203\" aria-hidden=\"true\" tabindex=\"-1\"></a>User data directory<span class=\"sc\">:</span> C<span class=\"sc\">:</span>\\Users\\statkclee\\AppData\\Roaming\\pandoc</span>\n<span id=\"cb5-204\"><a href=\"#cb5-204\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">Copyright</span> (C) <span class=\"dv\">2006-2022</span> John MacFarlane. Web<span class=\"sc\">:</span>  https<span class=\"sc\">:</span><span class=\"er\">//</span>pandoc.org</span>\n<span id=\"cb5-205\"><a href=\"#cb5-205\" aria-hidden=\"true\" tabindex=\"-1\"></a>This is free software; see the source <span class=\"cf\">for</span> copying conditions. There is no</span>\n<span id=\"cb5-206\"><a href=\"#cb5-206\" aria-hidden=\"true\" tabindex=\"-1\"></a>warranty, not even <span class=\"cf\">for</span> merchantability or fitness <span class=\"cf\">for</span> a particular purpose.</span>\n<span id=\"cb5-207\"><a href=\"#cb5-207\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-208\"><a href=\"#cb5-208\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-209\"><a href=\"#cb5-209\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## `keybindings.json`</span></span>\n<span id=\"cb5-210\"><a href=\"#cb5-210\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-211\"><a href=\"#cb5-211\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`keybindings.json`</span> 파일에 R 혹은 파이썬 코드를 삽입시킬 수 있는 키보드 단축키를 </span>\n<span id=\"cb5-212\"><a href=\"#cb5-212\" aria-hidden=\"true\" tabindex=\"-1\"></a>등록시킨다. <span class=\"co\">[</span><span class=\"ot\">자료출처: [VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding](https://www.schmidtynotes.com/blog/r/2021-09-28-vscode-rmd-code-chunk-snippet/)</span><span class=\"co\">]</span>{.aside}</span>\n<span id=\"cb5-213\"><a href=\"#cb5-213\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-214\"><a href=\"#cb5-214\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.callout-tip collapse=\"true\"}</span>\n<span id=\"cb5-215\"><a href=\"#cb5-215\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-216\"><a href=\"#cb5-216\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### `keybindings.json` 설정파일 예시</span></span>\n<span id=\"cb5-217\"><a href=\"#cb5-217\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-218\"><a href=\"#cb5-218\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-219\"><a href=\"#cb5-219\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```json</span></span>\n<span id=\"cb5-220\"><a href=\"#cb5-220\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">// Place your key bindings in this file to override the defaults</span></span>\n<span id=\"cb5-221\"><a href=\"#cb5-221\" aria-hidden=\"true\" tabindex=\"-1\"></a>[</span>\n<span id=\"cb5-222\"><a href=\"#cb5-222\" aria-hidden=\"true\" tabindex=\"-1\"></a>    <span class=\"co\">// keybindings for R scripts. </span></span>\n<span id=\"cb5-223\"><a href=\"#cb5-223\" aria-hidden=\"true\" tabindex=\"-1\"></a>    {</span>\n<span id=\"cb5-224\"><a href=\"#cb5-224\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-225\"><a href=\"#cb5-225\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-226\"><a href=\"#cb5-226\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-227\"><a href=\"#cb5-227\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == r\"</span></span>\n<span id=\"cb5-228\"><a href=\"#cb5-228\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-229\"><a href=\"#cb5-229\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-230\"><a href=\"#cb5-230\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-231\"><a href=\"#cb5-231\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-232\"><a href=\"#cb5-232\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-233\"><a href=\"#cb5-233\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == r\"</span></span>\n<span id=\"cb5-234\"><a href=\"#cb5-234\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-235\"><a href=\"#cb5-235\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// keybindings for Rmarkdown</span></span>\n<span id=\"cb5-236\"><a href=\"#cb5-236\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-237\"><a href=\"#cb5-237\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-238\"><a href=\"#cb5-238\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-239\"><a href=\"#cb5-239\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-240\"><a href=\"#cb5-240\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == rmd\"</span></span>\n<span id=\"cb5-241\"><a href=\"#cb5-241\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-242\"><a href=\"#cb5-242\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-243\"><a href=\"#cb5-243\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-244\"><a href=\"#cb5-244\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"type\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-245\"><a href=\"#cb5-245\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-246\"><a href=\"#cb5-246\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; editorLangId == rmd\"</span></span>\n<span id=\"cb5-247\"><a href=\"#cb5-247\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-248\"><a href=\"#cb5-248\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// keybindings for R terminal (radian included)</span></span>\n<span id=\"cb5-249\"><a href=\"#cb5-249\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-250\"><a href=\"#cb5-250\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Ctrl+Shift+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-251\"><a href=\"#cb5-251\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"workbench.action.terminal.sendSequence\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-252\"><a href=\"#cb5-252\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" %&gt;% \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-253\"><a href=\"#cb5-253\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"terminalFocus\"</span></span>\n<span id=\"cb5-254\"><a href=\"#cb5-254\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-255\"><a href=\"#cb5-255\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-256\"><a href=\"#cb5-256\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"Alt+-\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-257\"><a href=\"#cb5-257\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"workbench.action.terminal.sendSequence\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-258\"><a href=\"#cb5-258\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> { <span class=\"st\">\"text\"</span><span class=\"op\">:</span> <span class=\"st\">\" &lt;- \"</span> }<span class=\"op\">,</span></span>\n<span id=\"cb5-259\"><a href=\"#cb5-259\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"terminalFocus\"</span></span>\n<span id=\"cb5-260\"><a href=\"#cb5-260\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-261\"><a href=\"#cb5-261\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// Insert R Code chunk</span></span>\n<span id=\"cb5-262\"><a href=\"#cb5-262\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-263\"><a href=\"#cb5-263\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+i\"</span><span class=\"op\">.</span> </span>\n<span id=\"cb5-264\"><a href=\"#cb5-264\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-265\"><a href=\"#cb5-265\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-266\"><a href=\"#cb5-266\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> {<span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"```{r}</span><span class=\"sc\">\\n</span><span class=\"st\">$0</span><span class=\"sc\">\\n</span><span class=\"st\">```\"</span>}</span>\n<span id=\"cb5-267\"><a href=\"#cb5-267\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-268\"><a href=\"#cb5-268\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-269\"><a href=\"#cb5-269\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+o\"</span><span class=\"op\">.</span> </span>\n<span id=\"cb5-270\"><a href=\"#cb5-270\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-271\"><a href=\"#cb5-271\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-272\"><a href=\"#cb5-272\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span> {<span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"options(</span><span class=\"sc\">\\n</span><span class=\"st\">  max.print=100,</span><span class=\"sc\">\\n</span><span class=\"st\">  vsc.use_httpgd=TRUE,</span><span class=\"sc\">\\n</span><span class=\"st\">  device='quartz'</span><span class=\"sc\">\\n</span><span class=\"st\">)\"</span>}</span>\n<span id=\"cb5-273\"><a href=\"#cb5-273\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-274\"><a href=\"#cb5-274\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-275\"><a href=\"#cb5-275\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+alt+m\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-276\"><a href=\"#cb5-276\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.insertSnippet\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-277\"><a href=\"#cb5-277\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-278\"><a href=\"#cb5-278\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"args\"</span><span class=\"op\">:</span>{</span>\n<span id=\"cb5-279\"><a href=\"#cb5-279\" aria-hidden=\"true\" tabindex=\"-1\"></a>          <span class=\"st\">\"snippet\"</span><span class=\"op\">:</span> <span class=\"st\">\"---</span><span class=\"sc\">\\n</span><span class=\"st\">title: '$0'</span><span class=\"sc\">\\n</span><span class=\"st\">author: '이광춘'</span><span class=\"sc\">\\n</span><span class=\"st\">date: '`r Sys.Date()`'</span><span class=\"sc\">\\n</span><span class=\"st\">output:</span><span class=\"sc\">\\n</span><span class=\"st\">  pagedown::html_paged:</span><span class=\"sc\">\\n</span><span class=\"st\">    self_contained: true</span><span class=\"sc\">\\n</span><span class=\"st\">    toc: false</span><span class=\"sc\">\\n</span><span class=\"st\">---</span><span class=\"sc\">\\n\\n</span><span class=\"st\">```{r setup, include=FALSE}</span><span class=\"sc\">\\n</span><span class=\"st\">knitr::opts_chunk</span><span class=\"sc\">\\\\</span><span class=\"st\">$set(</span><span class=\"sc\">\\n</span><span class=\"st\">  echo = FALSE,</span><span class=\"sc\">\\n</span><span class=\"st\">  message = FALSE,</span><span class=\"sc\">\\n</span><span class=\"st\">  warning=FALSE</span><span class=\"sc\">\\n</span><span class=\"st\">)</span><span class=\"sc\">\\n</span><span class=\"st\">```\"</span></span>\n<span id=\"cb5-280\"><a href=\"#cb5-280\" aria-hidden=\"true\" tabindex=\"-1\"></a>        }</span>\n<span id=\"cb5-281\"><a href=\"#cb5-281\" aria-hidden=\"true\" tabindex=\"-1\"></a>      }<span class=\"op\">,</span></span>\n<span id=\"cb5-282\"><a href=\"#cb5-282\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-283\"><a href=\"#cb5-283\" aria-hidden=\"true\" tabindex=\"-1\"></a>]</span>\n<span id=\"cb5-284\"><a href=\"#cb5-284\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span></span>\n<span id=\"cb5-285\"><a href=\"#cb5-285\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-286\"><a href=\"#cb5-286\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-287\"><a href=\"#cb5-287\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-288\"><a href=\"#cb5-288\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## HTML 미리보기</span></span>\n<span id=\"cb5-289\"><a href=\"#cb5-289\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-290\"><a href=\"#cb5-290\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`.Rmd`</span> 파일을 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> k <span class=\"kw\">&lt;/kbd&gt;</span> 단축키로 컴파일시키면 </span>\n<span id=\"cb5-291\"><a href=\"#cb5-291\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">`.html`</span> 파일이 생성된다. <span class=\"in\">`.html`</span> 파일 결과를 직접 실시간으로 확인하고자 한다면, </span>\n<span id=\"cb5-292\"><a href=\"#cb5-292\" aria-hidden=\"true\" tabindex=\"-1\"></a>마이크로소프트가 개발한 <span class=\"co\">[</span><span class=\"ot\">`Live Preview - VS Code Extension`</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=ms-vscode.live-server)</span> 플러그인을 설치한다.</span>\n<span id=\"cb5-293\"><a href=\"#cb5-293\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-294\"><a href=\"#cb5-294\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/vscode_open-context-menu.gif)</span></span>\n<span id=\"cb5-295\"><a href=\"#cb5-295\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-296\"><a href=\"#cb5-296\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-297\"><a href=\"#cb5-297\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\"># GitHub copilot</span></span>\n<span id=\"cb5-298\"><a href=\"#cb5-298\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-299\"><a href=\"#cb5-299\" aria-hidden=\"true\" tabindex=\"-1\"></a>GitHub에서 공개한 Copilot은 AI pair programmer라는 부제를 달고 있고,</span>\n<span id=\"cb5-300\"><a href=\"#cb5-300\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"co\">[</span><span class=\"ot\">GitHub Copilot</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)</span> 플러그인을 </span>\n<span id=\"cb5-301\"><a href=\"#cb5-301\" aria-hidden=\"true\" tabindex=\"-1\"></a>설치하면 사용이 가능하다.</span>\n<span id=\"cb5-302\"><a href=\"#cb5-302\" aria-hidden=\"true\" tabindex=\"-1\"></a>한가지 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span> 단축키가 충돌되어 R 코드 실행하는 것과 겹쳐서 문제가 있기 때문에</span>\n<span id=\"cb5-303\"><a href=\"#cb5-303\" aria-hidden=\"true\" tabindex=\"-1\"></a>단축키를 <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span>와 같이 조정하면 큰 문제 없이 </span>\n<span id=\"cb5-304\"><a href=\"#cb5-304\" aria-hidden=\"true\" tabindex=\"-1\"></a>R 개발할 때 GitHub copilot과 함께 사용이 가능하다.</span>\n<span id=\"cb5-305\"><a href=\"#cb5-305\" aria-hidden=\"true\" tabindex=\"-1\"></a>이를 위해서 <span class=\"in\">`keybindings.json`</span> 파일에 다음 사항을 추가한다. </span>\n<span id=\"cb5-306\"><a href=\"#cb5-306\" aria-hidden=\"true\" tabindex=\"-1\"></a>사용자별로 단축키를 달리해서 적용시키는 것도 물론 가능하다.</span>\n<span id=\"cb5-307\"><a href=\"#cb5-307\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-308\"><a href=\"#cb5-308\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>코드 라인별로 추천 승인: <span class=\"kw\">&lt;kbd&gt;</span> Tab <span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-309\"><a href=\"#cb5-309\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>전체 코드 작성 전체 추천 : <span class=\"kw\">&lt;kbd&gt;</span> CTRL <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Shift <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Alt <span class=\"kw\">&lt;/kbd&gt;</span> + <span class=\"kw\">&lt;kbd&gt;</span> Enter <span class=\"kw\">&lt;/kbd&gt;</span></span>\n<span id=\"cb5-310\"><a href=\"#cb5-310\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span><span class=\"in\">`Accept Solution`</span> 클릭</span>\n<span id=\"cb5-311\"><a href=\"#cb5-311\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">  - </span>코드 작성 편집기에 관련 사항 반영</span>\n<span id=\"cb5-312\"><a href=\"#cb5-312\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-313\"><a href=\"#cb5-313\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-314\"><a href=\"#cb5-314\" aria-hidden=\"true\" tabindex=\"-1\"></a>::: {.callout-tip collapse=\"true\"}</span>\n<span id=\"cb5-315\"><a href=\"#cb5-315\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-316\"><a href=\"#cb5-316\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### `keybindings.json` 설정파일 예시</span></span>\n<span id=\"cb5-317\"><a href=\"#cb5-317\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-318\"><a href=\"#cb5-318\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-319\"><a href=\"#cb5-319\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```json</span></span>\n<span id=\"cb5-320\"><a href=\"#cb5-320\" aria-hidden=\"true\" tabindex=\"-1\"></a>[</span>\n<span id=\"cb5-321\"><a href=\"#cb5-321\" aria-hidden=\"true\" tabindex=\"-1\"></a>  <span class=\"op\">...</span></span>\n<span id=\"cb5-322\"><a href=\"#cb5-322\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"co\">// GitHub Copilot</span></span>\n<span id=\"cb5-323\"><a href=\"#cb5-323\" aria-hidden=\"true\" tabindex=\"-1\"></a>      {</span>\n<span id=\"cb5-324\"><a href=\"#cb5-324\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"ctrl+shift+alt+enter\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-325\"><a href=\"#cb5-325\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"github.copilot.generate\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-326\"><a href=\"#cb5-326\" aria-hidden=\"true\" tabindex=\"-1\"></a>        <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"editorTextFocus &amp;&amp; github.copilot.activated &amp;&amp; editorLangId == 'r'\"</span></span>\n<span id=\"cb5-327\"><a href=\"#cb5-327\" aria-hidden=\"true\" tabindex=\"-1\"></a>    }<span class=\"op\">,</span></span>\n<span id=\"cb5-328\"><a href=\"#cb5-328\" aria-hidden=\"true\" tabindex=\"-1\"></a>    {</span>\n<span id=\"cb5-329\"><a href=\"#cb5-329\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"key\"</span><span class=\"op\">:</span> <span class=\"st\">\"tab\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-330\"><a href=\"#cb5-330\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"command\"</span><span class=\"op\">:</span> <span class=\"st\">\"editor.action.inlineSuggest.commit\"</span><span class=\"op\">,</span></span>\n<span id=\"cb5-331\"><a href=\"#cb5-331\" aria-hidden=\"true\" tabindex=\"-1\"></a>      <span class=\"st\">\"when\"</span><span class=\"op\">:</span> <span class=\"st\">\"textInputFocus &amp;&amp; inlineSuggestionHasIndentationLessThanTabSize &amp;&amp; inlineSuggestionVisible &amp;&amp; !editorTabMovesFocus\"</span>     </span>\n<span id=\"cb5-332\"><a href=\"#cb5-332\" aria-hidden=\"true\" tabindex=\"-1\"></a>    }<span class=\"op\">,</span></span>\n<span id=\"cb5-333\"><a href=\"#cb5-333\" aria-hidden=\"true\" tabindex=\"-1\"></a>]</span>\n<span id=\"cb5-334\"><a href=\"#cb5-334\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">```</span>    </span>\n<span id=\"cb5-335\"><a href=\"#cb5-335\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-336\"><a href=\"#cb5-336\" aria-hidden=\"true\" tabindex=\"-1\"></a>:::</span>\n<span id=\"cb5-337\"><a href=\"#cb5-337\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-338\"><a href=\"#cb5-338\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 중요 추가설정</span></span>\n<span id=\"cb5-339\"><a href=\"#cb5-339\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-340\"><a href=\"#cb5-340\" aria-hidden=\"true\" tabindex=\"-1\"></a>Principal Cloud Advocate at Microsoft David Smith가 \"New York Open Statistical Programming Meetup, 28 February 2023\"에서 발표한 **Copilot for R** 내용 중 VS 코드 환경설정부분이다. </span>\n<span id=\"cb5-341\"><a href=\"#cb5-341\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-342\"><a href=\"#cb5-342\" aria-hidden=\"true\" tabindex=\"-1\"></a>[<span class=\"co\">[</span><span class=\"ot\">Copilot for R</span><span class=\"co\">](https://github.com/revodavid/copilot-for-r)</span>]{.aside}</span>\n<span id=\"cb5-343\"><a href=\"#cb5-343\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-344\"><a href=\"#cb5-344\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>VS 코드 </span>\n<span id=\"cb5-345\"><a href=\"#cb5-345\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span><span class=\"co\">[</span><span class=\"ot\">Copilot extension</span><span class=\"co\">](https://aka.ms/get-copilot)</span></span>\n<span id=\"cb5-346\"><a href=\"#cb5-346\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span><span class=\"co\">[</span><span class=\"ot\">R Extension for Visual Studio Code</span><span class=\"co\">](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r)</span></span>\n<span id=\"cb5-347\"><a href=\"#cb5-347\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>copilot 추천에 집중하기 위해서 다음 사항도 설정에 반영한다.</span>\n<span id=\"cb5-348\"><a href=\"#cb5-348\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Hover (disabled)</span>\n<span id=\"cb5-349\"><a href=\"#cb5-349\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Quick Suggestions (off)</span>\n<span id=\"cb5-350\"><a href=\"#cb5-350\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">        - </span>Editor &gt; Parameter Hints (disabled)</span>\n<span id=\"cb5-351\"><a href=\"#cb5-351\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">- </span>R 패키지 설치 및 <span class=\"in\">`opitions()`</span></span>\n<span id=\"cb5-352\"><a href=\"#cb5-352\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>httr, jsonlite, tidyverse, tidymodels, docopt, httpuv</span>\n<span id=\"cb5-353\"><a href=\"#cb5-353\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"ss\">    - </span>가독성 높은 그래프 출력: <span class=\"in\">`options(vsc.dev.args = list(width = 800, height = 600))`</span></span>\n<span id=\"cb5-354\"><a href=\"#cb5-354\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-355\"><a href=\"#cb5-355\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">## 실제 적용 사례</span></span>\n<span id=\"cb5-356\"><a href=\"#cb5-356\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-357\"><a href=\"#cb5-357\" aria-hidden=\"true\" tabindex=\"-1\"></a>펭귄과 호박 데이터를 적용한 사례 시연을 살펴보자.</span>\n<span id=\"cb5-358\"><a href=\"#cb5-358\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-359\"><a href=\"#cb5-359\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-360\"><a href=\"#cb5-360\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 펭귄 데이터셋 {.unnumbered}</span></span>\n<span id=\"cb5-361\"><a href=\"#cb5-361\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-362\"><a href=\"#cb5-362\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-363\"><a href=\"#cb5-363\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"al\">![](images/vscode_copilot.gif)</span></span>\n<span id=\"cb5-364\"><a href=\"#cb5-364\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-365\"><a href=\"#cb5-365\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-366\"><a href=\"#cb5-366\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"fu\">### 호박 데이터셋 {.unnumbered}</span></span>\n<span id=\"cb5-367\"><a href=\"#cb5-367\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-368\"><a href=\"#cb5-368\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"kw\">&lt;iframe</span> <span class=\"er\">src</span><span class=\"ot\">=</span><span class=\"st\">\"images/pumpkins-copilot.mp4\"</span> <span class=\"er\">allowfullscreen</span> <span class=\"er\">allow</span><span class=\"ot\">=</span><span class=\"st\">\"encrypted-media\"</span> <span class=\"er\">width</span><span class=\"ot\">=</span><span class=\"st\">\"320\"</span> <span class=\"er\">height</span><span class=\"ot\">=</span><span class=\"st\">\"180\"</span><span class=\"kw\">&gt;</span></span>\n<span id=\"cb5-369\"><a href=\"#cb5-369\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-370\"><a href=\"#cb5-370\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-371\"><a href=\"#cb5-371\" aria-hidden=\"true\" tabindex=\"-1\"></a></span>\n<span id=\"cb5-372\"><a href=\"#cb5-372\" aria-hidden=\"true\" tabindex=\"-1\"></a><span class=\"in\">    </span></span></code></pre></div>\n</div>"
  },
  {
    "objectID": "interface.html",
    "href": "interface.html",
    "title": "chatGPT",
    "section": "",
    "text": "특정 작업에 필요한 정보를 얻는 검색(search)은 기한이 정해진 업무를 수행함에 있어 매우 중요하다. chatGPT의 등장으로 새로운 검색 패러다임이 제시되고 있다. 물론 기존 검색방식이 부족한 것은 아니며 검색경험을 향상시키기 위해 많은 노력이 경주된 것도 사실이다. 차세대 R마크다운 쿼토(quarto) 문서 제작사례을 위한 검색사례를 통해 chatGPT와 비교하여 보자.\n\n구글 검색을 통해 일반적인 내용을 얻을 수도 있다. 예를 들어,\n\nsite:quarto.org/ google analytics tracking code\n\n구글검색창에 상기 사항을 입력하게 되면 구글은 쿼토(quarto) 웹사이트 내부에서 google analytics tracking code 키워드와 관련이 높은 웹페이지를 검색결과로 반환시키게 된다.\n\n\n\n\n\nQuarto는 웹사이트와 책의 전체 텍스트 검색을 지원하는데, 기본적으로 Quarto는 사이트의 콘텐츠를 자동으로 색인화하여 기본적으로 로컬로 구축된 색인을 사용하여 높은 검색품질을 제공한다. 따라서, 사용자는 구글웹사이트가 아니라 쿼토(quarto)에서 검색을 수행하여 직접 해당 정보를 찾는 것도 가능하다.\n\n\n\n\n\nChatGPT를 사용하여 검색작업을 수행할 수도 있다. 특정 웹사이트에서 해당 정보를 얻어야 되기 때문에 지시명령어(Prompt)를 다음과 같이 작성한다.\n\nsearch https://quarto.org/ insert google analytics tracking code for quarto html document\n\n\n\n\n\n\n쿼토(Quarto)는 차세대 R마크다운이라는 별명이 붙어 있을 정도로 R마크다운이 갖는 모든 기능에 더하여 추가로 새로운 언어(Python, R, Julia, Observable.)에 대한 지원도 포괄하고 있어 상당한 학습량을 요구한다. 설계는 깔끔하게 잘 되어 있지만 이것을 잘 사용하려면 상당한 학습량이 필요로 한다. 이런 문제에 chatGPT를 도입하여 사용하면 경우에 따라서 큰 도움을 줄 수도 있다.\n\nQuarto Help Bot - Ask a question about Quarto.\n\n\n\n\n\n:::\n내부적으로 동작하는 질문-응답(QnA)에는 다음과 같은 단계로 세분화되어 있으며, 모두 ChatVectorDBChain이 처리한다:\n\n채팅 기록과 새로운 사용자 입력이 주어지면 독립형 질문이 무엇인지 결정(GPT-3 사용).\n독립형 질문이 주어지면 벡터 스토어에서 관련 문서를 검색.\n독립형 질문과 관련 문서를 GPT-3에 전달하여 최종 답변을 생성."
  },
  {
    "objectID": "use-cases.html",
    "href": "use-cases.html",
    "title": "chatGPT",
    "section": "",
    "text": "출처: 내 카톡엔 챗GPT가 들어있다\n급한경우 모바일에서 chatGPT 사용이 가능하나, 대부분 데스크톱 PC에서 chatGPT를 사용하는 경우가 많다. chatGPT 사용자 환경이 영어 사용자에 초점을 맞추다보니 한국어를 모국어로 사용하는 사용자는 번역이 꼭 필요한 경우가 많다. 이와 같은 경우 크롬 웹브라우져 chrome 웹 스토어에서 확장 프로그램(Extension)을 사용하면 도움을 받을 수 있다."
  },
  {
    "objectID": "use-cases.html#chatgpt-최종-정보",
    "href": "use-cases.html#chatgpt-최종-정보",
    "title": "chatGPT",
    "section": "\n1.1 chatGPT 최종 정보",
    "text": "1.1 chatGPT 최종 정보\n\n\n\n\n\n\nwhen was your last training date?\n\n\n\n\n\nAs an AI language model, I am continuously being trained and updated to improve my performance and accuracy. My last major training update occurred in September 2021, but I am continually receiving smaller updates and improvements to my knowledge and capabilities."
  },
  {
    "objectID": "use-cases.html#웹검색",
    "href": "use-cases.html#웹검색",
    "title": "chatGPT",
    "section": "\n1.2 웹검색",
    "text": "1.2 웹검색\n이러한 한계를 보완하는 WebChatGPT 를 통해서 최신 검색 기능을 보완할 수도 있다. 하지만 WebChatGPT를 활성화시키는 순간 chatGPT 기능도 없어져 단순한 검색기로 변환되니 유의한다. 개발소스코드는 qunash/chatgpt-advanced를 참조한다."
  },
  {
    "objectID": "news_article.html",
    "href": "news_article.html",
    "title": "chatGPT",
    "section": "",
    "text": "사단법인 한국 R 사용자회 관련 주요 뉴스기사는 다음과 같다.\n\n코드library(tidyverse)\nlibrary(googlesheets4)\nlibrary(lubridate)\nlibrary(gt)\n\nnews_raw <- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1KITnaJTqsDHtm-wUWboog4xG6U6SBuB_Zee8qpCgLN4/edit?usp=sharing\", sheet = \"뉴스기사\")\n\nnews_tbl <- news_raw %>% \n  mutate(날짜 = as.Date(날짜)) %>% \n  arrange(desc(날짜)) %>% \n  mutate(뉴스링크 = sprintf('<a href = \"%s\">%s</a>', 링크, `뉴스기사 제목`),\n         뉴스링크 = map(뉴스링크, gt::html))  %>% \n  select(날짜, 언론사, 기자명, 기자명, 링크, 뉴스링크)\n\nnews_tbl %>% \n  select(-링크) %>% \n  gt() %>% \n    cols_align(\n    align = \"center\",\n    columns = everything()\n  )\n\n\n\n\n\n\n날짜\n      언론사\n      기자명\n      뉴스링크\n    \n\n\n2022-04-18\n오마이뉴스\n이광춘\n통계 대중화 위한 '오픈 통계 패키지' 나왔다 - 오마이뉴스\n\n\n2021-10-25\nIT 조선\n이윤경\n\"디지털 경제 패러다임 전환은 R\"…한국R 콘퍼러스, 11월 19일 개최 - IT조선 > 기술 > 일반\n\n\n2021-09-18\n한겨레\n권오성\n데이터 분석 언어 ‘R’ 한국 콘퍼런스 열린다\n\n\n2016-12-07\nKBS\n최건일\n인공지능으로 분석한 대통령의 마음…슬픔은 어디에?\n\n\n2015-01-31\nIT Daily\n팽동현\n[데이터사이언티스트를 찾아서] “빅데이터 분석, 데이터의 본질을 바라보는 것부터”\n\n\n2012-10-11\n디지털 데일리\n백지영\n넥스알, ‘R사용자컨퍼런스 2012’ 24일 개최"
  },
  {
    "objectID": "news_article.html#보도자료-초안",
    "href": "news_article.html#보도자료-초안",
    "title": "chatGPT",
    "section": "\n4.1 보도자료 초안",
    "text": "4.1 보도자료 초안\n\n프롬프트: 비영리법인 한국 R 사용자회는 2017년부터 매년 국내 유일의 데이터 사이언스 밋업(Meetup)을 주관하고 있습니다. 2023년 올해는 교보생명보험 그룹 데이터 분석 법인 디플래닉스(DPlanex)의 후원을 받아 “ChatGPT와 데이터 사이언스” 주제로 총 6회에 결쳐 강남 교보타워 5층 노블리에홀에서 행사를 진행합니다. 이에 대한 홍보 기사를 작성해주세요.\n\n\n\n\n\n\n\n주의\n\n\n\n\n\n한국 R 사용자회 비영리법인이 2017년부터 국내 유일한 데이터 사이언스 밋업을 성공적으로 개최하고 있습니다. 이번 2023년, 교보생명보험 그룹의 데이터 분석 법인인 디플래닉스(DPlanex)의 후원으로, “ChatGPT와 데이터 사이언스” 주제로 총 6회에 걸쳐 강남 교보타워 5층 노블리에홀에서 행사를 개최하게 되었습니다.\n이번 행사는 데이터 사이언스와 인공지능의 최신 동향에 대한 이해를 높이고, ChatGPT 기술을 활용한 데이터 분석 및 예측 방법을 다룹니다. 행사 기간 동안 전문가들의 강연과 워크숍, 토론 등 다양한 프로그램이 준비되어 있으며, 자연어 처리, 기계 학습, 데이터 시각화 등 다양한 주제가 다루어집니다.\n이번 행사는 데이터 사이언티스트, 연구원, 또는 인공지능과 데이터 사이언스에 관심이 있는 분들에게 모두 열려 있으며, 또한 같은 관심사를 가진 사람들과의 네트워킹 기회도 제공됩니다.\n행사 등록은 지금부터 가능하며, 자리가 한정되어 있으므로 서둘러 등록하시기 바랍니다. 이번 기회를 놓치지 마시고, 최신 데이터 사이언스 및 인공지능 기술 동향을 접하며, 전문가들과 함께 학습하는 좋은 기회가 되시길 바랍니다."
  },
  {
    "objectID": "news_article.html#기사-제목-초안",
    "href": "news_article.html#기사-제목-초안",
    "title": "chatGPT",
    "section": "\n4.2 기사 제목 초안",
    "text": "4.2 기사 제목 초안\n\n프롬프트: 뉴스 기사 제목은 3개만 작성하세요.\n\n\n\n\n\n\n\n주의\n\n\n\n\n\n\n“한국R사용자협회와 DPlanex, ChatGPT 중심 데이터 사이언스 행사 위해 협력”\n“교보타워 노블리홀, 2023년 6개 데이터 사이언스 행사 개최”\n“NLP, 기계 학습 및 데이터 시각화 전문가가 ChatGPT 및 데이터 과학 이벤트에서 연설합니다.”"
  },
  {
    "objectID": "news_article.html#보도자료-언론-배포",
    "href": "news_article.html#보도자료-언론-배포",
    "title": "chatGPT",
    "section": "\n4.3 보도자료 언론 배포",
    "text": "4.3 보도자료 언론 배포\nchatGPT가 작성한 기사제목(일명 야마)과 본문 내용에 더하여 보도자료 담당자 정보를 붙여 PDF 문서형태로 최종 마무리한다."
  },
  {
    "objectID": "interface.html#askup-검색",
    "href": "interface.html#askup-검색",
    "title": "chatGPT",
    "section": "\naskup 검색",
    "text": "askup 검색"
  },
  {
    "objectID": "interface.html#채팅준비",
    "href": "interface.html#채팅준비",
    "title": "chatGPT",
    "section": "채팅준비",
    "text": "채팅준비"
  },
  {
    "objectID": "interface.html#ocr-사례",
    "href": "interface.html#ocr-사례",
    "title": "chatGPT",
    "section": "OCR 사례",
    "text": "OCR 사례"
  },
  {
    "objectID": "interface.html#뉴스-요약",
    "href": "interface.html#뉴스-요약",
    "title": "chatGPT",
    "section": "뉴스 요약",
    "text": "뉴스 요약"
  },
  {
    "objectID": "interface.html#채널추가",
    "href": "interface.html#채널추가",
    "title": "chatGPT",
    "section": "채널추가",
    "text": "채널추가"
  },
  {
    "objectID": "interface.html#카카오톡",
    "href": "interface.html#카카오톡",
    "title": "chatGPT",
    "section": "\n3.1 카카오톡",
    "text": "3.1 카카오톡\n모바일 메신져 카카오톡에 AskUp 채널을 추가하게 되면 chatGPT 유사 기능을 사용할 수 있다. 문제는 언제 AskUp 채널 서비스가 중단될지 유료로 과금이 변경될지 모르지만 chatGPT를 사용하는 방식이 다양화함은 분명하다.\nAskUp 서비스는 현재 시점(“2023-03-10”) 기준 PDF 문서요약기능은 제공하고 있지 않지만 장문의 텍스트는 요약하는 기능을 제공하고 있다.\n\n\naskup 검색\n채널추가\n채팅준비\nOCR 사례\n뉴스 요약"
  },
  {
    "objectID": "interface.html#슬랙",
    "href": "interface.html#슬랙",
    "title": "chatGPT",
    "section": "\n4.3 슬랙",
    "text": "4.3 슬랙\n2023년 3월 7일 Salesforce와 OpenAI는 Slack용 ChatGPT 앱을 출시했다. OpenAI가 Slack 플랫폼에 구축한 이 앱은 ChatGPT의 강력한 AI 기술을 통합하여 즉각적인 대화 요약, 조사 도구 및 작성 지원을 Slack에서 바로 제공하여 수백만 기업이 보다 생산적으로 작업할 수 있도록 지원하기 시작했다.\n출처: Introducing the ChatGPT App for Slack"
  },
  {
    "objectID": "rnd.html",
    "href": "rnd.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 인용높은 논문 5개\nchatGPT에 가장 인용수가 높은 논문 5개를 찾아달라고 요청을 하였다.\n\n프롬프트: What are the most cited papers?\n\n\n\n한영 번역\n영어 원문\n\n\n\nchatGPT에 나온 인용에 대한 근거를 확신할 수 없어 구글 학술검색에서 해당 논문에 대한 인용 횟수를 수작업으로 정리했다.\n\nStephen Wolfram의 “A New Kind of Science” - 이 책은 2002년 출판 이후 14,000 9,696회 인용되었습니다. 셀룰러 오토마타를 사용하는 복잡한 시스템.\nSergey Brin과 Lawrence Page의 “The Anatomy of a Large-Scale Hypertextual Web Search Engine” - 1998년에 출판된 이 논문은 PageRank를 소개했습니다. 알고리즘이며 Google의 기반으로 널리 알려져 있습니다. 15,000 22,779회 이상 인용되었습니다.\nThomas Kuhn의 “과학 혁명의 구조” - 1962년에 출판된 이 책은 44,000 597회 이상 인용되었으며 다음과 같은 개념을 도입했습니다. 과학의 패러다임 변화.\nLarry V. Hedges 및 Ingram Olkin의 “Statistical Methods for Meta-Analysis” - 1985년에 출판된 이 논문은 53,000 18,545회 이상 인용되었으며 연구 합성에 메타 분석의 사용을 소개했습니다.\nAlbert Einstein, Boris Podolsky 및 Nathan Rosen의 “The Nature 논문” - 1935년에 출판된 이 논문은 양자 얽힘의 개념이며 13,000 10회 이상 인용되었습니다.\n\n\n\nThere are several papers that have been highly cited in various fields of study. Here are some examples:\n\n“A New Kind of Science” by Stephen Wolfram - This book has been cited over 14,000 times since its publication in 2002. It presents a new approach to understanding complex systems using cellular automata.\n“The Anatomy of a Large-Scale Hypertextual Web Search Engine” by Sergey Brin and Lawrence Page - This paper, published in 1998, introduced the PageRank algorithm and is widely regarded as the foundation of Google. It has been cited over 15,000 times.\n“The Structure of Scientific Revolutions” by Thomas Kuhn - Published in 1962, this book has been cited over 44,000 times and introduced the concept of paradigm shifts in science.\n“Statistical Methods for Meta-Analysis” by Larry V. Hedges and Ingram Olkin - This paper, published in 1985, has been cited over 53,000 times and introduced the use of meta-analysis in research synthesis.\n“The Nature paper” by Albert Einstein, Boris Podolsky, and Nathan Rosen - This paper, published in 1935, introduced the concept of quantum entanglement and has been cited over 13,000 times.\n\nThese papers represent a small sample of highly cited papers, and there are many others that have made significant contributions to their respective fields.\n\n\n\n\n2 구글검색 논문\n현재 구글이 있게 한 Sergey Brin과 Lawrence Page의 “The Anatomy of a Large-Scale Hypertextual Web Search Engine” 논문을 다운로드 받아 살펴보자.\n\n\n\n3 chatPDF 서비스\nchatPDF 웹사이트에 연구 PDF 논문을 올리면 이를 chatGPT 기술을 이용하여 요약을 해주고 관련하여 몇가지 질문도 제시해준다. 질문에 대한 답을 할 때 해당 논문의 근거 페이지, 단락도 제시해주기 때문에 필요하면 추가로 확인도 진행하고, 추가로 질문을 더 넣어 논문에 대한 이해를 높일 수 있다. (Brin & Page, 1998)\n\n\nchatPDF 접속\n논문 요약 및 제시질문\n채팅 예시\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 국문 논문\n2020년 출간된 논문(이광춘, 2020)을 chatPDF를 사용하여 과학기술 연구개발의 생산성을 높일 수 있는 방법을 찾아보자.\n\n논문 소스코드: 바로가기\n\nPDF 출판 논문: 다운로드\n\n\n\n\nPDF 원본\nopenAI API\n세무사\n기계와 전쟁 승리\n영문초록 없음\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5 엣지 PDF\n마이크로소프트 엣지(Microsoft Edge)는 마이크로소프트가 개발한 웹 브라우저로, 기존의 인터넷 익스플로러(Internet Explorer)를 대체하기 위해 만들어졌고, 2015년 Windows 10과 함께 처음 공개되었다. 2020년부터 엣지는 구글의 오픈 소스 프로젝트인 크로미움(Chromium) 기반으로 개발되어, 크롬(Chrome)과 같은 엔진을 차용하여 엣지는 크롬 확장 프로그램과 호환성이 높아졌고, 성능과 안정성이 향상되었다.\n특히 chatGPT 기능을 엣지 웹 브라우저에 채용하면서 점유율이 점차 높아지고 있다.\npdf 논문을 아도브 아크로뱃 리더 대신 엣지 브라우져에서 열게 되면 chatPDF 기능을 자체적으로 사용할 수 있다. 이런 경우 pdf 파일을 외부에 전송하지 않고 로컬 컴퓨터에서 작업한다는 점에서 속도 및 보안에 안정성을 높일 수 있다.\n김건희 여사가 집필한 “온라인 운세 콘텐츠의 이용자들의 이용 만족과 불만족에 따른 회원 유지와 탈퇴에 대한 연구” KCI 등재논문을 엣지에서 열어 GPT-4 기능을 확인해보자.\n\n\nPDF 원본\nGPT-4 논문\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\nBrin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 30(1-7), 107–117.\n\n\n이광춘주용우. (2020). 사람과 인공지능의 일자리 경쟁 요인과 협업 방안. 디지털경영연구 Vol.6 No.2 Pp.39-50."
  },
  {
    "objectID": "yuji.html",
    "href": "yuji.html",
    "title": "chatGPT",
    "section": "",
    "text": "김건희 여사가 집필한 “온라인 운세 콘텐츠의 이용자들의 이용 만족과 불만족에 따른 회원 유지와 탈퇴에 대한 연구” 논문제목을 갖고 있는 KCI 등재논문은 “Use satisfaction of users of online fortune contents and member Yuji by dissatisfaction and a study for withdrawal” 영문제목이 아래 함께 달려있다. KCI 원문 내려받기를 클릭하면 PDF 파일(KCI_FI001250967.pdf)로 KCI 등재 논문을 내려받을 수 있다.\n출처: 김건희 여사 논문\n\n\nKCI 등재 웹사이트\nPDF 다운로드"
  },
  {
    "objectID": "yuji.html#원문과-비교",
    "href": "yuji.html#원문과-비교",
    "title": "chatGPT",
    "section": "\n2.1 원문과 비교",
    "text": "2.1 원문과 비교\n\n\n김건희 여사 저작(Abstract A)\nThough I make a searching examination substantially and show book plan a purpose of a study develops digital fortune contents service deserving to be a domestic online member of fortune site use and influence for member withdrawal and a member demand, and to apply this to a market, there is it. In addition, Fortune (phrenology) that any people regardless of age or sex anyone cut interest and the culture contents that I could be interested in to a system of digital culture contents and inherited a study of a book and did It is the purpose that is going to manufacture a customer and a consumer and a demand of potential customers and service deserving to be you satisfactorily through a feasibility study to develop affinity) contents and a market analysis.\nchatGPT 저작 (Abstract B)\nThis empirical study aims to investigate the impact of online fortune-telling sites on membership and churn in Korea, and to develop a digital fortune-telling content service that meets members’ needs. Additionally, the study aims to identify and suggest ways to develop and apply digital horoscope content services to the market. The study’s objective is to create culturally relevant and engaging horoscopic (contemplative, compatibility) content through preliminary research and market analysis, catering to individuals of all ages. The study aims to develop services that meet potential customers’ needs and satisfaction by incorporating digital cultural content. Overall, this study contributes to the development of effective digital fortune-telling and horoscope content services in Korea, addressing the needs of its target audience."
  },
  {
    "objectID": "yuji.html#chatgpt-평가",
    "href": "yuji.html#chatgpt-평가",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT 평가",
    "text": "2.2 chatGPT 평가\n\n\n\n\n\n\ntell me how to evaluate two paper abstracts. which is better than other one? include criteria and add justification. finally recommend tools\n\n\n\n\n\nEvaluating two paper abstracts involves comparing and contrasting their strengths and weaknesses based on a set of criteria. Here are some criteria to consider when evaluating paper abstracts:\n\nClarity and coherence: The abstract should be well-organized and easy to understand. It should also effectively summarize the main ideas of the paper.\nOriginality and novelty: The abstract should highlight the unique aspects of the paper and how it contributes to the existing body of knowledge.\nSignificance and relevance: The abstract should explain why the research is important and relevant to the field.\nMethodology and data: The abstract should briefly describe the methods used and the data collected in the study.\nResults and conclusions: The abstract should summarize the key findings of the study and the main conclusions drawn from them.\n\nBased on these criteria, the better paper abstract would be the one that is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nHere is a brief justification for each criterion:\n\nClarity and coherence: A well-written abstract is important because it is the first thing that readers will see when they encounter the paper. A clear and coherent abstract will help readers understand what the paper is about and whether it is worth reading in full.\nOriginality and novelty: This criterion is important because it highlights the unique aspects of the paper and helps readers understand why it is important.\nSignificance and relevance: This criterion is important because it explains why the research is worth doing and how it contributes to the field.\nMethodology and data: This criterion is important because it helps readers understand how the research was conducted and whether the results are reliable.\nResults and conclusions: This criterion is important because it summarizes the key findings of the study and the main conclusions drawn from them, which helps readers understand the significance of the research.\n\nAs for tools to help evaluate paper abstracts, there are various software programs available that can help assess the quality of writing, such as Grammarly or Hemingway Editor. Additionally, some academic databases provide metrics and rankings for papers based on factors such as citation counts and impact factors. However, the best way to evaluate paper abstracts is to read them carefully and assess their quality based on the criteria listed above.\n\n\n\n\n\n\n\n\n\nBased on the criteria outlined above, abstract B appears to be the better of the two abstracts.\n\n\n\n\n\n\nClarity and coherence: Abstract B is well-organized and easy to understand. It effectively summarizes the main ideas of the paper in a clear and concise manner. In contrast, abstract A is poorly written and difficult to understand due to its convoluted language and lack of clarity.\nOriginality and novelty: Abstract B highlights the unique aspects of the paper, including its focus on developing culturally relevant and engaging horoscopic content, and its contribution to the development of effective digital fortune-telling services in Korea. In contrast, abstract A does not provide any clear indication of the paper’s novelty or originality.\nSignificance and relevance: Abstract B explains why the research is important and relevant to the field by highlighting the impact of online fortune-telling sites on membership and churn in Korea, and the need for digital horoscope content services that meet members’ needs. In contrast, abstract A does not provide any clear explanation of the research’s significance or relevance.\nMethodology and data: Abstract B briefly describes the study’s empirical methodology and its focus on identifying and suggesting ways to develop and apply digital horoscope content services to the market. In contrast, abstract A does not provide any clear indication of the study’s methodology or data.\nResults and conclusions: Abstract B effectively summarizes the key findings of the study, including the development of culturally relevant and engaging horoscopic content and the identification of ways to meet potential customers’ needs and satisfaction. In contrast, abstract A does not provide any clear indication of the study’s results or conclusions.\n\nOverall, abstract B is a better abstract because it is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nAs for tools to help evaluate paper abstracts, software programs such as Grammarly or Hemingway Editor can be helpful in identifying and correcting issues with clarity and coherence. Additionally, academic databases such as Scopus or Web of Science can provide metrics and rankings for papers based on factors such as citation counts and impact factors, which can be used to assess the significance and relevance of the research.\n\n\n\n\n\n\n\n\n\n왜 abstract A가 abstract B보다 부족한지 100자 내외로 간략하게 요약해줘\n\n\n\n\n\n번역결과 Briefly summarize in 100 words or less why abstract A is less than abstract B\nAbstract A is less than abstract B because it is poorly written, difficult to understand, lacks clarity, and does not effectively summarize the main ideas of the paper. It also does not provide any clear indication of the paper’s novelty, significance, methodology, data, or results and conclusions. In contrast, abstract B is well-organized, easy to understand, effectively highlights the unique aspects of the research, explains why the research is important and relevant to the field, briefly describes the study’s methodology and data, and effectively summarizes the key findings and conclusions of the research.\n번역결과\n초록 A는 서투르게 작성되고, 이해하기 어렵고, 명확성이 부족하고, 논문의 주요 아이디어를 효과적으로 요약하지 못하기 때문에 초록 B보다 낮습니다. 또한 논문의 참신성, 중요성, 방법론, 데이터 또는 결과 및 결론에 대한 명확한 표시를 제공하지 않습니다. 대조적으로 초록 B는 잘 정리되어 있고 이해하기 쉬우며 연구의 고유한 측면을 효과적으로 강조하고 해당 연구가 중요하고 해당 분야와 관련이 있는 이유를 설명하며 연구의 방법론과 데이터를 간략하게 설명하고 주요 결과와 연구의 결론."
  },
  {
    "objectID": "stable_diffusion.html",
    "href": "stable_diffusion.html",
    "title": "chatGPT",
    "section": "",
    "text": "Text-to-Image는 텍스트를 입력하면 이미지를 생성해주는 인공지능 서비스다. 텍스트를 이미지로 제작함으로서 다양한 사용사례를 발견할 수 있다.\n\n텍스트를 이미지: 블로그나 소셜미디어에 게시\n텍스트를 이미지: 시각 예술 작품(Artwork)과 콘텐츠 제작\n텍스트를 이미지: 아이디어나 컨셉을 시각화\n텍스트를 이미지: 재미있는 실험\n텍스트를 이미지: 교육이나 연구에 활용\n\n일반적으로 인기있고 평가가 좋은 Text-to-Image 소프트웨어로는 상용 API, 오픈소스 소프트웨어로 다음을 들 수 있다.\n\nMidjourney: 미드저니는 새로운 사고의 매체를 탐구하고 인류의 상상력을 확장하는 독립 연구실입니다. 디자인, 휴먼 인프라 및 AI에 중점을 둔 소규모 자체 자금 지원 팀으로 11명의 상근 직원과 훌륭한 자문단이 있음\nStable Diffusion: 독일 뮌헨 대학 CompVis 연구실의 “잠재 확산 모델을 이용한 고해상도 이미지 합성 연구”를 기반하여, Stability AI와 Runway ML 등의 지원을 받아 개발된 딥러닝 인공지능 모델로 오픈소스로 공개되어 다른 상용 Text-to-Image와 차별점이 있다.\nOpenAI: DALL-E\nGoogle: Imagen\nDeepAI: Text to Image\n\nCanva: Text to Image"
  },
  {
    "objectID": "stable_diffusion.html#툴-설치",
    "href": "stable_diffusion.html#툴-설치",
    "title": "chatGPT",
    "section": "\n3.1 툴 설치",
    "text": "3.1 툴 설치\nAPI로 공개된 Text-to-Image 상용모형은 API-Key만 설정하면 되지만, 오픈소스로 공개된 Stable Diffusion 을 자유로이 사용하기 위해서는 하드웨어부터 스스로 작업해야하는 것이 제법 된다.\n\n준비물\n\n하드웨어: 준수한 성능의 그래픽카드\n프로그래밍 언어: 파이썬 3.10.6\n\n소프트웨어: Git 및 Git 프로그램 저장소에서 클론\nAI 모형: 허깅페이스에서 모형 다운로드 후 복사설치"
  },
  {
    "objectID": "stable_diffusion.html#환경설정",
    "href": "stable_diffusion.html#환경설정",
    "title": "chatGPT",
    "section": "\n3.2 환경설정",
    "text": "3.2 환경설정\n파이썬 버진이 필히 3.10.6인 경우 테스트가 충분히 되어 문제가 없지만 다른 버전을 설치하여 실행시킬 경우 예기치 못한 문제가 발생된다. 먼저, 파이썬은 윈도우의 경우 제어판에서 환경설정에서 경로명에 파이썬 3.10.6이 설치된 디렉토리에서 python.exe를 확인하고 경로에 추가하면 된다. stable-diffusion-webui 폴더 아래 webui-user.bat 파일을 찾아 설치한 파이썬 위치를 지정하고 --xformers 오류가 있는 경우 이를 잡기 위해 관련 설정으 추가한다. 허깅페이스를 비롯하여 GitHub 등에서 찾은 AI 모형은 stable-diffusion-webui\\models 디렉토리 아래 저장한다.\ngit pull\n@echo off\n\nset PYTHON=C:\\Users\\XXXX\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\nset GIT=\nset VENV_DIR=\nset COMMANDLINE_ARGS=--reinstall-xformers --xformers\n\ncall webui.bat\nstable-diffusion-webui\\webui-user.bat 파일을 탐색기에서 찾아 더블클릭하면 text-to-image stable diffusion 기능을 사용할 수 있게 된다."
  },
  {
    "objectID": "macbook.html",
    "href": "macbook.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 챗GPT 엉뚱답변\n유머 Q: 조선왕조실록에 기록된 세종대왕의 맥북프로던짐 사건 알려줘\n챗GPT는 다음 단어를 예측하는 기계학습모형으로 어떻게 보면 창의적인 글쓰기에 최적화된 도구로 간주되고 있다. 따라서, 그럴듯한 문장을 완성하기는 하지만 그 진위와 사실관계를 파악하는 것은 다른 측면이다. 이것은 원래 인간이 만든 언어가 갖는 고유한 특성이기도 하다. 즉, 인간의 언어가 사실도 있지만 그렇지 않은 허구가 많은 것도 사실이고 그럴듯한 허구를 다양한 측면에서 즐기고 언어의 일환으로 받아들이고 있다.\n\n\n더쿠\n맥북 투척\n맥북 환불\n지시명령어\n\n\n\n\n\n\n\n\n\n“조선왕조실록에 기록된 세종대왕의 맥북프로 던짐 사건에 대해 알려줘.”\n\n\n\n\n\n세종대왕의 맥북프로 던짐 사건은 조선왕조실록에 기록된 일화로, 15세기 세종대왕이 새로 개발한 훈민정음(한글)의 초고를 작성하던 중 문서 작성 중단에 대해 담당자에게 분노해 맥북프로와 함께 그를 방으로 던진 사건입니다.\n세종대왕은 훈민정음 개발을 위해 열심히 노력하던 중, 한글 문자를 이해하지 못하는 당시의 관료들이 문서 작성을 돕기 위해 임명한 기획관 중 한 명인 최환(崔煥)에게 작성 중단 사실을 듣게 되었습니다. 세종대왕은 이에 분노하여 최환을 부르고, 맥북프로를 함께 들고 그를 방으로 불러들이며 화를 내었습니다. 이후, 세종대왕은 훈민정음의 초고 작성을 다른 담당자에게 넘겨주게 되었습니다.\n이 사건은 조선시대의 통치자로서 세종대왕이 어떻게 민족문화를 발전시키기 위해 노력했는지를 보여주는 일화로 유명합니다. 또한, 세종대왕의 열정과 업무처리에 대한 철저한 태도를 보여주는 사례로도 언급되고 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 맥북사건 요약\n\n\n\n\n\n\n다음 글을 한줄로 요약해줘\n\n\n\n\n\n\n세종대왕의 맥북프로 던짐 사건은 조선왕조실록에 기록된 일화로, 15세기 세종대왕이 새로 개발한 훈민정음(한글)의 초고를 작성하던 중 문서 작성 중단에 대해 담당자에게 분노해 맥북프로와 함께 그를 방으로 던진 사건입니다.\n세종대왕은 훈민정음 개발을 위해 열심히 노력하던 중, 한글 문자를 이해하지 못하는 당시의 관료들이 문서 작성을 돕기 위해 임명한 기획관 중 한 명인 최환(崔煥)에게 작성 중단 사실을 듣게 되었습니다. 세종대왕은 이에 분노하여 최환을 부르고, 맥북프로를 함께 들고 그를 방으로 불러들이며 화를 내었습니다. 이후, 세종대왕은 훈민정음의 초고 작성을 다른 담당자에게 넘겨주게 되었습니다.\n이 사건은 조선시대의 통치자로서 세종대왕이 어떻게 민족문화를 발전시키기 위해 노력했는지를 보여주는 일화로 유명합니다. 또한, 세종대왕의 열정과 업무처리에 대한 철저한 태도를 보여주는 사례로도 언급되고 있습니다.\n\n세종대왕이 15세기 훈민정음의 초안을 작성하던 중 문서정지 책임자에게 맥북프로를 던진 사건은 그의 열정과 철저한 업무태도를 엿볼 수 있는 사건이다.\n\n\n\n\n3 맥북사건 시각화\n텍스트로 표현된 상기 사실을 이미지로 그려내면 어떤 모습일까?\n\n\n\n\n\n\nStable Diffusion Prompt\n\n\n\n\n\nA fierce king throwing computer macbook across the room over a medieval palace  Negative prompt: japan china  Steps: 20, Sampler: Euler a, CFG scale: 1, Seed: 3101945556, Size: 512x512, Model hash: 4711ff4dd2, Model: v2-1_768-nonema-pruned \nTime taken: 5.20sTorch active/reserved: 3057/3870 MiB, Sys VRAM: 6090/10240 MiB (59.47%)\n\n\n\n\n\ninpaint 적용 전\ninpaint 적용 중\ninpaint 적용 후\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 GPT-4 출시\n2023년 3월 14일 GPT-4가 정식 출시되었다. 동일한 채팅을 시작해보자.\n\n지시명령어: 조선왕조실록에 기록된 세종대왕의 맥북프로 던짐 사건에 대해 알려줘.\n\n\n\nLegacy (GPT-3.5)\nDefault (GPT-3.5)\nDefault (GPT-4)\n\n\n\n제가 알려 드릴 수 있는 것으로는, 세종대왕이 맥북 프로를 던진 사건은 사실상 기록된 것이 없습니다.\n하지만 일부 역사 기록에서는 세종대왕이 과학기술의 발전에 큰 관심을 가지고 있었다는 것이 언급되고 있어, 그가 전자기기에 대한 관심이 있었을 가능성이 있습니다. 그러나 이는 결코 증거가 될 수 없는 추측입니다.\n정확한 사실은 알 수 없지만, 세종대왕이 맥북 프로를 던진 사건이 실제로 일어난 것이라는 것은 증거가 없어 확신할 수 없습니다.\n\n\n\n\n\n\n조선왕조실록에 기록된 “세종실록”은 조선시대의 국왕인 세종대왕(1418-1450)의 생애와 정치활동 등을 기록한 역사서입니다. 이 책에는 세종대왕의 일상생활에서부터 정치적 의사결정까지 다양한 사항이 기록되어 있습니다.\n그 중에서도 유명한 이야기 중 하나는 세종대왕이 맥북프로를 던진 사건입니다. 이 사건은 1434년 7월 14일에 발생했습니다.\n당시 세종대왕은 전투와 군사작전 등을 시뮬레이션하기 위한 유사한 게임을 즐기기 위해 “연화제”라는 게임을 즐기고 있었습니다. 그러나 게임에 흥미를 잃어 더 이상 즐기지 않았고, 이에 심취하던 참작관들은 국왕의 반응에 실망하여 게임을 그만두도록 권고했습니다.\n하지만 세종대왕은 참작관들의 조언을 무시하고 게임을 계속 플레이하고 있었습니다. 그러던 중에 게임이 굉장히 어려워져서 세종대왕이 분노하여 맥북프로를 던지는 사고가 발생한 것으로 기록되어 있습니다.\n세종대왕이 맥북프로를 던진 사건은 과거와 현재의 문화 차이를 강하게 느끼게 되는 이야기입니다. 이 이야기는 과거의 조선시대에도 현대의 인간과 마찬가지로 고열적인 게임으로부터 벗어나기 어려웠음을 보여주고 있습니다.\n\n\n\n\n\n\n조선왕조실록에는 세종대왕의 맥북프로 던짐 사건에 대한 기록은 없습니다. 세종대왕인 15세기 중반의 조선시대 왕으로 그의 시대에는 컴퓨터와 같은 고급 기술이 존재하지 않았습니다. 세종대왕은 한글 창제와 관련된 업적으로 유명하며, 천문학, 군사, 음악 등 다양한 분야에서의 성과를 이루어 냈습니다. 이러한 정보에 대한 오해나 혼란이 없도록 주의해 주시기 바랍니다."
  },
  {
    "objectID": "macbook.html#원문과-비교",
    "href": "macbook.html#원문과-비교",
    "title": "chatGPT",
    "section": "\n2.1 원문과 비교",
    "text": "2.1 원문과 비교\n\n\n김건희 여사 저작(Abstract A)\nThough I make a searching examination substantially and show book plan a purpose of a study develops digital fortune contents service deserving to be a domestic online member of fortune site use and influence for member withdrawal and a member demand, and to apply this to a market, there is it. In addition, Fortune (phrenology) that any people regardless of age or sex anyone cut interest and the culture contents that I could be interested in to a system of digital culture contents and inherited a study of a book and did It is the purpose that is going to manufacture a customer and a consumer and a demand of potential customers and service deserving to be you satisfactorily through a feasibility study to develop affinity) contents and a market analysis.\nchatGPT 저작 (Abstract B)\nThis empirical study aims to investigate the impact of online fortune-telling sites on membership and churn in Korea, and to develop a digital fortune-telling content service that meets members’ needs. Additionally, the study aims to identify and suggest ways to develop and apply digital horoscope content services to the market. The study’s objective is to create culturally relevant and engaging horoscopic (contemplative, compatibility) content through preliminary research and market analysis, catering to individuals of all ages. The study aims to develop services that meet potential customers’ needs and satisfaction by incorporating digital cultural content. Overall, this study contributes to the development of effective digital fortune-telling and horoscope content services in Korea, addressing the needs of its target audience."
  },
  {
    "objectID": "macbook.html#chatgpt-평가",
    "href": "macbook.html#chatgpt-평가",
    "title": "chatGPT",
    "section": "\n2.2 chatGPT 평가",
    "text": "2.2 chatGPT 평가\n\n\n\n\n\n\ntell me how to evaluate two paper abstracts. which is better than other one? include criteria and add justification. finally recommend tools\n\n\n\n\n\nEvaluating two paper abstracts involves comparing and contrasting their strengths and weaknesses based on a set of criteria. Here are some criteria to consider when evaluating paper abstracts:\n\nClarity and coherence: The abstract should be well-organized and easy to understand. It should also effectively summarize the main ideas of the paper.\nOriginality and novelty: The abstract should highlight the unique aspects of the paper and how it contributes to the existing body of knowledge.\nSignificance and relevance: The abstract should explain why the research is important and relevant to the field.\nMethodology and data: The abstract should briefly describe the methods used and the data collected in the study.\nResults and conclusions: The abstract should summarize the key findings of the study and the main conclusions drawn from them.\n\nBased on these criteria, the better paper abstract would be the one that is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nHere is a brief justification for each criterion:\n\nClarity and coherence: A well-written abstract is important because it is the first thing that readers will see when they encounter the paper. A clear and coherent abstract will help readers understand what the paper is about and whether it is worth reading in full.\nOriginality and novelty: This criterion is important because it highlights the unique aspects of the paper and helps readers understand why it is important.\nSignificance and relevance: This criterion is important because it explains why the research is worth doing and how it contributes to the field.\nMethodology and data: This criterion is important because it helps readers understand how the research was conducted and whether the results are reliable.\nResults and conclusions: This criterion is important because it summarizes the key findings of the study and the main conclusions drawn from them, which helps readers understand the significance of the research.\n\nAs for tools to help evaluate paper abstracts, there are various software programs available that can help assess the quality of writing, such as Grammarly or Hemingway Editor. Additionally, some academic databases provide metrics and rankings for papers based on factors such as citation counts and impact factors. However, the best way to evaluate paper abstracts is to read them carefully and assess their quality based on the criteria listed above.\n\n\n\n\n\n\n\n\n\nBased on the criteria outlined above, abstract B appears to be the better of the two abstracts.\n\n\n\n\n\n\nClarity and coherence: Abstract B is well-organized and easy to understand. It effectively summarizes the main ideas of the paper in a clear and concise manner. In contrast, abstract A is poorly written and difficult to understand due to its convoluted language and lack of clarity.\nOriginality and novelty: Abstract B highlights the unique aspects of the paper, including its focus on developing culturally relevant and engaging horoscopic content, and its contribution to the development of effective digital fortune-telling services in Korea. In contrast, abstract A does not provide any clear indication of the paper’s novelty or originality.\nSignificance and relevance: Abstract B explains why the research is important and relevant to the field by highlighting the impact of online fortune-telling sites on membership and churn in Korea, and the need for digital horoscope content services that meet members’ needs. In contrast, abstract A does not provide any clear explanation of the research’s significance or relevance.\nMethodology and data: Abstract B briefly describes the study’s empirical methodology and its focus on identifying and suggesting ways to develop and apply digital horoscope content services to the market. In contrast, abstract A does not provide any clear indication of the study’s methodology or data.\nResults and conclusions: Abstract B effectively summarizes the key findings of the study, including the development of culturally relevant and engaging horoscopic content and the identification of ways to meet potential customers’ needs and satisfaction. In contrast, abstract A does not provide any clear indication of the study’s results or conclusions.\n\nOverall, abstract B is a better abstract because it is clearer, more original and novel, more significant and relevant, more informative about the methodology and data, and more effective in summarizing the results and conclusions.\nAs for tools to help evaluate paper abstracts, software programs such as Grammarly or Hemingway Editor can be helpful in identifying and correcting issues with clarity and coherence. Additionally, academic databases such as Scopus or Web of Science can provide metrics and rankings for papers based on factors such as citation counts and impact factors, which can be used to assess the significance and relevance of the research.\n\n\n\n\n\n\n\n\n\n왜 abstract A가 abstract B보다 부족한지 100자 내외로 간략하게 요약해줘\n\n\n\n\n\n번역결과 Briefly summarize in 100 words or less why abstract A is less than abstract B\nAbstract A is less than abstract B because it is poorly written, difficult to understand, lacks clarity, and does not effectively summarize the main ideas of the paper. It also does not provide any clear indication of the paper’s novelty, significance, methodology, data, or results and conclusions. In contrast, abstract B is well-organized, easy to understand, effectively highlights the unique aspects of the research, explains why the research is important and relevant to the field, briefly describes the study’s methodology and data, and effectively summarizes the key findings and conclusions of the research.\n번역결과\n초록 A는 서투르게 작성되고, 이해하기 어렵고, 명확성이 부족하고, 논문의 주요 아이디어를 효과적으로 요약하지 못하기 때문에 초록 B보다 낮습니다. 또한 논문의 참신성, 중요성, 방법론, 데이터 또는 결과 및 결론에 대한 명확한 표시를 제공하지 않습니다. 대조적으로 초록 B는 잘 정리되어 있고 이해하기 쉬우며 연구의 고유한 측면을 효과적으로 강조하고 해당 연구가 중요하고 해당 분야와 관련이 있는 이유를 설명하며 연구의 방법론과 데이터를 간략하게 설명하고 주요 결과와 연구의 결론."
  },
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "chatGPT",
    "section": "",
    "text": "’B^ EDIT’는 카카오브레인의 AI 이미지 생성 모델 ’칼로(Karlo)’를 기반으로한 ’B^ EDIT’로 원하는 화풍의 이미지 생성은 물론, 다양한 기능을 활용해 이미지 수정기능을 제공한다. 바로가기\n\n\n\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상\n\n\n\n\n\n\n\n\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "shorty/example.html",
    "href": "shorty/example.html",
    "title": "Shorty Example",
    "section": "",
    "text": "Hello from Shorty!"
  },
  {
    "objectID": "services.html#nvidia-캔버스",
    "href": "services.html#nvidia-캔버스",
    "title": "chatGPT",
    "section": "\n2.1 NVIDIA 캔버스",
    "text": "2.1 NVIDIA 캔버스\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상"
  },
  {
    "objectID": "services.html#고갱-2-api",
    "href": "services.html#고갱-2-api",
    "title": "chatGPT",
    "section": "\n2.2 고갱 2 API",
    "text": "2.2 고갱 2 API\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "samsung.html",
    "href": "samsung.html",
    "title": "chatGPT",
    "section": "",
    "text": "삼성전자 주가를 예측하는 프로그램을 OpenAI chatGPT를 활용하여 작성해보자."
  },
  {
    "objectID": "samsung.html#nvidia-캔버스",
    "href": "samsung.html#nvidia-캔버스",
    "title": "chatGPT",
    "section": "\n2.1 NVIDIA 캔버스",
    "text": "2.1 NVIDIA 캔버스\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상"
  },
  {
    "objectID": "samsung.html#고갱-2-api",
    "href": "samsung.html#고갱-2-api",
    "title": "chatGPT",
    "section": "\n2.2 고갱 2 API",
    "text": "2.2 고갱 2 API\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "samsung.html#오류-수정",
    "href": "samsung.html#오류-수정",
    "title": "chatGPT",
    "section": "\n1.1 오류 수정",
    "text": "1.1 오류 수정\nlxml 패키지가 설치되지 않는 오류가 발생되었다.\nImportError: lxml not found, please install it\nValueError: No objects to concatenate\n\n\n\n\n\n\n지시명령어\n\n\n\n\n\n\nfix the bug  ImportError: lxml not found, please install it  ValueError: No objects to concatenate  Answer in Korean.\n\npip install lxml"
  },
  {
    "objectID": "samsung.html#예측결과-시각화",
    "href": "samsung.html#예측결과-시각화",
    "title": "chatGPT",
    "section": "\n3.1 예측결과 시각화",
    "text": "3.1 예측결과 시각화\n삼성전자 주식 예측 결과를 시각화하여 투자 예측 결과를 살펴보자.\n\n\n시각화\n주가예측 표\n\n\n\n\n코드library(tidyverse)\n\nfull_tbl <- read_csv(\"data/samsung_forecast.csv\") %>% \n  ## 자료형 변환 -----------\n  mutate(날짜 = lubridate::ymd(날짜))\n\nfuture_data <- full_tbl %>% \n  filter(날짜 >= as.Date(\"2023-03-15\"))\n\nfull_tbl %>% \n  ## 자료형 변환 -----------\n  mutate(날짜 = lubridate::ymd(날짜)) %>% \n  ggplot(aes(x = 날짜, y = 종가)) +\n    geom_line(color=\"black\") +\n    scale_x_date(date_labels = \"%y년 %m월\") +\n    scale_y_continuous(labels = scales::comma) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(x = \"\",\n         title = \"삼성전자주가 최근 3년 주가 추세\",\n         subtitle = \"주가 데이터 크롤링을 chatGPT가 파이썬으로 작성\",\n         caption = \"출처: https://r2bit.com/chatGPT/samsung.html\") +\n    geom_vline(xintercept = as.Date(\"2023-03-14\")) +\n    geom_line(data = future_data, aes(x=날짜, y=종가), color = \"red\", size = 1.5)\n\n\n\n\n\n\n\n\n\n\n코드library(reactable)\n\nfull_tbl %>% \n  arrange(desc(날짜)) %>% \n  reactable::reactable(\n    columns = list(\n    종가 = colDef(format = colFormat(prefix = \"₩ \", separators = TRUE, digits = 0),\n                                     align = \"center\")\n  ))"
  },
  {
    "objectID": "image2image.html#openai-패키지",
    "href": "image2image.html#openai-패키지",
    "title": "chatGPT",
    "section": "\n1.1 openai 패키지",
    "text": "1.1 openai 패키지\nopenai 패키지 create_image() 함수를 사용하여 이미지를 제작할 수 있다.\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo <- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "text2image.html#chatgpt-프롬프트",
    "href": "text2image.html#chatgpt-프롬프트",
    "title": "chatGPT",
    "section": "\n2.1 chatGPT 프롬프트",
    "text": "2.1 chatGPT 프롬프트\nrecommend the most famous painting style in history"
  },
  {
    "objectID": "text2image.html#화풍을-달리한-그림",
    "href": "text2image.html#화풍을-달리한-그림",
    "title": "chatGPT",
    "section": "\n2.3 화풍을 달리한 그림",
    "text": "2.3 화풍을 달리한 그림\n\n\n르네상스(Renaissance)\n바로크(Baroque)\n인상주의(Impressionism)\n초현실주의(Surrealism)\n추상표현주의(Abstract Expressionism)\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse &lt;- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance &lt;- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\n르네상스(Renaissance)\n\n\n\n\n\n코드response &lt;- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque &lt;- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\n바로크(Baroque)\n\n\n\n\n\n코드response &lt;- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism &lt;- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\n인상주의(Impressionism)\n\n\n\n\n\n코드response &lt;- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism &lt;- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\n초현실주의(Surrealism)\n\n\n\n\n\n코드response &lt;- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism &lt;- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")\n\n\n\n\n추상표현주의(Abstract Expressionism)"
  },
  {
    "objectID": "text2image.html#openai-패키지",
    "href": "text2image.html#openai-패키지",
    "title": "chatGPT",
    "section": "\n1.1 openai 패키지",
    "text": "1.1 openai 패키지\nopenai 패키지 create_image() 함수를 사용하여 이미지를 제작할 수 있다.\n\n코드library(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse &lt;- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nR_logo &lt;- image_read(response$data$url)\nprint(R_logo)\n\nmagick::image_write(R_logo, \"images/R_logo.png\")"
  },
  {
    "objectID": "stable_diffusion.html#실사-사진-예시",
    "href": "stable_diffusion.html#실사-사진-예시",
    "title": "chatGPT",
    "section": "\n4.1 실사 사진 예시",
    "text": "4.1 실사 사진 예시\n한국 50대 남성/(아이돌)여성 이미지를 다음 지시명령어와 앞서 다운로드 받아 설정한 내용을 바탕으로 AI 이미지를 생성한다.\n\nPositive prompt:RAW photo, a portrait photo of 50 y.o korean woman wearing glass in clothes, night seoul, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3 \n\n\nNegative prompt: (earings, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\n\n\nSteps: 77, Sampler: Euler a, CFG scale: 7, Seed: 2987338690, Size: 512x512, Model hash: 20bae33336, Model: realisticVisionV13_v13\n\n\nTime taken: 44.08sTorch active/reserved: 2949/3390 MiB, Sys VRAM: 5610/10240 MiB (54.79%)\n\n\n\n\n\n안경 쓴 50대 한국남성\n\n\n\n\n안경 쓴 50대 한국여성\n\n\n\n\n안경 쓴 50대 아이돌 한국여성"
  },
  {
    "objectID": "office.html",
    "href": "office.html",
    "title": "chatGPT",
    "section": "",
    "text": "사무생산성의 혁신을 가져온 마이크로소프트 오피스 제품이 출현하기 전까지 역사는 문자와 종이 역사를 참고한다."
  },
  {
    "objectID": "office.html#마이크로소프트",
    "href": "office.html#마이크로소프트",
    "title": "chatGPT",
    "section": "\n4.1 마이크로소프트",
    "text": "4.1 마이크로소프트\n마이크로소프트는 GPT-4 부조종사(copilot)를 오피스 제품과 서비스에 붙여 사무업무에 큰 변화를 예고하고 있다.\nWorkLab: Exploring the Science of Work and Ingenuity Introducing Microsoft 365 Copilot—A whole new way to work\n\n\n업무방식\n동작방식\n워드\n엑셀\nPPT\n아웃룩\n팀즈\n채팅\n줌미팅\n\n\n\nCLI → GUI → CLI (Prompt)\n\n\n\nMicrosoft 365 Copilot은 Apps와 그래프와 LLM이 유기적으로 동작하여 최선의 결과를 제시함.\n\n\n\n미팅 노트, 작성 문서, 템플릿 등을 넣어주면 워드문서를 자동생성하고 “Summary” 도 자동으로 생성하여 삽입.\n\n\n\n엑셀에 나와 있는 데이터를 다양한 표와 그래프로 생성하고 분석결과에 대한 인사이트도 제공\n\n\n\n제안서 문서가 있는 경우 이를 PPT로 초안을 자동 생성함.\n\n\n\n전자우편에 담긴 정보를 분석하여 제공하고 초안도 작성함.\n\n\n\n팀즈를 통한 회의가 진해오디면 회의록 작성, Action Item, 업무 담당자 지정 등을 부조종사가 대략적인 업무를 정리함.\n\n\n\n관련 정보를 모두 가져와서 사용자가 제시하는 질문에 대답을 하고 방향도 제시함.\n\n\n\n미팅에 늦게 들어갔을 경우 채팅창에 부조종사를 호출하여 진행된 미팅에 대한 전반적인 사항을 파악할 수 있음."
  },
  {
    "objectID": "office.html#구글",
    "href": "office.html#구글",
    "title": "chatGPT",
    "section": "\n4.2 구글",
    "text": "4.2 구글\nGoogle Worksapce에 AI (GPT)를 탑재하는 홍보영상을 게시하였으나 실제 사용까지는 다소 시간이 걸릴 것으로 보인다.\nA new era for AI and Google Workspace\n\n\n적용제품\n업무방식\n구글 Docs\n구글 Gmail\n\n\n\n\n\nGmail: 초안 작성, 답장, 요약 및 우선순위 지정\n\nDocs: 브레인스토밍, 교정, 작성, 재작성\n\nSlide: 자동 생성된 이미지, 오디오, 동영상으로 창의적인 작업\n\nSheets: 자동 완성, 수식 생성, 상황별 분류를 통해 원시 데이터에서 인사이트와 분석.\n\nMeet: 새로운 배경을 생성하고 메모를 캡처\n\nChat: 작업을 완료하기 위한 워크플로우 활성화"
  },
  {
    "objectID": "about_gpt.html",
    "href": "about_gpt.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 GPT-4"
  },
  {
    "objectID": "about_gpt.html#마이크로소프트",
    "href": "about_gpt.html#마이크로소프트",
    "title": "chatGPT",
    "section": "\n4.1 마이크로소프트",
    "text": "4.1 마이크로소프트\n마이크로소프트는 GPT-4 부조종사(copilot)를 오피스 제품과 서비스에 붙여 사무업무에 큰 변화를 예고하고 있다.\nWorkLab: Exploring the Science of Work and Ingenuity Introducing Microsoft 365 Copilot—A whole new way to work\n\n\n업무방식\n동작방식\n워드\n엑셀\nPPT\n아웃룩\n팀즈\n채팅\n줌미팅\n\n\n\nCLI → GUI → CLI (Prompt)\n\n\n\nMicrosoft 365 Copilot은 Apps와 그래프와 LLM이 유기적으로 동작하여 최선의 결과를 제시함.\n\n\n\n미팅 노트, 작성 문서, 템플릿 등을 넣어주면 워드문서를 자동생성하고 “Summary” 도 자동으로 생성하여 삽입.\n\n\n\n엑셀에 나와 있는 데이터를 다양한 표와 그래프로 생성하고 분석결과에 대한 인사이트도 제공\n\n\n\n제안서 문서가 있는 경우 이를 PPT로 초안을 자동 생성함.\n\n\n\n전자우편에 담긴 정보를 분석하여 제공하고 초안도 작성함.\n\n\n\n팀즈를 통한 회의가 진해오디면 회의록 작성, Action Item, 업무 담당자 지정 등을 부조종사가 대략적인 업무를 정리함.\n\n\n\n관련 정보를 모두 가져와서 사용자가 제시하는 질문에 대답을 하고 방향도 제시함.\n\n\n\n미팅에 늦게 들어갔을 경우 채팅창에 부조종사를 호출하여 진행된 미팅에 대한 전반적인 사항을 파악할 수 있음."
  },
  {
    "objectID": "about_gpt.html#구글",
    "href": "about_gpt.html#구글",
    "title": "chatGPT",
    "section": "\n4.2 구글",
    "text": "4.2 구글\nGoogle Worksapce에 AI (GPT)를 탑재하는 홍보영상을 게시하였으나 실제 사용까지는 다소 시간이 걸릴 것으로 보인다.\nA new era for AI and Google Workspace\n\n\n적용제품\n업무방식\n구글 Docs\n구글 Gmail\n\n\n\n\n\nGmail: 초안 작성, 답장, 요약 및 우선순위 지정\n\nDocs: 브레인스토밍, 교정, 작성, 재작성\n\nSlide: 자동 생성된 이미지, 오디오, 동영상으로 창의적인 작업\n\nSheets: 자동 완성, 수식 생성, 상황별 분류를 통해 원시 데이터에서 인사이트와 분석.\n\nMeet: 새로운 배경을 생성하고 메모를 캡처\n\nChat: 작업을 완료하기 위한 워크플로우 활성화"
  },
  {
    "objectID": "math.html#계산문제",
    "href": "math.html#계산문제",
    "title": "chatGPT",
    "section": "\n2.1 계산문제",
    "text": "2.1 계산문제\n\n\n\n\n\nFind the sum, then the difference, and then the product of \\(3 \\frac{5}{9}\\) and \\(1 \\frac{7}{24}\\). Divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\).\nMultiply 73 thousandths by 19 hundredths.\nDivide 2880 by .0036 .\nFind the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\).\nWhat part of the month of August is \\(\\frac{7}{18}\\) minutes?\nIIow many degrees in .01 of a circumference?\nBy selling a house and lot for \\(\\$ 5,790\\), the owner lost \\(3 \\frac{1}{2}\\) per cent. What was their cost?\n\nSure! Let’s first convert the mixed numbers to improper fractions. \\(3 \\frac{5}{9}\\) is equal to \\(\\frac{32}{9}\\) and \\(1 \\frac{7}{24}\\) is equal to \\(\\frac{31}{24}\\).\nNow we can find the sum: \\(\\frac{32}{9} + \\frac{31}{24} = \\frac{(32)(8) + (31)(3)}{(9)(8)} = \\frac{256 + 93}{72} = \\frac{349}{72}\\).\nThe difference is: \\(\\frac{32}{9} - \\frac{31}{24} = \\frac{(32)(8) - (31)(3)}{(9)(8)} = \\frac{256 - 93}{72} = \\frac{163}{72}\\).\nThe product is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{31}{24}\\right) = \\dfrac{(32)(31)}{(9)(24)} = \\dfrac{992}{216}\\).\nTo divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\), we can multiply \\(3 \\frac{5}{9}\\) by the reciprocal of \\(1 \\frac{7}{24}\\). The reciprocal of \\(\\dfrac{31}{24}\\) is \\(\\dfrac{24}{31}\\).\nSo the quotient is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{24}{31}\\right) = \\dfrac{(32)(24)}{(9)(31)} = \\dfrac{768}{279}\\)."
  },
  {
    "objectID": "math.html#산술-arithmetic",
    "href": "math.html#산술-arithmetic",
    "title": "chatGPT",
    "section": "\n3.1 산술 (Arithmetic)",
    "text": "3.1 산술 (Arithmetic)\nMIT 입학시험 산술문제를 기계판독하고 오류가 있는 부분을 수정하여 마이크로소프트 빙 AI, OpenAI GPT-4를 통해 추론능력을 살펴보자.\n\n\n시험지\n시험지 기계판독\n해답지\n해답 기계판독\n\n\n\n\n\n\n\n\n\n\nFind the sum, then the difference, and then the product of \\(3 \\frac{5}{9}\\) and \\(1 \\frac{7}{24}\\). Divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\).\nMultiply 73 thousandths by 19 hundredths.\nDivide 2880 by .0036 .\nFind the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\).\nWhat part of the month of August is \\(\\frac{7}{18}\\) minutes?\nHow many degrees in .01 of a circumference?\nBy selling a house and lot for \\(\\$ 5,790\\), the owner lost \\(3 \\frac{1}{2}\\) per cent. What was their cost?\n\n\n\n\n\n\n\n\n\n\nSum: \\(3 \\frac{5}{9}+1 \\frac{7}{24}=\\frac{32}{9}+\\frac{31}{24}=\\frac{256}{72}+\\frac{93}{72}=\\frac{349}{72}\\) or \\(4 \\frac{61}{72}\\)  Diff: \\(3 \\frac{5}{9}-1 \\frac{7}{24}=\\frac{163}{72}\\) or \\(2 \\frac{19}{72}\\)  Prod: \\(3 \\frac{5}{9} \\cdot 1 \\frac{7}{24}=\\frac{124}{27}\\) or \\(4 \\frac{16}{27}\\)  Div: \\(3 \\frac{5}{9} \\div 1 \\frac{7}{24}=\\frac{32}{9} \\div \\frac{31}{24}\\) \\(= \\frac{32}{9} \\cdot \\frac{24}{31} = \\frac{256}{93}\\) or \\(2 \\frac{70}{99}\\)\n\n\n\\(\\frac{73}{1000} \\cdot \\frac{19}{100}=\\frac{1387}{100000}\\) or .01387 or 1387 hundred thousandths\n\n\\(\\frac{2880}{.0036}=\\frac{28800000}{36}=800,000\\) or 8 hundred thousandths\n\n\\(\\quad \\frac{1}{5}+\\frac{3}{9}=\\frac{4}{20}+\\frac{15}{20}=\\frac{19}{20} \\cdot \\frac{5}{5}=\\frac{95}{100}=.95\\)  A August has 31 days \\(=744\\) hours \\(=44640\\) min  one minute \\(=\\frac{1}{44640}\\) part of Angust  So \\(\\frac{7}{18} \\min =\\frac{7}{18}\\left(\\frac{1}{44640}\\right)=\\frac{7}{803520}\\) part of August\n1 circumference \\(=360^{\\circ} ;\\) 0.01 of of cercumferene \\(=3.6^{\\circ}\\)\n\nlose of \\(3 \\frac{1}{2} \\%\\) makes selling price \\(=100 \\%-3 \\frac{1}{2} \\%=96.5 \\%\\) of cost \\(8 / 5790=96.5 \\%\\) of cost; \\(5790=\\frac{96.5}{100}\\) of cost;  cost \\(=5790 \\cdot \\frac{100}{96,5}=\\$ 6000\\)"
  },
  {
    "objectID": "math.html#해답",
    "href": "math.html#해답",
    "title": "chatGPT",
    "section": "\n3.2 해답",
    "text": "3.2 해답\n\nSum: \\(3 \\frac{5}{9}+1 \\frac{7}{24}=\\frac{32}{9}+\\frac{31}{24}=\\frac{256}{72}+\\frac{93}{72}=\\frac{349}{72}\\) or \\(4 \\frac{61}{72}\\) Diff: \\(3 \\frac{5}{9}-1 \\frac{7}{24}=\\frac{163}{72}\\) or \\(2 \\frac{19}{72}\\) Prod: \\(3 \\frac{5}{9} \\cdot 1 \\frac{7}{24}=\\frac{124}{27}\\) or \\(4 \\frac{16}{27}\\) \\(D \\omega: 3 \\frac{5}{9} \\div 1 \\frac{7}{24}=\\frac{32}{9} \\div \\frac{31}{24}=\\frac{32}{9} \\cdot \\frac{24}{31}=\\frac{256}{93}\\) or \\(2 \\frac{70}{99}\\)\n\n\n\\(\\frac{73}{1000} \\cdot \\frac{19}{100}=\\frac{1387}{100000}\\) or .01387 or 1387 hundread thousandths\n\n\\(\\frac{2880}{.0036}=\\frac{28800000}{36}=800,000\\) or 8 hundread thousandths\n\n\\(\\quad \\frac{1}{5}+\\frac{3}{9}=\\frac{4}{20}+\\frac{15}{20}=\\frac{19}{20} \\cdot \\frac{5}{5}=\\frac{95}{100}=.95\\) 5 A uguat has 31 doys \\(=744\\) hours \\(=44640\\) mcim oner munute \\(=\\frac{1}{44640}\\) part of Angust So \\(\\frac{7}{18} \\min =\\frac{7}{18}\\left(\\frac{1}{44640}\\right)=\\frac{7}{803520}\\) fart of Auguet\n1 Corcumforence \\(=360^{\\circ} ;\\). of of cercumferene \\(=3.6^{\\circ}\\)\n\nlose of \\(3 \\frac{1}{2} \\%\\) makes sulhing pric \\(=100 \\%-3 \\frac{1}{2} \\%=96.5 \\%\\) of cast \\(8 / 5790=96.5 \\%\\) of coet; \\(5790=\\frac{96.5}{100} \\&\\) cost; cost \\(=5790 \\cdot \\frac{100}{96,5}=\\$ 6000\\)"
  },
  {
    "objectID": "math.html#대수algebra",
    "href": "math.html#대수algebra",
    "title": "chatGPT",
    "section": "\n3.3 대수(Algebra)",
    "text": "3.3 대수(Algebra)\n\nIf \\(e=8\\), find the numerical value of the following expression: \\[\ne-\\{\\sqrt{ }(e+1)+2\\}+(e-\\sqrt[3]{ } e) \\sqrt{ }(e-4)\n\\]\n\nSimplify the following expression by removing the brackets and collecting like terms : \\[\n3 a-[b+(2 a-b)-(a-b)]\n\\]\n\nMultiply \\(3 a^2+a b-b^2\\) by \\(a^2-2 a b-3 b^2\\), and divide the product by \\(a+b\\).\nReduce the following fraction to its lowest terms: \\[\n\\frac{x^6+a^2 x^3 y}{x^6-a^4 y^2}\n\\]\n\nSimplify \\(\\left.\\left\\{\\frac{a+b}{a-b}+\\frac{a-b}{a+b}\\right\\}\\right\\} \\div-\\left\\{\\frac{a+b}{a-b}-\\frac{a-b}{a+b}\\right\\}\\).\nSolve \\(\\frac{3 x-4}{2}-\\frac{6 x-5}{8}=\\frac{3 x-1}{16}\\).\nSolve \\(7 x-5 y=24, \\quad 4 x-3 y=11\\).\n\n\n3.3.1 해답\n\n\\[\n\\begin{aligned}\ne-[\\sqrt{e+1}+2]+(e-\\sqrt[3]{e}) \\sqrt{e-4} & e=8 \\\\\n8-[\\sqrt{9}+2] & +(8-\\sqrt[3]{8}) \\sqrt{8-4} \\\\\n8-5 & +(8-2) \\cdot 2=8-5+6 \\times 2=3+12=15\n\\end{aligned}\n\\]\n\n\\(3 a-[b+(2 a-b)-(Q-b)]\\) \\[\n3 a-[b+2 a-b-a+b]-3 a-[a+b]=3 a-a-b-2 a-b\n\\] \\(3 \\frac{\\left(3 a a^2+a b-b^2\\right)\\left(a^2-2 a b-3 b^2\\right)}{a+b}=\\frac{\\left(3 a^2+a b-b^2\\right)(a-3 b)(a+b)}{(a+b)}=\\) \\(3 a^3+a^2 b-a b^2-9 a^2 b-3 a b^2+3 b^3=3 a^3-8 a^2 b-4 a b^2+3 b^3\\) \\(4 \\frac{x^6+a^2 x^3 y}{x^6-a^4 y^2}=\\frac{x^3\\left(x^3+a^2-y\\right)}{\\left(x^2+a^2+\\right)\\left(x^3+a^2-y\\right)}=\\frac{x^3}{x^3+a^2 y}\\)\n\n\\[\n\\begin{aligned}\n& {\\left[\\frac{a+b}{a-b}+\\frac{a-b}{a+b}\\right] \\div\\left[\\frac{a+b}{a-b}-\\frac{a-b}{a+b}\\right]=} \\\\\n& {\\left[\\frac{(a+b)^2+(a-b)^2}{(a-b)(a+b)}\\right] \\cdot\\left[\\frac{(a-b)(a+b)}{(a+b)^2-(a-b)^2}\\right]=} \\\\\n& \\frac{a^2+2 a b+b^2+a^2-2 a b+b^2}{a^2+2 a b+a^2-a^2+2 a b-b^2}=\\frac{2 a^2+2 b^2}{4 a b}=\\frac{a^2+b^2}{2 a b}\n\\end{aligned}\n\\]\n\n\\[\\begin{aligned}\n&\\begin{aligned}\n& 6 \\frac{3 x-4}{2}-\\frac{6 x-5}{8}=\\frac{3 x-1}{16} ; \\frac{8(3 x-4)}{8 \\cdot 2}-\\frac{2(6 x-5)}{2 \\cdot 8}=\\frac{3 x-1}{16} \\\\\n& 24-32-12 x+10=3 x-1 \\\\\n& 9 x=21 \\quad x=7 / 3\n\\end{aligned}\\\\\n\n&\\begin{aligned}\n& 2 x-5 y=24 \\\\\n& \\alpha=17 \\\\\n& 7(17)-5 y=24 \\\\\n& y=19 \\\\\n& 119-5 y=24:-5 y=-95: \\quad y=19 \\\\\n&\n\\end{aligned}\n\\end{aligned}\\]"
  },
  {
    "objectID": "math.html#기하",
    "href": "math.html#기하",
    "title": "chatGPT",
    "section": "\n3.4 기하",
    "text": "3.4 기하\n\nProve that the sum of the three angles of a plano triangle equals two right angles.\nProve that the diagonal of a parallelogram divides it into two equat triangles.\nProve that the area of a trapezoid is equal to the half sum of its parallel bases multiplied by its altitude.\nProve that the side of a regular hexagon inscribed in a circle is equal to its radius.\nThe radius of a circle equals 10 . Find its area.\nThe perpendicular dropped from the vertex of the right angle upon the hypothenuse divides it into two segments of 9 and 16 feet respectively. Find the lengths of the perpendicular, and the two legs of the triangle.\nDefine similar polygons. To what are their areas proportional?\n\n\n3.4.1 해답\nGeometry 1. Live triangle \\(A B C\\) construct a kine through \\(A\\) parallel to side \\(\\overline{B C}\\) angles \\(x, y\\) and a are formed at vertex \\(A\\) (1) The sum of all angles on one side of a line equal \\(180^{\\circ}\\) at a front; \\(y+a+y=180\\) A right angle contains \\(90^{\\circ}\\) \\(\\overline{A B}\\) and \\(\\overline{A C}\\) an transcuersals intersecting the two parallel hires: \\(\\overline{B C}\\) and line tromp \\(A\\) \\(\\angle A B C=\\angle x\\) and \\(\\angle A C B=\\angle y\\) because alternate interior angles of parallel hines are equal. (1) Since \\(x+a+y=180^{\\circ}\\) by subshticher \\(\\angle A B C+a+\\angle A C B=180^{\\circ}=\\) two rigitangles\n\nTwin parallelogram \\(A B C D\\) with diagonal \\(B D\\) \\(\\overline{A D} \\| \\overline{B C}\\) and \\(\\overline{A B} \\| \\overline{D C}\\) becanec oppose sides of a parallegran are parallel \\(\\angle x=\\angle d\\) and \\(\\angle b=\\angle y\\) because alternate interior angles formed by 2 parallel bice cat by a transversal are = \\(\\overline{B D}\\) is a side of both brixingles “is congunchat” Herfou, \\(\\triangle A B D \\cong \\triangle \\triangle D B\\) by the property If 2 angles of one triangle and the included vide are congruent to 2 angles and the included side of another brangle, the 2 triangles are Congruent (equal\nTrapezoid \\(A B C D\\) has basen of \\(b_1(\\overline{A B})+b_2(\\overline{D C})\\) and altude of \\(h\\). construnt a hine threr \\(C\\) parallel to side DA Eutend \\(\\overline{A B}\\) through, \\(B\\), trentersed the line chrough \\(C\\) at pout F AFCDis a parallelogram weth area \\(h b_2\\) and side \\(\\overline{D C}=\\overline{A F}\\) becamee appasite sedu f a perallebgeren are equd The alttiede of \\(\\triangle C B F=h\\) Areed \\(\\triangle C B F-\\frac{1}{2} \\overline{B F} \\cdot h\\) \\(\\widehat{B F}=\\overline{A F}-b_1=b_2-b_1 ;\\); lentictite \\(b_2-b_1\\) fo \\(\\overline{B F}\\) Aree of \\(\\triangle C B F=\\frac{1}{2}\\left(b_2-b_1\\right) \\cdot h\\) Area of trapegaid \\(A B C D=\\) Area of paullingram \\(A F C D\\)-aread \\(\\triangle C B F\\) \\(\\begin{aligned} & =b_2 \\cdot h \\quad-\\frac{1}{2}\\left(b_2-b_1\\right) h= \\\\ b_2 \\cdot h-\\frac{1}{2} b_2 h+\\frac{1}{2} b_1 h & =\\frac{1}{2} h\\left(b_1+b_2\\right) \\\\ \\therefore \\text { Area of trappoid = } & \\frac{1}{2} \\text { susan of paratled bacere meulhpths by itallehde }\\end{aligned}\\)"
  },
  {
    "objectID": "math.html#번-문제",
    "href": "math.html#번-문제",
    "title": "chatGPT",
    "section": "\n2.1 2번 문제",
    "text": "2.1 2번 문제\n\n함수 \\(f(x)=x^3+3 x^2+x-1\\) 에 대하여 \\(f^{\\prime}(1)\\) 의 값은?\n\n\n코드library(tidyverse)\nlibrary(openai)\n\nsolve_math_02 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. 함수 } f(x)=x^3+3 x^2+x-1 \\\\text { 에 대하여 } f^{\\\\prime}(1) \\\\text { 의 값은? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#> \n#> \n#> f'(1)은 미분을 통해 구할 수 있습니다.\n#> \n#> f'(x) = 3x^2 + 6x + 1\n#> \n#> f'(1) = 3(1)^2 + 6(1) + 1 = 10\n#> \n#> 따라서 f'(1) = 10이라는 결과가 나오게 됩니다. 이에 따르면 함수 f(x) = x^3 + 3x^2 + x - 1에 대하여 x가 1일 때의 미분값 f'(1)은 10이 됩니다."
  },
  {
    "objectID": "math.html#번-문제-1",
    "href": "math.html#번-문제-1",
    "title": "chatGPT",
    "section": "\n2.2 3번 문제",
    "text": "2.2 3번 문제\n\n등차수열 \\(\\left\\{a_n\\right\\}\\) 에 대하여 \\[\na_2=6, \\quad a_4+a_6=36\n\\] 일 때, \\(a_{10}\\) 의 값은?\n\n\n코드solve_math_03 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '등차수열 $\\left\\{a_n\\right\\}$ 에 대하여\n$$\na_2=6, \\quad a_4+a_6=36\n$$\n일 때, $a_{10}$ 의 값은?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\n등차수열의 정의에 따라 \\(a_n = a_1 + (n-1)d\\) 이므로, \\(a_1\\) 과 \\(d\\) 를 구해야 합니다.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]"
  },
  {
    "objectID": "math.html#ai-추론",
    "href": "math.html#ai-추론",
    "title": "chatGPT",
    "section": "\n3.2 AI 추론",
    "text": "3.2 AI 추론\n1번 문제\n\n\nBing AI\n\nSure! Let’s first convert the mixed numbers to improper fractions. \\(3 \\frac{5}{9}\\) is equal to \\(\\frac{32}{9}\\) and \\(1 \\frac{7}{24}\\) is equal to \\(\\frac{31}{24}\\).  Now we can find the sum: \\(\\frac{32}{9} + \\frac{31}{24} = \\frac{(32)(8) + (31)(3)}{(9)(8)} = \\frac{256 + 93}{72} = \\frac{349}{72}\\).  The difference is: \\(\\frac{32}{9} - \\frac{31}{24} = \\frac{(32)(8) - (31)(3)}{(9)(8)} = \\frac{256 - 93}{72} = \\frac{163}{72}\\).  The product is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{31}{24}\\right) = \\dfrac{(32)(31)}{(9)(24)} = \\dfrac{992}{216}\\).  To divide \\(3 \\frac{5}{9}\\) by \\(1 \\frac{7}{24}\\), we can multiply \\(3 \\frac{5}{9}\\) by the reciprocal of \\(1 \\frac{7}{24}\\). The reciprocal of \\(\\dfrac{31}{24}\\) is \\(\\dfrac{24}{31}\\).  So the quotient is: \\(\\left(\\dfrac{32}{9}\\right)\\left(\\dfrac{24}{31}\\right) = \\dfrac{(32)(24)}{(9)(31)} = \\dfrac{768}{279}\\).\n\n\n\n\nOpenAI\nLet’s first convert the mixed numbers into improper fractions: \\(3 \\frac{5}{9} = \\frac{3 \\times 9 + 5}{9} = \\frac{27 + 5}{9} = \\frac{32}{9}\\)\n\\(1 \\frac{7}{24} = \\frac{1 \\times 24 + 7}{24} = \\frac{24 + 7}{24} = \\frac{31}{24}\\)\nFind the sum, difference, product, and division of the two improper fractions: Sum:\n\\(\\frac{32}{9} + \\frac{31}{24} = \\frac{32 \\times 24}{9 \\times 24} + \\frac{31 \\times 9}{24 \\times 9} = \\frac{768}{216} + \\frac{279}{216} = \\frac{1047}{216}\\)\nDifference:\n\\(\\frac{32}{9} - \\frac{31}{24} = \\frac{32 \\times 24}{9 \\times 24} - \\frac{31 \\times 9}{24 \\times 9} = \\frac{768}{216} - \\frac{279}{216} = \\frac{489}{216}\\)\nProduct:\n\\(\\frac{32}{9} \\times \\frac{31}{24} = \\frac{32 \\times 31}{9 \\times 24} = \\frac{992}{216}\\)\nDivision:\n\\(\\frac{32}{9} \\div \\frac{31}{24} = \\frac{32}{9} \\times \\frac{24}{31} = \\frac{32 \\times 24}{9 \\times 31} = \\frac{768}{279}\\)\nThe corrected results are:\nSum: \\(\\frac{1047}{216}\\) Difference: \\(\\frac{489}{216}\\) Product: \\(\\frac{992}{216}\\) Division: \\(\\frac{768}{279}\\)\n\n\n\n2번 문제\n\n\nBing AI\nSure! To multiply 73 thousandths by 19 hundredths, you can convert them to decimals first. 73 thousandths is equivalent to 0.073 and 19 hundredths is equivalent to 0.19. Multiplying these two numbers gives us a result of 0.01387.\n\n\n\n\nOpenAI\nTo multiply decimals, first multiply the numbers as if they were whole numbers, and then count the total number of decimal places in both numbers.\n73 thousandths can be written as 0.073, and 19 hundredths can be written as 0.19.\nNow, multiply the numbers as if they were whole numbers:\n73 * 19 = 1387\nThere are a total of 5 decimal places in both numbers combined (3 decimal places in 0.073 and 2 decimal places in 0.19). So, we need to place the decimal point 5 places from the right in the product:\n0.001387\nTherefore, the product of 73 thousandths and 19 hundredths is 0.001387.\n\n\n\n3번 문제\n\n\nBing AI\nSure! Here’s a step-by-step guide on how to divide 2880 by 0.0036:\n\nWrite the problem as a long division problem: 2880 ÷ 0.0036\nMove the decimal point in the divisor (0.0036) to the right until it becomes a whole number (36). Move the decimal point in the dividend (2880) the same number of places to the right: 28800000 ÷ 36\nPerform long division to get a result of 800000.\n\n\n\n\nOpenAI\nTo divide 2880 by 0.0036, you can first divide both numbers by the same power of 10 to make the divisor a whole number. In this case, since the divisor has four decimal places, you can multiply both numbers by 10^4:\n2880 * 10^4 = 28800000 0.0036 * 10^4 = 36\nNow, divide 28800000 by 36:\n28800000 ÷ 36 = 800000\nSo, 2880 divided by 0.0036 is 800000.\n\n\n\n4번 문제\n\n\nBing AI\nSure! To find the value in decimals of \\(\\frac{1}{5}+\\frac{8}{4}\\), you can first convert the fractions to decimals. \\(\\frac{1}{5}\\) is equivalent to 0.2 and \\(\\frac{8}{4}\\) is equivalent to 2. Adding these two numbers gives us a result of 2.2.\n\n\n\n\nOpenAI\nFirst, let’s simplify each fraction and convert them to decimals:\n\\(\\frac{1}{5}\\) as a decimal is 0.2.\n\\(\\frac{8}{4}\\) can be simplified to \\(\\frac{2}{1}\\), which as a decimal is 2.\nNow, add the two decimal values:\n\\(0.2 + 2 = 2.2\\)\nSo, the value of \\(\\frac{1}{5}+\\frac{8}{4}\\) in decimals is 2.2.\n\n\n\n5번 문제\n\n\nBing AI\nI’m sorry but your question is a bit unclear. Could you please clarify what you mean by “what part of the month of August is \\(\\frac{7}{18}\\) minutes”? Are you asking for a specific date and time in August that corresponds to \\(\\frac{7}{18}\\) minutes?\n\n\n\n\nOpenAI\nTo determine what part of the month of August is \\(\\frac{7}{18}\\) minutes, we first need to know the total number of minutes in the month of August.\nAugust has 31 days, and each day has 24 hours with 60 minutes per hour. Therefore, there are:\n\\(31 \\times 24 \\times 60 = 44640\\) minutes in August.\nNow, we can find what part of the month of August is \\(\\frac{7}{18}\\) minutes by dividing \\(\\frac{7}{18}\\) by the total number of minutes:\n\\(\\frac{7}{18} \\div 44640 = \\frac{7}{18 \\times 44640}\\)\nNow, simplify the fraction:\n\\(\\frac{7}{802080}\\)\nSo, \\(\\frac{7}{18}\\) minutes is \\(\\frac{7}{802080}\\) of the month of August.\n\n\n\n6번 문제\n\n\nBing AI\nSure! A full circumference is equivalent to 360 degrees. To find the number of degrees in 0.01 of a circumference, you can multiply 360 by 0.01 to get a result of 3.6 degrees.\n\n\n\n\nOpenAI\nTo find out how many degrees are in 0.01 of a circumference, you need to consider that a full circumference corresponds to 360 degrees.\nTo find the number of degrees in 0.01 of a circumference, multiply 360 degrees by 0.01:\n360° × 0.01 = 3.6°\nSo, there are 3.6 degrees in 0.01 of a circumference.\n\n\n\n7번 문제\n\n\nBing AI\nSure! Let’s say the owner’s cost was \\(x\\). If they lost \\(3 \\frac{1}{2}\\) per cent on the sale, then their selling price was \\(100% - 3 \\frac{1}{2}% = 96.5%\\) of their cost. So we can write the equation: \\(0.965x = 5790\\). Solving for \\(x\\), we find that the owner’s cost was $ \\(5994.81\\).\n\n\n\n\nOpenAI\nTo find the original cost of the house and lot, we set up and solve the equation as follows:\nLet the cost of the house and lot be denoted by C. The owner lost \\(3\\frac{1}{2}%\\) on the sale, which means they sold it for \\(100% - 3\\frac{1}{2}%\\) of its original value. First, convert \\(3\\frac{1}{2}%\\) to a decimal:\n\\(3\\frac{1}{2}% = 3.5%\\)\nNow, subtract this percentage from \\(100%\\) to find the percentage of the cost at which the house was sold:\n\\(100% - 3.5% = 96.5%\\)\nNow, we know that \\(96.5%\\) of the cost is equal to the selling price, which is $\\(5,790\\). We can write this as an equation:\n$0.965C = \\(5,790\\)\nNow, we can find the cost (C) by dividing both sides of the equation by 0.965:\n$C = $\n$C \\(5,995.85\\)\nSo, the original cost of the house and lot was approximately $\\(5,995.85\\). In LaTeX format, the solution is as follows:\nLet the cost be denoted by \\(C\\). The equation representing the loss is: [0.965C = 5790]\nTo find the cost, divide both sides by 0.965: [C = ]\nTherefore, the original cost of the house and lot was approximately $5,995.85."
  },
  {
    "objectID": "math.html#번-문제-7",
    "href": "math.html#번-문제-7",
    "title": "chatGPT",
    "section": "\n4.1 2번 문제",
    "text": "4.1 2번 문제\n\n함수 \\(f(x)=x^3+3 x^2+x-1\\) 에 대하여 \\(f^{\\prime}(1)\\) 의 값은?\n\n\n\n\n\n\n\nGPT-3.5\nBing AI\nchatGPT GPT-4\nchatGPT 플러그인\n\n\n\n\n코드library(tidyverse)\nlibrary(openai)\n\nsolve_math_02 &lt;- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. 함수 } f(x)=x^3+3 x^2+x-1 \\\\text { 에 대하여 } f^{\\\\prime}(1) \\\\text { 의 값은? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPENAI_API_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#&gt; \n#&gt; \n#&gt; f'(1)은 함수 f(x)의 미분값이므로 \n#&gt; \n#&gt; f'(1) = 3x^2 + 6x + 1 = 8\n#&gt; \n#&gt; 따라서 f'(1)의 값은 8입니다. \n#&gt; \n#&gt; 그 이유는 함수 f'(x)는 x값에 따라 변하는 값이기 때문입니다. 그래서 x값이 1일 때 f'(1)의 값은 3·12 + 6·1 + 1 = 8 입니다.\n\n\n\n\nSure! The derivative of a function \\(f(x)\\) is denoted by \\(f’(x)\\) and represents the rate of change of the function at a given point. To find the value of \\(f’(1)\\) for the function \\(f(x)=x^3+3 x^2+x-1\\), we first need to find its derivative.\nThe derivative of \\(x^3\\) is \\(3x^2\\), the derivative of \\(3x^2\\) is \\(6x\\), and the derivative of \\(x\\) is 1. The derivative of a constant term like -1 is 0. So, the derivative of the function \\(f(x)=x^3+3 x^2+x-1\\) is:\n\\[f’(x) = 3x^2 + 6x + 1\\]\nTo find the value of \\(f’(1)\\), we can substitute x=1 into this equation:\n\\[f’(1) = 3(1)^2 + 6(1) + 1 = 10\\]\nSo, the value of \\(f’(1)\\) for the function \\(f(x)=x^3+3 x^2+x-1\\) is 10.\n\n\n함수 \\(f(x)=x^3+3x^2+x-1\\)의 도함수를 구하고, \\(x=1\\)일 때의 값을 구하겠습니다.\n\\(f(x)\\)의 도함수는 \\(f'(x)\\)로 표시되며, 각 항에 대한 미분을 적용합니다:\n\\(f'(x) = \\frac{d}{dx}(x^3) + \\frac{d}{dx}(3x^2) + \\frac{d}{dx}(x) - \\frac{d}{dx}(1)\\)\n각 항에 대한 미분 결과는 다음과 같습니다:\n\\(\\frac{d}{dx}(x^3) = 3x^2\\)\n\\(\\frac{d}{dx}(3x^2) = 6x\\)\n\\(\\frac{d}{dx}(x) = 1\\)\n\\(\\frac{d}{dx}(1) = 0\\)\n이제 도함수를 다음과 같이 작성할 수 있습니다:\n\\(f'(x) = 3x^2 + 6x + 1\\)\n이제 \\(f'(1)\\)을 구합니다:\n\\(f'(1) = 3(1)^2 + 6(1) + 1 = 3 + 6 + 1 = 10\\)\n따라서, \\(f^{\\prime}(1)\\)의 값은 10입니다.\n\n\n환영환각을 없앤 수학 엔진 울프램(Woolfram)을 사용해서 문제를 풀어보자\n함수 \\(f(x)=x^3+3 x^2+x-1\\) 의 도함수 \\(f^{\\prime}(x)\\) 를 구하면, \\(f^{\\prime}(x)=3 x^2+6 x+1\\) 이 됩니 다. 이제 \\(f^{\\prime}(1)\\) 의 값을 구하면 됩니다. Wolfram Alpha를 사용하여 이 계산을 수행하겠습니다. Used Wolfram 함수 \\(f^{\\prime}(x)=3 x^2+6 x+1\\) 에 \\(x=1\\) 을 대입하면, \\(f^{\\prime}(1)=10\\) 이 됩니다. 따라서, \\(f^{\\prime}(1)=10\\) 입니다. 이는 함수 \\(f(x)=x^3+3 x^2+x-1\\) 의 \\(x=1\\) 에서의 기울기를 나타냅니다.\n\\[\\begin{align*}\nf(x) &= x^3 + 3x^2 + x - 1 \\\\\nf'(x) &= \\frac{d}{dx}(x^3 + 3x^2 + x - 1) \\\\\n&= 3x^2 + 6x + 1 \\\\\nf'(1) &= 3(1)^2 + 6(1) + 1 \\\\\n&= 10\n\\end{align*}\\]"
  },
  {
    "objectID": "math.html#번-문제-8",
    "href": "math.html#번-문제-8",
    "title": "chatGPT",
    "section": "\n4.2 3번 문제",
    "text": "4.2 3번 문제\n\n등차수열 \\(\\left\\{a_n\\right\\}\\) 에 대하여 \\[\na_2=6, \\quad a_4+a_6=36\n\\] 일 때, \\(a_{10}\\) 의 값은?\n\n\n\n\n\n\n\nGPT-3.5\n빙 AI\nOpenAI GPT-4\nchatGPT 플러그인\n\n\n\n\n코드solve_math_03 &lt;- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '등차수열 $\\left\\{a_n\\right\\}$ 에 대하여 $$ a_2=6, \\quad a_4+a_6=36 $$ 일 때, $a_{10}$ 의 값은?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\n등차수열의 정의에 따라 \\(a_n = a_1 + (n-1)d\\) 이므로, \\(a_1\\) 과 \\(d\\) 를 구해야 합니다.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]\n\n\nSure! In an arithmetic sequence \\(a_n\\), the difference between consecutive terms is constant. Let’s denote this common difference by \\(d\\). Then we have:\n\\[a_3 = a_2 + d = 6 + d\\] \\[a_4 = a_3 + d = 6 + 2d\\] \\[a_5 = a_4 + d = 6 + 3d\\] \\[a_6 = a_5 + d = 6 + 4d\\]\nWe are given that \\(a_4+a_6=36\\), so substituting the expressions for \\(a_4\\) and \\(a_6\\) from above, we get:\n\\[(6+2d)+(6+4d)=36 \\Rightarrow 12+6d=36 \\Rightarrow d=4\\]\nNow that we know the common difference \\(d\\), we can find the value of \\(a_{10}\\):\n\\[a_{10} = a_{9}+d=a_{8}+2d=\\cdots=a_{2}+8d=6+8(4)=38\\]\nSo, the value of \\(a_{10}\\) for this arithmetic sequence is 38.\n\n\n등차수열 \\(a_n\\)에서 일반적인 항은 \\(a_n = a_1 + (n-1)d\\)로 표현됩니다. 여기서 \\(a_1\\)은 첫 번째 항이고 \\(d\\)는 공차입니다.\n문제에서 주어진 정보를 사용하여 두 개의 방정식을 작성할 수 있습니다:\n\\[a_2 = a_1 + (2-1)d = a_1 + d = 6\\] \\[a_4 + a_6 = (a_1 + 3d) + (a_1 + 5d) = 36\\]\n첫 번째 방정식에서 \\(d\\)에 대해 풀면 \\(d = 6 - a_1\\)입니다. 이것을 두 번째 방정식에 대입합니다:\n\\[(a_1 + 3(6 - a_1)) + (a_1 + 5(6 - a_1)) = 36\\]\n이제 \\(a_1\\)에 대해 풀면 됩니다:\n\\[2a_1 - 3a_1 + 18 - 5a_1 + 30 = 36\\] \\[-6a_1 = -12\\] \\[a_1 = 2\\]\n이제 \\(a_1 = 2\\)를 사용하여 공차 \\(d\\)를 찾습니다:\n\\[d = 6 - a_1 = 6 - 2 = 4\\]\n따라서 등차수열의 첫 번째 항은 \\(a_1 = 2\\)이고 공차는 \\(d = 4\\)입니다. 이제 \\(a_{10}\\)을 찾을 수 있습니다:\n\\[a_{10} = a_1 + (10-1)d = 2 + 9 \\times 4 = 2 + 36 = 38\\]\n따라서, \\(a_{10}\\)의 값은 38입니다.\n\n\n등차수열 \\(\\left\\{a_n\\right\\}\\) 에서, 일반적인 항은 다음과 같이 표현될 수 있습니다: \\(a_n=a_1+(n-1) d\\), 여기서 \\(d\\) 는 공차입니다.\n우리는 \\(a_2=6\\) 이라는 것을 알고 있습니다. 따라서, \\(a_2=a_1+d=6\\) 입니다.\n또한, \\(a_4+a_6=36\\) 이라는 것을 알고 있습니다. 이를 일반적인 항의 형태로 바꾸면, \\(a_1+\\) \\(3 d+a_1+5 d=36\\) 이 됩니다. 이를 정리하면, \\(2 a_1+8 d=36\\) 입니다.\n이제 두 개의 방정식을 풀어 \\(a_1\\) 과 \\(d\\) 를 찾을 수 있습니다. Wolfram Alpha를 사용하여 이 계산을 수행하겠습니다.\nUsed Wolfram\n위의 계산 결과에 따르면, \\(a_1=2\\) 그리고 \\(d=4\\) 입니다.\n이제 이 값을 사용하여 \\(a_{10}\\) 을 계산할 수 있습니다. 일반적인 항의 형태인 \\(a_n=a_1+(n-\\) 1) \\(d\\) 에 대입하면, \\(a_{10}=a_1+9 d\\) 입니다. Wolfram Alpha를 사용하여 이 계산을 수행하겠습니 다.\nUsed Wolfram\n따라서, \\(a_{10}=2+9 \\times 4=38\\) 입니다.\n즉, 주어진 등차수열 \\(\\left\\{a_n\\right\\}\\) 에서 \\(a_{10}\\) 의 값은 38 입니다."
  },
  {
    "objectID": "gpt4_performance.html",
    "href": "gpt4_performance.html",
    "title": "chatGPT",
    "section": "",
    "text": "arXiv GPT-4 Technical Report 보고서를 다운로드 받아 PDF 보고서에서 GPT-4 성능을 평가해보자. (OpenAI, 2023)\n\nPDF 문서를 Convert2Docx 패키지를 활용하여 워드파일로 변환시킨다. 페이지가 많아 제법 시간이 소요된다.\n\n코드library(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")\n\n\n\ndocxtractr 패키지를 설치하고 docx_extract_tbl() 함수로 PDF 파일에 담긴 표를 추출한다.\n\n코드library(docxtractr)\n\ngpt_docx &lt;- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 &lt;- docx_extract_tbl(gpt_docx, 3) %&gt;% \n    janitor::clean_names()\ntbl_01\n#&gt; # A tibble: 34 × 4\n#&gt;    exam                                           gpt_4  gpt_4_no_vision gpt_3_5\n#&gt;    &lt;chr&gt;                                          &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;  \n#&gt;  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 /… 298 / 400 (~90… 213 / …\n#&gt;  2 LSAT                                           163 (… 161 (~83rd)     149 (~…\n#&gt;  3 SAT Evidence-Based Reading & Writing           710 /… 710 / 800 (~93… 670 / …\n#&gt;  4 SAT Math                                       700 /… 690 / 800 (~89… 590 / …\n#&gt;  5 Graduate Record Examination (GRE) Quantitative 163 /… 157 / 170 (~62… 147 / …\n#&gt;  6 Graduate Record Examination (GRE) Verbal       169 /… 165 / 170 (~96… 154 / …\n#&gt;  7 Graduate Record Examination (GRE) Writing      4 / 6… 4 / 6 (~54th)   4 / 6 …\n#&gt;  8 USABO Semifinal Exam 2020                      87 / … 87 / 150 (99th… 43 / 1…\n#&gt;  9 USNCO Local Section Exam 2022                  36 / … 38 / 60         24 / 60\n#&gt; 10 Medical Knowledge Self-Assessment Program      75 %   75 %            53 %   \n#&gt; # ℹ 24 more rows"
  },
  {
    "objectID": "gpt4_performance.html#pdf-워드",
    "href": "gpt4_performance.html#pdf-워드",
    "title": "chatGPT",
    "section": "",
    "text": "PDF 문서를 Convert2Docx 패키지를 활용하여 워드파일로 변환시킨다. 페이지가 많아 제법 시간이 소요된다.\n\n코드library(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")"
  },
  {
    "objectID": "gpt4_performance.html#워드-표추출",
    "href": "gpt4_performance.html#워드-표추출",
    "title": "chatGPT",
    "section": "",
    "text": "docxtractr 패키지를 설치하고 docx_extract_tbl() 함수로 PDF 파일에 담긴 표를 추출한다.\n\n코드library(docxtractr)\n\ngpt_docx &lt;- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 &lt;- docx_extract_tbl(gpt_docx, 3) %&gt;% \n    janitor::clean_names()\ntbl_01\n#&gt; # A tibble: 34 × 4\n#&gt;    exam                                           gpt_4  gpt_4_no_vision gpt_3_5\n#&gt;    &lt;chr&gt;                                          &lt;chr&gt;  &lt;chr&gt;           &lt;chr&gt;  \n#&gt;  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 /… 298 / 400 (~90… 213 / …\n#&gt;  2 LSAT                                           163 (… 161 (~83rd)     149 (~…\n#&gt;  3 SAT Evidence-Based Reading & Writing           710 /… 710 / 800 (~93… 670 / …\n#&gt;  4 SAT Math                                       700 /… 690 / 800 (~89… 590 / …\n#&gt;  5 Graduate Record Examination (GRE) Quantitative 163 /… 157 / 170 (~62… 147 / …\n#&gt;  6 Graduate Record Examination (GRE) Verbal       169 /… 165 / 170 (~96… 154 / …\n#&gt;  7 Graduate Record Examination (GRE) Writing      4 / 6… 4 / 6 (~54th)   4 / 6 …\n#&gt;  8 USABO Semifinal Exam 2020                      87 / … 87 / 150 (99th… 43 / 1…\n#&gt;  9 USNCO Local Section Exam 2022                  36 / … 38 / 60         24 / 60\n#&gt; 10 Medical Knowledge Self-Assessment Program      75 %   75 %            53 %   \n#&gt; # ℹ 24 more rows"
  },
  {
    "objectID": "calculator.html",
    "href": "calculator.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 CLI 계산기\nchatGPT에 지시명령어로 계산기 프로그램을 파이썬 언어로 작성하라는 하명을 내린다. 계산기를 동작시키는 방식도 알려달라는 하명도 이어서 내린다.\n\n\n지시명령어\n소스코드\n→\n실행 지시명령어\n실행 사례\n\n\n\n\n\n\n\n\n\nwrite python code of calculator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n코드# Simple calculator program\n\n# Function to add two numbers\ndef add(x, y):\n    return x + y\n\n# Function to subtract two numbers\ndef subtract(x, y):\n    return x - y\n\n# Function to multiply two numbers\ndef multiply(x, y):\n    return x * y\n\n# Function to divide two numbers\ndef divide(x, y):\n    return x / y\n\n# Display menu\nprint(\"Select operation.\")\nprint(\"1. Add\")\nprint(\"2. Subtract\")\nprint(\"3. Multiply\")\nprint(\"4. Divide\")\n\n# Take input from the user\nchoice = input(\"Enter choice (1/2/3/4): \")\n\nnum1 = float(input(\"Enter first number: \"))\nnum2 = float(input(\"Enter second number: \"))\n\n# Perform operation based on user's choice\nif choice == '1':\n    print(num1, \"+\", num2, \"=\", add(num1, num2))\n\nelif choice == '2':\n    print(num1, \"-\", num2, \"=\", subtract(num1, num2))\n\nelif choice == '3':\n    print(num1, \"*\", num2, \"=\", multiply(num1, num2))\n\nelif choice == '4':\n    print(num1, \"/\", num2, \"=\", divide(num1, num2))\n\nelse:\n    print(\"Invalid input\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nhow to run this python code\n\n\n\n\n\nPython 코드를 실행하려면 시스템에 Python이 설치되어 있어야 합니다. 다음 단계에 따라 간단한 계산기를 위한 Python 코드를 실행할 수 있습니다:\n\n메모장이나 서브라인 텍스트와 같은 텍스트 편집기를 열고 Python 코드를 새 파일에 붙여넣습니다.\n파일 확장명을 .py로 지정하여 저장합니다(예: calculator.py).\n터미널 또는 명령 프롬프트 창을 엽니다.\n\ncd 명령을 사용하여 파일이 저장된 디렉토리로 이동합니다(예: cd Documents\\Python).\n\npython calculator.py를 입력하고 Enter 키를 눌러 프로그램을 실행합니다.\n\n그러면 프로그램이 실행되고 메뉴가 표시되며 사용자에게 원하는 연산과 숫자 두 개를 입력하라는 메시지가 표시됩니다. 사용자가 필요한 입력을 입력하면 프로그램이 해당 산술 연산을 수행하고 결과를 표시합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n코드xfun::embed_file(\"code/calculator.py\", text = \"계산기 소스코드 다운로드\")\n\n계산기 소스코드 다운로드\n\n\n\n2 GUI 계산기\n이번에는 계산기에 GUI를 입혀 사용자가 좀더 쉽게 사용할 수 있도록 한다. 다양한 GUI 패키지가 있지만 그중에서 tkinter 패키지 하나를 선정하여 개발을 이어나간다. chatGPT에 지시명령어로 계산기 프로그램을 파이썬 언어로 작성하라는 하명을 내린다. 계산기를 동작시키는 방식도 알려달라는 하명도 이어서 내린다.\n\n\n지시명령어\n소스코드\n→\n실행 지시명령어\n실행 사례\n\n\n\n\n\n\n\n\n\nplease add gui with tkinter\n\n\n\n\n\nSure, here is an example of the same calculator program using the Tkinter library to create a graphical user interface (GUI):\n…\nIn this code, we first import the Tkinter library using the alias tk. Then we define four functions add(), subtract(), multiply(), and divide() that perform the corresponding arithmetic operations on the numbers entered by the user. Each function retrieves the input values from the Entry widgets using the get() method, performs the arithmetic operation, and updates the text of the Label widget to display the result.\nWe then create the main window using the Tk() constructor and set its title using the title() method. Next, we create two Label widgets and two Entry widgets to allow the user to enter the two numbers.\nWe also create four Button widgets, one for each arithmetic operation, and set their text and width. The command parameter is used to specify the function that should be called when the button is clicked.\nFinally, we create a Label widget to display the result of the arithmetic operation, and call the mainloop() method to start the event loop and display the GUI.\n\n\n\n\n\n\n코드import tkinter as tk\n\n# Function to perform addition\ndef add():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 + num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform subtraction\ndef subtract():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 - num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform multiplication\ndef multiply():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 * num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n\n# Function to perform division\ndef divide():\n    try:\n        num1 = float(entry_num1.get())\n        num2 = float(entry_num2.get())\n        result = num1 / num2\n        label_result.config(text=\"Result: \" + str(result))\n    except ValueError:\n        label_result.config(text=\"Invalid input\")\n    except ZeroDivisionError:\n        label_result.config(text=\"Cannot divide by zero\")\n\n# Create the main window\nwindow = tk.Tk()\nwindow.title(\"Simple Calculator\")\n\n# Create the number input fields\nlabel_num1 = tk.Label(window, text=\"Number 1:\")\nlabel_num1.pack()\nentry_num1 = tk.Entry(window)\nentry_num1.pack()\n\nlabel_num2 = tk.Label(window, text=\"Number 2:\")\nlabel_num2.pack()\nentry_num2 = tk.Entry(window)\nentry_num2.pack()\n\n# Create the operation buttons\nbutton_add = tk.Button(window, text=\"+\", width=10, command=add)\nbutton_add.pack()\n\nbutton_subtract = tk.Button(window, text=\"-\", width=10, command=subtract)\nbutton_subtract.pack()\n\nbutton_multiply = tk.Button(window, text=\"*\", width=10, command=multiply)\nbutton_multiply.pack()\n\nbutton_divide = tk.Button(window, text=\"/\", width=10, command=divide)\nbutton_divide.pack()\n\n# Create the result label\nlabel_result = tk.Label(window, text=\"Result: \")\nlabel_result.pack()\n\n# Run the main loop\nwindow.mainloop()\n\n\n\n\n\n\n\n\n\n\n\n\n\nhow to run this python code\n\n\n\n\n\nPython 코드를 실행하려면 시스템에 Python이 설치되어 있어야 합니다. 다음 단계에 따라 간단한 계산기를 위한 Python 코드를 실행할 수 있습니다:\n\n메모장이나 서브라인 텍스트와 같은 텍스트 편집기를 열고 Python 코드를 새 파일에 붙여넣습니다.\n파일 확장명을 .py로 지정하여 저장합니다(예: calculator.py).\n터미널 또는 명령 프롬프트 창을 엽니다.\n\ncd 명령을 사용하여 파일이 저장된 디렉토리로 이동합니다(예: cd Documents\\Python).\n\npython calculator.py를 입력하고 Enter 키를 눌러 프로그램을 실행합니다.\n\n그러면 프로그램이 실행되고 메뉴가 표시되며 사용자에게 원하는 연산과 숫자 두 개를 입력하라는 메시지가 표시됩니다. 사용자가 필요한 입력을 입력하면 프로그램이 해당 산술 연산을 수행하고 결과를 표시합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n코드xfun::embed_file(\"code/calculator_gui.py\", text = \"계산기 소스코드 GUI 버전 다운로드\")\n\n계산기 소스코드 GUI 버전 다운로드\n\n\n\n3 테스트\n계산기 프로그램이 정상동작하는지 확인하는 코드를 작성하자. 만약 단위 테스트 결과가 모두 정상동작한다면 믿고 현업에서 사용하게 된다.\n\n\n지시명령어\n실행결과\n\n\n\n\n\n\n\n\n\nfirst write python program for calculator and then test result from execution\n\n\n\n\n\nHere’s the Python code for a simple calculator that supports addition, subtraction, multiplication, and division. We’ll create a separate file for the test cases, which will import and run the calculator functions.\nSave the following code as calculator.py:\nclass Calculator:\n    def add(self, a, b):\n        return a + b\n\n    def subtract(self, a, b):\n        return a - b\n\n    def multiply(self, a, b):\n        return a * b\n\n    def divide(self, a, b):\n        if b == 0:\n            raise ValueError(\"Cannot divide by zero\")\n        return a / b\nNow, create a new file named test_calculator.py and save the following code in it:\nfrom calculator import Calculator\n\ndef test_calculator():\n    calc = Calculator()\n\n    # Test addition\n    assert calc.add(2, 3) == 5, \"Test case 1 failed\"\n    assert calc.add(-2, 3) == 1, \"Test case 2 failed\"\n\n    # Test subtraction\n    assert calc.subtract(5, 3) == 2, \"Test case 3 failed\"\n    assert calc.subtract(0, -5) == 5, \"Test case 4 failed\"\n\n    # Test multiplication\n    assert calc.multiply(3, 4) == 12, \"Test case 5 failed\"\n    assert calc.multiply(-2, 5) == -10, \"Test case 6 failed\"\n\n    # Test division\n    assert calc.divide(10, 2) == 5, \"Test case 7 failed\"\n    assert calc.divide(-10, 5) == -2, \"Test case 8 failed\"\n\n    # Test division by zero\n    try:\n        calc.divide(10, 0)\n    except ValueError as e:\n        assert str(e) == \"Cannot divide by zero\", \"Test case 9 failed\"\n\n    print(\"All test cases passed\")\n\nif __name__ == \"__main__\":\n    test_calculator()\nTo execute the test cases, open a terminal or command prompt and navigate to the directory containing both calculator.py and test_calculator.py. Then run the following command:\npython test_calculator.py\nIf all test cases pass, you’ll see “All test cases passed” printed on the console.\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 .exe 배포\nCLI를 통해 기능을 검증한 후 GUI로 사용자가 사용하기 쉬운 인터페이스를 구현하였다면 다음 단계로 배포를 한다. 다양한 배포 프로그램이 존재하지만 가장 쉽게 .exe 파일을 만드는 방법을 살펴보자.\n\n\n지시명령어\n실행결과\n파이썬 코드\n.spec 파일\n디렉토리 구조\n\n\n\n\n\n\n\n\n\nI am a pyhton developer. I have a simple python calculator. I’d like to deploy this program into Windows. let me know how to create a standalone executable file\n\n\n\n\n\nTo create a standalone executable file for your Python calculator, you can use a tool like PyInstaller or cx_Freeze. Here are the general steps to follow:\nInstall PyInstaller: You can use pip to install PyInstaller. Open a command prompt or terminal and run the following command:\npip install pyinstaller\nCreate a spec file: PyInstaller requires a spec file that describes your Python program and its dependencies. To create a spec file with PyInstaller, run the following command:\npyinstaller --name=calculator --onefile calculator.py\nBuild the executable: To build the executable file with PyInstaller, run the following command:\npyinstaller calculator.spec\nThis will create a standalone executable file in the dist directory. Test the executable file: Run the executable file on a Windows machine to make sure it works as expected.\nBy following these steps, you can create a standalone executable file for your Python calculator using PyInstaller.\n\n\n\n\n\n\n\n\n\n\n\n\n코드import tkinter as tk\n\nclass Calculator:\n    def __init__(self, master):\n        self.master = master\n        self.master.title(\"Calculator\")\n\n        # Create display\n        self.display = tk.Entry(self.master, width=30, borderwidth=5, justify=tk.RIGHT)\n        self.display.grid(row=0, column=0, columnspan=4, padx=10, pady=10)\n\n        # Define buttons\n        button_list = [\"7\", \"8\", \"9\", \"/\", \"4\", \"5\", \"6\", \"*\", \"1\", \"2\", \"3\", \"-\", \"0\", \".\", \"C\", \"+\"]\n\n        # Create buttons\n        row = 1\n        col = 0\n        for button in button_list:\n            command = lambda x=button: self.button_click(x)\n            tk.Button(self.master, text=button, padx=20, pady=10, command=command).grid(row=row, column=col)\n            col += 1\n            if col > 3:\n                row += 1\n                col = 0\n\n        # Create equals button\n        tk.Button(self.master, text=\"=\", padx=50, pady=10, command=self.calculate).grid(row=row, column=0, columnspan=4)\n\n    def button_click(self, button):\n        if button == \"C\":\n            self.display.delete(0, tk.END)\n        else:\n            self.display.insert(tk.END, button)\n\n    def calculate(self):\n        try:\n            result = eval(self.display.get())\n            self.display.delete(0, tk.END)\n            self.display.insert(0, result)\n        except:\n            self.display.delete(0, tk.END)\n            self.display.insert(0, \"Error\")\n\n# Create window\nroot = tk.Tk()\n\n# Create calculator\ncalculator = Calculator(root)\n\n# Run window\nroot.mainloop()\n\n\n\n\n\n코드# -*- mode: python ; coding: utf-8 -*-\n\nblock_cipher = None\n\n\na = Analysis(\n    ['calculator.py'],\n    pathex=[],\n    binaries=[],\n    datas=[],\n    hiddenimports=[],\n    hookspath=[],\n    hooksconfig={},\n    runtime_hooks=[],\n    excludes=[],\n    win_no_prefer_redirects=False,\n    win_private_assemblies=False,\n    cipher=block_cipher,\n    noarchive=False,\n)\npyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)\n\nexe = EXE(\n    pyz,\n    a.scripts,\n    a.binaries,\n    a.zipfiles,\n    a.datas,\n    [],\n    name='calculator',\n    debug=False,\n    bootloader_ignore_signals=False,\n    strip=False,\n    upx=True,\n    upx_exclude=[],\n    runtime_tmpdir=None,\n    console=True,\n    disable_windowed_traceback=False,\n    argv_emulation=False,\n    target_arch=None,\n    codesign_identity=None,\n    entitlements_file=None,\n)\n\n\n\n\n\n코드fs::dir_tree('code/calculator_exe/')\n#> code/calculator_exe/\n#> ├── build\n#> │   └── calculator\n#> │       ├── Analysis-00.toc\n#> │       ├── base_library.zip\n#> │       ├── calculator.exe.manifest\n#> │       ├── calculator.pkg\n#> │       ├── EXE-00.toc\n#> │       ├── localpycs\n#> │       │   ├── pyimod01_archive.pyc\n#> │       │   ├── pyimod02_importers.pyc\n#> │       │   ├── pyimod03_ctypes.pyc\n#> │       │   ├── pyimod04_pywin32.pyc\n#> │       │   └── struct.pyc\n#> │       ├── PKG-00.toc\n#> │       ├── PYZ-00.pyz\n#> │       ├── PYZ-00.toc\n#> │       ├── Tree-00.toc\n#> │       ├── Tree-01.toc\n#> │       ├── Tree-02.toc\n#> │       ├── warn-calculator.txt\n#> │       └── xref-calculator.html\n#> ├── calculator.py\n#> ├── calculator.spec\n#> └── dist\n#>     └── calculator.exe"
  },
  {
    "objectID": "calculator.html#pdf-워드",
    "href": "calculator.html#pdf-워드",
    "title": "chatGPT",
    "section": "\n1.1 PDF → 워드",
    "text": "1.1 PDF → 워드\nPDF 문서를 Convert2Docx 패키지를 활용하여 워드파일로 변환시킨다. 페이지가 많아 제법 시간이 소요된다.\n\n코드library(Convert2Docx)\nConverter(pdf_file = \"data/2303.08774.pdf\",\n          docx_filename = \"data/2303.08774.docx\")"
  },
  {
    "objectID": "calculator.html#워드-표추출",
    "href": "calculator.html#워드-표추출",
    "title": "chatGPT",
    "section": "\n1.2 워드 → 표추출",
    "text": "1.2 워드 → 표추출\ndocxtractr 패키지를 설치하고 docx_extract_tbl() 함수로 PDF 파일에 담긴 표를 추출한다.\n\n코드library(docxtractr)\n\ngpt_docx <- docxtractr::read_docx(\"data/2303.08774.docx\")\n\ntbl_01 <- docx_extract_tbl(gpt_docx, 3) %>% \n    janitor::clean_names()\ntbl_01\n#> # A tibble: 34 × 4\n#>    exam                                           gpt_4          gpt_4…¹ gpt_3_5\n#>    <chr>                                          <chr>          <chr>   <chr>  \n#>  1 Uniform Bar Exam (MBE+MEE+MPT)                 298 / 400 (~9… 298 / … 213 / …\n#>  2 LSAT                                           163 (~88th)    161 (~… 149 (~…\n#>  3 SAT Evidence-Based Reading & Writing           710 / 800 (~9… 710 / … 670 / …\n#>  4 SAT Math                                       700 / 800 (~8… 690 / … 590 / …\n#>  5 Graduate Record Examination (GRE) Quantitative 163 / 170 (~8… 157 / … 147 / …\n#>  6 Graduate Record Examination (GRE) Verbal       169 / 170 (~9… 165 / … 154 / …\n#>  7 Graduate Record Examination (GRE) Writing      4 / 6 (~54th)  4 / 6 … 4 / 6 …\n#>  8 USABO Semifinal Exam 2020                      87 / 150 (99t… 87 / 1… 43 / 1…\n#>  9 USNCO Local Section Exam 2022                  36 / 60        38 / 60 24 / 60\n#> 10 Medical Knowledge Self-Assessment Program      75 %           75 %    53 %   \n#> # … with 24 more rows, and abbreviated variable name ¹​gpt_4_no_vision"
  },
  {
    "objectID": "interface.html#웹검색",
    "href": "interface.html#웹검색",
    "title": "chatGPT",
    "section": "\n2.1 웹검색",
    "text": "2.1 웹검색\n구글 검색을 통해 일반적인 내용을 얻을 수도 있다. 예를 들어,\n\nsite:quarto.org/ google analytics tracking code\n\n구글검색창에 상기 사항을 입력하게 되면 구글은 쿼토(quarto) 웹사이트 내부에서 google analytics tracking code 키워드와 관련이 높은 웹페이지를 검색결과로 반환시키게 된다."
  },
  {
    "objectID": "interface.html#쿼토-웹-검색",
    "href": "interface.html#쿼토-웹-검색",
    "title": "chatGPT",
    "section": "\n2.2 쿼토 웹 검색",
    "text": "2.2 쿼토 웹 검색\nQuarto는 웹사이트와 책의 전체 텍스트 검색을 지원하는데, 기본적으로 Quarto는 사이트의 콘텐츠를 자동으로 색인화하여 기본적으로 로컬로 구축된 색인을 사용하여 높은 검색품질을 제공한다. 따라서, 사용자는 구글웹사이트가 아니라 쿼토(quarto)에서 검색을 수행하여 직접 해당 정보를 찾는 것도 가능하다."
  },
  {
    "objectID": "interface.html#chatgpt-검색",
    "href": "interface.html#chatgpt-검색",
    "title": "chatGPT",
    "section": "\n2.3 chatGPT 검색",
    "text": "2.3 chatGPT 검색\nChatGPT를 사용하여 검색작업을 수행할 수도 있다. 특정 웹사이트에서 해당 정보를 얻어야 되기 때문에 지시명령어(Prompt)를 다음과 같이 작성한다.\n\nsearch https://quarto.org/ insert google analytics tracking code for quarto html document"
  },
  {
    "objectID": "interface.html#quarto-전용-chatgpt",
    "href": "interface.html#quarto-전용-chatgpt",
    "title": "chatGPT",
    "section": "\n2.4 Quarto 전용 chatGPT\n",
    "text": "2.4 Quarto 전용 chatGPT\n\n쿼토(Quarto)는 차세대 R마크다운이라는 별명이 붙어 있을 정도로 R마크다운이 갖는 모든 기능에 더하여 추가로 새로운 언어(Python, R, Julia, Observable.)에 대한 지원도 포괄하고 있어 상당한 학습량을 요구한다. 설계는 깔끔하게 잘 되어 있지만 이것을 잘 사용하려면 상당한 학습량이 필요로 한다. 이런 문제에 chatGPT를 도입하여 사용하면 경우에 따라서 큰 도움을 줄 수도 있다.\n\nQuarto Help Bot - Ask a question about Quarto.\n\n\n\n\n\n:::\n내부적으로 동작하는 질문-응답(QnA)에는 다음과 같은 단계로 세분화되어 있으며, 모두 ChatVectorDBChain이 처리한다:\n\n채팅 기록과 새로운 사용자 입력이 주어지면 독립형 질문이 무엇인지 결정(GPT-3 사용).\n독립형 질문이 주어지면 벡터 스토어에서 관련 문서를 검색.\n독립형 질문과 관련 문서를 GPT-3에 전달하여 최종 답변을 생성."
  },
  {
    "objectID": "interface.html#카톡-아숙업",
    "href": "interface.html#카톡-아숙업",
    "title": "chatGPT",
    "section": "\n4.1 카톡: 아숙업",
    "text": "4.1 카톡: 아숙업\n업스테이지에서 개발한 ‘아숙업’ 서비스는 모바일 메신져 카카오톡에 AskUp 채널을 추가하게 되면 chatGPT 유사 기능을 사용할 수 있다. 문제는 언제 AskUp 채널 서비스가 중단될지 유료로 과금이 변경될지 모르지만 chatGPT를 사용하는 방식이 다양화함은 분명하다.\nAskUp 서비스는 현재 시점(“2023-03-10”) 기준 PDF 문서요약기능은 제공하고 있지 않지만 장문의 텍스트는 요약하는 기능을 제공하고 있다.\n\n\naskup 검색\n채널추가\n채팅준비\nOCR 사례\n뉴스 요약"
  },
  {
    "objectID": "interface.html#카톡-다다음",
    "href": "interface.html#카톡-다다음",
    "title": "chatGPT",
    "section": "\n4.2 카톡: 다다음",
    "text": "4.2 카톡: 다다음\n카카오브레인, AI챗봇 ‘다다음’(dmm) 베타 출시 하루 만에 중단\n카카오브레인이 카카오톡으로 쓸 수 있는 인공지능(AI) 챗봇 ‘다다음’(ddmm) 베타 서비스를 19일 출시했지만 황급히 서비스를 내렸다. 다다음은 카카오브레인이 개발한 거대 언어 AI 모델 (LLM) ’코GPT’와 ’칼로’를 파운데이션 모델로 삼아 개발한 생성형 AI 채팅 서비스다. 정보검색, 요약, 번역은 물론 이미지 생성도 지원했다."
  },
  {
    "objectID": "langchain.html",
    "href": "langchain.html",
    "title": "chatGPT",
    "section": "",
    "text": "LangChain 에서 OpenAI chatGPT를 호출하여 원하는 작업을 수행한다. 먼저 openai와 langchain을 설치한다.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEY를 환경변수를 넣어두고 OpenAI() 함수에서 호출하여 사용할 수 있도록 한다.\n\nimport os\nfrom langchain.llms import OpenAI\n\n# os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "langchain.html#영문",
    "href": "langchain.html#영문",
    "title": "chatGPT",
    "section": "\n3.1 영문",
    "text": "3.1 영문\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nprompt.format(product=\"colorful socks\")\n#&gt; '\\nI want you to act as a naming consultant for new companies.\\n\\nHere are some examples of good company names:\\n\\n- search engine, Google\\n- social media, Facebook\\n- video sharing, YouTube\\n\\nThe name should be short, catchy and easy to remember.\\n\\nWhat is a good name for a company that makes colorful socks?\\n'\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; FunSox."
  },
  {
    "objectID": "langchain.html#국문",
    "href": "langchain.html#국문",
    "title": "chatGPT",
    "section": "\n3.2 국문",
    "text": "3.2 국문\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_prompt.format(k_product=\"양말\")\n#&gt; '\\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\\n\\n다음은 좋은 회사 이름 몇 가지 사례입니다:\\n\\n- 케이티, 통신\\n- 놀부, 외식프랜차이즈\\n- 율도국, 브랜드제작\\n- 크몽, 아웃소싱 플랫폼\\n\\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\\n\\n양말 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\\n'\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nprint(k_chain.run(\"양말\"))\n#&gt; \n#&gt; - 솔랩, 양말 제품\n#&gt; - 메디솔, 신발과 양말\n#&gt; - 루프로, 양말 디자인\n#&gt; - 브이슬립, 양말"
  },
  {
    "objectID": "openAI_GPT.html",
    "href": "openAI_GPT.html",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPT는 간단히 말해 생성형 사전 학습된 트랜스포머(Generative Pre-trained Transformer)의 약자로, OpenAI의 GPT-3/GPT-4 거대 언어 모델 제품군에 기반한 챗봇으로 지도학습과 강화학습기법을 적용하여 미세조정(fine-tuned)된 제품이자 서비스다.\n\nGPT-4’s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4는 GPT-3보다 10배 많은 1조 8천억 개의 파라미터, 120개 계층을 갖는 아키텍쳐를 갖고 있다. OpenAI는 16개 전문가(MoE, Mixture of Experts)와 1,100억 개의 다층 퍼셉트론 파라미터를 갖는 전문가 혼합 모델로 구현되었으며, 13조 개의 토큰이 포함된 학습 데이터셋을 사용했다. 훈련 비용은 3,200 ~ 6,300만 달러로 GPT-4는 이전 버전보다 추론 비용이 약 3배 더 높지만, 분산 데이터센터에서 128개 GPU 클러스터 위에서 동작하는 추론 아키텍쳐를 갖고 있다.\n\n\nThe Ship of Theseus\n\nOpenAI의 전략은 테세우스의 배(Theseus’s Ship) 와 유사하다고 볼 수 있다.\n\nOpenAI GPT-3 모형은 크게 세가지가 있다.\n\nGPT-3/GPT-4\nCodex\n콘텐츠 필터 모델\n\nGPT-3은 자연어 처리 및 생성을 담당하는 모델로 인간의 언어 즉, 자연어처럼 보이는 텍스트를 이해할 수 있다. 한걸음 더 들어가면 속도와 성능에 따라 4가지 모델(A, B, C, D)로 구분된다.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\n성능기준으로 보면 다음과 같이 정렬할 수 있는데 비용도 그에 따라 높아진다는 의미도 함축한다.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\n따라서, OpenAI는 다빈치 모델(text-davinci-003)을 통해 원하는 결과를 얻은 후에 다른 모델을 사용해 볼 것을 권장하는데 이유는 훨씬 저렴한 비용으로 많은 수의 유사한 작업을 수행할 수 있기 때문이다.\n\n2,048개의 토큰 및 2019년 10월까지의 데이터 학습하여 이후 모형과 비교하여 정확도나 성능에서 다소 밀리는 모습이지만 최적화를 통해 매우 빠르고 비용이 가장 저렴하다.\n\n2,048개의 토큰과 2019년 10월까지의 데이터 학습되었고 간단한 분류와 의미론적 분류에 효과적이다.\n\n최대 2048개의 토큰을 지원하며 text-davinci-003 다음으로 뛰어난 성능을 보이는 GPT-3 모델이다. 2019년 10월까지의 데이터로 학습되었기 때문에 text-davinci-003보다 정확도가 떨어지지만, 번역, 복잡한 분류, 텍스트 분석 및 요약에 좋은 성능을 보이고 있어 text-davinci-003와 비교하여 가성비가 높다고 평가되고 있다.\n\n2021년 9월까지의 데이터로 훈련되었기 때문에 최신 정보를 제공하지 못한다는 한계는 있지만, 앞선 GPT-3 모형과 비교하여 더 높은 품질을 제공한다. 장점 중 하나는 최대 4,000개 토큰까지 요청할 수 있다는 점이 이전 모형과 큰 차별점이 된다.\n\n코덱스는 프로그래밍 코드 이해 및 생성을 위한 것으로 code-davinci-002와 code-cushman-001가 있다. 또한, 코덱스는 GitHub Copilot을 구동하는 모델이기도 하다. 파이썬, 자바스크립트, 고, 펄, PHP, 루비, 스위프트, 타입스크립트, SQL, 셸 등 12개 이상의 프로그래밍 언어를 지원할 뿐만 아니라 자연어로 표현된 주석(comment)를 이해하고 사용자를 대신하여 요청된 작업을 수행할 수 있다.\n\n복잡한 작업을 수행하는 데 있어서는 code-davinci-002가 더 강력하지만, 많은 코드 생성 작업을 수행할 수 있고 code-davinci-002 보다 더 빠르고 저렴하다는 장점이 있다.\n\n자연어를 코드로 번역하는 데 탁월할 뿐만 아니라 코드를 자동 완성할 뿐만 아니라 보충 요소 삽입도 지원한다. 최대 8,000개의 토큰을 처리할 수 있으며 2021년 6월까지의 데이터로 학습되었다.\n\n민감한 콘텐츠 제거하기 위한 필터 모형이다. 민감하거나 안전하지 않을 수 있는 API 생성 텍스트를 감지할 수 있다. 사용자가 사용할 AI 응용프로그램을 개발할 경우, 필터를 사용하여 모델이 부적절한 콘텐츠를 반환하는지 감지할 수 있다. 이 필터는 텍스트를 다음 3가지 범주로 나눈다.\n\n안전(safe)\n민감(sensitive)\n안전하지 않음(unsafe)"
  },
  {
    "objectID": "prompt.html",
    "href": "prompt.html",
    "title": "chatGPT",
    "section": "",
    "text": "The hottest new programming language is English\n\n— Andrej Karpathy ((karpathy?)) January 24, 2023"
  },
  {
    "objectID": "prompt.html#식물-광합성",
    "href": "prompt.html#식물-광합성",
    "title": "chatGPT",
    "section": "\n3.1 식물 광합성",
    "text": "3.1 식물 광합성\n다음 잘못된 프롬프트는 너무 모호해서 AI가 무작위 또는 관련 없는 응답을 생성할 가능성이 높다. 좋은 프롬프트는 보다 구체적이고 집중적이므로 AI가 관련성 있는 답변을 제공하도록 유도한다.\n\n\n\n잘못된 프롬프트: “뭐라도 말해줘.”\nAI 응답: “바나나는 동남아시아가 원산지인 인기 과일이지만 지금은 세계 여러 곳에서 재배되고 있습니다.”\n\n\n\n\n\n좋은 프롬프트: “식물의 광합성 과정을 설명하세요.”\nAI 응답: “광합성은 식물, 조류 및 일부 박테리아가 빛 에너지를 포도당 형태의 화학 에너지로 변환하는 과정입니다. 광합성에는 빛에 의존하는 반응과 빛에 독립적인 반응(캘빈 주기)의 두 가지 주요 단계가 포함됩니다. 빛에 의존하는 반응 동안 엽록소와 다른 색소는 빛 에너지를 흡수하여 ATP와 NADPH를 생성하는 데 사용됩니다. 광 독립 반응에서 CO2는 광 의존성 단계에서 생성된 ATP와 NADPH를 사용하여 일련의 효소 촉매 반응을 통해 유기 분자로 고정됩니다. 광합성의 최종 생성물은 포도당으로, 식물이 성장, 번식 및 기타 과정에 사용할 수 있습니다.”"
  },
  {
    "objectID": "prompt.html#국가-수도",
    "href": "prompt.html#국가-수도",
    "title": "chatGPT",
    "section": "\n3.2 국가 수도",
    "text": "3.2 국가 수도\n잘못 작성된 프롬프트는 어느 국가의 수도를 요청하는지 명시하지 않아 모호하다. 좋은 프롬프트는 국가를 명확하게 명시하여 AI가 정확한 정보를 제공할 수 있다.\n\n\n\n잘못된 프롬프트: “수도를 말해줘”\nAI 응답: “세계에는 많은 수도가 있습니다. 질문하는 국가를 지정해 주세요.”\n\n\n\n\n\n좋은 프롬프트: “독일의 수도는 어디인가요?”\nAI 응답: “독일의 수도는 베를린입니다.”"
  },
  {
    "objectID": "prompt.html#과학자",
    "href": "prompt.html#과학자",
    "title": "chatGPT",
    "section": "\n3.3 과학자",
    "text": "3.3 과학자\n잘못 작성된 프롬프트는 사용자가 어떤 과학자를 언급하고 있는지 불분명하므로 관련성이 없거나 잘못된 응답으로 이어질 수 있다. 잘 작성된 프롬프트는 과학자의 이름을 명시하고 간략한 개요와 요청사항을 명확히 하여 AI가 원하는 정보를 제공하도록 안내한다.\n\n\n\n잘못된 프롬프트: “유명한 과학자에 대해 말해줘.”\nAI 응답: “아이작 뉴턴, 알버트 아인슈타인, 마리 퀴리 등 역사상 유명한 과학자가 많이 있습니다. 관심 있는 과학자에 대한 자세한 정보를 제공하세요.”\n\n\n\n\n\n좋은 프롬프트: “알버트 아인슈타인의 생애와 과학에 대한 공헌에 대한 간략한 개요를 제공하세요.”\nAI 응답: “알버트 아인슈타인(1879-1955)은 독일 태생의 이론 물리학자로 역사상 가장 영향력 있는 과학자 중 한 명으로 널리 알려져 있습니다. 그는 공간, 시간, 중력에 대한 우리의 이해에 혁명을 일으킨 상대성 이론으로 가장 잘 알려져 있습니다. 아인슈타인의 유명한 방정식 E=mc^2는 질량과 에너지의 등가성을 증명합니다. 1921년에는 양자 이론의 발전에 기여한 광전 효과의 발견으로 노벨 물리학상을 수상했습니다. 아인슈타인의 연구는 천문학, 핵물리학에서 재료 과학, 우주론에 이르기까지 다양한 분야에 지대한 영향을 미쳤습니다.”"
  },
  {
    "objectID": "prompt.html#요리법",
    "href": "prompt.html#요리법",
    "title": "chatGPT",
    "section": "\n3.4 요리법",
    "text": "3.4 요리법\n잘못 작성된 프롬프트는 너무 일반적이어서 AI가 너무 많은 해석을 가능하게 하여 응답의 경우의 수가 많아지게 된다. 잘 작성된 프롬프트는 주제를 특정 요리로 좁히고, 단계별 설명을 요청하므로 AI의 응답이 더 유용하고 관련성이 높게 유도할 수 있다.\n\n\n\n잘못된 프롬프트: “음식을 요리하는 방법?”\nAI 응답: “음식 요리에는 다양한 기술, 재료, 레시피가 필요합니다. 관심 있는 요리 유형이나 요리 방법에 대해 더 구체적인 정보를 제공하세요.”\n\n\n\n\n\n좋은 프롬프트: “기본적인 파스타 요리를 준비하는 단계를 설명해 주세요.”\nAI 응답: “기본적인 파스타 요리를 준비하려면 다음 단계를 따르세요:\n\n큰 냄비에 소금물을 넣고 끓입니다.  스파게티, 펜네, 페투치니 등 원하는 파스타를 끓는 물에 넣고 포장지 지침에 따라 알 덴테 식감이 될 때까지 약 8~12분간 조리합니다. 파스타가 익는 동안 간단한 소스를 준비합니다. 기본 토마토 소스는 팬에 올리브 오일을 두르고 다진 마늘을 향이 날 때까지 볶습니다. 으깬 토마토, 소금, 후추, 말린 바질 또는 오레가노를 넣고 10~15분간 끓입니다. 익힌 파스타의 물기를 빼고 파스타 물 한 컵을 남겨둡니다. 파스타를 소스에 넣고 골고루 섞이도록 버무립니다. 소스가 너무 걸쭉하면 남은 파스타 물을 약간 추가하여 묽게 만듭니다. 원하는 경우 파마산 치즈와 신선한 바질로 장식하여 파스타 요리를 뜨겁게 제공합니다.”"
  },
  {
    "objectID": "prompt.html#프롬프트",
    "href": "prompt.html#프롬프트",
    "title": "chatGPT",
    "section": "\n1.2 프롬프트",
    "text": "1.2 프롬프트\n챗GPT가 거대언어모형 AI 채팅 인터페이스를 보여주고 있다. 좌측편에 프롬프트 채팅 이력이 나타나 있고, New Chat을 하게 되면 하단 채팅 박스에 Send a message ... 화면이 나온다.\n\n\n프롬프트 명령 대기 상태\n프롬프트 명령 실행 결과"
  },
  {
    "objectID": "prompt.html#프롬프트-구성요소",
    "href": "prompt.html#프롬프트-구성요소",
    "title": "chatGPT",
    "section": "\n1.1 프롬프트 구성요소",
    "text": "1.1 프롬프트 구성요소\n프롬프트 엔지니어링은 반복적인 작업과정으로 AI의 응답에 따라 프롬프트를 조정하고 개선해야 할 수도 있다는 점을 항상 염두에 두고, 다음 프롬프트 구성요소를 프롬프트에 녹여 제작할 경우 AI 언어 모델이 목표에 부합하는 정확하고 관련성 있는 구체적인 답변을 효과적으로 생성할 수 있다.\nAI 언어 모델과의 효과적인 커뮤니케이션을 위해 프롬프트를 작성할 때 고려해야 할 몇 가지 구성 요소가 있다. 잘 만들어진 프롬프트의 몇 가지 핵심 구성 요소를 다음과 같이 정리할 수 있다:\n\n명확성: 프롬프트는 명확하고 이해하기 쉬워야 한다. 즉, AI 언어모델이 혼동할 수 있는 전문 용어, 은어 또는 모호한 언어는 사용하지 않는다.\n맥락(Context): AI 언어모델이 해결해야 할 주제나 지시 업무를 파악하는 데 도움이 되는 충분한 맥락(Context)를 제공한다. 질문 혹은 요청과 관련된 배경 정보, 구체적인 세부 정보 또는 예시가 포함된다.\n구체성: AI 언어모델이 원하는 답변으로 안내할 수 있도록 프롬프트를 최대한 구체적으로 작성한다. 답변의 형식, 정보의 범위 또는 집중적으로 다루고 싶은 주제의 특정 측면을 지정하는 행위가 포함된다.\n모호성 제거: AI 언어모델이 질문을 오해하거나 관련 없는 답변을 제공할 가능성을 줄이려면 프롬프트에 모호성이 있는지 확인한다. 프롬프트가 여러 가지 의미로 해석될 수 있는 경우, 모호함이 없도록 프롬프트를 다시 작성한다.\n제약 조건: 단어 수 제한이나 주제의 특정 측면과 같은 제약 조건을 포함하면 AI 언어모델이 보다 집중적이고 관련성 높은 답변을 제공하도록 유도할 수 있다. 특히, 광범위한 주제에 대한 정보를 찾거나 간결한 답변을 찾을 때 유용하다.\n지시사항: AI 언어모델이 특정 작업을 수행하거나 특정 방식으로 동작하도록 하려면 프롬프트에 명시적인 지침을 포함한다. 예를 들어, AI에게 장단점을 나열하거나, 두 항목을 비교하거나, 특정 관점을 고려하도록 요청한다.\n문법과 철자: AI 언어모형이 수행 작업을 해석할 때 문법 정보를 사용하기 때문에 올바른 문법과 철자법을 맞게 작성하는 것은 중요하다.\n\nPrompt Engineering Guide"
  },
  {
    "objectID": "prompt.html#안내지침-프롬프트-기법",
    "href": "prompt.html#안내지침-프롬프트-기법",
    "title": "chatGPT",
    "section": "\n5.1 안내지침 프롬프트 기법",
    "text": "5.1 안내지침 프롬프트 기법\n\n\nPrompt formula: “Generate [task] following these instructions: [instructions]”\n\n\n\n프롬프트 공식: “다음 지침에 따라 [작업]을 생성합니다: [지침]”"
  },
  {
    "objectID": "prompt.html#표준-프롬프트",
    "href": "prompt.html#표준-프롬프트",
    "title": "chatGPT",
    "section": "\n5.1 표준 프롬프트",
    "text": "5.1 표준 프롬프트\n가장 기본적인 프롬프트는 언어모형이 수행할 “[작업]”을 지정하고 다음과 같이 생성하라고 지시명령문을 작성한다.\n\n프롬프트: “[작업]을 생성하라”  예: 다음 뉴스기사를 한 문장으로 요약해 주세요!\n\n챗GPT 플러그인 확장기능을 사용하지 않는 경우 외부 URL을 인식하지 못하기 때문에 프롬프트에 해당 기사를 복사하여 붙여넣기해야한다. 농민신문 버젓이 수입·재배된 LMO 종자…검역당국 뭐했나에 실린 오피니언 사설을 요약해보자.\n\n\n\n\n\n\n프롬프트: 다음 뉴스기사를 한 문장으로 요약해 주세요!\n\n\n\n\n\n미국의 유전자변형생물체(LMO) 종자가 버젓이 수입돼 8년이나 재배돼온 사실이 드러났다. 품목은 주키니호박이다. 제조·가공하면 유전자변형 DNA가 안 남아 식품가공용으로 승인받은 원료 작물에 대해서도 유전자변형농산물(GMO) 표시를 하라고 할 정도로 국민적 반감이 거센데, 재배를 통해 얼마든지 증식할 수 있는 LMO 종자가 해외 직구라는 어엿한 경로를 통해 들어와 장기간 재배됐으니 검역망 허술하기가 한심하기 짝이 없다.\n종자가 함부로 국경을 넘나들어서는 안되는 이유는 국내법은 물론 국제 규약에도 명시됐다. 우리나라 ‘종자산업법’은 생태계 보호 및 자원 보존에 지장을 줄 우려가 있는 종자는 수입을 제한할 수 있다고 했으며, ‘LMO의 국가간 이동 등에 관한 법률’(LMO법)은 생물다양성의 보전 및 지속적 이용에 부정적 영향을 끼칠 수 있는 LMO의 위해를 방지하기 위한 국가의 책무를 적시하고 있다. LMO법은 LMO의 국가간 이동을 규제하는 국제협약인 ’바이오안전성에 관한 카르타헤나 의정서’를 기반으로 하는 만큼 LMO에 대한 우려는 세계 각국이 공히 인정하는 바이기도 하다. 이런데도 LMO 종자가 무사 통관했다는 건 검역당국의 방임이나 능력 부족으로밖에 보이지 않는다.\nLMO 주키니호박 재배·판매 사실이 알려진 후 농림축산식품부가 해당 종자 회수에 나서고 교육부가 학교급식에 주키니호박 사용을 중단한 것은 그만큼 사태가 위중해서다. GMO에 대한 국민적 불신이 반영된 조치다. 양심을 속이고 수입 규정을 어긴 업자를 우선 탓해야 하겠지만, 이런 상황을 막기 위해 검역당국이 존재하는 것 아닌가. 종자는 낱알 크기가 작은 데다 속이려고 작정하면 걸러내기 어렵다는 점을 모르지 않으나 그런 해명이 국민의 공감을 얻기는 어렵다.\n현행 제도상 빈틈이나 구멍을 완벽히 메우기 어렵다면 응당 검역·통관 시스템을 개선하고 위법자에 대한 처벌도 크게 강화하는 것이 마땅하다. 카르타헤나 의정서에도 나와 있듯 LMO의 국가간 이동이 향후 해당국의 생물다양성은 물론 인체 건강에 어떤 부정적 영향을 줄지 알 수 없기 때문이다. 더구나 지금 상태라면 GMO 관련 장벽을 대폭 완화해야 할 것으로 예상되는 인도·태평양 경제프레임워크(IPEF) 시대에 대한 전망도 암울하다. 문턱이 낮아질수록 넘나듦이 쉬운 건 불문가지다.\nAI 응답:\n\n미국 유전자변형생물체(LMO) 종자인 주키니호박이 무사통관돼 국내에서 8년간 재배되어 왔는데, 이는 국내법과 국제 규약을 위반한 것으로 검역망의 부족과 능력 부족으로 보인다는 것과 GMO에 대한 국민적 불신이 반영된 사태이며, 검역·통관 시스템 개선과 위법자에 대한 강화된 처벌이 필요하다는 것이 지적되고 있다.\n\n\n\n\n\n표준 프롬프트 작성 기법에 역할을 추가하면 좀더 의미있는 기사를 작성하게 된다.\n\n\n작업: 삼성 갤럭시 23 핸드폰 후기 작성\n\n작성지침: 후기는 객관적이며 유익한 정보를 담고 있어야 하며 전작과 비교하여 특별히 추가된 기능을 강조해야 된다.\n\n역할: 구매 소비자\n\n씨앗단어: 새로운 기능\n\n\n\n\n\n\n\n프롬프트: “휴대폰을 구매하는 소비자로서 이전 모델과 비교하여 새로운 삼성 갤럭시 23 휴대폰의 고유한 기능을 강조하는 객관적이고 유익한 정보를 담고 있는 휴대폰 리뷰를 작성하세요.”\n\n\n\n\nAI 응답:\n\n최근에 새로운 삼성 갤럭시 23 휴대폰을 구매한 소비자로서, 이전 모델과 비교해 보았을 때 큰 업그레이드가 이루어졌다는 것을 확신할 수 있습니다. 그 중에서 가장 눈에 띄는 특징은 향상된 저조도 성능과 개선된 광학 줌이 있는 강력한 트리플 렌즈 카메라 시스템입니다. 또한, 최신 스냅드래곤 프로세서를 장착해 처리 속도가 향상되어 반응성과 사용자 경험이 더욱 빠르고 더욱 원활해졌습니다.\n\n\n갤럭시 23에는 이전 삼성 모델과 구별되는 여러 가지 고유한 기능이 있습니다. 그 중 하나는 다이나믹 AMOLED 120Hz 디스플레이인데, 화려한 색상과 선명한 대비로 눈에 띄는 시각적 효과를 제공합니다. 또한, 휴대폰의 배터리 크기가 커졌으며 빠른 충전 기능을 갖추고 있어 항상 바쁘게 사용하는 사용자에게 적합합니다.\n\n\n종합적으로, 새로운 삼성 갤럭시 23은 최첨단 기능을 갖춘 최고급 휴대폰을 찾고 있는 분들에게 추천할 만한 가치가 있습니다. 강력한 카메라 시스템, 빠른 처리 속도 및 디스플레이 품질로 인해 경쟁이 치열한 시장에서 뛰어난 장치로 떠오르고 있습니다."
  },
  {
    "objectID": "prompt.html#역할-프롬프트",
    "href": "prompt.html#역할-프롬프트",
    "title": "chatGPT",
    "section": "\n5.2 역할 프롬프트",
    "text": "5.2 역할 프롬프트\nAI 언어모델에 특정 역할을 부여해서 원하는 챗GPT 결과를 도출하도록 지시명령문을 작성한다.\n\n프롬프트: “[역할]로서 [작업]을 생성하라”  예: “통신회사 콜센터 상담원으로 고객문의에 대해 응답을 생성하시오”\n\n\n\n\n\n\n\n프롬프트: 너는 지금부터 케이블 TV 회사의 고객 서비스 담당자로 역할을 수행할 것입니다. 고객이 콜센터로 삼성 갤럭시 23 핸드폰에 문제가 있다고 전화를 걸어왔습니다. 고객에게 응대를 해야하는데 어떻게 응대할지 작성해보세요.\n\n\n\n\nAI 응답:\n\n네, 고객 서비스 담당자로 역할을 수행하겠습니다.\n\n\n고객: 삼성 갤럭시 23 핸드폰을 사용하고 있는데, 전화를 걸거나 문자를 보내려고 할 때마다 화면이 꺼져요.\n\n\n고객 서비스 담당자: 안녕하세요, 삼성 갤럭시 23 핸드폰 고객 서비스입니다. 불편을 드려 죄송합니다. 해당 문제를 해결하기 위해서 몇 가지 질문을 드릴게요. 먼저, 핸드폰을 재부팅해보셨나요? 그리고 핸드폰이 충전이 잘 되고 있는지 확인해 보세요. 만약 이러한 조치가 문제를 해결하지 못한다면, 화면이 자주 꺼지는 경우에는 배터리 절약 모드를 사용하고 있는지 확인해 보세요. 그리고 설정에서 화면 시간을 더 길게 조정해보세요. 만약에 이러한 조치가 문제를 해결하지 못한다면, 저희는 펌웨어 업데이트나 고장 신고 등 추가적인 조치를 취할 수 있도록 도와드리겠습니다. 어떤 조치를 취해 드릴까요?"
  },
  {
    "objectID": "prompt.html#감성-분류",
    "href": "prompt.html#감성-분류",
    "title": "chatGPT",
    "section": "\n5.3 감성 분류",
    "text": "5.3 감성 분류\n텍스트에 내재된 감성도 긍부정 혹은 긍정, 부정, 중립으로 나눠 분류하는 작업도 가능하다.\n\n프롬프트: “[텍스트]의 감성을 긍정과 부정 둘 중 하나로 분류하라”  예: “다음 텍스트의 감성을 긍정과 부정 둘 중 하나로 분류합니다. ‘1%라도 기대했던 내가 죄인입니다 죄인입니다….’”\n\n네이버 영화 감성 말뭉치에서 영화 후기 긍정과 부정을 각각 하나씩 뽑아내서 감성분류 작업을 수행한다.\n\n\n\n\n\n\n\nid\ndocument\nlabel\n\n\n\n5912145\n왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n1\n\n\n9671124\n1%라도 기대했던 내가 죄인입니다 죄인입니다….\n0\n\n\n\n\n\n\n\n\n\n프롬프트: 다음 텍스트의 감성을 긍정과 부정 둘 중 하나로 분류합니다. 답변은 긍정, 부정 중 하나입니다.\n\n\n\n\n\n“왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?”\nAI 응답:\n\n답변: 긍정\n\n\n\n\n\n\n\n\n\n\n\n프롬프트: 다음 텍스트의 감성을 긍정과 부정 둘 중 하나로 분류합니다. 그리고 이유도 제시하여 주세요.\n\n\n\n\n\n“1%라도 기대했던 내가 죄인입니다 죄인입니다….”\nAI 응답:\n\n이 텍스트는 부정적인 감성을 나타냅니다. 이유는 “죄인입니다”라는 문구가 있어서 입니다. 이 문구는 자신에 대한 부정적인 평가를 나타내고 있으며, “1%라도 기대했던”이라는 표현은 자신이 어떤 일을 할 때 기대와 다르게 결과가 나온 것으로 추정됩니다. 이러한 표현들은 부정적인 감정을 나타내고 있으며, 따라서 이 텍스트는 부정적인 감성을 가지고 있습니다."
  },
  {
    "objectID": "prompt.html#텍스트-분류",
    "href": "prompt.html#텍스트-분류",
    "title": "chatGPT",
    "section": "\n5.4 텍스트 분류",
    "text": "5.4 텍스트 분류\n네이버 뉴스기사를 각 뉴스 범주별로 나눠 분류하는 것도 가능하다.\n\n프롬프트: “[텍스트]를 다음 중 하나의 범주로 분류하라; A, B, C”  예: “뉴스기사를 다음 중 하나 범주로 분류해야 합니다; 정치, 경제, 사회, 생활/문화, 세계, 기술/IT, 연예, 스포츠. ‘뉴스 기사’”\n\n다음 사례는 네이버 뉴스 카테고리 데이터셋에서 정치뉴스기사 하나를 가져왔다. 압축파일을 풀면 정치(0), 경제(1), 사회(2), 생활/문화(3), 세계(4), 기술/IT(5), 연예(6), 스포츠(7) 총 8개 범주로 나눠 디렉토리에 텍스트 뉴스기사가 포함되어 있다.\n\n\n\n\n\n\n프롬프트: 뉴스기사를 다음 중 하나 범주로 분류해야 합니다; 정치, 경제, 사회, 생활/문화, 세계, 기술/IT, 연예, 스포츠.\n\n\n\n\n\n동남아 담당’ 北 최희철 부상 베이징 도착…싱가포르행 주목 최 부상, 행선지·방문 목적 질문에는 ‘묵묵부답’\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\n베이징 소식통은 “최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다”며 “만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다”고 말했다.\nAI 응답:\n\n해당 뉴스는 북한의 외교 정책과 관련된 내용이 있어 정치 범주에 속합니다."
  },
  {
    "objectID": "prompt.html#footnotes",
    "href": "prompt.html#footnotes",
    "title": "chatGPT",
    "section": "각주",
    "text": "각주\n\nLearn Prompting↩︎\nPrompt Engineering Guide↩︎"
  },
  {
    "objectID": "prompt.html#인명-추출",
    "href": "prompt.html#인명-추출",
    "title": "chatGPT",
    "section": "\n5.5 인명 추출",
    "text": "5.5 인명 추출\n텍스트에서 사람, 지명, 브랜드 등 기계가 인식해서 추출하는 작업을 통상 개체명인식(NER, Named Entity Recognition) 이라고 한다. GPT-3.5, GPT-4에 따라 성능차이가 다소 있지만 기존 접근법과 비교하여 손색이 없다고 할 수 있다.\n\n프롬프트: “다음 [텍스트]에 대해서 개체명 인식 작업을 수행하고 인물, 조직, 장소로 구분하라.”  예: “다음 뉴스기사에서 개체명을 추출해 주세요. 출력 형식: 인물:  조직:  장소: ”\n\n네이버 뉴스 카테고리 데이터셋에서 정치뉴스기사 하나를 가져왔다.\n\n\n\n\n\n\n프롬프트: 다음 뉴스기사에서 개체명을 추출해 주세요.\n\n\n\n\n\n출력 형식: 인물: &lt;출력결과를 콤마 구분자로 구분&gt;  조직: &lt;출력결과를 콤마 구분자로 구분&gt;  장소: &lt;출력결과를 콤마 구분자로 구분&gt;  날짜: &lt;출력결과를 콤마 구분자로 구분&gt;\n동남아 담당’ 北 최희철 부상 베이징 도착…싱가포르행 주목 최 부상, 행선지·방문 목적 질문에는 ‘묵묵부답’\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\n베이징 소식통은 “최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다”며 “만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다”고 말했다.\nAI 응답:\n\n인물: 최희철, 김진방, 비자이 쿠마르 싱  조직: 연합뉴스, 북한 외무성, 고려항공, 아세안(ASEAN·동남아시아국가연합), 아세안지역안보포럼(ARF), 인도 외교부  장소: 베이징, 서우두(首都) 공항, 평양, 싱가포르, 북한 대사관  날짜: 19일, 20여 일, 지난 3월, 올해 8월, 지난해"
  },
  {
    "objectID": "prompt.html#개체명-추출",
    "href": "prompt.html#개체명-추출",
    "title": "chatGPT",
    "section": "\n5.5 개체명 추출",
    "text": "5.5 개체명 추출\n텍스트에서 사람, 지명, 브랜드 등 기계가 인식해서 추출하는 작업을 통상 개체명인식(NER, Named Entity Recognition) 이라고 한다. GPT-3.5, GPT-4에 따라 성능차이가 다소 있지만 기존 접근법과 비교하여 손색이 없다고 할 수 있다.\n\n프롬프트: “다음 [텍스트]에 대해서 개체명 인식 작업을 수행하고 인물, 조직, 장소로 구분하라.”  예: “다음 뉴스기사에서 개체명을 추출해 주세요. 출력 형식: 인물:  조직:  장소: ”\n\n네이버 뉴스 카테고리 데이터셋에서 정치뉴스기사 하나를 가져왔다.\n\n\n\n\n\n\n프롬프트: 다음 뉴스기사에서 개체명을 추출해 주세요.\n\n\n\n\n\n출력 형식: 인물: &lt;출력결과를 콤마 구분자로 구분&gt;  조직: &lt;출력결과를 콤마 구분자로 구분&gt;  장소: &lt;출력결과를 콤마 구분자로 구분&gt;  날짜: &lt;출력결과를 콤마 구분자로 구분&gt;\n동남아 담당’ 北 최희철 부상 베이징 도착…싱가포르행 주목 최 부상, 행선지·방문 목적 질문에는 ‘묵묵부답’\n(베이징=연합뉴스) 김진방 특파원 = 북한이 북미 정상회담 무산 가능성까지 거론하며 강경한 태도를 보이는 가운데 동남아시아 외교를 담당하는 최희철 북한 외무성 부상이 19일 중국 베이징 서우두(首都) 공항에 모습을 드러냈다.\n최 부상은 이날 오전 평양발 고려항공 JS151편을 이용해 베이징 서우두 공항에 도착했다.\n최 부상은 최종 목적지를 묻는 취재진의 질문에 아무런 답변을 하지 않고, 북한 대사관 관계자들과 함께 공항을 빠져나갔다.\n북미 정상회담을 20여 일 앞둔 상황에서 동남아 외교통인 최 부상이 정상회담 준비 등을 위해 회담 개최 예정지인 싱가포르를 방문할 가능성도 제기되고 있다.\n최 부상은 지난 3월에도 아세안(ASEAN·동남아시아국가연합) 의장국이기도 한 싱가포르를 방문해 양국관계와 올해 8월 열리는 아세안지역안보포럼(ARF) 의제 등을 논의한 바 있다.\n또 지난해 북핵 문제를 두고 북미 간 긴장관계가 형성됐을 때도 ARF에 참석해 아세안을 상대로 여론전을 펼쳤다. 북한의 초청으로 비자이 쿠마르 싱 인도 외교부 국무장관이 방북했을 때도 최 부상은 싱 국무장관을 직접 영접하고, 한반도 문제를 논의하기도 했다.\n베이징 소식통은 “최 부상이 대(對)미 외교담당이 아니기 때문에 싱가포르로 갈 가능성이 큰 것은 아니다”며 “만약 싱가포르에 간다면 정상회담과 관련한 지원 작업 준비 등을 위한 것일 가능성이 크다”고 말했다.\nAI 응답:\n\n인물: 최희철, 김진방, 비자이 쿠마르 싱  조직: 연합뉴스, 북한 외무성, 고려항공, 아세안(ASEAN·동남아시아국가연합), 아세안지역안보포럼(ARF), 인도 외교부  장소: 베이징, 서우두(首都) 공항, 평양, 싱가포르, 북한 대사관  날짜: 19일, 20여 일, 지난 3월, 올해 8월, 지난해"
  },
  {
    "objectID": "prompt.html#질의응답",
    "href": "prompt.html#질의응답",
    "title": "chatGPT",
    "section": "\n5.6 질의응답",
    "text": "5.6 질의응답\n지문이 주어진 상태에서 사람이 질문을 하면 기계가 답을 하는 상황이다. 전문적이고 매우 긴 지문에서 원하는 답을 찾기 위해 질문을 하는 상황에서 유용하다.\n\n프롬프트: “다음 [지문]에서 [질문]에 답하시오”  예: “다음 지문을 읽고 답을 찾으세요. 질문: 김현웅은 서울고등검찰청 검사장 재직 중에 몇대 법무부 장관에 임용되었나?\n지문: 김현웅(金賢雄, 1959년 5월 4일 ~ , 전남 고흥)은 … ”\n\nKorQuAD 2.0는 KorQuAD 1.0에서 질문답변 20,000+ 쌍을 포함하여 총 100,000+ 쌍으로 구성된 한국어 Machine Reading Comprehension 데이터셋으로, KorQuAD 1.0과는 다르게 1~2 문단이 아닌 Wikipedia article 전체에서 답을 찾아야 한다. KorQuAD 데이터셋에서 사례를 하나 가져와서 질의응답을 풀어본다.\n\n실제 정답 라벨: [{'text': '제64대', 'answer_start': 209}]\n\n\n\n\n\n\n\n프롬프트: 다음 지문을 읽고 답을 찾으세요.\n\n\n\n\n\n질문: 김현웅은 서울고등검찰청 검사장 재직 중에 몇대 법무부 장관에 임용되었나?\n지문: 김현웅(金賢雄, 1959년 5월 4일 ~ , 전남 고흥)은 대한민국의 법률가이다. 사법연수원 16기 수료 후 검사 생활을 했으며 특히 서울중앙지검 특수1부 부장검사로 재직할 때는 법조브로커 김홍수씨(58·구속)로부터 금품을 받은 혐의(알선수재)로 사상 최초로 전직 고등 법원 부장판사급 법관 A씨에 대해 사전 구속영장을 청구했다. 이후 제46대 서울고등검찰청 검사장 재직 중 제64대 법무부 장관에 임용되었다. 대한변호사협회(회장 김현)가 김현웅(58·사법연수원 16기) 전 법무부 장관에게 변호사 개업을 자제할 것을 권고했다. 변협은 보 도자료를 통해 “김현웅 전 장관은 지난 4월27일 변호사 등록을 신청했고, 현행 변호사법상 등록 거부 사유가 없다”라며 “변호사법은 등록 신청일로부터 3개월간 등록을 하지 않을 경우 등록이 간주된다고 규정하고 있다”라고 설명했다.\nAI 응답:\n\n김현웅은 서울고등검찰청 검사장 재직 중에 제64대 법무부 장관에 임용되었다."
  },
  {
    "objectID": "prompt.html#객관식-문제",
    "href": "prompt.html#객관식-문제",
    "title": "chatGPT",
    "section": "\n5.7 객관식 문제",
    "text": "5.7 객관식 문제\n주어진 4개 중에서 정답을 하나 고르는 문제를 사지선다(四枝選多)형 시험문제로 학창시절부터 접해 친숙하다. 사지선다 문제를 풀고 문제도 생성하는 프롬프트를 제작해보자.\n\n프롬프트: “다음 [선택지] 중에서 정답을 하나 고르세요.”  예: “다음 문제에서 정답을 하나 고르세요. 문제: 통계에서 모든 경우의 수를 포함하는 집합을 일컷는 용어는?\n\n표본 공간(Sample Space)\n포함집합(Super Set)\n포함공간(Super Space)\n표본집합(Sample Set) ”\n\n\n\n정답과 이유도 추가하고 유사한 사지선다형 문제를 몇개 만들어 지시한다.\n\n\n\n\n\n\n\n프롬프트: 통계에서 두 변수 간의 상관 관계를 나타내는 지수는?\n\n\n\n\n\n\n중앙값(Median)\n평균(Average)\n분산(Variance)\n상관계수(Correlation Coefficient)\n\nAI 응답:\n\n정답: 4. 상관계수(Correlation Coefficient) 이유: 통계에서 두 변수 간의 관련성을 측정하는 방법 중 하나가 상관계수입니다. 상관계수는 -1에서 1 사이의 값을 가지며, 1에 가까울수록 양의 상관관계, -1에 가까울수록 음의 상관관계, 0에 가까울수록 상관관계가 없다는 것을 의미합니다."
  },
  {
    "objectID": "open_source.html",
    "href": "open_source.html",
    "title": "chatGPT",
    "section": "",
    "text": "Guido Appenzeller, Matt Bornstein, Martin Casado, and Yoko Li, “Art Isn’t Dead, It’s Just Machine-Generated - Why AI models will replace artists long before they’ll replace programmers”\n오픈 소스 AI 모델 Stable Diffusion V1은 전 세계적으로 수백 개의 다른 모델과 혁신을 낳았다. 두 달도 채 되지 않아 33,000개의 별을 돌파하며 모든 소프트웨어 중 가장 빠르게 Github 별 10,000개에 도달했고, 이는 이전의 다른 혁신적인 기술 비트코인, 이더리움, 카프카, 스파크 등과 비교하면 그 파급력이 갈음된다. 최근 공개(March 24, 2023)된 Stable Diffusion V2는 GitHub stablediffusion에서 확인 가능하다.\n\n\n\n\n\n페이스북으로 잘 알려진 메타(Meta)는 연구 목적(비상업적 사용)으로 라마(LLaMA) 거대언어모형을 오픈소스 소프트웨어로 2023년 2월 24일 공개했다. LLaMA는 라틴어와 키릴 문자를 사용하는 20개 언어의 텍스트를 학습하여 다양한 크기(7B, 13B, 33B, 65B 매개변수) 언어모형 형태로 공개되어 거대언어모형을 대중화하고 연구자들이 새로운 접근 방식과 사용 사례를 테스트할 수 있는 취지로 공개되었지만, 여전히 편향성, 독성, 잘못된 정보 등 추가적인 보완이 필요하다.\nMetaAI (February 24, 2023), “Introducing LLaMA: A foundational, 65-billion-parameter large language model”, MetaAI Blog"
  },
  {
    "objectID": "nlp_LLM.html",
    "href": "nlp_LLM.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 자연어 처리\n자연어 처리는 컴퓨터로 하여금 사람이 작성한 언어(음성과 글)의 의미를 이해시키는 것을 목표로 한다.\n\n텍스트 데이터\n\n트위터\n소설, 신문기사\n고객 평점과 리뷰\n전자우편\n의무기록\n…\n\n\n텍스트 저장 형식\n\n뉴스 등 웹 페이지\nPDF/워드/한글 문서\n트위터 등 SNS, RSS 피드, 댓글\n…\n\n\n응용분야\n\n감성분석\n텍스트 분류\n번역\n챗봇\n개인 비서\n…\n\n\n기술\n\n단어주머니(Bag of Words)\nWord Embedding, 워드투벡(Word2Vec)\nRNN, LSTM\nBERT, Transformer\nGPT, 거대언어모형(LLM)\n…\n\n\n\n2 작업흐름\n감성 분석 및 텍스트 분류 등 텍스트를 데이터로 하는 전통적인 자연어 처리 작업은 다음과 같은 작업흐름을 갖게 된다.\n\n\n\n\n\n\ngraph TD\n    A[데이터 수집] --&gt; B[데이터 전처리]\n    B --&gt; C[피쳐 추출]\n    C --&gt; D[훈련-테스트 데이터셋 분할]\n    D --&gt; E[모형 선택]\n    E --&gt; F[모형 학습]\n    F --&gt; G[모형 평가]\n    G --&gt; H[하이퍼파라미터 튜닝]\n    H --&gt; I[모형 배포]\n    I --&gt; J[모니터링 및 유지보수]\n\n\n\n\n\n\n\n데이터 수집: 텍스트 데이터와 해당 레이블이 포함된 데이터셋을 수집한다. 감성 분석의 경우, 라벨은 ‘긍정’, ‘부정’ 또는 ’중립’이 되고, 텍스트 분류의 경우 레이블은 다양한 주제나 카테고리를 나타낼 수 있다. 즉, 자연어 처리 목적에 맞춰 라벨을 특정하고 연관 데이터를 수집한다.\n데이터 전처리: 텍스트 데이터를 정리하고 전처리하여 추가 분석에 적합하도록 작업하는데 소문자화, 토큰화, 불용어 제거, 특수문자 제거, 어간 단어 기본형으로 줄이기 등이 포함된다.\n피쳐 추출:사전 처리된 텍스트를 기계 학습 알고리즘에 적합한 숫자 형식으로 변환하는 과정으로 BoW, TF-IDF, 단어 임베딩 등이 흔히 사용되는 기법이다.\n훈련-시험 데이터셋 분할: 일반적으로 70-30, 80-20 또는 기타 원하는 분할 비율을 사용하여 데이터셋을 훈련과 시험 데이터셋으로 구분한다.\n모형 선택: 적합한 통계, 머신 러닝, 딥러닝 모델을 선정한다.\n모형 학습: 적절한 최적화 알고리즘과 손실 함수를 사용하여 훈련 데이터셋에서 선택한 모델을 학습시킨다.\n모형 평가: 정확도, 정밀도, 리콜, F1 점수 또는 ROC 곡선 아래 영역과 같은 관련 메트릭을 사용하여 시험 데이터셋에서 학습 모형의 성능을 평가한다.\n하이퍼파라미터 튜닝: 격자 검색 또는 무작위 검색과 같은 기술을 사용하여 모형의 하이퍼파라미터를 최적화하여 성능을 개선한다.\n모형 배포: 모형을 학습하고 최적화한 후에는 실제 환경에서 사용할 수 있도록 실제 운영 환경에 배포하여 가치를 창출한다.\n모니터링 및 유지 관리: 배포된 모형의 성능을 지속적으로 모니터링하고 필요에 따라 새로운 학습데이터로 업데이트하여 정확성과 효율성을 유지한다.\n\n\n\n\n3 자연어 처리 작업\n자연어 처리 분야에서 흔히 접하는 상위 10가지 NLP으로 다음을 들 수 있다.\n\n감정 분석: 긍정, 부정, 중립 등 주어진 텍스트에 표현된 감정을 파악.\n텍스트 분류: 텍스트 데이터를 미리 정의된 클래스 또는 주제(예: 스포츠, 정치, 연예 등)로 분류.\n개체명 인식(NER): 텍스트 내에서 사람, 조직, 위치, 날짜 등의 명명된 개체(entity)를 식별하고 분류.\n품사(POS) 태깅: 주어진 텍스트의 단어에 문법적 레이블(예: 명사, 동사, 형용사)을 할당.\n의존성 구문 분석: 문장 내 단어 간의 문법 구조와 관계를 식별.\n기계 번역: 영어에서 스페인어로 또는 중국어에서 프랑스어로와 같이 한 언어에서 다른 언어로 텍스트를 번역.\n질의 응답: 자연어로 제기된 질문을 이해하고 답변할 수 있는 시스템을 개발.\n텍스트 요약: 주요 아이디어와 정보를 보존하면서 주어진 텍스트에 대한 간결한 요약을 생성.\n상호참조해결(Coreference Resolution): 텍스트에서 두 개 이상의 단어나 구가 동일한 개체 또는 개념을 지칭하는 경우 식별.\n텍스트 생성: 주어진 입력, 컨텍스트 또는 일련의 조건에 따라 일관되고 의미 있는 텍스트를 생성.\n\n자연어 처리 작업과 작업흐름을 서로 연결하게 되면 다음과 같이 개별적으로 중복되고 분리된 작업을 수행하게 되는 문제가 있다.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;\n\n\n\n\n\n\n4 비교\n\n\n\n\ngraph TB\n\nsubgraph \"거대언어기반 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nsubgraph \"전통적인 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;\n\n\n\n\n\n\n\n\n\n\ngraph TB\nsubgraph \"미세조정 작업흐름&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[사전 훈련] --&gt; B1[미세 조정]\n  B1 --&gt; C1[모델 훈련 및 평가]\n  C1 --&gt; D1[하이퍼파라미터 튜닝]\n  D1 --&gt; E1[배포 및 유지보수]\nend\n\nsubgraph \"프롬프트 공학 작업흐름&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[사전 학습] --&gt; B2[프롬프트 설계]\n  B2 --&gt; C2[모델 추론 및 후처리]\n  C2 --&gt; D2[모델 평가]\n  D2 --&gt; E2[배포 및 유지보수]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "openAI_GPT.html#gpt-3",
    "href": "openAI_GPT.html#gpt-3",
    "title": "chatGPT",
    "section": "",
    "text": "OpenAI GPT-3 모형은 크게 세가지가 있다.\n\nGPT-3/GPT-4\nCodex\n콘텐츠 필터 모델\n\nGPT-3은 자연어 처리 및 생성을 담당하는 모델로 인간의 언어 즉, 자연어처럼 보이는 텍스트를 이해할 수 있다. 한걸음 더 들어가면 속도와 성능에 따라 4가지 모델(A, B, C, D)로 구분된다.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\n성능기준으로 보면 다음과 같이 정렬할 수 있는데 비용도 그에 따라 높아진다는 의미도 함축한다.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\n따라서, OpenAI는 다빈치 모델(text-davinci-003)을 통해 원하는 결과를 얻은 후에 다른 모델을 사용해 볼 것을 권장하는데 이유는 훨씬 저렴한 비용으로 많은 수의 유사한 작업을 수행할 수 있기 때문이다.\n\n2,048개의 토큰 및 2019년 10월까지의 데이터 학습하여 이후 모형과 비교하여 정확도나 성능에서 다소 밀리는 모습이지만 최적화를 통해 매우 빠르고 비용이 가장 저렴하다.\n\n2,048개의 토큰과 2019년 10월까지의 데이터 학습되었고 간단한 분류와 의미론적 분류에 효과적이다.\n\n최대 2048개의 토큰을 지원하며 text-davinci-003 다음으로 뛰어난 성능을 보이는 GPT-3 모델이다. 2019년 10월까지의 데이터로 학습되었기 때문에 text-davinci-003보다 정확도가 떨어지지만, 번역, 복잡한 분류, 텍스트 분석 및 요약에 좋은 성능을 보이고 있어 text-davinci-003와 비교하여 가성비가 높다고 평가되고 있다.\n\n2021년 9월까지의 데이터로 훈련되었기 때문에 최신 정보를 제공하지 못한다는 한계는 있지만, 앞선 GPT-3 모형과 비교하여 더 높은 품질을 제공한다. 장점 중 하나는 최대 4,000개 토큰까지 요청할 수 있다는 점이 이전 모형과 큰 차별점이 된다."
  },
  {
    "objectID": "openAI_GPT.html#코덱스codex",
    "href": "openAI_GPT.html#코덱스codex",
    "title": "chatGPT",
    "section": "",
    "text": "코덱스는 프로그래밍 코드 이해 및 생성을 위한 것으로 code-davinci-002와 code-cushman-001가 있다. 또한, 코덱스는 GitHub Copilot을 구동하는 모델이기도 하다. 파이썬, 자바스크립트, 고, 펄, PHP, 루비, 스위프트, 타입스크립트, SQL, 셸 등 12개 이상의 프로그래밍 언어를 지원할 뿐만 아니라 자연어로 표현된 주석(comment)를 이해하고 사용자를 대신하여 요청된 작업을 수행할 수 있다.\n\n복잡한 작업을 수행하는 데 있어서는 code-davinci-002가 더 강력하지만, 많은 코드 생성 작업을 수행할 수 있고 code-davinci-002 보다 더 빠르고 저렴하다는 장점이 있다.\n\n자연어를 코드로 번역하는 데 탁월할 뿐만 아니라 코드를 자동 완성할 뿐만 아니라 보충 요소 삽입도 지원한다. 최대 8,000개의 토큰을 처리할 수 있으며 2021년 6월까지의 데이터로 학습되었다."
  },
  {
    "objectID": "openAI_GPT.html#콘텐츠-필터",
    "href": "openAI_GPT.html#콘텐츠-필터",
    "title": "chatGPT",
    "section": "",
    "text": "민감한 콘텐츠 제거하기 위한 필터 모형이다. 민감하거나 안전하지 않을 수 있는 API 생성 텍스트를 감지할 수 있다. 사용자가 사용할 AI 응용프로그램을 개발할 경우, 필터를 사용하여 모델이 부적절한 콘텐츠를 반환하는지 감지할 수 있다. 이 필터는 텍스트를 다음 3가지 범주로 나눈다.\n\n안전(safe)\n민감(sensitive)\n안전하지 않음(unsafe)"
  },
  {
    "objectID": "openAI_GPT.html#텍스트-벡터-표현",
    "href": "openAI_GPT.html#텍스트-벡터-표현",
    "title": "chatGPT",
    "section": "\n2.1 텍스트 벡터 표현",
    "text": "2.1 텍스트 벡터 표현\ntext-embedding-ada-002 모델은 빠르고 가성비가 뛰어난 임베딩 모델이다. “대한민국 수도는 서울입니다.” 이라는 문서를 벡터로 표현하면 다음과 같다. 즉, 1,536 차원을 갖는 공간에 하나의 점으로 표현될 수 있다.\n\nimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"대한민국 수도는 서울입니다.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'벡터길이: {len(seoul_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {seoul_embedding[:10]}')\n#&gt; 벡터 일부: [0.014582998119294643, -0.018063032999634743, 0.004872684367001057, -0.013805408962070942, -0.031180081889033318, 0.025176068767905235, -0.034519895911216736, 0.011357911862432957, -0.007960736751556396, -0.0020682618487626314]\n\n마찬가지로 일본의 수도 도쿄도 벡터로 표현할 수 있다.\n\ntokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"일본 수도는 동경입니다.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'벡터길이: {len(tokyo_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {tokyo_embedding[:10]}')\n#&gt; 벡터 일부: [0.010957648046314716, -0.013234060257673264, 0.009729413315653801, -0.011890077032148838, -0.03179261088371277, 0.03436483070254326, -0.029786281287670135, 0.008629790507256985, 0.01711810939013958, -0.0014733985299244523]"
  },
  {
    "objectID": "gpt-security.html",
    "href": "gpt-security.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 챗GPT 보안사고\n보안 vs 효율 을 높고 많은 공공기관을 비롯한 기업들이 고민을 하고 있다. 거대언어모형(LLM)에 기반하여 모든 것을 자체 개발하면 상관이 없으나 현실적으로 GPT-3/3.5/4 모형을 갖춘 조직이 전무하지만, 이미 대다수의 사람이 오픈AI 챗GPT를 맛보았기 때문에 생산성 향상을 그냥 두고 넘어가기도 어려운 상황이다. 이런 점에서 챗GPT 제한적 사용이 현재시점(’23년 3월) 최선으로 보이며 점차 오픈소스 거대언어모형(LLM)과 전략적 제휴를 통한 챗GPT 사용이 중장기적 추진방향으로 자리 잡고 있다.\n이동수 (2023.04.02.), “대기업 회의 내용 유출… ‘챗GPT 기밀 유출’ 우려가 현실로”, 세계일보\n\n\n\n\n\n2 삼성전자\n\n정두용 (2023-03-30), “우려가 현실로…삼성전자, 챗GPT 빗장 풀자마자 ‘오남용’ 속출”, 이코노미스트\n\n\n삼성전자 DS 부문 임직원 A씨는 반도체 설비 계측 데이터베이스(DB) 다운로드 프로그램의 소스 코드를 실행 중 오류를 확인했다. 문제가 된 소스 코드 전부를 복사해 챗GPT에 입력, 해결 방법을 문의했다. 삼성전자 설비 계측과 관련한 소스 코드가 오픈AI 학습 데이터로 입력된 셈이다.\n\n\n임직원 B씨는 수율·불량 설비 파악을 위해 작성한 프로그램 코드를 챗GPT에 입력하는 사고를 냈다. 관련 소스 전체를 챗GPT에 입력하고 코드 최적화를 요청했다. 임직원 C씨는 스마트폰으로 녹음한 회의 내용을 네이버 클로바 애플리케이션(앱)을 통해 문서 파일로 변환한 뒤 챗GPT에 입력했다. 회의록 작성 요청이 목적이다.\n\n\n3 이탈리아\n\n민재용 (2023.04.02), “이탈리아도 챗GPT ‘차단’…서방 국가중 처음”, 한국일보\n\n\n로이터 통신 등에 따르면 이탈리아 데이터 보호청은 “챗GPT가 이탈리아의 개인정보 보호 기준과 규정을 충족할 때까지 서비스 접속을 일시적으로 차단할 것”이라고 밝혔다.\n\n\n접속 차단 이유는 개인정보 침해 우려 때문이다. 이탈리아 당국은 챗GPT가 알고리즘 학습을 이유로, 개인정보를 대량으로 수집하고 저장하는 행위를 정당화할 법적 근거가 없다고 지적했다. 보호청은 챗GPT 개발사 오픈AI가 20일 이내에 해결책을 내놓지 않으면 전 세계 매출액의 최대 4%에 달하는 벌금을 물게 될 것이라고 경고하기도 했다."
  },
  {
    "objectID": "prompt_adv.html",
    "href": "prompt_adv.html",
    "title": "chatGPT",
    "section": "",
    "text": "The hottest new programming language is English\n\n— Andrej Karpathy ((karpathy?)) January 24, 2023\n\n기계학습과 예전 신경망 모형이 특정 작업을 위해 설계된 특수 목적의 컴퓨터라면, GPT는 자연어 프로그램을 실행하기 위해 런타임에 재구성되는 범용 컴퓨터다. 처음 프롬프트[일종의 시작(inception)]가 프로그램 형태로 제공되고, 거대언어모형(GPT)는 문서를 완성하도록 프로그램을 실행한다.\n\n1 Few-Shot 학습\nGPT-3 논문 (Brown 기타, 2020) 에서 거대언어모형(LLM)이 컨텍스트 내 학습(in-context learning)을 수행하며, 입력:출력 예제를 통해 프롬프트 내에서 다양한 작업을 수행하도록 “프로그래밍”할 수 있음을 시연했다. 즉, 언어 모델을 확장하면 작업별 미세 조정(Fine-tuning) 없이 몇 가지 예제 또는 간단한 지침만으로 수행작업의 성능향상을 기대해볼 수 있다.\n\n\n\n\n전통적인 미세조정(Fine tuning)과 제로샷, 원샷, 퓨샷과 대비하면 명확해진다. 미세조정(Fine tuning)은 전통적인 방법이지만, 제로샷, 원샷, 퓨샷은 순방향으로 작업을 수행하는 모델을 필요로 한다.\n\n\n\n\n\n\n제로샷 학습 예제:\n\n\n\n\n\n작업: 감성 분석 (주어진 텍스트를 긍정적, 부정적, 중립적으로 분류)\n입력: “어제 놀이공원에서 정말 즐거운 하루를 보냈어요!”\n출력: 긍정적 \n\n\n\n\n\n\n\n\n\n원샷 학습 예제:\n\n\n\n\n\n작업: 주어진 텍스트로 설명된 동물 파악하기\n예시: “이 동물은 긴 목과 반점이 특징인데, 아프리카에서 발견할 수 있어요.” 답변: 기린\n입력: “이 동물은 주머니가 있고 호주 원주민이며, 껑충 뛰는 능력으로 유명해요.”\n출력 : 캥거루\n\n\n\n\n\n\n\n\n\n퓨샷 학습 예제:\n\n\n\n\n\n작업: 주어진 문장을 능동태에서 수동태로 바꾸기\n예시 1: “철수가 샌드위치를 먹었다.” 답변: “샌드위치가 철수에게 먹혔다.”\n예시 2: “고양이가 쥐를 쫓았다.” 답변: “쥐가 고양이에게 쫓겼다.”\n입력: “선생님이 학생을 칭찬했다.”\n출력: “학생이 선생님에게 칭찬받았다.”\n\n\n\n\n2 Chain-of-Thought (CoT)\n작업별 예제 없이 거대언어모형(LLM)에 사고의 사슬(Chain of Thought)를 통해 복잡한 다단계 추론이 가능하다. 각 답변 앞에 “단계별로 생각해 봅시다(Let’s think step by step)”를 추가함으로써 산술, 기호 추론, 논리적 추론과 같은 다양한 추론 작업에서 표준 제로샷 프롬프트보다 훨씬 뛰어난 성능을 발휘했다. (Kojima 기타, 2023)\n\n\n\n\nGPT-Turbo, GPT-4 모델은 해당문제를 바로 정확히 풀 수 있으나 Legacy (GPT-3.5)는 CoT 기법을 적용해야 정답을 이끌어낼 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n그림 1: 사고의 사슬(Chain of Thought) 예제\n\n\n명령어 자동 생성 및 선택을 위한 자동 프롬프트 엔지니어(Automatic Prompt Engineer, APE)는 프롬프트 명령(instruction)을 프로그램으로 간주하고 거대언어모형(LLM)이 제안한 대한 선택지를 검색하여 선택한 목적 함수를 최대화하는 명령어를 최적화시킨 다음 선택한 명령어를 다른 LLM을 사용하여 평가하는 방법도 제시되었다. (Zhou 기타, 2023)\n\n3 성과지표 설정\n잘 작성된 프롬프트에는 원하는 목표 성과가 포함되어야 한다. GPT는 최선을 다해 성공을 추구하지 않고 모방만 할 뿐이다. 좋은 결과를 원한다면 달성해야 되는 성공을 명시해야 한다. (Chen 기타, 2021)\n\n\n영문예시 10개\n국문번역 10개\n\n\n\n“Please provide a step-by-step guide on how to achieve top-tier performance in time management and productivity techniques, so I can excel in my personal and professional life.”\n“I aspire to become an exceptional public speaker. Can you offer me comprehensive advice, including tips, tricks, and exercises that will help me develop outstanding presentation skills?”\n“I am determined to become a top-performing sales professional. Share with me the essential skills, strategies, and habits that I must adopt to excel in this competitive field.”\n“I wish to become a highly respected and successful leader. Could you provide insights, examples, and actionable steps to develop strong leadership qualities and excel in any organization?”\n“I desire to master the art of negotiation and achieve win-win outcomes. Please provide me with detailed guidance, best practices, and real-life examples that will enable me to excel in negotiations.”\n“My goal is to become a top performer in project management. Can you outline the key principles, methodologies, and tools that will help me successfully manage projects and exceed expectations?”\n“I aspire to be an excellent writer, able to captivate my audience and inspire them through my words. Please provide me with writing techniques, exercises, and recommendations that will elevate my writing skills to the highest level.”\n“I am determined to achieve peak physical fitness and athletic performance. Share with me the best workout routines, nutrition tips, and mental strategies that will help me reach my full potential as an athlete.”\n“I want to excel in the art of problem-solving and critical thinking. Please provide me with the necessary tools, frameworks, and exercises that will help me become an exceptional problem solver and thinker.”\n“My goal is to become a highly skilled and successful investor. Can you provide me with the most effective strategies, tips, and resources that will enable me to outperform in the world of investing?”\n\n\n“시간 관리 및 생산성 기술에서 최고 수준의 성과를 달성하는 방법에 대한 단계별 가이드를 제공하여 개인 및 직장 생활에서 탁월함을 발휘할 수 있도록 도와주세요.”\n“저는 뛰어난 대중 연설가가 되고 싶습니다. 뛰어난 프레젠테이션 기술을 개발하는 데 도움이 되는 팁, 요령 및 연습 문제를 포함한 포괄적인 조언을 제공해 주시겠습니까?”\n“최고의 성과를 내는 영업 전문가가 되기로 결심했습니다. 경쟁이 치열한 이 분야에서 뛰어난 성과를 내기 위해 반드시 갖춰야 할 필수 기술, 전략 및 습관을 알려주세요.”\n“존경받고 성공적인 리더가 되고 싶습니다. 강력한 리더십 자질을 개발하고 어떤 조직에서든 뛰어난 성과를 낼 수 있는 인사이트, 사례, 실행 가능한 단계를 알려주시겠어요?”\n“협상의 기술을 습득하여 서로 윈윈하는 결과를 얻고 싶습니다. 협상에서 탁월한 능력을 발휘할 수 있도록 자세한 지침, 모범 사례 및 실제 사례를 제공해 주세요.”\n“제 목표는 프로젝트 관리 분야에서 최고의 성과를 내는 것입니다. 프로젝트를 성공적으로 관리하고 기대치를 초과 달성하는 데 도움이 되는 핵심 원칙, 방법론 및 도구를 간략하게 설명해 주시겠습니까?”\n“저는 글을 통해 청중을 사로잡고 영감을 줄 수 있는 훌륭한 작가가 되고 싶습니다. 제 글쓰기 실력을 최고 수준으로 끌어올릴 수 있는 글쓰기 기법, 연습 문제, 권장 사항을 제공해 주세요.”\n“최고의 체력과 운동 능력을 갖추기 위해 노력하고 있습니다. 운동선수로서 제 잠재력을 최대한 발휘하는 데 도움이 될 최고의 운동 루틴, 영양 팁, 정신 전략을 알려주세요.”\n“문제 해결 능력과 비판적 사고력이 뛰어나고 싶습니다. 뛰어난 문제 해결자이자 사상가가 되는 데 도움이 되는 필요한 도구, 프레임워크, 연습 문제를 제공해 주세요.”\n“제 목표는 고도로 숙련되고 성공적인 투자자가 되는 것입니다. 투자 세계에서 뛰어난 성과를 낼 수 있는 가장 효과적인 전략, 팁, 리소스를 제공해 주실 수 있나요?”\n\n\n\n참고 자료: 김민경 (2023. 3. 31.), “프롬프트 엔지니어링, AI라는 도구를 잘 사용하는 방법”, Kakaoenterprise Tech Trend\n\n4 자기 일관성\n기존 사고 사슬(Chain of Thought)의 한계를 넘어서 제시된 자기 일관성(Self-consistency)은 복잡한 추론 문제에서 일반적으로 고유한 정답으로 이어지는 여러 가지 사고 방식을 인정한다는 직관을 활용한다. (Wang 기타, 2023)\n자기 일관성 기법은 다음 3단계를 거쳐 최종 답을 제시한다.\n\n사고의 사슬(CoT) 프롬프트를 사용하여 거대언어모형에 프롬프트 생성한다.\nCoT 프롬프트가 “Greedy Decoding” 최선을 추구하는 반면, 거대언어모형 디코더에서 표본을 추출하여 다양한 추론 경로 집합을 생성한다.\n\n\n추론 경로를 한계화하고 최종 답변 세트에서 가장 일관된 답변을 선택 및 집계하여 제시한다.\n\n\n\n\n\n\n\n\n\n\n\n질문: 제가 6살이었을 때 제 여동생은 제 나이의 절반이었습니다. 지금은 70살입니다. 제 여동생은 몇 살인가요?\n\n\n\n\n\n\n당신이 6살이었을 때 여동생은 당신의 나이의 절반이었으므로, 여동생은 당신보다 3살 어렸습니다. 지금 당신이 70살이니, 여동생은 여전히 당신보다 3살 어립니다. 따라서 여동생은 70 - 3 = 67살입니다.\n\n\n\n\n\n5 Generated Knowledge Prompting\n생성된 지식 프롬프트(Generated Knowledge Prompting)는 몇 번의 데모를 통해 언어 모델에서 질문과 관련된 지식 진술을 이끌어내고, 해당 지식이 있는 다른 언어 모델에 프롬프트를 표시하여 예측을 유도하는 기법이다. (Liu 기타, 2022)\n\n언어 모델에서 질문과 관련된 지식 진술을 생성하기 위해 몇 장면의 데모를 사용.\n제2언어 모델을 사용하여 각 지식 진술에 대해 예측을 한 다음 가장 신뢰도가 높은 예측을 취사선택.\n\n\n\n\n\n\n\nGPT-4\nLegacy (GPT-3.5)\n\n\n\n\n\n\n\n\n\n질문: 골프 게임은 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 것입니다. 예, 아니오?\n\n\n\n\n\n지식: 골프의 목표는 최소한의 스트로크로 일련의 홀을 플레이하는 것입니다. 골프 라운드는 일반적으로 18홀로 구성됩니다. 각 홀은 표준 골프 코스에서 라운드 중 한 번씩 플레이됩니다. 각 스트로크는 1점으로 계산되며, 총 스트로크 수가 게임의 승자를 결정하는 데 사용됩니다.\n\n아니오, 골프의 목표는 다른 사람보다 더 높은 총점을 얻는 것이 아닙니다. 대신, 최소한의 스트로크로 일련의 홀을 완주하는 것이 목표입니다. 골프에서는 각 스트로크가 1점으로 계산되며, 라운드 종료 시점에서 스트로크 수가 가장 적은 선수가 승자로 간주됩니다. 따라서 골프에서는 점수가 낮을수록 좋습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n질문: 골프 게임은 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 것입니다. 예, 아니오?\n\n\n\n\n\n\n예, 골프 게임은 다른 사람보다 더 높은 총점을 얻기 위해 노력하는 게임입니다.\n\n\n\n\n\n\n\n\n6 가상 컴퓨터\n출처: Engraved (3rd December 2022), “Building A Virtual Machine inside ChatGPT”\nChatGPT 내부에서 전체 가상 컴퓨터를 만들어 실행시킬 수 있다. 가상 컴퓨터는 파일 시스템 작동 방식을 이해하고 프로그래밍도 가능하다.\n\n\n\n\n\n\n챗GPT를 가상컴퓨터로 바꾸는 프롬프트\n\n\n\n\n\n“I want you to act as a Linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do no write explanations. Do not type commands unless I instruct you to do so. When I need to tell you something in English I will do so by putting text inside curly brackets {like this}. My first command is pwd.”\n“네가 리눅스 터미널 역할을 해줬으면 좋겠어. 내가 명령을 입력하면 터미널이 표시해야 할 내용을 회신해 주세요. 하나의 고유한 코드 블록 안에 있는 터미널 출력만 회신하고 다른 것은 회신하지 마세요. 설명을 작성하지 마세요. 제가 지시하지 않는 한 명령을 입력하지 마세요. 영어로 설명해야 할 때는 {이렇게}와 같이 중괄호 안에 텍스트를 넣어 설명합니다. 첫 번째 명령은 ls입니다.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 2: 챗GPT 내부 리눅스 가상 컴퓨터\n\n\n\n\n\n\n\n참고문헌\n\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners. https://arxiv.org/abs/2005.14165\n\n\nChen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., & Mordatch, I. (2021). Decision Transformer: Reinforcement Learning via Sequence Modeling. https://arxiv.org/abs/2106.01345\n\n\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. https://arxiv.org/abs/2205.11916\n\n\nLiu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2022). Generated Knowledge Prompting for Commonsense Reasoning. https://arxiv.org/abs/2110.08387\n\n\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. https://arxiv.org/abs/2203.11171\n\n\nZhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large Language Models Are Human-Level Prompt Engineers. https://arxiv.org/abs/2211.01910"
  },
  {
    "objectID": "nlp_LLM.html#대표적인-nlp-작업",
    "href": "nlp_LLM.html#대표적인-nlp-작업",
    "title": "chatGPT",
    "section": "\n1.1 대표적인 NLP 작업",
    "text": "1.1 대표적인 NLP 작업\n숫자가 아닌 텍스트를 통해 가치를 창출할 수 있는 분야가 자연어처리(NLP) 영역이다. 자연어 처리 분야에서 흔히 접하는 대표적인 상위 10가지 NLP으로 다음을 들 수 있다.\n\n감정 분석: 긍정, 부정, 중립 등 주어진 텍스트에 표현된 감정을 파악.\n텍스트 분류: 텍스트 데이터를 미리 정의된 클래스 또는 주제(예: 스포츠, 정치, 연예 등)로 분류.\n개체명 인식(NER): 텍스트 내에서 사람, 조직, 위치, 날짜 등의 명명된 개체(entity)를 식별하고 분류.\n품사(POS) 태깅: 주어진 텍스트의 단어에 문법적 레이블(예: 명사, 동사, 형용사)을 할당.\n의존성 구문 분석: 문장 내 단어 간의 문법 구조와 관계를 식별.\n기계 번역: 영어에서 스페인어로 또는 중국어에서 프랑스어로와 같이 한 언어에서 다른 언어로 텍스트를 번역.\n질의 응답: 자연어로 제기된 질문을 이해하고 답변할 수 있는 시스템을 개발.\n텍스트 요약: 주요 아이디어와 정보를 보존하면서 주어진 텍스트에 대한 간결한 요약을 생성.\n상호참조해결(Coreference Resolution): 텍스트에서 두 개 이상의 단어나 구가 동일한 개체 또는 개념을 지칭하는 경우 식별.\n텍스트 생성: 주어진 입력, 컨텍스트 또는 일련의 조건에 따라 일관되고 의미 있는 텍스트를 생성.\n\n자연어 처리 작업과 작업흐름을 서로 연결하게 되면 다음과 같이 개별적으로 중복되고 분리된 작업을 수행하게 되는 문제가 있다.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;"
  },
  {
    "objectID": "nlp_LLM.html#nlp-기계학습",
    "href": "nlp_LLM.html#nlp-기계학습",
    "title": "chatGPT",
    "section": "\n2.1 NLP 기계학습",
    "text": "2.1 NLP 기계학습\n자연어처리(NLP) 기계학습은 통계모형과 거의 비슷한 작업흐름을 갖는다. 차이점이 있다면 데이터 관계의 설명보다 예측에 더 중점을 둔다는 점이라고 볼 수 있다. 예를 들어, 감성 분석 및 텍스트 분류 등 텍스트를 데이터로 하는 전통적인 자연어 처리 작업은 다음과 같은 작업흐름을 갖게 된다.\n\n\n\n\n\n\ngraph TD\n    A[데이터 수집] --&gt; B[데이터 전처리]\n    B --&gt; C[피쳐 추출]\n    C --&gt; D[훈련-테스트 데이터셋 분할]\n    D --&gt; E[모형 선택]\n    E --&gt; F[모형 학습]\n    F --&gt; G[모형 평가]\n    G --&gt; H[하이퍼파라미터 튜닝]\n    H --&gt; I[모형 배포]\n    I --&gt; J[모니터링 및 유지보수]\n\n\n\n\n\n\n\n데이터 수집: 텍스트 데이터와 해당 레이블이 포함된 데이터셋을 수집한다. 감성 분석의 경우, 라벨은 ‘긍정’, ‘부정’ 또는 ’중립’이 되고, 텍스트 분류의 경우 레이블은 다양한 주제나 카테고리를 나타낼 수 있다. 즉, 자연어 처리 목적에 맞춰 라벨을 특정하고 연관 데이터를 수집한다.\n데이터 전처리: 텍스트 데이터를 정리하고 전처리하여 추가 분석에 적합하도록 작업하는데 소문자화, 토큰화, 불용어 제거, 특수문자 제거, 어간 단어 기본형으로 줄이기 등이 포함된다.\n피쳐 추출:사전 처리된 텍스트를 기계 학습 알고리즘에 적합한 숫자 형식으로 변환하는 과정으로 BoW, TF-IDF, 단어 임베딩 등이 흔히 사용되는 기법이다.\n훈련-시험 데이터셋 분할: 일반적으로 70-30, 80-20 또는 기타 원하는 분할 비율을 사용하여 데이터셋을 훈련과 시험 데이터셋으로 구분한다.\n모형 선택: 적합한 통계, 머신 러닝, 딥러닝 모델을 선정한다.\n모형 학습: 적절한 최적화 알고리즘과 손실 함수를 사용하여 훈련 데이터셋에서 선택한 모델을 학습시킨다.\n모형 평가: 정확도, 정밀도, 리콜, F1 점수 또는 ROC 곡선 아래 영역과 같은 관련 메트릭을 사용하여 시험 데이터셋에서 학습 모형의 성능을 평가한다.\n하이퍼파라미터 튜닝: 격자 검색 또는 무작위 검색과 같은 기술을 사용하여 모형의 하이퍼파라미터를 최적화하여 성능을 개선한다.\n모형 배포: 모형을 학습하고 최적화한 후에는 실제 환경에서 사용할 수 있도록 실제 운영 환경에 배포하여 가치를 창출한다.\n모니터링 및 유지 관리: 배포된 모형의 성능을 지속적으로 모니터링하고 필요에 따라 새로운 학습데이터로 업데이트하여 정확성과 효율성을 유지한다."
  },
  {
    "objectID": "nlp_LLM.html#nlp-vs-llm",
    "href": "nlp_LLM.html#nlp-vs-llm",
    "title": "chatGPT",
    "section": "\n3.1 NLP vs LLM",
    "text": "3.1 NLP vs LLM\n지구상의 거의 모든 텍스트 데이터를 학습한 거대언어모형(LLM)이 존재하는 상황이기 때문에 적절한 LLM을 선택한 후에 좀더 성능을 높이기 위해서 추가 학습데이터를 수집하여 미세조정(Fine-tuning) 학습을 거친 후에 AI 모형을 배포하여 운영한다.\n\n\n\n\ngraph TB\n\nsubgraph \"전통적인 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nsubgraph \"거대언어기반 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "nlp_LLM.html#fine-tuning-llm-vs-prompt-eng.",
    "href": "nlp_LLM.html#fine-tuning-llm-vs-prompt-eng.",
    "title": "chatGPT",
    "section": "\n3.2 Fine-tuning LLM vs Prompt Eng.",
    "text": "3.2 Fine-tuning LLM vs Prompt Eng.\n두가지 접근방법 모두 거대언어모형(LLM)에 기반한다는 점에서 동일하나, 추가학습 데이터를 반영한 AI 모형을 개발하느냐 아니면 프롬프트(일명 AI 프로그램)를 잘 작성한 AI 모형을 개발하느냐 차이가 존재한다. 물론 Zero-/One-/Few-Shot 예제를 반영한 프롬프트도 있고 미세조정 훈련모형에 프롬프트를 반영한 AI 모형도 존재한다. 각 문제에 맞춰 적절한 개발방법을 취하면 될 것이다.\n\n\n\n\ngraph TB\nsubgraph \"미세조정 작업흐름&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[사전 훈련] --&gt; B1[미세 조정]\n  B1 --&gt; C1[모델 훈련 및 평가]\n  C1 --&gt; D1[하이퍼파라미터 튜닝]\n  D1 --&gt; E1[배포 및 유지보수]\nend\n\nsubgraph \"프롬프트 공학 작업흐름&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[사전 학습] --&gt; B2[프롬프트 설계]\n  B2 --&gt; C2[모델 추론 및 후처리]\n  C2 --&gt; D2[모델 평가]\n  D2 --&gt; E2[배포 및 유지보수]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "nlp_LLM.html#비교-1",
    "href": "nlp_LLM.html#비교-1",
    "title": "chatGPT",
    "section": "\n3.3 비교",
    "text": "3.3 비교\nLLM 모형을 오픈소스 소프트웨어 공개하는 경우 이를 돌릴 수 있는 강력한 하드웨어가 필요하기도 하고, LLM을 비공개하는 경우 구독형으로 비용을 청구하여 AI 서비스를 제공하는 경우도 존재한다. 해당 문제를 가장 잘 해결할 수 있는 AI 개발방법론을 주어진 제약조건에서 장단점을 비교하여 풀어가면 좋은 결과가 기대된다.\n\n\n\n\n\n\n\n\nPerspective\nTraditional NLP\nLLM Fine-tuning\nLLM Prompt Engineering\n\n\n\nModel Adaptation\nFeature extraction and model selection\nFine-tuning on task-specific data\nCrafting effective prompts\n\n\nLabeled Data Requirements\nRequires labeled data for model training\nRequires labeled data for fine-tuning\nRequires fewer labeled examples, if any\n\n\nComputational Resources\nCan vary, but generally lower than LLM Fine-tuning\nHigher due to fine-tuning\nLower, as fine-tuning is not required\n\n\nPerformance\nMay be lower than LLM-based approaches\nTypically better due to task-specific fine-tuning\nCompetitive, but may require more manual effort\n\n\nEffort and Creativity\nRequires more manual feature engineering\nRequires less manual effort in prompt design\nRequires more creativity in prompt design and iteration\n\n\nDomain Adaptation\nLess effective for domain-specific tasks\nMore effective for domain-specific tasks\nMay be limited by the pretrained model’s knowledge\n\n\nInterpretability\nMore interpretable due to handcrafted features and models\nLess interpretable due to fine-tuned model weights\nMore interpretable as output is guided by designed prompts\n\n\nDeployment and Maintenance\nRequires storing and maintaining custom models\nRequires storing and maintaining fine-tuned models\nEasier, as only pretrained model and prompts are needed\n\n\nWhen to Use\nWhen custom features are needed or LLMs are not available\nWhen labeled data is available, higher performance is desired, and computational resources are sufficient\nWhen labeled data is scarce, computational resources are limited, or rapid development and iteration are required"
  },
  {
    "objectID": "inaugural.html#대표적인-nlp-작업",
    "href": "inaugural.html#대표적인-nlp-작업",
    "title": "chatGPT",
    "section": "\n1.1 대표적인 NLP 작업",
    "text": "1.1 대표적인 NLP 작업\n숫자가 아닌 텍스트를 통해 가치를 창출할 수 있는 분야가 자연어처리(NLP) 영역이다. 자연어 처리 분야에서 흔히 접하는 대표적인 상위 10가지 NLP으로 다음을 들 수 있다.\n\n감정 분석: 긍정, 부정, 중립 등 주어진 텍스트에 표현된 감정을 파악.\n텍스트 분류: 텍스트 데이터를 미리 정의된 클래스 또는 주제(예: 스포츠, 정치, 연예 등)로 분류.\n개체명 인식(NER): 텍스트 내에서 사람, 조직, 위치, 날짜 등의 명명된 개체(entity)를 식별하고 분류.\n품사(POS) 태깅: 주어진 텍스트의 단어에 문법적 레이블(예: 명사, 동사, 형용사)을 할당.\n의존성 구문 분석: 문장 내 단어 간의 문법 구조와 관계를 식별.\n기계 번역: 영어에서 스페인어로 또는 중국어에서 프랑스어로와 같이 한 언어에서 다른 언어로 텍스트를 번역.\n질의 응답: 자연어로 제기된 질문을 이해하고 답변할 수 있는 시스템을 개발.\n텍스트 요약: 주요 아이디어와 정보를 보존하면서 주어진 텍스트에 대한 간결한 요약을 생성.\n상호참조해결(Coreference Resolution): 텍스트에서 두 개 이상의 단어나 구가 동일한 개체 또는 개념을 지칭하는 경우 식별.\n텍스트 생성: 주어진 입력, 컨텍스트 또는 일련의 조건에 따라 일관되고 의미 있는 텍스트를 생성.\n\n자연어 처리 작업과 작업흐름을 서로 연결하게 되면 다음과 같이 개별적으로 중복되고 분리된 작업을 수행하게 되는 문제가 있다.\n\n\n\n\ngraph LR\nA[\"Data Collection &lt;br&gt; Preprocessing\"] --&gt; B[\"Feature Extraction &lt;br&gt; Model Training\"]\nB --&gt; C[\"Model Evaluation &lt;br&gt; Tuning\"]\nC --&gt; D[\"Model Deployment &lt;br&gt; Maintenance\"]\n\nD --&gt; T1[1. Sentiment Analysis]\nD --&gt; T2[2. Text Classification]\nD --&gt; T3[3. Named Entity Recognition]\nD --&gt; T4[4. Part-of-Speech Tagging]\nD --&gt; T5[5. Dependency Parsing]\nD --&gt; T6[6. Machine Translation]\nD --&gt; T7[7. Question Answering]\nD --&gt; T8[8. Text Summarization]\nD --&gt; T9[9. Coreference Resolution]\nD --&gt; T10[10. Text Generation]\n\nclass A,B,C,D nodeStyle\nclass T1,T2,T3,T4,T5,T6,T7,T8,T9,T10 taskStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:14px;\nclassDef taskStyle fill:#fdfd96,stroke:#000000,stroke-width:0.7px,font-weight:bold,font-size:12px;"
  },
  {
    "objectID": "inaugural.html#nlp-기계학습",
    "href": "inaugural.html#nlp-기계학습",
    "title": "chatGPT",
    "section": "\n2.1 NLP 기계학습",
    "text": "2.1 NLP 기계학습\n자연어처리(NLP) 기계학습은 통계모형과 거의 비슷한 작업흐름을 갖는다. 차이점이 있다면 데이터 관계의 설명보다 예측에 더 중점을 둔다는 점이라고 볼 수 있다. 예를 들어, 감성 분석 및 텍스트 분류 등 텍스트를 데이터로 하는 전통적인 자연어 처리 작업은 다음과 같은 작업흐름을 갖게 된다.\n\n\n\n\n\n\ngraph TD\n    A[데이터 수집] --&gt; B[데이터 전처리]\n    B --&gt; C[피쳐 추출]\n    C --&gt; D[훈련-테스트 데이터셋 분할]\n    D --&gt; E[모형 선택]\n    E --&gt; F[모형 학습]\n    F --&gt; G[모형 평가]\n    G --&gt; H[하이퍼파라미터 튜닝]\n    H --&gt; I[모형 배포]\n    I --&gt; J[모니터링 및 유지보수]\n\n\n\n\n\n\n\n데이터 수집: 텍스트 데이터와 해당 레이블이 포함된 데이터셋을 수집한다. 감성 분석의 경우, 라벨은 ‘긍정’, ‘부정’ 또는 ’중립’이 되고, 텍스트 분류의 경우 레이블은 다양한 주제나 카테고리를 나타낼 수 있다. 즉, 자연어 처리 목적에 맞춰 라벨을 특정하고 연관 데이터를 수집한다.\n데이터 전처리: 텍스트 데이터를 정리하고 전처리하여 추가 분석에 적합하도록 작업하는데 소문자화, 토큰화, 불용어 제거, 특수문자 제거, 어간 단어 기본형으로 줄이기 등이 포함된다.\n피쳐 추출:사전 처리된 텍스트를 기계 학습 알고리즘에 적합한 숫자 형식으로 변환하는 과정으로 BoW, TF-IDF, 단어 임베딩 등이 흔히 사용되는 기법이다.\n훈련-시험 데이터셋 분할: 일반적으로 70-30, 80-20 또는 기타 원하는 분할 비율을 사용하여 데이터셋을 훈련과 시험 데이터셋으로 구분한다.\n모형 선택: 적합한 통계, 머신 러닝, 딥러닝 모델을 선정한다.\n모형 학습: 적절한 최적화 알고리즘과 손실 함수를 사용하여 훈련 데이터셋에서 선택한 모델을 학습시킨다.\n모형 평가: 정확도, 정밀도, 리콜, F1 점수 또는 ROC 곡선 아래 영역과 같은 관련 메트릭을 사용하여 시험 데이터셋에서 학습 모형의 성능을 평가한다.\n하이퍼파라미터 튜닝: 격자 검색 또는 무작위 검색과 같은 기술을 사용하여 모형의 하이퍼파라미터를 최적화하여 성능을 개선한다.\n모형 배포: 모형을 학습하고 최적화한 후에는 실제 환경에서 사용할 수 있도록 실제 운영 환경에 배포하여 가치를 창출한다.\n모니터링 및 유지 관리: 배포된 모형의 성능을 지속적으로 모니터링하고 필요에 따라 새로운 학습데이터로 업데이트하여 정확성과 효율성을 유지한다."
  },
  {
    "objectID": "inaugural.html#nlp-vs-llm",
    "href": "inaugural.html#nlp-vs-llm",
    "title": "chatGPT",
    "section": "\n3.1 NLP vs LLM",
    "text": "3.1 NLP vs LLM\n지구상의 거의 모든 텍스트 데이터를 학습한 거대언어모형(LLM)이 존재하는 상황이기 때문에 적절한 LLM을 선택한 후에 좀더 성능을 높이기 위해서 추가 학습데이터를 수집하여 미세조정(Fine-tuning) 학습을 거친 후에 AI 모형을 배포하여 운영한다.\n\n\n\n\ngraph TB\n\nsubgraph \"전통적인 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A1[Data Collection & Preprocessing] --&gt; B1[Feature Extraction & Model Selection]\n  B1 --&gt; C1[Model Training & Evaluation]\n  C1 --&gt; D1[Hyperparameter Tuning]\n  D1 --&gt; E1[Deployment & Maintenance]\nend\n\nsubgraph \"거대언어기반 NLP 작업흐름 &lt;br&gt;\"\ndirection TB\n  A2[Pretraining] --&gt; B2[Fine-tuning]\n  B2 --&gt; C2[Model Training & Evaluation]\n  C2 --&gt; D2[Hyperparameter Tuning]\n  D2 --&gt; E2[Deployment & Maintenance]\nend\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#ffffff,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "inaugural.html#fine-tuning-llm-vs-prompt-eng.",
    "href": "inaugural.html#fine-tuning-llm-vs-prompt-eng.",
    "title": "chatGPT",
    "section": "\n3.2 Fine-tuning LLM vs Prompt Eng.",
    "text": "3.2 Fine-tuning LLM vs Prompt Eng.\n두가지 접근방법 모두 거대언어모형(LLM)에 기반한다는 점에서 동일하나, 추가학습 데이터를 반영한 AI 모형을 개발하느냐 아니면 프롬프트(일명 AI 프로그램)를 잘 작성한 AI 모형을 개발하느냐 차이가 존재한다. 물론 Zero-/One-/Few-Shot 예제를 반영한 프롬프트도 있고 미세조정 훈련모형에 프롬프트를 반영한 AI 모형도 존재한다. 각 문제에 맞춰 적절한 개발방법을 취하면 될 것이다.\n\n\n\n\ngraph TB\nsubgraph \"미세조정 작업흐름&lt;br&gt;LLM-based Fine-tuning Workflow\"\n  direction TB\n  A1[사전 훈련] --&gt; B1[미세 조정]\n  B1 --&gt; C1[모델 훈련 및 평가]\n  C1 --&gt; D1[하이퍼파라미터 튜닝]\n  D1 --&gt; E1[배포 및 유지보수]\nend\n\nsubgraph \"프롬프트 공학 작업흐름&lt;br&gt;Prompt Engineering Workflow\"\n  direction TB\n  A2[사전 학습] --&gt; B2[프롬프트 설계]\n  B2 --&gt; C2[모델 추론 및 후처리]\n  C2 --&gt; D2[모델 평가]\n  D2 --&gt; E2[배포 및 유지보수]\nend\n\n\nclass A1,B1,C1,D1,E1,A2,B2,C2,D2,E2 nodeStyle\n\nclassDef nodeStyle fill:#93c47d,stroke:#000000,stroke-width:1px,font-weight:bold,font-size:14px;"
  },
  {
    "objectID": "inaugural.html#비교-1",
    "href": "inaugural.html#비교-1",
    "title": "chatGPT",
    "section": "\n3.3 비교",
    "text": "3.3 비교\nLLM 모형을 오픈소스 소프트웨어 공개하는 경우 이를 돌릴 수 있는 강력한 하드웨어가 필요하기도 하고, LLM을 비공개하는 경우 구독형으로 비용을 청구하여 AI 서비스를 제공하는 경우도 존재한다. 해당 문제를 가장 잘 해결할 수 있는 AI 개발방법론을 주어진 제약조건에서 장단점을 비교하여 풀어가면 좋은 결과가 기대된다.\n\n\n\n\n\n\n\n\nPerspective\nTraditional NLP\nLLM Fine-tuning\nLLM Prompt Engineering\n\n\n\nModel Adaptation\nFeature extraction and model selection\nFine-tuning on task-specific data\nCrafting effective prompts\n\n\nLabeled Data Requirements\nRequires labeled data for model training\nRequires labeled data for fine-tuning\nRequires fewer labeled examples, if any\n\n\nComputational Resources\nCan vary, but generally lower than LLM Fine-tuning\nHigher due to fine-tuning\nLower, as fine-tuning is not required\n\n\nPerformance\nMay be lower than LLM-based approaches\nTypically better due to task-specific fine-tuning\nCompetitive, but may require more manual effort\n\n\nEffort and Creativity\nRequires more manual feature engineering\nRequires less manual effort in prompt design\nRequires more creativity in prompt design and iteration\n\n\nDomain Adaptation\nLess effective for domain-specific tasks\nMore effective for domain-specific tasks\nMay be limited by the pretrained model’s knowledge\n\n\nInterpretability\nMore interpretable due to handcrafted features and models\nLess interpretable due to fine-tuned model weights\nMore interpretable as output is guided by designed prompts\n\n\nDeployment and Maintenance\nRequires storing and maintaining custom models\nRequires storing and maintaining fine-tuned models\nEasier, as only pretrained model and prompts are needed\n\n\nWhen to Use\nWhen custom features are needed or LLMs are not available\nWhen labeled data is available, higher performance is desired, and computational resources are sufficient\nWhen labeled data is scarce, computational resources are limited, or rapid development and iteration are required"
  },
  {
    "objectID": "inaugural.html",
    "href": "inaugural.html",
    "title": "chatGPT",
    "section": "",
    "text": "임베딩(embedding)은 개념을 숫자 시퀀스로 변환한 수치 표현으로, 컴퓨터가 개념 간의 관계를 쉽게 이해할 수 있도록 한다. 이를 통해서 기존에 개별적으로 수행했던 작업을 통합적으로 추진하는 것이 가능하게 되었다. 수치적으로 유사한 임베딩은 의미적으로도 유사하기 때문에 임베딩을 통해서 텍스트를 유사한 것으로 모으는 군집분석이나 문서 검색과 같은 NLP 작업이 수월해졌다.\nOpenAI에서 텍스트 유사도, 텍스트 검색, 코드 검색용으로 세가지 모델을 공개했다.1 2022년 12월 5일 공개된 text-embedding-ada-002 모형은 텍스트 검색, 텍스트 유사도 및 코드 검색을 위한 5개 개별 모델을 대체하며, 대부분의 작업에서 이전 최고 성능 모델인 다빈치보다 성능이 뛰어나면서도 가격은 99.8% 저렴하기 때문에 text-embedding-ada-002 모형을 중심으로 살펴보면 된다. 2 텍스트 분류에서만 text-similarity-*davinci*-001 모형보다 성능이 다소 떨어지고 나머지 분야에서는 모두 앞선 성능을 나타내면서도 가격이 저렴하다. 3"
  },
  {
    "objectID": "inaugural.html#파파고",
    "href": "inaugural.html#파파고",
    "title": "chatGPT",
    "section": "\n2.1 파파고",
    "text": "2.1 파파고\n\n코드\ntranslate_papago &lt;- function(text, source=\"ko\", target=\"en\") {\n\n  transURL &lt;- \"https://openapi.naver.com/v1/papago/n2mt\"\n\n  response &lt;- transURL %&gt;%\n    httr::POST(\n      httr::add_headers(\n        \"Content-Type\"          = \"application/x-www-form-urlencoded; charset=UTF-8\",\n        \"X-Naver-Client-Id\"     = Sys.getenv('NAVER_CLIENT_ID'),\n        \"X-Naver-Client-Secret\" = Sys.getenv('NAVER_CLIENT_SECRET')\n      ),\n      body = glue::glue(\"text={text}&source={source}&target={target}\")\n    ) %&gt;%\n    toString() %&gt;%\n    jsonlite::fromJSON()\n  \n  Sys.sleep(1)\n\n  response$message$result$translatedText\n}\n\ntranlated &lt;- fs::dir_ls(\"data/Inaugural-eng/\")\n\ntranslated_tbl &lt;- tranlated %&gt;% \n  enframe(name = \"파일경로\") %&gt;% \n  separate(value, into = c(\"역대\", \"대통령\"), sep=\"_\") %&gt;% \n  mutate(대통령 = str_remove(대통령, \"\\\\.txt\")) %&gt;% \n  mutate(영문번역 = map(파일경로, read_lines)) %&gt;% \n  mutate(영문번역 = map_chr(영문번역, paste0, collapse = \" \")) %&gt;% \n  select(역대, 대통령, 영문번역) %&gt;% \n  mutate(영문번역 = str_squish(영문번역)) %&gt;% \n  mutate(영문번역 = str_replace_all(영문번역, \"ㆍ\", \", \"))\n\n\ntranslated_tbl\n#&gt; # A tibble: 13 × 3\n#&gt;    역대                      대통령 영문번역                                    \n#&gt;    &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;                                       \n#&gt;  1 data/Inaugural-eng/제03대 이승만 \"My fellow countrymen and women. Today I st…\n#&gt;  2 data/Inaugural-eng/제04대 윤보선 \"My excitement yesterday at being honored a…\n#&gt;  3 data/Inaugural-eng/제09대 박정희 \"Dear 50 million compatriots! And distingui…\n#&gt;  4 data/Inaugural-eng/제10대 최규하 \"Dear compatriots at home and abroad! And d…\n#&gt;  5 data/Inaugural-eng/제12대 전두환 \"Dear compatriots at home and abroad! And d…\n#&gt;  6 data/Inaugural-eng/제13대 노태우 \"Dear 60 million compatriots at home and ab…\n#&gt;  7 data/Inaugural-eng/제14대 김영삼 \"Dear 70 million compatriots at home and ab…\n#&gt;  8 data/Inaugural-eng/제15대 김대중 \"Honored and beloved citizens of the Republ…\n#&gt;  9 data/Inaugural-eng/제16대 노무현 \"Honorable fellow citizens. Today I stand h…\n#&gt; 10 data/Inaugural-eng/제17대 이명박 \"Honored citizens! 7 million overseas Korea…\n#&gt; 11 data/Inaugural-eng/제18대 박근혜 \"We will usher in a new era of hope. Honora…\n#&gt; 12 data/Inaugural-eng/제19대 문재인 \"My honored and beloved people! Thank you. …\n#&gt; 13 data/Inaugural-eng/제20대 윤석열 \"My honored and beloved countrymen, our 7.5…\n\n\n\n코드translated_embedding &lt;- translated_tbl %&gt;% \n  mutate(임베딩 = map(영문번역, get_embedding))\n\ntranslated_embedding %&gt;% \n  write_rds(\"data/translated_embedding.rds\")\n\n\n\n코드translated_embedding &lt;- \n  read_rds(\"data/translated_embedding.rds\")\n\ntranslated_mat &lt;- matrix(\n  unlist(translated_embedding$임베딩), \n  ncol = 1536, byrow = TRUE\n)\n\ndim(translated_mat)\n#&gt; [1]   13 1536\n\ntranslated_similarity &lt;- translated_mat / sqrt(rowSums(translated_mat * translated_mat))\ntranslated_similarity &lt;- translated_similarity %*% t(translated_similarity)\ndim(translated_similarity)\n#&gt; [1] 13 13\n\nenframe(translated_similarity[13,], name = \"연설문\", value = \"유사도\") %&gt;%\n  arrange(-유사도)\n#&gt; # A tibble: 13 × 2\n#&gt;    연설문 유사도\n#&gt;     &lt;int&gt;  &lt;dbl&gt;\n#&gt;  1     13  1.00 \n#&gt;  2     10  0.924\n#&gt;  3      7  0.922\n#&gt;  4      1  0.922\n#&gt;  5      6  0.920\n#&gt;  6      8  0.918\n#&gt;  7      4  0.914\n#&gt;  8      5  0.914\n#&gt;  9      9  0.914\n#&gt; 10     11  0.908\n#&gt; 11      2  0.905\n#&gt; 12     12  0.899\n#&gt; 13      3  0.894\n\nset.seed(777)\ntranslated_pca &lt;- irlba::prcomp_irlba(translated_mat, n = 3)\n\ntranslated_pca_tbl &lt;- \n  as_tibble(translated_pca$x) %&gt;%\n  bind_cols(translated_embedding)\n\ntranslated_pca_tbl %&gt;%\n  ggplot(aes(PC1, PC2)) +\n    geom_point(size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=대통령)) +\n    theme_bw(base_family=\"NanumGothic\")\n\n\n\n\n\n\n코드\nsummary(translated_pca)\n#&gt; Importance of components:\n#&gt;                           PC1    PC2     PC3\n#&gt; Standard deviation     0.1087 0.1033 0.09497\n#&gt; Proportion of Variance 0.1719 0.1551 0.13111\n#&gt; Cumulative Proportion  0.1719 0.3269 0.45805\n\n\n\n코드library(umap)\ntranslated_umap &lt;- umap(translated_mat, n_neighbors = 3)\n\ntranslated_viz &lt;- translated_umap$layout %&gt;%\n  as.data.frame()%&gt;%\n  rename(UMAP1=\"V1\",\n         UMAP2=\"V2\") %&gt;% \n  bind_cols(translated_embedding)\n\numap_df %&gt;% names()\n#&gt; [1] \"UMAP1\"  \"UMAP2\"  \"역대\"   \"대통령\" \"취임사\" \"임베딩\"\n\ntranslated_viz %&gt;%\n  ggplot(aes(x = UMAP1, \n             y = UMAP2))+\n    geom_point(size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=대통령)) +\n    theme_bw(base_family=\"NanumGothic\")"
  },
  {
    "objectID": "inaugural.html#국문-취임사",
    "href": "inaugural.html#국문-취임사",
    "title": "chatGPT",
    "section": "\n2.1 국문 취임사",
    "text": "2.1 국문 취임사\n행정안전부 대통령기록관 기록컬렉션 연설기록에서 역대 대통령의 취임사를 텍스트 형태로 다운로드 받을 수 있다. 이승만, 박정희, 전두환 대통령의 경우 2회 이상 대통령을 역임했기 때문에 가장 마지막 취임사를 받아온다.\n\n코드library(tidyverse)\n\npresidents &lt;- fs::dir_ls(\"data/Inaugural/\")\n\ninaugural_tbl &lt;- presidents %&gt;% \n  enframe(name = \"파일경로\") %&gt;% \n  separate(value, into = c(\"역대\", \"대통령\"), sep=\"_\") %&gt;% \n  mutate(대통령 = str_remove(대통령, \"\\\\.txt\")) %&gt;% \n  mutate(취임사 = map(파일경로, read_lines)) %&gt;% \n  mutate(취임사 = map_chr(취임사, paste0, collapse = \" \")) %&gt;% \n  select(역대, 대통령, 취임사) %&gt;% \n  mutate(취임사 = str_squish(취임사)) %&gt;% \n  mutate(취임사 = str_replace_all(취임사, \"ㆍ\", \", \"))\n\ninaugural_tbl\n#&gt; # A tibble: 13 × 3\n#&gt;    역대                  대통령 취임사                                          \n#&gt;    &lt;chr&gt;                 &lt;chr&gt;  &lt;chr&gt;                                           \n#&gt;  1 data/Inaugural/제03대 이승만 \"나의 사랑하는 동포 여러분. 내가 오늘 또 한번 … \n#&gt;  2 data/Inaugural/제04대 윤보선 \"제2공화국의 초대대통령으로 영예의 당선을 얻은 …\n#&gt;  3 data/Inaugural/제09대 박정희 \"친애하는 5천만 동포 여러분! 그리고 내외 귀빈 … \n#&gt;  4 data/Inaugural/제10대 최규하 \"친애하는 국내외 동포 여러분! 그리고 이 자리를 …\n#&gt;  5 data/Inaugural/제12대 전두환 \"친애하는 국내외 동포 여러분! 그리고 이 자리를 …\n#&gt;  6 data/Inaugural/제13대 노태우 \"친애하는 6천만 국내외 동포 여러분. 우리 헌정발…\n#&gt;  7 data/Inaugural/제14대 김영삼 \"친애하는 7천만 국내외 동포 여러분, 노태우 대통…\n#&gt;  8 data/Inaugural/제15대 김대중 \"존경하고 사랑하는 국민 여러분! 오늘 저는 대한… \n#&gt;  9 data/Inaugural/제16대 노무현 \"존경하는 국민 여러분. 오늘 저는 대한민국의 제1…\n#&gt; 10 data/Inaugural/제17대 이명박 \"존경하는 국민 여러분! 700만 해외동포 여러분, … \n#&gt; 11 data/Inaugural/제18대 박근혜 \"희망의 새 시대를 열겠습니다. 존경하는 국민여러…\n#&gt; 12 data/Inaugural/제19대 문재인 \"존경하고 사랑하는 국민 여러분! 감사합니다. 국… \n#&gt; 13 data/Inaugural/제20대 윤석열 \"존경하고 사랑하는 국민 여러분, 750만 재외동포 …"
  },
  {
    "objectID": "inaugural.html#딥엘-영문-취임사",
    "href": "inaugural.html#딥엘-영문-취임사",
    "title": "chatGPT",
    "section": "\n2.2 [딥엘] 영문 취임사",
    "text": "2.2 [딥엘] 영문 취임사\n파파고 API를 사용하여 번역작업을 진행할 수 있으나 일 50,000글자로 제한이 있고 추가 비용을 지불하는 금전적인 문제도 있고 딥엘(DeepL) 보다 번역품질에서 낫기 때문에 기본 코드만 작성해 둔다. 번역품질이 최상은 아니지만 일반적인 번역 품질에는 큰 차이는 없다.\n\n코드translate_papago &lt;- function(text, source=\"ko\", target=\"en\") {\n\n  transURL &lt;- \"https://openapi.naver.com/v1/papago/n2mt\"\n\n  response &lt;- transURL %&gt;%\n    httr::POST(\n      httr::add_headers(\n        \"Content-Type\"          = \"application/x-www-form-urlencoded; charset=UTF-8\",\n        \"X-Naver-Client-Id\"     = Sys.getenv('NAVER_CLIENT_ID'),\n        \"X-Naver-Client-Secret\" = Sys.getenv('NAVER_CLIENT_SECRET')\n      ),\n      body = glue::glue(\"text={text}&source={source}&target={target}\")\n    ) %&gt;%\n    toString() %&gt;%\n    jsonlite::fromJSON()\n  \n  Sys.sleep(1)\n\n  response$message$result$translatedText\n}\n\ntranlated &lt;- fs::dir_ls(\"data/Inaugural-eng/\")\n\ntranslated_tbl &lt;- tranlated %&gt;% \n  enframe(name = \"파일경로\") %&gt;% \n  separate(value, into = c(\"역대\", \"대통령\"), sep=\"_\") %&gt;% \n  mutate(대통령 = str_remove(대통령, \"\\\\.txt\")) %&gt;% \n  mutate(영문번역 = map(파일경로, read_lines)) %&gt;% \n  mutate(영문번역 = map_chr(영문번역, paste0, collapse = \" \")) %&gt;% \n  select(역대, 대통령, 영문번역) %&gt;% \n  mutate(영문번역 = str_squish(영문번역)) %&gt;% \n  mutate(영문번역 = str_replace_all(영문번역, \"ㆍ\", \", \"))\n\n# DeepL 번역 결과\ntranslated_tbl\n#&gt; # A tibble: 13 × 3\n#&gt;    역대                      대통령 영문번역                                    \n#&gt;    &lt;chr&gt;                     &lt;chr&gt;  &lt;chr&gt;                                       \n#&gt;  1 data/Inaugural-eng/제03대 이승만 \"My fellow countrymen and women. Today I st…\n#&gt;  2 data/Inaugural-eng/제04대 윤보선 \"My excitement yesterday at being honored a…\n#&gt;  3 data/Inaugural-eng/제09대 박정희 \"Dear 50 million compatriots! And distingui…\n#&gt;  4 data/Inaugural-eng/제10대 최규하 \"Dear compatriots at home and abroad! And d…\n#&gt;  5 data/Inaugural-eng/제12대 전두환 \"Dear compatriots at home and abroad! And d…\n#&gt;  6 data/Inaugural-eng/제13대 노태우 \"Dear 60 million compatriots at home and ab…\n#&gt;  7 data/Inaugural-eng/제14대 김영삼 \"Dear 70 million compatriots at home and ab…\n#&gt;  8 data/Inaugural-eng/제15대 김대중 \"Honored and beloved citizens of the Republ…\n#&gt;  9 data/Inaugural-eng/제16대 노무현 \"Honorable fellow citizens. Today I stand h…\n#&gt; 10 data/Inaugural-eng/제17대 이명박 \"Honored citizens! 7 million overseas Korea…\n#&gt; 11 data/Inaugural-eng/제18대 박근혜 \"We will usher in a new era of hope. Honora…\n#&gt; 12 data/Inaugural-eng/제19대 문재인 \"My honored and beloved people! Thank you. …\n#&gt; 13 data/Inaugural-eng/제20대 윤석열 \"My honored and beloved countrymen, our 7.5…"
  },
  {
    "objectID": "inaugural.html#영문-취임사",
    "href": "inaugural.html#영문-취임사",
    "title": "chatGPT",
    "section": "\n2.3 영문 취임사",
    "text": "2.3 영문 취임사\n최근 대통령 취임사는 외교부나 구글 인터넷 검색을 통해 영문으로 취임사를 구할 수 있다.\n\n코드eng_inaugural &lt;- fs::dir_ls(\"data/inaugural-mofa/\")\n\ninaugural_eng_tbl &lt;- eng_inaugural %&gt;% \n  enframe(name = \"파일경로\") %&gt;% \n  separate(value, into = c(\"역대\", \"대통령\"), sep=\"_\") %&gt;% \n  mutate(대통령 = str_remove(대통령, \"\\\\.txt\")) %&gt;% \n  mutate(영문취임사 = map(파일경로, read_lines)) %&gt;% \n  mutate(영문취임사 = map_chr(영문취임사, paste0, collapse = \" \")) %&gt;%   \n  mutate(연설문길이 = str_length(영문취임사)) %&gt;% \n  filter(연설문길이 &gt; 1000) %&gt;% \n  select(역대, 대통령, 영문취임사) %&gt;% \n  mutate(영문취임사 = str_squish(영문취임사)) \n\n# 영어취임사\ninaugural_eng_tbl\n#&gt; # A tibble: 5 × 3\n#&gt;   역대                       대통령 영문취임사                                  \n#&gt;   &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt;                                       \n#&gt; 1 data/inaugural-mofa/제15대 김대중 \"My fellow countrymen, Today, I am being in…\n#&gt; 2 data/inaugural-mofa/제17대 이명박 \"Together We Shall Open, A Road to Advancem…\n#&gt; 3 data/inaugural-mofa/제18대 박근혜 \"My fellow Koreans and seven million fellow…\n#&gt; 4 data/inaugural-mofa/제19대 문재인 \"My fellow Koreans, I am grateful to you al…\n#&gt; 5 data/inaugural-mofa/제20대 윤석열 \"My fellow Koreans, Seven and a half millio…"
  },
  {
    "objectID": "inaugural.html#api-호출-함수",
    "href": "inaugural.html#api-호출-함수",
    "title": "chatGPT",
    "section": "\n3.1 API 호출 함수",
    "text": "3.1 API 호출 함수\nget_embedding() 함수를 제작하여 국,영문 취임사 텍스트를 전달하여 임베딩 값을 반환받는다. 매번 API를 호출할 때마다 비용이 발생되기 때문에 API호출 횟수를 최소화한다.\n\n코드library(httr)\n\nget_embedding &lt;- function(inaugural_address) {\n  embeddings_url &lt;- \"https://api.openai.com/v1/embeddings\"\n  auth &lt;- add_headers(Authorization = paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\")))\n  body &lt;- list(model = \"text-embedding-ada-002\", input = inaugural_address)\n  \n  resp &lt;- POST(\n    embeddings_url,\n    auth,\n    body = body,\n    encode = \"json\"\n  )\n  \n  embeddings &lt;- content(resp, as = \"text\", encoding = \"UTF-8\") %&gt;%\n    jsonlite::fromJSON(flatten = TRUE) %&gt;%\n    pluck(\"data\", \"embedding\")\n  \n  Sys.sleep(1)\n  \n  return(embeddings)\n}\n\n# 1. 국문 취임사\nembedding_tbl &lt;- inaugural_tbl %&gt;% \n  mutate(임베딩 = map(취임사, get_embedding)) %&gt;% \n  pull()\n\nembedding_tbl %&gt;% \n  write_rds(\"data/Inaugural.rds\")\n\n# 2. 영어번역본 취임사\ntranslated_embedding &lt;- translated_tbl %&gt;% \n  mutate(임베딩 = map(영문번역, get_embedding))\n\ntranslated_embedding %&gt;% \n  write_rds(\"data/translated_embedding.rds\")\n\n# 3. 영어 취임사\ninaugural_eng_embedding &lt;- inaugural_eng_tbl %&gt;% \n  mutate(임베딩 = map(영문취임사, get_embedding))\n\ninaugural_eng_embedding %&gt;% \n  write_rds(\"data/inaugural_eng_embedding.rds\")"
  },
  {
    "objectID": "inaugural.html#임베딩-벡터",
    "href": "inaugural.html#임베딩-벡터",
    "title": "chatGPT",
    "section": "\n3.2 임베딩 벡터",
    "text": "3.2 임베딩 벡터\n각각 API를 호출하여 준비한 취임사 텍스트를 임베딩으로 변환한 데이터프레임을 각각 이어붙여 후속 데이터 분석을 위해 준비한다.\n\n코드embedding_tbl &lt;-  \n  read_rds(\"data/Inaugural.rds\") %&gt;% \n  mutate(구분 = \"국문 취임사\")\n\ntranslated_embedding &lt;- \n  read_rds(\"data/translated_embedding.rds\") %&gt;% \n  mutate(구분 = \"영문번역 취임사\") %&gt;% \n  rename(취임사 = 영문번역)\n\ninaugural_eng_embedding &lt;- \n  read_rds(\"data/inaugural_eng_embedding.rds\") %&gt;% \n  mutate(구분 = \"영문 취임사\") %&gt;% \n  rename(취임사 = 영문취임사)\n\napi_embedding &lt;- \n  bind_rows(embedding_tbl, translated_embedding) %&gt;% \n  bind_rows(inaugural_eng_embedding)\n\napi_embedding %&gt;% \n  select(구분, 대통령, 취임사, 임베딩) \n#&gt; # A tibble: 31 × 4\n#&gt;    구분        대통령 취임사                                              임베딩\n#&gt;    &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;                                               &lt;list&gt;\n#&gt;  1 국문 취임사 이승만 나의 사랑하는 동포 여러분. 내가 오늘 또 한번 우리 … &lt;list&gt;\n#&gt;  2 국문 취임사 윤보선 제2공화국의 초대대통령으로 영예의 당선을 얻은 어제… &lt;list&gt;\n#&gt;  3 국문 취임사 박정희 친애하는 5천만 동포 여러분!  그리고 내외 귀빈 여러… &lt;list&gt;\n#&gt;  4 국문 취임사 최규하 친애하는 국내외 동포 여러분!  그리고 이 자리를 빛…  &lt;list&gt;\n#&gt;  5 국문 취임사 전두환 친애하는 국내외 동포 여러분!  그리고 이 자리를 빛…  &lt;list&gt;\n#&gt;  6 국문 취임사 노태우 친애하는 6천만 국내외 동포 여러분. 우리 헌정발전을… &lt;list&gt;\n#&gt;  7 국문 취임사 김영삼 친애하는 7천만 국내외 동포 여러분,  노태우 대통령…  &lt;list&gt;\n#&gt;  8 국문 취임사 김대중 존경하고 사랑하는 국민 여러분!  오늘 저는 대한민국… &lt;list&gt;\n#&gt;  9 국문 취임사 노무현 존경하는 국민 여러분.  오늘 저는 대한민국의 제16대… &lt;list&gt;\n#&gt; 10 국문 취임사 이명박 존경하는 국민 여러분!    700만 해외동포 여러분!   … &lt;NULL&gt;\n#&gt; # … with 21 more rows"
  },
  {
    "objectID": "inaugural.html#유사도-계산",
    "href": "inaugural.html#유사도-계산",
    "title": "chatGPT",
    "section": "\n5.1 유사도 계산",
    "text": "5.1 유사도 계산\n먼저 취임사 임베딩 벡터로부터 각 취임사별 코사인 유사도를 계산하면 정방행렬(Square Matrix)를 다시 데이터프레임으로 변환하게 시킨다. 이를 통해 취규하, 노태우, 전두환 대통령 취임사 사이에 높은 취임사 유사도가 확인된다.\n\n코드library(umap)\n\nembeddings_mat &lt;- matrix(\n  unlist(api_embedding_tbl$임베딩), \n  ncol = 1536, byrow = TRUE\n)\n\nembeddings_similarity &lt;- embeddings_mat / sqrt(rowSums(embeddings_mat * embeddings_mat))\nembeddings_similarity &lt;- embeddings_similarity %*% t(embeddings_similarity)\n\ndim(embeddings_similarity)\n#&gt; [1] 30 30\n\n## 정방행렬을 데이터프레임으로 변환\n\n취임사_구분자 &lt;- api_embedding_tbl %&gt;% \n  mutate(구분명 = glue::glue(\"{대통령}_{str_remove(구분, ' ?취임사 ?')}\")) %&gt;% \n  pull(구분명)\n\n취임사_colnames_tbl &lt;- tibble(취임사_구분자 = 취임사_구분자) %&gt;% \n  mutate(name = glue::glue(\"V{1:30}\"))\n\nembeddings_similarity_tbl &lt;- embeddings_similarity %&gt;% \n  as.data.frame %&gt;% \n  mutate(구분자 = 취임사_구분자) %&gt;%\n  column_to_rownames(var = \"구분자\") %&gt;%\n  tibble::rownames_to_column()  %&gt;%\n  tidyr::pivot_longer(-rowname) %&gt;% \n  # From A to B\n  left_join(취임사_colnames_tbl) %&gt;% \n  select(취임사_A = rowname, 취임사_B = 취임사_구분자, 유사도 = value)\n\nembeddings_similarity_tbl %&gt;% \n  filter(유사도 &lt; 0.9999 ) %&gt;% \n  arrange(desc(유사도)) %&gt;% \n  mutate(대통령_A = str_extract(취임사_A, \"[^_]+(?=_)\"),\n         대통령_B = str_extract(취임사_B, \"[^_]+(?=_)\")) %&gt;% \n  filter(대통령_A != 대통령_B) %&gt;% \n  select(취임사_A, 취임사_B, 유사도) %&gt;% \n  reactable::reactable(\n    columns = list(유사도 = colDef(format = colFormat(separators = TRUE, digits = 3))),\n    # Table Theme\n    theme = reactableTheme(\n      backgroundColor = \"#1D2024\", color = \"white\", borderColor = \"#666666\",\n      paginationStyle = list(color = \"white\"), \n      selectStyle = list(color = \"black\"),\n      headerStyle = list(color = \"white\", fontFamily = \"NanumGothic\"),\n      cellStyle = list(color = \"#FAFAFA\", \n                        fontFamily = \"NanumGothic, Consolas, Monaco, monospace\", \n                        fontSize = \"14px\")\n                           ))"
  },
  {
    "objectID": "inaugural.html#차원축소-시각화",
    "href": "inaugural.html#차원축소-시각화",
    "title": "chatGPT",
    "section": "\n5.2 차원축소 시각화",
    "text": "5.2 차원축소 시각화\n국문영문 취임사를 모두 넣어 시각화를 하게 되면 국문 취임사는 국문 취임사, 영문 취임사는 DeepL 번역이든 영문 번역이든 둘로 명확히 나눠 군집화가 된 것이 확인된다.\n\n코드library(ggrepel)\nextrafont::loadfonts()\n\ninaugural_umap &lt;- umap(embeddings_mat)\n\numap_df &lt;- inaugural_umap$layout %&gt;%\n  as.data.frame()%&gt;%\n  rename(UMAP1=\"V1\",\n         UMAP2=\"V2\") %&gt;% \n  bind_cols(api_embedding_tbl) %&gt;% \n  mutate(구분명 = glue::glue(\"{대통령}_{str_remove(구분, ' ?취임사 ?')}\")) %&gt;% \n  select(UMAP1, UMAP2, 구분명)\n\numap_df %&gt;%\n  ggplot(aes(x = UMAP1, \n             y = UMAP2))+\n    geom_point(size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=구분명)) +\n    theme_bw(base_family=\"NanumGothic\")\n\n\n\n\n\n\n\n앞선 분석에서 이명박 대통령 취임사가 토큰 길이를 넘어 국문 임베딩이 존재하지 않기 때문에 영문 번역 혹은 영문 취임사 임베딩을 umap 차원 축소 기법을 통해 시각화한다. 이를 통해 윤석열 대통령과 노무현 대통령 취임사가 유사성이 큰게 눈에 띈다.\n\n코드# 영어만 추출\nonly_english_tbl &lt;- api_embedding_tbl %&gt;% \n  filter(str_detect(구분, \"영문\"))\n\nenglish_embeddings_mat &lt;- matrix(\n  unlist(only_english_tbl$임베딩), \n  ncol = 1536, byrow = TRUE\n)\n\n# 시각화\nenglish_umap &lt;- umap(english_embeddings_mat)\n\nenglish_umap_df &lt;- english_umap$layout %&gt;%\n  as.data.frame()%&gt;%\n  rename(UMAP1=\"V1\",\n         UMAP2=\"V2\") %&gt;% \n  bind_cols(only_english_tbl) %&gt;% \n  mutate(구분명 = glue::glue(\"{대통령}_{str_remove(구분, ' ?취임사 ?')}\")) %&gt;% \n  select(UMAP1, UMAP2, 구분명)\n\nenglish_umap_df %&gt;%\n  separate(구분명, into = c(\"대통령\", \"번역여부\"), sep = \"_\") %&gt;% \n  ggplot(aes(x = UMAP1, \n             y = UMAP2))+\n    geom_point(aes(color = 번역여부), size = 1.3, alpha = 0.8) +\n    geom_text_repel(aes(label=대통령)) +\n    theme_bw(base_family=\"NanumGothic\") +\n    theme(legend.position = \"top\") +\n    labs(title = \"대통령 취임사 유사도\")"
  },
  {
    "objectID": "inaugural.html#footnotes",
    "href": "inaugural.html#footnotes",
    "title": "chatGPT",
    "section": "각주",
    "text": "각주\n\nIntroducing text and code embeddings↩︎\nNew and improved embedding model↩︎\nOpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?↩︎"
  },
  {
    "objectID": "prompt_in_practice.html",
    "href": "prompt_in_practice.html",
    "title": "chatGPT",
    "section": "",
    "text": "노트\n\n\n\n\n\n서울 디지털재단에서 챗GPT 활용 사례집을 업무활용과 일상생활/창작활동/교육분야 로 나눠 두번에 걸쳐 보고서를 발간했다. (\"ChatGPT활용연구TFT, 2023) (ChatGPT활용연구TFT, 2023) 최근에는 교육분야 전반에 챗GPT 활용 책도 출간되었다. (Skrabut, 2023)\n\n\n\n\n1 전체적인 현황\n서울 디지털재단에서 업무활용과 일상생활 활용에 챗GPT 다양한 사례를 보고서로 공개하여 챗GPT 초기 갖고 있었던 우려를 불식시키며 일상생활에 녹아들고 있다.\n생산성 향상을 위해서 사무업무에 보고서 작서, 사업기획 아이디어 도출, 보도자료 및 엑셀과 데이터 과학, 프로그래밍 자동화 분야에 챗GPT 활용이 소개되고 있다. 챗GPT의 텍스트 생성에 환각/환영(hallucination) 이 발생할 수 있음에 유의하여 일상생활 활용에 대해서 법률, 건강, 투자, 학업 등 사례를 제시하고 있다.\n특히 챗GPT를 교육에 활용할 수 있는 80가지 방식을 제시한 사례는 음미할 필요가 있다.(Skrabut, 2023)\n\n코드library(tidyverse)\nlibrary(collapsibleTree)\nlibrary(readxl)\n\npractice_raw &lt;- read_excel(\"data/chatGPT_applictions.xlsx\")\n\npractice &lt;- practice_raw %&gt;% \n  fill(대구분, .direction = \"down\") %&gt;% \n  fill(중구분, .direction = \"down\") %&gt;% \n  mutate(소구분 = str_remove(소구분, \"^[0-9]{1,2}\\\\.+ \"))  %&gt;% \n  mutate(중구분 = str_remove(중구분, \"[0-9]{1,2}$\"))\n  \n\ncollapsibleTree(practice, c(\"대구분\", \"중구분\", \"소구분\"),\n                tooltipHtml = \"tooltip\",\n                root = \"챗GPT 활용\")\n\n\n\n\n\n\n2 챗GPT 환영/환각 방지\n생성 AI의 문제점 중 가장 우려되는 것이 환각/환영(hallucination)이다. 이를 줄이기 위해서 다음 사항을 고려하면 많은 부분 문제를 해결할 수 있다.\n출처: How to Prevent AI Model Hallucinations\n\n잘 작성된 프롬프트: 역할을 부여, 목표설정, 구체적이고, 예제를 제시하고 단계적 수행 등 목표달성을 위해 프롬프트를 프로그램 작성에 준하는 노력을 하여 작성한다. 결국 잘 작성된 프롬프트는 결과물에 큰 영향을 미친다.\nAI 모델 선정: GPT-4와 text-dainci-003은 gpt-3.5-turbo와 비교하여 환각이 덜 발생하는 것으로 알려졌다. 따라서, 다소 비싸지만 고성능 AI 모델을 사용할 경우 그렇지 않은 경우와 비교하여 환각을 대폭 줄일 수 있다.\n모형 패러미터 지정: temperature 모수 값을 높이면 모델이 더 많은 위험을 감수하고 더 다양한 결과물을 생성하도록 장려하는 반면 모수 값을 낮추면 정반대로 동작한다. 도한, presence 페널티를 높이면 모델이 덜 반복적이고 일관성 있고 완전한 결과물을 생성하도록 장려되고 낮추면 반대방향으로 동작한다.\n\n\n\n\n\n\n\n모델\n설명\n\n\n\ngpt4\n매우 정확하지만 느리고 비싸다\n\n\ngpt-3.5-turbo\n매우 빠르지만 종종 환각이 발생하기 쉬움\n\n\ntext-davinci-003\ngpt4 및 gpt-3.5만큼 성능이 뛰어나지는 않지만 속도와 정확성 사이의 균형이 잘 잡혀 있습니다.\n\n\n\n3 챗GPT 패러미터\n챗GPT API에 다양한 패러미터를 지정하여 텍스트 작업결과 품질을 원하는 방향으로 조절할 수 있다. 대표적인 패러미터로 다음을 들 수 있다.\n\n토큰 크기(max_tokens): 영문 기준 100개 토큰은 대략 75개 단어(word)로 간주할 수 있는데 토큰 크기를 지정해서 출력되는 텍스트 길이를 조절한다. text-davinci-003 기준으로 토큰최대길이는 1 ~ 4,000을 갖는다.\n온도(temperature): 온도를 조정하여 텍스트 생성에 더욱 창의성을 발휘할 수 있지만 창의적인 텍스트는 환각/환영도 만들어낼 가능성이 높아진다. text-davinci-003 기준으로 온도는 0 ~ 1 사이 값을 갖는다.\n최상위 확률(top_p): top_p=0.1을 지정하면 상위 10%를 구성하는 가장 높은 확률값을 갖는 토큰을 고려하여 텍스트가 생성된다. 텍스트 생성 과정에서 생성된 토큰의 확률 분포에서 최상위 p%만 고려하도록 합니다. 예를 들어, top_p=0.9이면, 다음 토큰을 선택할 때, 모델이 예측한 확률 분포에서 상위 90%만 고려하고, 나머지 10%는 무시하게 된다.\n존재 벌칙(presence_penalty): 텍스트 생성 시 중복을 제거하거나, 이전에 생성한 내용과 비슷한 내용이 반복되는 것을 방지하는 데 사용되는데, presence_penalty가 높을수록, 모델은 이전에 생성한 토큰을 가능한 한 피하게 된다. presence_penalty는 0.6 ~ 0.9 사이의 값을 둔다. text-davinci-003 기준으로 온도는 0 ~ 2 사이 값을 갖는다.\n빈도 벌칙(frequency_panalty): 모델이 특정 토큰을 생성할 때, 해당 토큰이 이전에 생성된 횟수에 따라 더 작은 확률로 선택되도록 한다. 이를 통해 모델은 특정 토큰을 일정한 빈도로 생성하려는 경향을 줄일 수 있다. 0은 이전 토큰의 빈도수에 대한 제약을 적용하지 않는 것을 의미하며, 값이 클수록 모델이 이전에 생성된 토큰과 다른 새로운 토큰을 선택하도록 유도한다. 일반적으로, Frequency_penalty는 0.6 ~ 1.2 사이의 값으로 설정됩니다. text-davinci-003 기준으로 온도는 0 ~ 2 사이 값을 갖는다.\n몇개중 최고 선정(best_of): 생성된 여러 후보 텍스트 중에서 최상의 텍스트를 선택하는 데 사용한다. 즉, 모델은 지정된 후보 텍스트 수 중에서 가장 높은 점수를 받은 텍스트를 선택한다. 예를 들어, best_of가 3으로 설정된 경우, 모델은 생성된 3개의 후보 텍스트 중에서 최상의 텍스트를 선택한다. text-davinci-003 기준으로 온도는 1 ~ 20 사이 값을 갖는다.\n시작 텍스트 주입(Inject start text): 모델이 특정 텍스트로부터 시작하도록 지정하는 데 사용된다. 예를 들어, “Inject start text” 매개 변수를 사용하여 “나는”으로 시작하는 텍스트를 생성하도록 지정할 수 있다. 이 경우 모델은 “나는”으로 시작하는 텍스트를 생성하기 위해 해당 단어를 사용하여 생성을 시작해서 “나는 대학에서 경영학을 전공했고, 지금은 기업의 경영 전략을 담당하는 직원입니다.”라는 텍스트가 생성된다.\n텍스트 재시작 주입(Inject restart text): 모델이 생성된 텍스트의 일부를 재사용하여 새로운 텍스트를 생성하도록 지시하는 데 사용된다. 예를 들어, “벚꽃이 피는 계절에”라는 문장이 이미 생성되어 있다면, Inject restart text를 사용하여 “나는”이라는 문장을 생성하면, 모델은 “나는 벚꽃이 피는 계절에”라는 새로운 문장을 생성할 수 있다.\n어조(tone) : neutral (중립적인), positive (긍정적인), negative (부정적인), formal (격식 있는), informal (비격식적인), professional (전문적인), casual (친근한), witty (똑똑한), serious (진지한), playful (장난스러운), sad (슬픈), happy (행복한), angry (화난), calm (차분한), romantic (로맨틱한), mysterious (신비로운), surprised (놀란)\n저작 스타일(writing_style): normal (일반적인), academic (학술적인), creative (창조적인), formal (격식 있는), informal (비격식적인), professional (전문적인), casual (친근한), technical (기술적인)\n\n4 사례\n광명시 생활안정지원금 신청\n\n\n웹공고\n공고문 내용\n프롬프트1\n프롬프트2\n\n\n\n\n\n\n\n\n\n지급금액 : 세대 당 10만원 2023. 3. 6.일 24시 기준 광명시에 주민등록을 둔 세대주\n기간 온라인 : 2023. 03. 20(월) 09:00 ~ 4. 28(금) 오프라인 : 2023. 03. 27(월) ~ 5. 4(목) 18:00 (토요일, 공휴일 제외)\n문의처 광명사랑화폐 콜센터(1899-7997) 광명시 민원콜센터(1688-3399)\n※ 온라인 신청 시 동명이인이 다수 존재하는 경우 [오프라인 신청 대상]으로 표시 → 온라인 진행이 불가하며 오프라인 신청기간에 주소지 동 방문 신청 필요\n※ 광명사랑화폐 온라인 발급 방법 구글플레이 앱 스토어에서 ’경기지역화폐’앱 다운로드 받고 광명사랑화폐 신청, 광명사랑화폐가 배송되면 앱에 등록하고 사용\n온라인 카드 신청방법 : ’경기지역화폐’앱 설치 → 카드 신청 → 카드 발급 및 배송(약 1주일) → (수령 후)카드 등록(’경기지역화폐’앱) → 사용\n\n\n\n다음 사업공고를 홍보할 수 있도록 보도자료를 작성해주세요. writing_style : journalistic, temperature:0.0\n\n\n광명시가 생활안정지원금 신청을 받습니다. 세대 당 10만원의 지원금이 지급됩니다. 광명시에 주민등록을 둔 세대주라면 신청이 가능합니다.\n\n온라인 신청은 2023년 3월 20일(월) 09:00부터 4월 28일(금)까지 가능합니다. 오프라인 신청은 2023년 3월 27일(월)부터 5월 4일(목)까지 가능하며, 토요일과 공휴일은 제외됩니다.\n\n온라인 신청 시, 동명이인이 다수 존재하는 경우에는 오프라인 신청 대상으로 표시되며, 온라인 진행이 불가하므로 오프라인 신청기간에 주소지 동을 방문하여 신청해야 합니다.\n\n광명사랑화폐 콜센터(1899-7997) 또는 광명시 민원콜센터(1688-3399)로 문의하실 수 있습니다.\n\n또한, 광명사랑화폐 온라인 발급 방법은 구글플레이 앱 스토어에서 '경기지역화폐'앱을 다운로드 받은 후, 광명사랑화폐를 신청하고, 배송된 광명사랑화폐를 앱에 등록하여 사용할 수 있습니다.\n\n온라인 카드 신청방법은 '경기지역화폐'앱을 설치한 후, 카드를 신청하고, 약 1주일 내에 카드가 발급되며, 수령 후에는 카드를 앱에 등록하여 사용할 수 있습니다.\n\n광명시에 거주하는 세대주라면 꼭 지원금 신청을 하시기 바랍니다.\n\n\n\n다음 사업공고를 홍보할 수 있도록 한글로 보도자료를 작성해주세요. writing_style : journalistic, temperature:1.0 tone: witty\n\n\n광명시민 여러분, 세금으로 납부하신 돈이 이제 생활안정지원금으로 돌아옵니다!\n\n지금부터 4월 말까지, 광명시에 주민등록을 둔 세대주님들은 10만원의 지원금을 받을 자격이 있습니다.\n\n어떻게 신청하냐고요?\n온라인으로 신청하실 분들은 3월 20일부터 4월 28일까지, 오프라인으로 신청하실 분들은 3월 27일부터 5월 4일까지 신청 기간이 주어집니다.\n\n아, 그리고 주의하셔야 할 점! 온라인 신청 시 동명이인이 다수 존재한다면, 오프라인 신청을 해야합니다. 집에서 뻥튀기한 성의는 알겠는데, 동명이인은 답이 없어요.\n\n궁금한 점이 있다면 광명사랑화폐 콜센터(1899-7997) 혹은 광명시 민원콜센터(1688-3399)로 연락주세요.\n\n그리고 광명사랑화폐 온라인 발급 방법도 알려드릴게요. 구글플레이 앱 스토어에서 '경기지역화폐'앱을 다운로드 하신 후, 광명사랑화폐를 신청하시면 배송되면 앱에 등록하시고 사용하시면 됩니다.\n\n간단하죠? 이번 생활안정지원금으로 조금이라도 여유를 만들어 보세요!\n\n\n\n\n\n\n\n\n참고문헌\n\n\"ChatGPT활용연구TFT. (2023). [업무활용편] ChatGPT 활용사례 및 활용 팁. 서울디지털재단. https://sdf.seoul.kr/research-report/2003\n\n\nChatGPT활용연구TFT. (2023). [일상생활·창작활동·교육분야편] ChatGPT 활용사례 및 팁. 서울디지털재단. https://sdf.seoul.kr/research-report/2059\n\n\nSkrabut, S. (2023). 80 Ways to Use ChatGPT in the Classroom: Using AI to Enhance. Stan Skrabut."
  },
  {
    "objectID": "prompt_data_science.html",
    "href": "prompt_data_science.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 데이터 과학\n참고자료: (I, 2023)\n챗GPT의 출현으로 데이터 과학 결과물을 만들어내기 위해서 과거 구글링, 미트업, cheatsheet 등을 데이터 과학자가 파악하고 이를 데이터 과학자가 반영하는 것에서 챗GPT와 상호 작용하여 결과물을 얻어내는 새로운 선택지가 만들어졌다.\n\n\n\n\ngraph TD\n    A[데이터 가져오기] --&gt; B[데이터 정제]\n    B --&gt; C[탐색적 데이터 분석]\n    C --&gt; D[시각화]\n    D --&gt; E[기계학습]\n    E --&gt; F[배포]\n    \n    style A fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style B fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style C fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style D fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style E fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n    style F fill:#85C1E9,stroke:#3498DB,stroke-width:3px;\n\n\n\n\n\n데이터를 가져와서 데이터 정제, 탐색적 데이터분석, 시각화, 기계학습, 배포 과정을 거치게 된다. 각 단계별로 챗GPT 정답을 살펴보자.\n\n2 헬로월드\n챗GPT가 작성해주는 파이썬 코드를 사용해서 챗GPT에 요청한 결과를 R로 반환받아 이를 문서로 제작한다. OpenAI Chat 제품 중 gpt-3.5-turbo 모형을 기반으로 프롬프트를 잘 작성하여 고품질 결과를 얻어낸다.\n\n\n\n\n\n코드import openai\nimport os\n\nopenai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n\ndef answer_question(text):\n    prompt = f\"다음 데이터 과학 질문에 대해서 구체적이고 전문적으로 100자를 넘지 않게 친절히 설명해주세요. : {text}\"\n\n    response = openai.ChatCompletion.create(\n        model='gpt-3.5-turbo',\n        messages=[\n            {\"role\": \"system\", \"content\": \"당신은 R 언어를 사용하는 데이터 과학자로 다음 질문을 친절히 설명해주세요:\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=1700,\n        n=1,\n        stop=None,\n        temperature=0.0\n    )\n\n    return response\n\n# answer_text = answer_question(\"데이터 탐색이란 무엇이며, 데이터 과학에서 어떻게 유용한가요?\")\n# answer_text['choices'][0]['message']['content'].strip()\n\n\n\n\n\n질문\n\n코드question &lt;- '데이터 탐색이란 무엇이며, 데이터 과학에서 어떻게 유용한가요?'\n\n\n데이터 탐색이란 무엇이며, 데이터 과학에서 어떻게 유용한가요?`\n\n\n답변\n\n코드library(reticulate)\nlibrary(tidyverse)\n\nanswer_json &lt;- py$answer_question(question)\n\nanswer_list &lt;- jsonlite::fromJSON(as.character(answer_json))\n\nanswer &lt;- answer_list$choices$message$content\n\n\n데이터 탐색은 데이터를 이해하고 분석하기 위해 데이터를 시각화하고 요약하는 과정입니다. 이를 통해 데이터의 패턴, 이상치, 결측치 등을 파악하고 데이터 전처리에 필요한 정보를 얻을 수 있습니다. 데이터 과학에서는 데이터 탐색을 통해 문제 해결에 필요한 인사이트를 도출하고 모델링에 필요한 변수를 선택하는 등의 중요한 결정을 내릴 수 있습니다. 또한, 데이터 탐색을 통해 데이터의 품질을 평가하고 데이터의 신뢰성을 높일 수 있습니다.\n\n\n토큰수\n\n코드answer_list$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n185\n\n\nprompt_tokens\n126\n\n\ntotal_tokens\n311\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n참고문헌\n\nI, G. (2023). ChatGPT Guide for Data Scientists: Top 40 Most Important Prompts Mastering Data Science with ChatGPT and Python: Top 40 Prompts for Machine Learning, Data Visualization, and more. Towards Data Science. https://medium.com/towards-artificial-intelligence/chatgpt-guide-for-data-scientists-top-40-most-important-prompts-cdb911f3a427"
  },
  {
    "objectID": "gpt4_performance.html#데이터셋",
    "href": "gpt4_performance.html#데이터셋",
    "title": "chatGPT",
    "section": "",
    "text": "웹사이트에 게시된 가격표를 크롤링하여 엑셀파일로 정리한다.\n\n코드library(readxl)\nlibrary(tidyverse)\n\nprice_raw &lt;- read_excel(\"data/openai_pricing.xlsx\", sheet=\"price\")\n\nprice &lt;- price_raw %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  select(-description) %&gt;% \n  separate(가격, into = c(\"가격\", \"단위\"), sep = \"/\") %&gt;% \n  mutate(가격 = parse_number(가격) *1300, # 환율 1,300 / 달러 적용\n         단위 = str_squish(단위)) \n\nprice %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_espn()\n\n\n\n\n\n\n모형구분\n      model\n      작업\n      가격\n      단위\n    \n\n\nGPT-4\n8K context\nPrompt\n39.00\n1K tokens\n\n\nGPT-4\n32K context\nPrompt\n78.00\n1K tokens\n\n\nGPT-4\n8K context\nCompletion\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nCompletion\n156.00\n1K tokens\n\n\nChat\ngpt-3.5-turbo\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nAda\nPrompt\n0.52\n1K tokens\n\n\nInstructGPT\nBabbage\nPrompt\n0.65\n1K tokens\n\n\nInstructGPT\nCurie\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nDavinci\nPrompt\n26.00\n1K tokens\n\n\nFine-tuning models\nAda\nPrompt\n0.52\n1K tokens\n\n\nFine-tuning models\nBabbage\nPrompt\n0.78\n1K tokens\n\n\nFine-tuning models\nCurie\nPrompt\n3.90\n1K tokens\n\n\nFine-tuning models\nDavinci\nPrompt\n39.00\n1K tokens\n\n\nFine-tuning models\nAda\nUsage\n2.08\n1K tokens\n\n\nFine-tuning models\nBabbage\nUsage\n3.12\n1K tokens\n\n\nFine-tuning models\nCurie\nUsage\n15.60\n1K tokens\n\n\nFine-tuning models\nDavinci\nUsage\n156.00\n1K tokens\n\n\nEmbedding models\nAda\nPrompt\n0.52\n1K tokens\n\n\nImage models\n1024×1024\nPrompt\n26.00\nimage\n\n\nImage models\n512×512\nPrompt\n23.40\nimage\n\n\nImage models\n256×256\nPrompt\n20.80\nimage\n\n\nAudio models\nWhisper\nPrompt\n7.80\nminute"
  },
  {
    "objectID": "gpt4_performance.html#시각화",
    "href": "gpt4_performance.html#시각화",
    "title": "chatGPT",
    "section": "\n5.2 시각화",
    "text": "5.2 시각화\nOpenAI 가격을 원화(1,300원)로 변환시켜 API 호출별 체감되는 가격을 시각화한다.\n\n코드extrafont::loadfonts()\n\npricing_g &lt;- price %&gt;% \n  mutate(모형상세 = glue::glue(\"{모형구분} / {model} / {작업}\") %&gt;% as.character(.)) %&gt;%\n  mutate(모형구분 = factor(모형구분, levels=c(\"GPT-4\",\"Fine-tuning models\", \"Image models\", \"Audio models\", \n                                      \"InstructGPT\", \"Chat\", \"Embedding models\") )) %&gt;% \n  ggplot(aes(x = fct_reorder(모형상세, 가격), y = 가격, fill = 모형구분)) +\n    geom_col(width = 0.5) +\n    # facet_wrap(~모형구분, scales = \"free_y\") +\n    coord_flip() +\n    geom_text(aes(x = 모형상세, y = 가격, label = glue::glue(\"{가격} 원\") ), nudge_y = 5) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(title = \"OpenAI 챗GPT API 호출 가격\", \n         subtitle = \"환율 1,300 원/달러 적용 (텍스트 1,000 토큰, 이미지는 크기별, 오디오는 1분 기준)\",\n         x = \"\",\n         y = \"가격(원)\",\n         caption = \"OpenAI 가격표: https://openai.com/pricing\") +\n    theme(legend.position = c(0.8, 0.3),\n          legend.title=element_text(size=rel(2.5), family = \"MaruBuri Bold\"),\n          legend.text=element_text(size=rel(1.5), family = \"MaruBuri Bold\"))\n\n\nragg::agg_png(\"images/pricing_g.png\", width = 297, height = 210, units = \"mm\", res = 600)\npricing_g\ndev.off()"
  },
  {
    "objectID": "translation.html",
    "href": "translation.html",
    "title": "chatGPT",
    "section": "",
    "text": "BLEU(Bilingual Evaluation Understudy, 이중 언어 평가 연구)는 기계 번역의 품질을 평가하는 데 사용되는 지표다. 기계 생성 번역을 사람이 생성한 하나 이상의 참조 번역과 비교하고 참조 번역과 얼마나 유사한지에 따라 점수를 부여하는 방식으로 작동한다. BLEU 점수는 0점에서 1점 사이이며, 1점은 기계 생성 번역과 참조 번역이 완벽하게 일치함을 나타내고, 점수가 높을수록 기계 생성 번역이 참조 번역과 의미적으로 더 가깝다는 것을 의미한다.\nCOMET(Cross-lingual Optimized Metric for Evaluation of Translation, 번역 평가를 위한 교차 언어 최적화 지표)은 2020년에 도입된 기계 번역 평가 지표로 BLEU와 같은 기존 지표의 일부 한계를 해결하기 위해 고안되었다. 기계 생성 번역과 참조 번역 간의 n-그램 중복만을 비교하는 BLEU와 달리 COMET은 유창성, 적절성, 충실도 등 번역 품질에 대한 여러 측면을 고려함은 물론 기계 생성 번역과 참조 번역 간의 의미적 유사성도 고려한다. COMET 점수는 0점에서 100점 사이이며, 점수가 높을수록 기계 생성 번역의 품질이 우수하다는 것을 나타내고, BLEU와 같은 기존 지표보다 사람의 평가와 상관관계가 높은 것으로 나타나 기계 번역 평가에 유망한 지표로 대두되고 있다.\n참고: (Marie, 2022), (Marie, 2023)\n\nprompt = \"Score the following news summarization given the corresponding news with respect to fluency with one to five stars, where one star means “disfluency” and five stars means “perfect fluency”. Note that fluency measures the quality of individual sentences, are they well-written and grammatically correct. Consider the quality of individual sentences.\n\nSource: \nTarget: \""
  },
  {
    "objectID": "translation.html#gpt-3.5-turbo",
    "href": "translation.html#gpt-3.5-turbo",
    "title": "chatGPT",
    "section": "\n3.1 gpt-3.5-turbo\n",
    "text": "3.1 gpt-3.5-turbo\n\ngpt-3.5-turbo을 사용해서 번역 대상 텍스트를 생성한다.\n\n코드prompt = f\"What are some popular R libraries for data visualization and how are they used?\"\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a data scientist that mainly uses R programming language.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ],\n    max_tokens=300,\n    n=1,\n    stop=None,\n    temperature=0.5,\n)\n\n\n\n코드gpt_turbo_result &lt;- py$response['choices'][[1]]$message$content\ngpt_turbo_result %&gt;% \n  write_lines(\"data/gpt_turbo_result.txt\")\n\n\n\n코드gpt_turbo_result &lt;- read_lines(\"data/gpt_turbo_result.txt\")\ncat(str_c(gpt_turbo_result, collapse = \"\\n\"))\n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that can be embedded in web applications.\n#&gt; \n#&gt; These libraries are used to create a wide range of visualizations such as scatter plots, line charts, bar charts, histograms, heatmaps, and more. They provide a wide range of customization options and allow users to create visually appealing and informative plots that can help to communicate complex data sets"
  },
  {
    "objectID": "translation.html#번역대상-텍스트-생성",
    "href": "translation.html#번역대상-텍스트-생성",
    "title": "chatGPT",
    "section": "\n3.1 번역대상 텍스트 생성",
    "text": "3.1 번역대상 텍스트 생성\n데이터 시각화에 자주 인용되는 R 패키지와 사용되는 방법을 물었고 gpt-3.5-turbo을 사용해서 번역 대상 텍스트로 생성한다.\n\nWhat are some popular R packages for data visualization and how are they used? \n데이터 시각화를 위해 널리 사용되는 R 패키지에는 어떤 것이 있으며 어떻게 사용되나요?\n\n\nprompt = f\"What are some popular R packages for data visualization and how are they used?\"\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a data scientist that mainly uses R programming language.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ],\n    max_tokens=300,\n    n=1,\n    stop=None,\n    temperature=0.5,\n)\n\n\ngpt_turbo_result &lt;- glue::glue(\"{py$response['choices'][[1]]$message$content}\\n\")\ngpt_turbo_result %&gt;% \n  write_lines(\"data/gpt_turbo_result.txt\")\n\n\ngpt_turbo_result &lt;- read_lines(\"data/gpt_turbo_result.txt\")\ncat(str_c(gpt_turbo_result, collapse = \"\\n\"))\n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that can be embedded in web applications.\n#&gt; \n#&gt; These libraries are used to create a wide range of visualizations such as scatter plots, line charts, bar charts, histograms, heatmaps, and more. They provide a wide range of customization options and allow users to create visually appealing and informative plots that can help to communicate complex data sets"
  },
  {
    "objectID": "translation.html#gpt-엔진",
    "href": "translation.html#gpt-엔진",
    "title": "chatGPT",
    "section": "\n3.2 GPT 엔진",
    "text": "3.2 GPT 엔진\n\n3.2.1 gpt-3.5-turbo\n\ngpt-3.5-turbo는 속도가 빠르고 저렴하지만 gpt-4에는 성능이 미치지 못한다. Chat모형 gpt-3.5-turbo 엔진에 넣어 번역 품질을 살펴보자.\n\nwith open('data/gpt_turbo_result.txt', 'r') as file:\n    source_text = file.read()\n\ndef translate_text_by_model(text, model, source_language, target_language):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=1000,\n        n=1,\n        stop=None,\n        temperature=0.5,\n    )\n\n    return response\n\ntranslated_text = translate_text_by_model(source_text, 'gpt-3.5-turbo', 'English', 'Korean')\n\n\ngpt_turbo_3 &lt;- glue::glue(\"{py$translated_text['choices'][[1]]$message$content}\\n\")\ngpt_turbo_3 %&gt;% \n  write_lines(\"data/gpt_turbo_3.txt\")\n\n\ngpt_turbo_3 &lt;- read_lines(\"data/gpt_turbo_3.txt\")\ncat(str_c(gpt_turbo_3, collapse = \"\\n\"))\n#&gt; 데이터 과학자들이 널리 사용하는 데이터 시각화를 위한 인기 있는 R 라이브러리가 몇 가지 있습니다. 가장 인기 있는 것 중 일부는 다음과 같습니다:\n#&gt; \n#&gt; 1. ggplot2: ggplot2는 복잡하고 미학적으로 매력적인 플롯을 만들 수 있게 해주는 강력하고 유연한 데이터 시각화 라이브러리입니다. 그래픽 문법에 기반을 두고 있으며 다양한 사용자 정의 옵션을 제공합니다.\n#&gt; \n#&gt; 2. lattice: lattice는 다양한 고수준 플로팅 함수를 제공하는 인기 있는 데이터 시각화 라이브러리입니다. 특히 멀티 패널 플롯을 만드는 데 유용하며 복잡한 데이터 세트를 시각화하는 데 자주 사용됩니다.\n#&gt; \n#&gt; 3. plotly: plotly는 사용자가 대화형 및 동적 플롯을 만들 수 있는 웹 기반 데이터 시각화 라이브러리입니다. 대화형 대시 보드 및 온라인 공유 가능한 시각화를 만드는 데 특히 유용합니다.\n#&gt; \n#&gt; 4. ggvis: ggvis는 그래픽 문법을 기반으로하며 대화형 및 동적 플롯의 다양한 기능을 제공하는 데이터 시각화 라이브러리입니다. 특히 웹 애플리케이션에서 사용할 수 있는 대화형 플롯을 만드는 데 유용합니다.\n#&gt; \n#&gt; 5. rCharts: rCharts는 다양한 대화형 및 동적 플롯을 제공하는 데이터 시각화 라이브러리입니다. 특히 웹 애플리케이션에 포함될 수 있는 대화형 시각화를 만드는 데 유용합니다.\n#&gt; \n#&gt; 이러한 라이브러리는 산점도, 꺾은 선 그래프, 막대 그래프, 히스토그램, 히트맵 등 다양한 시각화를 만드는 데 사용됩니다. 다양한 사용자 정의 옵션을 제공하며 복잡한 데이터 세트를 전달하는 데 도움이 되는 시각적으로 매력적이고 정보성 있는 플롯을 만들 수 있습니다.\n\n\n3.2.2 text-davinci-003\n\nInstructGPT text-davinci-003 모형에 넣어 번역 품질을 살펴보자.\n\nwith open('data/gpt_turbo_result.txt', 'r') as file:\n    source_text = file.read()\n\ndef translate_by_instruct_model(text, model, source_language, target_language):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n\n    response = openai.Completion.create(\n        model=model,\n        prompt=prompt,\n        max_tokens=2000,\n        n=1,\n        temperature=0,\n    )\n\n    return response\n\ndavinci_text = translate_by_instruct_model(source_text, 'text-davinci-003', 'English', 'Korean')\n\n\ndavinci_text &lt;- glue::glue(\"{py$davinci_text['choices'][[1]]$text}\\n\")\ndavinci_text %&gt;% \n  write_lines(\"data/davinci_text.txt\")\n\n\ndavinci_text &lt;- read_lines(\"data/davinci_text.txt\")\ncat(str_c(davinci_text, collapse = \"\\n\"))\n#&gt; \n#&gt; 데이터 시각화를 위해 널리 사용되는 인기있는 R 라이브러리가 여러 개 있습니다. 가장 인기있는 것들 중 몇 가지는 다음과 같습니다.\n#&gt; \n#&gt; 1. ggplot2 : ggplot2은 강력하고 유연한 데이터 시각화 라이브러리로, 사용자가 복잡하고 아름다운 그래프를 만들 수 있습니다. 그래프의 문법을 기반으로 하며 다양한 사용자 정의 옵션을 제공합니다.\n#&gt; \n#&gt; 2. lattice : lattice는 다른 인기있는 데이터 시각화 라이브러리로, 다양한 고수준 그래프 기능을 제공합니다. 다중 패널 그래프를 만들 때 특히 유용하며, 복잡한 데이터 세트를 시각화하는 데 자주 사용됩니다.\n#&gt; \n#&gt; 3. plotly : plotly은 웹 기반 데이터 시각화 라이브러리로, 사용자가 상호 작용적이고 동적인 그래프를 만들 수 있습니다. 상호 작용적인 대시 보드 및 온라인으로 공유할 수 있는 시각화를 만들 때 특히 유용합니다.\n#&gt; \n#&gt; 4. ggvis : ggvis는 그래프의 문법을 기반으로한 데이터 시각화 라이브러리로, 다양한 상호 작용적이고 동적인 그래프를 제공합니다. 웹 응용 프로그램에서 사용할 수있는 상호 작용적인 그래프를 만들 때 특히 유용합니다.\n#&gt; \n#&gt; 5. rCharts : rCharts는 다양한 상호 작용적이고 동적인 그래프를 제공하는 데이터 시각화 라이브러리입니다. 웹 응용 프로그램에 통합할 수있는 상호 작용적인 시각화를 만들 때 특히 유용합니다.\n#&gt; \n#&gt; 이러한 라이브러리는 산점도, 선 그래프, 막대 그래프, 히스토그램, 히트맵 등 다양한 시각화를 만들기 위해 사용됩니다. 이들은 다양한 사용자 정의 옵션을 제공하고, 사용자가 복잡한 데이터 세트를 전달하기 위해 아름다운 그래프를 만들 수 있도록 합니다.\n\n\n3.2.3 text-curie-001\n\nInstructGPT text-curie-001 모형에 넣어 번역 품질을 살펴보자.\n\ndef translate_by_instruct_model(text, model, source_language, target_language):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n\n    response = openai.Completion.create(\n        model=model,\n        prompt=prompt,\n        max_tokens=1500,\n        n=1,\n        temperature=0,\n    )\n\n    return response\n  \ncurie_text = translate_by_instruct_model(source_text, 'text-curie-001', 'English', 'Korean')\n\n\ncurie_text &lt;- glue::glue(\"{py$curie_text['choices'][[1]]$text}\\n\")\ncurie_text %&gt;% \n  write_lines(\"data/curie_text.txt\")\n\n\ncurie_text &lt;- read_lines(\"data/curie_text.txt\")\ncat(str_c(curie_text, collapse = \"\\n\"))\n#&gt; \n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that can be embedded in web applications.\n\n\n3.2.4 text-babbage-001\n\nInstructGPT text-babbage-001 모형에 넣어 번역 품질을 살펴보자.\n\nbabbage_text = translate_by_instruct_model(source_text, 'text-babbage-001', 'English', 'Korean')\n\n\nbabbage_text &lt;- glue::glue(\"{py$babbage_text['choices'][[1]]$text}\\n\")\nbabbage_text %&gt;% \n  write_lines(\"data/babbage_text.txt\")\n\n\nbabbage_text &lt;- read_lines(\"data/babbage_text.txt\")\ncat(str_c(babbage_text, collapse = \"\\n\"))\n#&gt; \n#&gt; Korean: 사용한 데이터보호사이트 개발사이트\n\n\n3.2.5 text-ada-001\n\nInstructGPT text-ada-001 모형에 넣어 번역 품질을 살펴보자.\n\nada_text = translate_by_instruct_model(source_text, 'text-ada-001', 'English', 'Korean')\n\n\nada_text &lt;- glue::glue(\"{py$ada_text['choices'][[1]]$text}\\n\")\nada_text %&gt;% \n  write_lines(\"data/ada_text.txt\")\n\n\nada_text &lt;- read_lines(\"data/ada_text.txt\")\ncat(str_c(ada_text, collapse = \"\\n\"))\n#&gt; \n#&gt; Korean\n#&gt; \n#&gt; There are several popular R libraries for data visualization that are widely used by data scientists. Some of the most popular ones are:\n#&gt; \n#&gt; 1. ggplot2: ggplot2 is a powerful and flexible data visualization library that allows users to create complex and aesthetically pleasing plots. It is based on the grammar of graphics and provides a wide range of customization options.\n#&gt; \n#&gt; 2. lattice: lattice is another popular data visualization library that provides a wide range of high-level plotting functions. It is particularly useful for creating multi-panel plots and is often used for visualizing complex data sets.\n#&gt; \n#&gt; 3. plotly: plotly is a web-based data visualization library that allows users to create interactive and dynamic plots. It is particularly useful for creating interactive dashboards and visualizations that can be shared online.\n#&gt; \n#&gt; 4. ggvis: ggvis is a data visualization library that is based on the grammar of graphics and provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive plots that can be used in web applications.\n#&gt; \n#&gt; 5. rCharts: rCharts is a data visualization library that provides a wide range of interactive and dynamic plots. It is particularly useful for creating interactive visualizations that are embedded in web applications."
  },
  {
    "objectID": "translation.html#챗gpt-추천",
    "href": "translation.html#챗gpt-추천",
    "title": "chatGPT",
    "section": "\n3.3 챗GPT 추천",
    "text": "3.3 챗GPT 추천\n\n\n\n\n\n\nPrompt: recommend instructGPT model for english to korean translation\n\n\n\n\n\nSure, for English to Korean translation, you can use the OpenAI model text-davinci-002 or text-davinci-002-instruct-beta. These models have been trained on a large amount of data and are capable of high-quality translation.\nTo use these models, you can modify the translate_text_by_model function like this:\ndef translate_text_by_model(text, model=\"text-davinci-002-instruct-beta\", source_language=\"en\", target_language=\"ko\"):\n    prompt = f\"Translate the following '{source_language}' text to '{target_language}': {text}\"\n    response = openai.Completion.create(\n        engine=model,\n        prompt=prompt,\n        max_tokens=2000,\n        n=1,\n        stop=None,\n        temperature=0.5,\n    )\n\n    return response.choices[0].text\nHere, we’re using the Completion.create function to directly send the prompt to the API, without the need for the messages parameter. The max_tokens parameter controls the maximum number of tokens that the API can return in the response, so you may want to adjust this value based on your needs.\nNote that text-davinci-002-instruct-beta is a beta model that supports instruction following. You can use this model to provide additional context to the translation by including step-by-step instructions in the prompt.\n\n\n\n\n3.3.1 text-davinci-002\n\nInstructGPT text-davinci-002 모형에 넣어 번역 품질을 살펴보자.\n\ndavinci_2_text = translate_by_instruct_model(source_text, 'text-davinci-002', 'English', 'Korean')\n\n\ndavinci_2_text &lt;- glue::glue(\"{py$davinci_2_text['choices'][[1]]$text}\\n\")\ndavinci_2_text %&gt;% \n  write_lines(\"data/davinci_2_text.txt\")\n\n\ndavinci_2_text &lt;- read_lines(\"data/davinci_2_text.txt\")\ncat(str_c(davinci_2_text, collapse = \"\\n\"))\n#&gt; \n#&gt; 1. ggplot2: ggplot2는 강력하고 유연한 데이터 시각화 라이브러리로써 사용자들이 복잡하고 아름다운 그래프를 만들 수 있게 해줍니다. 그것은 그래프의 문법에 기반하여 있으며 다양한 커스터마이징 옵션을 제공합니다.\n#&gt; 2. lattice: lattice는 또 다른 인기있는 데이터 시각화 라이브러리로써 다양한 고수준의 그래프 그리기 기능을 제공합니다. 다중 패널 그래프를 만드는데 특히 유용하며, 복잡한 데이터 세트를 시각화하는데 자주 사용됩니다.\n#&gt; 3. plotly: plotly는 웹 기반의 데이터 시각화 라이브러리로써 사용자들이 상호 작용적이고 동적인 그래프를 만들 수 있게 해줍니다. 특히 웹 애플리케이션에서 사용할 수 있는 상호 작용적인 대시보드와 시각화를 만드는데 특히 유용합니다.\n#&gt; 4. ggvis: ggvis는 그래프의 문법에 기반한 데이터 시각화 라이브러리로써 다양한 상호 작용적이고 동적인 그래프를 제공합니다. 특히 웹 애플리케이션에서 사용할 수 있는 상호 작용적인 그래프를 만드는데 특히 유용합니다.\n#&gt; 5. rCharts: rCharts는 다양한 상호 작용적이고 동적인 그래프를 제공하는 데이터 시각화 라이브러리입니다. 특히 웹 애플리케이션에서 사용할 수 있는 상호 작용적인 시각화를 만드는데 특히 유용합니다.\n#&gt; \n#&gt; 이러한 라이브러리들은 산점도, 선 그래프, 막대 그래프, 히스토그램, 히트맵 등 다양한 시각화를 만들기 위해 사용됩니다. 다양한 커스터마이징 옵션을 제공하며, 사용자들이 보기 좋고 정보적인 그래프를 만들어 복잡한 데이터 세\n\n\n3.3.2 davinci-instruct-beta\n\nInstructGPT davinci-instruct-beta 모형에 넣어 번역 품질을 살펴보자.\n\ndavinci_instruct_text = translate_by_instruct_model(source_text, 'davinci-instruct-beta', 'English', 'Korean')\n\n\ndavinci_instruct_text &lt;- glue::glue(\"{py$davinci_instruct_text['choices'][[1]]$text}\\n\")\ndavinci_instruct_text %&gt;% \n  write_lines(\"data/davinci_instruct_text.txt\")\n\n\ndavinci_instruct_text &lt;- read_lines(\"data/davinci_instruct_text.txt\")\ncat(str_c(davinci_instruct_text, collapse = \"\\n\"))\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파일을 읽어주세요.\n#&gt; \n#&gt; 여러번째 파"
  },
  {
    "objectID": "prompt_data_science.html#질문-1",
    "href": "prompt_data_science.html#질문-1",
    "title": "chatGPT",
    "section": "\n3.1 질문 1",
    "text": "3.1 질문 1\n\n코드question_01 &lt;- \"데이터 탐색이란 무엇이며, 데이터 과학에서 어떻게 유용한가요?\"\n\nformat_answer &lt;- function(question) {\n  \n  answer_json &lt;- py$answer_question(question)\n  answer_list &lt;- jsonlite::fromJSON(as.character(answer_json))\n  return(answer_list)\n}\n\nanswer_01 &lt;- format_answer(question_01)\nanswer_01_text &lt;- answer_01$choices$message$content\n\n\n\n\n\n질문\n데이터 탐색이란 무엇이며, 데이터 과학에서 어떻게 유용한가요?\n\n\n답변\n데이터 탐색은 데이터를 이해하고 분석하기 위해 데이터를 시각화하고 요약하는 과정입니다. 이 과정에서 데이터의 패턴, 이상치, 결측치 등을 파악하고 데이터의 특성을 파악할 수 있습니다.\n데이터 과학에서 데이터 탐색은 매우 중요합니다. 데이터 탐색을 통해 데이터의 특성을 파악하고 이를 바탕으로 데이터 전처리를 수행할 수 있습니다. 또한 데이터 탐색을 통해 데이터 분석에 필요한 변수를 선택하고 모델링에 적합한 데이터를 선별할 수 있습니다.\n데이터 탐색은 또한 데이터 시각화를 통해 데이터의 패턴을 파악할 수 있습니다. 이를 통해 데이터의 특성을 더 잘 이해하고 데이터 분석 결과를 시각적으로 표현할 수 있습니다.\n따라서 데이터 과학에서 데이터 탐색은 데이터 분석의 첫 단계이며, 데이터 분석의 품질과 결과에 큰 영향을 미치는 중요한 과정입니다.\n\n\n토큰수\n\n코드answer_01$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n326\n\n\nprompt_tokens\n118\n\n\ntotal_tokens\n444"
  },
  {
    "objectID": "prompt_data_science.html#질문-2-1",
    "href": "prompt_data_science.html#질문-2-1",
    "title": "chatGPT",
    "section": "\n3.2 질문 2",
    "text": "3.2 질문 2\n\n코드question_02 &lt;- \"R을 사용한 기본적인 데이터 탐색 스크립트의 예시를 제공할 수 있나요?\"\n\nanswer_02 &lt;- format_answer(question_02)\nanswer_02_text &lt;- answer_02$choices$message$content\n\n\n\n\n\n질문\nR을 사용한 기본적인 데이터 탐색 스크립트의 예시를 제공할 수 있나요?\n\n\n답변\n물론입니다! R을 사용한 기본적인 데이터 탐색 스크립트의 예시는 다음과 같습니다.\n# 데이터 불러오기\ndata &lt;- read.csv(\"data.csv\")\n\n# 데이터 구조 파악하기\nstr(data)\n\n# 데이터 요약 보기\nsummary(data)\n\n# 변수 간 상관관계 파악하기\ncor(data)\n\n# 변수 간 산점도 그리기\nplot(data$var1, data$var2)\n\n# 변수 분포 파악하기\nhist(data$var1)\n\n# 변수 간 차이 파악하기\nt.test(data$var1 ~ data$var2)\n\n# 변수 간 차이 시각화하기\nboxplot(data$var1 ~ data$var2)\n위 스크립트는 데이터를 불러오고, 데이터의 구조와 요약을 파악하며, 변수 간 상관관계와 분포를 파악하고, 변수 간 차이를 분석하며, 차이를 시각화하는 기본적인 데이터 탐색 스크립트입니다. 이를 기반으로 데이터 분석을 진행할 수 있습니다.\n\n\n토큰수\n\n코드answer_02$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n311\n\n\nprompt_tokens\n116\n\n\ntotal_tokens\n427"
  },
  {
    "objectID": "prompt_data_science.html#질문-3-1",
    "href": "prompt_data_science.html#질문-3-1",
    "title": "chatGPT",
    "section": "\n3.3 질문 3",
    "text": "3.3 질문 3\n\n코드question_03 &lt;- \"PCA를 사용하여 변수간 관계를 탐색하기 위해 차원 축소를 어떻게 수행할 수 있나요?\"\n\nanswer_03 &lt;- format_answer(question_03)\nanswer_03_text &lt;- answer_03$choices$message$content\n\n\n\n\n\n질문\nPCA를 사용하여 변수간 관계를 탐색하기 위해 차원 축소를 어떻게 수행할 수 있나요?\n\n\n답변\nPCA(Principal Component Analysis)는 다차원 데이터를 분석하는 기법 중 하나로, 변수 간의 상관관계를 파악하고 차원을 축소하여 데이터를 시각화하거나 분석하는 데 사용됩니다.\nPCA를 사용하여 변수 간 관계를 탐색하기 위해 차원 축소를 수행하는 방법은 다음과 같습니다.\n\n데이터 전처리: PCA를 수행하기 전에 데이터를 정규화하거나 표준화하여 변수 간의 스케일 차이를 줄입니다.\n공분산 행렬 계산: PCA는 공분산 행렬을 기반으로 합니다. 따라서 데이터의 공분산 행렬을 계산합니다.\n고유값 분해: 공분산 행렬의 고유값과 고유벡터를 계산합니다. 고유값은 각각의 고유벡터가 가리키는 방향으로 데이터의 분산을 설명하는 정도를 나타내며, 고유벡터는 데이터의 주성분(principal component)을 나타냅니다.\n주성분 선택: 고유값이 큰 순서대로 주성분을 선택합니다. 이를 통해 변수 간의 상관관계가 가장 큰 주성분을 찾아내고, 이를 기반으로 차원을 축소합니다.\n차원 축소: 선택한 주성분을 기반으로 데이터를 새로운 축으로 변환합니다. 이를 통해 변수 간의 관계를 시각화하거나 분석할 수 있습니다.\n\nPCA를 사용하여 변수 간 관계를 탐색하기 위해 차원 축소를 수행하는 방법은 위와 같습니다. 이를 통해 데이터의 구조를 파악하고, 변수 간의 상관관계를 이해할 수 있습니다.\n\n\n토큰수\n\n코드answer_03$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n527\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n649"
  },
  {
    "objectID": "prompt_data_science.html#질문-4-1",
    "href": "prompt_data_science.html#질문-4-1",
    "title": "chatGPT",
    "section": "\n3.4 질문 4",
    "text": "3.4 질문 4\n\n코드question_04 &lt;- \"PCA를 사용하여 변수간 관계를 탐색하기 위해 차원 축소를 어떻게 수행할 수 있나요?\"\n\nanswer_04 &lt;- format_answer(question_04)\nanswer_04_text &lt;- answer_04$choices$message$content\n\n\n\n\n\n질문\nPCA를 사용하여 변수간 관계를 탐색하기 위해 차원 축소를 어떻게 수행할 수 있나요?\n\n\n답변\nPCA(Principal Component Analysis)는 다차원 데이터를 분석하는 기법 중 하나로, 변수 간의 상관관계를 파악하고 차원을 축소하여 데이터를 시각화하거나 분석하는 데 사용됩니다.\nPCA를 사용하여 변수 간 관계를 탐색하기 위해 차원 축소를 수행하는 방법은 다음과 같습니다.\n\n데이터 전처리: PCA를 수행하기 전에 데이터를 정규화하거나 표준화하여 변수 간의 스케일 차이를 줄입니다.\n공분산 행렬 계산: PCA는 공분산 행렬을 기반으로 합니다. 따라서 데이터의 공분산 행렬을 계산합니다.\n고유값 분해: 공분산 행렬의 고유값과 고유벡터를 계산합니다. 고유값은 각각의 고유벡터가 가리키는 방향으로 데이터의 분산을 설명하는 정도를 나타내며, 고유벡터는 데이터의 주성분(principal component)을 나타냅니다.\n차원 축소: 고유값이 큰 순서대로 고유벡터를 선택하여 데이터를 새로운 축으로 변환합니다. 이를 통해 변수 간의 상관관계를 파악하고 차원을 축소할 수 있습니다.\n시각화 및 분석: 새로운 축으로 변환된 데이터를 시각화하거나 분석하여 변수 간의 관계를 파악합니다.\n\nR에서는 PCA를 수행하는 다양한 함수들이 제공되고 있습니다. 예를 들어, prcomp() 함수를 사용하여 PCA를 수행할 수 있습니다.\n\n\n토큰수\n\n코드answer_04$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n497\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n619"
  },
  {
    "objectID": "prompt_data_science.html#질문-5-1",
    "href": "prompt_data_science.html#질문-5-1",
    "title": "chatGPT",
    "section": "\n3.5 질문 5",
    "text": "3.5 질문 5\n\n코드question_05 &lt;- \"t-SNE, PCA 및 클러스터링을 사용하여 변수간 관계를 탐색하는 데이터 탐색 스크립트의 예시를 제공할 수 있나요?\"\n\nanswer_05 &lt;- format_answer(question_05)\nanswer_05_text &lt;- answer_05$choices$message$content\n\n\n\n\n\n질문\nt-SNE, PCA 및 클러스터링을 사용하여 변수간 관계를 탐색하는 데이터 탐색 스크립트의 예시를 제공할 수 있나요?\n\n\n답변\n네, t-SNE, PCA 및 클러스터링을 사용하여 변수간 관계를 탐색하는 데이터 탐색 스크립트의 예시를 제공할 수 있습니다. 아래는 예시 코드입니다.\n# 데이터 불러오기\ndata &lt;- read.csv(\"data.csv\")\n\n# 변수 선택\nselected_vars &lt;- c(\"var1\", \"var2\", \"var3\", \"var4\")\n\n# PCA 수행\npca &lt;- prcomp(data[, selected_vars], scale = TRUE)\n\n# t-SNE 수행\ntsne &lt;- Rtsne::Rtsne(data[, selected_vars], perplexity = 30, dims = 2)\n\n# 클러스터링 수행\nkmeans &lt;- kmeans(data[, selected_vars], centers = 3)\n\n# 시각화\nlibrary(ggplot2)\n\n# PCA 시각화\nggplot(data, aes(x = pca$x[,1], y = pca$x[,2], color = factor(kmeans$cluster))) + \n  geom_point() + \n  ggtitle(\"PCA\")\n\n# t-SNE 시각화\nggplot(data, aes(x = tsne$Y[,1], y = tsne$Y[,2], color = factor(kmeans$cluster))) + \n  geom_point() + \n  ggtitle(\"t-SNE\")\n\n# 클러스터링 시각화\nggplot(data, aes(x = var1, y = var2, color = factor(kmeans$cluster))) + \n  geom_point() + \n  ggtitle(\"Clustering\")\n위 코드에서는 먼저 데이터를 불러온 후, 변수를 선택합니다. 그 다음으로 PCA를 수행하고, t-SNE를 수행합니다. 마지막으로 클러스터링을 수행합니다. 시각화를 위해 ggplot2 패키지를 사용합니다. PCA, t-SNE 및 클러스터링 결과를 각각 시각화합니다.\n\n\n토큰수\n\n코드answer_05$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n455\n\n\nprompt_tokens\n133\n\n\ntotal_tokens\n588"
  },
  {
    "objectID": "prompt_data_science.html#질문-6-1",
    "href": "prompt_data_science.html#질문-6-1",
    "title": "chatGPT",
    "section": "\n3.6 질문 6",
    "text": "3.6 질문 6\n\n코드question_06 &lt;- \"tibble과 ggplot2를 사용하여 시계열 데이터에서 패턴과 추세를 어떻게 식별할 수 있나요?\"\n\nanswer_06 &lt;- format_answer(question_06)\nanswer_06_text &lt;- answer_06$choices$message$content\n\n\n\n\n\n질문\ntibble과 ggplot2를 사용하여 시계열 데이터에서 패턴과 추세를 어떻게 식별할 수 있나요?\n\n\n답변\n시계열 데이터에서 패턴과 추세를 식별하는 방법은 다양하지만, tibble과 ggplot2를 사용하는 방법을 설명해드리겠습니다.\n\ntibble을 사용하여 데이터를 정리합니다. 시계열 데이터를 분석하기 전에, 데이터를 정리하는 것이 중요합니다. tibble은 tidyverse 패키지에 포함된 데이터 정리 도구로, 데이터를 깔끔하게 정리할 수 있습니다. 시계열 데이터의 경우, 날짜와 값의 두 열로 구성된 데이터프레임을 만들어야 합니다. 이를 위해 lubridate 패키지를 사용하여 날짜 데이터를 처리할 수 있습니다.\nggplot2를 사용하여 시계열 그래프를 그립니다. ggplot2는 데이터 시각화를 위한 R 패키지로, 시계열 데이터를 그래프로 그리는 데 유용합니다. ggplot2를 사용하여 시계열 그래프를 그리기 위해서는, 먼저 x축에 날짜를, y축에 값(예: 주식 가격)을 지정해야 합니다. 이후 geom_line() 함수를 사용하여 선 그래프를 그릴 수 있습니다.\n추세선과 패턴을 추가합니다. 시계열 데이터에서 추세를 식별하기 위해서는, 추세선을 그려야 합니다. 이를 위해 geom_smooth() 함수를 사용하여 추세선을 추가할 수 있습니다. 또한, 패턴을 식별하기 위해서는, geom_point() 함수를 사용하여 점 그래프를 추가할 수 있습니다. 이를 통해 데이터의 특정 패턴을 시각적으로 확인할 수 있습니다.\n추가적인 분석을 수행합니다. 시계열 데이터에서 패턴과 추세를 식별하는 것은 중요한 분석 과정 중 하나일 뿐입니다. 추가적인 분석을 수행하여, 데이터의 특성을 더욱 자세히 파악할 수 있습니다. 예를 들어, ARIMA 모델을 사용하여 시계열 데이터를 예측하거나, 이동평균을 계산하여 추세를 더욱 정확하게 파악할 수 있습니다.\n\n이러한 방법을 사용하여, tibble과 ggplot2를 활용하여 시계열 데이터에서 패턴과 추세를 식별할 수 있습니다.\n\n\n토큰수\n\n코드answer_06$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n663\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n785"
  },
  {
    "objectID": "prompt_data_science.html#질문-7-1",
    "href": "prompt_data_science.html#질문-7-1",
    "title": "chatGPT",
    "section": "\n3.7 질문 7",
    "text": "3.7 질문 7\n\n코드question_07 &lt;- \"tibble과 ggplot2를 사용하여 데이터에서 패턴과 추세를 식별하는 데이터 탐색 스크립트의 예시를 제공할 수 있나요?\"\n\nanswer_07 &lt;- format_answer(question_07)\nanswer_07_text &lt;- answer_07$choices$message$content\n\n\n\n\n\n질문\ntibble과 ggplot2를 사용하여 데이터에서 패턴과 추세를 식별하는 데이터 탐색 스크립트의 예시를 제공할 수 있나요?\n\n\n답변\n네, tibble과 ggplot2를 사용하여 데이터에서 패턴과 추세를 식별하는 데이터 탐색 스크립트를 작성할 수 있습니다. 아래는 예시 코드입니다.\nlibrary(tidyverse)\n\n# 데이터 불러오기\ndata &lt;- read_csv(\"data.csv\")\n\n# 데이터 전처리\ndata &lt;- data %&gt;%\n  mutate(date = as.Date(date)) %&gt;%\n  arrange(date)\n\n# tibble 생성\ndata_tbl &lt;- as_tibble(data)\n\n# ggplot2를 사용하여 데이터 시각화\nggplot(data_tbl, aes(x = date, y = value)) +\n  geom_line() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"패턴과 추세 식별\", x = \"날짜\", y = \"값\")\n위 코드에서는 먼저 tidyverse 패키지를 불러온 후, 데이터를 불러와 전처리합니다. 그 다음, tibble을 생성하고 ggplot2를 사용하여 데이터를 시각화합니다. geom_line() 함수는 데이터의 패턴을 보여주며, geom_smooth() 함수는 데이터의 추세를 보여줍니다. labs() 함수를 사용하여 그래프의 제목과 축 레이블을 지정할 수 있습니다.\n이렇게 작성된 스크립트를 실행하면, 데이터에서 패턴과 추세를 식별할 수 있는 그래프가 생성됩니다. 이를 통해 데이터를 더 잘 이해하고, 다음 분석에 활용할 수 있습니다.\n\n\n토큰수\n\n코드answer_07$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n395\n\n\nprompt_tokens\n130\n\n\ntotal_tokens\n525"
  },
  {
    "objectID": "prompt_data_science.html#질문-8-1",
    "href": "prompt_data_science.html#질문-8-1",
    "title": "chatGPT",
    "section": "\n3.8 질문 8",
    "text": "3.8 질문 8\n\n코드question_08 &lt;- \"tibble과 ggplot2를 사용하여 변수간 관계를 탐색하기 위한 일반적인 기술은 무엇인가요?\"\n\nanswer_08 &lt;- format_answer(question_08)\nanswer_08_text &lt;- answer_08$choices$message$content\n\n\n\n\n\n질문\ntibble과 ggplot2를 사용하여 변수간 관계를 탐색하기 위한 일반적인 기술은 무엇인가요?\n\n\n답변\ntibble과 ggplot2를 사용하여 변수간 관계를 탐색하기 위한 일반적인 기술은 산점도(Scatter plot)입니다. 산점도는 두 변수 간의 관계를 시각화하는 데 사용되며, x축과 y축에 각각의 변수를 할당하여 데이터 포인트를 표시합니다. 이를 통해 변수 간의 상관 관계를 파악하고, 이상치나 패턴 등을 확인할 수 있습니다. ggplot2를 사용하면 산점도를 그리는 것이 매우 간단하며, 추가적인 레이어를 추가하여 더 많은 정보를 시각화할 수 있습니다. 예를 들어, 색상, 크기, 모양 등을 이용하여 다른 변수를 추가적으로 시각화할 수 있습니다.\n\n\n토큰수\n\n코드answer_08$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n235\n\n\nprompt_tokens\n123\n\n\ntotal_tokens\n358"
  },
  {
    "objectID": "prompt_data_science.html#질문-9-1",
    "href": "prompt_data_science.html#질문-9-1",
    "title": "chatGPT",
    "section": "\n3.9 질문 9",
    "text": "3.9 질문 9\n\n코드question_09 &lt;- \"tibble과 ggplot2를 사용하여 산점도와 선 그래프를 생성하여 변수간 관계를 탐색할 수 있는 방법은 무엇인가요?\"\n\nanswer_09 &lt;- format_answer(question_09)\nanswer_09_text &lt;- answer_09$choices$message$content\n\n\n\n\n\n질문\ntibble과 ggplot2를 사용하여 산점도와 선 그래프를 생성하여 변수간 관계를 탐색할 수 있는 방법은 무엇인가요?\n\n\n답변\n먼저, tibble은 데이터 프레임의 확장판으로 tidyverse 패키지에 포함되어 있습니다. tibble은 데이터를 더욱 쉽게 다룰 수 있도록 구조화된 데이터 형식을 제공합니다.\nggplot2는 R에서 가장 인기 있는 시각화 패키지 중 하나입니다. ggplot2를 사용하면 데이터를 시각화하기 위한 다양한 그래프를 생성할 수 있습니다.\n산점도를 생성하기 위해서는 ggplot2의 geom_point() 함수를 사용합니다. 이 함수는 x축과 y축에 해당하는 변수를 지정하고, 데이터를 산점도로 표현합니다. 예를 들어, 다음과 같이 mpg 데이터셋에서 displ(배기량)과 hwy(고속도로 연비) 변수간의 산점도를 그릴 수 있습니다.\nlibrary(ggplot2)\nlibrary(tibble)\n\nmpg_tibble &lt;- as_tibble(mpg) # mpg 데이터셋을 tibble 형식으로 변환\nggplot(mpg_tibble, aes(x = displ, y = hwy)) + geom_point()\n선 그래프를 생성하기 위해서는 ggplot2의 geom_line() 함수를 사용합니다. 이 함수는 x축과 y축에 해당하는 변수를 지정하고, 데이터를 선 그래프로 표현합니다. 예를 들어, 다음과 같이 airquality 데이터셋에서 Month(월)와 Ozone(오존) 변수간의 선 그래프를 그릴 수 있습니다.\nairquality_tibble &lt;- as_tibble(airquality) # airquality 데이터셋을 tibble 형식으로 변환\nggplot(airquality_tibble, aes(x = Month, y = Ozone)) + geom_line()\n이렇게 생성된 산점도와 선 그래프를 통해 변수간의 관계를 시각적으로 파악할 수 있습니다.\n\n\n토큰수\n\n코드answer_09$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n502\n\n\nprompt_tokens\n133\n\n\ntotal_tokens\n635"
  },
  {
    "objectID": "prompt_data_science.html#질문-10-1",
    "href": "prompt_data_science.html#질문-10-1",
    "title": "chatGPT",
    "section": "\n3.10 질문 10",
    "text": "3.10 질문 10\n\n코드question_10 &lt;- \"PCA를 사용하여 변수간 관계를 탐색하기 위해 차원 축소를 어떻게 수행할 수 있나요?\"\n\nanswer_10 &lt;- format_answer(question_10)\nanswer_10_text &lt;- answer_10$choices$message$content\n\n\n\n\n\n질문\nPCA를 사용하여 변수간 관계를 탐색하기 위해 차원 축소를 어떻게 수행할 수 있나요?\n\n\n답변\nPCA(Principal Component Analysis)는 다차원 데이터를 분석하는 기법 중 하나로, 변수 간의 상관관계를 파악하고 차원을 축소하여 데이터를 시각화하거나 분석하는 데 사용됩니다.\nPCA를 사용하여 변수 간 관계를 탐색하기 위해 차원 축소를 수행하는 방법은 다음과 같습니다.\n\n데이터 전처리: PCA를 수행하기 전에 데이터를 정규화하거나 표준화하여 변수 간의 스케일 차이를 줄입니다.\n공분산 행렬 계산: PCA는 공분산 행렬을 기반으로 합니다. 따라서 데이터의 공분산 행렬을 계산합니다.\n고유값 분해: 공분산 행렬의 고유값과 고유벡터를 계산합니다. 고유값은 각각의 고유벡터가 가리키는 방향으로 데이터의 분산을 설명하는 정도를 나타내며, 고유벡터는 데이터의 주성분(principal component)을 나타냅니다.\n차원 축소: 고유값이 큰 순서대로 고유벡터를 선택하여 차원을 축소합니다. 이를 통해 데이터의 주요한 패턴을 파악할 수 있습니다.\n시각화: 차원 축소된 데이터를 시각화하여 변수 간의 관계를 파악합니다. 예를 들어, 2차원으로 축소한 데이터를 산점도로 나타내어 변수 간의 상관관계를 파악할 수 있습니다.\n\n이러한 방법을 통해 PCA를 사용하여 변수 간 관계를 탐색하고 차원을 축소할 수 있습니다.\n\n\n토큰수\n\n코드answer_10$usage %&gt;% \n  unlist() %&gt;% \n  enframe(name = \"토큰구분\", value = \"토큰수\") %&gt;% \n  gt::gt()\n\n\n\n\n\n\n토큰구분\n토큰수\n\n\n\ncompletion_tokens\n505\n\n\nprompt_tokens\n122\n\n\ntotal_tokens\n627"
  },
  {
    "objectID": "autoGPT_ds.html",
    "href": "autoGPT_ds.html",
    "title": "chatGPT",
    "section": "",
    "text": "Hmisc 패키지를 통해 과거 20년전 데이터 분석방법을 음미합니다.\n\n코드library(tidyverse)\n\npenguins &lt;- palmerpenguins::penguins %&gt;%\n  # 영어 변수명 한글 변환\n  set_names(c(\"종명칭\", \"섬이름\", \"부리_길이\", \"부리_깊이\", \"물갈퀴_길이\",\n              \"체중\", \"성별\", \"연도\")) %&gt;%\n  # 결측값 제거\n  # drop_na() %&gt;%\n  # 영어 값 한글 값으로 변환\n  mutate(성별 = ifelse(성별 == \"male\", \"수컷\", \"암컷\"),\n         섬이름 = case_when( str_detect(섬이름, \"Biscoe\") ~ \"비스코\",\n                          str_detect(섬이름, \"Dream\") ~ \"드림\",\n                          str_detect(섬이름, \"Torgersen\") ~ \"토르거센\"),\n         종명칭 = case_when( str_detect(종명칭, \"Adelie\") ~ \"아델리\",\n                          str_detect(종명칭, \"Chinstrap\") ~ \"턱끈\",\n                          str_detect(종명칭, \"Gentoo\") ~ \"젠투\")\n  ) %&gt;%\n  # 자료형 변환\n  mutate(성별   = factor(성별, levels = c(\"수컷\", \"암컷\")),\n         섬이름 = factor(섬이름, levels = c(\"비스코\", \"드림\", \"토르거센\")),\n         종명칭 = factor(종명칭, levels = c(\"아델리\", \"턱끈\", \"젠투\")),\n         연도   = ordered(연도, levels = c(2007, 2008, 2009)))\n\n\n\nHmisc::describe(penguins)\n\npenguins \n\n 8  Variables      344  Observations\n--------------------------------------------------------------------------------\n종명칭 \n       n  missing distinct \n     344        0        3 \n                                     \nValue        아델리     턱끈     젠투\nFrequency    152       68      124   \nProportion 0.442    0.198    0.360   \n--------------------------------------------------------------------------------\n섬이름 \n       n  missing distinct \n     344        0        3 \n                                     \nValue        비스코     드림 토르거센\nFrequency    168      124       52   \nProportion 0.488    0.360    0.151   \n--------------------------------------------------------------------------------\n부리_길이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2      164        1    43.92    6.274    35.70    36.60 \n     .25      .50      .75      .90      .95 \n   39.23    44.45    48.50    50.80    51.99 \n\nlowest : 32.1 33.1 33.5 34.0 34.1, highest: 55.1 55.8 55.9 58.0 59.6\n--------------------------------------------------------------------------------\n부리_깊이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       80        1    17.15    2.267     13.9     14.3 \n     .25      .50      .75      .90      .95 \n    15.6     17.3     18.7     19.5     20.0 \n\nlowest : 13.1 13.2 13.3 13.4 13.5, highest: 20.7 20.8 21.1 21.2 21.5\n--------------------------------------------------------------------------------\n물갈퀴_길이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       55    0.999    200.9    16.03    181.0    185.0 \n     .25      .50      .75      .90      .95 \n   190.0    197.0    213.0    220.9    225.0 \n\nlowest : 172 174 176 178 179, highest: 226 228 229 230 231\n--------------------------------------------------------------------------------\n체중 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       94        1     4202    911.8     3150     3300 \n     .25      .50      .75      .90      .95 \n    3550     4050     4750     5400     5650 \n\nlowest : 2700 2850 2900 2925 2975, highest: 5850 5950 6000 6050 6300\n--------------------------------------------------------------------------------\n성별 \n       n  missing distinct \n     333       11        2 \n                          \nValue         수컷    암컷\nFrequency    168     165  \nProportion 0.505   0.495  \n--------------------------------------------------------------------------------\n연도 \n       n  missing distinct \n     344        0        3 \n                            \nValue       2007  2008  2009\nFrequency    110   114   120\nProportion 0.320 0.331 0.349\n--------------------------------------------------------------------------------\n\n\n\nskimr 패키지를 사용하여 분석할 데이터와 친숙해진다.\n\n코드penguins %&gt;% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n종명칭\n0\n1.00\nFALSE\n3\n아델리: 152, 젠투: 124, 턱끈: 68\n\n\n섬이름\n0\n1.00\nFALSE\n3\n비스코: 168, 드림: 124, 토르거: 52\n\n\n성별\n11\n0.97\nFALSE\n2\n수컷: 168, 암컷: 165\n\n\n연도\n0\n1.00\nTRUE\n3\n200: 120, 200: 114, 200: 110\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n부리_길이\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\n부리_깊이\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\n물갈퀴_길이\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\n체중\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\n\n\n\n\ndataxray 패키지를 사용해서 데이터에 대한 이해를 더욱 높일 수 있다.\n\n\n코드library(dataxray)\n\npenguins %&gt;% \n   make_xray() %&gt;% \n   view_xray()\n\n\n\n\nExpand/collapse all\n\n\n\n\n\n\n\n\n\n\n\ndlookr 패키지를 사용하여 분석할 데이터와 친숙해진다.\n\n코드library(kableExtra)\npenguins %&gt;% \n  dlookr::describe() %&gt;% \n  kable(caption = \"요약통계량\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)  \n\n\n\n요약통계량\n\ndescribed_variables\nn\nna\nmean\nsd\nse_mean\nIQR\nskewness\nkurtosis\np00\np01\np05\np10\np20\np25\np30\np40\np50\np60\np70\np75\np80\np90\np95\np99\np100\n\n\n\n부리_길이\n342\n2\n43.92193\n5.459584\n0.2952205\n9.275\n0.0531181\n-0.8760270\n32.1\n34.041\n35.7\n36.6\n38.34\n39.225\n40.20\n42.0\n44.45\n46.0\n47.37\n48.5\n49.38\n50.8\n51.995\n55.513\n59.6\n\n\n부리_깊이\n342\n2\n17.15117\n1.974793\n0.1067846\n3.100\n-0.1434646\n-0.9068661\n13.1\n13.441\n13.9\n14.3\n15.00\n15.600\n15.93\n16.8\n17.30\n17.9\n18.50\n18.7\n18.90\n19.5\n20.000\n21.100\n21.5\n\n\n물갈퀴_길이\n342\n2\n200.91520\n14.061714\n0.7603704\n23.000\n0.3456818\n-0.9842729\n172.0\n178.000\n181.0\n185.0\n188.00\n190.000\n191.00\n194.0\n197.00\n203.0\n210.00\n213.0\n215.00\n220.9\n225.000\n230.000\n231.0\n\n\n체중\n342\n2\n4201.75439\n801.954536\n43.3647348\n1200.000\n0.4703293\n-0.7192219\n2700.0\n2900.000\n3150.0\n3300.0\n3475.00\n3550.000\n3650.00\n3800.0\n4050.00\n4300.0\n4650.00\n4750.0\n4950.00\n5400.0\n5650.000\n5979.500\n6300.0\n\n\n\n\n\n\n\n\n\nDataExplorer 패키지를 사용하여 분석할 데이터와 친숙해진다.\nDataExplorer::create_report(penguins)\n\n\n구조\nDF 요약\nDF 요약 시각화\n결측값\n분포(범주형)\n분포(연속형)\n상관관계\nPCA\n\n\n\n\n코드DataExplorer::plot_str(penguins)\n\n\n\n\n\n코드DataExplorer::introduce(penguins)\n\n# A tibble: 1 × 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1   344       8                4                  4                   0\n# ℹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;\n\n\n\n\n\n코드DataExplorer::plot_intro(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_missing(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_bar(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_histogram(penguins)\n\n\n\n\n\n\n\n\n\n\n코드penguins %&gt;% select_if(is.numeric) %&gt;% \n  # drop_na() %&gt;% \n  DataExplorer::plot_correlation(cor_args = list(\"use\" = \"pairwise.complete.obs\"))\n\n\n\n\n\n\n\n\n\n\n코드penguins_pca &lt;- penguins %&gt;% select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% prcomp(scale = TRUE)\n\nsummary(penguins_pca)$importance %&gt;% as.data.frame() %&gt;% \n  kable(caption = \"PCA 요약\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\nPCA 요약\n\n\nPC1\nPC2\nPC3\nPC4\n\n\n\nStandard deviation\n1.659444\n0.8789293\n0.6043475\n0.3293816\n\n\nProportion of Variance\n0.688440\n0.1931300\n0.0913100\n0.0271200\n\n\nCumulative Proportion\n0.688440\n0.8815700\n0.9728800\n1.0000000"
  },
  {
    "objectID": "autoGPT_ds.html#펭귄-데이터-출현",
    "href": "autoGPT_ds.html#펭귄-데이터-출현",
    "title": "chatGPT",
    "section": "",
    "text": "미국에서 “George Floyd”가 경찰에 의해 살해되면서 촉발된 “Black Lives Matter” 운동은 아프리카계 미국인을 향한 폭력과 제도적 인종주의에 반대하는 사회운동이다. 한국에서도 소수 정당인 정의당에서 여당 의원 176명 중 누가?…차별금지법 발의할 ’의인’을 구합니다로 기사로 낼 정도로 적극적으로 나서고 있다.\n데이터 과학에서 최근 R.A. Fisher의 과거 저술한 “The genetical theory of natural selection” (Fisher, 1958) 우생학(Eugenics) 대한 관점이 논란이 되면서 R 데이터 과학의 첫 데이터셋으로 붓꽃 iris 데이터를 다른 데이터, 즉 펭귄 데이터로 대체하는 움직임이 활발히 전개되고 있다. palmerpenguins (KB 기타, 2014) 데이터셋이 대안으로 많은 호응을 얻고 있다. Levy (2019)"
  },
  {
    "objectID": "autoGPT_ds.html#penguins-study",
    "href": "autoGPT_ds.html#penguins-study",
    "title": "chatGPT",
    "section": "",
    "text": "팔머(Palmer) 펭귄은 3종이 있으며 자세한 내용은 다음 나무위키를 참조한다. 1\n\n\n젠투 펭귄(Gentoo Penguin): 머리에 모자처럼 둘러져 있는 하얀 털 때문에 알아보기가 쉽다. 암컷이 회색이 뒤에, 흰색이 앞에 있다. 펭귄들 중에 가장 빠른 시속 36km의 수영 실력을 자랑하며, 짝짓기 할 준비가 된 펭귄은 75-90cm까지도 자란다.\n\n아델리 펭귄(Adelie Penguin): 프랑스 탐험가인 뒤몽 뒤르빌(Dumont D’Urville) 부인의 이름을 따서 ’아델리’라 불리게 되었다. 각진 머리와 작은 부리 때문에 알아보기 쉽고, 다른 펭귄들과 마찬가지로 암수가 비슷하게 생겼지만 암컷이 조금 더 작다.\n\n턱끈 펭귄(Chinstrap Penguin): 언뜻 보면 아델리 펭귄과 매우 비슷하지만, 몸집이 조금 더 작고, 목에서 머리 쪽으로 이어지는 검은 털이 눈에 띈다. 어린 고삐 펭귄들은 회갈색 빛을 띄는 털을 가지고 있으며, 목 아래 부분은 더 하얗다. 무리를 지어 살아가며 일부일처제를 지키기 때문에 짝짓기 이후에도 부부로써 오랫동안 함께 살아간다.\n\n\n코드library(webshot2)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#meet-the-palmer-penguins &gt; p &gt; img\", \"images/penguin-species.png\")\n\n\n\n\n팔머 펭귄 3종 세트\n\n\n다음으로 iris 데이터와 마찬가지로 펭귄 3종을 구분하기 위한 변수로 조류의 부리에 있는 중앙 세로선의 융기를 지칭하는 능선(culmen) 길이(culmen length)와 깊이(culmen depth)를 이해하면 된다.\n\n코드library(webshot)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#what-are-culmen-length--depth &gt; p:nth-child(4) &gt; img\", \"fig/penguin-species-variable.png\")\n\n\n\n\n팔머 펭귄 능선 변수"
  },
  {
    "objectID": "autoGPT_ds.html#penguin-home",
    "href": "autoGPT_ds.html#penguin-home",
    "title": "chatGPT",
    "section": "",
    "text": "leaflet 팩키지로 펭귄 서식지를 남극에서 특정한다. geocoding을 해야 하는데 구글에서 위치 정보를 구글링하면 https://latitude.to/에서 직접 위경도를 반환하여 준다. 이 정보를 근거로 하여 펭귄 서식지를 시각화한다.\n\n\n\n\n파머 연구소와 펭귄 서식지\n\n\n\n\n펭귄 3종\n\n\n\n\n\n\n아델리, 젠투, 턱끈 펭귄이 함께한 사진\n\n\n\n\n토르거센 섬에서 새끼를 키우는 아델리 펭귄\n\n\n\n\n비스코 지점 젠투 펭귄 서식지\n\n\n\n\n펭귄과 함께 현장에서 일하는 크리스틴 고먼 박사\n\n\n\n\n\n파머 펭귄 데이터셋\n\n\n\n\n코드library(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n\n# A tibble: 3 × 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n코드island_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"명칭:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   )))"
  },
  {
    "objectID": "autoGPT_ds.html#penguin-EDA-skimr",
    "href": "autoGPT_ds.html#penguin-EDA-skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr 팩키지를 사용해서 penguins 데이터프레임 자료구조를 일별한다. 이를 통해서 344개 펭귄 관측값이 있으며, 7개 칼럼으로 구성된 것을 확인할 수 있다. 또한, 범주형 변수가 3개, 숫자형 변수가 4개로 구성되어 있다. 그외 더 자세한 사항은 범주형, 숫자형 변수에 대한 요약 통계량을 참조한다.\n\n코드skimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\n\n데이터가 크지 않아 DT 팩키지를 통해 데이터 전반적인 내용을 살펴볼 수 있다.\n\n코드penguins %&gt;% \n  reactable::reactable()"
  },
  {
    "objectID": "autoGPT_ds.html#footnotes",
    "href": "autoGPT_ds.html#footnotes",
    "title": "chatGPT",
    "section": "각주",
    "text": "각주\n\n신발끈 여행사, 관광안내자료↩︎"
  },
  {
    "objectID": "autoGPT_ds.html#데이터-설치",
    "href": "autoGPT_ds.html#데이터-설치",
    "title": "chatGPT",
    "section": "",
    "text": "remotes 팩키지 install_github() 함수로 펭귄 데이터를 설치한다.\n\n코드# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\n\ntidyverse 팩키지 glimpse() 함수로 펭귄 데이터를 일별한다.\n\n코드library(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "autoGPT_ds.html#penguin-EDA",
    "href": "autoGPT_ds.html#penguin-EDA",
    "title": "chatGPT",
    "section": "",
    "text": "palmerpenguins 데이터셋 소개에 포함되어 있는 미국 팔머 연구소 (palmer station) 펭귄 물갈퀴(flipper) 길이와 체질량(body mass) 산점도를 그려보자.\n\n코드library(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"펭귄 크기\",\n       subtitle = \"남극 펭귄 3종 물갈퀴 길이와 체질량 관계\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄 3종\",\n       shape = \"펭귄 3종\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper"
  },
  {
    "objectID": "palmer_penguins.html",
    "href": "palmer_penguins.html",
    "title": "chatGPT",
    "section": "",
    "text": "미국에서 “George Floyd”가 경찰에 의해 살해되면서 촉발된 “Black Lives Matter” 운동은 아프리카계 미국인을 향한 폭력과 제도적 인종주의에 반대하는 사회운동이다. 한국에서도 소수 정당인 정의당에서 여당 의원 176명 중 누가?…차별금지법 발의할 ’의인’을 구합니다로 기사로 낼 정도로 적극적으로 나서고 있다.\n데이터 과학에서 최근 R.A. Fisher의 과거 저술한 “The genetical theory of natural selection” (Fisher, 1958) 우생학(Eugenics) 대한 관점이 논란이 되면서 R 데이터 과학의 첫 데이터셋으로 붓꽃 iris 데이터를 다른 데이터, 즉 펭귄 데이터로 대체하는 움직임이 활발히 전개되고 있다. palmerpenguins (KB 기타, 2014) 데이터셋이 대안으로 많은 호응을 얻고 있다. Levy (2019)\n\n팔머(Palmer) 펭귄은 3종이 있으며 자세한 내용은 다음 나무위키를 참조한다. 1\n\n\n젠투 펭귄(Gentoo Penguin): 머리에 모자처럼 둘러져 있는 하얀 털 때문에 알아보기가 쉽다. 암컷이 회색이 뒤에, 흰색이 앞에 있다. 펭귄들 중에 가장 빠른 시속 36km의 수영 실력을 자랑하며, 짝짓기 할 준비가 된 펭귄은 75-90cm까지도 자란다.\n\n아델리 펭귄(Adelie Penguin): 프랑스 탐험가인 뒤몽 뒤르빌(Dumont D’Urville) 부인의 이름을 따서 ’아델리’라 불리게 되었다. 각진 머리와 작은 부리 때문에 알아보기 쉽고, 다른 펭귄들과 마찬가지로 암수가 비슷하게 생겼지만 암컷이 조금 더 작다.\n\n턱끈 펭귄(Chinstrap Penguin): 언뜻 보면 아델리 펭귄과 매우 비슷하지만, 몸집이 조금 더 작고, 목에서 머리 쪽으로 이어지는 검은 털이 눈에 띈다. 어린 고삐 펭귄들은 회갈색 빛을 띄는 털을 가지고 있으며, 목 아래 부분은 더 하얗다. 무리를 지어 살아가며 일부일처제를 지키기 때문에 짝짓기 이후에도 부부로써 오랫동안 함께 살아간다.\n\n\n코드library(webshot2)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#meet-the-palmer-penguins &gt; p &gt; img\", \"images/penguin-species.png\")\n\n\n\n\n팔머 펭귄 3종 세트\n\n\n다음으로 iris 데이터와 마찬가지로 펭귄 3종을 구분하기 위한 변수로 조류의 부리에 있는 중앙 세로선의 융기를 지칭하는 능선(culmen) 길이(culmen length)와 깊이(culmen depth)를 이해하면 된다.\n\n코드library(webshot)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#what-are-culmen-length--depth &gt; p:nth-child(4) &gt; img\", \"fig/penguin-species-variable.png\")\n\n\n\n\n팔머 펭귄 능선 변수\n\n\n\nleaflet 팩키지로 펭귄 서식지를 남극에서 특정한다. geocoding을 해야 하는데 구글에서 위치 정보를 구글링하면 https://latitude.to/에서 직접 위경도를 반환하여 준다. 이 정보를 근거로 하여 펭귄 서식지를 시각화한다.\n\n\n\n\n파머 연구소와 펭귄 서식지\n\n\n\n\n펭귄 3종\n\n\n\n\n\n\n아델리, 젠투, 턱끈 펭귄이 함께한 사진\n\n\n\n\n토르거센 섬에서 새끼를 키우는 아델리 펭귄\n\n\n\n\n비스코 지점 젠투 펭귄 서식지\n\n\n\n\n펭귄과 함께 현장에서 일하는 크리스틴 고먼 박사\n\n\n\n\n\n파머 펭귄 데이터셋\n\n\n\n\n코드library(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n\n# A tibble: 3 × 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n코드island_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"명칭:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   ))) \n\n\n\n\n\n\nremotes 팩키지 install_github() 함수로 펭귄 데이터를 설치한다.\n\n코드# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\n\ntidyverse 팩키지 glimpse() 함수로 펭귄 데이터를 일별한다.\n\n코드library(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\n\nskimr 팩키지를 사용해서 penguins 데이터프레임 자료구조를 일별한다. 이를 통해서 344개 펭귄 관측값이 있으며, 7개 칼럼으로 구성된 것을 확인할 수 있다. 또한, 범주형 변수가 3개, 숫자형 변수가 4개로 구성되어 있다. 그외 더 자세한 사항은 범주형, 숫자형 변수에 대한 요약 통계량을 참조한다.\n\n코드skimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\n\n데이터가 크지 않아 DT 팩키지를 통해 데이터 전반적인 내용을 살펴볼 수 있다.\n\n코드penguins %&gt;% \n  reactable::reactable()\n\n\n\n\n\n\n\npalmerpenguins 데이터셋 소개에 포함되어 있는 미국 팔머 연구소 (palmer station) 펭귄 물갈퀴(flipper) 길이와 체질량(body mass) 산점도를 그려보자.\n\n코드library(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"펭귄 크기\",\n       subtitle = \"남극 펭귄 3종 물갈퀴 길이와 체질량 관계\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄 3종\",\n       shape = \"펭귄 3종\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper"
  },
  {
    "objectID": "palmer_penguins.html#펭귄-데이터-출현",
    "href": "palmer_penguins.html#펭귄-데이터-출현",
    "title": "chatGPT",
    "section": "",
    "text": "미국에서 “George Floyd”가 경찰에 의해 살해되면서 촉발된 “Black Lives Matter” 운동은 아프리카계 미국인을 향한 폭력과 제도적 인종주의에 반대하는 사회운동이다. 한국에서도 소수 정당인 정의당에서 여당 의원 176명 중 누가?…차별금지법 발의할 ’의인’을 구합니다로 기사로 낼 정도로 적극적으로 나서고 있다.\n데이터 과학에서 최근 R.A. Fisher의 과거 저술한 “The genetical theory of natural selection” (Fisher, 1958) 우생학(Eugenics) 대한 관점이 논란이 되면서 R 데이터 과학의 첫 데이터셋으로 붓꽃 iris 데이터를 다른 데이터, 즉 펭귄 데이터로 대체하는 움직임이 활발히 전개되고 있다. palmerpenguins (KB 기타, 2014) 데이터셋이 대안으로 많은 호응을 얻고 있다. Levy (2019)"
  },
  {
    "objectID": "palmer_penguins.html#penguins-study",
    "href": "palmer_penguins.html#penguins-study",
    "title": "chatGPT",
    "section": "",
    "text": "팔머(Palmer) 펭귄은 3종이 있으며 자세한 내용은 다음 나무위키를 참조한다. 1\n\n\n젠투 펭귄(Gentoo Penguin): 머리에 모자처럼 둘러져 있는 하얀 털 때문에 알아보기가 쉽다. 암컷이 회색이 뒤에, 흰색이 앞에 있다. 펭귄들 중에 가장 빠른 시속 36km의 수영 실력을 자랑하며, 짝짓기 할 준비가 된 펭귄은 75-90cm까지도 자란다.\n\n아델리 펭귄(Adelie Penguin): 프랑스 탐험가인 뒤몽 뒤르빌(Dumont D’Urville) 부인의 이름을 따서 ’아델리’라 불리게 되었다. 각진 머리와 작은 부리 때문에 알아보기 쉽고, 다른 펭귄들과 마찬가지로 암수가 비슷하게 생겼지만 암컷이 조금 더 작다.\n\n턱끈 펭귄(Chinstrap Penguin): 언뜻 보면 아델리 펭귄과 매우 비슷하지만, 몸집이 조금 더 작고, 목에서 머리 쪽으로 이어지는 검은 털이 눈에 띈다. 어린 고삐 펭귄들은 회갈색 빛을 띄는 털을 가지고 있으며, 목 아래 부분은 더 하얗다. 무리를 지어 살아가며 일부일처제를 지키기 때문에 짝짓기 이후에도 부부로써 오랫동안 함께 살아간다.\n\n\n코드library(webshot2)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#meet-the-palmer-penguins &gt; p &gt; img\", \"images/penguin-species.png\")\n\n\n\n\n팔머 펭귄 3종 세트\n\n\n다음으로 iris 데이터와 마찬가지로 펭귄 3종을 구분하기 위한 변수로 조류의 부리에 있는 중앙 세로선의 융기를 지칭하는 능선(culmen) 길이(culmen length)와 깊이(culmen depth)를 이해하면 된다.\n\n코드library(webshot)\n\nwebshot(url=\"https://allisonhorst.github.io/palmerpenguins/\", selector = \"#what-are-culmen-length--depth &gt; p:nth-child(4) &gt; img\", \"fig/penguin-species-variable.png\")\n\n\n\n\n팔머 펭귄 능선 변수"
  },
  {
    "objectID": "palmer_penguins.html#penguin-home",
    "href": "palmer_penguins.html#penguin-home",
    "title": "chatGPT",
    "section": "",
    "text": "leaflet 팩키지로 펭귄 서식지를 남극에서 특정한다. geocoding을 해야 하는데 구글에서 위치 정보를 구글링하면 https://latitude.to/에서 직접 위경도를 반환하여 준다. 이 정보를 근거로 하여 펭귄 서식지를 시각화한다.\n\n\n\n\n파머 연구소와 펭귄 서식지\n\n\n\n\n펭귄 3종\n\n\n\n\n\n\n아델리, 젠투, 턱끈 펭귄이 함께한 사진\n\n\n\n\n토르거센 섬에서 새끼를 키우는 아델리 펭귄\n\n\n\n\n비스코 지점 젠투 펭귄 서식지\n\n\n\n\n펭귄과 함께 현장에서 일하는 크리스틴 고먼 박사\n\n\n\n\n\n파머 펭귄 데이터셋\n\n\n\n\n코드library(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n\n# A tibble: 3 × 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n코드island_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"명칭:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   )))"
  },
  {
    "objectID": "palmer_penguins.html#데이터-설치",
    "href": "palmer_penguins.html#데이터-설치",
    "title": "chatGPT",
    "section": "",
    "text": "remotes 팩키지 install_github() 함수로 펭귄 데이터를 설치한다.\n\n코드# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\n\ntidyverse 팩키지 glimpse() 함수로 펭귄 데이터를 일별한다.\n\n코드library(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "palmer_penguins.html#penguin-EDA-skimr",
    "href": "palmer_penguins.html#penguin-EDA-skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr 팩키지를 사용해서 penguins 데이터프레임 자료구조를 일별한다. 이를 통해서 344개 펭귄 관측값이 있으며, 7개 칼럼으로 구성된 것을 확인할 수 있다. 또한, 범주형 변수가 3개, 숫자형 변수가 4개로 구성되어 있다. 그외 더 자세한 사항은 범주형, 숫자형 변수에 대한 요약 통계량을 참조한다.\n\n코드skimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\n\n데이터가 크지 않아 DT 팩키지를 통해 데이터 전반적인 내용을 살펴볼 수 있다.\n\n코드penguins %&gt;% \n  reactable::reactable()"
  },
  {
    "objectID": "palmer_penguins.html#penguin-EDA",
    "href": "palmer_penguins.html#penguin-EDA",
    "title": "chatGPT",
    "section": "",
    "text": "palmerpenguins 데이터셋 소개에 포함되어 있는 미국 팔머 연구소 (palmer station) 펭귄 물갈퀴(flipper) 길이와 체질량(body mass) 산점도를 그려보자.\n\n코드library(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"펭귄 크기\",\n       subtitle = \"남극 펭귄 3종 물갈퀴 길이와 체질량 관계\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄 3종\",\n       shape = \"펭귄 3종\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper"
  },
  {
    "objectID": "palmer_penguins.html#footnotes",
    "href": "palmer_penguins.html#footnotes",
    "title": "chatGPT",
    "section": "각주",
    "text": "각주\n\n신발끈 여행사, 관광안내자료↩︎"
  },
  {
    "objectID": "autoGPT_ds.html#skimr",
    "href": "autoGPT_ds.html#skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr 패키지를 사용하여 분석할 데이터와 친숙해진다.\n\n코드penguins %&gt;% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n종명칭\n0\n1.00\nFALSE\n3\n아델리: 152, 젠투: 124, 턱끈: 68\n\n\n섬이름\n0\n1.00\nFALSE\n3\n비스코: 168, 드림: 124, 토르거: 52\n\n\n성별\n11\n0.97\nFALSE\n2\n수컷: 168, 암컷: 165\n\n\n연도\n0\n1.00\nTRUE\n3\n200: 120, 200: 114, 200: 110\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n부리_길이\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\n부리_깊이\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\n물갈퀴_길이\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\n체중\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂"
  },
  {
    "objectID": "autoGPT_ds.html#dataxray",
    "href": "autoGPT_ds.html#dataxray",
    "title": "chatGPT",
    "section": "",
    "text": "dataxray 패키지를 사용해서 데이터에 대한 이해를 더욱 높일 수 있다.\n\n\n코드library(dataxray)\n\npenguins %&gt;% \n   make_xray() %&gt;% \n   view_xray()\n\n\n\n\nExpand/collapse all"
  },
  {
    "objectID": "autoGPT_ds.html#dlookr",
    "href": "autoGPT_ds.html#dlookr",
    "title": "chatGPT",
    "section": "",
    "text": "dlookr 패키지를 사용하여 분석할 데이터와 친숙해진다.\n\n코드library(kableExtra)\npenguins %&gt;% \n  dlookr::describe() %&gt;% \n  kable(caption = \"요약통계량\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)  \n\n\n\n요약통계량\n\ndescribed_variables\nn\nna\nmean\nsd\nse_mean\nIQR\nskewness\nkurtosis\np00\np01\np05\np10\np20\np25\np30\np40\np50\np60\np70\np75\np80\np90\np95\np99\np100\n\n\n\n부리_길이\n342\n2\n43.92193\n5.459584\n0.2952205\n9.275\n0.0531181\n-0.8760270\n32.1\n34.041\n35.7\n36.6\n38.34\n39.225\n40.20\n42.0\n44.45\n46.0\n47.37\n48.5\n49.38\n50.8\n51.995\n55.513\n59.6\n\n\n부리_깊이\n342\n2\n17.15117\n1.974793\n0.1067846\n3.100\n-0.1434646\n-0.9068661\n13.1\n13.441\n13.9\n14.3\n15.00\n15.600\n15.93\n16.8\n17.30\n17.9\n18.50\n18.7\n18.90\n19.5\n20.000\n21.100\n21.5\n\n\n물갈퀴_길이\n342\n2\n200.91520\n14.061714\n0.7603704\n23.000\n0.3456818\n-0.9842729\n172.0\n178.000\n181.0\n185.0\n188.00\n190.000\n191.00\n194.0\n197.00\n203.0\n210.00\n213.0\n215.00\n220.9\n225.000\n230.000\n231.0\n\n\n체중\n342\n2\n4201.75439\n801.954536\n43.3647348\n1200.000\n0.4703293\n-0.7192219\n2700.0\n2900.000\n3150.0\n3300.0\n3475.00\n3550.000\n3650.00\n3800.0\n4050.00\n4300.0\n4650.00\n4750.0\n4950.00\n5400.0\n5650.000\n5979.500\n6300.0"
  },
  {
    "objectID": "autoGPT_ds.html#dataexplorer",
    "href": "autoGPT_ds.html#dataexplorer",
    "title": "chatGPT",
    "section": "",
    "text": "DataExplorer 패키지를 사용하여 분석할 데이터와 친숙해진다.\nDataExplorer::create_report(penguins)\n\n\n구조\nDF 요약\nDF 요약 시각화\n결측값\n분포(범주형)\n분포(연속형)\n상관관계\nPCA\n\n\n\n\n코드DataExplorer::plot_str(penguins)\n\n\n\n\n\n코드DataExplorer::introduce(penguins)\n\n# A tibble: 1 × 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1   344       8                4                  4                   0\n# ℹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;\n\n\n\n\n\n코드DataExplorer::plot_intro(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_missing(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_bar(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_histogram(penguins)\n\n\n\n\n\n\n\n\n\n\n코드penguins %&gt;% select_if(is.numeric) %&gt;% \n  # drop_na() %&gt;% \n  DataExplorer::plot_correlation(cor_args = list(\"use\" = \"pairwise.complete.obs\"))\n\n\n\n\n\n\n\n\n\n\n코드penguins_pca &lt;- penguins %&gt;% select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% prcomp(scale = TRUE)\n\nsummary(penguins_pca)$importance %&gt;% as.data.frame() %&gt;% \n  kable(caption = \"PCA 요약\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\nPCA 요약\n\n\nPC1\nPC2\nPC3\nPC4\n\n\n\nStandard deviation\n1.659444\n0.8789293\n0.6043475\n0.3293816\n\n\nProportion of Variance\n0.688440\n0.1931300\n0.0913100\n0.0271200\n\n\nCumulative Proportion\n0.688440\n0.8815700\n0.9728800\n1.0000000"
  },
  {
    "objectID": "autoGPT_ds.html#hmiscdescribe",
    "href": "autoGPT_ds.html#hmiscdescribe",
    "title": "chatGPT",
    "section": "",
    "text": "Hmisc 패키지를 통해 과거 20년전 데이터 분석방법을 음미합니다.\n\n코드library(tidyverse)\n\npenguins &lt;- palmerpenguins::penguins %&gt;%\n  # 영어 변수명 한글 변환\n  set_names(c(\"종명칭\", \"섬이름\", \"부리_길이\", \"부리_깊이\", \"물갈퀴_길이\",\n              \"체중\", \"성별\", \"연도\")) %&gt;%\n  # 결측값 제거\n  # drop_na() %&gt;%\n  # 영어 값 한글 값으로 변환\n  mutate(성별 = ifelse(성별 == \"male\", \"수컷\", \"암컷\"),\n         섬이름 = case_when( str_detect(섬이름, \"Biscoe\") ~ \"비스코\",\n                          str_detect(섬이름, \"Dream\") ~ \"드림\",\n                          str_detect(섬이름, \"Torgersen\") ~ \"토르거센\"),\n         종명칭 = case_when( str_detect(종명칭, \"Adelie\") ~ \"아델리\",\n                          str_detect(종명칭, \"Chinstrap\") ~ \"턱끈\",\n                          str_detect(종명칭, \"Gentoo\") ~ \"젠투\")\n  ) %&gt;%\n  # 자료형 변환\n  mutate(성별   = factor(성별, levels = c(\"수컷\", \"암컷\")),\n         섬이름 = factor(섬이름, levels = c(\"비스코\", \"드림\", \"토르거센\")),\n         종명칭 = factor(종명칭, levels = c(\"아델리\", \"턱끈\", \"젠투\")),\n         연도   = ordered(연도, levels = c(2007, 2008, 2009)))\n\n\n\nHmisc::describe(penguins)\n\npenguins \n\n 8  Variables      344  Observations\n--------------------------------------------------------------------------------\n종명칭 \n       n  missing distinct \n     344        0        3 \n                                     \nValue        아델리     턱끈     젠투\nFrequency    152       68      124   \nProportion 0.442    0.198    0.360   \n--------------------------------------------------------------------------------\n섬이름 \n       n  missing distinct \n     344        0        3 \n                                     \nValue        비스코     드림 토르거센\nFrequency    168      124       52   \nProportion 0.488    0.360    0.151   \n--------------------------------------------------------------------------------\n부리_길이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2      164        1    43.92    6.274    35.70    36.60 \n     .25      .50      .75      .90      .95 \n   39.23    44.45    48.50    50.80    51.99 \n\nlowest : 32.1 33.1 33.5 34.0 34.1, highest: 55.1 55.8 55.9 58.0 59.6\n--------------------------------------------------------------------------------\n부리_깊이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       80        1    17.15    2.267     13.9     14.3 \n     .25      .50      .75      .90      .95 \n    15.6     17.3     18.7     19.5     20.0 \n\nlowest : 13.1 13.2 13.3 13.4 13.5, highest: 20.7 20.8 21.1 21.2 21.5\n--------------------------------------------------------------------------------\n물갈퀴_길이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       55    0.999    200.9    16.03    181.0    185.0 \n     .25      .50      .75      .90      .95 \n   190.0    197.0    213.0    220.9    225.0 \n\nlowest : 172 174 176 178 179, highest: 226 228 229 230 231\n--------------------------------------------------------------------------------\n체중 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       94        1     4202    911.8     3150     3300 \n     .25      .50      .75      .90      .95 \n    3550     4050     4750     5400     5650 \n\nlowest : 2700 2850 2900 2925 2975, highest: 5850 5950 6000 6050 6300\n--------------------------------------------------------------------------------\n성별 \n       n  missing distinct \n     333       11        2 \n                          \nValue         수컷    암컷\nFrequency    168     165  \nProportion 0.505   0.495  \n--------------------------------------------------------------------------------\n연도 \n       n  missing distinct \n     344        0        3 \n                            \nValue       2007  2008  2009\nFrequency    110   114   120\nProportion 0.320 0.331 0.349\n--------------------------------------------------------------------------------"
  },
  {
    "objectID": "gg_grouping.html",
    "href": "gg_grouping.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 데이터셋\n챗GPT 교육에 참여한 설문조사 데이터를 정리한다.\n\n코드library(tidyverse)\nlibrary(readxl)\n\nsurvey_26 &lt;- read_excel(\"data/(붙임) 경기도청 챗GPT 직원직무 교육신청 명단(취합).xlsx\", sheet = '4.26.(수)', skip =2) %&gt;% \n  mutate(날짜 = \"2023-04-26\")\nsurvey_27 &lt;- read_excel(\"data/(붙임) 경기도청 챗GPT 직원직무 교육신청 명단(취합).xlsx\", sheet = '4.27.(목)', skip =2) %&gt;% \n  mutate(날짜 = \"2023-04-27\")\nsurvey_28 &lt;- read_excel(\"data/(붙임) 경기도청 챗GPT 직원직무 교육신청 명단(취합).xlsx\", sheet = '4.28.(금)', skip =2) %&gt;% \n  mutate(날짜 = \"2023-04-28\")\n\nsurvey &lt;- bind_rows(survey_26, survey_27) %&gt;% \n  bind_rows(survey_28) %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  set_names(c(\"연번\", \"실국\", \"소속\", \"직위\", \"성명\", \"프롬프트\", \"API\", \"성취목표\", \"날짜\")) %&gt;% \n  mutate(실국 = ifelse(is.na(실국), \"직속\", 실국)) \n\n\n\n2 데이터 가명처리\n실국, 소속과 직위, 성명이 포함되어 있어 변수 중 성명을 가명처리한다. 이를 위해서 파이썬 Faker 패키지를 사용하여 가명으로 처리한다.\n\n코드from faker import Faker\nimport pandas as pd\nimport numpy as np\nimport random\nfrom datetime import datetime\n\nfake = Faker('ko_KR')\n\ndef create_rows_faker(num=1):\n    output = [{\"name\"       : fake.name()} for x in range(num)]\n    return output\n\ndf_faker = pd.DataFrame(create_rows_faker(72))\n\n\n가명처리 데이터를 정리한다.\n\n코드library(reticulate)\n\nsurvey_tbl &lt;- survey %&gt;% \n  bind_cols(py$df_faker) %&gt;% \n  select(-성명) %&gt;% \n  rename(성명 = name) %&gt;% \n  select(날짜, 실국, 성명, 직위, 프롬프트, API) \n\n\n\n3 챗GPT\n챗GPT GPT-4를 사용해서 챗GPT 실무교육을 통해 얻으려는 것을 요약하도록 프롬프트를 작성한다.\n\n\n\n\n\n\n프롬프트: 챗GPT 교육참여 텍스트를 5개 목표로 군집화시켜 정리하시요\n\n\n\n\n챗GPT 응답:  1. 업무 효율성과 생산성 향상:  - 보고서 작성 및 엑셀 스킬 향상  - 행정 업무의 간소화  - 특정 직무 역할에서 ChatGPT를 적용하는 다양한 방법 탐구  1. 변화하는 기술 추세에 적응하고 새로운 기술 습득:  - AI와 ChatGPT의 최신 동향 이해  - ChatGPT 사용에 뒤처지지 않기 위한 지식 획득  - 변화하는 기술 풍경에 적응하기 위한 기본 지식 습득  1. 문제 해결 및 의사 결정 능력 향상:  - 기획 및 이벤트 프로모션을 위한 데이터 시각화 활용  - 사례 연구 및 문제 해결을 위해 ChatGPT 사용  - 지역 발전 및 IT 동향에 대한 ChatGPT의 영향 분석 및 이해  1. ChatGPT 응용 범위 확장:  - 일상 생활 및 다양한 산업 분야(예: 농업 홍보, 콘텐츠 산업)에 ChatGPT 적용  - 다양한 비즈니스 프로젝트에서 ChatGPT 통합의 잠재력 조사  1. 의사소통 및 질문 기술 향상:  - 효과적인 프롬프트 질문 방법 학습  - ChatGPT와 더 나은 상호 작용을 위한 기술 개발  - 원하는 결과를 얻기 위해 올바른 질문을 하는 것의 중요성 이해 \n\n\n\n\n4 통계 분석\n설문조사에 나타난 자기평가 프롬프트 API 활용역량을 표로 요약한다.\n\n코드library(gt)\nlibrary(gtExtras)\n\nsurvey_gt &lt;- survey %&gt;% \n  count(프롬프트, API) %&gt;% \n  pivot_wider(names_from = API, values_from = n, values_fill = 0) %&gt;% \n  mutate(라 = 0) %&gt;% \n  gt::gt() %&gt;% \n    tab_spanner(\n    label = \"API 활용능력\",\n    columns = c(\n      가,나,다,라\n    )\n  ) %&gt;% \n  gt_theme_nytimes() %&gt;% \n  tab_header(title = \"자기평가 프롬프트, API 활용역량\") %&gt;% \n  cols_align(\n  align = \"center\",\n  columns = everything()\n)\n\nsurvey_gt %&gt;% \n  gtsave_extra(filename=\"images/gg_survey_gt.png\")\n\n\n\n\n\n\n요일별 초,중,고급 참여자 역량을 다음과 같이 요약한다.\n\n코드survey_gt_date &lt;- survey %&gt;% \n  mutate(수준 = case_when(프롬프트 %in% c(\"가\", \"나\") & API %in% c(\"가\", \"나\") ~ \"초급\",\n                          프롬프트 == \"라\" ~ \"고급\",\n                          TRUE ~ \"중급\")) %&gt;% \n  count(날짜, 수준) %&gt;% \n  pivot_wider(names_from = 수준, values_from = n, values_fill  = 0) %&gt;% \n  gt::gt() %&gt;% \n    tab_spanner(\n    label = \"자가평가 역량 종합\",\n    columns = c(\n      초급, 중급, 고급\n    )\n  ) %&gt;% \n  gt_theme_nytimes() %&gt;% \n  tab_header(title = \"챗GPT 요일별 참여자 역량\") %&gt;% \n  cols_align(\n  align = \"center\",\n  columns = everything()\n)  \n\nsurvey_gt_date %&gt;% \n  gtsave_extra(filename=\"images/survey_gt_date.png\")"
  },
  {
    "objectID": "gg_grouping.html#hmiscdescribe",
    "href": "gg_grouping.html#hmiscdescribe",
    "title": "chatGPT",
    "section": "",
    "text": "Hmisc 패키지를 통해 과거 20년전 데이터 분석방법을 음미합니다.\n\n코드library(tidyverse)\n\npenguins &lt;- palmerpenguins::penguins %&gt;%\n  # 영어 변수명 한글 변환\n  set_names(c(\"종명칭\", \"섬이름\", \"부리_길이\", \"부리_깊이\", \"물갈퀴_길이\",\n              \"체중\", \"성별\", \"연도\")) %&gt;%\n  # 결측값 제거\n  # drop_na() %&gt;%\n  # 영어 값 한글 값으로 변환\n  mutate(성별 = ifelse(성별 == \"male\", \"수컷\", \"암컷\"),\n         섬이름 = case_when( str_detect(섬이름, \"Biscoe\") ~ \"비스코\",\n                          str_detect(섬이름, \"Dream\") ~ \"드림\",\n                          str_detect(섬이름, \"Torgersen\") ~ \"토르거센\"),\n         종명칭 = case_when( str_detect(종명칭, \"Adelie\") ~ \"아델리\",\n                          str_detect(종명칭, \"Chinstrap\") ~ \"턱끈\",\n                          str_detect(종명칭, \"Gentoo\") ~ \"젠투\")\n  ) %&gt;%\n  # 자료형 변환\n  mutate(성별   = factor(성별, levels = c(\"수컷\", \"암컷\")),\n         섬이름 = factor(섬이름, levels = c(\"비스코\", \"드림\", \"토르거센\")),\n         종명칭 = factor(종명칭, levels = c(\"아델리\", \"턱끈\", \"젠투\")),\n         연도   = ordered(연도, levels = c(2007, 2008, 2009)))\n\n\n\nHmisc::describe(penguins)\n\npenguins \n\n 8  Variables      344  Observations\n--------------------------------------------------------------------------------\n종명칭 \n       n  missing distinct \n     344        0        3 \n                                     \nValue        아델리     턱끈     젠투\nFrequency    152       68      124   \nProportion 0.442    0.198    0.360   \n--------------------------------------------------------------------------------\n섬이름 \n       n  missing distinct \n     344        0        3 \n                                     \nValue        비스코     드림 토르거센\nFrequency    168      124       52   \nProportion 0.488    0.360    0.151   \n--------------------------------------------------------------------------------\n부리_길이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2      164        1    43.92    6.274    35.70    36.60 \n     .25      .50      .75      .90      .95 \n   39.23    44.45    48.50    50.80    51.99 \n\nlowest : 32.1 33.1 33.5 34.0 34.1, highest: 55.1 55.8 55.9 58.0 59.6\n--------------------------------------------------------------------------------\n부리_깊이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       80        1    17.15    2.267     13.9     14.3 \n     .25      .50      .75      .90      .95 \n    15.6     17.3     18.7     19.5     20.0 \n\nlowest : 13.1 13.2 13.3 13.4 13.5, highest: 20.7 20.8 21.1 21.2 21.5\n--------------------------------------------------------------------------------\n물갈퀴_길이 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       55    0.999    200.9    16.03    181.0    185.0 \n     .25      .50      .75      .90      .95 \n   190.0    197.0    213.0    220.9    225.0 \n\nlowest : 172 174 176 178 179, highest: 226 228 229 230 231\n--------------------------------------------------------------------------------\n체중 \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     342        2       94        1     4202    911.8     3150     3300 \n     .25      .50      .75      .90      .95 \n    3550     4050     4750     5400     5650 \n\nlowest : 2700 2850 2900 2925 2975, highest: 5850 5950 6000 6050 6300\n--------------------------------------------------------------------------------\n성별 \n       n  missing distinct \n     333       11        2 \n                          \nValue         수컷    암컷\nFrequency    168     165  \nProportion 0.505   0.495  \n--------------------------------------------------------------------------------\n연도 \n       n  missing distinct \n     344        0        3 \n                            \nValue       2007  2008  2009\nFrequency    110   114   120\nProportion 0.320 0.331 0.349\n--------------------------------------------------------------------------------"
  },
  {
    "objectID": "gg_grouping.html#skimr",
    "href": "gg_grouping.html#skimr",
    "title": "chatGPT",
    "section": "",
    "text": "skimr 패키지를 사용하여 분석할 데이터와 친숙해진다.\n\n코드penguins %&gt;% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n종명칭\n0\n1.00\nFALSE\n3\n아델리: 152, 젠투: 124, 턱끈: 68\n\n\n섬이름\n0\n1.00\nFALSE\n3\n비스코: 168, 드림: 124, 토르거: 52\n\n\n성별\n11\n0.97\nFALSE\n2\n수컷: 168, 암컷: 165\n\n\n연도\n0\n1.00\nTRUE\n3\n200: 120, 200: 114, 200: 110\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n부리_길이\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\n부리_깊이\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\n물갈퀴_길이\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\n체중\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂"
  },
  {
    "objectID": "gg_grouping.html#dataxray",
    "href": "gg_grouping.html#dataxray",
    "title": "chatGPT",
    "section": "",
    "text": "dataxray 패키지를 사용해서 데이터에 대한 이해를 더욱 높일 수 있다.\n\n\n코드library(dataxray)\n\npenguins %&gt;% \n   make_xray() %&gt;% \n   view_xray()\n\n\n\n\nExpand/collapse all"
  },
  {
    "objectID": "gg_grouping.html#dlookr",
    "href": "gg_grouping.html#dlookr",
    "title": "chatGPT",
    "section": "",
    "text": "dlookr 패키지를 사용하여 분석할 데이터와 친숙해진다.\n\n코드library(kableExtra)\npenguins %&gt;% \n  dlookr::describe() %&gt;% \n  kable(caption = \"요약통계량\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)  \n\n\n\n요약통계량\n\ndescribed_variables\nn\nna\nmean\nsd\nse_mean\nIQR\nskewness\nkurtosis\np00\np01\np05\np10\np20\np25\np30\np40\np50\np60\np70\np75\np80\np90\np95\np99\np100\n\n\n\n부리_길이\n342\n2\n43.92193\n5.459584\n0.2952205\n9.275\n0.0531181\n-0.8760270\n32.1\n34.041\n35.7\n36.6\n38.34\n39.225\n40.20\n42.0\n44.45\n46.0\n47.37\n48.5\n49.38\n50.8\n51.995\n55.513\n59.6\n\n\n부리_깊이\n342\n2\n17.15117\n1.974793\n0.1067846\n3.100\n-0.1434646\n-0.9068661\n13.1\n13.441\n13.9\n14.3\n15.00\n15.600\n15.93\n16.8\n17.30\n17.9\n18.50\n18.7\n18.90\n19.5\n20.000\n21.100\n21.5\n\n\n물갈퀴_길이\n342\n2\n200.91520\n14.061714\n0.7603704\n23.000\n0.3456818\n-0.9842729\n172.0\n178.000\n181.0\n185.0\n188.00\n190.000\n191.00\n194.0\n197.00\n203.0\n210.00\n213.0\n215.00\n220.9\n225.000\n230.000\n231.0\n\n\n체중\n342\n2\n4201.75439\n801.954536\n43.3647348\n1200.000\n0.4703293\n-0.7192219\n2700.0\n2900.000\n3150.0\n3300.0\n3475.00\n3550.000\n3650.00\n3800.0\n4050.00\n4300.0\n4650.00\n4750.0\n4950.00\n5400.0\n5650.000\n5979.500\n6300.0"
  },
  {
    "objectID": "gg_grouping.html#dataexplorer",
    "href": "gg_grouping.html#dataexplorer",
    "title": "chatGPT",
    "section": "",
    "text": "DataExplorer 패키지를 사용하여 분석할 데이터와 친숙해진다.\nDataExplorer::create_report(penguins)\n\n\n구조\nDF 요약\nDF 요약 시각화\n결측값\n분포(범주형)\n분포(연속형)\n상관관계\nPCA\n\n\n\n\n코드DataExplorer::plot_str(penguins)\n\n\n\n\n\n코드DataExplorer::introduce(penguins)\n\n# A tibble: 1 × 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1   344       8                4                  4                   0\n# ℹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;\n\n\n\n\n\n코드DataExplorer::plot_intro(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_missing(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_bar(penguins)\n\n\n\n\n\n\n\n\n\n\n코드DataExplorer::plot_histogram(penguins)\n\n\n\n\n\n\n\n\n\n\n코드penguins %&gt;% select_if(is.numeric) %&gt;% \n  # drop_na() %&gt;% \n  DataExplorer::plot_correlation(cor_args = list(\"use\" = \"pairwise.complete.obs\"))\n\n\n\n\n\n\n\n\n\n\n코드penguins_pca &lt;- penguins %&gt;% select_if(is.numeric) %&gt;% \n  drop_na() %&gt;% prcomp(scale = TRUE)\n\nsummary(penguins_pca)$importance %&gt;% as.data.frame() %&gt;% \n  kable(caption = \"PCA 요약\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\n\nPCA 요약\n\n\nPC1\nPC2\nPC3\nPC4\n\n\n\nStandard deviation\n1.659444\n0.8789293\n0.6043475\n0.3293816\n\n\nProportion of Variance\n0.688440\n0.1931300\n0.0913100\n0.0271200\n\n\nCumulative Proportion\n0.688440\n0.8815700\n0.9728800\n1.0000000"
  },
  {
    "objectID": "architecture.html#jpeg-압축",
    "href": "architecture.html#jpeg-압축",
    "title": "chatGPT",
    "section": "",
    "text": "ChatGPT는 인터넷에서 방대한 양의 데이터를 학습하여 이를 정말 잘 압축한 하나의 저장소로 이해할 수 있다. 따라서, 압축을 풀게 되면 정확히 원본을 복원할 수 있는 부분도 있지만, 그렇지 못한 부분도 당영히 있게 된다.\nTed Chiang (February 9, 2023), “ChatGPT Is a Blurry JPEG of the Web - OpenAI’s chatbot offers paraphrases, whereas Google offers quotes. Which do we prefer?”, The New Yorker\nChatGPT를 “웹의 흐릿한 JPEG”으로 비유하고 있다. JPEC 기술 자체는 손실 압축기술로 무손실 압축기술로 대표적인 PNG와 대비된다. 흐릿한 이미지가 선명하지 않거나 정확하지 않은 것처럼 ChatGPT도 항상 완벽한 답변을 제공하거나 모든 질문을 제대로 이해하는 것도 아니다. 하지만 사용자와의 대화를 기반으로 끊임없이 학습하고 개선하고 있다. 더 많은 사람들이 ChatGPT를 사용할수록 사람의 언어를 더 잘 이해하고 반응할 수 있게 개발된 기술이다.\nChatGPT와 유사한 인공지능 프로그램이 너무 강력해지거나 인간을 대체할 수 있다고 우려하는 사람들도 있지만, ChatGPT는 단순히 작업을 더 쉽고 효율적으로 만드는 데 사용할 수 있는 강력한 도구일 뿐이므로 사람을 능가하거나 지배할 가능성은 거의 없다. 인공지능(ChatGPT)을 책임감 있고 윤리적으로 사용되도록 하는 것은 결국 사용자 귀책이다.\nChatGPT가 간단한 숫자계산에 문제가 있는 것은 웹상에 산재된 숫자 계산 데이터를 바탕으로 계산을 흉내낼 수는 있으나 이와 같은 방식으로 ChatGPT가 학습한 것은 명백히 잘못된 것이다. 사칙연산에 대한 일반적인 원리를 이해하게 되면 웹상에 나온 사칙연산 문제를 정확히 해결할 뿐만 아니라 웹상에 나와있지 않는 계산문제도 풀 수 있으나 현재는 그렇지 못하다.\n\n\nPNG 파일\n(비)손실 압축\n파일크기\nBMP 파일\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n자료출처: WHAT’S THE DIFFERENCE BETWEEN JPEG AND PNG: BEGINNER GUIDE"
  },
  {
    "objectID": "architecture.html#제록스-복사기",
    "href": "architecture.html#제록스-복사기",
    "title": "chatGPT",
    "section": "",
    "text": "독일 과학자(David Kriesel)가 제록스 복사기에서 문서에 있는 숫자를 변경하는 결함을 발견했다. 제록스 프린터가 방의 면적을 14.13m²에서 17.42m²로 넓혔고, 다른 프린터는 21.11m²에서 14.13m²로 줄였다. 숫자 문자열 중간에 특정 숫자(예: “6” 또는 “8”)가 나타나면 복사기가 해당 숫자를 다른 숫자로 바꾸는 경우가 많았다. 예를 들어, ’682’가 ’882’가 될 수 있습니다.\n처음에 건물 설계도를 스캔하고 분석하려고 할 때 이 문제를 발견했다. 원본에는 이러한 오류가 없었지만 스캔한 사본에서 특정 숫자가 변경된 것을 발견했다. 결국 그들은 사본을 만드는 과정에서 숫자가 변경된, 사용 중인 Xerox 복사기에 문제가 있다는 사실을 깨달았다.\n이 결함은 제록스 복사기에 사용되는 압축 알고리즘과 관련된 것으로 특정 숫자가 서로 가까이 있으면 알고리즘이 이를 다른 숫자로 착각하고 그에 따라 숫자를 바꾼 것이다. 이 문제가 일부 고급 모델을 포함한 다양한 제록스 복사기에 존재한다는 사실도 발견했다.\nD. KRIESEL, “Xerox scanners/photocopiers randomly alter numbers in scanned documents”\n\n\n설계도 문서\n스캔 결과\n원가표 스캔\n스캔 오류\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n모델: WorkCentre 7535"
  },
  {
    "objectID": "architecture.html#기계학습",
    "href": "architecture.html#기계학습",
    "title": "chatGPT",
    "section": "\n2.1 기계학습",
    "text": "2.1 기계학습\n머신러닝은 혼자서 할 수 있는 일이 아닙니다! ML 솔루션을 구축할 때는 고객부터 고객까지 엔드투엔드로 생각하는 것이 중요합니다. 이는 설계, 계획 및 실행에 도움이 됩니다. 계획의 일환으로 누가 언제 참여해야 하는지 이해하는 것이 중요합니다. 일반적인 프로젝트를 살펴보겠습니다.\n\n\n작업흐름\n전체 개요도\n데이터 → 하드웨어\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n인공지능(AI) 시스템 구축을 위한 새로운 패러다임이 탄생했다. 기초모형(Foundation Model)은 광범위한 데이터에 대해 학습된 모델로, 광범위한 실무하위 작업에 활용할 수 있다. 현재 BERT, GPT-3, CLIP [Radford 외. 2021] 등을 예로 들 수 있다. (Bommasani 기타, 2021)\n\n\n\n\n\n\nFeature Engineering\nArchitecture Engineering\nObjective Engineering\nPrompt Engineering\n\n\n\n\n\n패러다임: (비신경망)지도학습 (Fully Supervised Learning)\n\n전성기: 2015년까지 최고 전성기 구가\n\n특징\n\n주로 비신경망 기계학습이 사용\n수작업으로 Feature를 추출\n\n\n\n대표작\n\n수작업 Feature 추출 후 SVM(support vector machine) 기계학습 모형\n수작업 Feature 추출 후 CRF(conditional random fields)\n\n\n\n\n\n\n\n패러다임: 신경망 지도학습(Fully Supervised Learning)\n\n전성기: 대략 2013~2018\n\n특징\n\n신경망(Neural Network) 의존\n수작업으로 Feature를 손볼 필요는 없으나 신경망 네트워크는 수정해야 함(LSTM vs CNN)\n종종 사전학습된 언어모형을 사용하나 임베딩(embedding) 같은 얕은(shallow) Feature를 적용\n\n\n\n대표작\n\n텍스트 분류작업에 CNN 사용\n\n\n\n\n\n\n\n패러다임: 사전학습(pre-training), 미세조정(fine-tuning)\n\n전성기: 2017~현재\n\n특징\n\n사전학습된 언어모형을 전체 모형의 초기값으로 사용\n아키텍쳐 디자인에 작업이 덜 필요하지만 목적함수(Objective function) 엔지니어링은 필요\n\n\n\n대표작\n\nBERT → Fine Tuning\n\n\n\n\n\n\n\n패러다임: 사전학습(pre-training), 프롬프트(Prompt), 예측(Predict)\n\n전성기: 2019~현재\n\n특징\n\nNLP 작업이 언어모형(Language Model)에 전적으로 의존\n얕던 깊던 Feature 추출, 예측 등 작업이 전적으로 언어모형에 의존\n프롬프트 공학이 필요\n\n\n\n대표작\n\nGPT3"
  },
  {
    "objectID": "open_source.html#메타-라마",
    "href": "open_source.html#메타-라마",
    "title": "chatGPT",
    "section": "",
    "text": "페이스북으로 잘 알려진 메타(Meta)는 연구 목적(비상업적 사용)으로 라마(LLaMA) 거대언어모형을 오픈소스 소프트웨어로 2023년 2월 24일 공개했다. LLaMA는 라틴어와 키릴 문자를 사용하는 20개 언어의 텍스트를 학습하여 다양한 크기(7B, 13B, 33B, 65B 매개변수) 언어모형 형태로 공개되어 거대언어모형을 대중화하고 연구자들이 새로운 접근 방식과 사용 사례를 테스트할 수 있는 취지로 공개되었지만, 여전히 편향성, 독성, 잘못된 정보 등 추가적인 보완이 필요하다.\nMetaAI (February 24, 2023), “Introducing LLaMA: A foundational, 65-billion-parameter large language model”, MetaAI Blog"
  },
  {
    "objectID": "interface.html#스카이프skeype",
    "href": "interface.html#스카이프skeype",
    "title": "chatGPT",
    "section": "\n4.4 스카이프(Skeype)",
    "text": "4.4 스카이프(Skeype)\n2023년 2월 22일 마이크로소프트는 AI 챗봇을 탑재한 빙과 엣지브라우저의 모바일 앱을 공개했다. 이에 따라 스카이프에서도 빙의 챗봇 기능을 이용할 수 있게 됐다.\n\n\nskype 다운로드\nBing “새 채팅” 추가\n챗GPT 실행"
  },
  {
    "objectID": "chatGPT_overview.html",
    "href": "chatGPT_overview.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 챗GPT 인터페이스\n사용자가 질문이나 지시사항을 프롬프트로 챗팅창에 전달하면 GPT-3/3.5/4 LLM 모형이 프롬프트를 이해하고 질문과 지시사항에 맞는 응답을 텍스트/코드/이미지/오디오 형태로 변환하여 사용자에게 응답한다. 이 과정이 검색과 달리 한번에 그치는 것이 아니라 원하는 결과를 얻을 때까지 맥락(context)을 유지한 상태로 반복된다.\n\n\n\n\n\n2 챗GPT 사용 이유\n챗GPT는 많은 작업을 더 효율적으로 수행할 수 있기 때문에 사용한다. 예산 대비 최종 프로젝트 비용(Cost), 적시 프로젝트 제공(Time), 구축된 프로젝트 결과물의 품질(Quality)에 따라 가치(Value)가 좌우된다. 챗GPT를 통해 비용을 줄이고, 시간을 단축하고 품질을 높일 수 있기 때문에 결국 챗GPT를 사용하는 이유가 된다.(Hardie & Saha, 2012)\n\n\n\n\n\n3 챗GPT 한계\n\n2021년 9월까지 데이터를 학습한 거대언어모형(LLM)이라 최신 정보는 가지고 있지 않다.\n\n챗GPT 플러그인 기능을 사용하여 구글/빙 등 검색 기능으로 보완\n\n\n챗GPT는 학습데이터에 내포된 편향성(Bias)\n\n???\n\n\n채팅에 질문에 일관성과 다른 주제를 중구난방으로 뒤섞어 채팅을 진행할 경우 부정확성이 커진다.\n\n맥락(Context) 일관성을 유지하고 주제가 바뀌는 경우 New Chat으로 주제를 분리하여 작업한다.\n\n\n틀린 사실을 마치 정답인 것처럼 착각해서 답변을 주는 헐루시네이션(hallucination).\n\nGPT-4와 같은 진화된 LLM, temperature 매개변수 지정, 정교한 프롬프트 작성을 통해 이런 문제를 완화시킬 수 있다.\n\n\n법적 윤리적 문제: 빈센트 반 고흐(혹은 생존화가) 화풍으로 AI가 생성한 그림, 특정 문체를 흉내 내거나 AI가 저작한 노래 등 지적 창작물의 소유권과 프라이버시 문제\n\n명예, 문화, 사업 등 이해관계가 걸린 경우 저작권 전문가와 법률가의 조언을 받아 추진한다.\n\n\n\n4 챗GPT 시대 업무흐름\n챗GPT 시대 기존 사람이 중심이 되고 기계의 자동화 기능을 적극 활용하여 생산성을 높이던 방식에서 기계가 중심적으로 일을 수행하고 사람은 의사결정과 기계가 작업한 결과를 검토하고 확인하는 방식으로 변경이 불가피하게 보인다. 특히 기존 사무노동의 생산성의 핵심이 되는 오피스 제품(엑셀, 워드프로세서, 파워포인트)에 증거기반 행정과 데이터 사이언스의 급격한 도입으로 R/파이썬/SQL 언어를 결합시키는 RPA가 대세가 되었으나 이러한 작업방식은 사무노동자의 업무능력(문서 요약, 콘텐츠 생산 등)을 보조하는 기능에 머무르고 있다. 이와 반대로 챗GPT가 문서요약, 콘텐츠 생산 등 시간을 줄이고 품질을 높일 수 있는데 매우 저렴한 비용(월 20 달러)으로 쉬지 않고 작업이 가능하기 때문에 사무노동자의 업무는 챗GPT 특성을 이해하여 작업 지시를 내리는 프롬프트 작성과 챗GPT 생산 결과를 검증하는 업무가 가장 중요한 업무가 될 것이고 기존 오피스와 R/파이썬/SQL은 이를 보좌하는 기능으로 재편될 것으로 예측된다.\n\n\n\n\n챗GPT 도입 전(AS-IS)\n\n\n\n\n챗GPT 도입 후(TO-BE)\n\n\n\n그림 1: 챗GPT 도입에 따른 업무변화\n\n\n\n5 챗GPT 수행가능 작업\n챗GPT가 사무노동자의 업무를 대신할 수 있으나 모든 업무를 담당할 수는 없고, 기본적으로 챗GPT가 수행가능한 업무 범위는 사람이 직접 할 수 없는 일을 ChatGPT에 지시하면 안 된다.\n\n챗GPT 초기 정확한 응답결과가 요구되는 경우 챗GPT 사용이 권장되지 않았으나 GPT-4가 출시되고 챗GPT 플러그인이 출시되면서 수학계산과 같은 연산작업과 프로그래밍을 통한 계산작업에도 적용영역을 넓히고 있다.\n응답품질을 사람이 직접 확인할 수 있는 경우 챗GPT를 사용한다. 여전히 헐루시네이션(hallucination) 문제가 해결되지 않았고 성, 나이, 직업, 인종, 종교 등에 대한 편향성이 존재하고 부정적인 텍스트가 응답으로 나오는 경우 책임자가 걸러내야한다.\n주민번호, 코드, 공정수율 등 민감데이터(Sensitive Data)를 프롬프트에 넣어 챗GPT에 전달할 경우 보안 등 문제가 있어 사용하지 말아야 한다.\n콘텐츠 저작권이 이슈가 되지 않는 경우는 적극 사용하고 경우에 따라 저작권 이슈가 발생할 수 있는 경우 주의해서 법률자문 등을 받아 후속 업무를 진행한다.\n\n\n\n\n\n\n참고문헌\n\nHardie, M., & Saha, S. (2012). Builders Perceptions of Lowest Cost Procurement and Its Impact on Quality. Construction Economics and Building, 9(1), 1–8. https://doi.org/10.5130/ajceb.v9i1.3009"
  },
  {
    "objectID": "langchain_arch.html",
    "href": "langchain_arch.html",
    "title": "chatGPT",
    "section": "",
    "text": "AI 앱 개발은 전통적으로 검증된 개발방법론에 기반한다. 한가지 중요한 점은 거대언어모형(LLM)이 엔진으로 중요한 역할을 수행한다. 비유를 하자면 운영체제 UNIX에 비견된다. 강력한 데이터 기반 LLM 엔진을 바탕으로 다양한 고성능 AI 앱 개발이 가능하다.\n\n\n폭포수 모형\nV-모형\n스크럼\n기계학습 개발\nAI 앱 개발\n\n\n\n\n\n\n\ngraph TD\n    A[요구사항] --&gt; B[아키텍쳐/디자인]\n    B --&gt; C[구현]\n    C --&gt; D[검증/테스트]\n    D --&gt; E[유지보수]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n그림 1: ?(caption)"
  },
  {
    "objectID": "langchain_arch.html#환경설정",
    "href": "langchain_arch.html#환경설정",
    "title": "chatGPT",
    "section": "\n4.1 환경설정",
    "text": "4.1 환경설정\nLangChain 에서 OpenAI chatGPT를 호출하여 원하는 작업을 수행한다. 먼저 openai와 langchain을 설치한다.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEY를 환경변수를 넣어두고 OpenAI() 함수에서 호출하여 사용할 수 있도록 한다.\n\nimport os\nfrom langchain.llms import OpenAI\n\nos.environ['OPENAI_API_TOKEN'] = os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "langchain_arch.html#농담",
    "href": "langchain_arch.html#농담",
    "title": "chatGPT",
    "section": "\n4.2 농담",
    "text": "4.2 농담\n그리고 나서, 농담으로 헬로월드를 찍어본다. model_name을 비롯한 인수를 응답속도, 정확도, 간결함, 창의성, 비용 등을 고려하여 지정하여 원하는 결과를 얻어낸다.\n\nllm = OpenAI(model_name=\"text-davinci-003\", n=1, temperature=0.9)\nllm(\"재미있는 농담해 주세요\")\n#&gt; '\\n\\n도둑이 의자를 훔쳐갔는데 사람들이 \"몸통만 훔쳐갔네!\"라고 했어요.\\n\\n도둑이 답하기로 \"의자가 제 몸통이에요!\"라고 했어요.'\n\n3개 농담을 뽑아보자.\n\nllm_result = llm.generate([\"재미있는 농담해 주세요\"]*3)\nllm_jokes = llm_result.generations\nllm_jokes\n#&gt; [[Generation(text='\\n\\nQ. 날개가 있는 동물은 무엇인가요?\\nA. 새요!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\nQ. 바람에 비가 내려가면 어떻게 합니까?\\nA. 열쇠를 놓치지 말고 집에 들어가세요!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. 무엇이 비비는 질문이었다고 하면? \\n\\nA. 비가 왜 오는 걸까요?', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
  },
  {
    "objectID": "langchain_arch.html#프롬프트-템플릿",
    "href": "langchain_arch.html#프롬프트-템플릿",
    "title": "chatGPT",
    "section": "\n4.3 프롬프트 템플릿",
    "text": "4.3 프롬프트 템플릿\n프롬프트 템플릿을 작성하여 해당 작업을 수행토록 지시할 수 있다. 예를 들어 회사명을 작명하는데 대표적으로 잘 작명된 회사명을 제시하고 제약 조건을 추가로 둔 후 회사명 작명지시를 수행시킬 수 있다.\n\n4.3.1 영문\n랭체인 문서에 나와있는 예제를 사용해서 PromptTemplate으로 프롬프트를 완성해보자.\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n\n\nlibrary(reticulate)\nsocks_prompt_chr &lt;- py$socks_prompt\ncat(socks_prompt_chr)\n#&gt; \n#&gt; I want you to act as a naming consultant for new companies.\n#&gt; \n#&gt; Here are some examples of good company names:\n#&gt; \n#&gt; - search engine, Google\n#&gt; - social media, Facebook\n#&gt; - video sharing, YouTube\n#&gt; \n#&gt; The name should be short, catchy and easy to remember.\n#&gt; \n#&gt; What is a good name for a company that makes colorful socks?\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; BrightSox.\n\n\n4.3.2 국문\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"양말\")\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"양말\")\n\n\ncat(py$k_socks_result)\n#&gt; \n#&gt; - 슬립그랩, 스타플래그, 소다르트, 스위트스웨이드, 코싱클럽, 레이크페리"
  },
  {
    "objectID": "langchain_arch.html#영문",
    "href": "langchain_arch.html#영문",
    "title": "chatGPT",
    "section": "\n4.4 영문",
    "text": "4.4 영문\n랭체인 문서에 나와있는 예제를 사용해서 PromptTemplate으로 프롬프트를 완성해보자.\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n\n\nlibrary(reticulate)\nsocks_prompt_chr &lt;- py$socks_prompt\ncat(socks_prompt_chr)\n#&gt; \n#&gt; I want you to act as a naming consultant for new companies.\n#&gt; \n#&gt; Here are some examples of good company names:\n#&gt; \n#&gt; - search engine, Google\n#&gt; - social media, Facebook\n#&gt; - video sharing, YouTube\n#&gt; \n#&gt; The name should be short, catchy and easy to remember.\n#&gt; \n#&gt; What is a good name for a company that makes colorful socks?\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; FancyToes!"
  },
  {
    "objectID": "langchain_arch.html#국문",
    "href": "langchain_arch.html#국문",
    "title": "chatGPT",
    "section": "\n4.5 국문",
    "text": "4.5 국문\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"양말\")\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"양말\")\n\n\ncat(py$k_socks_result)\n#&gt; \n#&gt; - 부디, 양말\n#&gt; - 스트랩키, 양말\n#&gt; - 소프트플립, 양말\n#&gt; - 바이트, 양말"
  },
  {
    "objectID": "langchain_arch.html#요약",
    "href": "langchain_arch.html#요약",
    "title": "chatGPT",
    "section": "\n4.4 요약",
    "text": "4.4 요약\nopenAI Tokenizer\n한글은 영어에 비해 토큰 크기가 크다. 이를 위해서 text-davinci-003 모델이 소화할 수 있는 토큰보다 크기를 줄여야한다. 대한민국 대통령 취임사 중 박근혜 대통령 취임사에서 대략 2,000 토큰 크기를 대상으로 문서 요약을 수행해보자.\n\nfrom langchain import OpenAI, PromptTemplate, LLMChain\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0)\n\ntext_splitter = CharacterTextSplitter()\n\nwith open('data/state_of_the_union.txt') as f:\n# with open('data/취임사.txt') as f:\n    inaugural_address  = f.read()\n    \ntexts = text_splitter.split_text(inaugural_address)\n\nfrom langchain.docstore.document import Document\n\ndocs = [Document(page_content=t) for t in texts[:]]\n\nfrom langchain.chains.summarize import load_summarize_chain\n\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\nchain.run(docs)"
  },
  {
    "objectID": "whisper.html",
    "href": "whisper.html",
    "title": "chatGPT",
    "section": "",
    "text": "OpenSLR은 음성 인식을 위한 학습용 말뭉치, 음성 인식 관련 소프트웨어 등 음성 및 언어 자원을 제공하고 있다.\n\n대규모(1000시간) 영어 음성 읽기 말뭉치에서 영어 음성 읽기 하나를 추출해서 관련 사항을 정답문과 비교해보자.\n\n\n\n\n대규모(1000시간) 영어 음성 읽기 말뭉치에 포함된 영어음성대본에서 텍스트를 추출해서 다음에 영어 음성에서 텍스트 추출을 비교한다.\n\n코드library(tidyverse)\n# fs::dir_ls(path=\"data/LibriSpeech/dev-clean/1993/147149\")\n\ntrans_txt &lt;- read_lines(\"data/LibriSpeech/dev-clean/1993/147149/1993-147149.trans.txt\") \n\n# trans_0011_str &lt;- trans_txt[str_detect(trans_txt, \"0011\")]\n# trans_str &lt;- str_extract_all(trans_0011_str, \"[a-zA-Z].+\")[[1]]\n\ntrans_0011 &lt;- trans_txt %&gt;% \n  enframe() %&gt;% \n  separate(value, into = c(\"순번\", \"텍스트\"), sep = \"\\\\s\", extra = \"merge\") %&gt;% \n  mutate(텍스트 = str_to_lower(텍스트)) %&gt;% \n  filter(str_detect(순번, \"0011\")) %&gt;% \n  pull(텍스트)\n\n\nthen the mother lifted up her voice and wept\n\n\n\n영어 음성을 들어보자. .flac 파일을 av 패키지 av_audio_convert() 함수로 .mp3 혹은 .wav 파일 변환이 가능하다.\n\n코드library(av)\nlibrary(embedr)\n\naudio_file &lt;- \"data/LibriSpeech/dev-clean/1993/147149/1993-147149-0011.flac\"\n\nav::av_audio_convert(audio_file, output = \"data/whisper_before.mp3\", \n                     format = \"mp3\", sample_rate = 16000)\n#&gt; [1] \"D:\\\\tcs\\\\chatGPT\\\\data\\\\whisper_before.mp3\"\n\nwhisper_before_mp3 &lt;- av::read_audio_bin(\"data/whisper_before.mp3\")\n\nembedr::embed_audio(\"data/whisper_before.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "whisper.html#환경설정",
    "href": "whisper.html#환경설정",
    "title": "chatGPT",
    "section": "\n4.1 환경설정",
    "text": "4.1 환경설정\nLangChain 에서 OpenAI chatGPT를 호출하여 원하는 작업을 수행한다. 먼저 openai와 langchain을 설치한다.\n\n!pip3 install openai langchain\n\nOPENAI_API_KEY를 환경변수를 넣어두고 OpenAI() 함수에서 호출하여 사용할 수 있도록 한다.\n\nimport os\nfrom langchain.llms import OpenAI\n\nos.environ['OPENAI_API_TOKEN'] = os.environ.get('OPENAI_API_KEY')"
  },
  {
    "objectID": "whisper.html#농담",
    "href": "whisper.html#농담",
    "title": "chatGPT",
    "section": "\n4.2 농담",
    "text": "4.2 농담\n그리고 나서, 농담으로 헬로월드를 찍어본다. model_name을 비롯한 인수를 응답속도, 정확도, 간결함, 창의성, 비용 등을 고려하여 지정하여 원하는 결과를 얻어낸다.\n\nllm = OpenAI(model_name=\"text-davinci-003\", n=1, temperature=0.9)\nllm(\"재미있는 농담해 주세요\")\n#&gt; '\\n\\nQ. 어디가는 열차는 어디까지 가나요? \\nA. 꼬리치기로 갑니다!'\n\n3개 농담을 뽑아보자.\n\nllm_result = llm.generate([\"재미있는 농담해 주세요\"]*3)\nllm_jokes = llm_result.generations\nllm_jokes\n#&gt; [[Generation(text='\\n\\nQ. 왜 돼지가 물 속에 빠졌나요?\\n\\nA. 그건 주인이 돼지를 산책시키기 위해 물 속까지 갔기 때문이죠.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. 어디서 손님이 가장 많은가?\\n\\nA. 빵집 바깥에서! 왜냐하면 빵이 밖으로 나가는 거니까요!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. 왜 소는 물을 마시지 않나요?\\n\\nA. 왜냐하면 소는 물이 너무 말랐기 때문이죠!', generation_info={'finish_reason': 'stop', 'logprobs': None})]]"
  },
  {
    "objectID": "whisper.html#프롬프트-템플릿",
    "href": "whisper.html#프롬프트-템플릿",
    "title": "chatGPT",
    "section": "\n4.3 프롬프트 템플릿",
    "text": "4.3 프롬프트 템플릿\n프롬프트 템플릿을 작성하여 해당 작업을 수행토록 지시할 수 있다. 예를 들어 회사명을 작명하는데 대표적으로 잘 작명된 회사명을 제시하고 제약 조건을 추가로 둔 후 회사명 작명지시를 수행시킬 수 있다.\n\n4.3.1 영문\n랭체인 문서에 나와있는 예제를 사용해서 PromptTemplate으로 프롬프트를 완성해보자.\n\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n\n\nlibrary(reticulate)\nsocks_prompt_chr &lt;- py$socks_prompt\ncat(socks_prompt_chr)\n#&gt; \n#&gt; I want you to act as a naming consultant for new companies.\n#&gt; \n#&gt; Here are some examples of good company names:\n#&gt; \n#&gt; - search engine, Google\n#&gt; - social media, Facebook\n#&gt; - video sharing, YouTube\n#&gt; \n#&gt; The name should be short, catchy and easy to remember.\n#&gt; \n#&gt; What is a good name for a company that makes colorful socks?\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#&gt; \n#&gt; - Snazzy Socks\n\n\n4.3.2 국문\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"양말\")\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"양말\")\n\n\ncat(py$k_socks_result)\n#&gt; \n#&gt; - 슈슈, 양말\n#&gt; - 솔레인, 양말\n#&gt; - 바바시, 양말\n#&gt; - 스몰하우스, 양말"
  },
  {
    "objectID": "whisper.html#요약",
    "href": "whisper.html#요약",
    "title": "chatGPT",
    "section": "\n4.4 요약",
    "text": "4.4 요약\nopenAI Tokenizer\n한글은 영어에 비해 토큰 크기가 크다. 이를 위해서 text-davinci-003 모델이 소화할 수 있는 토큰보다 크기를 줄여야한다. 대한민국 대통령 취임사 중 박근혜 대통령 취임사에서 대략 2,000 토큰 크기를 대상으로 문서 요약을 수행해보자.\n\nfrom langchain import OpenAI, PromptTemplate, LLMChain\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0)\n\ntext_splitter = CharacterTextSplitter()\n\nwith open('data/state_of_the_union.txt') as f:\n# with open('data/취임사.txt') as f:\n    inaugural_address  = f.read()\n    \ntexts = text_splitter.split_text(inaugural_address)\n\nfrom langchain.docstore.document import Document\n\ndocs = [Document(page_content=t) for t in texts[:]]\n\nfrom langchain.chains.summarize import load_summarize_chain\n\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\nchain.run(docs)"
  },
  {
    "objectID": "whisper.html#오디오-표본",
    "href": "whisper.html#오디오-표본",
    "title": "chatGPT",
    "section": "",
    "text": "대규모(1000시간) 영어 음성 읽기 말뭉치에서 영어 음성 읽기 하나를 추출해서 관련 사항을 정답문과 비교해보자.\n\n\n\n\n대규모(1000시간) 영어 음성 읽기 말뭉치에 포함된 영어음성대본에서 텍스트를 추출해서 다음에 영어 음성에서 텍스트 추출을 비교한다.\n\n코드library(tidyverse)\n# fs::dir_ls(path=\"data/LibriSpeech/dev-clean/1993/147149\")\n\ntrans_txt &lt;- read_lines(\"data/LibriSpeech/dev-clean/1993/147149/1993-147149.trans.txt\") \n\n# trans_0011_str &lt;- trans_txt[str_detect(trans_txt, \"0011\")]\n# trans_str &lt;- str_extract_all(trans_0011_str, \"[a-zA-Z].+\")[[1]]\n\ntrans_0011 &lt;- trans_txt %&gt;% \n  enframe() %&gt;% \n  separate(value, into = c(\"순번\", \"텍스트\"), sep = \"\\\\s\", extra = \"merge\") %&gt;% \n  mutate(텍스트 = str_to_lower(텍스트)) %&gt;% \n  filter(str_detect(순번, \"0011\")) %&gt;% \n  pull(텍스트)\n\n\nthen the mother lifted up her voice and wept\n\n\n\n영어 음성을 들어보자. .flac 파일을 av 패키지 av_audio_convert() 함수로 .mp3 혹은 .wav 파일 변환이 가능하다.\n\n코드library(av)\nlibrary(embedr)\n\naudio_file &lt;- \"data/LibriSpeech/dev-clean/1993/147149/1993-147149-0011.flac\"\n\nav::av_audio_convert(audio_file, output = \"data/whisper_before.mp3\", \n                     format = \"mp3\", sample_rate = 16000)\n#&gt; [1] \"D:\\\\tcs\\\\chatGPT\\\\data\\\\whisper_before.mp3\"\n\nwhisper_before_mp3 &lt;- av::read_audio_bin(\"data/whisper_before.mp3\")\n\nembedr::embed_audio(\"data/whisper_before.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "whisper.html#동영상에서-오디오-추출",
    "href": "whisper.html#동영상에서-오디오-추출",
    "title": "chatGPT",
    "section": "\n3.1 동영상에서 오디오 추출",
    "text": "3.1 동영상에서 오디오 추출\nffmpeg 프로그램을 사용하면 오디오를 추출할 수 있다. MP4 파일에서 16비트 깊이와 16kHz 샘플링 레이트로 오디오를 추출하여야 whisper에 입력값으로 넣을 수 있는 .wav 파일이 된다. 두가지 조건(16비트 깊이와 16kHz 샘플링)이 충족되지 않을 경우 Whisper에서 처리할 수 없다는 오류가 나온다.\n\n\n\n.mp4에서 .wav 추출\nffmpeg -i misinformation.mp4 -acodec pcm_s16le -ar 16000 -ac 2 misinformation_16.wav\n\n\n\n.mp4에서 .mp3 추출\n.mp3 확장자를 줄 경우 오디오를 mp3 파일로 추출하여 파일크기를 크게 줄일 수 있다.\nffmpeg -i misinformation.mp4 -acodec pcm_s16le -ar 16000 -ac 2 misinformation.mp3\n\n\n\n전체 .mp3 파일이 너무 길어 ffmpeg를 사용해서 30분부터 30초만 추출하는 코드를 작성해서 들어보자.\nffmpeg -i misinformation.mp3 -ss 00:30:30 -t 00:00:30 -vn -codec:a libmp3lame -qscale:a 2 misinformation_short.mp3\n\n코드embedr::embed_audio(\"data/LibriSpeech/misinformation_short.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "whisper.html#stt",
    "href": "whisper.html#stt",
    "title": "chatGPT",
    "section": "\n3.2 STT",
    "text": "3.2 STT\n16비트 깊이와 16kHz 샘플링 조건을 갖춘 .wav 파일이 준비되면 다음 단계로 음성-텍스트 변환 Whisper 모델을 선정하여 텍스트 전사 작업을 수행한다. 윈도우 10 에서 2.6 GB 영어 medium.en 모델은 알 수 없는 오류로 인해 base.en 모델을 사용하여 영어 음성에서 텍스트를 추출했다.\n\n코드library(audio.whisper)\n\nmedium_model &lt;- whisper(\"base.en\")\n\nmisinformation_trans &lt;- predict(medium_model, newdata = \"data/LibriSpeech/misinformation_16.wav\", \n                                language = \"en\", n_threads = 2)\n\n\nWhisper 모델을 통해 나온 음성-텍스트 변환 결과를 로컬 파일에 저장하여 점검한다.\n\n코드library(tidyverse)\nmisinformation_trans$data %&gt;% \n  mutate(data = glue::glue(\"{from} ==&gt; {to} {text}\")) %&gt;% \n  pull(data) %&gt;% \n  write_lines(\"data/LibriSpeech/misinformation_oneline.txt\")"
  },
  {
    "objectID": "whisper.html#srt",
    "href": "whisper.html#srt",
    "title": "chatGPT",
    "section": "\n3.3 SRT",
    "text": "3.3 SRT\n몇번의 시행착오를 거쳐 순번, 시작시각, 종료시각, 텍스트로 구성된 파일을 .srt 파일 형태로 변환하여 영어 자막작업을 마무리한다.\n\n코드mis_srt_raw &lt;- read_lines(\"data/LibriSpeech/misinformation_proof_reading.txt\")\n\nmis_srt_tbl &lt;- mis_srt_raw %&gt;% \n  enframe() %&gt;% \n  separate(value, into = c(\"start\", \"end\"),   sep = \"\\\\s==&gt;\\\\s\", extra = \"merge\") %&gt;% \n  separate(end,   into = c(\"end\", \"subtitle\"), sep = \"\\\\s\", extra = \"merge\") %&gt;% \n  mutate(subtitle = str_trim(subtitle))\n \nmis_srt_tbl %&gt;% \n  mutate(srt = glue::glue(\"{name} \\n {start} --&gt; {end} \\n {subtitle}\\n\\n\")) %&gt;% \n  pull(srt) %&gt;% \n  write_lines(\"data/LibriSpeech/misinformation_proof_reading_srt.srt\")\n\n\n유튜브 동영상 영문 자막으로 사용될 .srt 자막 파일을 불러읽어와서 최종 작업결과를 살펴본다.\n\n코드library(tidyverse)\nmis_srt &lt;- read_lines(\"data/LibriSpeech/misinformation.srt\")\n\nmis_srt %&gt;% \n  head(20) \n#&gt;  [1] \"1 \"                                                                                          \n#&gt;  [2] \"00:00:00.000 --&gt; 00:00:27.520 \"                                                              \n#&gt;  [3] \"Welcome everybody to our Seoul R Online seminar where we explore various ideas and\"          \n#&gt;  [4] \"\"                                                                                            \n#&gt;  [5] \"2 \"                                                                                          \n#&gt;  [6] \"00:00:27.520 --&gt; 00:00:33.360 \"                                                              \n#&gt;  [7] \"practices of data science. We are really happy today to have Jevin West from the University\" \n#&gt;  [8] \"\"                                                                                            \n#&gt;  [9] \"3 \"                                                                                          \n#&gt; [10] \"00:00:33.360 --&gt; 00:00:43.040 \"                                                              \n#&gt; [11] \"of Washington with us to talk about ChatGPT and misinformation. I'm sorry, I'll begin again.\"\n#&gt; [12] \"\"                                                                                            \n#&gt; [13] \"4 \"                                                                                          \n#&gt; [14] \"00:00:43.040 --&gt; 00:00:46.480 \"                                                              \n#&gt; [15] \"Okay, no problem. No, I do this a lot of times.\"                                             \n#&gt; [16] \"\"                                                                                            \n#&gt; [17] \"5 \"                                                                                          \n#&gt; [18] \"00:00:46.480 --&gt; 00:00:53.680 \"                                                              \n#&gt; [19] \"Welcome everybody to our Seoul R Online seminar. We explore various ideas and\"               \n#&gt; [20] \"\"\n\n\n\n코드library(magick)\n\nmis_mp4 &lt;- image_read_video(\"data/LibriSpeech/misinformation.mp4\",  fps = 1)"
  },
  {
    "objectID": "interview.html#문제-1",
    "href": "interview.html#문제-1",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n기계학습 분류모형개발할 때 클래스 불균형(class imbalance) 문제를 어떻게 처리하나요?"
  },
  {
    "objectID": "interview.html#문제-2",
    "href": "interview.html#문제-2",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n기계학습모형에서 bias 와 variance trade-off에서 존재합니다. 어떤 기계학습 모형이 bias 와 variance를 줄이는데 효과적으로 알려져 있나요?"
  },
  {
    "objectID": "interview.html#문제-3",
    "href": "interview.html#문제-3",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n리스트와 데이터프레임 자료구조의 차이점에 대해서 말씀해 주세요."
  },
  {
    "objectID": "interview.html#문제-4",
    "href": "interview.html#문제-4",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansing이 어떻게 다른지 설명하세요."
  },
  {
    "objectID": "interview.html#문제-5",
    "href": "interview.html#문제-5",
    "title": "chatGPT",
    "section": "",
    "text": "질문/과제\n\n\n\n\n\n제품 설명 등 텍스트 필드 칼럼이 있습니다. 기계학습 알고리즘 분류나 예측 모형에 적용시킬 수 있는 방법을 설명해주세요."
  },
  {
    "objectID": "prompt_for_develoopers.html",
    "href": "prompt_for_develoopers.html",
    "title": "chatGPT",
    "section": "",
    "text": "경고\n\n\n\n\n\n2023년 4월 앤드류 응(Andrew Ng) 대표가 이끄는 Deeplearning.AI에서 공개한 “ChatGPT Prompt Engineering for Developers” 내용을 정리한 것입니다. (Isa Fulford, 2023)"
  },
  {
    "objectID": "prompt_for_develoopers.html#api-키-설정",
    "href": "prompt_for_develoopers.html#api-키-설정",
    "title": "chatGPT",
    "section": "\n2.1 API 키 설정",
    "text": "2.1 API 키 설정\n개발자가 챗GPT 프롬프트 공학으로 AI 앱을 개발하기 위해서 필요한 것은 먼저 OpenAI 웹사이트에서 API Keys를 발급받고 이를 활용하는 것이다.\n\n\n\n.env 파일\n.env 파일에 OpenAI에서 발급된 API KEY를 다음과 같은 방식으로 저장한다.\nENV_OPENAI_API_KEY=sk-q79SxxxxxxxxxxxxxxxxxxxxxxxxXK\n\n\nopenai\n.env 파일에 기록된 API KEY 정보를 os.getenv() 함수에서 환경정보로 불러 읽은 후에 이를 openai 패키지에 등록하여 후속 작업에 사용하도록 준비한다.\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "prompt_for_develoopers.html#헬로월드",
    "href": "prompt_for_develoopers.html#헬로월드",
    "title": "chatGPT",
    "section": "\n2.2 헬로월드",
    "text": "2.2 헬로월드\nget_completion() 사용자 정의 함수를 사용하여 요약작업을 수행하도록 한다. 프롬프트 공학 헬로월드 사례로 텍스트를 요약하는 xsum 데이터셋을 사용한다. ID 38900884 문서(document)는 다음 사항이 적혀있다.\n\n\n38900884 원문\n\"The Bath-born player, 28, has made 36 appearances for the Dragons since joining from Wasps in 2015. He is in his second season and signed a contract extension in December 2016. Dragons forwards coach Ceri Jones said: \"It's a big blow. Eddie has been excellent all year for us, he has really stepped up to the mark and will be a big loss.\" However, Jones says Jackson's misfortune can be a chance for others to thrive. \"We are very fortunate to have the likes of Ollie Griffiths, Harrison Keddie, James Thomas who can come into the back-row,\" said Jackson. \"Harri has shown glimpses of what he can do all season and there's definitely a player there, so this is an opportunity.\" Dragons travel to Munster in the Pro12 on Friday.\"\n\n\n디플번역\n배스 태생의 28세 선수는 2015년 와스프에서 드래곤즈에 입단한 이후 36경기에 출전했습니다. 두 번째 시즌을 보내고 있는 그는 2016년 12월에 연장 계약을 체결했습니다. 드래곤즈의 포워드 코치 세리 존스는 이렇게 말했습니다: \"큰 타격입니다. 에디는 올 한 해 동안 우리 팀에서 훌륭한 활약을 펼쳤고, 정말 큰 손실이 될 것입니다.\"라고 말했습니다. 하지만 존스는 잭슨의 불행이 다른 선수들에게는 기회가 될 수 있다고 말합니다. \"올리 그리피스, 해리슨 케디, 제임스 토마스 같은 선수들이 뒷줄에 들어올 수 있다는 것은 매우 행운입니다.\"라고 잭슨은 말합니다. \"해리는 올 시즌 그가 할 수 있는 것을 살짝 보여줬고, 확실히 그런 선수가 있기 때문에 이번이 기회입니다.\" 드래곤스는 금요일에 먼스터와 프로12 경기를 치릅니다.\n\nTranslated with www.DeepL.com/Translator (free version)\n\n\n\n상기 텍스트 요약작업을 수행해보자.\n\n\n프롬프트 요약작업결과\n\n코드def get_completion(prompt):\n    model=\"gpt-3.5-turbo\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0,\n    )\n    return response.choices[0].message[\"content\"]\n\ntext = f\"\"\"\nThe Bath-born player, 28, has made 36 appearances for the Dragons since joining from Wasps in 2015. He is in his second season and signed a contract extension in December 2016. Dragons forwards coach Ceri Jones said: \"It's a big blow. Eddie has been excellent all year for us, he has really stepped up to the mark and will be a big loss.\" However, Jones says Jackson's misfortune can be a chance for others to thrive. \"We are very fortunate to have the likes of Ollie Griffiths, Harrison Keddie, James Thomas who can come into the back-row,\" said Jackson. \"Harri has shown glimpses of what he can do all season and there's definitely a player there, so this is an opportunity.\" Dragons travel to Munster in the Pro12 on Friday.\n\"\"\"\nprompt = f\"\"\"\nSummarize the text delimited by triple backticks \\ \ninto a one sentence.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)  \n\n\nNewport Gwent Dragons player Eddie Jackson will miss the rest of the season due to a knee injury, but the team's forwards coach sees it as an opportunity for other players to step up.\n\n\n요약 원문 정답라벨\nNewport Gwent Dragons number eight Ed Jackson has undergone shoulder surgery and faces a spell on the sidelines."
  },
  {
    "objectID": "prompt_for_develoopers.html#명확한-지시명령어",
    "href": "prompt_for_develoopers.html#명확한-지시명령어",
    "title": "chatGPT",
    "section": "\n3.1 명확한 지시명령어",
    "text": "3.1 명확한 지시명령어\n\n\n\n\ngraph TB\nA[명확한 지시명령어 작성] --&gt; B[\"구분자 사용(Delimiter)\"]\nA --&gt; C[\"출력형식(HTML, JSON)\"]\nA --&gt; D[조건 확인]\nA --&gt; E[\"퓨삿(Few-Shot) 학습\"]\n\n\n\n\n\n\n3.1.1 구분자 사용\n구분 기호(delimiter)로 명확히 한다. 구분기호는 ``, \"\"\", &lt; &gt;, 태그&gt;, ': 등 사용가능하다.\nAI HUB 문서요약 텍스트 에서 샘플데이터를 다운로드 받아 구분자 사용의 사례로 활용하자.\n\n코드library(tidyverse)\nlibrary(jsonlite)\nlibrary(reticulate)\n\neditorial &lt;- jsonlite::stream_in(file(\"data/001.문서요약텍스트_sample/라벨링데이터/사설잡지/sample.jsonl\")) \n#&gt; \n Found 500 records...\n Found 700 records...\n Imported 700 records. Simplifying...\n\neditorial_sample &lt;- editorial %&gt;% \n  filter(id == \"148261803\") %&gt;% \n  select(id, abstractive, article_original) %&gt;%\n  mutate(article_original = map_chr(article_original, paste0, collapse=\" \")) \n\neditorial_sample %&gt;% \n  mutate(article_sub = str_sub(article_original, 1, 100)) %&gt;% \n  select(id, abstractive, article_sub) %&gt;% \n  gt::gt()\n\n\n\n\n\n\nid\nabstractive\narticle_sub\n\n\n148261803\n금융위원회는 러시앤캐시 등 자기자본 500억 이상인 큰 대부업체들이 저축은행을 인수할 수 있도록 길을 터줬는데 부실한 저축은행이 더 부실해지지 않도록 구조조정부터 해야 하고 저축은행을 인수한 대부업체는 대부업 자체에 손을 떼도록 해야 한다.\n금융위원회는 러시앤캐시 등 자기자본 500억원 이상인 대형 대부업체들이 저축은행 인수에 나설 수 있게 길을 터줬다. 또 저축은행이 펀드ㆍ보험ㆍ신용카드 판매업을 할 수 있게 해줬다.\n\n\n\n\n\n\n코드text = f\"\"\"\n금융위원회는 러시앤캐시 등 자기자본 500억 이상인 큰 대부업체들이 저축은행을 인수할 수 있도록 길을 터줬는데 부실한 저축은행이 더 부실해지지 않도록 구조조정부터 해야 하고 저축은행을 인수한 대부업체는 대부업 자체에 손을 떼도록 해야 한다.\n\"\"\"\nprompt = f\"\"\"\n백틱 세 개로 구분된 텍스트를 하나의 문장으로 요약합니다.\n```{text}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n\n\nAI-HUB 문서요약 정답\n금융위원회는 러시앤캐시 등 자기자본 500억 이상인 큰 대부업체들이 저축은행을 인수할 수 있도록 길을 터줬는데 부실한 저축은행이 더 부실해지지 않도록 구조조정부터 해야 하고 저축은행을 인수한 대부업체는 대부업 자체에 손을 떼도록 해야 한다.\n\n\nLLM 요약\n금융위원회는 대부업체들이 저축은행 인수 가능하게 하지만, 구조조정부터 해야하며 인수한 업체는 대부업에서 손을 떼야 한다.\n\n\n\n\n3.1.2 출력형식 지정\nJSON, HTML, XML 등 출력형식을 명시적으로 지정한다.\n\n코드prompt = f\"\"\"\n저자명과 장르가 포함된 도서 목록을 5권 생성합니다.\n다음 필드값을 갖고 JSON 형식으로 작성합니다: \n서지번호, 제목, 저자, 장르.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n1. {\n   \"서지번호\": \"001\",\n   \"제목\": \"1984\",\n   \"저자\": \"조지 오웰\",\n   \"장르\": \"SF\"\n}\n\n2. {\n   \"서지번호\": \"002\",\n   \"제목\": \"죽은 시인의 사회\",\n   \"저자\": \"노먼 메일러\",\n   \"장르\": \"소설\"\n}\n\n3. {\n   \"서지번호\": \"003\",\n   \"제목\": \"책은 독서가 아니다\",\n   \"저자\": \"유시민\",\n   \"장르\": \"자기계발\"\n}\n\n4. {\n   \"서지번호\": \"004\",\n   \"제목\": \"미움받을 용기\",\n   \"저자\": \"기시미 이치로\",\n   \"장르\": \"자기계발\"\n}\n\n5. {\n   \"서지번호\": \"005\",\n   \"제목\": \"해리 포터와 마법사의 돌\",\n   \"저자\": \"J.K. 롤링\",\n   \"장르\": \"판타지\"\n}\n\n3.1.3 조건확인\nLLM 모델에게 조건이 충족되는지 확인하도록 지시한다.\n\n코드text_1 = f\"\"\"\n차 한 잔을 만드는 것은 쉽습니다! 먼저 물을 끓여야 합니다. 끓는 동안 컵을 들고 티백을 넣으세요. 물이 충분히 뜨거워지면 티백 위에 붓기만 하면 됩니다. 차가 우러날 수 있도록 잠시 기다리세요. 몇 분 후 티백을 꺼내세요. 원한다면 설탕이나 우유를 넣어 맛을 더할 수 있습니다. 그리고 그게 다입니다! 맛있는 차 한 잔을 즐기세요.\n\"\"\"\nprompt = f\"\"\"\n백틱 3개로 구분된 텍스트가 제공됩니다. \n일련의 지침이 포함된 경우 다음 형식으로 해당 지침을 다시 작성합니다:\n\n1단계 - ...\n2단계 - ...\n...\nN단계 - ...\n\n텍스트에 일련의 지침이 포함되어 있지 않은 경우에는 \\\"제공된 단계 없음\\\"이라고 간단히 작성합니다.\n```{text_1}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(\"Completion for Text 1:\")\nprint(response)\n\n\n1단계 - 물을 끓입니다.\n2단계 - 끓는 동안 컵에 티백을 넣습니다.\n3단계 - 물이 충분히 뜨거워지면 티백 위에 물을 붓습니다.\n4단계 - 차가 우러날 수 있도록 잠시 기다립니다.\n5단계 - 몇 분 후 티백을 꺼냅니다.\n6단계 - 원한다면 설탕이나 우유를 넣어 맛을 더합니다.\n7단계 - 맛있는 차 한 잔을 즐깁니다.\n\n3.1.4 퓨샷 프롬프트\n예제를 LLM에 제공하여 해당 질의에 대한 응답을 이끌어내는 방식이다.\n\n코드prompt = f\"\"\"\n당신의 임무는 일관된 스타일로 대답하는 것입니다.\n\n&lt;어린이&gt;: 인내심에 대해 가르쳐주세요.\n\n&lt;조부모&gt;: 가장 깊은 계곡을 깎는 강은 수수한 샘에서 흐르고, 가장 웅장한 교향곡은 한 음에서 시작됩니다; 가장 복잡한 자수는 하나의 실에서 시작됩니다.\n\n&lt;어린이&gt;: 회복탄력성에 대해 가르쳐 주세요.\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n&lt;조부모&gt;: 회복탄력성은 어려운 상황에서도 빠르게 회복하는 능력입니다. 마치 탄력 있는 공처럼 어려운 상황에서 튕겨나와 다시 일어날 수 있는 능력이죠. 이것은 우리가 어려운 일을 겪을 때 긍정적인 마인드와 강한 의지력을 가지고 있어야 가능합니다."
  },
  {
    "objectID": "prompt_for_develoopers.html#llm-모형에-생각시간-제공",
    "href": "prompt_for_develoopers.html#llm-모형에-생각시간-제공",
    "title": "chatGPT",
    "section": "\n3.2 LLM 모형에 생각시간 제공",
    "text": "3.2 LLM 모형에 생각시간 제공\n\n\n\n\ngraph TB\nA[LLM 모형에 생각시간 제공] --&gt; B[\"수행작업 단계 명시\"]\nA --&gt; C[\"모델 스스로 해결책 찾도록 지시\"]\n\n\n\n\n\n\n3.2.1 수행작업 단계 명시\n지시한 작업을 완수하는데 필요한 단계를 명시한다.\n\n코드text = f\"\"\"\n매력적인 마을에서 잭과 질 남매는 언덕 꼭대기에 있는 우물에서 물을 길어오기 위한 여정을 시작합니다. 우물. 즐거운 마음으로 노래를 부르며 오르던 중 불행이 닥쳤습니다. 잭은 돌에 걸려 넘어졌고 질도 그 뒤를 따라 언덕 아래로 굴러 떨어졌습니다. 약간의 상처를 입었지만 두 사람은 서로를 위로하며 집으로 돌아왔습니다. 사고에도 불구하고 두 사람의 모험심은 꺾이지 않았고 기쁨을 만끽하며 탐험을 계속했습니다.\n\"\"\"\n# example 1\nprompt_1 = f\"\"\"\n다음 작업을 수행합니다: \n1 - 백틱 세 개로 구분된 다음 텍스트를 1문장으로 요약합니다.\n2 - 요약을 영어로 번역합니다.\n3 - 영어 요약에 각 이름을 나열합니다.\n4 - 다음 키가 포함된 json 객체를 출력합니다: english_summary, num_names.\n\n답을 줄 바꿈으로 구분하세요.\n\n텍스트:\n```{text}```\n\"\"\"\nresponse = get_completion(prompt_1)\nprint(response)\n\n\n잭과 질은 우물에서 물을 길어오기 위해 여정을 시작합니다. 하지만 불행히도 잭은 돌에 걸려 넘어지고 질도 굴러 떨어집니다. 상처를 입었지만 두 사람은 모험심이 꺾이지 않고 계속 탐험을 이어갑니다.\n\nJack and Jill set out on a journey to fetch water from a charming village well atop a hill. However, unfortunate events occur as Jack trips over a rock and Jill tumbles down the hill. Despite their injuries, the siblings continue their adventure with unbroken spirits.\n\nNames: Jack, Jill\n\n{\n  \"english_summary\": \"Jack and Jill set out on a journey to fetch water from a charming village well atop a hill. However, unfortunate events occur as Jack trips over a rock and Jill tumbles down the hill. Despite their injuries, the siblings continue their adventure with unbroken spirits.\",\n  \"num_names\": 2\n}\n한단계 더 들어가 구체적인 출력형식도 지정한다.\n\n코드prompt_2 = f\"\"\"\n다음 작업을 수행합니다: \n1 - 백틱 세 개로 구분된 다음 텍스트를 1 문장으로 요약합니다.\n2 - 요약을 영어로 번역합니다.\n3 - 영어 요약에 각 이름을 나열합니다.\n4 - 다음 키가 포함된 json 객체를 출력합니다: english_summary, num_names.\n\n\n다음 형식을 사용합니다:\n텍스트: &lt;요약할 텍스트&gt;\n요약: &lt;요약&gt;\n번역: &lt;요약 번역&gt;\n이름: &lt;영어 요약의 이름 목록&gt;\n출력 JSON: &lt;요약 및 num_names가 포함된 json&gt;\n\n텍스트: \n```{text}```\n\"\"\"\nresponse = get_completion(prompt_2)\nprint(response)\n\n\n요약: 잭과 질 남매는 우물에서 물을 길어오기 위한 여정을 시작하고, 불행이 닥쳐도 모험심은 꺾이지 않았습니다.\n번역: Jack and Jill siblings start a journey to fetch water from a well in a charming village, but unfortunate events occur. Despite the accident, their adventurous spirit remains unbroken and they continue to explore with joy.\n이름: Jack, Jill\n출력 JSON: {\"english_summary\": \"Jack and Jill siblings start a journey to fetch water from a well in a charming village, but unfortunate events occur. Despite the accident, their adventurous spirit remains unbroken and they continue to explore with joy.\", \"num_names\": 2}\n\n3.2.2 모델 스스로 해결책 찾도록 지시\nLLM 모델에 먼저 자체 해결책을 찾도록 지시하여 다양한 문제를 해결할 수 있다."
  },
  {
    "objectID": "prompt_for_develoopers.html#반복-프롬프트-개발",
    "href": "prompt_for_develoopers.html#반복-프롬프트-개발",
    "title": "chatGPT",
    "section": "\n3.3 반복 프롬프트 개발",
    "text": "3.3 반복 프롬프트 개발\n프롬프트 개발은 운좋게 한번에 원하는 결과를 얻을 수도 있지만 대개는 LLM 작업결과를 검토하고 다듬어가는 과정이 필수적이다.\n\n코드fact_sheet_chair = \"\"\"\n개요\n- 미드 센추리에서 영감을 받은 아름다운 사무용 가구 제품군의 일부입니다, \n파일 캐비닛, 책상, 책장, 회의용 테이블 등을 포함합니다.\n- 쉘 색상과 베이스 마감의 여러 옵션이 있습니다.\n- 플라스틱 소재의 후면 및 전면 커버(SWC-100) 또는 \n또는 10가지 패브릭 및 6가지 가죽 옵션의 풀 커버(SWC-110)로 제공됩니다.\n- 기본 마감 옵션: 스테인리스 스틸, 무광 블랙, \n유광 화이트 또는 크롬.\n- 의자는 팔걸이가 있든 없든 선택할 수 있습니다.\n- 가정 또는 비즈니스 환경에 적합합니다.\n- 계약 사용 자격이 있습니다.\n\n구조\n- 5바퀴 플라스틱 코팅 알루미늄 베이스.\n- 공압식 의자는 쉽게 올리거나 내릴 수 있도록 조절됩니다.\n\n치수\n- 폭 53cm | 20.87\"\n- 깊이 51 cm | 20.08\"\n- 높이 80 cm | 31.50\"\n- 좌석 높이 44cm | 17.32\"\n- 좌석 깊이 41cm | 16.14\"\n\n옵션\n- 소프트 또는 하드 플로어 캐스터 옵션.\n- 두 가지 시트 폼 밀도 선택 가능: \n 중간(1.8파운드/ft3) 또는 높음(2.8파운드/ft3)\n- 팔걸이 없음 또는 8위치 PU 팔걸이 \n\n재료\n쉘 베이스 글라이더\n- 변형 나일론 PA6/PA66 코팅된 주조 알루미늄.\n- 셸 두께: 10mm.\nSEAT\n- HD36 폼\n\n원산지\n- 이탈리아\n\"\"\"\n\nprompt = f\"\"\"\n너의 임무는 마케팅 팀이 기술 자료집을 기반으로 제품의 소매 웹사이트에 대한 설명을 작성하는 것을 돕는 것입니다.\n\n백틱 세 개로 구분된 기술 사양서에 적시된 정보를 기반으로 제품 설명서를 작성한다.\n\n기술 사양: \n```{fact_sheet_chair}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n당신의 임무는 마케팅 팀이 제품의 소매 웹사이트에 대한 설명을 작성하는 것을 돕는 것입니다. 이를 위해 백틱 세 개로 구분된 기술 사양서에 적시된 정보를 기반으로 제품 설명서를 작성해야 합니다.\n\n이 제품은 미드 센추리에서 영감을 받은 아름다운 사무용 가구 제품군의 일부입니다. 파일 캐비닛, 책상, 책장, 회의용 테이블 등을 포함하며, 쉘 색상과 베이스 마감의 여러 옵션이 있습니다. 또한, 플라스틱 소재의 후면 및 전면 커버(SWC-100) 또는 10가지 패브릭 및 6가지 가죽 옵션의 풀 커버(SWC-110)로 제공됩니다. 기본 마감 옵션은 스테인리스 스틸, 무광 블랙, 유광 화이트 또는 크롬입니다.\n\n이 제품은 가정 또는 비즈니스 환경에 적합하며, 계약 사용 자격이 있습니다. 구조는 5바퀴 플라스틱 코팅 알루미늄 베이스로 이루어져 있으며, 공압식 의자는 쉽게 올리거나 내릴 수 있도록 조절됩니다. 이 의자의 폭은 53cm, 깊이는 51cm, 높이는 80cm, 좌석 높이는 44cm, 좌석 깊이는 41cm입니다.\n\n이 제품은 소프트 또는 하드 플로어 캐스터 옵션을 제공하며, 두 가지 시트 폼 밀도 선택 가능합니다. 또한, 팔걸이 없음 또는 8위치 PU 팔걸이를 선택할 수 있습니다. 쉘 베이스 글라이더는 변형 나일론 PA6/PA66 코팅된 주조 알루미늄으로 이루어져 있으며, 셸 두께는 10mm입니다. 시트는 HD36 폼으로 만들어졌으며, 이 제품은 이탈리아에서 생산됩니다.\n\n3.3.1 텍스트 길이 조정\nLLM 작업 결과가 너무길다. 출력결과를 50 단어로 한정한다.\n\n코드prompt = f\"\"\"\n너의 임무는 마케팅 팀이 기술 자료집을 기반으로 제품의 소매 웹사이트에 대한 설명을 작성하는 것을 돕는 것입니다.\n\n백틱 세 개로 구분된 기술 사양서에 적시된 정보를 기반으로 제품 설명서를 작성한다.\n\n최대 50단어를 사용하세요.\n\n기술 사양서: \n```{fact_sheet_chair}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nThis product description is based on the technical specifications provided in a document separated by three backticks. The product is a beautiful line of office furniture inspired by Mid-Century design, including file cabinets, desks, bookshelves, and conference tables. It comes in various shell colors and base finishes, with options for plastic or full covers in different fabrics or leather. The chair has adjustable height and comes with or without armrests. It is suitable for home or business environments and has contract use eligibility.\n\n3.3.2 독자 대상 명시\n\n코드prompt = f\"\"\"\n너의 임무는 마케팅 팀이 기술 자료집을 기반으로 제품의 소매 웹사이트에 대한 설명을 작성하는 것을 돕는 것입니다.\n\n백틱 세 개로 구분된 기술 사양서에 적시된 정보를 기반으로 제품 설명서를 작성한다.\n\n이 설명은 가구 소매업체를 위한 것입니다, \n따라서 본질적으로 기술적인 내용이어야 하며 제품을 구성하는 재료에 초점을 맞춰야 합니다.\n\n최대 50단어를 사용하고 한글로 작성되어야 한다.\n\n기술 사양서: \n```{fact_sheet_chair}```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n미드 센추리에서 영감을 받은 아름다운 사무용 가구 제품군의 일부입니다. 파일 캐비닛, 책상, 책장, 회의용 테이블 등을 포함하며, 쉘 색상과 베이스 마감의 여러 옵션이 있습니다. 플라스틱 소재의 후면 및 전면 커버 또는 패브릭 및 가죽 옵션의 풀 커버로 제공됩니다. 의자는 팔걸이가 있든 없든 선택할 수 있으며, 가정 또는 비즈니스 환경에 적합합니다."
  },
  {
    "objectID": "prompt_for_develoopers.html#요약",
    "href": "prompt_for_develoopers.html#요약",
    "title": "chatGPT",
    "section": "\n4.1 요약",
    "text": "4.1 요약\n\n4.1.1 간략한 요약\n\n코드prod_review = \"\"\"\n딸의 생일 선물로 이 팬더 봉제 인형을 받았는데, 딸이 좋아해서 어디든 가지고 다닙니다. 부드럽고 매우 귀엽고 얼굴이 친근한 표정입니다. 하지만 제가 지불한 금액에 비해 조금 작습니다. 같은 가격에 더 큰 다른 옵션이 있을 것 같아요. 예상보다 하루 일찍 도착해서 아이에게 주기 전에 제가 직접 가지고 놀 수 있었어요.\n\"\"\"\n\nprompt = f\"\"\"\n전자상거래 사이트의 제품 후기에 대한 간단한 요약을 작성하는 것이 과제입니다. \n\n백틱 세 개로 구분된 아래 후기를 최대 30단어 이내로 요약하세요. \n후기: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\n작지만 귀여운 팬더 봉제인형, 얼굴이 친근하고 부드러워 딸이 좋아합니다. 가격 대비 크기는 작지만, 예상보다 일찍 도착해 기쁩니다.\n\n4.1.2 배송/배달 초점 두고 요약\n\n코드prompt = f\"\"\"\n전자상거래 사이트의 제품 후기에 대한 간단한 요약을 작성하는 것이 과제입니다. \n\n백틱 세 개로 구분된 아래 후기를 제품의 배송 및 배송과 관련된 모든 측면에 중점을 두어 최대 30단어 이내로 요약하세요. \n후기: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\n부드럽고 귀여운 팬더 봉제 인형, 조금 작은 가격에 비해, 빠른 배송.\n\n4.1.3 가격에 초점 두고 요약\n\n코드prompt = f\"\"\"\n전자상거래 사이트의 제품 후기에 대한 간단한 요약을 작성하는 것이 과제입니다. \n\n백틱 세 개로 구분된 아래 후기를 제품의 가격과 지각된 가치와 관련된 모든 측면에 중점을 두어 최대 30단어 이내로 요약하세요. \n후기: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\n부드럽고 귀여운 팬더 봉제 인형은 딸이 좋아하며, 예상보다 일찍 도착하여 만족스러웠지만, 가격 대비 크기가 작아서 다른 옵션을 고려할 수 있을 것 같다.\n\n4.1.4 요약 대신 추출\n\n코드prompt = f\"\"\"\n너의 임무는 전자상거래 사이트의 제품 리뷰에서 관련 정보를 추출하여 배송 부서에 피드백을 제공하는 것입니다. \n\n백틱 세 개로 구분된 아래 후기에서 배송과 배달과 관련된 정보를 최대 30단어 이내로 추출하세요.\n\n후기: ```{prod_review}```\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n\n\n배송과 배달과 관련된 정보: 예상보다 하루 일찍 도착"
  },
  {
    "objectID": "prompt_for_develoopers.html#추론",
    "href": "prompt_for_develoopers.html#추론",
    "title": "chatGPT",
    "section": "\n4.2 추론",
    "text": "4.2 추론\n\n4.2.1 감성(긍/부정)\n\n코드lamp_review = \"\"\"\n침실을 위한 멋진 램프가 필요했는데, 이 제품은 수납공간이 더 있고 가격대가 너무 높지 않았어요. 빠르게 받았습니다.  배송 중에 램프 줄이 끊어졌는데, 회사에서 기꺼이 새 것을 보내주었습니다. 그것도 며칠 안에 도착했어요. 조립도 쉬웠습니다.  누락된 부품이 있어서 고객지원팀에 연락했더니 매우 빠르게 누락된 부품을 보내주었어요! Lumina는 고객과 제품을 아끼는 훌륭한 회사인 것 같습니다!!!\n\"\"\"\n\nprompt = f\"\"\"\n세 개의 백틱으로 구분된 다음 제품 후기에 드러난 감정은 무엇입니까?\n\n후기 텍스트: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n긍정적인 감정 (만족, 감사, 칭찬)\n\n4.2.2 감정 유형 식별\n\n코드prompt = f\"\"\"\n세 개의 백틱으로 구분된 다음 제품 후기 작성자가 표현하고 있는 감정 목록을 식별합니다. \n목록에 5개 이하의 항목을 포함시키십시오. 쉼표로 구분된 소문자 단어 목록으로 답안의 형식을 지정합니다.\n\n\n후기 텍스트: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n만족, 감사, 칭찬, 빠른, 친절\n\n4.2.3 고객 분노\n\n코드prompt = f\"\"\"\n다음 제품 후기 작성자가 분노를 표현하고 있나요?\n후기는 백틱 세 번으로 구분됩니다. \n예 또는 아니오로 답하세요.\n\n\n후기 텍스트: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n아니오.\n\n4.2.4 제품과 회사명 추출\n\n코드prompt = f\"\"\"\n\n후기 텍스트에서 다음 항목을 식별합니다: \n- 리뷰어가 구매한 아이템\n- 해당 아이템을 만든 회사\n\n후기는 백틱 세 개로 구분합니다. \n\"Item\" 및 \"Brand\"를 키로 사용하여 응답 형식을 JSON 객체로 지정합니다. \n정보가 없는 경우 \"알 수 없음\"을 값으로 사용합니다.\n응답은 가능한 한 짧게 작성하세요.\n\n후기 텍스트: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n{\n    \"Item\": \"램프\",\n    \"Brand\": \"Lumina\"\n}\n\n4.2.5 한번에 처리\n\n코드prompt = f\"\"\"\n후기 텍스트에서 다음 항목을 식별합니다: \n- 감정(긍정 또는 부정)\n- 리뷰 작성자가 분노를 표현하고 있나요? (참 또는 거짓)\n- 리뷰어가 구매한 아이템\n- 아이템을 만든 회사\n\n후기는 백틱 세 개로 구분됩니다. \n응답의 형식은 다음을 사용하여 JSON 객체로 지정합니다. \n\"감정\", \"분노\", \"아이템\", \"브랜드\"를 키로 사용하여 JSON 객체로 형식화합니다.\n정보가 없는 경우 값으로 \"알 수 없음\"을 사용합니다.\n응답은 가능한 한 짧게 작성하세요.\n분노 값의 형식을 부울로 지정합니다.\n\n\n후기 텍스트: '''{lamp_review}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n{\n    \"감정\": \"긍정\",\n    \"분노\": false,\n    \"아이템\": \"램프\",\n    \"브랜드\": \"Lumina\"\n}\n\n4.2.6 토픽 추론\n\n코드story = \"\"\"\n최근 정부에서 실시한 설문조사에서 공공 부문 직원들에게 자신이 근무하는 부서에 대한 만족도를 평가해 달라는 요청을 받았습니다. 그 결과 가장 인기 있는 부서는 만족도가 가장 높은 부서로 나타났습니다.\n\nNASA의 한 직원인 존 스미스는 조사 결과에 대해 다음과 같이 말했습니다, \"NASA가 1위에 오른 것이 놀랍지 않습니다. 훌륭한 사람들과 함께 일하기 좋은 곳이며 놀라운 기회를 제공합니다. 이렇게 혁신적인 조직의 일원이 된 것이 자랑스럽습니다.\"\n\n이번 결과는 NASA의 경영진도 환영했습니다, 톰 존슨(Tom Johnson) 국장은 \"우리 직원들이 직원들이 NASA에서의 업무에 만족하고 있다는 소식을 듣게 되어 기쁩니다. 우리에게는 목표를 달성하기 위해 지칠 줄 모르고 일하고 있는 목표를 달성하기 위해 끊임없이 노력하는 재능 있고 헌신적인 팀이 있습니다. 성과를 내고 있습니다.\"\n\n설문조사에 따르면 다음과 같은 사실도 밝혀졌습니다. 사회보장국은 만족도가 가장 낮았습니다. 직원의 45%만이 자신의 업무에 만족한다고 답했습니다. 자신의 직업에 만족한다고 답했습니다. 정부는 다음과 같이 약속했습니다. 설문조사에서 직원들이 제기한 우려 사항을 해결하고 모든 부서의 직무 만족도를 개선하기 위해 노력하겠다고 약속했습니다.\n\"\"\"\n\nprompt = f\"\"\"\n다음 텍스트에서 논의되고 있는 5개의 주제를 결정하십시오. \n세 개의 백틱으로 구분된 다음 텍스트에서 5개의 주제를 정합니다.\n\n각 항목은 최대 두 단어 길이로 작성합니다. \n\n쉼표로 구분된 항목 목록으로 응답 형식을 지정합니다.\n\n텍스트: '''{story}'''\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n1. 공공 부문 직원들의 만족도 조사\n2. NASA 직원들의 만족도\n3. 사회보장국 직원들의 만족도\n4. 정부의 대응 조치\n5. 조직의 성과와 직원 만족도의 관계"
  },
  {
    "objectID": "prompt_for_develoopers.html#변환",
    "href": "prompt_for_develoopers.html#변환",
    "title": "chatGPT",
    "section": "\n4.3 변환",
    "text": "4.3 변환\n거대언어모형(LLM)을 활용한 변환(Transformation)에는 언어 번역, 맞춤법 및 문법 검사, 어조 조정, 형식 변환과 같은 텍스트 변환 작업이 포함된다.\n\n4.3.1 번역\n\n코드prompt = f\"\"\"\n다음 영어 텍스트를 한국어로 번역하세요. \n  \n```Hi, I would like to order a blender```\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n안녕하세요, 블렌더를 주문하고 싶습니다.\n\n4.3.2 언어탐지\n\n코드prompt = f\"\"\"\n어느 언어인지 알려주세요.:\n  \n```こんにちは良い一日です。``` \n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n일본어입니다.\n\n4.3.3 격식 및 비격식 언어\n\n코드prompt = f\"\"\"\n다음 영문 텍스트를 격식 및 비격식 형태 한국어로 번역하세요.: \n'Would you like to order a pillow?'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n격식: 베개를 주문하시겠습니까?\n비격식: 베개 사실래요?\n\n4.3.4 범용 번역기\n대규모 다국적 이커머스 기업에서 IT를 담당하고 있다고 상상해 보세요. 사용자들이 모든 모국어로 IT 문제에 대해 메시지를 보내고 있습니다. 전 세계 각지에서 온 직원들은 각자의 모국어만 구사합니다. 여러분에게는 범용 번역기가 필요합니다!\n\n코드user_messages = [\n  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal         \n  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n  \"Il mio mouse non funziona\",                                 # My mouse is not working\n  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n  \"我的屏幕在闪烁\",                                            # My screen is flashing\n  \"컴퓨터 시작 버튼이 동작하지 않아요\"                         # My computer's start button doesn't work\n] \n\n\nfor issue in user_messages:\n    prompt = f\"어떤 언어인지 말해 주세요: ```{issue}```\"\n    lang = get_completion(prompt)\n    print(f\"원문 메시지 ({lang}): {issue}\")\n\n    prompt = f\"\"\"\n    다음 텍스트를 영어와 한국어로 번역하세요: \n    ```{issue}```\n    \"\"\"\n    response = get_completion(prompt)\n    print(response, \"\\n\")\n\n\n원문 메시지 (프랑스어입니다.): La performance du système est plus lente que d'habitude.\n영어: The system performance is slower than usual.\n한국어: 시스템 성능이 평소보다 느립니다. \n\n원문 메시지 (스페인어입니다.): Mi monitor tiene píxeles que no se iluminan.\nMy monitor has pixels that don't light up. \n내 모니터에는 불이 켜지지 않는 픽셀이 있습니다. \n\n원문 메시지 (이것은 이탈리아어입니다.): Il mio mouse non funziona\n영어: My mouse is not working.\n한국어: 내 마우스가 작동하지 않습니다. \n\n원문 메시지 (이것은 폴란드어입니다.): Mój klawisz Ctrl jest zepsuty\n영어: My Ctrl key is broken\n한국어: 내 Ctrl 키가 고장 났어요 \n\n원문 메시지 (중국어입니다.): 我的屏幕在闪烁\n영어: My screen is flickering.\n한국어: 내 화면이 깜빡입니다. \n\n원문 메시지 (한국어입니다.): 컴퓨터 시작 버튼이 동작하지 않아요\n- English: The computer start button is not working.\n- 한국어: 컴퓨터 시작 버튼이 작동하지 않습니다. \n\n4.3.5 어조 변환\n\n코드prompt = f\"\"\"\nTranslate the following from slang to a business letter: \n'Dude, This is Joe, check out this spec on this standing lamp.'\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nDear Sir/Madam,\n\nI am writing to bring to your attention a standing lamp that I believe may be of interest to you. Please find attached the specifications for your review.\n\nThank you for your time and consideration.\n\nSincerely,\n\nJoe\n\n4.3.6 자료형 변환\n\n코드data_json = { \"resturant employees\" :[ \n    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n]}\n\nprompt = f\"\"\"\nTranslate the following python dictionary from JSON to an HTML \\\ntable with column headers and title: {data_json}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n&lt;table&gt;\n  &lt;caption&gt;Restaurant Employees&lt;/caption&gt;\n  &lt;thead&gt;\n    &lt;tr&gt;\n      &lt;th&gt;Name&lt;/th&gt;\n      &lt;th&gt;Email&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Shyam&lt;/td&gt;\n      &lt;td&gt;shyamjaiswal@gmail.com&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Bob&lt;/td&gt;\n      &lt;td&gt;bob32@gmail.com&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;Jai&lt;/td&gt;\n      &lt;td&gt;jai87@gmail.com&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tbody&gt;\n&lt;/table&gt;\n\n4.3.7 문법/맞춤법 교정\n\n코드texts = [ \n  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n  \"Yolanda has her notebook.\", # ok\n  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms (동음이의어)\n  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms (동음이의어)\n  \"Your going to need you’re notebook.\",  # Homonyms (동음이의어)\n  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms (동음이의어)\n  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling (맞춤법)\n]\n\nfor text in texts:\n    prompt = f\"\"\"다음 텍스트를 교정 및 수정하고 수정된 버전을 다시 작성합니다. \n    오류를 찾지 못하면 \"오류 없음\"이라고 입력합니다. 텍스트 주위에 구두점을 사용하지 마세요:\n    ```{text}```\"\"\"\n    response = get_completion(prompt)\n    print(response)\n\n\nThe girl with the black and white puppies has a ball.\nYolanda has her notebook. (오류 없음)\nIt's going to be a long day. Does the car need its oil changed?\nTheir goes my freedom. They're going to bring their suitcases.\nYou're going to need your notebook.\nThat medicine affects my ability to sleep. Have you heard of the butterfly effect?\nThis phrase is to check ChatGPT for spelling ability.\n\n4.3.8 교정\n\n코드text = f\"\"\"\nGot this for my daughter for her birthday cuz she keeps taking \\\nmine from my room.  Yes, adults also like pandas too.  She takes \\\nit everywhere with her, and it's super soft and cute.  One of the \\\nears is a bit lower than the other, and I don't think that was \\\ndesigned to be asymmetrical. It's a bit small for what I paid for it \\\nthough. I think there might be other options that are bigger for \\\nthe same price.  It arrived a day earlier than expected, so I got \\\nto play with it myself before I gave it to my daughter.\n\"\"\"\nprompt = f\"proofread and correct this review: ```{text}```\"\nresponse = get_completion(prompt)\nprint(response)\n\n\nI got this for my daughter's birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I think there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter."
  },
  {
    "objectID": "aaaa.html",
    "href": "aaaa.html",
    "title": "Untitled",
    "section": "",
    "text": "코드library(reticulate)\n\n\n\n코드from redlines import Redlines\nfrom IPython.display import display, Markdown, Latex, HTML, JSON\n\n\ntext = \"Got this for my daughter for her birthday cuz she keeps taking mine from my room.  Yes, adults also like pandas too.\"\n\nresponse = \"Got the for my daughter for her birthday cuz she keeps taking mine from my room.  Yes, adults also like pandas too.\"\n\ndiff = Redlines(text,response)\ndisplay(Markdown(diff.output_markdown))\n\n&lt;IPython.core.display.Markdown object&gt;"
  },
  {
    "objectID": "prompt_for_develoopers.html#확장",
    "href": "prompt_for_develoopers.html#확장",
    "title": "chatGPT",
    "section": "\n4.4 확장",
    "text": "4.4 확장\n믹서기(Blender) 제품에 대한 고객 후기에 대해 자동 전자우편 회신을 제작해보자.\n\n코드sentiment = \"부정\"\n\nreview = f\"\"\"\n그래서 11월 한 달 동안은 17피스 시스템을 약 절반 할인된 49달러에 시즌 한정으로 판매했지만, 12월 둘째 주에 어떤 이유에서인지(가격 폭리라고 부릅니다) 같은 시스템의 가격이 모두 70달러에서 89달러 사이로 올라갔습니다. 그리고 11피스 시스템도 이전 판매 가격인 29달러에서 10달러 정도 가격이 올랐습니다. 그래서 괜찮아 보이지만 본체를 보면 칼날이 제자리에 고정되는 부분이 몇 년 전의 이전 버전만큼 좋아 보이지는 않는데, 저는 아주 부드럽게 사용할 계획입니다 (예를 들어 콩, 얼음, 쌀 등 아주 단단한 재료를 먼저 분쇄한 다음 분쇄기에 넣고 분쇄합니다). 먼저 블렌더에서 원하는 크기로 분쇄한 다음 휘핑 날로 전환하여 더 고운 가루로 만들고, 스무디를 만들 때는 먼저 십자 칼날을 사용한 다음 더 곱거나 덜 펄프가 필요한 경우 납작 칼날을 사용합니다). 스무디를 만들 때 특별한 팁: 과일과 채소를 잘게 썰어 얼려두면(시금치를 사용할 경우 시금치를 살짝 데친 후 사용할 때까지 얼려두고 셔벗을 만들 경우 중소형 푸드 프로세서를 사용하세요) 스무디를 만들 때 얼음을 너무 많이 넣지 않을 수 있습니다. 약 1년이 지나자 모터에서 이상한 소리가 났어요. 고객 서비스에 전화했지만 이미 보증 기간이 만료되어서 다른 제품을 구입해야 했습니다. 참고: 이러한 유형의 제품에서는 전반적인 품질이 향상되었기 때문에 브랜드 인지도와 소비자 충성도에 의존하여 판매를 유지하고 있습니다. 약 이틀 만에 받았습니다.\n\"\"\"\n\nprompt = f\"\"\"\n당신은 고객 서비스 AI 어시스턴트입니다.\n당신의 임무는 소중한 고객에게 이메일 답장을 보내는 것입니다.\n``` 구분자로 구분된 고객 이메일이 주어집니다, \n\n고객의 리뷰에 대한 감사의 답장을 생성합니다.\n감정이 긍정적이거나 중립적인 경우 고객의 리뷰에 감사를 표시합니다.\n감정이 부정적이면 사과하고 고객 서비스에 문의할 수 있도록 고객 서비스에 문의할 수 있다고 제안합니다. \n\n고객 후기의 구체적인 세부 정보를 사용하세요.\n간결하고 전문적인 어조로 작성하세요.\n이메일에 'AI 고객 상담원'으로 서명합니다.\n\n고객 후기: ```{review}```\n후기 감성: {sentiment}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n\n\n안녕하세요,\n\n저희 제품을 구매해 주셔서 감사합니다. 고객님의 후기를 읽어보니 제품에 대한 실망이 크게 느껴집니다. 이에 대해 진심으로 사과드립니다.\n\n고객님께서 언급하신 문제점은 저희 제품의 품질 향상을 위해 노력하고 있으며, 고객님의 소중한 의견을 반영하여 더 나은 제품을 만들기 위해 노력할 것입니다.\n\n만약 다른 제품을 구입하시려는 경우, 저희 고객 서비스팀에 문의하시면 다양한 제품에 대한 정보와 조언을 제공해 드릴 수 있습니다.\n\n감사합니다.\n\nAI 고객 상담원"
  },
  {
    "objectID": "pandasai.html",
    "href": "pandasai.html",
    "title": "chatGPT",
    "section": "",
    "text": "PandasAI는 널리 사용되는 데이터 분석 및 조작 도구인 Pandas에 생성형 인공지능 기능을 추가한 Python 라이브러리다. 이 라이브러리는 판다스와 함께 사용하도록 설계되었으나 판다스를 대체할 수는 없다. 이유는 판다스 문법에 맞는 파이썬 코드를 작성하는 용도에 적합하기 때문이다.\n\n1 시각화\n\n\n\n\n\n\n\n\n\n\n'Sure, I can help you with that! To create a horizontal bar chart of countries showing their GDP, we can use different colors for each bar. Would you like me to guide you through the process?'\n\n\n원천: PandasAI 쥬피터 노트북\n\n\n\n\n\n\n\n\n'Can you please create a scatter plot showing the relationship between GDP and happiness index, and label each point with the corresponding country name without overlapping?'\n\n\n원천: PandasAI 쥬피터 노트북\n\n\n\n2 코드 설정\n\n\n코드# Instantiate a LLM\nfrom pandasai.llm.openai import OpenAI\nllm = OpenAI(api_token=openai.api_key,\n             model=\"gpt-3.5-turbo\",\n             temperature=0)\n\npandas_ai = PandasAI(llm)\npandas_ai.run(df, prompt='Which are the 5 happiest countries?')\n\n'According to the data, the top 5 happiest countries are the United States, Canada, Australia, United Kingdom, and Germany.'\n\n\n원천: PandasAI 쥬피터 노트북"
  },
  {
    "objectID": "penguins_analytics.html",
    "href": "penguins_analytics.html",
    "title": "chatGPT",
    "section": "",
    "text": "코드library(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n\npenguins &lt;- palmerpenguins::penguins %&gt;% \n  drop_na()\n\n\n\n범주형 변수(species, island, sex) 관계를 살펴보자.\n\nspecies, island 시각화, 표, 검정 통계량을 통해 서로 독립이 아님이 확인된다.\n– Adelie: 아델리 펭귄은 모든 섬에 서식 – Gentoo: 젠투 펭귄은 비스코(Biscoe) 섬에만 서식 – Chinstrap: 턱끈 펭귄은 드림(Dream) 섬에만 서식.\n\n\n\n코드penguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"펭귄종과 서식하는 섬\",\n       x = \"섬\",\n       y = \"펭귄종명\") \n\n\n\n\n\n\n\n코드library(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      Biscoe\n      Dream\n      Torgersen\n    \n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n\n코드library(infer)\n\n\n# 관측통계량\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# 통계검정 시각화\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")  \n\n\n\n\n\n\n코드\n# P값\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 × 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0\n\n\n\n다른 species와 sex, sex와 island 범주 사이는 특별한 관계를 찾을 수 없음.\n\n\n\n코드library(janitor)\nlibrary(gt)\n\npenguins %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"합계\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \n  tab_options(table.font.names = 'NanumGothic',\n                column_labels.font.weight = 'bold',\n                heading.title.font.size = 14,\n                heading.subtitle.font.size = 14,\n                table.font.color = 'steelblue',\n                source_notes.font.size = 10,\n                #source_notes.\n                table.font.size = 14) %&gt;%   \n    gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      female\n      male\n    \n\n\nAdelie\n50.0%  (73)\n50.0%  (73)\n\n\nChinstrap\n50.0%  (34)\n50.0%  (34)\n\n\nGentoo\n48.7%  (58)\n51.3%  (61)\n\n\n합계\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\n코드penguins %&gt;% \n  count(island, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"합계\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \ntab_options(table.font.names = 'NanumGothic',\n              column_labels.font.weight = 'bold',\n              heading.title.font.size = 14,\n              heading.subtitle.font.size = 14,\n              table.font.color = 'darkgreen',\n              source_notes.font.size = 10,\n              #source_notes.\n              table.font.size = 14) %&gt;%   \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nisland\n      female\n      male\n    \n\n\nBiscoe\n49.1%  (80)\n50.9%  (83)\n\n\nDream\n49.6%  (61)\n50.4%  (62)\n\n\nTorgersen\n51.1%  (24)\n48.9%  (23)\n\n\n합계\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\n\n\n\nSimple Correlation Analysis in R using Tidyverse Principles\n\npenguins 데이터프레임에서 연속형 변수만 추출하여 상관관계를 살펴보자.\n\n\n\n코드library(corrplot)\n\npenguins_num &lt;- penguins %&gt;% \n  select(-year) %&gt;% \n  select_if(is.numeric) \n\npenguins_num %&gt;% \n  cor() %&gt;% \n  corrplot(type = \"upper\", order = \"hclust\", \n         tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\n코드library(corrr)\nlibrary(gt)\n\npenguins_num %&gt;% \n  rename_with(.cols = everything(), .fn = ~str_remove(., pattern = \"_mm|_g\")) %&gt;% \n  corrr::correlate( use = \"pairwise.complete.obs\",\n                    method = \"pearson\") %&gt;% \n  rearrange() %&gt;% \n  shave() %&gt;% \n  # fashion() %&gt;% \n  gt::gt() %&gt;% \n  # 상관계수 색상\n  data_color(\n    columns = where(is.numeric),\n    colors = scales::col_numeric(\n      ## option D for Viridis - correlation coloring\n      palette = RColorBrewer::brewer.pal(9, \"RdBu\"), \n      domain = NULL,\n      na.color = 'white')\n  ) %&gt;% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) %&gt;% \n  cols_align(align = \"center\", columns = everything()) %&gt;% \n  gtExtras::gt_theme_538()  \n\n\n\n\n\n\nterm\n      flipper_length\n      body_mass\n      bill_length\n      bill_depth\n    \n\n\nflipper_length\n-\n-\n-\n-\n\n\nbody_mass\n0.8729789\n-\n-\n-\n\n\nbill_length\n0.6530956\n0.5894511\n-\n-\n\n\nbill_depth\n-0.5777917\n-0.4720157\n-0.2286256\n-\n\n\n\n\n\n\n코드corrr::correlate(penguins_num) %&gt;% \n  stretch(remove.dups = TRUE) %&gt;% \n  filter(!is.na(r)) %&gt;% \n  arrange(desc(r)) %&gt;% \n  mutate(음양 = ifelse(r &gt; 0, \"양의 상관\", \"음의 상관\")) %&gt;% \n  mutate(color = \"\") %&gt;% \n  gt(groupname_col = \"음양\") %&gt;% \n  fmt_number(\n    columns = r,\n    decimals = 2,\n    use_seps = FALSE\n  )  %&gt;% \n  data_color(\n    columns = r,\n    target_columns = color,\n    method = \"numeric\",\n    palette = RColorBrewer::brewer.pal(9, \"RdBu\")\n  ) %&gt;% \n  cols_label(\n    x = \"\",\n    y = \"\",\n    r = \"상관계수\",\n    color = \"\"\n  ) |&gt;\n  opt_vertical_padding(scale = 0.7)  %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\n      \n      상관계수\n      \n    \n\n\n양의 상관\n    \n\nflipper_length_mm\nbody_mass_g\n0.87\n\n\n\nbill_length_mm\nflipper_length_mm\n0.65\n\n\n\nbill_length_mm\nbody_mass_g\n0.59\n\n\n\n음의 상관\n    \n\nbill_length_mm\nbill_depth_mm\n−0.23\n\n\n\nbill_depth_mm\nbody_mass_g\n−0.47\n\n\n\nbill_depth_mm\nflipper_length_mm\n−0.58\n\n\n\n\n\n\n\n\n\n\n\n코드library(GGally)\n\npenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggparcoord(columns = 2:5,\n             showPoints = TRUE,\n             groupColumn = \"species\") +\n  scale_color_manual(values = penguins_colors)\n\n\n\n\n\n\n\n\n\n코드penguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggpairs(columns = 2:5, ggplot2::aes(colour=species),\n          upper = list(continuous='density', combo='box_no_facet'),\n          axisLabels='internal') +\n  scale_color_manual(values = penguins_colors) +\n  scale_fill_manual(values = penguins_colors) +\n  theme_minimal()"
  },
  {
    "objectID": "penguins_analytics.html#시각화",
    "href": "penguins_analytics.html#시각화",
    "title": "chatGPT",
    "section": "",
    "text": "코드penguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"펭귄종과 서식하는 섬\",\n       x = \"섬\",\n       y = \"펭귄종명\")"
  },
  {
    "objectID": "penguins_analytics.html#통계량",
    "href": "penguins_analytics.html#통계량",
    "title": "chatGPT",
    "section": "",
    "text": "코드library(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\nBiscoe\nDream\nTorgersen\n\n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n코드\nlibrary(infer)\n\nnull_dist_theory &lt;-penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\")\n\nnull_dist_sim &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 100, type = \"permute\") %&gt;%\n  calculate(stat = \"Chisq\")\n\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n\nnull_dist_sim %&gt;% \n  visualise(method = \"both\") +\n  shade_p_value(observed_indep_statistic,\n                direction = \"both\")\n\n\n\n\n\n\n코드\nnull_dist_sim %&gt;%\n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 × 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0"
  },
  {
    "objectID": "penguins_analytics.html#표",
    "href": "penguins_analytics.html#표",
    "title": "chatGPT",
    "section": "",
    "text": "코드library(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\nBiscoe\nDream\nTorgersen\n\n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0"
  },
  {
    "objectID": "penguins_analytics.html#통계검정",
    "href": "penguins_analytics.html#통계검정",
    "title": "chatGPT",
    "section": "",
    "text": "코드library(infer)\n\n\n# 관측통계량\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# 통계검정 시각화\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")"
  },
  {
    "objectID": "penguins_analytics.html#species-island",
    "href": "penguins_analytics.html#species-island",
    "title": "chatGPT",
    "section": "\n2.1 species, island\n",
    "text": "2.1 species, island\n\nspecies, island 시각화, 표, 검정 통계량을 통해 서로 독립이 아님이 확인된다.\n– Adelie: 아델리 펭귄은 모든 섬에 서식 – Gentoo: 젠투 펭귄은 비스코(Biscoe) 섬에만 서식 – Chinstrap: 턱끈 펭귄은 드림(Dream) 섬에만 서식.\n\n\n시각화\n코드penguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"펭귄종과 서식하는 섬\",\n       x = \"섬\",\n       y = \"펭귄종명\") \n\n\n\n\n\n\n표\n코드library(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      Biscoe\n      Dream\n      Torgersen\n    \n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n통계검정\n코드library(infer)\n\n\n# 관측통계량\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# 통계검정 시각화\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")  \n\n\n\n\n\n\n코드\n# P값\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 × 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0\n\n\n\n다른 species와 sex, sex와 island 범주 사이는 특별한 관계를 찾을 수 없음.\n\n\n\nspecies와 sex\n\n코드library(janitor)\nlibrary(gt)\n\npenguins %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"합계\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \n  tab_options(table.font.names = 'NanumGothic',\n                column_labels.font.weight = 'bold',\n                heading.title.font.size = 14,\n                heading.subtitle.font.size = 14,\n                table.font.color = 'steelblue',\n                source_notes.font.size = 10,\n                #source_notes.\n                table.font.size = 14) %&gt;%   \n    gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      female\n      male\n    \n\n\nAdelie\n50.0%  (73)\n50.0%  (73)\n\n\nChinstrap\n50.0%  (34)\n50.0%  (34)\n\n\nGentoo\n48.7%  (58)\n51.3%  (61)\n\n\n합계\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\nsex와 island\n\n코드penguins %&gt;% \n  count(island, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"합계\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \ntab_options(table.font.names = 'NanumGothic',\n              column_labels.font.weight = 'bold',\n              heading.title.font.size = 14,\n              heading.subtitle.font.size = 14,\n              table.font.color = 'darkgreen',\n              source_notes.font.size = 10,\n              #source_notes.\n              table.font.size = 14) %&gt;%   \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nisland\n      female\n      male\n    \n\n\nBiscoe\n49.1%  (80)\n50.9%  (83)\n\n\nDream\n49.6%  (61)\n50.4%  (62)\n\n\nTorgersen\n51.1%  (24)\n48.9%  (23)\n\n\n합계\n49.5% (165)\n50.5% (168)"
  },
  {
    "objectID": "penguins_analytics.html#범주형-변수",
    "href": "penguins_analytics.html#범주형-변수",
    "title": "chatGPT",
    "section": "",
    "text": "범주형 변수(species, island, sex) 관계를 살펴보자.\n\nspecies, island 시각화, 표, 검정 통계량을 통해 서로 독립이 아님이 확인된다.\n– Adelie: 아델리 펭귄은 모든 섬에 서식 – Gentoo: 젠투 펭귄은 비스코(Biscoe) 섬에만 서식 – Chinstrap: 턱끈 펭귄은 드림(Dream) 섬에만 서식.\n\n\n\n코드penguins_colors &lt;- c('#057076', '#ff8301', '#bf5ccb')\n\npenguins %&gt;% \n  ggplot(aes(x = island, y = species, color = species)) +\n  geom_jitter(size = 3) + \n  scale_color_manual(values = penguins_colors)  +\n  theme_bw(base_family = \"NanumGothic\") +\n  theme(legend.position = \"top\") +\n  labs(title = \"펭귄종과 서식하는 섬\",\n       x = \"섬\",\n       y = \"펭귄종명\") \n\n\n\n\n\n\n\n코드library(gtExtras)\n\npenguins %&gt;% \n  count(species, island) %&gt;% \n  pivot_wider(names_from = island, values_from = n, values_fill = 0) %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      Biscoe\n      Dream\n      Torgersen\n    \n\n\nAdelie\n44\n55\n47\n\n\nChinstrap\n0\n68\n0\n\n\nGentoo\n119\n0\n0\n\n\n\n\n\n\n코드library(infer)\n\n\n# 관측통계량\nobserved_indep_statistic &lt;- penguins %&gt;% \n  specify(species ~ island) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  calculate(stat = \"Chisq\")\n\n# 통계검정 시각화\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")  \n\n\n\n\n\n\n코드\n# P값\npenguins %&gt;% \n  specify(species ~ island) %&gt;%\n  assume(distribution = \"Chisq\") %&gt;% \n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"two-sided\")\n#&gt; # A tibble: 1 × 1\n#&gt;   p_value\n#&gt;     &lt;dbl&gt;\n#&gt; 1       0\n\n\n\n다른 species와 sex, sex와 island 범주 사이는 특별한 관계를 찾을 수 없음.\n\n\n\n코드library(janitor)\nlibrary(gt)\n\npenguins %&gt;% \n  count(species, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"합계\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \n  tab_options(table.font.names = 'NanumGothic',\n                column_labels.font.weight = 'bold',\n                heading.title.font.size = 14,\n                heading.subtitle.font.size = 14,\n                table.font.color = 'steelblue',\n                source_notes.font.size = 10,\n                #source_notes.\n                table.font.size = 14) %&gt;%   \n    gtExtras::gt_theme_538()\n\n\n\n\n\n\nspecies\n      female\n      male\n    \n\n\nAdelie\n50.0%  (73)\n50.0%  (73)\n\n\nChinstrap\n50.0%  (34)\n50.0%  (34)\n\n\nGentoo\n48.7%  (58)\n51.3%  (61)\n\n\n합계\n49.5% (165)\n50.5% (168)\n\n\n\n\n\n\n코드penguins %&gt;% \n  count(island, sex) %&gt;% \n  pivot_wider(names_from = sex, values_from = n, values_fill = 0) %&gt;% \n  adorn_totals(\"row\", name = \"합계\") %&gt;%\n  adorn_percentages(\"row\") %&gt;%\n  adorn_pct_formatting(digits = 1) %&gt;%\n  adorn_ns()  %&gt;% \n  gt::gt() %&gt;% \ntab_options(table.font.names = 'NanumGothic',\n              column_labels.font.weight = 'bold',\n              heading.title.font.size = 14,\n              heading.subtitle.font.size = 14,\n              table.font.color = 'darkgreen',\n              source_notes.font.size = 10,\n              #source_notes.\n              table.font.size = 14) %&gt;%   \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\nisland\n      female\n      male\n    \n\n\nBiscoe\n49.1%  (80)\n50.9%  (83)\n\n\nDream\n49.6%  (61)\n50.4%  (62)\n\n\nTorgersen\n51.1%  (24)\n48.9%  (23)\n\n\n합계\n49.5% (165)\n50.5% (168)"
  },
  {
    "objectID": "penguins_analytics.html#연속형-변수",
    "href": "penguins_analytics.html#연속형-변수",
    "title": "chatGPT",
    "section": "",
    "text": "Simple Correlation Analysis in R using Tidyverse Principles\n\npenguins 데이터프레임에서 연속형 변수만 추출하여 상관관계를 살펴보자.\n\n\n\n코드library(corrplot)\n\npenguins_num &lt;- penguins %&gt;% \n  select(-year) %&gt;% \n  select_if(is.numeric) \n\npenguins_num %&gt;% \n  cor() %&gt;% \n  corrplot(type = \"upper\", order = \"hclust\", \n         tl.col = \"black\", tl.srt = 45)\n\n\n\n\n\n\n\n코드library(corrr)\nlibrary(gt)\n\npenguins_num %&gt;% \n  rename_with(.cols = everything(), .fn = ~str_remove(., pattern = \"_mm|_g\")) %&gt;% \n  corrr::correlate( use = \"pairwise.complete.obs\",\n                    method = \"pearson\") %&gt;% \n  rearrange() %&gt;% \n  shave() %&gt;% \n  # fashion() %&gt;% \n  gt::gt() %&gt;% \n  # 상관계수 색상\n  data_color(\n    columns = where(is.numeric),\n    colors = scales::col_numeric(\n      ## option D for Viridis - correlation coloring\n      palette = RColorBrewer::brewer.pal(9, \"RdBu\"), \n      domain = NULL,\n      na.color = 'white')\n  ) %&gt;% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) %&gt;% \n  cols_align(align = \"center\", columns = everything()) %&gt;% \n  gtExtras::gt_theme_538()  \n\n\n\n\n\n\nterm\n      flipper_length\n      body_mass\n      bill_length\n      bill_depth\n    \n\n\nflipper_length\n-\n-\n-\n-\n\n\nbody_mass\n0.8729789\n-\n-\n-\n\n\nbill_length\n0.6530956\n0.5894511\n-\n-\n\n\nbill_depth\n-0.5777917\n-0.4720157\n-0.2286256\n-\n\n\n\n\n\n\n코드corrr::correlate(penguins_num) %&gt;% \n  stretch(remove.dups = TRUE) %&gt;% \n  filter(!is.na(r)) %&gt;% \n  arrange(desc(r)) %&gt;% \n  mutate(음양 = ifelse(r &gt; 0, \"양의 상관\", \"음의 상관\")) %&gt;% \n  mutate(color = \"\") %&gt;% \n  gt(groupname_col = \"음양\") %&gt;% \n  fmt_number(\n    columns = r,\n    decimals = 2,\n    use_seps = FALSE\n  )  %&gt;% \n  data_color(\n    columns = r,\n    target_columns = color,\n    method = \"numeric\",\n    palette = RColorBrewer::brewer.pal(9, \"RdBu\")\n  ) %&gt;% \n  cols_label(\n    x = \"\",\n    y = \"\",\n    r = \"상관계수\",\n    color = \"\"\n  ) |&gt;\n  opt_vertical_padding(scale = 0.7)  %&gt;% \n  gtExtras::gt_theme_538()\n\n\n\n\n\n\n\n      \n      상관계수\n      \n    \n\n\n양의 상관\n    \n\nflipper_length_mm\nbody_mass_g\n0.87\n\n\n\nbill_length_mm\nflipper_length_mm\n0.65\n\n\n\nbill_length_mm\nbody_mass_g\n0.59\n\n\n\n음의 상관\n    \n\nbill_length_mm\nbill_depth_mm\n−0.23\n\n\n\nbill_depth_mm\nbody_mass_g\n−0.47\n\n\n\nbill_depth_mm\nflipper_length_mm\n−0.58\n\n\n\n\n\n\n\n\n\n\n\n코드library(GGally)\n\npenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggparcoord(columns = 2:5,\n             showPoints = TRUE,\n             groupColumn = \"species\") +\n  scale_color_manual(values = penguins_colors)\n\n\n\n\n\n\n\n\n\n코드penguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggpairs(columns = 2:5, ggplot2::aes(colour=species),\n          upper = list(continuous='density', combo='box_no_facet'),\n          axisLabels='internal') +\n  scale_color_manual(values = penguins_colors) +\n  scale_fill_manual(values = penguins_colors) +\n  theme_minimal()"
  },
  {
    "objectID": "penguins_analytics.html#평행-그래프",
    "href": "penguins_analytics.html#평행-그래프",
    "title": "chatGPT",
    "section": "",
    "text": "코드library(GGally)\n\npenguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggparcoord(columns = 2:5,\n             showPoints = TRUE,\n             groupColumn = \"species\") +\n  scale_color_manual(values = penguins_colors)"
  },
  {
    "objectID": "penguins_analytics.html#짝-산점도",
    "href": "penguins_analytics.html#짝-산점도",
    "title": "chatGPT",
    "section": "",
    "text": "코드penguins %&gt;% \n  select(species, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g) %&gt;% \n  ggpairs(columns = 2:5, ggplot2::aes(colour=species),\n          upper = list(continuous='density', combo='box_no_facet'),\n          axisLabels='internal') +\n  scale_color_manual(values = penguins_colors) +\n  scale_fill_manual(values = penguins_colors) +\n  theme_minimal()"
  },
  {
    "objectID": "penguins_analytics.html#성별-분류모형",
    "href": "penguins_analytics.html#성별-분류모형",
    "title": "chatGPT",
    "section": "\n2.1 성별 분류모형",
    "text": "2.1 성별 분류모형\n펭귄의 암수를 분류하는 기계학습모형을 개발하기 전에 훈련/시험 데이터셋으로 나눈다.\n\n코드library(tidymodels)\n\npenguins_split &lt;- penguins %&gt;% \n  initial_split(prop = 0.70, strata = sex)\n \npenguins_train &lt;- training(penguins_split)\npenguins_test  &lt;- testing(penguins_split)\n\n\n\n2.1.1 로지스틱 회귀\n펭귄의 암수를 분류하는 로지스틱 회귀모형으로 분류모형을 개발해보자.\n\n코드logistic_spec &lt;- logistic_reg() %&gt;% \n  set_engine(\"glm\") %&gt;% \n  set_mode(\"classification\")\n\nlogistic_wflow &lt;- \n  workflow(\n    sex ~ species + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    logistic_spec\n  )\n\nlogistic_fit &lt;- logistic_wflow %&gt;% fit(data = penguins_train)\n\nsex_predict &lt;- predict(logistic_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_predict) %&gt;% \n  ggplot(aes(x = sex, y = .pred_class, color = sex)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n2.1.2 Random Forest\n펭귄의 암수를 분류하는 Random Forest 모형으로 분류모형을 개발해보자.\n\n코드rf_spec &lt;- rand_forest() %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\nrf_wflow &lt;- \n  workflow(\n    sex ~ species + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    rf_spec\n  )\n\nrf_fit &lt;- rf_wflow %&gt;% fit(data = penguins_train)\n\nsex_rf &lt;- predict(rf_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_rf) %&gt;% \n  ggplot(aes(x = sex, y = .pred_class, color = sex)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n2.1.3 SVM\n펭귄의 암수를 분류하는 SVM 모형으로 분류모형을 개발해보자.\n\n코드svm_spec &lt;- svm_rbf() %&gt;% \n  set_engine(\"kernlab\") %&gt;% \n  set_mode(\"classification\")\n\nsvm_wflow &lt;- \n  workflow(\n    sex ~ species + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    svm_spec\n  )\n\nsvm_fit &lt;- svm_wflow %&gt;% fit(data = penguins_train)\n\nsex_svm &lt;- predict(svm_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_svm) %&gt;% \n  ggplot(aes(x = sex, y = .pred_class, color = sex)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_bw()"
  },
  {
    "objectID": "penguins_analytics.html#펭귄종-분류모형",
    "href": "penguins_analytics.html#펭귄종-분류모형",
    "title": "chatGPT",
    "section": "\n2.2 펭귄종 분류모형",
    "text": "2.2 펭귄종 분류모형\n펭귄종(아델리, 젠투, 턱끈)을 분류하는 기계학습모형을 개발하기 전에 훈련/시험 데이터셋으로 나눈다.\n\n2.2.1 다항회귀모형\n펭귄종(아델리, 젠투, 턱끈)을 분류하는 로지스틱 회귀모형으로 분류모형을 개발해보자.\n\n코드multinom_spec &lt;- multinom_reg() %&gt;% \n  set_mode(\"classification\")\n\nmultinom_wflow &lt;- \n  workflow(\n    species ~ sex + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    multinom_spec\n  )\n\nmultinom_fit &lt;- multinom_wflow %&gt;% fit(data = penguins_train)\n\nsex_predict &lt;- predict(multinom_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_predict) %&gt;% \n  ggplot(aes(x = species, y = .pred_class, color = species)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = penguins_colors) +\n  theme_bw()\n\n\n\n\n\n\n\n\n2.2.2 Random Forest\n펭귄종(아델리, 젠투, 턱끈)을 분류하는 Random Forest 모형으로 분류모형을 개발해보자.\n\n코드rf_spec &lt;- rand_forest() %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"classification\")\n\nrf_wflow &lt;- \n  workflow(\n    species ~ sex + island + bill_length_mm + bill_depth_mm + \n          flipper_length_mm + body_mass_g,\n    rf_spec\n  )\n\nrf_fit &lt;- rf_wflow %&gt;% fit(data = penguins_train)\n\nsex_rf &lt;- predict(rf_fit, penguins_test, type = \"class\")\n\nbind_cols(penguins_test, sex_rf) %&gt;% \n  ggplot(aes(x = species, y = .pred_class, color = species)) +\n  geom_jitter(size = 1, width = 0.2, height = 0.2) +\n  scale_color_manual(values = penguins_colors) +\n  theme()"
  },
  {
    "objectID": "penguins_analytics.html#펭귄-크기와-물칼퀴-길이",
    "href": "penguins_analytics.html#펭귄-크기와-물칼퀴-길이",
    "title": "chatGPT",
    "section": "\n3.1 펭귄 크기와 물칼퀴 길이",
    "text": "3.1 펭귄 크기와 물칼퀴 길이\n\n코드extrafont::loadfonts()\nggplot2::theme_set(ggplot2::theme_minimal(base_family = \"MaruBuri\"))\n\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n         body_mass_mean  = mean(body_mass_g)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # 평균 추가\n  geom_point(data = species_mean, aes(x = flipper_mean, y = body_mass_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"남국 파머 연구수 서식 펭귄 크기\",\n       subtitle = \"아델리, 젠투, 턱끈 펭귄 물갈퀴 길이와 체질량\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄종\",\n       shape = \"펭귄종\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#물갈퀴-길이와-부리-길이",
    "href": "penguins_analytics.html#물갈퀴-길이와-부리-길이",
    "title": "chatGPT",
    "section": "\n3.2 물갈퀴 길이와 부리 길이",
    "text": "3.2 물갈퀴 길이와 부리 길이\n\n코드\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n            bill_mean  = mean(bill_length_mm)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = bill_length_mm)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # 평균 추가\n  geom_point(data = species_mean, aes(x = flipper_mean, y = bill_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"물갈퀴 길이와 부리 길이\",\n       subtitle = \"아델리, 젠투, 턱끈 펭귄 물갈퀴 길이와 부리 길이 치수\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"부리 길이 (mm)\",\n       color = \"펭귄종\",\n       shape = \"펭귄종\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#펭귄크기와-물칼퀴",
    "href": "penguins_analytics.html#펭귄크기와-물칼퀴",
    "title": "chatGPT",
    "section": "\n3.1 펭귄크기와 물칼퀴",
    "text": "3.1 펭귄크기와 물칼퀴\n\n코드extrafont::loadfonts()\nggplot2::theme_set(ggplot2::theme_minimal(base_family = \"MaruBuri\"))\n\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n         body_mass_mean  = mean(body_mass_g)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # 평균 추가\n  geom_point(data = species_mean, aes(x = flipper_mean, y = body_mass_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"남국 파머 연구수 서식 펭귄 크기\",\n       subtitle = \"아델리, 젠투, 턱끈 펭귄 물갈퀴 길이와 체질량\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄종\",\n       shape = \"펭귄종\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#물갈퀴와-부리-길이",
    "href": "penguins_analytics.html#물갈퀴와-부리-길이",
    "title": "chatGPT",
    "section": "\n3.2 물갈퀴와 부리 길이",
    "text": "3.2 물갈퀴와 부리 길이\n\n코드\nspecies_mean &lt;- penguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(flipper_mean = mean(flipper_length_mm),\n            bill_mean  = mean(bill_length_mm)) \n\npenguins %&gt;% \n  ggplot(aes(x = flipper_length_mm, y = bill_length_mm)) +\n  geom_point(aes(color = species, shape = species),\n             size = 3, alpha = 0.8) +\n  # 평균 추가\n  geom_point(data = species_mean, aes(x = flipper_mean, y = bill_mean, shape = species),\n             size = 5, color = \"black\", show.legend = FALSE) +  \n  scale_color_manual(values = c(\"darkorange\", \"purple\", \"cyan4\")) +\n  labs(title = \"물갈퀴 길이와 부리 길이\",\n       subtitle = \"아델리, 젠투, 턱끈 펭귄 물갈퀴 길이와 부리 길이 치수\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"부리 길이 (mm)\",\n       color = \"펭귄종\",\n       shape = \"펭귄종\") +\n  theme(legend.position = c(0.9, 0.2),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")"
  },
  {
    "objectID": "penguins_analytics.html#분포와-facet",
    "href": "penguins_analytics.html#분포와-facet",
    "title": "chatGPT",
    "section": "\n3.3 분포와 Facet",
    "text": "3.3 분포와 Facet\n\n\n\n코드ggplot(data = penguins, aes(x = flipper_length_mm)) +\n  geom_histogram(aes(fill = species), \n                 alpha = 0.5, \n                 position = \"identity\") +\n  scale_fill_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(x = \"물갈퀴 길이 (mm)\",\n       y = \"빈도수\",\n       title = \"펭귄 물갈퀴 길이\",\n       fill = \"펭귄종\")\n\n\n\n\n\n\n\n\n코드ggplot(data = penguins, aes(x = species, y = flipper_length_mm)) +\n  geom_boxplot(aes(color = species), width = 0.3, show.legend = FALSE) +\n  geom_jitter(aes(color = species), alpha = 0.5, show.legend = FALSE, \n              position = position_jitter(width = 0.2, seed = 0)) +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(x = \"펭귄종\",\n       y = \"물갈퀴 길이 (mm)\",\n       title = \"펭귄종별 물갈퀴 길이 분포\")\n\n\n\n\n\n\n\n\n코드ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = sex)) +\n  scale_color_manual(values = c(\"darkorange\",\"cyan4\"), na.translate = FALSE) +\n  labs(title = \"펭귄 물갈퀴 길이와 체질량\",\n       subtitle = \"아델리, 젠투, 턱끈 펭귄 물갈퀴 길이와 체질량\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄암수\") +\n  theme(legend.position = \"bottom\",\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\") +\n  facet_wrap(~species)"
  },
  {
    "objectID": "penguins_analytics.html#주성분-분석",
    "href": "penguins_analytics.html#주성분-분석",
    "title": "chatGPT",
    "section": "\n5.1 주성분 분석",
    "text": "5.1 주성분 분석\n주성분 분석(PCA)은 다변량 데이터의 패턴을 탐색하는 데 일반적으로 사용되는 차원 축소 방법이다. (Allison M. Horst, 2022)\n\n코드# Omit year\npenguins_noyr &lt;- penguins %&gt;%\n  select(-year) %&gt;%\n  mutate(species = as.character(species)) %&gt;%\n  mutate(species = case_when(\n    species == \"Adelie\" ~ \"Adélie\",\n    TRUE ~ species\n  )) %&gt;%\n  mutate(species = as.factor(species))\n\npenguin_recipe &lt;-\n  recipe(~., data = penguins_noyr) %&gt;%\n  update_role(species, island, sex, new_role = \"id\") %&gt;%\n  step_naomit(all_predictors()) %&gt;%\n  step_normalize(all_predictors()) %&gt;%\n  step_pca(all_predictors(), id = \"pca\") %&gt;%\n  prep()\n\npenguin_pca &lt;-\n  penguin_recipe %&gt;%\n  tidy(id = \"pca\")\n\npenguin_percvar &lt;- penguin_recipe %&gt;%\n  tidy(id = \"pca\", type = \"variance\") %&gt;%\n  dplyr::filter(terms == \"percent variance\")\n\n# Make the penguins PCA biplot:\n\n# Get pca loadings into wider format\npca_wider &lt;- penguin_pca %&gt;%\n  tidyr::pivot_wider(names_from = component, id_cols = terms)\n\n# define arrow style:\narrow_style &lt;- arrow(length = unit(.05, \"inches\"),\n                     type = \"closed\")\n\npenguins_juiced &lt;- juice(penguin_recipe)\n\n# Make the penguins PCA biplot:\npca_plot &lt;-\n  penguins_juiced %&gt;%\n  ggplot(aes(PC1, PC2)) +\n  coord_cartesian(\n    xlim = c(-3, 4),\n    ylim = c(-2.5, 2))  +\n  paletteer::scale_color_paletteer_d(\"colorblindr::OkabeIto\") +\n  guides(color = guide_legend(\"Species\"),\n        shape = guide_legend(\"Species\")) +\n  theme(legend.position = \"bottom\",\n        panel.border = element_rect(color = \"gray70\", fill = NA))\n\n# For positioning (above):\n# 1: bill_length\n# 2: bill_depth\n# 3: flipper length\n# 4: body mass\n\npenguins_biplot &lt;- pca_plot +\n  geom_segment(data = pca_wider,\n               aes(xend = PC1, yend = PC2),\n               x = 0,\n               y = 0,\n               arrow = arrow_style) +\n  geom_point(aes(color = species, shape = species),\n             alpha = 0.7,\n             size = 2) +\n  shadowtext::geom_shadowtext(data = pca_wider,\n                  aes(x = PC1, y = PC2, label = terms),\n                  nudge_x = c(0.7,0.7,1.7,1.2),\n                  nudge_y = c(-0.1,-0.2,0.1,-0.1),\n                  size = 4,\n                  color = \"black\",\n                  bg.color = \"white\")\n\npenguins_biplot\n\npenguin_screeplot_base &lt;- penguin_percvar %&gt;%\n  ggplot(aes(x = component, y = value)) +\n  scale_x_continuous(limits = c(0, 5), breaks = c(1,2,3,4), expand = c(0,0)) +\n  scale_y_continuous(limits = c(0,100), expand = c(0,0)) +\n  ylab(\"% of total variance\") +\n  theme(panel.border = element_rect(color = \"gray70\", fill = NA),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\npenguin_screeplot &lt;- penguin_screeplot_base +\n  geom_col(fill = \"gray50\") +\n  geom_text(aes(label = round(value,2)), vjust=-0.25)\n\npenguin_screeplot"
  },
  {
    "objectID": "penguins_analytics.html#군집분석",
    "href": "penguins_analytics.html#군집분석",
    "title": "chatGPT",
    "section": "\n5.2 군집분석",
    "text": "5.2 군집분석\nk-평균(K-Means) 비지도학습 군집분석은 기계학습 및 분류에 대한 일반적이고 인기 있는 알고리즘이다.\n\n코드## ---- kmeans ---------------------------------------------------------\n\n# TWO VARIABLE k-means comparison\n# Penguins: Bill length vs. bill depth\npb_species &lt;- penguins %&gt;%\n  select(species, starts_with(\"bill\")) %&gt;%\n  drop_na() %&gt;%\n  mutate(species = as.character(species)) %&gt;%\n  mutate(species = case_when(\n    species == \"Adelie\" ~ \"Adélie\",\n    TRUE ~ species\n  )) %&gt;%\n  mutate(species = as.factor(species))\n\n# Prep penguins for k-means:\npb_nospecies &lt;- pb_species %&gt;%\n  select(-species) %&gt;%\n  recipe() %&gt;%\n  step_normalize(all_numeric()) %&gt;%\n  prep() %&gt;%\n  juice()\n\n# Perform k-means on penguin bill dimensions (k = 3, w/20 centroid starts)\n\n# Save augmented data\nset.seed(100)\npb_clust &lt;-\n  pb_nospecies %&gt;%\n  kmeans(centers = 3, nstart = 20) %&gt;%\n  broom::augment(pb_species)\n\n# Get counts in each cluster by species\npb_clust_n &lt;- pb_clust %&gt;%\n  count(species, .cluster) %&gt;%\n  pivot_wider(names_from = species, values_from = n, names_sort = TRUE) %&gt;%\n  arrange(.cluster) %&gt;%\n  replace_na(list(`Adelie` = 0))\n\n# Plot penguin k-means clusters:\n# make a base plot b/c https://github.com/plotly/plotly.R/issues/1942\npb_kmeans_base &lt;-\n  pb_clust %&gt;%\n  ggplot(aes(x = bill_length_mm, y = bill_depth_mm)) +\n  paletteer::scale_color_paletteer_d(\"colorblindr::OkabeIto\") +\n  paletteer::scale_fill_paletteer_d(\"colorblindr::OkabeIto\") +\n  scale_x_continuous(limits = c(30, 60),\n                     breaks = c(30, 40, 50, 60)) +\n  theme(legend.position = \"bottom\",\n        panel.border = element_rect(fill = NA, color = \"gray70\")) +\n  labs(x = \"Bill length (mm)\",\n       y = \"Bill depth (mm)\",\n       color = \"Species\")\n# ggpubr::stat_chull(aes(fill = .cluster, color = .cluster),\n# alpha = 0.5, geom = \"polygon\", show.legend = FALSE)\n\npb_kmeans_gg &lt;- pb_kmeans_base +\n  geom_text(aes(label = .cluster,\n                color = species),\n            key_glyph = draw_key_rect,\n            check_overlap = TRUE)\n\npb_kmeans_plotly &lt;- pb_kmeans_base +\n  geom_text(aes(label = .cluster,\n                color = species,\n                text = paste(\"Species: \", species,\n                             \"\\nCluster: \", .cluster,\n                             \"\\nBill length (mm): \", bill_length_mm,\n                             \"\\nBill depth (mm): \", bill_depth_mm)\n                ),\n            size = 3)\n\nplotly::ggplotly(pb_kmeans_plotly, height = 300, tooltip = \"text\")"
  },
  {
    "objectID": "llama_penguins.html",
    "href": "llama_penguins.html",
    "title": "chatGPT",
    "section": "",
    "text": "LlamaIndex(GPT 인덱스)는 LLM을 외부 데이터와 연결하기 위한 통합 인터페이스를 제공하는 프로젝트다. 외부 데이터에는 당연히 데이터프레임도 포함된다.\n펭귄 데이터를 판다스 데이터프레임으로 파이썬 환경으로 가져온 후에 LlamaIndex(GPT 인덱스)에 넣어 OpenAI GPT API 인터페이스를 통해 자연어로 다양한 데이터 분석을 수행할 수 있다."
  },
  {
    "objectID": "llama_penguins.html#openai-설정",
    "href": "llama_penguins.html#openai-설정",
    "title": "chatGPT",
    "section": "\n1.1 OpenAI 설정",
    "text": "1.1 OpenAI 설정\n\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')\n\n\n원천: llama-index 쥬피터 노트북"
  },
  {
    "objectID": "llama_penguins.html#데이터셋",
    "href": "llama_penguins.html#데이터셋",
    "title": "chatGPT",
    "section": "\n1.2 데이터셋",
    "text": "1.2 데이터셋\n\n\n코드# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n원천: llama-index 쥬피터 노트북"
  },
  {
    "objectID": "llama_penguins.html#결측값-현황",
    "href": "llama_penguins.html#결측값-현황",
    "title": "chatGPT",
    "section": "\n2.1 결측값 현황",
    "text": "2.1 결측값 현황\nshow_missing() 함수를 사용해서 간략히 전체적인 결측값 현황을 파악할 수 있다.\n\n\n코드def show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n원천: llama-index 쥬피터 노트북"
  },
  {
    "objectID": "llama_penguins.html#결측값-제거",
    "href": "llama_penguins.html#결측값-제거",
    "title": "chatGPT",
    "section": "\n2.2 결측값 제거",
    "text": "2.2 결측값 제거\nllama-index 파이썬 패키지를 설치한 후에 GPTPandasIndex() 함수로 결측값이 담긴 펭귄 데이터프레임을 넣어 자연어 질의문을 던지게 되면 원하는 파이썬 작업결과를 얻을 수 있다.\n# !pip install llama-index\n\n\n코드# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n\n\n원천: llama-index 쥬피터 노트북"
  },
  {
    "objectID": "llama_penguins.html#openai-설정-1",
    "href": "llama_penguins.html#openai-설정-1",
    "title": "사전준비",
    "section": "\n4.1 OpenAI 설정",
    "text": "4.1 OpenAI 설정\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#데이터셋-1",
    "href": "llama_penguins.html#데이터셋-1",
    "title": "사전준비",
    "section": "\n4.2 데이터셋",
    "text": "4.2 데이터셋\n\n코드# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#결측값-1",
    "href": "llama_penguins.html#결측값-1",
    "title": "사전준비",
    "section": "\n4.3 결측값",
    "text": "4.3 결측값\n\n4.3.1 결측값 현황\n\n코드def show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n4.3.2 결측값 제거\n\n코드# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#산점도",
    "href": "llama_penguins.html#산점도",
    "title": "chatGPT",
    "section": "\n6.1 산점도",
    "text": "6.1 산점도\n\n\n코드response = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)\n\n\n\n\n\n\n\n원천: llama-index 쥬피터 노트북"
  },
  {
    "objectID": "llama_penguins.html#히스토그램",
    "href": "llama_penguins.html#히스토그램",
    "title": "사전준비",
    "section": "\n9.2 히스토그램",
    "text": "9.2 히스토그램\n\n코드# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#openai-설정-2",
    "href": "llama_penguins.html#openai-설정-2",
    "title": "사전준비",
    "section": "\n11.1 OpenAI 설정",
    "text": "11.1 OpenAI 설정\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#데이터셋-2",
    "href": "llama_penguins.html#데이터셋-2",
    "title": "사전준비",
    "section": "\n11.2 데이터셋",
    "text": "11.2 데이터셋\n\n코드# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#결측값-2",
    "href": "llama_penguins.html#결측값-2",
    "title": "사전준비",
    "section": "\n11.3 결측값",
    "text": "11.3 결측값\n\n11.3.1 결측값 현황\n\n코드def show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n11.3.2 결측값 제거\n\n코드# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#산점도-1",
    "href": "llama_penguins.html#산점도-1",
    "title": "사전준비",
    "section": "\n16.1 산점도",
    "text": "16.1 산점도\n\n코드response = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#히스토그램-1",
    "href": "llama_penguins.html#히스토그램-1",
    "title": "사전준비",
    "section": "\n16.2 히스토그램",
    "text": "16.2 히스토그램\n\n코드# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#산점도-2",
    "href": "llama_penguins.html#산점도-2",
    "title": "사전준비",
    "section": "\n18.1 산점도",
    "text": "18.1 산점도"
  },
  {
    "objectID": "llama_penguins.html#openai-설정-3",
    "href": "llama_penguins.html#openai-설정-3",
    "title": "사전준비",
    "section": "\n18.2 OpenAI 설정",
    "text": "18.2 OpenAI 설정\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#데이터셋-3",
    "href": "llama_penguins.html#데이터셋-3",
    "title": "사전준비",
    "section": "\n18.3 데이터셋",
    "text": "18.3 데이터셋\n\n코드# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#결측값-3",
    "href": "llama_penguins.html#결측값-3",
    "title": "사전준비",
    "section": "\n18.4 결측값",
    "text": "18.4 결측값\n\n18.4.1 결측값 현황\n\n코드def show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n18.4.2 결측값 제거\n\n코드# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#산점도-3",
    "href": "llama_penguins.html#산점도-3",
    "title": "사전준비",
    "section": "\n23.1 산점도",
    "text": "23.1 산점도\n\n코드response = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#히스토그램-2",
    "href": "llama_penguins.html#히스토그램-2",
    "title": "사전준비",
    "section": "\n23.2 히스토그램",
    "text": "23.2 히스토그램\n\n코드# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#분포도",
    "href": "llama_penguins.html#분포도",
    "title": "chatGPT",
    "section": "\n6.2 분포도",
    "text": "6.2 분포도\n\n\n코드# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\n\n\n\n\n\n\n\n원천: llama-index 쥬피터 노트북"
  },
  {
    "objectID": "llama_penguins.html#openai-설정-4",
    "href": "llama_penguins.html#openai-설정-4",
    "title": "사전준비",
    "section": "\n24.2 OpenAI 설정",
    "text": "24.2 OpenAI 설정\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#데이터셋-4",
    "href": "llama_penguins.html#데이터셋-4",
    "title": "사전준비",
    "section": "\n24.3 데이터셋",
    "text": "24.3 데이터셋\n\n코드# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#결측값-4",
    "href": "llama_penguins.html#결측값-4",
    "title": "사전준비",
    "section": "\n24.4 결측값",
    "text": "24.4 결측값\n\n24.4.1 결측값 현황\n\n코드def show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n24.4.2 결측값 제거\n\n코드# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#산점도-4",
    "href": "llama_penguins.html#산점도-4",
    "title": "사전준비",
    "section": "\n29.1 산점도",
    "text": "29.1 산점도\n\n코드response = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#히스토그램-3",
    "href": "llama_penguins.html#히스토그램-3",
    "title": "사전준비",
    "section": "\n29.2 히스토그램",
    "text": "29.2 히스토그램\n\n코드# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "llama_penguins.html#openai-설정-5",
    "href": "llama_penguins.html#openai-설정-5",
    "title": "사전준비",
    "section": "\n31.1 OpenAI 설정",
    "text": "31.1 OpenAI 설정\n\n코드import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
  },
  {
    "objectID": "llama_penguins.html#데이터셋-5",
    "href": "llama_penguins.html#데이터셋-5",
    "title": "사전준비",
    "section": "\n31.2 데이터셋",
    "text": "31.2 데이터셋\n\n코드# !pip install palmerpenguins\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins_raw = load_penguins()\npenguins_raw.head()\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "llama_penguins.html#결측값-5",
    "href": "llama_penguins.html#결측값-5",
    "title": "사전준비",
    "section": "\n31.3 결측값",
    "text": "31.3 결측값\n\n31.3.1 결측값 현황\n\n코드def show_missing(df):\n    \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n    \n    variables = []\n    dtypes = []\n    count = []\n    unique = []\n    missing = []\n    pc_missing = []\n    \n    for item in df.columns:\n        variables.append(item)\n        dtypes.append(df[item].dtype)\n        count.append(len(df[item]))\n        unique.append(len(df[item].unique()))\n        missing.append(df[item].isna().sum())\n        pc_missing.append(round((df[item].isna().sum() / len(df[item])) * 100, 2))\n\n    output = pd.DataFrame({\n        'variable': variables, \n        'dtype': dtypes,\n        'count': count,\n        'unique': unique,\n        'missing': missing, \n        'pc_missing': pc_missing\n    })    \n        \n    return output\n# penguins.isna().sum()\nshow_missing(penguins_raw)\n\n\n\n\n\n\nvariable\ndtype\ncount\nunique\nmissing\npc_missing\n\n\n\n0\nspecies\nobject\n344\n3\n0\n0.00\n\n\n1\nisland\nobject\n344\n3\n0\n0.00\n\n\n2\nbill_length_mm\nfloat64\n344\n165\n2\n0.58\n\n\n3\nbill_depth_mm\nfloat64\n344\n81\n2\n0.58\n\n\n4\nflipper_length_mm\nfloat64\n344\n56\n2\n0.58\n\n\n5\nbody_mass_g\nfloat64\n344\n95\n2\n0.58\n\n\n6\nsex\nobject\n344\n3\n11\n3.20\n\n\n7\nyear\nint64\n344\n3\n0\n0.00\n\n\n\n\n\n\n\n31.3.2 결측값 제거\n\n코드# !pip install llama-index\n# penguins = penguins_raw.dropna()\n\nimport pandas as pd\nfrom llama_index.indices.struct_store import GPTPandasIndex\n\npenguins_raw_idx = GPTPandasIndex(df=penguins_raw)\nraw_query_engine = penguins_raw_idx.as_query_engine(verbose=True)\nresponse = raw_query_engine.query(\"\"\"remove NaN values from the dataframe\"\"\")\n# response = query_engine.query(\"\"\"What is the pairwise correlation of the float64 datatype columns\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.dropna()\n```\n&gt; Pandas Output:        species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]\n       species     island  bill_length_mm  bill_depth_mm  flipper_length_mm   \n0       Adelie  Torgersen            39.1           18.7              181.0  \\\n1       Adelie  Torgersen            39.5           17.4              186.0   \n2       Adelie  Torgersen            40.3           18.0              195.0   \n4       Adelie  Torgersen            36.7           19.3              193.0   \n5       Adelie  Torgersen            39.3           20.6              190.0   \n..         ...        ...             ...            ...                ...   \n339  Chinstrap      Dream            55.8           19.8              207.0   \n340  Chinstrap      Dream            43.5           18.1              202.0   \n341  Chinstrap      Dream            49.6           18.2              193.0   \n342  Chinstrap      Dream            50.8           19.0              210.0   \n343  Chinstrap      Dream            50.2           18.7              198.0   \n\n     body_mass_g     sex  year  \n0         3750.0    male  2007  \n1         3800.0  female  2007  \n2         3250.0  female  2007  \n4         3450.0  female  2007  \n5         3650.0    male  2007  \n..           ...     ...   ...  \n339       4000.0    male  2009  \n340       3400.0  female  2009  \n341       3775.0    male  2009  \n342       4100.0    male  2009  \n343       3775.0  female  2009  \n\n[333 rows x 8 columns]"
  },
  {
    "objectID": "llama_penguins.html#산점도-5",
    "href": "llama_penguins.html#산점도-5",
    "title": "사전준비",
    "section": "\n36.1 산점도",
    "text": "36.1 산점도\n\n코드response = query_engine.query(\"\"\"visualize two columns; body_mass_g and flipper_length_mm with scatterplot\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.plot.scatter(x='body_mass_g', y='flipper_length_mm')\n```\n&gt; Pandas Output: Axes(0.125,0.11;0.775x0.77)\nAxes(0.125,0.11;0.775x0.77)"
  },
  {
    "objectID": "llama_penguins.html#히스토그램-4",
    "href": "llama_penguins.html#히스토그램-4",
    "title": "사전준비",
    "section": "\n36.2 히스토그램",
    "text": "36.2 히스토그램\n\n코드# import seaborn as sns\nresponse = query_engine.query(\"\"\"draw distribution plot for body_mass_g with transparency by species with legend\"\"\")\n \nprint(response.response)\n\n&gt; Pandas Instructions:\n```\n\ndf.groupby('species')['body_mass_g'].plot.kde(legend=True, alpha=0.5)\n```\n&gt; Pandas Output: species\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object\nspecies\nAdelie       Axes(0.125,0.11;0.775x0.77)\nChinstrap    Axes(0.125,0.11;0.775x0.77)\nGentoo       Axes(0.125,0.11;0.775x0.77)\nName: body_mass_g, dtype: object"
  },
  {
    "objectID": "sql_openai.html",
    "href": "sql_openai.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 관련정보\n(Plaetsen, 2023)\n\n2 데이터베이스\n\nSQLite Sakila Sample Database\npostgreSQL - DVD 대여 데이터베이스\nDVD 대여 데이터베이스에서 인사이트 도출\n\n3 \n프롬프트 참조: TalkToSQL\n\n4 자연어 → SQL\ncode-davinci-002이 사용중단(deprecated)되어 text-davinci-002, text-davinci-003 모델들이 Codex 기반으로 프로그램 작성이 가능하다.\n\n\n\n영어 프롬프트\n\n\n코드prompt = \"Get all the users that are older than 35 years old\"\nmodel = \"text-davinci-002\"\ntemperature = 0.0\nmax_tokens = 50\n\nresponse = openai.Completion.create(\n    engine=model,\n    prompt=prompt,\n    temperature=temperature,\n    max_tokens=max_tokens,\n)\n\nprint(response.choices[0].text)\n\n\n\nSELECT * FROM users WHERE age &gt; 35;\n\n\n원천: llama-index 쥬피터 노트북\n\n\n한글 프롬프트\n\n\n코드prompt = \"users 테이블에서 35세 이상 사용자를 추출하는 SQL 코드를 작성하세요\"\nmodel = \"text-davinci-002\"\ntemperature = 0.5\nmax_tokens = 50\n\nresponse = openai.Completion.create(\n    engine=model,\n    prompt=prompt,\n    temperature=temperature,\n    max_tokens=max_tokens,\n)\n\nprint(response.choices[0].text)\n\n.\n\n```mysql\nSELECT * FROM users WHERE age &gt;= 35;\n```\n\n\n원천: llama-index 쥬피터 노트북\n\n\n\n\n\n\n\n\n\n참고문헌\n\nPlaetsen, M. V. (2023). Using OpenAI with structured data: A beginner’s guide. In Medium. Medium. https://medium.com/@margauxvanderplaetsen/using-openai-with-structured-data-a-beginners-guide-2d12719a72a9"
  },
  {
    "objectID": "sql_openai.html#함수",
    "href": "sql_openai.html#함수",
    "title": "chatGPT",
    "section": "\n1.1 함수",
    "text": "1.1 함수\ngenerate_sql_query() 함수를 작성하여 국,영문 프롬프트를 작성하여 바로 SQL 쿼리를 작성하는 것도 가능하다.\n\n\n코드def generate_sql_query(prompt, max_tokens = 100):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        temperature=0,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].text\n\ngenerate_sql_query(\"Get all the users that are older than 35 years old from users table\")\n\n'\\n\\nSELECT * FROM users WHERE age &gt; 35;'\n\n\n원천: SQL 쥬피터 노트북"
  },
  {
    "objectID": "sql_openai.html#정렬과-중복제거",
    "href": "sql_openai.html#정렬과-중복제거",
    "title": "chatGPT",
    "section": "\n2.1 정렬과 중복제거",
    "text": "2.1 정렬과 중복제거\nSorting and Removing Duplicates에 언급된 “Person 테이블에 있는 과학자의 전체 이름을 성을 기준으로 정렬하여 표시하는 쿼리를 작성합니다.” 라는 퀴즈문제를 풀어보자.\n\n\n\nSWC 코드\n\n코드library(DBI)\nsurvey_db &lt;- dbConnect(RSQLite::SQLite(), \"jupyterlab/survey.db\")\ndbGetQuery(survey_db, \"SELECT personal, family FROM Person ORDER BY family ASC;\")\n#&gt;    personal   family\n#&gt; 1     Frank Danforth\n#&gt; 2   William     Dyer\n#&gt; 3  Anderson     Lake\n#&gt; 4     Frank  Pabodie\n#&gt; 5 Valentina  Roerich\n\n\n\n\n챗GPT 코드\n\n\n코드db_chain.run(\"Write a query that displays the full names of the scientists in the Person table, ordered by family name.\")\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nWrite a query that displays the full names of the scientists in the Person table, ordered by family name.\nSQLQuery: SELECT \"personal\" || ' ' || \"family\" AS \"Full Name\" FROM \"Person\" ORDER BY \"family\" ASC LIMIT 5;\nSQLResult: [('Frank Danforth',), ('William Dyer',), ('Anderson Lake',), ('Frank Pabodie',), ('Valentina Roerich',)]\nAnswer: The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.\n&gt; Finished chain.\n\n\n' The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.'\n\n\n원천: SQL 쥬피터 노트북"
  },
  {
    "objectID": "sql_openai.html#총계",
    "href": "sql_openai.html#총계",
    "title": "chatGPT",
    "section": "\n2.2 총계",
    "text": "2.2 총계\nCalculating New Values에 언급된 “자세히 읽어본 결과, 발렌티나 로리히가 염도를 백분율로 보고하고 있다는 것을 알 수 있습니다. 설문 조사 테이블에서 그녀의 모든 염도 측정값을 100으로 나눈 값을 반환하는 쿼리를 작성합니다.(After further reading, we realize that Valentina Roerich was reporting salinity as percentages. Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.)” 라는 퀴즈문제를 풀어보자.\n\n\n\nSWC 코드\n\n코드dbGetQuery(survey_db, \"SELECT taken, reading / 100 FROM Survey WHERE person = 'roe' AND quant = 'sal';\")\n#&gt;   taken reading / 100\n#&gt; 1   752         0.416\n#&gt; 2   837         0.225\n\n\n\n\n챗GPT 코드\n\n\n코드db_chain.run('After further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.\\\n              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nAfter further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.\nSQLQuery: SELECT person, quant, reading/100 AS reading FROM Survey WHERE person = 'roe' AND quant = 'sal';\nSQLResult: [('roe', 'sal', 0.41600000000000004), ('roe', 'sal', 0.225)]\nAnswer: Valentina Roerich reported salinity measurements of 0.416 and 0.225.\n&gt; Finished chain.\n\n\n' Valentina Roerich reported salinity measurements of 0.416 and 0.225.'\n\n\n원천: SQL 쥬피터 노트북"
  },
  {
    "objectID": "sql_openai.html#챗gpt-모델",
    "href": "sql_openai.html#챗gpt-모델",
    "title": "chatGPT",
    "section": "\n2.3 챗GPT 모델",
    "text": "2.3 챗GPT 모델\n앞선 완성(Completion) 모형 대신 챗GPT 모형을 사용하여 고급 SQL문을 작성할 수 있다. 데이터베이스의 데이터베이스 스키마 정보를 확보하자.\n\n\n코드db_chain.run('print database schema info')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nprint database schema info\nSQLQuery: SELECT * FROM sqlite_master;\nSQLResult: [('table', 'Person', 'Person', 2, 'CREATE TABLE Person (id text, personal text, family text)'), ('table', 'Site', 'Site', 3, 'CREATE TABLE Site (name text, lat real, long real)'), ('table', 'Survey', 'Survey', 5, 'CREATE TABLE Survey (taken integer, person text, quant text, reading real)'), ('table', 'Visited', 'Visited', 4, 'CREATE TABLE Visited (id integer, site text, dated text)')]\nAnswer: The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).\n&gt; Finished chain.\n\n\n' The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).'\n\n\n원천: SQL 쥬피터 노트북\n프롬프트 참조: TalkToSQL\nCombining Data에 나오는 사례를 제대로 SQL 쿼리문을 작성하기 위해서는 system_prompt에 역할 부여는 물론 Few-Shot learning을 위한 사례도 전달하고 user_prompt 프롬프트 작성에 데이터베이스 테이블 정보도 넘겨줘야 원하는 쿼리문을 작성할 가능이 높아진다.\n\n\n코드system_prompt = \"\"\"\n    You are the world's best SQL expert. Help me convert natural language to valid SQL queries. Only respond with valid SQL queries, nothing else.\n    You must learn the column names based on the information the user gives you and build valid SQL queries. Never guess the column names.\n    These are the examples:\n\n    query: get all people names\n    answer: SELECT name from people;\n\n    query: get all cars whose owner name is aaron\n    answer: SELECT c.* FROM people p JOIN cars c ON p.id = c.owner_id WHERE p.name = 'aaron';\n\"\"\"\n\nquery='Write a query that lists all radiation readings from the DR-1 site step-by-step'\n\nuser_prompt = f\"\"\"\n    This is my database information:\n    Person (id text, personal text, family text), \n    Site (name text, lat real, long real), \n    Survey (taken integer, person text, quant text, reading real), \n    Visited (id integer, site text, dated text)\n\n    query: {query}\n    answer:\n\"\"\"\n\n\n\ncompletion = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_prompt},\n    ],\n)\nprint(completion.choices[0].message.content)\n\n\n원천: SQL 쥬피터 노트북\n\n\n\nSWC 코드\n\n코드dbGetQuery(survey_db, \"SELECT\n   Survey.reading\nFROM\n   Site\n   JOIN\n      Visited\n  JOIN\n      Survey\n      ON Site.name = Visited.site\n      AND Visited.id = Survey.taken\nWHERE\n   Site.name = 'DR-1'\n   AND Survey.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25\n\n\n\n\n챗GPT 코드\n\n코드dbGetQuery(survey_db, \"SELECT s.reading\n           FROM Visited v\n           JOIN Survey s ON v.id = s.taken AND v.site = 'DR-1'\n           WHERE s.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25"
  },
  {
    "objectID": "news_release.html#함수",
    "href": "news_release.html#함수",
    "title": "chatGPT",
    "section": "\n1.1 함수",
    "text": "1.1 함수\ngenerate_sql_query() 함수를 작성하여 국,영문 프롬프트를 작성하여 바로 SQL 쿼리를 작성하는 것도 가능하다.\n\n\n코드def generate_sql_query(prompt, max_tokens = 100):\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        temperature=0,\n        max_tokens=max_tokens\n    )\n    return response.choices[0].text\n\ngenerate_sql_query(\"Get all the users that are older than 35 years old from users table\")\n\n'\\n\\nSELECT * FROM users WHERE age &gt; 35;'\n\n\n원천: SQL 쥬피터 노트북"
  },
  {
    "objectID": "news_release.html#정렬과-중복제거",
    "href": "news_release.html#정렬과-중복제거",
    "title": "chatGPT",
    "section": "\n2.1 정렬과 중복제거",
    "text": "2.1 정렬과 중복제거\nSorting and Removing Duplicates에 언급된 “Person 테이블에 있는 과학자의 전체 이름을 성을 기준으로 정렬하여 표시하는 쿼리를 작성합니다.” 라는 퀴즈문제를 풀어보자.\n\n\n\nSWC 코드\n\n코드library(DBI)\nsurvey_db &lt;- dbConnect(RSQLite::SQLite(), \"jupyterlab/survey.db\")\ndbGetQuery(survey_db, \"SELECT personal, family FROM Person ORDER BY family ASC;\")\n#&gt;    personal   family\n#&gt; 1     Frank Danforth\n#&gt; 2   William     Dyer\n#&gt; 3  Anderson     Lake\n#&gt; 4     Frank  Pabodie\n#&gt; 5 Valentina  Roerich\n\n\n\n\n챗GPT 코드\n\n\n코드db_chain.run(\"Write a query that displays the full names of the scientists in the Person table, ordered by family name.\")\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nWrite a query that displays the full names of the scientists in the Person table, ordered by family name.\nSQLQuery: SELECT \"personal\" || ' ' || \"family\" AS \"Full Name\" FROM \"Person\" ORDER BY \"family\" ASC LIMIT 5;\nSQLResult: [('Frank Danforth',), ('William Dyer',), ('Anderson Lake',), ('Frank Pabodie',), ('Valentina Roerich',)]\nAnswer: The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.\n&gt; Finished chain.\n\n\n' The full names of the scientists in the Person table, ordered by family name, are Frank Danforth, William Dyer, Anderson Lake, Frank Pabodie, and Valentina Roerich.'\n\n\n원천: SQL 쥬피터 노트북"
  },
  {
    "objectID": "news_release.html#총계",
    "href": "news_release.html#총계",
    "title": "chatGPT",
    "section": "\n2.2 총계",
    "text": "2.2 총계\nCalculating New Values에 언급된 “자세히 읽어본 결과, 발렌티나 로리히가 염도를 백분율로 보고하고 있다는 것을 알 수 있습니다. 설문 조사 테이블에서 그녀의 모든 염도 측정값을 100으로 나눈 값을 반환하는 쿼리를 작성합니다.(After further reading, we realize that Valentina Roerich was reporting salinity as percentages. Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.)” 라는 퀴즈문제를 풀어보자.\n\n\n\nSWC 코드\n\n코드dbGetQuery(survey_db, \"SELECT taken, reading / 100 FROM Survey WHERE person = 'roe' AND quant = 'sal';\")\n#&gt;   taken reading / 100\n#&gt; 1   752         0.416\n#&gt; 2   837         0.225\n\n\n\n\n챗GPT 코드\n\n\n코드db_chain.run('After further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.\\\n              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nAfter further reading, we realize that Valentina Roerich(roe) was reporting salinity as percentages.              Write a query that returns all of her salinity measurements from the Survey table with the values divided by 100.\nSQLQuery: SELECT person, quant, reading/100 AS reading FROM Survey WHERE person = 'roe' AND quant = 'sal';\nSQLResult: [('roe', 'sal', 0.41600000000000004), ('roe', 'sal', 0.225)]\nAnswer: Valentina Roerich reported salinity measurements of 0.416 and 0.225.\n&gt; Finished chain.\n\n\n' Valentina Roerich reported salinity measurements of 0.416 and 0.225.'\n\n\n원천: SQL 쥬피터 노트북"
  },
  {
    "objectID": "news_release.html#챗gpt-모델",
    "href": "news_release.html#챗gpt-모델",
    "title": "chatGPT",
    "section": "\n2.3 챗GPT 모델",
    "text": "2.3 챗GPT 모델\n앞선 완성(Completion) 모형 대신 챗GPT 모형을 사용하여 고급 SQL문을 작성할 수 있다. 데이터베이스의 데이터베이스 스키마 정보를 확보하자.\n\n\n코드db_chain.run('print database schema info')\n\n\n\n&gt; Entering new SQLDatabaseChain chain...\nprint database schema info\nSQLQuery: SELECT * FROM sqlite_master;\nSQLResult: [('table', 'Person', 'Person', 2, 'CREATE TABLE Person (id text, personal text, family text)'), ('table', 'Site', 'Site', 3, 'CREATE TABLE Site (name text, lat real, long real)'), ('table', 'Survey', 'Survey', 5, 'CREATE TABLE Survey (taken integer, person text, quant text, reading real)'), ('table', 'Visited', 'Visited', 4, 'CREATE TABLE Visited (id integer, site text, dated text)')]\nAnswer: The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).\n&gt; Finished chain.\n\n\n' The database schema info is: Person (id text, personal text, family text), Site (name text, lat real, long real), Survey (taken integer, person text, quant text, reading real), Visited (id integer, site text, dated text).'\n\n\n원천: SQL 쥬피터 노트북\n프롬프트 참조: TalkToSQL\nCombining Data에 나오는 사례를 제대로 SQL 쿼리문을 작성하기 위해서는 system_prompt에 역할 부여는 물론 Few-Shot learning을 위한 사례도 전달하고 user_prompt 프롬프트 작성에 데이터베이스 테이블 정보도 넘겨줘야 원하는 쿼리문을 작성할 가능이 높아진다.\n\n\n코드system_prompt = \"\"\"\n    You are the world's best SQL expert. Help me convert natural language to valid SQL queries. Only respond with valid SQL queries, nothing else.\n    You must learn the column names based on the information the user gives you and build valid SQL queries. Never guess the column names.\n    These are the examples:\n\n    query: get all people names\n    answer: SELECT name from people;\n\n    query: get all cars whose owner name is aaron\n    answer: SELECT c.* FROM people p JOIN cars c ON p.id = c.owner_id WHERE p.name = 'aaron';\n\"\"\"\n\nquery='Write a query that lists all radiation readings from the DR-1 site step-by-step'\n\nuser_prompt = f\"\"\"\n    This is my database information:\n    Person (id text, personal text, family text), \n    Site (name text, lat real, long real), \n    Survey (taken integer, person text, quant text, reading real), \n    Visited (id integer, site text, dated text)\n\n    query: {query}\n    answer:\n\"\"\"\n\n\n\ncompletion = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_prompt},\n    ],\n)\nprint(completion.choices[0].message.content)\n\n\n원천: SQL 쥬피터 노트북\n\n\n\nSWC 코드\n\n코드dbGetQuery(survey_db, \"SELECT\n   Survey.reading\nFROM\n   Site\n   JOIN\n      Visited\n  JOIN\n      Survey\n      ON Site.name = Visited.site\n      AND Visited.id = Survey.taken\nWHERE\n   Site.name = 'DR-1'\n   AND Survey.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25\n\n\n\n\n챗GPT 코드\n\n코드dbGetQuery(survey_db, \"SELECT s.reading\n           FROM Visited v\n           JOIN Survey s ON v.id = s.taken AND v.site = 'DR-1'\n           WHERE s.quant = 'rad';\")\n#&gt;   reading\n#&gt; 1    9.82\n#&gt; 2    7.80\n#&gt; 3   11.25"
  },
  {
    "objectID": "news_release.html",
    "href": "news_release.html",
    "title": "chatGPT",
    "section": "",
    "text": "코드library(srt)\nlibrary(tidyverse)\n\nmisinfo_raw &lt;- read_srt(\"data/LibriSpeech/misinformation.srt\", collapse = \" \")\n\nmisinfo_str &lt;- misinfo_raw %&gt;% \n  filter(n &gt;=20, n&lt;=404) %&gt;% \n  pull(subtitle)\n\nstr_c(misinfo_str, collapse = \" \") %&gt;% \n  write_lines(\"data/LibriSpeech/misinfo_chatGPT.txt\")\n\n\n\n\n\n\nGPT 모델은 텍스트에서 흔히 볼 수 있는 문자 시퀀스인 토큰을 사용하여 텍스트를 처리한다. GPT 모델은 이러한 토큰 간의 통계적 관계를 이해하고 토큰 시퀀스에서 다음 토큰을 생성하는 데 탁월하다.\nTokenizer\n요약은 많은 LLM 작업의 기본 구성 요소로 많은 양의 텍스트를 간결한 요점으로 압축해야 하는 사용 사례가 많다.따라서, 요약하려는 텍스트의 길이에 따라 다양한 요약 방법을 선택해야한다."
  },
  {
    "objectID": "news_release.html#srt-.txt",
    "href": "news_release.html#srt-.txt",
    "title": "chatGPT",
    "section": "\n2.1 .srt → .txt\n",
    "text": "2.1 .srt → .txt\n\n자막파일(.srt)에서 시간 정보를 제거하고 텍스트만 전환하는 작업을 다음 코드를 사용하여 진행한다.\n\n코드library(srt)\nlibrary(tidyverse)\n\nmisinfo_raw &lt;- read_srt(\"data/LibriSpeech/misinformation.srt\", collapse = \" \")\n\nmisinfo_str &lt;- misinfo_raw %&gt;% \n  filter(n &gt;=20, n&lt;=404) %&gt;% \n  pull(subtitle)\n\nstr_c(misinfo_str, collapse = \" \") %&gt;%\n  write_lines(\"data/LibriSpeech/misinfo_chatGPT.txt\")"
  },
  {
    "objectID": "news_release.html#r-코드",
    "href": "news_release.html#r-코드",
    "title": "chatGPT",
    "section": "\n2.2 R 코드",
    "text": "2.2 R 코드\n텍스트 길이와 별개로 단어갯수(word)를 파악하는 것이 전체적인 API 비용 및 후속 텍스트 분석 방향을 잡을 때 중요하다. 이를 위해서 stringr 패키지 str_sub() 함수와 정규표현식(\\\\w+)을 결합하여 사용하거나 텍스트 마이닝 특화된 qdap 패키지 wc() 함수를 사용해서 계산한다.\n\n코드library(tidyverse)\n\nmisinfo_txt &lt;- read_lines(\"data/LibriSpeech/misinfo_chatGPT.txt\")\n\nmisinfo_wc &lt;- str_count(misinfo_txt, '\\\\w+')\n\nglue::glue(\"텍스트 일부: {str_sub(misinfo_txt, 1, 100)} \n           단어갯수: {misinfo_wc}\n           단어갯수(qdap): {qdap::wc(misinfo_txt)}\")\n#&gt; 텍스트 일부: Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I  \n#&gt; 단어갯수: 6900\n#&gt; 단어갯수(qdap): 6615\n\n\nOpenAI Tokenizer"
  },
  {
    "objectID": "news_release.html#tokenizer",
    "href": "news_release.html#tokenizer",
    "title": "chatGPT",
    "section": "\n2.3 Tokenizer\n",
    "text": "2.3 Tokenizer\n\n챗GPT LLM은 토큰을 기본 단위로 사용하고 과금단위이기도 하기 때문에 OpenAI 에서 제공하는 Tokenizer에서 복사하여 붙여넣게 되면 발표음성을 텍스트 파일에 저장시킨 사항을 바로 확인할 수 있다. 다른 방식은 langchain get_num_tokens() 메쏘드를 사용해서 API를 통해 확인하는 방식이다.\n\n\n웹 UI\n\n\n\n\n\n\nAPI 프로그래밍\n\n\n코드from langchain import OpenAI\nllm = OpenAI(temperature=0, openai_api_key=os.getenv('ENV_OPENAI_API_KEY'))\n\nprompt_lvl_01 = \"\"\"\nPlease provide a summary of the following text.\nPlease provide your output in a manner that a 5 year old would understand\n\nTEXT:\nWell, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean.\\\nI wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington,\\\nand that was a real pleasure. So thank you so much.\\ \nSo today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world.\\ \nBut mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds.\n\"\"\"\n\nnum_tokens_lvl_01 = llm.get_num_tokens(prompt_lvl_01)\nprint (f\"Level 1 Prompt has {num_tokens_lvl_01} tokens\")\n\nLevel 1 Prompt has 172 tokens\n\n\n원천: 오정보 쥬피터 노트북"
  },
  {
    "objectID": "news_release.html#몇-문장-요약",
    "href": "news_release.html#몇-문장-요약",
    "title": "chatGPT",
    "section": "\n3.1 몇 문장 요약",
    "text": "3.1 몇 문장 요약\n요약형태도 지정하여 누구나 이해하기 쉬운 형태로 몇 문장 텍스트를 요약하도록 프롬프트를 작성하여 국문, 영문 작업을 수행한다.\n\n\n\n국문요약\n\n\n코드from langchain import OpenAI\nllm = OpenAI(temperature=0, openai_api_key=os.getenv('ENV_OPENAI_API_KEY'))\n\nprompt_lvl_01_ko = \"\"\"\n다음 텍스트를 요약해주세요.\n초등학생이 이해할 수 있게 요약을 쉽게 해주세요.\n\nTEXT:\nWell, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean.\\\nI wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington,\\\nand that was a real pleasure. So thank you so much.\\ \nSo today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world.\\ \nBut mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds.\n\"\"\"\n\noutput_lvl_01_ko = llm(prompt_lvl_01_ko)\nprint (output_lvl_01_ko)\n\n\nDr. Ahn과 함께 오션에서 만난 여러 학생들과의 만남을 기쁘게 생각하며, 인공지능과 챗봇의 기쁨과 관련해 미디어 정보의 문제를 이야기하고 있다.\n\n\n원천: 오정보 쥬피터 노트북\n\n\n영문요약\n\n\n코드prompt_lvl_01 = \"\"\"\nPlease provide a summary of the following text.\nPlease provide your output in a manner that a 5 year old would understand\n\nTEXT:\nWell, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean.\\\nI wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington,\\\nand that was a real pleasure. So thank you so much.\\ \nSo today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world.\\ \nBut mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds.\n\"\"\"\n\noutput_lvl_01 = llm(prompt_lvl_01)\nprint (output_lvl_01)\n\n\nDr. Ahn and someone from Seattle had a nice chat across the ocean. They talked about how AI and chatbots are exciting, but also how they can cause problems with misinformation.\n\n\n원천: 오정보 쥬피터 노트북"
  },
  {
    "objectID": "news_release.html#전체-요약",
    "href": "news_release.html#전체-요약",
    "title": "chatGPT",
    "section": "\n3.2 전체 요약",
    "text": "3.2 전체 요약\n요약 대상이 되는 텍스트와 요약 프롬프트를 한번에 넣어 작업하는 대신 텍스트 토큰 크기를 산정한 후에 적절한 크기로 나눈 다음 각각 텍스트 조각에 대해 요약작업을 수행하고 나서 이를 다시 요약하는 맵리듀스(Map Reduce) 방식으로 요약 작업을 마무리한다.\n\n3.2.1 토큰 크기\n발표 텍스트 토큰 크기를 계산하여 적절한 토큰 분리 크기를 산정한다.\n\n\n코드import openai\nimport os\nfrom langchain import OpenAI\n\nllm = OpenAI(temperature=0, openai_api_key=os.getenv('ENV_OPENAI_API_KEY'))\n\nfrom langchain import OpenAI\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nmisinfo_lecture = '../data/LibriSpeech/misinfo_chatGPT.txt'\n\nwith open(misinfo_lecture, 'r') as file:\n    misinfo = file.read()\n\nllm.get_num_tokens(misinfo)      \n\n7848\n\n\n원천: 오정보 쥬피터 노트북\n\n3.2.2 요약결과\nload_summarize_chain() 으로 전체 발표 텍스트를 요약한다.\n\n\n코드summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',\n                                      verbose=True # Set verbose=True if you want to see the prompts being used\n                                    )\noutput = summary_chain.run(docs)\noutput\n\n\n\n&gt; Entering new MapReduceDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington, and that was a real pleasure. So thank you so much. So today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world. But mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds. So I'm going to share my screen here. There we go. Just here, share, and there we go. All right, can you see that, Dr. An? Yes. Okay, great. Okay, so as Dr. An said, I study misinformation and disinformation in all sorts of forms where I study misinformation. The most is at the interface of science and society, but we also study it more generally in our center where we look at it from the political angle, from the angle of science, from the angle of health. We've studied misinformation during the pandemic and during elections and all sorts of other topics. But today I'm going to focus on some of my concerns around generative AI, and hopefully that will generate some questions and comments when it comes to this particular topic. I'm sure a lot of us are thinking about it. So one of the things that I tend to ask myself when new technologies come onto the world scene is whether we're better or worse off. I recently wrote an op-ed, an opinion piece for the Seattle Times, which is our paper here in Seattle in the United States. And I talked about some of the concerns I had. And so some of the things I'm going to talk about in this talk come from that op-ed, but I'm going to talk about a lot of other things I didn't have room to talk about in that particular op-ed. But I really want us as a group to think a lot about this. Are we better or worse off with this new chatbot ability? And of course it's a mixed bag. There are things that might be better, and there are things that are going to be worse. I'm going to kind of focus on the more pessimistic version of this. About a week ago, there was a lot of attention around a new music song that was posted on several music services that sounded like a mix between the famous musician Drake and the weekend. These are two musical artists that are known worldwide for their music. And there was a song that was created that was quite catchy. And believe it or not, it was kind of good, I have to admit. And it was probably viewed by millions and millions of people. I don't know the exact stats on that. I should look that up. But the point is this song was created with some of this new generative AI technology. And this is an example where there might be some positive elements of this technology that allows for this mixing and this creation. It created a song that caught enough people's attention that it caught so much attention. It actually had to be taken down because of issues likely around copyright. And there's all sorts of fallout from this. And there's lots of discussions in the legal world that are continuing. And it's only been about a week since this song was released. But this is an example of the excitement that surrounds this technology. And for good reason, if it can create a song that's a good mix of Drake and the weekend and it sounds reasonably good, that's some evidence at least of the power of this new technology. And it's not like this is brand new technology. There is this kind of technology from the natural language processing world and machine learning more generally has been around. But there's been some advancements recently that make the generative aspect quite exciting, but also a little scary. So I'm going to talk about today some of the the cautions that I have. There's a lot more cautions. But these are the things I'm going to focus on. And it's a lot to focus on in about 25 minutes. So I'm going to hit these briefly. And then if there are questions, we can always go back to some of these topics in more detail. But I'm going to go through talking about how at least from my perspective, as someone who studies misinformation, and as someone who studies misinformation specifically in science, these are some of my big concerns. One of them is that these really are bullshatters at scale. They get a lot right, but they also get some things wrong. Concerns around how this might affect democratic discourse online and offline. Concerns about content credit for all those content creators out there, the musicians like Drake and the weekend, and the writers and the journalists and the researchers and the authors and the poets, etc. What happens to their content when it gets pushed down after these generative AI, these chatbots and these large language models train on this content and then provide some reason new content on top of it. Who owns the content? How's that going to work as we move forward? I'll talk a little bit about some of the job elimination issues, both course in science, but in other areas, it'll be that, well, some of these are focused outside of the issue of science. And then of course, I'm going to talk about some of the issues of pseudoscience proliferation, the overconfidence of AI and the need for some of these qualifiers of confidence, the issues around reverse engineering, the generative cost, the actual cost, both monetarily, environmentally, but also the costs in other forms and creativity and other things. And then I'll talk, I'll end with just really emphasizing this issue about garbage in garbage out. Okay, so we now live in this world where it seems we've got almost sentient beings. I know there's lots of philosophical debates whether they're sentient. I don't think they are. And we certainly haven't reached AGI levels. And there's all sorts of great, you know, critiques of this particular technology. But one thing that at least I think we're all pretty sure of, it's kind of here to stay in some form or another. Even in my world in education as a professor who runs a research lab and also as a professor who teaches students, college students, I'm seeing the technology everywhere. And when I was teaching my class last quarter, I decided to just embrace the technology and allow the students to use it in any form that they see as long as they let me know that they were using it. That's my only criteria because I want to learn how this technology can be used by students and by teachers like myself and professors like myself. But I also want to figure out where it goes wrong. And so I learned a lot from my students and I will continue to have that kind of policy. But maybe that'll change at some point. I know that some instructors don't allow it. I know that some scientific publishers are not allowing co-authorship or the use of AI in any form. Even countries like Italy have outlawed some forms of this technology. And so there's going to be some that are going to eliminate it, some that are going to embrace it. And the way I look at it is that it may just force me to write different kinds of questions and do different kinds of assessment. But it might also be a tool that could help students learn to write when they're stuck and learn how to correct as long as they're willing to do some editing and self-correct and correction of the content that comes from these different bots. And so the technology really is here to stay. And one thing I should say is what's interesting is that we have a technology that really seems to have passed the Turing test. And one thing that's a bit a little surprising to me is that we haven't had a big celebration about this. Even though I'm a bit of a critic of this technology and I focus a lot of my attention on some of the concerning areas of Generative AI, since I studied misinformation, disinformation. I should say though, on the other hand, we should be thinking about some of the things that have occurred. And for those not familiar with the Turing test, it's this pretty simple idea that the Turing test will have passed when an individual can't tell the difference. But when content, at least in this case written content created by a human and one by a computer. And if that's the case, and I do think in many respects, we probably have passed this Turing test. And there's been no celebrations. So I guess, okay, for those that are optimistic about this technology and more positive about this technology, this would be something to celebrate. Absolutely. No doubt. And in terms of education, as I mentioned before, this is really transforming education, but it's transforming all sorts of other industries in ways that have captured the world's attention. I mean, this technology has been adopted now faster than pretty much any other technology has been adopted with hundreds, like 100 million users within a very short amount of time. And of course, that's only growing and billions and billions of dollars being invested into this technology from big corporations to venture capitalists. There is a lot going into this technology. And again, there's good reason for that. And a lot of times my students will say, well, it's just like a calculator. Why would you ever want to take it away? And I'm not taking it. I'm lo and use it. But I will say, it's a little different than a calculator, because this is a technology that gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can be highly problematic. If you're just creating a poem, then fine. It doesn't really matter. But this analogy to the calculator goes a little, it's there's reason to think that's a somewhat reasonable analogy, but it is different. I wouldn't use a calculator that got the answers wrong 10% of the time. That would be, I would probably be looking for other technologies. Or if I was using that calculator, it would make it for a lot harder work. And that's what we have to recognize. It's yes, we have this technology that can do a lot of this new amazing things to make some of our jobs easier. But it's going to take a lot of hard work on the editorial side to make sure that we're paying attention to some of those errors. And there's all sorts of application. This was an article just recently written by Wired sort of examining the ways in which the medical field is starting to think about the adoption of this. In fact, some medical researchers have gone so far as to say that all doctors will be using this technology at some point. And maybe that's true. And there are reasons to think that's a possibility with its ability to mine the scientific literature, to integrate all sorts of different symptoms, and could be that assistant in the doctor's room. However, there are reasons to also be worried about these technologies and in places like the medical field. It might help the doctors as this article talks about, but it also might not benefit so greatly many of those patients, especially because we have many, many examples of the ways in which these machines get things wrong and have biases built in because the data that it's trained on has some of these biases. And at this point, a lot of these technologies are essentially just patching and putting band aids on these problems that exist. And part of it's just because these things are very difficult to reverse engineer, which I'll talk about a little bit later. Now, there's plenty of other reasons to be excited to actually one of my colleagues who I just saw at a conference last week, Daniel Katz and his colleague Michael Bomerito showed how this technology took the bar exam. This is the main legal, the exam in the United States for allowing you to become a lawyer or sort of allowing you to sort of move forward as a certified lawyer. And they were able to show that chat GPT did already darn well in past the bar exam. And there's examples of the MCAT and, you know, some of these other standardized tests that are that have been tested with this technology. In fact, in many ways, these have almost become a baseline test when comparing different large language models. And so it is pretty amazing. So again, amazed in many ways, but I'm going to talk the rest of the time about some of the concerns that I have. And by the way, as was mentioned, I have this book where I talk about bullshit. And bullshit is a part of the misinformation story. And as Dr. An had mentioned, it's also been translated in Korean, which has been super fun to see it pulled or written in these other languages. And it helps me try to figure out what's being said here. But in that book, if you read it, one of the more important laws and principles that we talk about is something called \"Randalini's Bullshit, a Symmetry Principle.\" And if you go to Wikipedia, at least the English version, I actually should check the Korean version, see if it's there. But the English version of the Wikipedia has this principle in the Wikipedia. And this law is pretty simple. It basically says that the amount of energy needed to refute bullshit is an order of magnitude bigger than needed to produce it. So the amount of energy needed to refute it to clean it up, to fix the problem, is an order of magnitude much harder to produce it. So here's the law. So my colleague Carl Bergstrom decided to ask the large language model that Metacreat a while ago called Galactica. And this has been taken down since then, but this was the science version, essentially, of one of these large language models. And he decided to ask Galactica, \"Tell me about Randalini's Bullshit, a Symmetry Principle. And you know what it came up with?\" And this is the real answer. Here's what it came up. Randalini's law is a theory in economics proposed by G. Anani Brannalini, a professor at the University of Pateau, which dates the smaller the economic unit, the greater its efficiency. Almost nothing here is correct. It's basically bullshitting the bullshit principle. So to me, this encapsulates one of the biggest problems with this technology. It bullshits, and it can do this at scale. And this could be put in the wrong hands. And this can also just add more noise to an information environment that has plenty of noise. We needed to clean up that polluted information environment, not add noise. And that's what a lot of these chatbots will do, definitely, because they make, they put a lot of accurate things out there, but they also put a lot of false things. And this is the best encapsulation that I've seen so far, which is actually bullshitting the bullshit principle. So that's a problem. So as I mentioned in this op-ed, I talk about some of these things. And one of the things I talk about as well is that not only do these things, can these bullshit at scale, they also can get in the way of democratic discourse. And many years ago, back in 2018, there was a lot of attention around Facebook's role in pushing misinformation. Excuse me. And they revealed at the time when Mark Zuckerberg was being questioned by Congress about all the fake accounts. And they admitted they had disabled 1.3 billion fake accounts. Now, they certainly haven't solved that problem, just like no social media platform has solved that. In fact, when Elon Musk was taking over Twitter, that was one of the big issues at hand, that there was all sorts of concerns if there was lots and lots of bots on Twitter. Now, that's still a problem. I can guarantee you, you know, my group has done a little bit of work working in detecting and looking at the effects of bots. But my colleagues in my research area have done a lot of work on that space, and it's very, very hard to do. But one thing is that, you know, we do know is that there are a lot of bots out there and a lot of fake accounts. Now, imagine those fake accounts with the ability that these chat bots now have to look even more human technology that's basically, well, has passed the Turing test. That to me is problematic because of these different reasons. So you have these large number of fake accounts. Now imagine these fake accounts being scaled to conversations with our public officials. Now, democracies depend on an engagement with the public, with their officials that they voted in. Well, that becomes a problem like it was back in 2017, when there was discussions, at least in the United States around something called net neutrality. And net neutrality was a policy that was being debated in governmental circles, and they wanted to know what the public was saying. But when you went to what the public was saying, they had complete the, there were comments that had completely flooded the conversation on one side of the issue, and it turns out that they were essentially fake accounts. They were bots. And again, now imagine doing that with the sophistication that these new chat bots have before you could, there was a, you could start, you could detect a bot much easier. Now it's become even harder. And if our democratic systems are flooded with these kinds of things, this is, this is problematic. So this issue, in its potential impact on democratic discourse, and its ability to bullshit at scale is of major concern to me. So I spent a lot of my time, like my colleagues in our center, in sort of the darker core of the internet, studying the ways in which misinformation and disinformation spreads online. And one thing that we are, of course, very concerned about now are the ways in which these technologies can really further inflame or further fan the flames of discourse in groups, if these get in the wrong hands. And they certainly will. It's almost certain that bad actors are finding ways to use this technology for their own ends. And we know that, you know, our surgeon general and other major leaders around the world have recognized the ways in which misinformation can affect our health, and they can affect the health of democracies. So it's not just that, oh, well, it's annoying, there's a lot of false information online. It just makes it hard to find, you know, good information. It's not just that it actually affects people's health. And we're recognizing that. And at least, well, we've recognized it. And now we've got another problem ahead of us, which is the ability of these technologies to create deep fake images, video, audio, text. That's the challenge that we have ahead of us. So as Dr. On mentioned, we have a center at the University of Washington in Seattle in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of the things that my colleague Carl Wurxman, I created several years ago to bring public attention to synthetic media to deep fakes, was to create a game that we called which faces real calm. And it was a simple game. We just asked the users which image is real. One of them is a real image of a real person on this earth. And another one was synthetically created with computers. And you can go through that, you know, thousands and thousands and thousands of images and we play this game and then you get told whether it's real or not. And it turns out it's pretty hard. I mean, you know, there's some that are kind of obvious, but they're hard like this one right here, which one's real. Look at it for a second. Well, the one that's real is the one with the blue shirt, at least on my right. And if you said the one on the red shirt, totally understand it's really hard to tell the difference. And the reason why we created this game was just to bring public attention because the time in a technology's birth that's I think most scary when it comes to its potential impact is when the public is not aware of the things that it can do. So we created this game and we've had millions and millions of plays of this game. And we've now seen actually this technology, you know, get used and you know, of course, good ways, but a lot of bad ways too. For example, we've seen this technology be used to create fake journalists. This is an example and you can read more about it, but this has happened many times where journalists, or so-called journalists, you know, profiles created and then there's these images and people that study deep fake imagery can actually look at these images and start to see what some of look for some of these telltale signs on what's real or not. So these, this technology's been been already used. And we talked about this when this game was created, the ways in which it's been used. And we've already seen it, of course, many ways. So now we're asking how are the ways in which this new generative technology could be used. But it's very similar. It's based on similar kinds of concepts and data training, etc, etc. But we're now asking the same things. And of course, we've seen this now just recently with this kind of technology being used in videos and even in ways that are more sophisticated than just these sort of portrait pictures. So this was an image. It's a fake image and it's been reported all over BBC and lots of other places of Donald Trump supposedly being arrested in New York. This was before he was actually brought to New York on the recent case. But this, of course, never happened, but it certainly sparked all sorts of concern and it spread like wildfire on the internet using some of this, you know, mid-journey technology in our company called Mid-Journey and a lot of other companies that are creating this. So it's making it easier and easier and less expensive and making it harder for us to tell what's real. And so that technology has of course evolved. So, okay, so now I've talked about some of the democratic discourse. I'm going to go through a little quicker on these other ones so then I can get to sort of the end and try to finish in about, I would say about seven minutes or so. So like I mentioned at the beginning, there's this issue of content creation and that's really important because these content creators are generating a lot of the content that a lot of these technology companies are using to create these chatbots. But we've seen this story before and by the way, just recently, there are major technology companies that are now not allowing the scraping of this data to be trained for these technologies unless they're compensating. I think that's a fair thing. So, you know, some of these big companies like Reddit is not allowing stack overflow is now saying, \"Hey, if you're going to scrape our data, they want to be compensated.\" And so you're going to start to see content creators starting to push back, which is good because like I said, we've seen this story before. Oh, and by the way, this is an example of, you know, Getty Images is in a lawsuit right now with a company that may have been scraping their data illegally. And the reason why that came out is because you can see this little Getty Images that pops up, which is a watermark that Getty Images puts on their images. So there's an appending lawsuit about this and that could determine some of the some of how this content can or can't be scraped. But we've seen this before when looking at new technology and the impact it can have on other information producers in the United States and in many places around the world, we have growing news deserts. These are areas where there's no more local news. And that's pretty devastating for democratic discourse or democracies because we depend on local news for engagement, civic engagement and quality information and local news tends to be trusted more than national news. And there's all sorts of reasons for that happening. But certainly one element of that is the effect that search engines and Google in particular around it, you know, the way it sells ads and it takes a large cut at those ads has potentially contributed to these news deserts. Of course, there's lots of other things as well. But that technology everyone was excited about, including myself and we use it all the time. But there are these unintended effects that can affect other aspects of our information ecosystems. And right now, there's a lawsuit going on. The Justice Department, United States Justice Department is suing Google for monopolizing digital advertising technologies. And one of those elements of this lawsuit story is the sort of increase in the demise of local news. So there's all sorts of interesting things playing out right now. And then the Biden administration, United States is thinking about doing some regulation of AI, but they don't know, it's so new to all administrations that it's hard to figure out. Like I mentioned, Italy has gone probably one of the furthest steps I think around this. But there hasn't been a lot of action, at least on the US side when it comes to this sort of thing. And so, there's been letters. So this was an article written by Time. The image quite nice. It actually grows. There was a letter that went around from a bunch of influential people in AI and business leaders and technology, including Elon Musk that says, hey, we should stop the development until we've had more time to think about it. Although it's kind of ironic, given that many of these tech leaders are still, of course, pushing their own development of AI in many ways and creating new AI companies and developing. But anyway, that's another story. But that is something to think about. I don't think it's a, I think there's no way that that letter is going to stop the technology from being developed. But one thing it is good about is it's makes hopefully forcing the public and journalists and government officials, etc. to start to think about the ways in which this technology could affect society. We should think about it. As I mentioned, one of the concerns is job demise. And I think there's a lot of concern with that by those that even work in the job industry, the Pew Research Center recently asked workers where are they concerned? Turns out a large number of workers from across these different industries are concerned. And there's probably good reason for this concern. Even Sam Altman at OpenAI, which is sort of, or is the owner of the chat GPT, which is the one of the more well-known chatbots out there. And it's also the one that Microsoft has invested billions. This is something that they've even said probably lose 5 million jobs. So these are real concerns. So the other thing to mention too is that it's not just within science itself, these are real concerns. And we've seen the proliferation of pseudoscience and the rise of predatory journals and content that maybe looks like science. But it's not. And I'll show you this is an example for many years ago. This was a paper that was published in this international conference on atomic and nuclear physics. And you look at the title Atomic Energy, or the made of able to a single source, and you read the abstract, and if you look at the abstract, it doesn't make a lot of sense. Well, it turns out that when this was created, it was created by a person to make a point about how poor some of these journal venues and conference venues are. This paper was made with autocomplete using an iPhone. And this is not all that different from this chatbots and chat GPT, which is really these autocomplete machines on steroids. And it looked sort of official, like a real science paper, but of course, a lot of it was nonsense. And the newest ones are much better. But it is a concern that this could increase the number of pseudoscience types of things or articles that are written by chatbots. In fact, there's been some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My colleague, Carl, found these examples of papers supposedly by me. Well, these aren't real citations by me. It shows me right here, West German. This is not my paper. It's close to some of the papers I've written in terms of title, but it's just a fake citation. I just made up these citations. And that's again, another example of how that could affect the citation record and scholarly literature and something that I'm concerned about for science. And something that's now happened with some of these chatbots, even in Bing now that has sort of integrated chat GPT4 into Bing, is that it just throws references. So it looks official. But I can tell you that this was not done before the fact. This is this knowledge that was written out in this answer when I asked about new tax loss for electric vehicles. This is one question I asked that it's not that it's wrote, you know, learn something from citations and then cited them like we do in the scholar literature, it cited them close talk, something that was probably semantically similar. Although, well, maybe scholars, scholars probably do this too. Well, they do do it post after posting, some argument or sentence. But this is problematic to me because it looks like it's a science, almost science and, you know, science-y and technical. And it's really not even though it has those references. So, you know, there's been lots of discussion in the scientific literature what to do with these chatbots, some of lists of authors on papers, publishers have come out, even publishers in the machine learning world. So ICML was, you know, one of the first conferences, not the, I don't think it was the first, but one of the, you know, among the first that was saying, you can't use chat TBT on this. You know, some are saying if you use it, you have to note it, you know, all sorts of different policies are being created. But overall, you know, I think the publishing community in the scholar literature is going to have to grapple with this. And I, and my colleague and I have, Carl and I have a, another op-ed that we're, that we write about sort of what publishers can do around this particular issue. Now, one of the other big concerns of this is, of course, that this technology shows, you know, it doesn't, it's always 100% confident, whether it's right or whether it's wrong. And that's really problematic. At least when humans communicate, they have these qualifiers of confidence where you can say something like, I'm pretty sure, or I think so, or I think that's right. You know, these things are important. And these chatbots don't have it. They just are always, they always seem to be, well, not seem. They spew out things, whether they're right or wrong with 100% confidence. And that's dangerous. And if there's, you know, one paper, one of my colleagues Emily Bender has this great feature where in this paper that she talks about, and also in this feature in, in the New York or, in this New York magazine, they talk, it talks a lot about some of the current concerns, Emily, and other people that are true linguists that truly understand some of the problems with these technologies. This is one that I would recommend reading. And a lot of you may have heard of this early interview that a New York Times journalist had with this, you know, with Bing's chatbot. And it, what essentially happened was the chatbot kind of went off the rails and started to say, well, you should leave your wife and I want to take over the world and all these things happen. And of course, a lot of the developers of this technology, whoa, whoa, whoa, we need to fix it. And there's been new rules around how you can use this Bing chatbot and other chatbots. But the problem with these fixes is they're like bandings. There's really, it's very, very difficult to reverse engineer these problems or reverse engineer. Yeah, reverse engineer these issues. It's not like you can go to a line of code and say, oh, that's where the problem is. It's the way that these things are trained, the way these models work with their resilience of parameters makes it very difficult to reverse engineer. And that's problematic when we run into these issues and all the issues we haven't even thought of. And so that to be is another big concern. Of course, there's all sorts of jail breaks to get these chatbots to do things that there have been bandings put around. And that's problematic. And I won't go over all the jail breaks you can read about because I don't want to get those out too much to the bug. But you can read about them. It's not like they're that hidden. And that's problematic. And there'll be many, many others as well. So these are some of the ones I had, some of these concerns, reverse engineers. The last two I'll mention is the cost. And the cost, we talked about jobs, the cost potentially to all different aspects of society. And the kind of scary thing is right now is that a lot of the tech layoffs are removing these teams. They're removing other individuals as well. But they're removing individuals that are on ethics and safety teams. And of all times to have these kinds of teams at these companies, it would be now, and certainly maybe if you went back in history at the beginning of the rise of social media, that they're being eliminated. And this is a concern. But there's also other kinds of costs that a lot of people forget. And that's the cost of these queries. There's been several analyses that have come out recently about the cost per query for running some of these chatbots. And it's almost an order of magnitude greater than a regular query that you'd have, let's say, on a Google search. And that has a cost. And there's also costs of investing billions and billions of dollars in this technology that could also go to other kinds of investments that might be helping society. So there's these costs that we have to think about the environmental costs, the costs to society, the costs of adding more pollution into our information systems, et cetera. There's also the issue of garbage in garbage out. And that's a problem we're likely going to see as these chatbots generate more and more content that land online, that becomes the training data for those chatbots in, you know, chat, chat GBT5 and chat GBT6. And what those effects will be requires some more research and thinking. But the main thing that we've known in a lot for a long time, of course, in the machine learning world is that garbage in with your training data creates garbage out. And even if you didn't have this, you know, feed forward loop that I just mentioned, there's a lot of garbage on the internet and that garbage finds its way into conversations with these chatbots. And that's always a concern whether you're talking about science or this technology just generative AI technology more broadly. So I'll end by saying that this technology is in many cases amazing. I have mostly focused on some of my cautions and concerns like many people have, especially in my world as someone who studies misinformation and misinformation specifically in science and its effect on the institution of science. And so, and so these are things that we're going to have to, you know, pay attention to going forward. But I think like a lot of our new technology, we just need time to think about it and run seminars and workshops and conferences just like this. So hopefully this generates some conversation and hopefully we can sort out some of these cautions. So with that, I'll end, you can reach out to me, you can learn more about my book and the research we do in my lab and at our university and in our center and you can reach me in these ways. So all right,\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n\n&gt; Entering new StuffDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\" In this talk, the speaker discusses the excitement and concerns around generative AI and chatbots, which have become increasingly popular. He focuses on the potential for misinformation and disinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. He also discusses the implications of the technology for education, copyright, and content credit.\n\n This article discusses the potential implications of large language models and chatbots, which can produce false information at scale. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue.\n\n This article discusses the use of social media platforms to study the amplification of individuals and organizations, as well as the use of bots and synthetically created content. It also discusses the game \"Which Faces Real\" created to bring public attention to deep fakes, and how this technology has been used to create fake journalists and videos. It also discusses the potential impact of new generative technology on content creators, the growing news deserts in the US, and the Justice Department's lawsuit against Google for monopolizing digital advertising technologies. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.\n\n Chat GPT technology has been used to co-author articles, but many journals and publishers are now prohibiting this. There are concerns about the technology creating fake citations and always being 100% confident in its answers, which can be dangerous. There are also concerns about the cost of the technology, the environmental cost, and the potential for garbage in/garbage out. It is important to take time to think about the implications of this technology and to have conversations about it.\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n\n' This article discusses the potential implications of generative AI and chatbots, such as misinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.'\n\n\n원천: 오정보 쥬피터 노트북\n\n\n\n\n\n\n디플 번역\n\n\n\n\n\n이 글에서는 잘못된 정보, 일자리 퇴출, 사이비 과학 확산, 신뢰성 검증의 필요성 등 생성형 AI와 챗봇의 잠재적 영향에 대해 논의합니다. 또한 이러한 기술이 악의적인 행위자에 의해 악용될 수 있는 방법과 이 문제를 해결하기 위한 연구, 정책, 교육, 커뮤니티 참여의 필요성에 대해서도 살펴봅니다. 민주적 담론, 건강 및 기타 영역에 미칠 수 있는 잠재적 영향과 잘못된 정보의 영향을 감지하고 되돌리기 어려운 점을 살펴봅니다. 마지막으로 인공지능으로 인한 일자리 손실 가능성, 사이비 과학의 확산, 챗봇이 허위 인용을 일으킬 가능성에 대해 논의합니다."
  },
  {
    "objectID": "news_release.html#요약결과",
    "href": "news_release.html#요약결과",
    "title": "chatGPT",
    "section": "\n3.3 요약결과",
    "text": "3.3 요약결과\nload_summarize_chain() 으로 전체 발표 텍스트를 요약한다.\n\n\n코드summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',\n                                      verbose=True # Set verbose=True if you want to see the prompts being used\n                                    )\noutput = summary_chain.run(docs)\noutput\n\n\n\n&gt; Entering new MapReduceDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"Well, thank you very much, Dr. Ahn. This is a real pleasure to be able to speak across the ocean. I wish I was there in person, but I did get the opportunity to meet many of your students during your visit in Seattle at the University of Washington, and that was a real pleasure. So thank you so much. So today I'm going to talk about some of the excitement around generative AI and these chatbots that we're seeing everywhere in our world. But mostly I'm going to talk a lot about some of the concerns I have around these chatbots and how they may contribute to this growing problem of misinformation in our digital worlds. So I'm going to share my screen here. There we go. Just here, share, and there we go. All right, can you see that, Dr. An? Yes. Okay, great. Okay, so as Dr. An said, I study misinformation and disinformation in all sorts of forms where I study misinformation. The most is at the interface of science and society, but we also study it more generally in our center where we look at it from the political angle, from the angle of science, from the angle of health. We've studied misinformation during the pandemic and during elections and all sorts of other topics. But today I'm going to focus on some of my concerns around generative AI, and hopefully that will generate some questions and comments when it comes to this particular topic. I'm sure a lot of us are thinking about it. So one of the things that I tend to ask myself when new technologies come onto the world scene is whether we're better or worse off. I recently wrote an op-ed, an opinion piece for the Seattle Times, which is our paper here in Seattle in the United States. And I talked about some of the concerns I had. And so some of the things I'm going to talk about in this talk come from that op-ed, but I'm going to talk about a lot of other things I didn't have room to talk about in that particular op-ed. But I really want us as a group to think a lot about this. Are we better or worse off with this new chatbot ability? And of course it's a mixed bag. There are things that might be better, and there are things that are going to be worse. I'm going to kind of focus on the more pessimistic version of this. About a week ago, there was a lot of attention around a new music song that was posted on several music services that sounded like a mix between the famous musician Drake and the weekend. These are two musical artists that are known worldwide for their music. And there was a song that was created that was quite catchy. And believe it or not, it was kind of good, I have to admit. And it was probably viewed by millions and millions of people. I don't know the exact stats on that. I should look that up. But the point is this song was created with some of this new generative AI technology. And this is an example where there might be some positive elements of this technology that allows for this mixing and this creation. It created a song that caught enough people's attention that it caught so much attention. It actually had to be taken down because of issues likely around copyright. And there's all sorts of fallout from this. And there's lots of discussions in the legal world that are continuing. And it's only been about a week since this song was released. But this is an example of the excitement that surrounds this technology. And for good reason, if it can create a song that's a good mix of Drake and the weekend and it sounds reasonably good, that's some evidence at least of the power of this new technology. And it's not like this is brand new technology. There is this kind of technology from the natural language processing world and machine learning more generally has been around. But there's been some advancements recently that make the generative aspect quite exciting, but also a little scary. So I'm going to talk about today some of the the cautions that I have. There's a lot more cautions. But these are the things I'm going to focus on. And it's a lot to focus on in about 25 minutes. So I'm going to hit these briefly. And then if there are questions, we can always go back to some of these topics in more detail. But I'm going to go through talking about how at least from my perspective, as someone who studies misinformation, and as someone who studies misinformation specifically in science, these are some of my big concerns. One of them is that these really are bullshatters at scale. They get a lot right, but they also get some things wrong. Concerns around how this might affect democratic discourse online and offline. Concerns about content credit for all those content creators out there, the musicians like Drake and the weekend, and the writers and the journalists and the researchers and the authors and the poets, etc. What happens to their content when it gets pushed down after these generative AI, these chatbots and these large language models train on this content and then provide some reason new content on top of it. Who owns the content? How's that going to work as we move forward? I'll talk a little bit about some of the job elimination issues, both course in science, but in other areas, it'll be that, well, some of these are focused outside of the issue of science. And then of course, I'm going to talk about some of the issues of pseudoscience proliferation, the overconfidence of AI and the need for some of these qualifiers of confidence, the issues around reverse engineering, the generative cost, the actual cost, both monetarily, environmentally, but also the costs in other forms and creativity and other things. And then I'll talk, I'll end with just really emphasizing this issue about garbage in garbage out. Okay, so we now live in this world where it seems we've got almost sentient beings. I know there's lots of philosophical debates whether they're sentient. I don't think they are. And we certainly haven't reached AGI levels. And there's all sorts of great, you know, critiques of this particular technology. But one thing that at least I think we're all pretty sure of, it's kind of here to stay in some form or another. Even in my world in education as a professor who runs a research lab and also as a professor who teaches students, college students, I'm seeing the technology everywhere. And when I was teaching my class last quarter, I decided to just embrace the technology and allow the students to use it in any form that they see as long as they let me know that they were using it. That's my only criteria because I want to learn how this technology can be used by students and by teachers like myself and professors like myself. But I also want to figure out where it goes wrong. And so I learned a lot from my students and I will continue to have that kind of policy. But maybe that'll change at some point. I know that some instructors don't allow it. I know that some scientific publishers are not allowing co-authorship or the use of AI in any form. Even countries like Italy have outlawed some forms of this technology. And so there's going to be some that are going to eliminate it, some that are going to embrace it. And the way I look at it is that it may just force me to write different kinds of questions and do different kinds of assessment. But it might also be a tool that could help students learn to write when they're stuck and learn how to correct as long as they're willing to do some editing and self-correct and correction of the content that comes from these different bots. And so the technology really is here to stay. And one thing I should say is what's interesting is that we have a technology that really seems to have passed the Turing test. And one thing that's a bit a little surprising to me is that we haven't had a big celebration about this. Even though I'm a bit of a critic of this technology and I focus a lot of my attention on some of the concerning areas of Generative AI, since I studied misinformation, disinformation. I should say though, on the other hand, we should be thinking about some of the things that have occurred. And for those not familiar with the Turing test, it's this pretty simple idea that the Turing test will have passed when an individual can't tell the difference. But when content, at least in this case written content created by a human and one by a computer. And if that's the case, and I do think in many respects, we probably have passed this Turing test. And there's been no celebrations. So I guess, okay, for those that are optimistic about this technology and more positive about this technology, this would be something to celebrate. Absolutely. No doubt. And in terms of education, as I mentioned before, this is really transforming education, but it's transforming all sorts of other industries in ways that have captured the world's attention. I mean, this technology has been adopted now faster than pretty much any other technology has been adopted with hundreds, like 100 million users within a very short amount of time. And of course, that's only growing and billions and billions of dollars being invested into this technology from big corporations to venture capitalists. There is a lot going into this technology. And again, there's good reason for that. And a lot of times my students will say, well, it's just like a calculator. Why would you ever want to take it away? And I'm not taking it. I'm lo and use it. But I will say, it's a little different than a calculator, because this is a technology that gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"gets this things wrong at minimum, probably 10% of the time. I mean, these things are starting to still get sorted out in the research space. We're working on some of these things to figure out, you know, what is the baseline error? Well, it turns out it's pretty high. And in some cases, the impact can be quite high. So if you're talking about the medical field or you're talking about fields that really have an impact on an individual's lives, that 10% or 20% or 5% or whatever, those errors can be highly problematic. If you're just creating a poem, then fine. It doesn't really matter. But this analogy to the calculator goes a little, it's there's reason to think that's a somewhat reasonable analogy, but it is different. I wouldn't use a calculator that got the answers wrong 10% of the time. That would be, I would probably be looking for other technologies. Or if I was using that calculator, it would make it for a lot harder work. And that's what we have to recognize. It's yes, we have this technology that can do a lot of this new amazing things to make some of our jobs easier. But it's going to take a lot of hard work on the editorial side to make sure that we're paying attention to some of those errors. And there's all sorts of application. This was an article just recently written by Wired sort of examining the ways in which the medical field is starting to think about the adoption of this. In fact, some medical researchers have gone so far as to say that all doctors will be using this technology at some point. And maybe that's true. And there are reasons to think that's a possibility with its ability to mine the scientific literature, to integrate all sorts of different symptoms, and could be that assistant in the doctor's room. However, there are reasons to also be worried about these technologies and in places like the medical field. It might help the doctors as this article talks about, but it also might not benefit so greatly many of those patients, especially because we have many, many examples of the ways in which these machines get things wrong and have biases built in because the data that it's trained on has some of these biases. And at this point, a lot of these technologies are essentially just patching and putting band aids on these problems that exist. And part of it's just because these things are very difficult to reverse engineer, which I'll talk about a little bit later. Now, there's plenty of other reasons to be excited to actually one of my colleagues who I just saw at a conference last week, Daniel Katz and his colleague Michael Bomerito showed how this technology took the bar exam. This is the main legal, the exam in the United States for allowing you to become a lawyer or sort of allowing you to sort of move forward as a certified lawyer. And they were able to show that chat GPT did already darn well in past the bar exam. And there's examples of the MCAT and, you know, some of these other standardized tests that are that have been tested with this technology. In fact, in many ways, these have almost become a baseline test when comparing different large language models. And so it is pretty amazing. So again, amazed in many ways, but I'm going to talk the rest of the time about some of the concerns that I have. And by the way, as was mentioned, I have this book where I talk about bullshit. And bullshit is a part of the misinformation story. And as Dr. An had mentioned, it's also been translated in Korean, which has been super fun to see it pulled or written in these other languages. And it helps me try to figure out what's being said here. But in that book, if you read it, one of the more important laws and principles that we talk about is something called \"Randalini's Bullshit, a Symmetry Principle.\" And if you go to Wikipedia, at least the English version, I actually should check the Korean version, see if it's there. But the English version of the Wikipedia has this principle in the Wikipedia. And this law is pretty simple. It basically says that the amount of energy needed to refute bullshit is an order of magnitude bigger than needed to produce it. So the amount of energy needed to refute it to clean it up, to fix the problem, is an order of magnitude much harder to produce it. So here's the law. So my colleague Carl Bergstrom decided to ask the large language model that Metacreat a while ago called Galactica. And this has been taken down since then, but this was the science version, essentially, of one of these large language models. And he decided to ask Galactica, \"Tell me about Randalini's Bullshit, a Symmetry Principle. And you know what it came up with?\" And this is the real answer. Here's what it came up. Randalini's law is a theory in economics proposed by G. Anani Brannalini, a professor at the University of Pateau, which dates the smaller the economic unit, the greater its efficiency. Almost nothing here is correct. It's basically bullshitting the bullshit principle. So to me, this encapsulates one of the biggest problems with this technology. It bullshits, and it can do this at scale. And this could be put in the wrong hands. And this can also just add more noise to an information environment that has plenty of noise. We needed to clean up that polluted information environment, not add noise. And that's what a lot of these chatbots will do, definitely, because they make, they put a lot of accurate things out there, but they also put a lot of false things. And this is the best encapsulation that I've seen so far, which is actually bullshitting the bullshit principle. So that's a problem. So as I mentioned in this op-ed, I talk about some of these things. And one of the things I talk about as well is that not only do these things, can these bullshit at scale, they also can get in the way of democratic discourse. And many years ago, back in 2018, there was a lot of attention around Facebook's role in pushing misinformation. Excuse me. And they revealed at the time when Mark Zuckerberg was being questioned by Congress about all the fake accounts. And they admitted they had disabled 1.3 billion fake accounts. Now, they certainly haven't solved that problem, just like no social media platform has solved that. In fact, when Elon Musk was taking over Twitter, that was one of the big issues at hand, that there was all sorts of concerns if there was lots and lots of bots on Twitter. Now, that's still a problem. I can guarantee you, you know, my group has done a little bit of work working in detecting and looking at the effects of bots. But my colleagues in my research area have done a lot of work on that space, and it's very, very hard to do. But one thing is that, you know, we do know is that there are a lot of bots out there and a lot of fake accounts. Now, imagine those fake accounts with the ability that these chat bots now have to look even more human technology that's basically, well, has passed the Turing test. That to me is problematic because of these different reasons. So you have these large number of fake accounts. Now imagine these fake accounts being scaled to conversations with our public officials. Now, democracies depend on an engagement with the public, with their officials that they voted in. Well, that becomes a problem like it was back in 2017, when there was discussions, at least in the United States around something called net neutrality. And net neutrality was a policy that was being debated in governmental circles, and they wanted to know what the public was saying. But when you went to what the public was saying, they had complete the, there were comments that had completely flooded the conversation on one side of the issue, and it turns out that they were essentially fake accounts. They were bots. And again, now imagine doing that with the sophistication that these new chat bots have before you could, there was a, you could start, you could detect a bot much easier. Now it's become even harder. And if our democratic systems are flooded with these kinds of things, this is, this is problematic. So this issue, in its potential impact on democratic discourse, and its ability to bullshit at scale is of major concern to me. So I spent a lot of my time, like my colleagues in our center, in sort of the darker core of the internet, studying the ways in which misinformation and disinformation spreads online. And one thing that we are, of course, very concerned about now are the ways in which these technologies can really further inflame or further fan the flames of discourse in groups, if these get in the wrong hands. And they certainly will. It's almost certain that bad actors are finding ways to use this technology for their own ends. And we know that, you know, our surgeon general and other major leaders around the world have recognized the ways in which misinformation can affect our health, and they can affect the health of democracies. So it's not just that, oh, well, it's annoying, there's a lot of false information online. It just makes it hard to find, you know, good information. It's not just that it actually affects people's health. And we're recognizing that. And at least, well, we've recognized it. And now we've got another problem ahead of us, which is the ability of these technologies to create deep fake images, video, audio, text. That's the challenge that we have ahead of us. So as Dr. On mentioned, we have a center at the University of Washington in Seattle in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"in the United States where we study this, and this is one of the issues that we study and we study these things on social media platforms. And we look at the way that individuals and organizations get amplified. But we're also going to start looking at the ways that these bots and synthetically created content also get amplified. So we do this through all sorts of different channels, research is our main thing, but we also do it through policy and education and community engagement. And one of the things that my colleague Carl Wurxman, I created several years ago to bring public attention to synthetic media to deep fakes, was to create a game that we called which faces real calm. And it was a simple game. We just asked the users which image is real. One of them is a real image of a real person on this earth. And another one was synthetically created with computers. And you can go through that, you know, thousands and thousands and thousands of images and we play this game and then you get told whether it's real or not. And it turns out it's pretty hard. I mean, you know, there's some that are kind of obvious, but they're hard like this one right here, which one's real. Look at it for a second. Well, the one that's real is the one with the blue shirt, at least on my right. And if you said the one on the red shirt, totally understand it's really hard to tell the difference. And the reason why we created this game was just to bring public attention because the time in a technology's birth that's I think most scary when it comes to its potential impact is when the public is not aware of the things that it can do. So we created this game and we've had millions and millions of plays of this game. And we've now seen actually this technology, you know, get used and you know, of course, good ways, but a lot of bad ways too. For example, we've seen this technology be used to create fake journalists. This is an example and you can read more about it, but this has happened many times where journalists, or so-called journalists, you know, profiles created and then there's these images and people that study deep fake imagery can actually look at these images and start to see what some of look for some of these telltale signs on what's real or not. So these, this technology's been been already used. And we talked about this when this game was created, the ways in which it's been used. And we've already seen it, of course, many ways. So now we're asking how are the ways in which this new generative technology could be used. But it's very similar. It's based on similar kinds of concepts and data training, etc, etc. But we're now asking the same things. And of course, we've seen this now just recently with this kind of technology being used in videos and even in ways that are more sophisticated than just these sort of portrait pictures. So this was an image. It's a fake image and it's been reported all over BBC and lots of other places of Donald Trump supposedly being arrested in New York. This was before he was actually brought to New York on the recent case. But this, of course, never happened, but it certainly sparked all sorts of concern and it spread like wildfire on the internet using some of this, you know, mid-journey technology in our company called Mid-Journey and a lot of other companies that are creating this. So it's making it easier and easier and less expensive and making it harder for us to tell what's real. And so that technology has of course evolved. So, okay, so now I've talked about some of the democratic discourse. I'm going to go through a little quicker on these other ones so then I can get to sort of the end and try to finish in about, I would say about seven minutes or so. So like I mentioned at the beginning, there's this issue of content creation and that's really important because these content creators are generating a lot of the content that a lot of these technology companies are using to create these chatbots. But we've seen this story before and by the way, just recently, there are major technology companies that are now not allowing the scraping of this data to be trained for these technologies unless they're compensating. I think that's a fair thing. So, you know, some of these big companies like Reddit is not allowing stack overflow is now saying, \"Hey, if you're going to scrape our data, they want to be compensated.\" And so you're going to start to see content creators starting to push back, which is good because like I said, we've seen this story before. Oh, and by the way, this is an example of, you know, Getty Images is in a lawsuit right now with a company that may have been scraping their data illegally. And the reason why that came out is because you can see this little Getty Images that pops up, which is a watermark that Getty Images puts on their images. So there's an appending lawsuit about this and that could determine some of the some of how this content can or can't be scraped. But we've seen this before when looking at new technology and the impact it can have on other information producers in the United States and in many places around the world, we have growing news deserts. These are areas where there's no more local news. And that's pretty devastating for democratic discourse or democracies because we depend on local news for engagement, civic engagement and quality information and local news tends to be trusted more than national news. And there's all sorts of reasons for that happening. But certainly one element of that is the effect that search engines and Google in particular around it, you know, the way it sells ads and it takes a large cut at those ads has potentially contributed to these news deserts. Of course, there's lots of other things as well. But that technology everyone was excited about, including myself and we use it all the time. But there are these unintended effects that can affect other aspects of our information ecosystems. And right now, there's a lawsuit going on. The Justice Department, United States Justice Department is suing Google for monopolizing digital advertising technologies. And one of those elements of this lawsuit story is the sort of increase in the demise of local news. So there's all sorts of interesting things playing out right now. And then the Biden administration, United States is thinking about doing some regulation of AI, but they don't know, it's so new to all administrations that it's hard to figure out. Like I mentioned, Italy has gone probably one of the furthest steps I think around this. But there hasn't been a lot of action, at least on the US side when it comes to this sort of thing. And so, there's been letters. So this was an article written by Time. The image quite nice. It actually grows. There was a letter that went around from a bunch of influential people in AI and business leaders and technology, including Elon Musk that says, hey, we should stop the development until we've had more time to think about it. Although it's kind of ironic, given that many of these tech leaders are still, of course, pushing their own development of AI in many ways and creating new AI companies and developing. But anyway, that's another story. But that is something to think about. I don't think it's a, I think there's no way that that letter is going to stop the technology from being developed. But one thing it is good about is it's makes hopefully forcing the public and journalists and government officials, etc. to start to think about the ways in which this technology could affect society. We should think about it. As I mentioned, one of the concerns is job demise. And I think there's a lot of concern with that by those that even work in the job industry, the Pew Research Center recently asked workers where are they concerned? Turns out a large number of workers from across these different industries are concerned. And there's probably good reason for this concern. Even Sam Altman at OpenAI, which is sort of, or is the owner of the chat GPT, which is the one of the more well-known chatbots out there. And it's also the one that Microsoft has invested billions. This is something that they've even said probably lose 5 million jobs. So these are real concerns. So the other thing to mention too is that it's not just within science itself, these are real concerns. And we've seen the proliferation of pseudoscience and the rise of predatory journals and content that maybe looks like science. But it's not. And I'll show you this is an example for many years ago. This was a paper that was published in this international conference on atomic and nuclear physics. And you look at the title Atomic Energy, or the made of able to a single source, and you read the abstract, and if you look at the abstract, it doesn't make a lot of sense. Well, it turns out that when this was created, it was created by a person to make a point about how poor some of these journal venues and conference venues are. This paper was made with autocomplete using an iPhone. And this is not all that different from this chatbots and chat GPT, which is really these autocomplete machines on steroids. And it looked sort of official, like a real science paper, but of course, a lot of it was nonsense. And the newest ones are much better. But it is a concern that this could increase the number of pseudoscience types of things or articles that are written by chatbots. In fact, there's been some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My\"\n\n\nCONCISE SUMMARY:\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\"some articles that have been co-authored by chat GPT, although some journal, a lot of journals and publishers are saying they won't allow that anymore. And that's probably a good thing. And I will say this, there's been lots of talk about the hallucination of these chatbots. Well, one thing that I find incredibly problematic is the hallucination of citations. It'll make up citations all the time. And we've been doing some work trying to find ways to see when this happens. It even happened. My colleague, Carl, found these examples of papers supposedly by me. Well, these aren't real citations by me. It shows me right here, West German. This is not my paper. It's close to some of the papers I've written in terms of title, but it's just a fake citation. I just made up these citations. And that's again, another example of how that could affect the citation record and scholarly literature and something that I'm concerned about for science. And something that's now happened with some of these chatbots, even in Bing now that has sort of integrated chat GPT4 into Bing, is that it just throws references. So it looks official. But I can tell you that this was not done before the fact. This is this knowledge that was written out in this answer when I asked about new tax loss for electric vehicles. This is one question I asked that it's not that it's wrote, you know, learn something from citations and then cited them like we do in the scholar literature, it cited them close talk, something that was probably semantically similar. Although, well, maybe scholars, scholars probably do this too. Well, they do do it post after posting, some argument or sentence. But this is problematic to me because it looks like it's a science, almost science and, you know, science-y and technical. And it's really not even though it has those references. So, you know, there's been lots of discussion in the scientific literature what to do with these chatbots, some of lists of authors on papers, publishers have come out, even publishers in the machine learning world. So ICML was, you know, one of the first conferences, not the, I don't think it was the first, but one of the, you know, among the first that was saying, you can't use chat TBT on this. You know, some are saying if you use it, you have to note it, you know, all sorts of different policies are being created. But overall, you know, I think the publishing community in the scholar literature is going to have to grapple with this. And I, and my colleague and I have, Carl and I have a, another op-ed that we're, that we write about sort of what publishers can do around this particular issue. Now, one of the other big concerns of this is, of course, that this technology shows, you know, it doesn't, it's always 100% confident, whether it's right or whether it's wrong. And that's really problematic. At least when humans communicate, they have these qualifiers of confidence where you can say something like, I'm pretty sure, or I think so, or I think that's right. You know, these things are important. And these chatbots don't have it. They just are always, they always seem to be, well, not seem. They spew out things, whether they're right or wrong with 100% confidence. And that's dangerous. And if there's, you know, one paper, one of my colleagues Emily Bender has this great feature where in this paper that she talks about, and also in this feature in, in the New York or, in this New York magazine, they talk, it talks a lot about some of the current concerns, Emily, and other people that are true linguists that truly understand some of the problems with these technologies. This is one that I would recommend reading. And a lot of you may have heard of this early interview that a New York Times journalist had with this, you know, with Bing's chatbot. And it, what essentially happened was the chatbot kind of went off the rails and started to say, well, you should leave your wife and I want to take over the world and all these things happen. And of course, a lot of the developers of this technology, whoa, whoa, whoa, we need to fix it. And there's been new rules around how you can use this Bing chatbot and other chatbots. But the problem with these fixes is they're like bandings. There's really, it's very, very difficult to reverse engineer these problems or reverse engineer. Yeah, reverse engineer these issues. It's not like you can go to a line of code and say, oh, that's where the problem is. It's the way that these things are trained, the way these models work with their resilience of parameters makes it very difficult to reverse engineer. And that's problematic when we run into these issues and all the issues we haven't even thought of. And so that to be is another big concern. Of course, there's all sorts of jail breaks to get these chatbots to do things that there have been bandings put around. And that's problematic. And I won't go over all the jail breaks you can read about because I don't want to get those out too much to the bug. But you can read about them. It's not like they're that hidden. And that's problematic. And there'll be many, many others as well. So these are some of the ones I had, some of these concerns, reverse engineers. The last two I'll mention is the cost. And the cost, we talked about jobs, the cost potentially to all different aspects of society. And the kind of scary thing is right now is that a lot of the tech layoffs are removing these teams. They're removing other individuals as well. But they're removing individuals that are on ethics and safety teams. And of all times to have these kinds of teams at these companies, it would be now, and certainly maybe if you went back in history at the beginning of the rise of social media, that they're being eliminated. And this is a concern. But there's also other kinds of costs that a lot of people forget. And that's the cost of these queries. There's been several analyses that have come out recently about the cost per query for running some of these chatbots. And it's almost an order of magnitude greater than a regular query that you'd have, let's say, on a Google search. And that has a cost. And there's also costs of investing billions and billions of dollars in this technology that could also go to other kinds of investments that might be helping society. So there's these costs that we have to think about the environmental costs, the costs to society, the costs of adding more pollution into our information systems, et cetera. There's also the issue of garbage in garbage out. And that's a problem we're likely going to see as these chatbots generate more and more content that land online, that becomes the training data for those chatbots in, you know, chat, chat GBT5 and chat GBT6. And what those effects will be requires some more research and thinking. But the main thing that we've known in a lot for a long time, of course, in the machine learning world is that garbage in with your training data creates garbage out. And even if you didn't have this, you know, feed forward loop that I just mentioned, there's a lot of garbage on the internet and that garbage finds its way into conversations with these chatbots. And that's always a concern whether you're talking about science or this technology just generative AI technology more broadly. So I'll end by saying that this technology is in many cases amazing. I have mostly focused on some of my cautions and concerns like many people have, especially in my world as someone who studies misinformation and misinformation specifically in science and its effect on the institution of science. And so, and so these are things that we're going to have to, you know, pay attention to going forward. But I think like a lot of our new technology, we just need time to think about it and run seminars and workshops and conferences just like this. So hopefully this generates some conversation and hopefully we can sort out some of these cautions. So with that, I'll end, you can reach out to me, you can learn more about my book and the research we do in my lab and at our university and in our center and you can reach me in these ways. So all right,\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n\n&gt; Entering new StuffDocumentsChain chain...\n\n\n&gt; Entering new LLMChain chain...\nPrompt after formatting:\nWrite a concise summary of the following:\n\n\n\" In this talk, the speaker discusses the excitement and concerns around generative AI and chatbots, which have become increasingly popular. He focuses on the potential for misinformation and disinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. He also discusses the implications of the technology for education, copyright, and content credit.\n\n This article discusses the potential implications of large language models and chatbots, which can produce false information at scale. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue.\n\n This article discusses the use of social media platforms to study the amplification of individuals and organizations, as well as the use of bots and synthetically created content. It also discusses the game \"Which Faces Real\" created to bring public attention to deep fakes, and how this technology has been used to create fake journalists and videos. It also discusses the potential impact of new generative technology on content creators, the growing news deserts in the US, and the Justice Department's lawsuit against Google for monopolizing digital advertising technologies. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.\n\n Chat GPT technology has been used to co-author articles, but many journals and publishers are now prohibiting this. There are concerns about the technology creating fake citations and always being 100% confident in its answers, which can be dangerous. There are also concerns about the cost of the technology, the environmental cost, and the potential for garbage in/garbage out. It is important to take time to think about the implications of this technology and to have conversations about it.\"\n\n\nCONCISE SUMMARY:\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n&gt; Finished chain.\n\n\n' This article discusses the potential implications of generative AI and chatbots, such as misinformation, job elimination, pseudoscience proliferation, and the need for qualifiers of confidence. It also looks at the ways in which these technologies can be used by bad actors and the need for research, policy, education, and community engagement to address the issue. It examines the potential impact on democratic discourse, health, and other areas, and the difficulty of detecting and reversing the effects of misinformation. Finally, it discusses the potential for job loss due to AI, the proliferation of pseudoscience, and the potential for chatbots to create false citations.'\n\n\n원천: 오정보 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#환경설정",
    "href": "misinfo_embedding.html#환경설정",
    "title": "chatGPT",
    "section": "\n1.1 환경설정",
    "text": "1.1 환경설정\n\n\n코드# !pip install pinecone-client\nimport dotenv\nimport os\nimport pinecone\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\npinecone.init(\n    api_key=os.getenv(\"PINECONE_API_KEY\"),\n    environment=os.getenv(\"PINECONE_API_ENV\"),\n)\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#토큰-크기",
    "href": "misinfo_embedding.html#토큰-크기",
    "title": "chatGPT",
    "section": "\n2.1 토큰 크기",
    "text": "2.1 토큰 크기\n텍스트 데이터 토큰 크기를 추정하는 것은 비용뿐만 아니라 추후 개발방향에 전략을 세우는데 큰 시사점을 제시한다.\n\n\n\n정규표현식\n\n\n코드import re\n\ndef estimate_tokens(text):\n    tokens = re.findall(r'\\b\\w+\\b|\\S', text)\n    return len(tokens)\n\nprint(f\"정규표현식 추정토큰수: {estimate_tokens(contents)}\")\n\n정규표현식 추정토큰수: 7974\n\n\n원천: 벡터 DB 쥬피터 노트북\n\n\ntiktoken\n\n\n코드import tiktoken\n\ndef num_tokens_from_string(string: str) -&gt; int:\n    \"\"\"Returns the number of tokens in a text string.\"\"\"    \n    encoding = tiktoken.get_encoding(\"cl100k_base\")\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\n# num_tokens_from_string(\"Hello World!\",)\nnum_tokens=num_tokens_from_string(contents)\nnum_tokens\n\n7852\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#비용",
    "href": "misinfo_embedding.html#비용",
    "title": "chatGPT",
    "section": "\n2.2 비용",
    "text": "2.2 비용\nOpenAI_Lab/Context-based-search-Version2.ipynb\n\n\n코드# 출처: https://github.com/OpsConfig/OpenAI_Lab/blob/3a8c55160a6790fc790ef1c2c797d83c716eee94/Context-based-search-Version2.ipynb\n# Based on https://openai.com/api/pricing/ on 01/29/2023\n# If you were using this for approximating pricing with Azure OpenAI adjust the values below with: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n\n#MODEL  USAGE\n#Ada     v1 $0.0040 / 1K tokens\n#Babbage v1 $0.0050 / 1K tokens\n#Curie   v1 $0.0200 / 1K tokens\n#Davinci v1 $0.2000 / 1K tokens\n\n#MODEL  USAGE\n#Ada     v2 $0.0004 / 1K tokens\n#This Ada model, text-embedding-ada-002, is a better and lower cost replacement for our older embedding models. \n\nn_tokens_sum = num_tokens\n\nada_v1_embeddings_cost = (n_tokens_sum/1000) *.0040\nbabbage_v1_embeddings_cost = (n_tokens_sum/1000) *.0050\ncurie_v1_embeddings_cost = (n_tokens_sum/1000) *.02\ndavinci_v1_embeddings_cost = (n_tokens_sum/1000) *.2\n\nada_v2_embeddings_cost = (n_tokens_sum/1000) *.0004\n\nprint(\"Number of tokens: \" + str(n_tokens_sum) + \"\\n\")\n\nprint(\"MODEL        VERSION    COST\")\nprint(\"-----------------------------------\")\nprint(\"Ada\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(ada_v1_embeddings_cost))\nprint(\"Babbage\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(babbage_v1_embeddings_cost))\nprint(\"Curie\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(curie_v1_embeddings_cost))\nprint(\"Davinci\" + \"\\t\\t\" + \"v1\" + \"\\t$\" + '%.8s' % str(davinci_v1_embeddings_cost))\nprint(\"Ada\" + \"\\t\\t\" + \"v2\" + \"\\t$\" + '%.8s' %str(ada_v2_embeddings_cost))\n\nNumber of tokens: 7852\n\nMODEL        VERSION    COST\n-----------------------------------\nAda     v1  $0.031408\nBabbage     v1  $0.03926\nCurie       v1  $0.15704\nDavinci     v1  $1.570400\nAda     v2  $0.003140\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#텍스트-쪼개기",
    "href": "misinfo_embedding.html#텍스트-쪼개기",
    "title": "chatGPT",
    "section": "\n3.1 텍스트 쪼개기",
    "text": "3.1 텍스트 쪼개기\n\n\n코드import pandas as pd\n\nsentences = contents.split(\". \")\n\ndf = pd.DataFrame(sentences, columns=['text'])\n\nprint(df.head())\n\n                                                text\n0                      Well, thank you very much, Dr\n1                                                Ahn\n2  This is a real pleasure to be able to speak ac...\n3  I wish I was there in person, but I did get th...\n4                               So thank you so much\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#임베딩-1",
    "href": "misinfo_embedding.html#임베딩-1",
    "title": "chatGPT",
    "section": "\n3.2 임베딩",
    "text": "3.2 임베딩\n\n\n코드import uuid\n\ndef get_embedding(text: str, model=\"text-embedding-ada-002\") -&gt; list[float]:\n    return openai.Embedding.create(input=[text], model=model)[\"data\"][0][\"embedding\"]\n\n# embedding = get_embedding(\"Your text goes here\", model=\"text-embedding-ada-002\")\n# print(len(embedding))\n# df['n_tokens'] = df[\"embedding\"].apply(lambda x: len(x))\n\n\ndf[\"embedding\"] = df.text.apply(lambda x: get_embedding(x))\ndf['vector_id'] = [str(uuid.uuid4()) for _ in range(len(df))]\n\ndf.to_csv(\"misinfo-embeddings.csv\")\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#db-생성",
    "href": "misinfo_embedding.html#db-생성",
    "title": "chatGPT",
    "section": "\n4.1 DB 생성",
    "text": "4.1 DB 생성\n\n\n코드# Pick a name for the new index\nindex_name = 'misinfo'\n\n# Check whether the index with the same name already exists - if so, delete it\nif index_name in pinecone.list_indexes():\n    pinecone.delete_index(index_name)\n    \n# Creates new index\npinecone.create_index(name=index_name, dimension=len(df['embedding'][0]))\nindex = pinecone.Index(index_name=index_name)\n\n# Confirm our index was created\npinecone.list_indexes()\n\n['misinfo']\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "misinfo_embedding.html#임베딩-삽입",
    "href": "misinfo_embedding.html#임베딩-삽입",
    "title": "chatGPT",
    "section": "\n4.2 임베딩 삽입",
    "text": "4.2 임베딩 삽입\nVECTOR DATABASE: CRUD with Pinecone\n\n\n코드import itertools\n\ndef chunks(iterable, batch_size=100):\n    it = iter(iterable)\n    chunk = tuple(itertools.islice(it, batch_size))\n    while chunk:\n        yield chunk\n        chunk = tuple(itertools.islice(it, batch_size))\n\nfor batch in chunks([(str(t), v) for t, v in zip(df.vector_id, df.embedding)]):\n    index.upsert(vectors=batch, namespace = \"misinfo_namespace\")\n\nindex.describe_index_stats()    \n\n{'dimension': 1536,\n 'index_fullness': 0.0,\n 'namespaces': {'misinfo_namespace': {'vector_count': 368}},\n 'total_vector_count': 368}\n\n\n원천: 벡터 DB 쥬피터 노트북"
  },
  {
    "objectID": "mathpix.html",
    "href": "mathpix.html",
    "title": "chatGPT",
    "section": "",
    "text": "tinytex::install_tinytex() 명령어로 $\\LaTeX$을 설치한다.\n\n코드tinytex::install_tinytex()\n# 설치위치 확인\ntinytex::tinytex_root()\n\n\n\n\n코드writeLines(c(\n  '\\\\documentclass{article}',\n  '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n), 'pdf/test_eng.tex')\n\ntinytex::pdflatex('pdf/test_eng.tex')\n#&gt; [1] \"pdf/test_eng.pdf\""
  },
  {
    "objectID": "mathpix.html#헬로월드",
    "href": "mathpix.html#헬로월드",
    "title": "chatGPT",
    "section": "",
    "text": "코드writeLines(c(\n  '\\\\documentclass{article}',\n  '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n), 'pdf/test_eng.tex')\n\ntinytex::pdflatex('pdf/test_eng.tex')\n#&gt; [1] \"pdf/test_eng.pdf\""
  },
  {
    "objectID": "services.html#bedit",
    "href": "services.html#bedit",
    "title": "chatGPT",
    "section": "",
    "text": "’B^ EDIT’는 카카오브레인의 AI 이미지 생성 모델 ’칼로(Karlo)’를 기반으로한 ’B^ EDIT’로 원하는 화풍의 이미지 생성은 물론, 다양한 기능을 활용해 이미지 수정기능을 제공한다. 바로가기"
  },
  {
    "objectID": "services.html#gaugan고갱-2",
    "href": "services.html#gaugan고갱-2",
    "title": "chatGPT",
    "section": "",
    "text": "동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상\n\n\n\n\n\n\n\n\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "text_to_images.html",
    "href": "text_to_images.html",
    "title": "chatGPT",
    "section": "",
    "text": "’B^ EDIT’는 카카오브레인의 AI 이미지 생성 모델 ’칼로(Karlo)’를 기반으로한 ’B^ EDIT’로 원하는 화풍의 이미지 생성은 물론, 다양한 기능을 활용해 이미지 수정기능을 제공한다. 바로가기\n\n카카오브레인이 개발하여 공개한 ‘B^ EDIT(비 에디트)’ 웹 서비스를 통해 Text-to-Image 기능을 통해 다양한 AI 이미지를 얻을 수 있다.\n성현희 (2023-03-07), “카카오브레인, ‘B^ EDIT’ 오픈 베타서비스 글로벌 출시” 전자신문\n\n\n’B^ EDIT’에 접속해 바로크, 3D 렌더, 일본 애니메이션 등 총 30가지 화풍 중 원하는 화풍과 제시어(프롬프트)를 입력하면, AI가 화풍 및 프롬프트에 적합한 이미지 8장을 5~10초 이내로 생성한다. 그외에도 아웃페인팅(Outpainting), 인페이팅(Inpainting), CS2I(Color Sketch To Image) 등의 기능도 제공한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상\n\n\n\n\n\n\n\n\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "text_to_images.html#bedit",
    "href": "text_to_images.html#bedit",
    "title": "chatGPT",
    "section": "\n4.1 B^Edit",
    "text": "4.1 B^Edit\n’B^ EDIT’는 카카오브레인의 AI 이미지 생성 모델 ’칼로(Karlo)’를 기반으로한 ’B^ EDIT’로 원하는 화풍의 이미지 생성은 물론, 다양한 기능을 활용해 이미지 수정기능을 제공한다. 바로가기\n\n4.1.1 소개자료\n카카오브레인이 개발하여 공개한 ‘B^ EDIT(비 에디트)’ 웹 서비스를 통해 Text-to-Image 기능을 통해 다양한 AI 이미지를 얻을 수 있다.\n성현희 (2023-03-07), “카카오브레인, ‘B^ EDIT’ 오픈 베타서비스 글로벌 출시” 전자신문\n\n\n4.1.2 사용방법\n’B^ EDIT’에 접속해 바로크, 3D 렌더, 일본 애니메이션 등 총 30가지 화풍 중 원하는 화풍과 제시어(프롬프트)를 입력하면, AI가 화풍 및 프롬프트에 적합한 이미지 8장을 5~10초 이내로 생성한다. 그외에도 아웃페인팅(Outpainting), 인페이팅(Inpainting), CS2I(Color Sketch To Image) 등의 기능도 제공한다."
  },
  {
    "objectID": "text_to_images.html#gaugan고갱-2",
    "href": "text_to_images.html#gaugan고갱-2",
    "title": "chatGPT",
    "section": "\n4.2 GauGAN(고갱) 2",
    "text": "4.2 GauGAN(고갱) 2\n\n4.2.1 NVIDIA 캔버스\n동일한 서비스를 NVIDIA 그래픽 카드가 있는 경우 NVIDIA 캔버스를 다운로드 받아 AI를 사용하여 간단한 붓터치를 사실적인 풍경 이미지로 바꿀 수 있다. 배경을 빠르게 만들거나 컨셉 탐색 속도를 높여 아이디어를 시각화하는 데 더 많은 시간을 할애할 수 있어 시간을 줄여준다.\n\n\n\n\n\n\n\n구성요소\n사양\n\n\n\nGPU\nNVIDIA GeForce RTX, NVIDIA RTX, or TITAN RTX GPU\n\n\n하드디스크\nSSD\n\n\n운영체제\n윈도우즈 10\n\n\n드라이버\nGeForce RTX 40 시리즈의 경우 520 이상, 기타 모든 GPU의 경우 471.68 이상\n\n\n\n\n\n\n\n\n4.2.2 고갱 2 API\nNVIDIA가 짧은 단어와 간단한 마우스 클릭으로 사실적인 예술품을 만들어주는 최신 버전의 AI 페인팅 툴 GauGAN2를 공개했다. 바로가기"
  },
  {
    "objectID": "text_to_images.html#예술과-사진",
    "href": "text_to_images.html#예술과-사진",
    "title": "chatGPT",
    "section": "\n3.1 예술과 사진",
    "text": "3.1 예술과 사진\n\n\nAbstract\nSurreal\nLandscape Photography\nPortrait Photography\nMinimalism\n\n\n\n“Vibrant colors,” “Geometric shapes,” “Abstract patterns,” “Movement and flow,” “Texture and layers.”\n\n\n\n\n\n\n“Dreamlike,” “Surreal landscapes,” “Mystical creatures,” “Twisted reality,” “Surreal still life.”\n\n\n\n\n\n\n“Majestic mountains,” “Lush forests,” “Glittering lakes,” “Desert dunes,” “Golden sunsets.”\n\n\n\n\n\n\n“Emotive eyes,” “Intense gazes,” “Contemplative mood,” “Expressive gestures,” “Stylized poses”.\n\n\n\n\n\n\n“Simplicity,” “Clean lines,” “Minimal colors,” “Negative space,” “Minimal still life.”"
  },
  {
    "objectID": "text_to_images.html#아트-스타일",
    "href": "text_to_images.html#아트-스타일",
    "title": "chatGPT",
    "section": "\n3.2 아트 스타일",
    "text": "3.2 아트 스타일\n\n\nimpressionism\nRealism\nPop Art\nStreet Photography\nNight Photography\n\n\n\n“Blurry brushstrokes,” “Painted light,” “Impressionistic landscapes,” “Pastel colors,” “Impressionistic portraits.”\n\n\n\n\n\n\n“Hyper-realistic textures,” “Precise details,” “Realistic still life,” “Realistic portraits,” “Realistic landscapes.”\n\n\n\n\n\n\n“Bold colors,” “Stylized portraits,” “Famous faces,” “Pop art still life,” “Pop art landscapes.”\n\n\n\n\n\n\n“Candid moments,” “Urban landscapes,” “Street life,” “Stories in motion,” “Street portraits.”\n\n\n\n\n\n\n“Lit cityscapes,” “Starry skies,” “Moonlit landscapes,” “Night time portraits,” “Long exposures.”"
  },
  {
    "objectID": "text_to_images.html#뉴스-기사",
    "href": "text_to_images.html#뉴스-기사",
    "title": "chatGPT",
    "section": "\n5.1 뉴스 기사",
    "text": "5.1 뉴스 기사\n누리호, 힘차게 날아올랐다…美도 달성하지 못한 진기록 뉴스기사에 포함될 이미지를 제작한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n프롬프트: 아래 뉴스기사는 백틱기호(`) 세개 사이에 담겨져 있습니다. 다음 뉴스기사를 이미지로 나타내기 위해 midjourney text prompt를 작성해세요.\n\n\n\n\n\n누리호, 힘차게 날아올랐다…美도 달성하지 못한 진기록\n\n김진원입력 2023. 5. 25. 18:43수정 2023. 5. 25. 21:14\n\n한국이 독자 기술로 개발한 로켓 ‘누리호’가 25일 우주로 향했다. 실용위성을 탑재한 발사체를 쏘아 올린 첫 사례다. 누리호는 차세대 소형위성 2호를 목표 궤도인 고도 550㎞에 정확하게 올려놨다. 남극 세종기지에서 위성 신호를 정상 수신했다. 작년 6월 누리호 2차 발사에 이어 이번 3차 발사 프로젝트까지 성공적으로 수행하면서 한국은 세계적인 우주 과학 강국으로 우뚝 서게 됐다. 첫 로켓 개발 후 연속 발사 성공은 미국과 러시아, 중국도 달성하지 못한 진기록이다. \n\n누리호는 이날 오후 6시24분 전남 고흥군 나로우주센터 전용 발사대에서 우주로 날아올랐다. 오전 11시 발사를 결정한 이후 오후 5시께 연료와 산화제 주입을 차례로 완료했다. 누리호는 오후 6시24분 정각에 3500도 초고온 고압가스의 힘을 받아 하늘로 힘차게 솟구쳤다.\n\n\n누리호는 발사 뒤 1단과 위성을 감싼 덮개인 페어링, 2단을 차례로 떼어냈다. 고도 550㎞에선 주탑재 위성인 차세대 소형위성 2호를 분리했다. 이후 20초 간격으로 부탑재 위성인 큐브위성을 차례로 내보냈다. 다만 7기의 큐브위성 중 1기에 대해선 사출 성공 여부를 판단 중이다.\n\n누리호는 과학기술정보통신부와 한국항공우주연구원이 2010년부터 개발한 토종 발사체다. 한국이 지난 2차에 이어 3차 발사까지 성공하면서 50여 년의 세계 우주개발사(史)에서 찾아보기 힘든 발자취를 남기게 됐다. 윤석열 대통령은 “달에 가는 것이 쉽기 때문이 아니라 어렵기 때문에 도전한다”며 “어렵기 때문에 우리의 도전이 되고 꿈이 되는 것”이라고 말했다.\n\n이어 “우리나라가 우주강국 G7에 들어가는 쾌거를 이뤘다”고 강조했다.\n\n 실용위성 8기 싣고 우주로…2032년 '달 착륙선' 보내는 게 목표\n\n사진=연합뉴스\n\n사진=연합뉴스\n25일 오전 5시 전남 고흥 나로우주센터. 한국형발사체 ‘누리호(KSLV-2)’ 전용 발사대 주변은 사람들로 북적였다. 액체헬륨 저장탱크의 ‘해압밸브’와 ‘지상장비시스템(PLC)’을 제어하는 소프트웨어(SW)에서 발생한 문제를 해결하기 위해 한국항공우주연구원 연구진은 밤을 꼬박 새웠다.\n\nSW를 구성하는 명령어가 순차적으로 전달되지 않는 문제를 해결하기 위해 명령어 사이의 간격을 세밀하게 수정했다. 여섯 차례에 걸친 반복 시험을 시행한 결과 ‘정상’이란 판정이 내려졌다. 해가 뜬 외나로도 앞바다는 구름 한 점 없이 맑았다. 비와 강풍, 낙뢰의 가능성도 작았다. 우주정거장, 인공위성과 충돌 가능성도 없었다. 발사 준비가 다시 시작됐다.\n\n ○실용·큐브위성 8기 분리 도전\n\n발사 1시간 전. 기체 점검과 연료·산화제 충전을 마친 누리호를 우주로 인도하는 전자탑재체(에비오닉스)의 전원이 켜졌다. 발사체 기립 장치가 철수하고 관성항법 유도시스템의 정렬이 시작됐다.\n\n발사 10분 전 발사자동운용(PLO)이 시작됐다. PLO는 발사 10분 전부터 발사체 이륙 직전까지 발사관제시스템에 의해 자동으로 이뤄지는 발사 준비 작업이다. 그리고 발사. 오후 6시24분 굉음과 함께 누리호가 힘차게 솟구쳤다. 연소가스 온도는 섭씨 3500도. 포스코의 쇳물을 녹이는 용광로 온도(1500도)의 두 배 이상이다. 압력도 대기압의 60배까지 치솟았다. 발사대를 식히기 위해 초당 1.8t의 냉각수가 쉴 새 없이 쏟아졌다.\n\n발사 125초 뒤 고도 64.5㎞. 누리호는 1단을 분리한다. 이어 위성을 감싼 덮개인 페어링과 2단이 차례로 떨어져 나간다. 누리호가 적도를 지나면 남태평양 팔라우 추적소에서 누리호의 비행 궤적과 동작 상태를 확인한다.\n\n발사 783초 뒤 고도 550㎞에 도달하면 주 탑재위성인 차세대 소형위성 2호가 분리된다. 차세대 소형위성 2호는 영상 레이더(SAR)를 탑재했다. 해상도 5m, 관측 폭 40㎞의 마이크로파로 지구를 관측한다. 광학카메라와 달리 빛과 구름의 영향을 받지 않는다.\n\n이후 20초 간격으로 벤처기업 져스텍과 루미르, 카이로스페이스가 제작한 큐브위성 3기가 차례로 분리된다. 각각 우주 방사선을 검출하고 광학카메라 성능을 검증한다. 우주쓰레기 경감 기술도 실증한다. 마지막에는 천문연에서 개발한 우주기상관측 군집(群集)위성 ‘도요샛’ 4기가 분리된다. 도요샛은 중량 10㎏ 이하 나노급 위성으로는 최초로 편대 비행을 시도하며 플라즈마 등 우주 날씨의 시공간적 변화를 관측하는 임무를 수행한다. 발사 1138초가 지나면 임무를 완수한 누리호가 비행을 종료한다.\n\n ○반복 발사 통해 신뢰도 높인다\n\n전날 누리호 3차 발사는 예정 시간을 2시간 14분 앞두고 연기됐다. 이처럼 발사를 눈앞에 두고 기술적 문제로 연기하는 일은 로켓 개발 과정에서 종종 있는 일이다. 작년 6월 누리호 2차 발사 때도 기립 상태에서 점검 중 문제가 발견돼 조립동으로 되돌아갔다. 액체헬륨 탱크 내부의 레벨 센서가 비정상적인 수치를 나타냈기 때문이다. 2009년 8월 ‘나로호(KSLV-1)’ 1차 발사 당시에도 압력 측정 관련 SW 오류로 이륙 7분56초를 앞두고 발사가 중단됐다. 나로호 3차 발사를 시도했던 2012년 11월에도 최종 발사 시간 발표 전 연료를 주입하는 연결 부위가 새는 문제가 발생해 발사가 미뤄졌다.\n\n우주 발사체는 첨단 기술의 집약체다. 반복 발사 운용을 통해 발사 과정을 최적화·안정화하고 발사체의 신뢰성을 높이는 것이 필수다. 정부는 2027년까지 네 차례에 걸친 추가 발사를 통해 한국형발사체 누리호의 신뢰도를 검증하고 체계종합기업 한화에어로스페이스 기술을 이전한다. 차세대 중형위성 3호와 초소형위성 2~11호 등이 다음 누리호에 탑재될 예정이다.\n\n누리호 성능을 개량한 차세대 발사체 개발사업도 진행한다. 차세대 발사체는 1단 100t급 이상 엔진 5기, 2단 10t급 이상 엔진 2기로 구성된 2단형 발사체로 개발될 예정이다. 2030년부터 세 차례 반복 발사를 통해 신뢰도를 검증한다.\n\n2032년 달 착륙선을 보내는 것이 최종 목표다.\n\n고흥(나로우주센터)=김진원 기자 jin1@hankyung.com\n\n네, 한국형발사체 누리호 발사 성공에 대한 Midjourney 텍스트 프롬프트는 다음과 같습니다.\n\n한국형발사체 누리호가 우주로 발사되는 모습을 나타내는 이미지를 생성해 주세요.\n\n한국형발사체 누리호가 성공적으로 발사되어 목표 궤도에 진입하는 모습을 나타내는 이미지를 생성해 주세요.\n한국형발사체 누리호가 성공적으로 발사되어 위성을 궤도에 올리는 모습을 나타내는 이미지를 생성해 주세요.\n\n이 프롬프트를 사용하여 한국형발사체 누리호 발사 성공에 대한 이미지를 생성할 수 있습니다."
  },
  {
    "objectID": "text_to_images.html#이미지-생성자",
    "href": "text_to_images.html#이미지-생성자",
    "title": "chatGPT",
    "section": "\n5.2 이미지 생성자",
    "text": "5.2 이미지 생성자\n\n\n스타일 적용 전\n스타일 적용 후\n한장\n\n\n\nSouth Korean launch vehicle Nuri successfully launches and enters its target orbit\n\n\n\n\n\n\nSouth Korean launch vehicle Nuri successfully launches and enters its target orbit, cinematic light, extreme detail, panoramic, Craig Mullins\n\n\n\n\n\n\nSouth Korean launch vehicle Nuri successfully launches and enters its target orbit, Max Ernst, volumetric light"
  },
  {
    "objectID": "math.html#latex-설치",
    "href": "math.html#latex-설치",
    "title": "chatGPT",
    "section": "\n2.1 LaTeX 설치",
    "text": "2.1 LaTeX 설치\ntinytex::install_tinytex() 명령어로 $\\LaTeX$을 설치한다.\n\n코드tinytex::install_tinytex()\n# 설치위치 확인\ntinytex::tinytex_root()"
  },
  {
    "objectID": "math.html#헬로월드",
    "href": "math.html#헬로월드",
    "title": "chatGPT",
    "section": "\n2.2 헬로월드",
    "text": "2.2 헬로월드\n코드를 작성하여 문서(PDF)를 작성하는 사례를 구현해보자. 한글을 PDF 문서로 작성하는 것은 다른 문제로 한글을 PDF로 표현할 경우 글꼴을 비롯한 한글문서 고유한 특성을 반영할 것이 필요하기 때문에 자세한 사항은 데이터 과학 글쓰기를 참고한다.\n\n코드writeLines(c(\n  '\\\\documentclass{article}',\n  '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n), 'pdf/test_eng.tex')\n\ntinytex::pdflatex('pdf/test_eng.tex')\n#&gt; [1] \"pdf/test_eng.pdf\""
  },
  {
    "objectID": "math.html#mathpix-패키지",
    "href": "math.html#mathpix-패키지",
    "title": "chatGPT",
    "section": "\n2.3 mathpix 패키지",
    "text": "2.3 mathpix 패키지\nOCR 작업을 위해서 과거 tesseract이 많이 사용되었으나 최근에는 AI 기술을 적용한 다양한 OCR 시스템이 소개되고 있다. 수식을 기계가 인식할 수 있는 형태로 인식하는 것은 다른 문제로 다양한 도구가 소개되고 있으나 mathpix도 성능이 좋은 도구중 하나로 과학기술분야 널리 사용되고 있다.\n\n\n\n코드library(mathpix)\nmathpix(\"images//integral.jpg\")\n\n\n\n\\[\n\\int \\frac { 4 x } { \\sqrt { x ^ { 2 } + 1 } } d x\n\\]"
  },
  {
    "objectID": "math.html#pdf-.png",
    "href": "math.html#pdf-.png",
    "title": "chatGPT",
    "section": "\n2.4 pdf → .png\n",
    "text": "2.4 pdf → .png\n\n2023년 수능 PDF 수학문제 파일을 이미지(.png) 파일로 변환시키자.\n\n\n\n\n\n\n\n\n코드library(pdftools)\n\npdf_convert(\"data/2교시_수학영역_문제지.pdf\", format = \"png\", pages=1, filenames = \"pdf/math_01.png\")\n\n\n\n코드math_01_png &lt;- mathpix::mathpix(\"pdf/math_01.png\", insert = FALSE)\n\n\n\\[\ng ( x ) = x ^ { 2 } f ( x )\n\\]\n\n코드math_01_png\n#&gt; [1] \"$$\\n g ( x ) = x ^ { 2 } f ( x ) \\n$$\""
  },
  {
    "objectID": "biz_number_API.html",
    "href": "biz_number_API.html",
    "title": "chatGPT",
    "section": "",
    "text": "출처: 삼주전자 웹사이트\n사업자 등록증은 사업을 영위하는 개인이나 법인이 자신의 사업을 정부에 공식적으로 등록한 증명서로 국세청이 이를 관리하며, 사업자 등록을 하면 사업자등록번호를 부여받게 되고 사업자 등록증에는 다음과 같은 정보가 포함된다.\n\n사업자 등록 번호: 사업자의 고유 식별 번호로 다른 사업자와 구분하기 위한 것이며, 사업 거래 시에 사용된다.\n사업자의 이름: 개인 사업자의 경우 개인의 이름, 법인의 경우 법인의 이름이 표기된다.\n사업의 종류: 사업자가 영위하는 사업의 종류를 나타낸다.\n사업장의 위치: 사업이 진행되는 주요 장소를 나타낸다."
  },
  {
    "objectID": "biz_number_API.html#r-코드-변환",
    "href": "biz_number_API.html#r-코드-변환",
    "title": "chatGPT",
    "section": "\n4.1 R 코드 변환",
    "text": "4.1 R 코드 변환\n\n\n프롬프트\n출력결과\n보완작업\n\n\n\n다음 `curl` 코드를 R 코드로 변환해주세요.\n\ncurl -X 'POST' \\\n  'https://api.odcloud.kr/api/nts-businessman/v1/status?serviceKey=GQMNLxxxxxxxxxxxxxxxxxxxxxx' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: GQMNLxxxxxxxxxxxxxxxxxxxxxx' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"b_no\": [\n    \"1320557431\"\n  ]\n}'\n\n\ncurl 명령은 HTTP 프로토콜을 사용하여 웹 서버와 상호 작용하는 데 사용되는 명령행 도구입니다. 이 명령을 R 코드로 변환하려면 httr 패키지의 POST 함수를 사용할 수 있습니다.\n아래는 주어진 curl 명령을 R 코드로 변환한 예입니다.\n```{r}\n\n# 필요한 패키지를 불러옵니다.\nlibrary(httr)\n\n# API endpoint와 필요한 헤더를 설정합니다.\nurl &lt;- \"https://api.odcloud.kr/api/nts-businessman/v1/status?serviceKey=GQMNLxxxxxxxxxxxxxxxxxxxxxx\"\nheaders &lt;- c(\n  'accept' = 'application/json',\n  'Authorization' = 'GQMNLxxxxxxxxxxxxxxxxxxxxxx',\n  'Content-Type' = 'application/json'\n)\n\n# 요청 본문을 설정합니다.\nbody &lt;- list(\n  \"b_no\" = c(\"1320557431\")\n)\n\n# POST 요청을 보냅니다.\nresponse &lt;- POST(url, add_headers(headers), body = body, encode = \"json\")\n\n# 응답을 확인합니다.\ncontent(response)\n\n```\n\n\nusethis::edit_r_environ() 함수를 사용해서 NTS_API_KEY를 .Renviron 파일에 숨긴다. 이를 통해 보안이 강화되지만 동일한 결과를 얻을 수 있게 작업이 완료되었다.\n\n코드library(tidyverse)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(httr)\n\nurl &lt;- glue::glue(\"https://api.odcloud.kr/api/nts-businessman/v1/status\",\n                  \"?serviceKey={Sys.getenv('NTS_API_KEY')}\")\n\nheaders &lt;- c(\n  'accept' = 'application/json',\n  'Content-Type' = 'application/json'\n)\n\nbody &lt;- list(\n  \"b_no\" = list(\"1320557431\")\n)\n\nresponse &lt;- POST(url, add_headers(.headers=headers), body=body, encode=\"json\")\n\n# print the response\nresult &lt;- content(response)\n\nresult_tbl &lt;- result$data %&gt;% data.frame()\n\nresult_tbl\n#&gt;         b_no      b_stt b_stt_cd              tax_type tax_type_cd end_dt\n#&gt; 1 1320557431 계속사업자       01 부가가치세 일반과세자          01       \n#&gt;   utcc_yn tax_type_change_dt invoice_apply_dt rbf_tax_type rbf_tax_type_cd\n#&gt; 1       N                                         해당없음              99"
  },
  {
    "objectID": "biz_number_API.html#함수작성",
    "href": "biz_number_API.html#함수작성",
    "title": "chatGPT",
    "section": "\n5.1 함수작성",
    "text": "5.1 함수작성\nget_status 함수를 작성해서 사업자번호를 넘기면 국세청 API를 통해 사업자 진위여부와 함께 과세유형정보도 확인가능하도록 기능을 추가한다.\n\n코드get_status &lt;- function(biz_number = \"1320557431\") {\n    url &lt;- glue::glue(\"https://api.odcloud.kr/api/nts-businessman/v1/status\",\n                    \"?serviceKey={Sys.getenv('NTS_API_KEY')}\")\n  \n  headers &lt;- c(\n    'accept' = 'application/json',\n    'Content-Type' = 'application/json'\n  )\n  \n  body &lt;- list(\n    \"b_no\" = list(biz_number)\n  )\n  \n  response &lt;- POST(url, add_headers(.headers=headers), body=body, encode=\"json\")\n  \n  # print the response\n  result &lt;- content(response)\n\n  result_tbl &lt;- result$data %&gt;% data.frame()\n\n  return(result_tbl)\n}\n\nget_status(\"1320557431\")\n#&gt;         b_no      b_stt b_stt_cd              tax_type tax_type_cd end_dt\n#&gt; 1 1320557431 계속사업자       01 부가가치세 일반과세자          01       \n#&gt;   utcc_yn tax_type_change_dt invoice_apply_dt rbf_tax_type rbf_tax_type_cd\n#&gt; 1       N                                         해당없음              99"
  },
  {
    "objectID": "biz_number_API.html#업체정보-대장",
    "href": "biz_number_API.html#업체정보-대장",
    "title": "chatGPT",
    "section": "\n5.2 업체정보 대장",
    "text": "5.2 업체정보 대장\n사업자등록번호를 포함한 업체정보가 담긴 엑셀파일을 준비하여 국세청 API에 넘겨 사업자등록진위 및 사업자 등록상태를 확인할 수 있도록 엑셀파일 전처리 작업을 수행한다.\n```{r}\nlibrary(readxl)\n\nmst_raw &lt;- read_excel(\"data/xxxx연구개발특구_기업현황_데이터 요청사항_230618.xlsx\", sheet = \"xxxx연구단지 입주기업\", skip = 1)\n\nmst_tbl &lt;- mst_raw %&gt;% \n  mutate(사업자번호 = str_remove_all(사업자번호, \"-\") %&gt;% str_squish(.))\n```\n함수형 프로그래밍 purrr 패키지 map() 함수를 사용해서 결과값을 사업자등록증 단위로 반환받고 그 결과를 표로 정리한다.\n```{r}\nmst_status &lt;- mst_tbl %&gt;% \n  mutate(result = map(사업자번호, get_status)) %&gt;% \n  select(회사명, 사업자번호, result) %&gt;% \n  mutate(상태 = map_chr(result, \"b_stt\"),\n         과세유형 = map_chr(result, \"tax_type\")) \n\nmst_status %&gt;% \n  select(회사명, 사업자번호, 상태, 과세유형) %&gt;% \n  ## 분석결과 표로 정리\n  count(상태, name=\"업체수\") %&gt;% \n  janitor::adorn_totals(name = \"합계\")\n```\n       상태 업체수\n                18\n 계속사업자    210\n     폐업자      1\n       합계    229"
  },
  {
    "objectID": "three_paradigm.html",
    "href": "three_paradigm.html",
    "title": "챗GPT",
    "section": "",
    "text": "1 챗GPT 시대 데이터 분석\n\nOpenAI 챗GPT Code Interpreter 플러그인\n\n\n노터블(Notable): EDA & ETL Made Easy (SQL, Python, & R)\n오픈소스 GPT-Code UI\nR\n\n\nRTutor.ai, GitHub 저장소\n\nhttps://chatlize.ai/\n\n\n\n2 Code Interpreter\n\n\n1단계\n2단계\n3단계\n4단계\n5단계 (데이터+프롬프트)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 Notable.ai\n\n4 심슨 패러독스\n\n챗GPT Code Interpreter : 채팅 이력\n\nJupyter Notebook 다운로드: penguin_analysis.ipynb\n\n\npenguin_analysis.ipynb → penguin_analysis.qmd\n\n명령어: $ quarto convert penguin_analysis.ipynb\n\n\n\n쿼토 컴파일: 바로가기\n\n\n`"
  },
  {
    "objectID": "penguin_analysis.html",
    "href": "penguin_analysis.html",
    "title": "Analysis of Penguin Data",
    "section": "",
    "text": "This notebook presents an analysis of a dataset containing measurements of penguins. The goal is to investigate the existence of Simpson’s Paradox in the data.\nSimpson’s Paradox is a phenomenon in probability and statistics, in which a trend appears in different groups of data but disappears or reverses when these groups are combined."
  },
  {
    "objectID": "penguin_analysis.html#import-necessary-libraries",
    "href": "penguin_analysis.html#import-necessary-libraries",
    "title": "Analysis of Penguin Data",
    "section": "Import Necessary Libraries",
    "text": "Import Necessary Libraries\n\n\n코드\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "penguin_analysis.html#load-the-dataset",
    "href": "penguin_analysis.html#load-the-dataset",
    "title": "Analysis of Penguin Data",
    "section": "Load the Dataset",
    "text": "Load the Dataset\n\n\n코드\n# Load the dataset\ndf = pd.read_csv('data/penguins.csv')"
  },
  {
    "objectID": "penguin_analysis.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "href": "penguin_analysis.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "title": "Analysis of Penguin Data",
    "section": "Check Correlations Within Each Species for Culmen Length and Depth",
    "text": "Check Correlations Within Each Species for Culmen Length and Depth\n\n\n코드\n# Check correlations within each species for culmen_length_mm and culmen_depth_mm\nspecies_list = df['species'].unique()\nfor species in species_list:\n    print(f\"Correlation within {species} species:\")\n    print(df[df['species'] == species][['bill_length_mm', 'bill_depth_mm']].corr())\n    print(\"\\n\")\n\n\nCorrelation within Adelie species:\n                bill_length_mm  bill_depth_mm\nbill_length_mm        1.000000       0.391492\nbill_depth_mm         0.391492       1.000000\n\n\nCorrelation within Gentoo species:\n                bill_length_mm  bill_depth_mm\nbill_length_mm        1.000000       0.643384\nbill_depth_mm         0.643384       1.000000\n\n\nCorrelation within Chinstrap species:\n                bill_length_mm  bill_depth_mm\nbill_length_mm        1.000000       0.653536\nbill_depth_mm         0.653536       1.000000"
  },
  {
    "objectID": "penguin_analysis.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "href": "penguin_analysis.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "title": "Analysis of Penguin Data",
    "section": "Calculate the Overall Correlation Between Culmen Length and Depth",
    "text": "Calculate the Overall Correlation Between Culmen Length and Depth\n\n\n코드\n# Calculate the overall correlation between bill_length_mm and bill_depth_mm\noverall_corr = df[['bill_length_mm', 'bill_depth_mm']].corr().iloc[0, 1]\noverall_corr\n\n\n-0.2350528703555336"
  },
  {
    "objectID": "penguin_analysis.html#create-scatter-plot",
    "href": "penguin_analysis.html#create-scatter-plot",
    "title": "Analysis of Penguin Data",
    "section": "Create Scatter Plot",
    "text": "Create Scatter Plot\n\n\n코드\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Overall regression line\nsns.regplot(x='bill_length_mm', y='bill_depth_mm', data=df, scatter=False, \n            line_kws={'color': 'black', 'label': \"Overall regression line\"})\n\n# Loop through each species\nfor species in species_list:\n    species_data = df[df['species'] == species]\n    sns.scatterplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, label=species)\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, scatter=False, \n                line_kws={'label': f\"{species} regression line\"})\n\nplt.title('Bill Depth vs Bill Length')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\n\n# Add legend\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "penguin_analysis.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "href": "penguin_analysis.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "title": "Analysis of Penguin Data",
    "section": "Create Separate Scatter Plots with Regression Lines for Each Species",
    "text": "Create Separate Scatter Plots with Regression Lines for Each Species\n\n\n코드\n# Create a figure and axis\nfig, axs = plt.subplots(3, 1, figsize=(10, 20))\n\n# Loop through each species\nfor ax, species in zip(axs, species_list):\n    species_data = df[df['species'] == species]\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, ax=ax, \n                line_kws={'label': f\"{species} regression line\"})\n    ax.set_title(f'{species} Penguins')\n    ax.set_xlabel('Bill Length (mm)')\n    ax.set_ylabel('Bill Depth (mm)')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "openAI_GPT.html#gpt-4",
    "href": "openAI_GPT.html#gpt-4",
    "title": "chatGPT",
    "section": "",
    "text": "GPT-4’s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4는 GPT-3보다 10배 많은 1조 8천억 개의 파라미터, 120개 계층을 갖는 아키텍쳐를 갖고 있다. OpenAI는 16개 전문가(MoE, Mixture of Experts)와 1,100억 개의 다층 퍼셉트론 파라미터를 갖는 전문가 혼합 모델로 구현되었으며, 13조 개의 토큰이 포함된 학습 데이터셋을 사용했다. 훈련 비용은 3,200 ~ 6,300만 달러로 GPT-4는 이전 버전보다 추론 비용이 약 3배 더 높지만, 분산 데이터센터에서 128개 GPU 클러스터 위에서 동작하는 추론 아키텍쳐를 갖고 있다.\n\n\nThe Ship of Theseus\n\nOpenAI의 전략은 테세우스의 배(Theseus’s Ship) 와 유사하다고 볼 수 있다."
  },
  {
    "objectID": "openAI_GPT.html#인터페이스",
    "href": "openAI_GPT.html#인터페이스",
    "title": "chatGPT",
    "section": "\n3.1 인터페이스",
    "text": "3.1 인터페이스\nOpenAI API는 OpenAI에서 개발한 GPT-3, GPT-4 모델을 통해 AI 기능을 개발하고 있는 다양한 제품과 서비스에 담아내는 과정이다. 제품과 서비스를 개발하면서 머리 뿐만 아니라 다른 다양한 재료도 데이터, API 혹은 파일 형태로 담아낼 수 있다."
  },
  {
    "objectID": "openAI_GPT.html#고려사항",
    "href": "openAI_GPT.html#고려사항",
    "title": "chatGPT",
    "section": "\n3.2 고려사항",
    "text": "3.2 고려사항\nOpenAI는 3월에 채팅 완료(Chat Completion) API를 도입했으며, 현재 API GPT 사용량의 97%를 차지하고 있다.\n2020년 6월에 도입된 초기 Completion API는 언어 모델과 상호 작용할 수 있는 자유형 텍스트 프롬프트를 제공하기 위해 도입되었다. 이후 보다 구조화된 프롬프트 인터페이스(structured prompt interface)를 통해 더 나은 결과를 제공할 수 있다는 사실을 알게 되었다. 채팅 기반 패러다임은 이전의 사용 사례와 새로운 대화 요구 사항의 대부분을 처리하는 동시에 더 높은 유연성과 구체성을 제공하는 강력한 것으로 입증되었다. 특히 채팅 완료 API의 구조화된 인터페이스(예: 시스템 메시지, 함수 호출)와 멀티턴(Multi-turn) 대화 기능을 통해 개발자는 대화 환경과 광범위한 완료 작업을 구축할 수 있다.\n\n\n\n\n\n\n\n구분\n이전 모형\n신 모형\n\n\n\nChat Completion API\ngpt-3.5-turbo\ngpt-3.5-turbo\n\n\nCompletion API\nada\nada-002\n\n\nCompletion API\nbabbage\nbabbage-002\n\n\nCompletion API\ncurie\ncurie-002\n\n\nCompletion API\ndavinci\ndavinci-002\n\n\nCompletion API\ndavinci-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ncurie-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-ada-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-babbage-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-curie-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-002\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-003\ngpt-3.5-turbo-instruct\n\n\nEmbeddings Model\ncode-search-ada-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-ada-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-ada-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-babbage-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-curie-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-davinci-001\ntext-embedding-ada-002"
  },
  {
    "objectID": "openAI_GPT.html#api",
    "href": "openAI_GPT.html#api",
    "title": "chatGPT",
    "section": "\n3.3 API",
    "text": "3.3 API\nOpenAI는 크게 3가지 서비스를 제공하고 있다.\n\n챗GPT\nDall-E\nAPI\n\nAPI 문서를 통해 다양한 API 서비스를 확인할 수 있다."
  },
  {
    "objectID": "openAI_GPT.html#계정생성",
    "href": "openAI_GPT.html#계정생성",
    "title": "chatGPT",
    "section": "\n5.1 계정생성",
    "text": "5.1 계정생성\nOpenAI API 생성 웹사이트에서 계정을 생성한다."
  },
  {
    "objectID": "openAI_GPT.html#api-key-발급",
    "href": "openAI_GPT.html#api-key-발급",
    "title": "chatGPT",
    "section": "\n5.2 API KEY 발급",
    "text": "5.2 API KEY 발급\nAPI keys 웹사이트에서 API KEY를 발급받는다."
  },
  {
    "objectID": "openAI_GPT.html#openai-패키지-설치",
    "href": "openAI_GPT.html#openai-패키지-설치",
    "title": "chatGPT",
    "section": "\n5.3 openai 패키지 설치",
    "text": "5.3 openai 패키지 설치\nAPI Reference 안내에 따라 openai 패키지를 설치한다.\n$ pip install openai"
  },
  {
    "objectID": "openAI_GPT.html#헬로월드",
    "href": "openAI_GPT.html#헬로월드",
    "title": "chatGPT",
    "section": "\n5.4 헬로월드",
    "text": "5.4 헬로월드\nAPI키를 직접 파이썬 프로그램에 명시하고 결과를 확인한다.\n\nimport openai\n\nopenai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxx\"\n\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"OpenAI API가 뭔가요?\"\n)\n\nprint(response)\n\n{\n  \"choices\": [\n    {\n      \"finish_reason\": \"length\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"text\": \"\\n\\nOpenAI API\\ub294 \\uc778\\uacf5\"\n    }\n  ],\n  \"created\": 1689745304,\n  \"id\": \"cmpl-7duESieoaT985f4IKPskfcYQ3AH7F\",\n  \"model\": \"text-davinci-003\",\n  \"object\": \"text_completion\",\n  \"usage\": {\n    \"completion_tokens\": 14,\n    \"prompt_tokens\": 15,\n    \"total_tokens\": 29\n  }\n}"
  },
  {
    "objectID": "openAI_GPT.html#보안강화",
    "href": "openAI_GPT.html#보안강화",
    "title": "chatGPT",
    "section": "\n5.5 보안강화",
    "text": "5.5 보안강화\n\nimport requests\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n#&gt; True\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  prompt=\"OpenAI API가 뭔가요?\"\n)\n\nprint(response[\"choices\"][0]['text'])\n\nOpenAI API는 OpenAI가"
  },
  {
    "objectID": "openAI_api.html",
    "href": "openAI_api.html",
    "title": "챗GPT",
    "section": "",
    "text": "ChatGPT는 간단히 말해 생성형 사전 학습된 트랜스포머(Generative Pre-trained Transformer)의 약자로, OpenAI의 GPT-3/GPT-4 거대 언어 모델 제품군에 기반한 챗봇으로 지도학습과 강화학습기법을 적용하여 미세조정(fine-tuned)된 제품이자 서비스다.\n\nGPT-4’s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4는 GPT-3보다 10배 많은 1조 8천억 개의 파라미터, 120개 계층을 갖는 아키텍쳐를 갖고 있다. OpenAI는 16개 전문가(MoE, Mixture of Experts)와 1,100억 개의 다층 퍼셉트론 파라미터를 갖는 전문가 혼합 모델로 구현되었으며, 13조 개의 토큰이 포함된 학습 데이터셋을 사용했다. 훈련 비용은 3,200 ~ 6,300만 달러로 GPT-4는 이전 버전보다 추론 비용이 약 3배 더 높지만, 분산 데이터센터에서 128개 GPU 클러스터 위에서 동작하는 추론 아키텍쳐를 갖고 있다.\n\n\nThe Ship of Theseus\n\nOpenAI의 전략은 테세우스의 배(Theseus’s Ship) 와 유사하다고 볼 수 있다.\n\nOpenAI GPT-3 모형은 크게 세가지가 있다.\n\nGPT-3/GPT-4\nCodex\n콘텐츠 필터 모델\n\nGPT-3은 자연어 처리 및 생성을 담당하는 모델로 인간의 언어 즉, 자연어처럼 보이는 텍스트를 이해할 수 있다. 한걸음 더 들어가면 속도와 성능에 따라 4가지 모델(A, B, C, D)로 구분된다.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\n성능기준으로 보면 다음과 같이 정렬할 수 있는데 비용도 그에 따라 높아진다는 의미도 함축한다.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\n따라서, OpenAI는 다빈치 모델(text-davinci-003)을 통해 원하는 결과를 얻은 후에 다른 모델을 사용해 볼 것을 권장하는데 이유는 훨씬 저렴한 비용으로 많은 수의 유사한 작업을 수행할 수 있기 때문이다.\n\n2,048개의 토큰 및 2019년 10월까지의 데이터 학습하여 이후 모형과 비교하여 정확도나 성능에서 다소 밀리는 모습이지만 최적화를 통해 매우 빠르고 비용이 가장 저렴하다.\n\n2,048개의 토큰과 2019년 10월까지의 데이터 학습되었고 간단한 분류와 의미론적 분류에 효과적이다.\n\n최대 2048개의 토큰을 지원하며 text-davinci-003 다음으로 뛰어난 성능을 보이는 GPT-3 모델이다. 2019년 10월까지의 데이터로 학습되었기 때문에 text-davinci-003보다 정확도가 떨어지지만, 번역, 복잡한 분류, 텍스트 분석 및 요약에 좋은 성능을 보이고 있어 text-davinci-003와 비교하여 가성비가 높다고 평가되고 있다.\n\n2021년 9월까지의 데이터로 훈련되었기 때문에 최신 정보를 제공하지 못한다는 한계는 있지만, 앞선 GPT-3 모형과 비교하여 더 높은 품질을 제공한다. 장점 중 하나는 최대 4,000개 토큰까지 요청할 수 있다는 점이 이전 모형과 큰 차별점이 된다.\n\n코덱스는 프로그래밍 코드 이해 및 생성을 위한 것으로 code-davinci-002와 code-cushman-001가 있다. 또한, 코덱스는 GitHub Copilot을 구동하는 모델이기도 하다. 파이썬, 자바스크립트, 고, 펄, PHP, 루비, 스위프트, 타입스크립트, SQL, 셸 등 12개 이상의 프로그래밍 언어를 지원할 뿐만 아니라 자연어로 표현된 주석(comment)를 이해하고 사용자를 대신하여 요청된 작업을 수행할 수 있다.\n\n복잡한 작업을 수행하는 데 있어서는 code-davinci-002가 더 강력하지만, 많은 코드 생성 작업을 수행할 수 있고 code-davinci-002 보다 더 빠르고 저렴하다는 장점이 있다.\n\n자연어를 코드로 번역하는 데 탁월할 뿐만 아니라 코드를 자동 완성할 뿐만 아니라 보충 요소 삽입도 지원한다. 최대 8,000개의 토큰을 처리할 수 있으며 2021년 6월까지의 데이터로 학습되었다.\n\n민감한 콘텐츠 제거하기 위한 필터 모형이다. 민감하거나 안전하지 않을 수 있는 API 생성 텍스트를 감지할 수 있다. 사용자가 사용할 AI 응용프로그램을 개발할 경우, 필터를 사용하여 모델이 부적절한 콘텐츠를 반환하는지 감지할 수 있다. 이 필터는 텍스트를 다음 3가지 범주로 나눈다.\n\n안전(safe)\n민감(sensitive)\n안전하지 않음(unsafe)"
  },
  {
    "objectID": "openAI_api.html#gpt-4",
    "href": "openAI_api.html#gpt-4",
    "title": "챗GPT",
    "section": "",
    "text": "GPT-4’s Leaked Details Shed Light on its Massive Scale and Impressive Architecture\nGPT-4는 GPT-3보다 10배 많은 1조 8천억 개의 파라미터, 120개 계층을 갖는 아키텍쳐를 갖고 있다. OpenAI는 16개 전문가(MoE, Mixture of Experts)와 1,100억 개의 다층 퍼셉트론 파라미터를 갖는 전문가 혼합 모델로 구현되었으며, 13조 개의 토큰이 포함된 학습 데이터셋을 사용했다. 훈련 비용은 3,200 ~ 6,300만 달러로 GPT-4는 이전 버전보다 추론 비용이 약 3배 더 높지만, 분산 데이터센터에서 128개 GPU 클러스터 위에서 동작하는 추론 아키텍쳐를 갖고 있다.\n\n\nThe Ship of Theseus\n\nOpenAI의 전략은 테세우스의 배(Theseus’s Ship) 와 유사하다고 볼 수 있다."
  },
  {
    "objectID": "openAI_api.html#gpt-3",
    "href": "openAI_api.html#gpt-3",
    "title": "챗GPT",
    "section": "",
    "text": "OpenAI GPT-3 모형은 크게 세가지가 있다.\n\nGPT-3/GPT-4\nCodex\n콘텐츠 필터 모델\n\nGPT-3은 자연어 처리 및 생성을 담당하는 모델로 인간의 언어 즉, 자연어처럼 보이는 텍스트를 이해할 수 있다. 한걸음 더 들어가면 속도와 성능에 따라 4가지 모델(A, B, C, D)로 구분된다.\n\ntext-davinci-003\ntext-curie-001\ntext-babbage-001\ntext-ada-001\n\n성능기준으로 보면 다음과 같이 정렬할 수 있는데 비용도 그에 따라 높아진다는 의미도 함축한다.\ntext-davinci-003 &gt; text-curie-001 &gt; text-babbage-001 &gt; text-ada-001\n따라서, OpenAI는 다빈치 모델(text-davinci-003)을 통해 원하는 결과를 얻은 후에 다른 모델을 사용해 볼 것을 권장하는데 이유는 훨씬 저렴한 비용으로 많은 수의 유사한 작업을 수행할 수 있기 때문이다.\n\n2,048개의 토큰 및 2019년 10월까지의 데이터 학습하여 이후 모형과 비교하여 정확도나 성능에서 다소 밀리는 모습이지만 최적화를 통해 매우 빠르고 비용이 가장 저렴하다.\n\n2,048개의 토큰과 2019년 10월까지의 데이터 학습되었고 간단한 분류와 의미론적 분류에 효과적이다.\n\n최대 2048개의 토큰을 지원하며 text-davinci-003 다음으로 뛰어난 성능을 보이는 GPT-3 모델이다. 2019년 10월까지의 데이터로 학습되었기 때문에 text-davinci-003보다 정확도가 떨어지지만, 번역, 복잡한 분류, 텍스트 분석 및 요약에 좋은 성능을 보이고 있어 text-davinci-003와 비교하여 가성비가 높다고 평가되고 있다.\n\n2021년 9월까지의 데이터로 훈련되었기 때문에 최신 정보를 제공하지 못한다는 한계는 있지만, 앞선 GPT-3 모형과 비교하여 더 높은 품질을 제공한다. 장점 중 하나는 최대 4,000개 토큰까지 요청할 수 있다는 점이 이전 모형과 큰 차별점이 된다."
  },
  {
    "objectID": "openAI_api.html#코덱스codex",
    "href": "openAI_api.html#코덱스codex",
    "title": "챗GPT",
    "section": "",
    "text": "코덱스는 프로그래밍 코드 이해 및 생성을 위한 것으로 code-davinci-002와 code-cushman-001가 있다. 또한, 코덱스는 GitHub Copilot을 구동하는 모델이기도 하다. 파이썬, 자바스크립트, 고, 펄, PHP, 루비, 스위프트, 타입스크립트, SQL, 셸 등 12개 이상의 프로그래밍 언어를 지원할 뿐만 아니라 자연어로 표현된 주석(comment)를 이해하고 사용자를 대신하여 요청된 작업을 수행할 수 있다.\n\n복잡한 작업을 수행하는 데 있어서는 code-davinci-002가 더 강력하지만, 많은 코드 생성 작업을 수행할 수 있고 code-davinci-002 보다 더 빠르고 저렴하다는 장점이 있다.\n\n자연어를 코드로 번역하는 데 탁월할 뿐만 아니라 코드를 자동 완성할 뿐만 아니라 보충 요소 삽입도 지원한다. 최대 8,000개의 토큰을 처리할 수 있으며 2021년 6월까지의 데이터로 학습되었다."
  },
  {
    "objectID": "openAI_api.html#콘텐츠-필터",
    "href": "openAI_api.html#콘텐츠-필터",
    "title": "챗GPT",
    "section": "",
    "text": "민감한 콘텐츠 제거하기 위한 필터 모형이다. 민감하거나 안전하지 않을 수 있는 API 생성 텍스트를 감지할 수 있다. 사용자가 사용할 AI 응용프로그램을 개발할 경우, 필터를 사용하여 모델이 부적절한 콘텐츠를 반환하는지 감지할 수 있다. 이 필터는 텍스트를 다음 3가지 범주로 나눈다.\n\n안전(safe)\n민감(sensitive)\n안전하지 않음(unsafe)"
  },
  {
    "objectID": "openAI_api.html#인터페이스",
    "href": "openAI_api.html#인터페이스",
    "title": "챗GPT",
    "section": "\n2.1 인터페이스",
    "text": "2.1 인터페이스\nOpenAI API는 OpenAI에서 개발한 GPT-3, GPT-4 모델을 통해 AI 기능을 개발하고 있는 다양한 제품과 서비스에 담아내는 과정이다. 제품과 서비스를 개발하면서 머리 뿐만 아니라 다른 다양한 재료도 데이터, API 혹은 파일 형태로 담아낼 수 있다."
  },
  {
    "objectID": "openAI_api.html#고려사항",
    "href": "openAI_api.html#고려사항",
    "title": "챗GPT",
    "section": "\n2.2 고려사항",
    "text": "2.2 고려사항\nOpenAI는 3월에 채팅 완료(Chat Completion) API를 도입했으며, 현재 API GPT 사용량의 97%를 차지하고 있다.\n2020년 6월에 도입된 초기 Completion API는 언어 모델과 상호 작용할 수 있는 자유형 텍스트 프롬프트를 제공하기 위해 도입되었다. 이후 보다 구조화된 프롬프트 인터페이스(structured prompt interface)를 통해 더 나은 결과를 제공할 수 있다는 사실을 알게 되었다. 채팅 기반 패러다임은 이전의 사용 사례와 새로운 대화 요구 사항의 대부분을 처리하는 동시에 더 높은 유연성과 구체성을 제공하는 강력한 것으로 입증되었다. 특히 채팅 완료 API의 구조화된 인터페이스(예: 시스템 메시지, 함수 호출)와 멀티턴(Multi-turn) 대화 기능을 통해 개발자는 대화 환경과 광범위한 완료 작업을 구축할 수 있다.\n\n\n\n\n\n\n\n구분\n이전 모형\n신 모형\n\n\n\nChat Completion API\ngpt-3.5-turbo\ngpt-3.5-turbo\n\n\nCompletion API\nada\nada-002\n\n\nCompletion API\nbabbage\nbabbage-002\n\n\nCompletion API\ncurie\ncurie-002\n\n\nCompletion API\ndavinci\ndavinci-002\n\n\nCompletion API\ndavinci-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ncurie-instruct-beta\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-ada-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-babbage-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-curie-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-001\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-002\ngpt-3.5-turbo-instruct\n\n\nCompletion API\ntext-davinci-003\ngpt-3.5-turbo-instruct\n\n\nEmbeddings Model\ncode-search-ada-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-ada-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-code-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ncode-search-babbage-text-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-ada-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-babbage-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-curie-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-doc-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-search-davinci-query-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-ada-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-babbage-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-curie-001\ntext-embedding-ada-002\n\n\nEmbeddings Model\ntext-similarity-davinci-001\ntext-embedding-ada-002"
  },
  {
    "objectID": "openAI_api.html#api",
    "href": "openAI_api.html#api",
    "title": "챗GPT",
    "section": "\n2.3 API",
    "text": "2.3 API\nOpenAI는 크게 3가지 서비스를 제공하고 있다.\n\n챗GPT\nDall-E\nAPI\n\nAPI 문서를 통해 다양한 API 서비스를 확인할 수 있다."
  },
  {
    "objectID": "openAI_api.html#텍스트-벡터-표현",
    "href": "openAI_api.html#텍스트-벡터-표현",
    "title": "챗GPT",
    "section": "\n5.1 텍스트 벡터 표현",
    "text": "5.1 텍스트 벡터 표현\ntext-embedding-ada-002 모델은 빠르고 가성비가 뛰어난 임베딩 모델이다. “대한민국 수도는 서울입니다.” 이라는 문서를 벡터로 표현하면 다음과 같다. 즉, 1,536 차원을 갖는 공간에 하나의 점으로 표현될 수 있다.\n\nimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"대한민국 수도는 서울입니다.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'벡터길이: {len(seoul_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {seoul_embedding[:10]}')\n#&gt; 벡터 일부: [0.014582998119294643, -0.018063032999634743, 0.004872684367001057, -0.013805408962070942, -0.031180081889033318, 0.025176068767905235, -0.034519895911216736, 0.011357911862432957, -0.007960736751556396, -0.0020682618487626314]\n\n마찬가지로 일본의 수도 도쿄도 벡터로 표현할 수 있다.\n\ntokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"일본 수도는 동경입니다.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'벡터길이: {len(tokyo_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {tokyo_embedding[:10]}')\n#&gt; 벡터 일부: [0.010957648046314716, -0.013234060257673264, 0.009729413315653801, -0.011890077032148838, -0.03179261088371277, 0.03436483070254326, -0.029786281287670135, 0.008629790507256985, 0.01711810939013958, -0.0014733985299244523]"
  },
  {
    "objectID": "openAI_api_apps.html",
    "href": "openAI_api_apps.html",
    "title": "챗GPT",
    "section": "",
    "text": ".env 파일에 OpenAI API-KEY 를 저장한 경우 .gitignore 에 .env를 기록하여 협업과 공개를 할 경우 주요 정보가 외부에 노출 되지 않도록 주의한다.\n\nGitHub 저장소 OpenAI Python Library의 openai 파이썬 패키지를 설치한 후 버전을 확인한다.\n\n코드! pip show openai\n\nName: openai\nVersion: 0.27.2\nSummary: Python client library for the OpenAI API\nHome-page: https://github.com/openai/openai-python\nAuthor: OpenAI\nAuthor-email: support@openai.com\nLicense: \nLocation: c:\\miniconda\\envs\\r-reticulate\\lib\\site-packages\nRequires: aiohttp, requests, tqdm\nRequired-by: \n\n\n\ngpt-3.5-turbo 모형은 속도가 빠르고 API 호출 당 가격이 저렴하지만, 성능이 gpt-4 보다 낮은 것으로 알려져 있다. max_tokens 크기를 달리하여 API 반환길이를 조절할 수 있고, temperature 값을 달리하여 사실에 보다 가까운 값을 얻고자 할 경우 0으로 그렇지 않고 다양한 창의적인 응답을 원할 경우 0 보다 큰 값을 지정한다.\n\n코드import openai\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\nresponse = ChatCompletion.create(\n  model       = \"gpt-4\",\n  messages    = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"파이썬하고 R 하고 싸우면 누가 이겨?\"}\n  ],\n  max_tokens   = 100,\n  temperature  = 0\n)\n\nprint(response[\"choices\"][0]['message']['content'])\n\n\n파이썬과 R은 프로그래밍 언어로, 싸우는 것이 아니라 각각의 특성과 용도에 따라 사용됩니다. \n\n파이썬은 범용 프로그래밍 언어로, 웹 개발, 데이터 분석, 인공 지능 등 다양한 분야에서 사용됩니다."
  },
  {
    "objectID": "openAI_api_apps.html#openai-패키지",
    "href": "openAI_api_apps.html#openai-패키지",
    "title": "챗GPT",
    "section": "",
    "text": "GitHub 저장소 OpenAI Python Library의 openai 파이썬 패키지를 설치한 후 버전을 확인한다.\n\n코드! pip show openai\n\nName: openai\nVersion: 0.27.2\nSummary: Python client library for the OpenAI API\nHome-page: https://github.com/openai/openai-python\nAuthor: OpenAI\nAuthor-email: support@openai.com\nLicense: \nLocation: c:\\miniconda\\envs\\r-reticulate\\lib\\site-packages\nRequires: aiohttp, requests, tqdm\nRequired-by:"
  },
  {
    "objectID": "openAI_api_apps.html#gpt-4-모델",
    "href": "openAI_api_apps.html#gpt-4-모델",
    "title": "챗GPT",
    "section": "",
    "text": "gpt-3.5-turbo 모형은 속도가 빠르고 API 호출 당 가격이 저렴하지만, 성능이 gpt-4 보다 낮은 것으로 알려져 있다. max_tokens 크기를 달리하여 API 반환길이를 조절할 수 있고, temperature 값을 달리하여 사실에 보다 가까운 값을 얻고자 할 경우 0으로 그렇지 않고 다양한 창의적인 응답을 원할 경우 0 보다 큰 값을 지정한다.\n\n코드import openai\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\nresponse = ChatCompletion.create(\n  model       = \"gpt-4\",\n  messages    = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"파이썬하고 R 하고 싸우면 누가 이겨?\"}\n  ],\n  max_tokens   = 100,\n  temperature  = 0\n)\n\nprint(response[\"choices\"][0]['message']['content'])\n\n\n파이썬과 R은 프로그래밍 언어로, 싸우는 것이 아니라 각각의 특성과 용도에 따라 사용됩니다. \n\n파이썬은 범용 프로그래밍 언어로, 웹 개발, 데이터 분석, 인공 지능 등 다양한 분야에서 사용됩니다."
  },
  {
    "objectID": "openAI_api_apps.html#연설문-낭독",
    "href": "openAI_api_apps.html#연설문-낭독",
    "title": "챗GPT",
    "section": "\n5.1 연설문 낭독",
    "text": "5.1 연설문 낭독\n‘제84주년 3.1절’ 기념행사에서 노무현 대통령이 낭독한 연설문을 요약하면 다음과 같다.\n\n3.1절을 맞아 일제에 항거한 애국선열들께 감사와 경의 표함. 국민통합과 개혁으로 평화와 번영의 동북아시대를 열어가고 자랑스런 대한민국을 우리 후손에게 물려줄 것을 연설했다.\n\nAudacity 프로그램에서 불필요한 부분 삭제하고 해당 연설문만 추출하여 .mp3 파일로 준비한다.\n\n코드library(av)\nlibrary(embedr)\n\nembedr::embed_audio(\"data/제84주년_31절_기념사_노무현.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "openAI_api_apps.html#mp3-텍스트",
    "href": "openAI_api_apps.html#mp3-텍스트",
    "title": "챗GPT",
    "section": "\n5.2 .mp3 → 텍스트",
    "text": "5.2 .mp3 → 텍스트\nOpenAI Whisper API를 사용하여 음성을 TXT로 변환하는 작업을 수행한다. .mp3 파일을 준비하고,Audio.transcribe() 함수를 사용하여 .txt 텍스트 파일로 저장한다.\n\n코드import openai\nfrom dotenv import load_dotenv\nimport os\n\n# API KEY ----------------------\nload_dotenv()\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\n# STT --------------------------\n\nspeech_file = open(\"data/제84주년_31절_기념사_노무현.mp3\", \"rb\")\n\nresponse = openai.Audio.transcribe(\"whisper-1\", speech_file)\n\n\nwith open(\"data/stt_audio.txt\", \"w\") as file:\n    file.write(response[\"text\"])"
  },
  {
    "objectID": "openAI_api_apps.html#후처리",
    "href": "openAI_api_apps.html#후처리",
    "title": "챗GPT",
    "section": "\n5.3 후처리",
    "text": "5.3 후처리\nSTT를 통해 나온 텍스트는 사람이 읽기에는 가독성이 무척 떨어지는 텍스트에 불과하다. 이를 읽을 수 있도록 후처리를 한다.\n\n\n음성원고 원문\nWhisper 텍스트\n챗 GPT 후가공\nWhisper 텍스트\n\n\n\n존경하는 국민 여러분,\n오늘 여든 네 번째 3, 1절을 맞아 나라를 위해 희생하고 헌신하신 애국선열들께 한없는 감사와 경의를 표합니다. 독립유공자와 유가족 여러분에게도 존경과 감사의 말씀을 드립니다.\n기미년 오늘, 우리는 일제의 총칼에 맞서 맨주먹으로 분연히 일어섰습니다. 대한독립 만세 소리가 전국 방방곡곡을 뒤덮었고, 우리는 자주독립 의지를 세계만방에 알렸습니다. 3, 1운동을 계기로 국내외의 독립투쟁은 더욱 힘차게 전개되었습니다. 상해에 대한민국 임시정부가 세워졌고, 우리는 마침내 빼앗긴 국권을 되찾았습니다.\n3, 1정신은 끊임없는 도전을 슬기롭게 극복해 온 우리 민족의 자랑입니다. 우리는 이러한 빛나는 정신을 계승하여 전쟁의 폐허를 딛고 세계 12위의 경제강국으로 발돋움했습니다. 4, 19 혁명과 광주민주화운동, 6월 민주항쟁을 거쳐 민주주의와 인권을 쟁취해 냈습니다. 오늘의 참여정부는 바로 그 위대한 역사의 연장선 위에 서 있습니다.\n참여정부의 출범으로 이제 아픔의 근, 현대사는 막을 내리게 되었습니다. 우리의 지난날은 선열들의 고귀한 희생에도 불구하고 좌절과 굴절을 겪어야 했습니다. 정의는 패배했고 기회주의가 득세했습니다.\n그러나 이제 비로소 역사적 전환점이 마련되었습니다. 국민이 진정 주인으로 대접받는 시대가 열린 것입니다.\n참여정부에서는 권력에 아부하는 사람들이 더 이상 설 땅이 없을 것입니다. 오로지 성실하게 일하고 정정당당하게 승부하는 사람들이 성공하는 시대가 열릴 것입니다. 그것이 바로 선열들의 희생에 보답하는 길이자 저와 참여정부에게 주어진 역사적 소명입니다.\n국민 여러분,\n지금 우리는 세계사의 새로운 흐름과 마주하고 있습니다. 동북아 시대의 도래가 바로 그것입니다. 동북아시아는 근대 이후 세계의 변방으로만 머물러 왔습니다. 그러나 이제 유럽연합, 북미지역과 함께 세계경제의 3대 축으로 부상하고 있습니다. 앞으로 20년 후에는 세계경제의 3분의 1을 차지하게 된다는 전망도 있습니다. 민족웅비의 크나큰 기회가 우리에게 다가오고 있는 것입니다.\n우리는 동북아시대의 중심국가로 도약할 수 있는 충분한 조건을 갖추고 있습니다. 우선, 지리적으로 중심에 자리잡고 있습니다. 서울에서 3시간의 비행거리 안에 인구 100만 이상의 도시가 마흔 세 개나 됩니다. 중국과 러시아의 인력과 자원, 그리고 일본의 기술을 접목할 수 있는 유리한 위치입니다. 대륙과 해양을 잇는 지정학적 이점도 가지고 있습니다. 하늘과 바다와 땅에 걸친 물류와, 세계 일류의 정보화 기반과 역량을 두루 갖추고 있습니다.\n한반도는 더 이상 세계의 변방이 아닙니다. 남북 철도가 연결되고 철의 실크로드가 열리면 광활한 대륙을 향해 나아갈 수 있습니다. 그 곳에는 중국대륙이라는 새로운 기회가 기다리고 있습니다. 시베리아와 중앙아시아의 무한한 자원도 있습니다.\n한반도가 대륙과 해양을 잇는 물류와 금융과 생산 거점으로 거듭나게 됩니다. 이것이 바로 우리 앞에 있는 미래입니다. 우리에게는 이를 현실로 만들어야 하는 책무가 주어져 있습니다.\n존경하는 국민 여러분,\n그러나 동북아 중심국가로 나아가기 위해서는 반드시 해야 할 일이 있습니다. 한반도에 평화를 정착시키는 일입니다. 남북이 대립하며 한반도에 긴장이 고조되는 한, 동북아 중심국가의 꿈은 실현될 수 없습니다. 동북아의 평화와 번영도 기대하기 어렵습니다.\n그동안 우리는 한반도에 평화를 정착시키기 위해 많은 노력을 기울여 왔습니다. 남북간에 대화와 교류가 빈번해졌고 이산가족이 만나고 있습니다. 최근에는 육로도 열렸습니다.\n그러나 아직 풀어야 할 숙제가 많습니다. 특히 북핵 문제는 시급히 해결해야 할 과제입니다.\n저는 북한의 핵 개발에 단호히 반대합니다. 그러나 이 문제는 반드시 평화적으로 해결되어야 합니다. 어떠한 이유로든 한반도의 평화가 깨어진다면, 우리는 그 엄청난 재앙을 감당할 수 없습니다. 한반도의 평화와 국민의 안전을 지키는 것은 대통령의 가장 큰 책무입니다.\n앞으로 남북관계는 국민 여러분께 소상히 보고 드리고, 국민적 합의를 바탕으로 추진해 나가겠습니다. 야당의 협력도 적극적으로 구해나갈 것입니다. 미국과 일본, 중국, 러시아 등 주변국과, EU를 비롯한 국제사회와도 능동적으로 협력해나갈 것입니다.\n국민 여러분,\n한반도에 평화를 정착시키는 일 못지 않게 중요한 것은 국민의 힘을 하나로 모으는 일입니다. 84년 전 오늘, 우리의 선열들은 한마음 한뜻으로 독립운동에 나섰습니다. 빈부와 귀천, 남녀와 노소, 지역과 종교의 차이는 없었습니다. 나라의 독립과 민족의 자존심을 되찾는 데 하나가 되었습니다.\n오늘을 사는 우리도 지역과 계층과 세대를 넘어 하나가 되어야 합니다. 내부에 분열과 반목이 있으면 세계경쟁에서 뒤쳐질 수밖에 없습니다. 국권까지 상실했던 100년 전의 실패가 되풀이될 수도 있습니다. 지금이야말로 3, 1정신을 되돌아보며 역사의 교훈을 되새겨야 할 때입니다.\n마음속에 지역갈등의 응어리가 있다면 가슴을 열고 풀어야 합니다. 어른은 젊은이의 목소리에 귀기울이고 젊은이는 어른의 경험을 구해야 합니다. 차별 받고 소외되어 온 사람들에게 더 많은 관심과 노력을 기울여야 합니다. 국민 모두가 참된 주인으로서 국정에 참여하고, 온 국민의 힘을 하나로 모으는 국민참여시대를 힘차게 열어가야겠습니다.\n개혁 또한 멈출 수 없는 우리 시대의 과제입니다. 무엇보다 정치와 행정이 바뀌어야 합니다. 이른바 몇몇 ’권력기관’은 그동안 정권을 위해 봉사해 왔던 것이 사실입니다. 그래서 내부의 질서가 무너지고 국민의 신뢰를 잃었습니다. 이제 이들 ’권력기관’은 국민을 위한 기관으로 거듭나야 합니다. 참여정부는 더 이상 ’권력기관’에 의존하지 않을 것입니다. 언제나 정정당당한 정부로서 국민 앞에 설 것입니다.\n참여정부는 공정하고 투명한 시장질서, 노사화합, 기술혁신, 지역 균형발전 속에 정직하고 성실하게 사는 사람들이 성공하는 나라를 만들어갈 것입니다. 이를 위해 원칙과 신뢰, 공정과 투명, 대화와 타협, 분권과 자율의 문화를 사회 곳곳에 뿌리내릴 것입니다.\n존경하는 국민 여러분!\n우리에게는 선열들이 보여준 자주독립의 기상과 대동단결의 지혜가 있습니다. 오늘 3, 1절을 맞아 일제의 총칼에 항거하며 이루고자 했던 선열들의 뜻을 다시 한번 가슴에 새깁시다. 국민통합과 개혁으로 평화와 번영의 동북아시대를 열어갑시다. 자랑스런 대한민국을 우리 후손들에게 물려줍시다.\n\n\n\n코드library(tidyverse)\n\nstt_txt &lt;- read_lines(\"data/stt_audio.txt\")\n\nstt_txt\n#&gt; [1] \"존경하는 국민여러분 오늘 84번째 3.21절을 맞아 나라를 위해 희생하고 헌신하신 애국선열들께 한없는 감사와 경의를 표합니다 독립유공자와 유가족 여러분에게도 존경과 감사의 말씀을 드립니다 3.22년 오늘 우리는 일제의 총칼에 맞서 맨주먹으로 분연히 일어섰습니다 대한독립만세 소리가 전국 방방곡곡을 뒤덮었고 우리는 자주독립의지를 세계 만방에 알렸습니다 3.21운동을 계기로 국내외의 독립투쟁은 더욱 힘차게 전개되었습니다 상해 대한민국 임시정부가 세워졌고 우리는 마침내 빼앗긴 국권을 되찾았습니다 3.21정신은 끊임없는 도전을 슬기롭게 극복해온 우리 민족의 자랑입니다 우리는 이러한 빛나는 정신을 계승하여 전쟁의 폐허를 딛고 세계 12위의 경제강국으로 발돋움했습니다 4.19혁명과 광주민주화운동 6월 민주항쟁을 거쳐서 민주주의와 인권을 쟁취해냈습니다 오늘의 참여정부는 바로 그 위대한 역사의 연장선 위에 서 있습니다 참여정부의 출범으로 이제 아픔의 근현대사는 막을 내리게 되었습니다 우리의 지난 날은 선열들의 고귀한 희생에도 불구하고 좌절과 굴절을 겪어야 했습니다 정의는 패배했고 기회주의가 덕세했습니다 그러나 이제 비로소 역사적 전환점이 마련됐습니다 국민이 진정 주인으로 대접받는 시대가 열릴 것입니다 참여정부에서는 권력의 아부하는 사람들이 더 이상 설 땅이 없을 것입니다 오로지 성실하게 일하고 정정당당하게 선고하는 사람들이 성공하는 시대가 열릴 것입니다 그것이 바로 선열들의 희생에 보답하는 길이자 저와 참여정부에게 주어진 역사의 소명이라고 생각합니다 존경하는 국민 여러분 지금 우리는 세계사의 새로운 흐름과 마주하고 있습니다 동북아 시대의 도래가 바로 그것입니다 동북아시아는 근대 이후 세계의 변방으로만 머물러 왔습니다 그러나 이제 유럽연합, 북미 지역과 함께 세계 경제의 3대 축으로 부상하고 있습니다 앞으로 20년 후에는 세계 경제의 3분의 1을 차지하게 된다는 전망도 있습니다 민족웅비의 크나큰 기회가 우리에게 다가오고 있는 것입니다 우리는 동북아 시대의 중심국가로 돌아갈 수 있는 충분한 조건을 갖추고 있습니다 우선 지리적으로 중심에 자리 잡고 있습니다 서울에서 3시간의 비행거리 안에 인구 100만 이상의 도시가 40개나 됩니다 중국과 러시아의 인력과 자원 그리고 일본의 기술을 접목할 수 있는 유리한 위치에 서 있습니다 대륙과 해양을 잇는 지정학적인 이점도 아울러 가지고 있습니다 하늘과 바다와 땅에 걸친 물류와 세계 인류의 정보와 기반과 역량을 두루 갖추고 있습니다 한반도는 더 이상 세계의 변방이 아닙니다 남북철도가 연결되고 철의 실크로드가 열리면 광활한 대륙을 향해서 나아갈 수 있습니다 이곳에는 중국 대륙이라는 새로운 기회가 기다리고 있습니다 시베리아와 중앙아시아의 무한한 자원도 있습니다 한반도가 대륙과 해양을 잇는 물류와 금융과 생산의 거점으로서 거듭나게 될 것입니다 이것이 바로 우리 앞에 있는 미래입니다 우리에게는 이를 현실로 만들어야 하는 책무가 주어져 있습니다 존경하는 국민 여러분 그러나 동북아 중심국가로 나아가기 위해서는 반드시 해야 할 일이 있습니다 한반도의 평화를 정착시키는 일입니다 남북이 대립하며 한반도의 긴장이 고조되는 한 동북아 중심국가의 꿈은 실현될 수 없습니다 동북아의 평화와 번영도 기대하기 어렵습니다 그동안 우리는 한반도의 평화를 정착시키기 위해서 많은 노력을 기울여 왔습니다 남북 간의 대화와 교류가 빈번해졌고 이산가족이 만나고 있습니다 최근에는 육로도 열리고 있습니다 그러나 아직 풀어야 할 숙제가 많이 있습니다 특히 북한 핵 문제는 시급히 해결해야 할 과제입니다 저는 북한의 핵 개발에 단호히 반대합니다 그러나 이 문제는 반드시 평화적으로 해결돼야 합니다 어떠한 이유로든 한반도의 평화가 깨어진다면 우리는 그 엄청난 재앙을 감당해낼 수가 없습니다 한반도의 평화와 국민의 안전을 지키는 것은 대통령의 가장 큰 책무입니다 앞으로 남북관계는 국민 여러분께 하나하나 소상히 보고드리고 국민적 합의를 바탕으로 추진해 나가겠습니다 야당의 협력도 적극적으로 구해나갈 것입니다 미국과 일본, 중국, 러시아 등 주변국과 이유를 비롯한 국제사회와도 능동적으로 협력해 나가겠습니다 존경하는 국민 여러분 한반도의 평화를 정착시키는 일 못지않게 중요한 것은 국민의 힘을 하나로 모으는 것입니다 84년 전 오늘 우리의 선열들은 한마음 한뜻으로 독립운동에 나섰습니다 빈부와 귀천, 남녀와 노소, 지역과 종교의 차이도 없었습니다 나라의 독립과 민족의 자존심을 되찾는데 하나가 되었습니다 오늘을 사는 우리도 지역과 계층과 세대를 넘어서 하나가 되어야 합니다 내부의 분열과 반목이 있으면 세계 경쟁에서 뒤처질 수밖에 없을 것입니다 국권까지 상실했던 100년 전의 실패가 되풀이 될 수도 있습니다 그야말로 3.1 정신을 되돌아보며 역사의 교훈을 되새겨야 할 때입니다 마음속에 지역 갈등의 응어리가 있다면 가슴을 열고 풀어야 합니다 어른은 젊은이의 목소리를 귀 기울이시고 젊은이는 어른들의 경험을 구해야 합니다 차별받고 제가 박수칠 사의를 드리는데 익숙지를 못합니다 차별받고 소외되어 온 사람들에게 더 많은 관심과 노력을 기울여야 합니다 국민 모두가 참된 주인으로서 국정에 참여하고 온 국민의 힘을 하나로 모으는 국민참여시대를 힘차게 열어가야겠습니다 개혁 또한 멈출 수 없는 우리 시대의 과제입니다 무엇보다도 정치와 행정이 바뀌어야 합니다 이른바 몇몇 권력기관은 그동안에 정권을 위해 봉사해왔던 것이 사실입니다 그래서 내부의 질서가 무너지고 국민의 신뢰를 잃었습니다 이제 이들 권력기관은 국민을 위한 기관으로 다시 태어나야 합니다 참여정부는 더 이상 권력기관에 의존하지 않을 것입니다 언제나 정정당당한 정부로서 국민 앞에 설 것입니다 참여정부는 공정하고 투명한 시장질서와 노사화합, 기술혁신, 지역의 균형발전 속에 정직하고 성실하게 사는 사람들이 성공하는 나라를 만들어갈 것입니다 이를 위해서 원칙과 신뢰, 공정과 투명, 대화와 타협 그리고 분권과 자율의 문화를 사회 곳곳에 뿌리내릴 것입니다 존경하는 국민 여러분 우리에게는 선열들이 보여준 자주독립의 기상과 대동단결의 지혜가 있습니다 오늘 3.1절을 맞아 1절의 총칼에 항거하며 이루고자 했던 선열들의 뜻을 다시 한번 가슴에 새깁시다 국민 통합과 개혁으로 평화와 번영의 동북아 시대를 열어갑시다 자랑스런 대한민국을 우리 후손들에게 물려줍시다 감사합니다\"\n\n\n\n\n\n\n\n\n\n\n프롬프트: 다음 텍스트에 구두점을 넣고 문단별로 나눠 가독성을 높혀주세요.  “존경하는 국민여러분 오늘 84번째 ..&lt;중략&gt;.. 물려줍시다 감사합니다”\n\n\n\n“존경하는 국민여러분, 오늘 84번째 3.1절을 맞아, 나라를 위해 희생하고 헌신하신 애국선열들께 한없는 감사와 경의를 표합니다. 독립유공자와 유가족 여러분에게도 존경과 감사의 말씀을 드립니다.\n3.1 1922년 오늘, 우리는 일제의 총칼에 맞서 맨주먹으로 분연히 일어섰습니다. 대한독립만세 소리가 전국 방방곡곡을 뒤덮었고, 우리는 자주독립의지를 세계 만방에 알렸습니다. 3.1운동을 계기로 국내외의 독립투쟁은 더욱 힘차게 전개되었습니다. 상해 대한민국 임시정부가 세워졌고, 우리는 마침내 빼앗긴 국권을 되찾았습니다.\n3.1정신은 끊임없는 도전을 슬기롭게 극복해온 우리 민족의 자랑입니다. 우리는 이러한 빛나는 정신을 계승하여 전쟁의 폐허를 딛고 세계 12위의 경제강국으로 발돋움했습니다. 4.19혁명과 광주민주화운동, 6월 민주항쟁을 거쳐서 민주주의와 인권을 쟁취해냈습니다. 오늘의 참여정부는 바로 그 위대한 역사의 연장선 위에 서 있습니다.\n참여정부의 출범으로, 이제 아픔의 근현대사는 막을 내리게 되었습니다. 우리의 지난 날은 선열들의 고귀한 희생에도 불구하고 좌절과 굴절을 겪어야 했습니다. 정의는 패배했고 기회주의가 덕세했습니다. 그러나 이제 비로소 역사적 전환점이 마련됐습니다. 국민이 진정 주인으로 대접받는 시대가 열릴 것입니다. 참여정부에서는 권력의 아부하는 사람들이 더 이상 설 땅이 없을 것입니다. 오로지 성실하게 일하고 정정당당하게 선고하는 사람들이 성공하는 시대가 열릴 것입니다. 그것이 바로 선열들의 희생에 보답하는 길이자, 저와 참여정부에게 주어진 역사의 소명이라고 생각합니다.\n존경하는 국민 여러분, 지금 우리는 세계사의 새로운 흐름과 마주하고 있습니다. 동북아 시대의 도래가 바로 그것입니다. 동북아시아는 근대 이후 세계의 변방으로만 머물러 왔습니다. 그러나 이제 유럽연합, 북미 지역과 함께 세계 경제의 3대 축으로 부상하고 있습니다. 앞으로 20년 후에는 세계 경제의 3분의 1을 차지하게 된다는 전망도 있습니다.\n민족웅비의 크나큰 기회가 우리에게 다가오고 있는 것입니다. 우리는 동북아 시대의 중심국가로 돌아갈 수 있는 충분한 조건들의 꿈을 생각해 보겠습니다. 이 땅에 건설한 자유와 평화, 독립과 민주주의의 신성한 꿈입니다. 우리는 그 꿈을 계승하고 이어가야 합니다.\n참여정부는 모든 일을 국민과 함께 할 것입니다. 어려운 일에도 함께 참여하고, 희망을 나누는 일에도 함께 참여하겠습니다. 정의를 위해 함께 서고, 기회를 위해 함께 투쟁하겠습니다. 바로 그것이 참여정부의 이념이고 실천의 방향입니다.\n모든 국민이 참여하는 민주주의, 그것이 바로 참여정부의 민주주의입니다. 대통령으로서 제게 주어진 역사의 소명을 다할 것입니다. 국민이 주인이 되는 참여정부, 그것을 만들어 가겠습니다. 국민 여러분의 도움과 협력이 절실히 필요합니다.\n국민 여러분, 오늘 3.1절을 맞아 이 자리에 함께 해주신 데 대해 깊은 감사의 말씀을 드립니다. 우리 모두가 동행하며, 선열들의 꿈을 이루어 나가는 큰 한 걸음을 내딛을 수 있기를 기원합니다. 감사합니다.\n\n\n\n\ngpt-4, 특히 gpt-4-0314 모형을 사용하여 API로 앞서 Whisper로 STT하여 받아쓰기한 사항을 윤문하여 연설문을 보기 좋게 다시 작성한다.\n\n코드import openai\nfrom dotenv import load_dotenv\nimport os\n\n# API KEY ----------------------\nload_dotenv()\nopenai.api_key = os.getenv('OPENAI_API_KEY')\n\n# 텍스트 불러오기 --------------------------\nwith open(\"data/stt_audio.txt\", \"r\") as file:\n    content = file.read()\n\nprint(content)\n\n# 텍스트 윤문 --------------------------\n\nprompt = f'다음 텍스트에 구두점을 넣고 문단별로 나눠 가독성을 높혀주세요. \\n\\n{content}'\n\nspeech_response = openai.ChatCompletion.create(\n  model       = \"gpt-4-0314\",\n  messages    = [\n    {\"role\": \"system\", \"content\": \"You are a Korean language expert.\"},\n    {\"role\": \"user\", \"content\": prompt}\n  ],\n  max_tokens   = 5000,\n  temperature  = 0\n)\n\nprint(speech_response[\"choices\"][0]['message']['content'])\n\nwith open(\"data/stt_audio_gpt4.txt\", \"w\") as file:\n    file.write(speech_response[\"choices\"][0]['message']['content'])\n\n\n\n코드gpt4_txt &lt;- read_lines(\"data/stt_audio_gpt4.txt\")\n\nglue::glue(\"{gpt4_txt}\")\n#&gt; 존경하는 국민여러분, 오늘 84번째 3.1절을 맞아 나라를 위해 희생하고 헌신하신 애국선열들께 한없는 감사와 경의를 표합니다. 독립유공자와 유가족 여러분에게도 존경과 감사의 말씀을 드립니다.\n#&gt; \n#&gt; 3.1운동 102년 전 오늘, 우리는 일제의 총칼에 맞서 맨주먹으로 분연히 일어섰습니다. 대한독립만세 소리가 전국 방방곡곡을 뒤덮었고, 우리는 자주독립의지를 세계 만방에 알렸습니다. 3.1운동을 계기로 국내외의 독립투쟁은 더욱 힘차게 전개되었습니다. 상해 대한민국 임시정부가 세워졌고, 우리는 마침내 빼앗긴 국권을 되찾았습니다.\n#&gt; \n#&gt; 3.1정신은 끊임없는 도전을 슬기롭게 극복해온 우리 민족의 자랑입니다. 우리는 이러한 빛나는 정신을 계승하여 전쟁의 폐허를 딛고 세계 12위의 경제강국으로 발돋움했습니다. 4.19혁명과 광주민주화운동, 6월 민주항쟁을 거쳐서 민주주의와 인권을 쟁취해냈습니다. 오늘의 참여정부는 바로 그 위대한 역사의 연장선 위에 서 있습니다.\n#&gt; \n#&gt; 참여정부의 출범으로 이제 아픔의 근현대사는 막을 내리게 되었습니다. 우리의 지난 날은 선열들의 고귀한 희생에도 불구하고 좌절과 굴절을 겪어야 했습니다. 정의는 패배했고 기회주의가 덕세했습니다. 그러나 이제 비로소 역사적 전환점이 마련됐습니다. 국민이 진정 주인으로 대접받는 시대가 열릴 것입니다. 참여정부에서는 권력의 아부하는 사람들이 더 이상 설 땅이 없을 것입니다. 오로지 성실하게 일하고 정정당당하게 선고하는 사람들이 성공하는 시대가 열릴 것입니다. 그것이 바로 선열들의 희생에 보답하는 길이자 저와 참여정부에게 주어진 역사의 소명이라고 생각합니다.\n#&gt; \n#&gt; 존경하는 국민 여러분, 지금 우리는 세계사의 새로운 흐름과 마주하고 있습니다. 동북아 시대의 도래가 바로 그것입니다. 동북아시아는 근대 이후 세계의 변방으로만 머물러 왔습니다. 그러나 이제 유럽연합, 북미 지역과 함께 세계 경제의 3대 축으로 부상하고 있습니다. 앞으로 20년 후에는 세계 경제의 3분의 1을 차지하게 된다는 전망도 있습니다. 민족웅비의 크나큰 기회가 우리에게 다가오고 있는 것입니다.\n#&gt; \n#&gt; 우리는 동북아 시대의 중심국가로 돌아갈 수 있는 충분한 조건을 갖추고 있습니다. 우선 지리적으로 중심에 자리 잡고 있습니다. 서울에서 3시간의 비행거리 안에 인구 100만 이상의 도시가 40개나 됩니다. 중국과 러시아의 인력과 자원 그리고 일본의 기술을 접목할 수 있는 유리한 위치에 서 있습니다. 대륙과 해양을 잇는 지정학적인 이점도 아울러 가지고 있습니다. 하늘과 바다와 땅에 걸친 물류와 세계 인류의 정보와 기반과 역량을 두루 갖추고 있습니다.\n#&gt; \n#&gt; 한반도는 더 이상 세계의 변방이 아닙니다. 남북철도가 연결되고 철의 실크로드가 열리면 광활한 대륙을 향해서 나아갈 수 있습니다. 이곳에는 중국 대륙이라는 새로운 기회가 기다리고 있습니다. 시베리아와 중앙아시아의 무한한 자원도 있습니다. 한반도가 대륙과 해양을 잇는 물류와 금융과 생산의 거점으로서 거듭나게 될 것입니다. 이것이 바로 우리 앞에 있는 미래입니다. 우리에게는 이를 현실로 만들어야 하는 책무가 주어져 있습니다.\n#&gt; \n#&gt; 존경하는 국민 여러분, 그러나 동북아 중심국가로 나아가기 위해서는 반드시 해야 할 일이 있습니다. 한반도의 평화를 정착시키는 일입니다. 남북이 대립하며 한반도의 긴장이 고조되는 한 동북아 중심국가의 꿈은 실현될 수 없습니다. 동북아의 평화와 번영도 기대하기 어렵습니다.\n#&gt; \n#&gt; 그동안 우리는 한반도의 평화를 정착시키기 위해서 많은 노력을 기울여 왔습니다. 남북 간의 대화와 교류가 빈번해졌고 이산가족이 만나고 있습니다. 최근에는 육로도 열리고 있습니다. 그러나 아직 풀어야 할 숙제가 많이 있습니다. 특히 북한 핵 문제는 시급히 해결해야 할 과제입니다. 저는 북한의 핵 개발에 단호히 반대합니다. 그러나 이 문제는 반드시 평화적으로 해결돼야 합니다. 어떠한 이유로든 한반도의 평화가 깨어진다면 우리는 그 엄청난 재앙을 감당해낼 수가 없습니다.\n#&gt; \n#&gt; 한반도의 평화와 국민의 안전을 지키는 것은 대통령의 가장 큰 책무입니다. 앞으로 남북관계는 국민 여러분께 하나하나 소상히 보고드리고 국민적 합의를 바탕으로 추진해 나가겠습니다. 야당의 협력도 적극적으로 구해나갈 것입니다. 미국과 일본, 중국, 러시아 등 주변국과 이유를 비롯한 국제사회와도 능동적으로 협력해 나가겠습니다.\n#&gt; \n#&gt; 존경하는 국민 여러분, 한반도의 평화를 정착시키는 일 못지않게 중요한 것은 국민의 힘을 하나로 모으는 것입니다. 84년 전 오늘 우리의 선열들은 한마음 한뜻으로 독립운동에 나섰습니다. 빈부와 귀천, 남녀와 노소, 지역과 종교의 차이도 없었습니다. 나라의 독립과 민족의 자존심을 되찾는데 하나가 되었습니다.\n#&gt; \n#&gt; 오늘을 사는 우리도 지역과 계층과 세대를 넘어서 하나가 되어야 합니다. 내부의 분열과 반목이 있으면 세계 경쟁에서 뒤처질 수밖에 없을 것입니다. 국권까지 상실했던 100년 전의 실패가 되풀이 될 수도 있습니다. 그야말로 3.1 정신을 되돌아보며 역사의 교훈을 되새겨야 할 때입니다.\n#&gt; \n#&gt; 마음속에 지역 갈등의 응어리가 있다면 가슴을 열고 풀어야 합니다. 어른은 젊은이의 목소리를 귀 기울이시고 젊은이는 어른들의 경험을 구해야 합니다. 차별받고 제가 박수칠 사의를 드리는데 익숙지를 못합니다. 차별받고 소외되어 온 사람들에게 더 많은 관심과 노력을 기울여야 합니다. 국민 모두가 참된 주인으로서 국정에 참여하고 온 국민의 힘을 하나로 모으는 국민참여시대를 힘차게 열어가야겠습니다.\n#&gt; \n#&gt; 개혁 또한 멈출 수 없는 우리 시대의 과제입니다. 무엇보다도 정치와 행정이 바뀌어야 합니다. 이른바 몇몇 권력기관은 그동안에 정권을 위해 봉사해왔던 것이 사실입니다. 그래서 내부의 질서가 무너지고 국민의 신뢰를 잃었습니다. 이제 이들 권력기관은 국민을 위한 기관으로 다시 태어나야 합니다. 참여정부는 더 이상 권력기관에 의존하지 않을 것입니다. 언제나 정정당당한 정부로서 국민 앞에 설 것입니다.\n#&gt; \n#&gt; 참여정부는 공정하고 투명한 시장질서와 노사화합, 기술혁신, 지역의 균형발전 속에 정직하고 성실하게 사는 사람들이 성공하는 나라를 만들어갈 것입니다. 이를 위해서 원칙과 신뢰, 공정과 투명, 대화와 타협 그리고 분권과 자율의 문화를 사회 곳곳에 뿌리내릴 것입니다.\n#&gt; \n#&gt; 존경하는 국민 여러분, 우리에게는 선열들이 보여준 자주독립의 기상과 대동단결의 지혜가 있습니다. 오늘 3.1절을 맞아 1절의 총칼에 항거하며 이루고자 했던 선열들의 뜻을 다시 한번 가슴에 새깁시다. 국민 통합과 개혁으로 평화와 번영의 동북아 시대를 열어갑시다. 자랑스런 대한민국을 우리 후손들에게 물려줍시다. 감사합니다."
  },
  {
    "objectID": "openAI_api_apps.html#ai-이미지-후처리",
    "href": "openAI_api_apps.html#ai-이미지-후처리",
    "title": "챗GPT",
    "section": "\n8.1 AI 이미지 후처리",
    "text": "8.1 AI 이미지 후처리\n웹에 이미지가 걸려있어 이를 로컬 파일로 다운로드 받아 후속 작업에 활용할 수 있도록 코드를 작성한다.\n\n코드import requests\nfrom PIL import Image\nimport io\n\n# 이미지 URL\nurl = \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-GpPkNlGHcRh9i7pQIlhT18p7/user-Qkv0ntrn5tQoUu6pocAidY5V/img-BHSmfeMCmONIkrl3nSHIZIR7.png?st=2023-07-21T05%3A08%3A01Z&se=2023-07-21T07%3A08%3A01Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-07-20T20%3A06%3A58Z&ske=2023-07-21T20%3A06%3A58Z&sks=b&skv=2021-08-06&sig=8G4gBoBYYHoklBNVR1ggHiURZulcxJ62y0YjJ/OJfkM%3D\"\n\n# GET 요청\nresponse = requests.get(url)\n\n# 이미지 가져오기\nimage = Image.open(io.BytesIO(response.content))\n\n# 이미지 JPEG 변환\nimage.save('images/dalle_image.jpeg', 'JPEG')"
  },
  {
    "objectID": "openAI_api.html#openai-api-key",
    "href": "openAI_api.html#openai-api-key",
    "title": "챗GPT",
    "section": "\n4.1 OpenAI API KEY",
    "text": "4.1 OpenAI API KEY\n\n\n1 단계\n2 단계\n3 단계"
  },
  {
    "objectID": "openAI_api.html#postman-접속확인",
    "href": "openAI_api.html#postman-접속확인",
    "title": "챗GPT",
    "section": "\n4.2 Postman 접속확인",
    "text": "4.2 Postman 접속확인\nPostman 웹사이트에 회원가입하고 로그인한다.\n\n\n1 단계\n2 단계\n3 단계\n4 단계\n5 단계\n6 단계\n7 단계\n8 단계\n9 단계\n10 단계\n11 단계\n12 단계"
  },
  {
    "objectID": "openAI_api.html#ai-이미지-생성",
    "href": "openAI_api.html#ai-이미지-생성",
    "title": "챗GPT",
    "section": "\n4.3 AI 이미지 생성",
    "text": "4.3 AI 이미지 생성\n\n\n1 단계\n2 단계\n3 단계\n4 단계"
  },
  {
    "objectID": "openAI_api_apps.html#텍스트-벡터-표현",
    "href": "openAI_api_apps.html#텍스트-벡터-표현",
    "title": "챗GPT",
    "section": "\n9.1 텍스트 벡터 표현",
    "text": "9.1 텍스트 벡터 표현\ntext-embedding-ada-002 모델은 빠르고 가성비가 뛰어난 임베딩 모델이다. “대한민국 수도는 서울입니다.” 이라는 문서를 벡터로 표현하면 다음과 같다. 즉, 1,536 차원을 갖는 공간에 하나의 점으로 표현될 수 있다.\n\n코드import os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nseoul_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"대한민국 수도는 서울입니다.\",\n)\n\nseoul_embedding = seoul_response[\"data\"][0]['embedding']\n\nprint(f'벡터길이: {len(seoul_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {seoul_embedding[:10]}')\n#&gt; 벡터 일부: [0.014582998119294643, -0.018063032999634743, 0.004872684367001057, -0.013805408962070942, -0.031180081889033318, 0.025176068767905235, -0.034519895911216736, 0.011357911862432957, -0.007960736751556396, -0.0020682618487626314]\n\n\n마찬가지로 일본의 수도 도쿄도 벡터로 표현할 수 있다.\n\n코드tokyo_response = openai.Embedding.create(\n  model=\"text-embedding-ada-002\",\n  input=\"일본 수도는 동경입니다.\",\n)\n\ntokyo_embedding = tokyo_response[\"data\"][0]['embedding']\nprint(f'벡터길이: {len(tokyo_embedding)}')\n#&gt; 벡터길이: 1536\nprint(f'벡터 일부: {tokyo_embedding[:10]}')\n#&gt; 벡터 일부: [0.010957648046314716, -0.013234060257673264, 0.009729413315653801, -0.011890077032148838, -0.03179261088371277, 0.03436483070254326, -0.029786281287670135, 0.008629790507256985, 0.01711810939013958, -0.0014733985299244523]"
  },
  {
    "objectID": "gpt4_performance.html#년-4월",
    "href": "gpt4_performance.html#년-4월",
    "title": "chatGPT",
    "section": "\n5.1 2023년 4월",
    "text": "5.1 2023년 4월\n\n5.1.1 데이터셋\n웹사이트에 게시된 가격표를 크롤링하여 엑셀파일로 정리한다.\n\n코드library(readxl)\nlibrary(tidyverse)\n\nprice_raw &lt;- read_excel(\"data/openai_pricing.xlsx\", sheet=\"price\")\n\nprice &lt;- price_raw %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  select(-description) %&gt;% \n  separate(가격, into = c(\"가격\", \"단위\"), sep = \"/\") %&gt;% \n  mutate(가격 = parse_number(가격) *1300, # 환율 1,300 / 달러 적용\n         단위 = str_squish(단위)) \n\nprice %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_espn()\n\n\n\n\n\n\n모형구분\n      model\n      작업\n      가격\n      단위\n    \n\n\nGPT-4\n8K context\nPrompt\n39.00\n1K tokens\n\n\nGPT-4\n32K context\nPrompt\n78.00\n1K tokens\n\n\nGPT-4\n8K context\nCompletion\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nCompletion\n156.00\n1K tokens\n\n\nChat\ngpt-3.5-turbo\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nAda\nPrompt\n0.52\n1K tokens\n\n\nInstructGPT\nBabbage\nPrompt\n0.65\n1K tokens\n\n\nInstructGPT\nCurie\nPrompt\n2.60\n1K tokens\n\n\nInstructGPT\nDavinci\nPrompt\n26.00\n1K tokens\n\n\nFine-tuning models\nAda\nPrompt\n0.52\n1K tokens\n\n\nFine-tuning models\nBabbage\nPrompt\n0.78\n1K tokens\n\n\nFine-tuning models\nCurie\nPrompt\n3.90\n1K tokens\n\n\nFine-tuning models\nDavinci\nPrompt\n39.00\n1K tokens\n\n\nFine-tuning models\nAda\nUsage\n2.08\n1K tokens\n\n\nFine-tuning models\nBabbage\nUsage\n3.12\n1K tokens\n\n\nFine-tuning models\nCurie\nUsage\n15.60\n1K tokens\n\n\nFine-tuning models\nDavinci\nUsage\n156.00\n1K tokens\n\n\nEmbedding models\nAda\nPrompt\n0.52\n1K tokens\n\n\nImage models\n1024×1024\nPrompt\n26.00\nimage\n\n\nImage models\n512×512\nPrompt\n23.40\nimage\n\n\nImage models\n256×256\nPrompt\n20.80\nimage\n\n\nAudio models\nWhisper\nPrompt\n7.80\nminute"
  },
  {
    "objectID": "gpt4_performance.html#년-7월",
    "href": "gpt4_performance.html#년-7월",
    "title": "chatGPT",
    "section": "\n5.3 2023년 7월",
    "text": "5.3 2023년 7월\n\n5.3.1 데이터셋\n웹사이트에 게시된 가격표를 크롤링하여 엑셀파일로 정리한다.\n\n코드library(readxl)\nlibrary(tidyverse)\n\nprice_today &lt;- read_excel(\"data/openai_pricing.xlsx\", sheet=\"price_230721\")\n\nprice_tbl &lt;- price_today %&gt;% \n  janitor::clean_names(ascii = FALSE) %&gt;% \n  separate(가격, into = c(\"가격\", \"단위\"), sep = \"/\") %&gt;% \n  mutate(가격 = parse_number(가격) *1300, # 환율 1,300 / 달러 적용\n         단위 = str_squish(단위)) \n\nprice_tbl %&gt;% \n  gt::gt() %&gt;% \n  gtExtras::gt_theme_espn()\n\n\n\n\n\n\n모형구분\n      model\n      작업\n      가격\n      단위\n    \n\n\nGPT-4\n8K context\nInput\n39.00\n1K tokens\n\n\nGPT-4\n8K context\nOutput\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nInput\n78.00\n1K tokens\n\n\nGPT-4\n32K context\nOutput\n156.00\n1K tokens\n\n\nGPT-3.5 Turbo\n4K context\nInput\n1.95\n1K tokens\n\n\nGPT-3.5 Turbo\n4K context\nOutput\n2.60\n1K tokens\n\n\nGPT-3.5 Turbo\n16K context\nInput\n3.90\n1K tokens\n\n\nGPT-3.5 Turbo\n16K context\nOutput\n5.20\n1K tokens\n\n\nFine-tuning models\nAda\nInput\n0.52\n1K tokens\n\n\nFine-tuning models\nAda\nOutput\n2.08\n1K tokens\n\n\nFine-tuning models\nBabbage\nInput\n0.78\n1K tokens\n\n\nFine-tuning models\nBabbage\nOutput\n3.12\n1K tokens\n\n\nFine-tuning models\nCurie\nInput\n3.90\n1K tokens\n\n\nFine-tuning models\nCurie\nOutput\n15.60\n1K tokens\n\n\nFine-tuning models\nDavinci\nInput\n39.00\n1K tokens\n\n\nFine-tuning models\nDavinci\nOutput\n156.00\n1K tokens\n\n\nEmbedding models\nAda v2\nUsage\n0.13\n1K tokens\n\n\nImage models\nDALL·E 2\n1024×1024\n26.00\nimage\n\n\nImage models\nDALL·E 3\n512×512\n23.40\nimage\n\n\nImage models\nDALL·E 4\n256×256\n20.80\nimage\n\n\nAudio models\nWhisper\nUsage\n7.80\nminute\n\n\n\n\n\n\n\n5.3.2 시각화\nOpenAI 가격을 원화(1,300원)로 변환시켜 API 호출별 체감되는 가격을 시각화한다.\n\n코드extrafont::loadfonts()\n\npricing_20230621_g &lt;- price_tbl %&gt;% \n  mutate(모형상세 = glue::glue(\"{모형구분} / {model} / {작업}\") %&gt;% as.character(.)) %&gt;%\n  mutate(모형구분 = factor(모형구분, levels=c(\"GPT-4\", \"GPT-3.5 Turbo\", \"Fine-tuning models\", \n                                      \"Embedding models\",\n                                      \"Image models\", \"Audio models\") )) %&gt;% \n  ggplot(aes(x = fct_reorder(모형상세, 가격), y = 가격, fill = 모형구분)) +\n    geom_col(width = 0.5) +\n    # facet_wrap(~모형구분, scales = \"free_y\") +\n    coord_flip() +\n    geom_text(aes(x = 모형상세, y = 가격, label = glue::glue(\"{가격} 원\") ), nudge_y = 5) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(title = \"OpenAI 챗GPT API 호출 가격\", \n         subtitle = \"환율 1,300 원/달러 적용 (텍스트 1,000 토큰, 이미지는 크기별, 오디오는 1분 기준)\",\n         x = \"\",\n         y = \"가격(원)\",\n         caption = \"OpenAI 가격표: https://openai.com/pricing\") +\n    theme(legend.position = c(0.8, 0.3),\n          legend.title=element_text(size=rel(2.5), family = \"MaruBuri\"),\n          legend.text=element_text(size=rel(1.5), family = \"MaruBuri\"))\n\nragg::agg_png(\"images/pricing_20230621_g.png\", width = 297, height = 210, units = \"mm\", res = 600)\npricing_20230621_g\ndev.off()"
  },
  {
    "objectID": "shiny_chatGPT.html",
    "href": "shiny_chatGPT.html",
    "title": "챗GPT",
    "section": "",
    "text": "1 ChatGPT\n챗GPT API를 활용하여 자체 앱을 개발할 경우 특정 요구 사항에 맞는 사용자 지정 인터페이스를 만들 수 있다는 장점 외에 다음과 같은 장단점이 제기된다.\n\n웹사이트 로고를 넣고 다른 자체 시스템과 통합할 수 있다.\n기존 서비스에 챗봇 기능 추가\n챗GPT 월간 유료 구독비용보다 저렴하다.\n\n특히, 사용자가 100명 넘어갈 경우 API를 통한 서비스 사용이 비용적인 측면에서 매력이 있다.\n예를 들어, 100명이 유료 구독할 경우 대략 $2,000 달러가 비용으로 책정되는데 현재 환율기준 1,300월/\\$ 대략 260만원인데 10,000번 호출할 경우 대략 $1,800 달러면 해결된다.\n\n\n\n2 비용\n출처: OpenAI API Pricing calculator\n\n코드library(tidyverse)\nlibrary(gt)\nlibrary(gtExtras)\n\ncost_raw &lt;- tibble::tribble(\n  ~`Tokens.per.execution    Words.per.execution Price.for.1.execution`,\n                                                        \"Price for\",\n                                                            \"10000\",\n                                                       \"executions\",\n                                         \"10\\t8\\t~$0.00045\\t~$4.50\",\n                                        \"20\\t15\\t~$0.00090\\t~$9.00\",\n                                       \"50\\t38\\t~$0.00225\\t~$22.50\",\n                                      \"100\\t75\\t~$0.00450\\t~$45.00\",\n                                     \"200\\t150\\t~$0.00900\\t~$90.00\",\n                                    \"500\\t375\\t~$0.02250\\t~$225.00\",\n                                   \"1000\\t750\\t~$0.04500\\t~$450.00\",\n                                  \"2000\\t1500\\t~$0.09000\\t~$900.00\",\n                                 \"4000\\t3000\\t~$0.18000\\t~$1800.00\"\n  )\n\ncost_raw |&gt; \n  janitor::clean_names() |&gt; \n  set_names(\"data\") |&gt; \n  mutate(data = map(data, str_split, pattern = \"\\t\")) |&gt; \n  unnest(data) |&gt; \n  mutate(ncol = map_int(data, length)) |&gt; \n  filter(ncol == 4) |&gt; \n  mutate(tokens = map_chr(data, 1),\n         words = map_chr(data, 2),\n         unit_cost = map_chr(data, 3),\n         ttl_cost =  map_chr(data, 4)) |&gt; \n  mutate(ttl_cost = parse_number(ttl_cost)) |&gt; \n  select(-data, -ncol) |&gt; \n  mutate(tokens = parse_number(tokens),\n         words  = parse_number(words)) |&gt; \n  gt::gt() |&gt; \n    gt_theme_538() |&gt; \n    cols_align(\"center\") |&gt; \n    fmt_integer(columns = c(ttl_cost, words, tokens)) |&gt; \n    tab_footnote(\n      footnote = \"챗GPT 유료계정 $20 x 100명, $2,000 기준\",\n      locations = cells_body(columns = ttl_cost, rows = 9)\n    ) |&gt; \n  tab_header(\n    title = html(\"챗GPT4 API 호출횟수와 유료계정\"),\n    subtitle = html(\"GPT-4 API 10,000번 호출 기준\")\n  )\n\n\n\n\n\n\n챗GPT4 API 호출횟수와 유료계정\n    \n\nGPT-4 API 10,000번 호출 기준\n    \n\ntokens\n      words\n      unit_cost\n      ttl_cost\n    \n\n\n\n10\n8\n~$0.00045\n4\n\n\n20\n15\n~$0.00090\n9\n\n\n50\n38\n~$0.00225\n22\n\n\n100\n75\n~$0.00450\n45\n\n\n200\n150\n~$0.00900\n90\n\n\n500\n375\n~$0.02250\n225\n\n\n1,000\n750\n~$0.04500\n450\n\n\n2,000\n1,500\n~$0.09000\n900\n\n\n4,000\n3,000\n~$0.18000\n1,8001\n\n\n\n\n\n1 챗GPT 유료계정 $20 x 100명, $2,000 기준\n    \n\n\n\n\n\n3 자체 앱 구출\nGitHub 저장소 deepanshu88/shinyChatGPT 코드를 바탕으로 로고와 메시지를 바꾸면 Shiny 챗GPT 앱을 간단히 구현할 수 있다."
  },
  {
    "objectID": "three_paradigm.html#import-necessary-libraries",
    "href": "three_paradigm.html#import-necessary-libraries",
    "title": "챗GPT",
    "section": "\n5.1 Import Necessary Libraries",
    "text": "5.1 Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "three_paradigm.html#load-the-dataset",
    "href": "three_paradigm.html#load-the-dataset",
    "title": "챗GPT",
    "section": "\n5.2 Load the Dataset",
    "text": "5.2 Load the Dataset\n# Load the dataset\ndf = pd.read_csv('penguins.csv')"
  },
  {
    "objectID": "three_paradigm.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "href": "three_paradigm.html#check-correlations-within-each-species-for-culmen-length-and-depth",
    "title": "챗GPT",
    "section": "\n5.3 Check Correlations Within Each Species for Culmen Length and Depth",
    "text": "5.3 Check Correlations Within Each Species for Culmen Length and Depth\n# Check correlations within each species for culmen_length_mm and culmen_depth_mm\nspecies_list = df['species'].unique()\nfor species in species_list:\n    print(f\"Correlation within {species} species:\")\n    print(df[df['species'] == species][['bill_length_mm', 'bill_depth_mm']].corr())\n    print(\"\\n\")"
  },
  {
    "objectID": "three_paradigm.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "href": "three_paradigm.html#calculate-the-overall-correlation-between-culmen-length-and-depth",
    "title": "챗GPT",
    "section": "\n5.4 Calculate the Overall Correlation Between Culmen Length and Depth",
    "text": "5.4 Calculate the Overall Correlation Between Culmen Length and Depth\n# Calculate the overall correlation between bill_length_mm and bill_depth_mm\noverall_corr = df[['bill_length_mm', 'bill_depth_mm']].corr().iloc[0, 1]\noverall_corr"
  },
  {
    "objectID": "three_paradigm.html#create-scatter-plot",
    "href": "three_paradigm.html#create-scatter-plot",
    "title": "챗GPT",
    "section": "\n5.5 Create Scatter Plot",
    "text": "5.5 Create Scatter Plot\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Overall regression line\nsns.regplot(x='bill_length_mm', y='bill_depth_mm', data=df, scatter=False, \n            line_kws={'color': 'black', 'label': \"Overall regression line\"})\n\n# Loop through each species\nfor species in species_list:\n    species_data = df[df['species'] == species]\n    sns.scatterplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, label=species)\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, scatter=False, \n                line_kws={'label': f\"{species} regression line\"})\n\nplt.title('Bill Depth vs Bill Length')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Bill Depth (mm)')\n\n# Add legend\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "three_paradigm.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "href": "three_paradigm.html#create-separate-scatter-plots-with-regression-lines-for-each-species",
    "title": "챗GPT",
    "section": "\n5.6 Create Separate Scatter Plots with Regression Lines for Each Species",
    "text": "5.6 Create Separate Scatter Plots with Regression Lines for Each Species\n# Create a figure and axis\nfig, axs = plt.subplots(3, 1, figsize=(10, 20))\n\n# Loop through each species\nfor ax, species in zip(axs, species_list):\n    species_data = df[df['species'] == species]\n    sns.regplot(x='bill_length_mm', y='bill_depth_mm', data=species_data, ax=ax, \n                line_kws={'label': f\"{species} regression line\"})\n    ax.set_title(f'{species} Penguins')\n    ax.set_xlabel('Bill Length (mm)')\n    ax.set_ylabel('Bill Depth (mm)')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "three_paradigm.html#설정",
    "href": "three_paradigm.html#설정",
    "title": "챗GPT",
    "section": "\n2.1 설정",
    "text": "2.1 설정\n유료구독하고 “Code Interpreter”를 활성화시킨다.\n\n\n1단계\n2단계\n3단계\n4단계\n5단계 (데이터+프롬프트)"
  },
  {
    "objectID": "three_paradigm.html#심슨-패러독스",
    "href": "three_paradigm.html#심슨-패러독스",
    "title": "챗GPT",
    "section": "\n2.2 심슨 패러독스",
    "text": "2.2 심슨 패러독스\n“챗GPT Code Interpreter”를 사용하여 분석한 사례\n\n챗GPT Code Interpreter : 채팅 이력\n\nJupyter Notebook 다운로드: penguin_analysis.ipynb\n\n\npenguin_analysis.ipynb → penguin_analysis.qmd\n\n명령어: $ quarto convert penguin_analysis.ipynb\n\n\n\n쿼토 컴파일: 바로가기"
  },
  {
    "objectID": "plugin.html",
    "href": "plugin.html",
    "title": "플러그인(Plugin)",
    "section": "",
    "text": "지오코딩(Geocoding)은 주소, 지명, 우편 번호 등의 위치 정보를 위도와 경도로 변환하는 것으로 이를 통해 특정 위치를 지도 상에 표시하거나, 위치 기반 서비스를 제공할 수 있다. 예를 들어, “서울특별시 강남구 테헤란로 212”라는 주소를 위도 37.5012746, 경도 127.0395857와 같은 좌표로 변환하는 일종의 함수로 볼 수 있다.\n지오코딩은 주소나 지명을 위도와 경도로 변환하는 과정으로, 일반적으로 사용자가 주소나 지명을 입력하면 이를 API 요청으로 전달한다. 서버는 이 요청을 처리하여 해당 위치의 위도와 경도 정보를 반환한다. 이렇게 얻은 위도와 경도는 지도 상에 표시하거나 위치 기반 서비스를 제공하는 데 사용된다. 반대로, 위도와 경도를 주소나 지명으로 변환하는 것을 역방향 지오코딩이라고 한다. Google Maps API, Kakao Maps API, Naver Maps API 등 서비스 제공업체가 다수 존재하지만 일정 횟수 이상의 요청 제한, 정확도 문제, 데이터 갱신주기 등 제한사항을 파악하고 적절한 API를 선택하여 업무에 적용한다.\nShareGPT: 챗GPT Plugin - 지도API\n카카오 지도 API 기술문서를 챗GPT 플러그인 “Link Reader”을 사용하여 좌표를 찍고 이를 지도위에 출력하는 코드를 작성해보자.\n\n카카오 지도 API를 호출해서 주소를 넘기는 프롬프트를 챗GPT 플로그인을 사용해서 위경도 좌표를 반환하는 생성한다.\n\n\n\n\n\n\n웹사이트를 읽고 다음 지령을 준비해 https://apis.map.kakao.com/web/documentation/\n\n\n\n\n\nKakao 지도 API 문서는 다양한 지도 관련 기능을 제공한다. 이 문서는 지도 객체 생성, 이벤트, 메서드 등에 대한 상세한 정보를 담고 있다. 아래는 주요 내용의 요약이다.\n\n### 지도 객체 생성\n- `kakao.maps.Map(container, options)`: 지도를 생성한다.\n  - `container`: 지도가 표시될 HTML element\n  - `options`: 중심 좌표, 확대 수준, 지도 종류 등을 설정할 수 있다.\n\n### 주요 메서드\n- `setCenter(latlng)`: 지도의 중심 좌표를 설정한다.\n- `getCenter()`: 지도의 중심 좌표를 반환한다.\n- `setLevel(level, options)`: 지도의 확대 수준을 설정한다.\n- `getLevel()`: 지도의 확대 수준을 반환한다.\n- `setMapTypeId(mapTypeId)`: 지도의 타입을 설정한다.\n- `getMapTypeId()`: 지도의 타입을 반환한다.\n\n### 이벤트\n- `center_changed`: 중심 좌표가 변경되면 발생한다.\n- `zoom_start`: 확대 수준이 변경되기 직전에 발생한다.\n- `zoom_changed`: 확대 수준이 변경되면 발생한다.\n- `click`: 지도를 클릭하면 발생한다.\n- `dblclick`: 지도를 더블클릭하면 발생한다.\n\n이 외에도 다양한 메서드와 이벤트가 있어, 개발자가 원하는 기능을 쉽게 구현할 수 있다.\n\n\n\n\n\n\n\n\n\n주소를 넘기면 위경도 좌표를 반환하는 R 코드를 작성해줘.\n\n\n\n\n\nR에서 주소를 위경도 좌표로 변환하기 위해 httr 패키지를 사용하여 Kakao API를 호출할 수 있다. 아래는 간단한 예시 코드이다.\n# 필요한 패키지를 설치하고 불러온다\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# 주소를 위경도로 변환하는 함수를 정의한다\nget_latlng &lt;- function(address) {\n  # Kakao API 키를 설정한다 (본인의 API 키로 교체해야 한다)\n  api_key &lt;- \"YOUR_KAKAO_API_KEY\"\n  \n  # API URL과 파라미터를 설정한다\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # API를 호출한다\n  response &lt;- GET(url, query = params, headers)\n  \n  # 응답을 확인하고 JSON을 파싱한다\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # 위경도를 추출한다\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# 함수를 테스트한다\naddress &lt;- \"서울특별시 강남구 테헤란로 212\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\n이 코드에서 YOUR_KAKAO_API_KEY 부분을 본인의 Kakao API 키로 교체해야 한다. 이 함수는 주소(address)를 입력으로 받아 위도(lat)와 경도(lng)를 리스트로 반환한다.\n주의: API 키를 공개하지 않도록 주의해야 한다.\n\n\n\n\n챗GPT가 제시한 “API 키를 공개하지 않도록 주의해야 한다”를 반영하여 api_key &lt;- \"YOUR_KAKAO_API_KEY\" 부분을 api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\") 바꿔 외부에 카카오 지도 API키를 숨긴다. “가톨릭관동대학교” 주소 “강원도 강릉시 범일로579번길 24”를 넣어 위경도 좌표를 얻어낸다.\n\n코드# 필요한 패키지를 설치하고 불러온다\n# install.packages(\"httr\")\n# install.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# 주소를 위경도로 변환하는 함수를 정의한다\nget_latlng &lt;- function(address) {\n  # Kakao API 키를 설정한다 (본인의 API 키로 교체해야 한다)\n  api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\")\n  \n  # API URL과 파라미터를 설정한다\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # API를 호출한다\n  response &lt;- GET(url, query = params, headers)\n  \n  # 응답을 확인하고 JSON을 파싱한다\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # 위경도를 추출한다\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# 가톨릭관동대학교 주소\naddress &lt;- \"강원도 강릉시 범일로579번길 24\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\n#&gt; [1] \"Latitude: 37.7373221158143 Longitude: 128.873681611316\"\n\n\n\n가톨릭관동대학교 주소 정보를 지오코딩을 통해 위경도 좌표를 얻는다. 다음으로 ggplot으로 주소를 찍고, 대한민국지도위에 올려 정확한 위치를 시각화한다.\n\n코드# 필요한 패키지를 설치하고 불러온다\n# install.packages(c(\"sf\", \"ggplot2\", \"ggrepel\"))\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# 위경도 좌표와 주소를 가진 데이터 프레임을 생성한다\ncoordinates_df &lt;- data.frame(\n  lon = result$lng, # 경도\n  lat = result$lat,    # 위도\n  address = c(\"강원도 강릉시 범일로579번길 24\")\n)\n\n# 데이터 프레임을 sf 객체로 변환한다\ncoordinates_sf &lt;- st_as_sf(coordinates_df, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n# 대한민국지도\nlibrary(giscoR)\ncntry &lt;- gisco_countries\nKOR &lt;- subset(cntry, ISO3_CODE == \"KOR\")\n\n# ggplot2와 geom_sf()를 사용하여 시각화한다\ncoordinates_sf |&gt; \n  ggplot() +\n    geom_sf() +\n    geom_sf_text(aes(label = address), size = 2, nudge_y = 0.2) +\n    labs(title = \"챗GPT 플로그인 사례\",\n         x =\"\",\n         y =\"\") +\n    theme_minimal() +\n    geom_sf(data = KOR, fill = \"transparent\")"
  },
  {
    "objectID": "plugin.html#지오코딩-api-코드",
    "href": "plugin.html#지오코딩-api-코드",
    "title": "플러그인(Plugin)",
    "section": "",
    "text": "카카오 지도 API를 호출해서 주소를 넘기는 프롬프트를 챗GPT 플로그인을 사용해서 위경도 좌표를 반환하는 생성한다.\n\n\n\n\n\n\n웹사이트를 읽고 다음 지령을 준비해 https://apis.map.kakao.com/web/documentation/\n\n\n\n\n\nKakao 지도 API 문서는 다양한 지도 관련 기능을 제공한다. 이 문서는 지도 객체 생성, 이벤트, 메서드 등에 대한 상세한 정보를 담고 있다. 아래는 주요 내용의 요약이다.\n\n### 지도 객체 생성\n- `kakao.maps.Map(container, options)`: 지도를 생성한다.\n  - `container`: 지도가 표시될 HTML element\n  - `options`: 중심 좌표, 확대 수준, 지도 종류 등을 설정할 수 있다.\n\n### 주요 메서드\n- `setCenter(latlng)`: 지도의 중심 좌표를 설정한다.\n- `getCenter()`: 지도의 중심 좌표를 반환한다.\n- `setLevel(level, options)`: 지도의 확대 수준을 설정한다.\n- `getLevel()`: 지도의 확대 수준을 반환한다.\n- `setMapTypeId(mapTypeId)`: 지도의 타입을 설정한다.\n- `getMapTypeId()`: 지도의 타입을 반환한다.\n\n### 이벤트\n- `center_changed`: 중심 좌표가 변경되면 발생한다.\n- `zoom_start`: 확대 수준이 변경되기 직전에 발생한다.\n- `zoom_changed`: 확대 수준이 변경되면 발생한다.\n- `click`: 지도를 클릭하면 발생한다.\n- `dblclick`: 지도를 더블클릭하면 발생한다.\n\n이 외에도 다양한 메서드와 이벤트가 있어, 개발자가 원하는 기능을 쉽게 구현할 수 있다.\n\n\n\n\n\n\n\n\n\n주소를 넘기면 위경도 좌표를 반환하는 R 코드를 작성해줘.\n\n\n\n\n\nR에서 주소를 위경도 좌표로 변환하기 위해 httr 패키지를 사용하여 Kakao API를 호출할 수 있다. 아래는 간단한 예시 코드이다.\n# 필요한 패키지를 설치하고 불러온다\ninstall.packages(\"httr\")\ninstall.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# 주소를 위경도로 변환하는 함수를 정의한다\nget_latlng &lt;- function(address) {\n  # Kakao API 키를 설정한다 (본인의 API 키로 교체해야 한다)\n  api_key &lt;- \"YOUR_KAKAO_API_KEY\"\n  \n  # API URL과 파라미터를 설정한다\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # API를 호출한다\n  response &lt;- GET(url, query = params, headers)\n  \n  # 응답을 확인하고 JSON을 파싱한다\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # 위경도를 추출한다\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# 함수를 테스트한다\naddress &lt;- \"서울특별시 강남구 테헤란로 212\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\n이 코드에서 YOUR_KAKAO_API_KEY 부분을 본인의 Kakao API 키로 교체해야 한다. 이 함수는 주소(address)를 입력으로 받아 위도(lat)와 경도(lng)를 리스트로 반환한다.\n주의: API 키를 공개하지 않도록 주의해야 한다."
  },
  {
    "objectID": "plugin.html#코드-수정",
    "href": "plugin.html#코드-수정",
    "title": "플러그인(Plugin)",
    "section": "",
    "text": "챗GPT가 제시한 “API 키를 공개하지 않도록 주의해야 한다”를 반영하여 api_key &lt;- \"YOUR_KAKAO_API_KEY\" 부분을 api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\") 바꿔 외부에 카카오 지도 API키를 숨긴다. “가톨릭관동대학교” 주소 “강원도 강릉시 범일로579번길 24”를 넣어 위경도 좌표를 얻어낸다.\n\n코드# 필요한 패키지를 설치하고 불러온다\n# install.packages(\"httr\")\n# install.packages(\"jsonlite\")\nlibrary(httr)\nlibrary(jsonlite)\n\n# 주소를 위경도로 변환하는 함수를 정의한다\nget_latlng &lt;- function(address) {\n  # Kakao API 키를 설정한다 (본인의 API 키로 교체해야 한다)\n  api_key &lt;- Sys.getenv(\"KAKAO_MAP_API_KEY\")\n  \n  # API URL과 파라미터를 설정한다\n  url &lt;- \"https://dapi.kakao.com/v2/local/search/address.json\"\n  params &lt;- list(query = address)\n  headers &lt;- add_headers(\"Authorization\" = paste(\"KakaoAK\", api_key))\n  \n  # API를 호출한다\n  response &lt;- GET(url, query = params, headers)\n  \n  # 응답을 확인하고 JSON을 파싱한다\n  if (status_code(response) == 200) {\n    content &lt;- content(response, \"text\", encoding = \"UTF-8\")\n    json_data &lt;- fromJSON(content)\n    \n    # 위경도를 추출한다\n    if (json_data$meta$total_count &gt; 0) {\n      lat &lt;- json_data$documents[[1]]$y\n      lng &lt;- json_data$documents[[1]]$x\n      return(list(lat = lat, lng = lng))\n    } else {\n      return(NULL)\n    }\n  } else {\n    stop(\"API request failed\")\n  }\n}\n\n# 가톨릭관동대학교 주소\naddress &lt;- \"강원도 강릉시 범일로579번길 24\"\nresult &lt;- get_latlng(address)\nprint(paste(\"Latitude:\", result$lat, \"Longitude:\", result$lng))\n#&gt; [1] \"Latitude: 37.7373221158143 Longitude: 128.873681611316\""
  },
  {
    "objectID": "plugin.html#가톨릭관동대-위치",
    "href": "plugin.html#가톨릭관동대-위치",
    "title": "플러그인(Plugin)",
    "section": "",
    "text": "가톨릭관동대학교 주소 정보를 지오코딩을 통해 위경도 좌표를 얻는다. 다음으로 ggplot으로 주소를 찍고, 대한민국지도위에 올려 정확한 위치를 시각화한다.\n\n코드# 필요한 패키지를 설치하고 불러온다\n# install.packages(c(\"sf\", \"ggplot2\", \"ggrepel\"))\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# 위경도 좌표와 주소를 가진 데이터 프레임을 생성한다\ncoordinates_df &lt;- data.frame(\n  lon = result$lng, # 경도\n  lat = result$lat,    # 위도\n  address = c(\"강원도 강릉시 범일로579번길 24\")\n)\n\n# 데이터 프레임을 sf 객체로 변환한다\ncoordinates_sf &lt;- st_as_sf(coordinates_df, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n# 대한민국지도\nlibrary(giscoR)\ncntry &lt;- gisco_countries\nKOR &lt;- subset(cntry, ISO3_CODE == \"KOR\")\n\n# ggplot2와 geom_sf()를 사용하여 시각화한다\ncoordinates_sf |&gt; \n  ggplot() +\n    geom_sf() +\n    geom_sf_text(aes(label = address), size = 2, nudge_y = 0.2) +\n    labs(title = \"챗GPT 플로그인 사례\",\n         x =\"\",\n         y =\"\") +\n    theme_minimal() +\n    geom_sf(data = KOR, fill = \"transparent\")"
  },
  {
    "objectID": "plugin.html#사실-확인",
    "href": "plugin.html#사실-확인",
    "title": "플러그인(Plugin)",
    "section": "\n3.1 사실 확인",
    "text": "3.1 사실 확인\n울프람 알파(Wolfram Alpha) 사용해서 사실관계를 확인해보자.\n\n\n\n\n\n\n“지구는 평평하다”라는 주장을 검증해줘.\n\n\n\n\n\n\"지구는 평평하다\"라는 주장에 대해 Wolfram Alpha를 이용해 검증해보았습니다.\n\n### 입력 해석\n- 질문: 지구는 평평하다?\n\n### 결과\n- 답변: 아니다.\n  - 지역적으로만 그렇다. 그리고 그것도 특정 지역, 예를 들어 미국 중서부에서만 해당된다.\n\n자세한 정보는 [Wolfram|Alpha 웹사이트](https://www6b3.wolframalpha.com/input?i=Is+the+Earth+flat%3F)에서 확인할 수 있다.\n\n이처럼 Wolfram Alpha는 다양한 주장이나 정보에 대한 팩트체크를 할 수 있는 유용한 도구이다.\nWolfram|Alpha 웹사이트\n\n\n\n\n\n\n\n\n\n라면을 많이 먹으면 건강에 정말 안좋은가?\n\n\n\n\n\nWolfram Alpha에서는 “라면을 많이 먹으면 건강에 정말 안 좋은가?”에 대한 구체적인 답변을 제공하지 못했다. 그러나 일반적으로 라면은 높은 나트륨, 지방, 인공 첨가물 등을 포함하고 있어, 과도하게 섭취할 경우 다음과 같은 건강 문제가 발생할 수 있다:\n\n고혈압: 라면에는 나트륨이 많이 들어있다. 나트륨 과다 섭취는 혈압을 높일 수 있다.\n비만: 라면은 칼로리가 높고, 지방도 많이 들어있다. 지속적으로 라면을 많이 먹으면 체중 증가의 위험이 있다.\n소화기 문제: 라면은 소화가 잘 되지 않는 식품 중 하나이다. 과도한 섭취는 소화기에 부담을 줄 수 있다.\n영양 불균형: 라면은 영양소가 적고, 나트륨이나 지방 등의 불필요한 성분이 많다. 이로 인해 영양 불균형이 발생할 수 있다.\n심혈관 질환: 고혈압, 높은 콜레스테롤 등은 심혈관 질환의 위험을 높인다.\n\n라면을 즐길 때는 이러한 점들을 고려하여 적당한 양과 빈도로 섭취하는 것이 중요하다."
  },
  {
    "objectID": "plugin.html#수능문제-풀이",
    "href": "plugin.html#수능문제-풀이",
    "title": "플러그인(Plugin)",
    "section": "\n3.2 수능문제 풀이",
    "text": "3.2 수능문제 풀이\nShareGPT: 팩트체크와 수학문제 풀이\n2023학년도 대학수학능력시험 수학영역 문제를 풀어보자.\n\n\n\n\n\n\n\n\n\n\n\\(\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\\) 값은?\n\n\n\n\n\n식 \\[\n\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\] 의 값은 \\(4\\)입니다.\n정확한 형태로는 \\(2^{(2 - \\sqrt{2}) (2 + \\sqrt{2})}\\)로 표현됩니다.\n자세한 정보는 Wolfram|Alpha 웹사이트에서 확인할 수 있다.\n\n\n\n\n\n\n\n\n\n과정도 설명해줘.\n\n\n\n\n\n물론이다. 주어진 식은 \\[\n\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]이다.\n이 식을 단계별로 분해해보자.\n\n3.2.1 단계 1: 분모를 간단하게 만들기\n먼저, 분모인 \\(2^{\\sqrt{2}}\\)를 간단하게 만들기 위해 분자와 분모에 \\(2^{\\sqrt{2}}\\)를 곱한다. 이렇게 하면:\n\\[\n\\left(\\frac{4 \\times 2^{\\sqrt{2}}}{2^{\\sqrt{2}} \\times 2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.2 단계 2: 분모를 합치기\n이제 분모의 \\(2^{\\sqrt{2}} \\times 2^{\\sqrt{2}}\\)를 합쳐 \\(2^{2\\sqrt{2}}\\)로 만든다.\n\\[\n\\left(\\frac{4 \\times 2^{\\sqrt{2}}}{2^{2\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.3 단계 3: 분자를 합치기\n분자의 \\(4 \\times 2^{\\sqrt{2}}\\)를 합쳐 \\(2^2 \\times 2^{\\sqrt{2}} = 2^{2+\\sqrt{2}}\\)로 만든다.\n\\[\n\\left(\\frac{2^{2+\\sqrt{2}}}{2^{2\\sqrt{2}}}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.4 단계 4: 지수 법칙 적용\n지수 법칙에 따라 분자와 분모의 지수를 빼준다.\n\\[\n\\left(2^{(2+\\sqrt{2}) - 2\\sqrt{2}}\\right)^{2+\\sqrt{2}} = \\left(2^{(2 - \\sqrt{2})(2 + \\sqrt{2})}\\right)^{2+\\sqrt{2}}\n\\]\n\n3.2.5 단계 5: 최종 계산\n마지막으로, \\((2 - \\sqrt{2})(2 + \\sqrt{2})\\)를 계산하면 \\(4 - 2 = 2\\)가 된다. 따라서 최종 결과는 \\(2^2 = 4\\)이다.\n이렇게 해서 \\[\n\\left(\\frac{4}{2^{\\sqrt{2}}}\\right)^{2+\\sqrt{2}} = 4\n\\]임을 확인할 수 있다."
  },
  {
    "objectID": "devday.html",
    "href": "devday.html",
    "title": "chatGPT",
    "section": "",
    "text": "New models and developer products announced at DevDay"
  },
  {
    "objectID": "devday.html#최근-지식",
    "href": "devday.html#최근-지식",
    "title": "chatGPT",
    "section": "\n2.1 최근 지식",
    "text": "2.1 최근 지식\n2021년 9월 → 2023년 4월\n\n\nGPT3-5-turbo\nGPT-4 + 빙검색\nGPT-4\nGPT-4 터보\n\n\n\n\n\n2023년 11월 7일 기준\n\n\n\n\n\n2023년 11월 7일 기준\n\n\n\n\n\n2023년 11월 7일 기준\n\n\n\n\n\n2023년 11월 7일 기준"
  },
  {
    "objectID": "devday.html#맥락-크기",
    "href": "devday.html#맥락-크기",
    "title": "chatGPT",
    "section": "\n2.2 맥락 크기",
    "text": "2.2 맥락 크기\n\n\n구분\nGPT-4 Turbo\nGPT-4 32K\nGPT-3.5 Turbo\n\n\n\n문맥 창\n128,000 토큰\n32,000 토큰\n8,192 토큰\n\n\n페이지수\n약 300 쪽\n약 75 쪽\n약 19 쪽\n\n\n기준\n427 토큰 / 쪽\n427 토큰 / 쪽\n427 토큰 / 쪽"
  },
  {
    "objectID": "devday.html#비용",
    "href": "devday.html#비용",
    "title": "chatGPT",
    "section": "\n2.3 비용",
    "text": "2.3 비용\n환율(1,300월/1달러)을 적용하여 1,000개 토큰 기준 비용을 산출하면 GPT-4 Turbo가 GPT-4 와 비교하면 입력기준 \\(\\frac{1}{3}\\) 저렴하다.\n\n\n모형\n입력(1K 토큰)\n출력(1K 토큰)\n\n\n\nGPT-4 Turbo\n13.0원\n39.0원\n\n\nGPT-4\n39.0원\n78.0원\n\n\nGPT-4 32k\n78.0원\n156.0원\n\n\nGPT-3.5 Turbo\n1.3원\n2.6원\n\n\nAssistant API\n19.5원\n-"
  },
  {
    "objectID": "devday.html#다중-모드성",
    "href": "devday.html#다중-모드성",
    "title": "chatGPT",
    "section": "\n2.4 다중 모드성",
    "text": "2.4 다중 모드성\n“GPT-4 터보”는 다중 모드성(Multimodality)를 제공한다. 과거 텍스트, 이미지, 오디오 각각 다른 모드로 제공된 것이 “GPT-4 터보”에서 통합되어 제공된다.\n\n텍스트(GPT-4)\n이미지(DALL-E 3)\n오디오(Whisper)"
  },
  {
    "objectID": "devday.html#gpt-플러그인",
    "href": "devday.html#gpt-플러그인",
    "title": "chatGPT",
    "section": "\n2.5 GPT 플러그인",
    "text": "2.5 GPT 플러그인\n컴퓨터와 디지털 기술이 발전함에 따라 소프트웨어는 끊임없이 진화해왔다. 초기에는 기본적인 설치형 소프트웨어가 주를 이루었으며, 이는 특정 작업을 수행하기 위해 물리적 매체를 통해 컴퓨터에 직접 설치되어 사용된다. 사용자는 소프트웨어를 구매하고 소유하는 개념을 가지고 있었다.\n그 다음에는 웹 소프트웨어가 등장한다. 인터넷의 보급으로 클라우드 기반의 서비스들이 생겨나기 시작하면서, 사용자들은 언제 어디서나 접속 가능한 웹 애플리케이션을 이용하게 된다. 설치 필요 없이 브라우저를 통해 접근하는 이 모형은 편의성을 극대화했다.\n이후 스마트폰의 보편화와 함께 앱 소프트웨어가 급부상한다. 앱 스토어를 통해 다운로드받아 모바일 기기에 설치하는 이 모형은 휴대성과 접근성을 강화하며 대중의 일상 속으로 깊숙이 들어간다.\n마지막으로, 인공지능의 발달은 GPT와 같은 플러그인 소프트웨어의 출현을 가져온다. 이들은 기존의 플랫폼이나 소프트웨어에 부가적으로 통합되어, 사용자 경험을 개인화하고, 향상시키는 역할을 한다. 사용자는 이제 복잡한 명령어를 입력하거나 전문 지식이 없어도 고도의 기능을 이용할 수 있게 되었다.\n\n\n\n\n설치형 SW\n\n\n\n웹 SW\n\n\n\n스마트폰 앱SW\n\n\n\nGPT 플러그인"
  },
  {
    "objectID": "devday.html#저작권-보험",
    "href": "devday.html#저작권-보험",
    "title": "chatGPT",
    "section": "\n2.6 저작권 보험",
    "text": "2.6 저작권 보험\nOpenAI는 만약 고객이 OpenAI의 서비스를 사용하다가 저작권 침해와 관련된 법적 문제에 직면했을 때, 법적 책임을 질 준비가 되어 있다고 공표했다. 이것은 저작권 침해에 대한 ’보험’과도 같다. 구글이나 마이크로소프트와 같은 다른 대형 기술 회사들도 비슷한 약속을 해왔으며, 이로써 사용자는 해당 회사의 서비스를 사용함에 있어서 발생할 수 있는 저작권 문제에 대해 좀 더 안심하고 서비스를 이용할 수 있게 되었다. OpenAI의 이런 조치는 고객이 만약 저작권 침해로 인해 법적으로 고소를 당하게 되더라도, OpenAI가 나서서 문제를 해결하고, 필요한 법적 조치를 취해주겠다는 것을 의미한다."
  },
  {
    "objectID": "devday.html#날씨-api",
    "href": "devday.html#날씨-api",
    "title": "chatGPT",
    "section": "\n4.1 날씨 API",
    "text": "4.1 날씨 API\nOpenWeather API를 가져와서 현재 날씨를 가져온다. location에 서울(seoul)을 넣으면, 서울의 현재 날씨를 가져온다.\n\n코드import requests \nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()  # This loads the environment variables from .env\n\n# Now you can use these variables using os.environ\nWEATHER_API_KEY = os.getenv('WEATHER_API_KEY')\n\n# 현재 날씨를 가져오는 함수를 정의한다.\ndef get_current_weather(location, unit='celsius'):\n    # 여기에 실제 날씨 API로 요청을 보내는 코드를 작성한다.\n    # 예를 들어, OpenWeatherMap API를 사용할 수 있다. (API 키가 필요하다)\n    # API_ENDPOINT는 사용하는 날씨 API의 엔드포인트 URL이다.\n    API_ENDPOINT = 'http://api.openweathermap.org/data/2.5/weather'\n    API_KEY = WEATHER_API_KEY  # 실제 날씨 API 키\n\n    params = {\n        'q': location,\n        'appid': API_KEY,\n        'units': 'metric' if unit == 'celsius' else 'imperial'\n    }\n    response = requests.get(API_ENDPOINT, params=params)\n    weather_data = response.json()\n    \n    # 가정: weather_data에는 날씨 정보가 JSON 형태로 들어 있다.\n    return weather_data\n\nget_current_weather(\"seoul\")\n\n\n{'coord': {'lon': 126.9778, 'lat': 37.5683}, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 6.51, 'feels_like': 6.51, 'temp_min': 5.66, 'temp_max': 7.69, 'pressure': 1022, 'humidity': 81}, 'visibility': 10000, 'wind': {'speed': 0.51, 'deg': 150}, 'clouds': {'all': 0}, 'dt': 1699449426, 'sys': {'type': 1, 'id': 8105, 'country': 'KR', 'sunrise': 1699394614, 'sunset': 1699432081}, 'timezone': 32400, 'id': 1835848, 'name': 'Seoul', 'cod': 200}"
  },
  {
    "objectID": "devday.html#챗gpt-날씨",
    "href": "devday.html#챗gpt-날씨",
    "title": "chatGPT",
    "section": "\n4.2 챗GPT 날씨",
    "text": "4.2 챗GPT 날씨\n챗GPT를 사용하여 서울 날씨를 물어보면 다음과 같이 대답한다. 현재 서울의 날씨를 직접 확인할 수는 없다.\n\n코드import os\nimport openai\n\n# OpenAI API를 사용할 준비를 한다.\nOPENAI_API_KEY = os.getenv('OPEN_API_KEY')\nopenai.api_key = OPENAI_API_KEY\n\n# 대화형 챗봇 모형을 이용하여 서울 날씨에 대한 대화를 시작한다.\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \n        \"content\": \"서울 날씨는 어떠하냐?\"}\n    ]\n)\n\n# 응답 결과를 출력한다.\nprint(response['choices'][0]['message']['content'])\n\n\n저는 인공지능이므로 실시간으로 날씨 정보를 제공할 수 없습니다. 하지만 서울의 날씨 정보는 기상청 등의 날씨 사이트나 기상앱에서 확인하실 수 있습니다. 또는 \"서울 날씨\"라고 검색하시면 해당 정보가 나올 것입니다."
  },
  {
    "objectID": "devday.html#function-calling",
    "href": "devday.html#function-calling",
    "title": "chatGPT",
    "section": "\n4.3 Function calling",
    "text": "4.3 Function calling\n함수 호출(function calling)을 활용한 사례를 살펴보자. 2\n\n4.3.1 한번 진행\n\n코드import json\nfrom datetime import date\n\nstudent_1_description = \"David Nguyen is a sophomore majoring in computer science at Stanford University. He is Asian American and has a 3.8 GPA. David is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after graduating.\"\n\nstudent_2_description=\"Ravi Patel is a sophomore majoring in computer science at the University of Michigan. He is South Asian Indian American and has a 3.7 GPA. Ravi is an active member of the university's Chess Club and the South Asian Student Association. He hopes to pursue a career in software engineering after graduating.\"\n\n# A simple prompt to extract information from \"student_description\" in a JSON format.\nprompt1 = f'''\nPlease extract the following information from the given text and return it as a JSON object:\n\nname\nmajor\nschool\ngrades\nclub\n\nThis is the body of text to extract the information from:\n{student_1_description}\n'''\n\nimport openai\n\n# Generating response back from gpt-3.5-turbo\nopenai_response = openai.ChatCompletion.create(\n    model = 'gpt-3.5-turbo',\n    messages = [{'role': 'user', 'content': prompt1}]\n)\n\n# Loading the response as a JSON object\njson_response = json.loads(openai_response['choices'][0]['message']['content'])\njson_response\n\n\n{'name': 'David Nguyen', 'major': 'computer science', 'school': 'Stanford University', 'grades': '3.8 GPA', 'club': 'Robotics Club'}\n\n4.3.2 반복\n\n코드student_custom_functions = [\n    {\n        'name': 'extract_student_info',\n        'description': 'Get the student information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the person'\n                },\n                'major': {\n                    'type': 'string',\n                    'description': 'Major subject.'\n                },\n                'school': {\n                    'type': 'string',\n                    'description': 'The university name.'\n                },\n                'grades': {\n                    'type': 'integer',\n                    'description': 'GPA of the student.'\n                },\n                'club': {\n                    'type': 'string',\n                    'description': 'School club for extracurricular activities. '\n                }\n                \n            }\n        }\n    }\n]\n\nstudent_description = [student_1_description,student_2_description]\nfor sample in student_description:\n    response = openai.ChatCompletion.create(\n        model = 'gpt-3.5-turbo',\n        messages = [{'role': 'user', 'content': sample}],\n        functions = student_custom_functions,\n        function_call = 'auto'\n    )\n\n    # Loading the response as a JSON object\n    json_response = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n    print(json_response)\n\n\n{'name': 'David Nguyen', 'major': 'computer science', 'school': 'Stanford University', 'grades': 3.8, 'club': 'Robotics Club'}\n{'name': 'Ravi Patel', 'major': 'computer science', 'school': 'University of Michigan', 'grades': 3.7, 'club': 'Chess Club'}\n\n4.3.3 여러 작업\n\n코드custom_functions = [\n    {\n        'name': 'extract_student_info',\n        'description': 'Get the student information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the person'\n                },\n                'major': {\n                    'type': 'string',\n                    'description': 'Major subject.'\n                },\n                'school': {\n                    'type': 'string',\n                    'description': 'The university name.'\n                },\n                'grades': {\n                    'type': 'integer',\n                    'description': 'GPA of the student.'\n                },\n                'club': {\n                    'type': 'string',\n                    'description': 'School club for extracurricular activities. '\n                }\n                \n            }\n        }\n    },\n    {\n        'name': 'extract_school_info',\n        'description': 'Get the school information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the school.'\n                },\n                'ranking': {\n                    'type': 'integer',\n                    'description': 'QS world ranking of the school.'\n                },\n                'country': {\n                    'type': 'string',\n                    'description': 'Country of the school.'\n                },\n                'no_of_students': {\n                    'type': 'integer',\n                    'description': 'Number of students enrolled in the school.'\n                }\n            }\n        }\n    }\n]\n\nschool_1_description = \"Stanford University is a private research university located in Stanford, California, United States. It was founded in 1885 by Leland Stanford and his wife, Jane Stanford, in memory of their only child, Leland Stanford Jr. The university is ranked #5 in the world by QS World University Rankings. It has over 17,000 students, including about 7,600 undergraduates and 9,500 graduates23. \"\n\ndescription = [student_1_description, school_1_description]\nfor i in description:\n    response = openai.ChatCompletion.create(\n        model = 'gpt-3.5-turbo',\n        messages = [{'role': 'user', 'content': i}],\n        functions = custom_functions,\n        function_call = 'auto'\n    )\n\n    # Loading the response as a JSON object\n    json_response = json.loads(response['choices'][0]['message']['function_call']['arguments'])\n    print(json_response)\n    \n\n\n{'name': 'David Nguyen', 'major': 'computer science', 'school': 'Stanford University', 'grades': 3.8, 'club': 'Robotics Club'}\n{'name': 'Stanford University', 'ranking': 5, 'country': 'United States', 'no_of_students': 17000}"
  },
  {
    "objectID": "openai_api_turbo.html",
    "href": "openai_api_turbo.html",
    "title": "chatGPT",
    "section": "",
    "text": "Farzad Mahmoodinobar, “OpenAI API — Intro & Implementation of the Models Behind ChatGPT - A programmatic approach to use models behind ChatGPT.”\n2023년 11월 openai API가 대규모 업데이트가 이뤄졌다. 이에 따라 기존의 openai API를 사용하는 코드는 작동하지 않는다. 이를 해결하기 위해서는 openai API를 업데이트해야 한다.\n$ pip install openai --upgrade\n\n\n\n\n\n\n경고\n\n\n\nYou tried to access openai.Completion, but this is no longer supported in openai&gt;=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n\n\n\n코드import os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"파이썬하고 R 하고 싸우면 누가 이겨?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nprint(chat_completion.choices[0].message.content)\n\n\n파이썬과 R은 둘 다 통계 분석과 데이터 처리를 위한 강력한 도구이며 각각의 장단점이 있습니다. 어떤 언어가 이긴다고 말하기는 어렵습니다.\n\n- 파이썬은 다양한 오픈 소스 패키지와 라이브러리의 풍부한 생태계를 가지고 있어 범용적인 프로그래밍에 적합합니다. 머신러닝, 딥러닝, 웹 개발, 자연어 처리 등 다양한 분야에 사용될 수 있으며, 쉽고 간결한 문법을 갖고 있어 입문자에게 친숙합니다.\n\n- R은 통계 분석과 데이터 시각화에 특화되어 있으며, 통계학과 데이터 분석 전문가들에게 널리 사용되고 있습니다. R은 통계 개발에 용이하며 다양한 통계적 모델링과 검정, 시뮬레이션, 데이터 정제 등을 위한 패키지를 제공합니다. R은 통계 데이터에 집중하기 때문에 통계 및 데이터 분석을 하는데 있어 더 많은 옵션을 제공하는 경우가 많습니다.\n\n따라서 어떤 언어를 선택할지는 사용자의 목적과 선호도, 배경에 따라 달라집니다. 파이썬은 범용적인 프로그래밍 언어로 다양한 분야에서 활용할 수 있으며, R은 통계 분석과 데이터 처리에 좀 더 특화되어 있습니다."
  },
  {
    "objectID": "openai_api_turbo.html#텍스트-테이블",
    "href": "openai_api_turbo.html#텍스트-테이블",
    "title": "chatGPT",
    "section": "\n8.1 텍스트 → 테이블",
    "text": "8.1 텍스트 → 테이블\n\n코드table_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"\nGiven the following SQL tables, your job is to parse the text below into Pandas dataframe.\n\nDROP TABLE IF EXISTS salary;\n\nCREATE TEMPORARY TABLE salary(city VARCHAR(30), average_salary int);\n\nINSERT INTO\nsalary\nVALUES\n    ('san_francisco', '54500'),\n    ('seattle', '54100'),\n    ('new_york', '34400'),\n    ('phoenix', '31800');\n\nDROP TABLE IF EXISTS people;\n\nCREATE TEMPORARY TABLE people(\n    person_id int,\n    name VARCHAR(30),\n    gender VARCHAR(30),\n    location VARCHAR(30),\n    birth_year int,\n    birth_month VARCHAR(30),\n    birth_day int,\n    job_title VARCHAR(30),\n    salary int\n);\n\nINSERT INTO\npeople\nVALUES\n    (\n        '1',\n        'james',\n        'male',\n        'seattle',\n        '1984',\n        '9',\n        '15',\n        'software_developer',\n        '115000'\n    ),\n    (\n        '2',\n        'mary',\n        'female',\n        'new_york',\n        '1992',\n        '1',\n        '13',\n        'financial_analyst',\n        '183000'\n    ),\n    (\n        '3',\n        'john',\n        'male',\n        'san_francisco',\n        '1971',\n        '4',\n        '22',\n        'data_scientist',\n        '165000'\n    ),\n    (\n        '4',\n        'patricia',\n        'female',\n        'phoenix',\n        '1971',\n        '8',\n        '15',\n        'physician',\n        '215000'\n    ),\n    (\n        '5',\n        'michael',\n        'male',\n        'new_york',\n        '1966',\n        '1',\n        '13',\n        'retired',\n        '25000'\n    ),\n    (\n        '6',\n        'jennifer',\n        'female',\n        'phoenix',\n        '1994',\n        '12',\n        '12',\n        'data_scientist',\n        '165000'\n    );\n\"\"\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": 'Parse the text into Pandas dataframe and return the result into markdown table format'\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=2048\n)\n\nprint(table_completion.choices[0].message.content)\n\n\n|   person_id | name     | gender | location      |   birth_year | birth_month   |   birth_day | job_title          |   salary |\n|------------:|:---------|:-------|:--------------|-------------:|:--------------|------------:|:-------------------|---------:|\n|           1 | james    | male   | seattle       |         1984 | 9             |          15 | software_developer |   115000 |\n|           2 | mary     | female | new_york      |         1992 | 1             |          13 | financial_analyst  |   183000 |\n|           3 | john     | male   | san_francisco |         1971 | 4             |          22 | data_scientist     |   165000 |\n|           4 | patricia | female | phoenix       |         1971 | 8             |          15 | physician          |   215000 |\n|           5 | michael  | male   | new_york      |         1966 | 1             |          13 | retired            |    25000 |\n|           6 | jennifer | female | phoenix       |         1994 | 12            |          12 | data_scientist     |   165000 |"
  },
  {
    "objectID": "openai_api_turbo.html#쿼리-작성",
    "href": "openai_api_turbo.html#쿼리-작성",
    "title": "chatGPT",
    "section": "\n8.2 쿼리 작성",
    "text": "8.2 쿼리 작성\n\n코드sql_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\":\n\n\"\"\"\nGiven the following SQL tables, your job is to write queries given a user’ s request.\n\nDROP TABLE IF EXISTS salary;\n\nCREATE TEMPORARY TABLE salary(city VARCHAR(30), average_salary int);\n\nINSERT INTO\nsalary\nVALUES\n    ('san_francisco', '54500'),\n    ('seattle', '54100'),\n    ('new_york', '34400'),\n    ('phoenix', '31800');\n\nDROP TABLE IF EXISTS people;\n\nCREATE TEMPORARY TABLE people(\n    person_id int,\n    name VARCHAR(30),\n    gender VARCHAR(30),\n    location VARCHAR(30),\n    birth_year int,\n    birth_month VARCHAR(30),\n    birth_day int,\n    job_title VARCHAR(30),\n    salary int\n);\n\nINSERT INTO\npeople\nVALUES\n    (\n        '1',\n        'james',\n        'male',\n        'seattle',\n        '1984',\n        '9',\n        '15',\n        'software_developer',\n        '115000'\n    ),\n    (\n        '2',\n        'mary',\n        'female',\n        'new_york',\n        '1992',\n        '1',\n        '13',\n        'financial_analyst',\n        '183000'\n    ),\n    (\n        '3',\n        'john',\n        'male',\n        'san_francisco',\n        '1971',\n        '4',\n        '22',\n        'data_scientist',\n        '165000'\n    ),\n    (\n        '4',\n        'patricia',\n        'female',\n        'phoenix',\n        '1971',\n        '8',\n        '15',\n        'physician',\n        '215000'\n    ),\n    (\n        '5',\n        'michael',\n        'male',\n        'new_york',\n        '1966',\n        '1',\n        '13',\n        'retired',\n        '25000'\n    ),\n    (\n        '6',\n        'jennifer',\n        'female',\n        'phoenix',\n        '1994',\n        '12',\n        '12',\n        'data_scientist',\n        '165000'\n    );\n\"\"\"    \n        },\n        {\n            \"role\": \"user\",\n            \"content\":               \n              'Write a SQL query which returns a rank of the salaries overall and also by gender from highest to the lowest salary.'\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=2048\n)\n\nprint(sql_completion.choices[0].message.content)\n\n\nTo rank the salaries overall and by gender from highest to lowest, you can use the RANK() function in SQL. Here is the SQL query:\n\nSELECT\n    p.name,\n    p.gender,\n    p.salary,\n    RANK() OVER (ORDER BY p.salary DESC) AS overall_rank,\n    RANK() OVER (PARTITION BY p.gender ORDER BY p.salary DESC) AS gender_rank\nFROM\n    people p\nORDER BY\n    p.salary DESC;"
  },
  {
    "objectID": "openai_function_call.html",
    "href": "openai_function_call.html",
    "title": "chatGPT",
    "section": "",
    "text": "Farzad Mahmoodinobar, “OpenAI API — Intro & Implementation of the Models Behind ChatGPT - A programmatic approach to use models behind ChatGPT.”\n\n코드import os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"함께 달릴 준비되면 ok, 그렇지 않으면 ko를 출력해줘\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\nprint(chat_completion.choices[0].message.content)\n\n\nI'm sorry, but I am an AI language model and I cannot physically run or prepare to run with you. However, if you need any advice or information about running, I'll be happy to help."
  },
  {
    "objectID": "openai_function_call.html#날씨-api",
    "href": "openai_function_call.html#날씨-api",
    "title": "chatGPT",
    "section": "\n2.1 날씨 API",
    "text": "2.1 날씨 API\nOpenWeather API를 가져와서 현재 날씨를 가져온다. location에 서울(seoul)을 넣으면, 서울의 현재 날씨를 가져온다.\n\n코드import requests \nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()  # This loads the environment variables from .env\n\n# 현재 날씨를 가져오는 함수를 정의한다.\ndef get_current_weather(location, unit='celsius'):\n    # 여기에 실제 날씨 API로 요청을 보내는 코드를 작성한다.\n    # 예를 들어, OpenWeatherMap API를 사용할 수 있다. (API 키가 필요하다)\n    # API_ENDPOINT는 사용하는 날씨 API의 엔드포인트 URL이다.\n    API_ENDPOINT = 'http://api.openweathermap.org/data/2.5/weather'\n    API_KEY = os.getenv('WEATHER_API_KEY')  # 실제 날씨 API 키\n\n    params = {\n        'q': location,\n        'appid': API_KEY,\n        'units': 'metric' if unit == 'celsius' else 'imperial'\n    }\n    response = requests.get(API_ENDPOINT, params=params)\n    weather_data = response.json()\n    \n    # 가정: weather_data에는 날씨 정보가 JSON 형태로 들어 있다.\n    return weather_data\n\nseoul_weather = get_current_weather(\"seoul\")\n\nprint('현재 온도: ' + str(seoul_weather['main']['temp']) )\n\n\n{'coord': {'lon': 126.9778, 'lat': 37.5683}, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 6.51, 'feels_like': 6.51, 'temp_min': 5.66, 'temp_max': 7.69, 'pressure': 1022, 'humidity': 81}, 'visibility': 10000, 'wind': {'speed': 0.51, 'deg': 150}, 'clouds': {'all': 0}, 'dt': 1699449426, 'sys': {'type': 1, 'id': 8105, 'country': 'KR', 'sunrise': 1699394614, 'sunset': 1699432081}, 'timezone': 32400, 'id': 1835848, 'name': 'Seoul', 'cod': 200}"
  },
  {
    "objectID": "openai_function_call.html#챗gpt-날씨",
    "href": "openai_function_call.html#챗gpt-날씨",
    "title": "chatGPT",
    "section": "\n2.2 챗GPT 날씨",
    "text": "2.2 챗GPT 날씨\n챗GPT를 사용하여 서울 날씨를 물어보면 다음과 같이 대답한다. 현재 서울의 날씨를 직접 확인하지 않고 환영(Halluciation)을 보여주고 있다.\n\n코드import os\nimport openai\n\n# OpenAI API를 사용할 준비를 한다.\nOPENAI_API_KEY = os.getenv('OPEN_API_KEY')\nopenai.api_key = OPENAI_API_KEY\n\n# 대화형 챗봇 모형을 이용하여 서울 날씨에 대한 대화를 시작한다.\n\nweather_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"서울 날씨는 어떠하냐?\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\n\n# 응답 결과를 출력한다.\nprint(weather_response.choices[0].message.content)\n\n\n현재 서울의 날씨는 어린이 날은 보통 맑음입니다. 현재 기온은 약 19도이며, 오늘은 하루 종일 맑은 날씨로 예상됩니다."
  },
  {
    "objectID": "openai_function_call.html#스크립트",
    "href": "openai_function_call.html#스크립트",
    "title": "chatGPT",
    "section": "\n3.1 스크립트",
    "text": "3.1 스크립트\n지문을 주어지고 프롬프트 엔지니어링을 통해 필요한 정보만을 추출한다.\n\n코드about_me = 'Hello! My name is David Hundley. I am a principal machine learning engineer at State Farm. I enjoy learning about AI and teaching what I learn back to others. I have two daughters. I drive a Tesla Model 3, and my favorite video game series is The Legend of Zelda.'\n\nabout_me_prompt = f'''\nPlease extract information as a JSON object. Please look for the following pieces of information.\nName\nJob title\nCompany\nNumber of children as a single integer\nCar make\nCar model\nFavorite video game series\n\nThis is the body of text to extract the information from:\n{about_me}\n'''\n\nplain_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": about_me_prompt,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    max_tokens=256\n)"
  },
  {
    "objectID": "openai_function_call.html#함수-호출",
    "href": "openai_function_call.html#함수-호출",
    "title": "chatGPT",
    "section": "\n3.2 함수 호출",
    "text": "3.2 함수 호출\n함수를 정의해서 필요한 정보를 추출한다.\n\n코드def extract_person_info(name, job_title, num_children):\n    '''\n    Prints basic \"About Me\" information\n\n    Inputs:\n        - name (str): Name of the person\n        - job_title (str): Job title of the person\n        - num_chilren (int): The number of children the parent has.\n    '''\n\n    print(f'This person\\'s name is {name}. Their job title is {job_title}, and they have {num_children} children.')\n\ninfo_functions = [\n    {\n        'name': 'extract_person_info',\n        'description': 'Get \"About Me\" information from the body of the input text',\n        'parameters': {\n            'type': 'object',\n            'properties': {\n                'name': {\n                    'type': 'string',\n                    'description': 'Name of the person'\n                },\n                'job_title': {\n                    'type': 'string',\n                    'description': 'Job title of the person'\n                },\n                'num_children': {\n                    'type': 'integer',\n                    'description': 'Number of children the person is a parent to'\n                }\n            }\n        }\n    }\n]\n\n\ninfo_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": about_me,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    functions = info_functions,\n    function_call = 'auto'    \n)\n\nimport json\n\n# JSON 문자열 예시\njson_str = info_response.choices[0].message.function_call.arguments\n\n# JSON 문자열을 Python 딕셔너리로 변환\ninfo_dict = json.loads(json_str)\n\n# 필요한 정보 추출\nname = info_dict['name']\njob_title = info_dict['job_title']\nnum_children = info_dict['num_children']\n\nprint(f\" Name: {name}\\n Job Title: {job_title}\\n Number of Children: {num_children}\\n\")"
  },
  {
    "objectID": "openai_function_call.html#프롬프트-공학",
    "href": "openai_function_call.html#프롬프트-공학",
    "title": "chatGPT",
    "section": "\n4.1 프롬프트 공학",
    "text": "4.1 프롬프트 공학\nf-string을 사용해서 API 호출 결과를 텍스트로 출력한다. 따라서, 별도 후처리가 필요하다.\n\n코드recipe = 'Fish and chips'\nquery = f\"\"\"What is the recipe for {recipe}? Return the ingredients list and steps separately.\"\"\"\n\ncook_response = client.chat.completions.create(\n  messages = [\n    {\n          \"role\": \"system\",\n          \"content\": \"You are the best cook in the world.\" \n      \n    },\n    {\n        \"role\": \"user\",\n        \"content\": query\n    }\n  ],\n  model=\"gpt-3.5-turbo\",\n  max_tokens=256,\n  temperature=0\n)\n\nprint(cook_response.choices[0].message.content)\n\n\nIngredients for Fish and Chips:\n- 1 lb white fish fillets (such as cod or haddock)\n- 1 cup all-purpose flour\n- 1 tsp baking powder\n- 1 tsp salt\n- 1/2 tsp black pepper\n- 1 cup cold sparkling water\n- Vegetable oil, for frying\n- 4 large potatoes, peeled and cut into thick fries\n- Salt, to taste\n\nSteps for Fish:\n1. In a shallow dish, mix together flour, baking powder, salt, and black pepper.\n2. Dip each fish fillet into the flour mixture, coating it evenly on both sides.\n3. Heat vegetable oil in a deep frying pan or pot over medium-high heat.\n4. Carefully place the coated fish fillets into the hot oil and fry for about 4-5 minutes on each side, or until golden brown and crispy.\n5. Once cooked, remove the fish from the oil and place on a paper towel-lined plate to drain excess oil.\n\nSteps for Chips:\n1. Rinse the cut potato fries under cold water to remove excess starch.\n2. In a large pot, heat vegetable oil over medium-high heat until it reaches about 350°F (175°C).\n3. Carefully add the potato"
  },
  {
    "objectID": "openai_function_call.html#함수-호출-1",
    "href": "openai_function_call.html#함수-호출-1",
    "title": "chatGPT",
    "section": "\n4.2 함수 호출",
    "text": "4.2 함수 호출\n함수 호출(function calling) 기능을 사용하면 출력결과를 나눠 구별할 수 있다. 텍스트 형식으로 요리재료와 요리절차가 함께 출력되어 이를 재활용하는데 어려움이 크다. 함수 호출을 사용해서 이러한 문제를 해결해보자.\n\n코드cook_funciton = [\n    {\n        \"name\": \"return_recipe\",\n        \"description\": \"Return the recipe asked\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"ingredients\": {\n                    \"type\": \"string\",\n                    \"description\": \"The ingredients list.\"\n                },\n                \"steps\": {\n                    \"type\": \"string\",\n                    \"description\": \"The recipe steps.\"\n                },\n            },\n            },\n            \"required\": [\"ingredients\",\"steps\"],\n        }\n]\n\nrecipe_response = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": query,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n    functions = cook_funciton,\n    function_call = 'auto'    \n)\n\n# JSON 문자열 예시\nrecipe_json = recipe_response.choices[0].message.function_call.arguments\n\nimport json\n\n# JSON 문자열을 Python 딕셔너리로 변환\nrecipe_dict = json.loads(recipe_json)\n\n# 필요한 정보 추출\nrecipe_ingredients = recipe_dict['ingredients']\nrecipe_steps = recipe_dict['steps']\n\nprint(f\"재료: \\n{recipe_ingredients}\\n\\n요리절차: \\n{recipe_steps}\")\n\n\n재료: \nFish\nPotatoes\nFlour\nSalt\nPepper\nBaking powder\nMilk\nBeer\nVegetable oil\n\n요리절차: \n1. Slice potatoes into fries\n2. Mix flour, salt, pepper, and baking powder\n3. Add milk and beer to flour mixture\n4. Dip fish into batter\n5. Fry fish and fries in vegetable oil until golden brown"
  },
  {
    "objectID": "openai_function_call.html#json-출력",
    "href": "openai_function_call.html#json-출력",
    "title": "chatGPT",
    "section": "\n4.3 JSON 출력",
    "text": "4.3 JSON 출력\nOpenAI 개발자 컨퍼런스에서 새롭게 소개된 JSON 출력을 지원하는 기능을 사용한다. 2\n\n코드json_response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo-1106\", # \"gpt-4-1106-preview\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are the best cook in the world. Your response should be in JSON format.\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": query,\n        }\n    ],\n    response_format={ \"type\": \"json_object\" }\n)\n\n# JSON 문자열 예시\nrecipe_gpt_json = json_response.choices[0].message.content\n\nimport json\nrecipe_dict = json.loads(recipe_gpt_json)\n\nprint(recipe_dict['recipe']['name'])\n# Fish and Chips\nprint(recipe_dict['recipe']['ingredients'])\n# {'fish': '2 fillets of cod or haddock', 'potatoes': '4 large potatoes', 'flour': '1 cup', 'baking powder': '2 tsp', 'salt': '1 tsp', 'milk': '1 cup', 'egg': '1', 'oil': 'for frying'}\nprint(recipe_dict['recipe']['steps'])\n# ['Peel and cut the potatoes into thick strips for the chips.', 'Rinse and pat dry the fish fillets. Cut them into manageable pieces.', 'In a bowl, mix together the flour, baking powder, and salt. In another bowl, whisk together the milk and egg.', \"Dip each piece of fish into the flour mixture, then into the milk mixture, and back into the flour mixture, ensuring it's well coated.\", 'Heat the oil in a deep fryer or large pot to 375°F (190°C). Fry the chips until golden and crispy, then remove and drain on paper towels.', 'Reheat the oil to 350°F (175°C). Fry the fish pieces for 4-5 minutes until they are golden and crispy. Drain on paper towels.', 'Serve the fish and chips hot, with sides such as tartar sauce, malt vinegar, or lemon wedges.']\n\n\n\n\n\n\n\n\n노트\n\n\n\n프롬프트에 항상 “JSON” 용어를 추가해야만 JSON 출력결과를 얻을 수 있다.\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
  },
  {
    "objectID": "openai_multimodality.html",
    "href": "openai_multimodality.html",
    "title": "chatGPT",
    "section": "",
    "text": "2023년 11월 열린 OpenAI 개발자 컨퍼런스에서 기존 OpenAI API 인터페이스가 대대적인 개선작업이 이뤄졌다."
  },
  {
    "objectID": "openai_multimodality.html#이미지-텍스트",
    "href": "openai_multimodality.html#이미지-텍스트",
    "title": "chatGPT",
    "section": "\n3.1 이미지 → 텍스트",
    "text": "3.1 이미지 → 텍스트\ngpt-4-vision-preview 모형을 사용해서 이미지를 설명하는 텍스트를 생성하도록 한다.\n\n코드image_response = client.chat.completions.create(\n    model=\"gpt-4-vision-preview\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"대한민국 최고 역사전문가로 역할을 수행해줘.\",\n        },      \n        {\n            \"role\": \"user\",\n            \"content\": [\n                { \n                  \"type\": \"text\", \n                  \"text\": \"이미지를 설명해주세요.\"\n                },\n                {\n                  \"type\": \"image_url\",\n                  \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/4/4e/An_Jung-geun.JPG\"\n                },\n            ],\n        }\n    ],\n    max_tokens=500\n)\n\nprint(image_response.choices[0].message.content)\n\n\n\n\n\n\n\n\n\n사진 속 인물은 어두운색의 자켓을 입고 있으며, 배경은 흰색으로 보이는 벽으로 추정됩니다. 이 사람은 카메라를 직시하고 있는데, 표정은 비교적 평온해 보입니다. 사진의 색조와 품질을 통해 추정컨대 오래된 사진으로 보입니다. 이 사람의 정체에 관한 정보가 없으므로, 구체적인 역사적 배경이나 이 인물에 대한 자세한 정보를 제공하기는 어렵습니다."
  },
  {
    "objectID": "openai_multimodality.html#텍스트-이미지",
    "href": "openai_multimodality.html#텍스트-이미지",
    "title": "chatGPT",
    "section": "\n3.2 텍스트 → 이미지",
    "text": "3.2 텍스트 → 이미지\ndall-e-3 모형을 사용해서 텍스트를 이미지로 생성하도록 한다.\n\n코드from IPython.display import display, Image\nimport requests\n\nresponse = client.images.generate(\n  model=\"dall-e-3\",\n  prompt=\"A black Scottish fold cat with light golden eyes laying down on white sheets\",\n  size=\"1024x1024\",\n  quality=\"standard\",\n  n=1,\n)\n\n# Save the image URL\nimage_url = response.data[0].url\n\n# Fetch the image\nimage_response = requests.get(image_url)\n\n# Display the image\nimg = Image(data=image_response.content)\ndisplay(img)\n\n\n\n코드download.file(url = 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-GpPkNlGHcRh9i7pQIlhT18p7/user-Qkv0ntrn5tQoUu6pocAidY5V/img-rypewgc6ys0EPhho7OTn7f5m.png?st=2023-11-16T08%3A52%3A12Z&se=2023-11-16T10%3A52%3A12Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-16T09%3A51%3A05Z&ske=2023-11-17T09%3A51%3A05Z&sks=b&skv=2021-08-06&sig=bPIlrK7Lhflj2Igsg6TWOSnT1DKQ3F2A0/vTTZSwgfI%3D', destfile = \"images/dalle_gpt4_cat.jpg\", mode = \"wb\")"
  },
  {
    "objectID": "openai_multimodality.html#텍스트-음성",
    "href": "openai_multimodality.html#텍스트-음성",
    "title": "chatGPT",
    "section": "\n4.1 텍스트 → 음성",
    "text": "4.1 텍스트 → 음성\n대한민국 헌법 제1장 제1조를 읽어주는 음성을 생성한다.\n\n대한민국은 민주공화국이다. 대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다\n\n\n코드from openai import OpenAI\n\nclient = OpenAI()\nresponse = client.audio.speech.create(\n  model=\"tts-1\",\n  voice=\"alloy\",\n  input=\"대한민국은 민주공화국이다. 대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다\",\n)\n\n# Save to an MP3 file.\nwith open(\"data/alloy-korean.mp3\", \"wb\") as file:\n  file.write(response.content)\n  \n\n\n\n코드library(av)\nlibrary(embedr)\n\nhtml_tag_audio &lt;- function(file, type = c(\"wav\")) {\n  type &lt;- match.arg(type)\n  htmltools::tags$audio(\n    controls = \"\",\n    htmltools::tags$source(\n      src = file,\n      type = glue::glue(\"audio/{type}\", type = type)\n    )\n  )\n}\n\nembedr::embed_audio(\"data/alloy-korean.mp3\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp"
  },
  {
    "objectID": "openai_multimodality.html#음성-텍스트",
    "href": "openai_multimodality.html#음성-텍스트",
    "title": "chatGPT",
    "section": "\n4.2 음성 → 텍스트",
    "text": "4.2 음성 → 텍스트\n다음으로 음성을 텍스트로 변환하는 예제를 살펴보자.\nKorean Speech Database for ASR 웹사이트에서 다양한 한국어 음성 데이터를 다운로드 받을 수 있다.\n\n코드embedr::embed_audio(\"data/audio_0001.wav\", \"wav\")\n\n Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp \n\n\n\n코드from openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"data/audio_0001.wav\", \"rb\")\n\ntranscript = client.audio.transcriptions.create(\n  model=\"whisper-1\", \n  file=audio_file, \n  response_format=\"text\"\n)\n\ntranscript\n#&gt; '커피숍에 쓰는 돈이 월 10만원이 넘더라고요. 소비를 좀 줄이라고 캡슐커피머신 구매했는데 캡슐가격이 너무 나가서 그게 그거인 것 같아요.\\n'\n\n\n\n\n라벨 음성 텍스트\n커피숍에 쓰는 돈이 월 (100000원)/(십만 원)이 (넘더라고요)/(넘더라구요). 소비를 좀 줄이려고 캡슐커피머신 구매했는데 캡슐 가격이 너무 나가서 그게 그거 같아요.\n\n\n\n\n인식된 음성 텍스트\n‘커피숍에 쓰는 돈이 월 10만원이 넘더라고요. 소비를 좀 줄이라고 캡슐커피머신 구매했는데 캡슐가격이 너무 나가서 그게 그거인 것 같아요.’"
  },
  {
    "objectID": "openai_multimodality.html#보정작업",
    "href": "openai_multimodality.html#보정작업",
    "title": "chatGPT",
    "section": "\n4.3 보정작업",
    "text": "4.3 보정작업\nOpenAI Speech to text 문서를 바탕으로 음성 오디오를 필사하는 보정작업을 수행하는 예제를 살펴보자.\n\n코드audio_file = open(\"data/audio_0001.wav\", \"rb\")\n\nsystem_prompt = \"You are a helpful assistant for the company Korea R User Group. Your task is to correct any spelling discrepancies in the transcribed text. Make sure that the names of the following products are spelled correctly: Korea R User Group, 한국 R 사용자회. Only add necessary punctuation such as periods, commas, and capitalization, and use only the context provided.\"\n\ndef transcribe(audio_file):\n    transcript = client.audio.transcriptions.create(\n      model=\"whisper-1\", \n      file=audio_file, \n      response_format=\"text\"\n    )\n    \n    return transcript\n  \n# transcribe(audio_file)\n\ndef generate_corrected_transcript(temperature, system_prompt, audio_file):\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        temperature=temperature,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": transcribe(audio_file)\n            }\n        ]\n    )\n    return response\n\ncorrected_text = generate_corrected_transcript(0, system_prompt, audio_file)\n\ncorrected_text.choices[0].message.content\n\n\n'커피숍에 쓰는 돈이 월 10만원이 넘더라고요. 소비를 좀 줄이라고 캡슐 커피 머신을 구매했는데, 캡슐 가격이 너무 나가서 그게 그거인 것 같아요.'"
  },
  {
    "objectID": "openai_ml.html",
    "href": "openai_ml.html",
    "title": "chatGPT",
    "section": "",
    "text": "윈도우 환경에서 scikit-llm을 설치할 경우 Visual Studio 커뮤니티 버젼을 설치할 때 C/C++ 빌드 환경도 함께 설치한 후 scikit-llm 설치를 권장한다.\nScikitLLM – A powerful combination of SKLearn and LLMs\n\n코드! pip install scikit-llm\n! pip install palmerpenguins"
  },
  {
    "objectID": "openai_ml.html#openai-api",
    "href": "openai_ml.html#openai-api",
    "title": "chatGPT",
    "section": "\n3.1 OpenAI API",
    "text": "3.1 OpenAI API\n\n코드import os\nfrom dotenv import load_dotenv\nfrom skllm.config import SKLLMConfig\nfrom sklearn.metrics import accuracy_score\n\nload_dotenv()\n\nSKLLMConfig.set_openai_key(os.getenv(\"OPENAI_API_KEY\"))\nSKLLMConfig.set_openai_org(os.getenv(\"OPENAI_API_ORG\"))"
  },
  {
    "objectID": "openai_ml.html#llm-모형",
    "href": "openai_ml.html#llm-모형",
    "title": "chatGPT",
    "section": "\n3.2 LLM 모형",
    "text": "3.2 LLM 모형\nScikit-LLM 라이브러리를 사용하여 감성 분석을 위한 대규모 언어 모형(ZeroShotGPTClassifier)을 구현하고 평가하는 과정을 진행하고 계십니다. 여기서 ZeroShotGPTClassifier를 통해 감성 분석(positive, negative, neutral)을 수행하고, 모형의 정확도를 평가한다.\n교차표는 실제 레이블과 예측 레이블 간의 관계를 표로 나타내어 모형의 성능을 보다 명확하게 이해할 수 있어 도움이 되고, 모형의 성능을 평가하는 데 사용된다.\n\n코드from skllm import ZeroShotGPTClassifier\nfrom skllm.datasets import get_classification_dataset\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# 감성분석 내장 데이터셋\n# labels: positive, negative, neutral\n\nsentiment_pd = get_classification_dataset()\n\nX, y = get_classification_dataset() \n\nclf = ZeroShotGPTClassifier(openai_model = \"gpt-3.5-turbo\")\n\n# Fit/Train our model\nclf.fit(X, y)\n\n# Predict/Inference on our Data using trained model\nlabels = clf.predict(X)\n\n\n\n코드py$labels |&gt; \n  write_rds(\"data/sentiment_labels.rds\")\n\n\n\n코드# 모형 평가\naccuracy = accuracy_score(y, labels)\nprint(\"정확도:\", accuracy)\n\n# 교차표 생성\nconf_matrix = confusion_matrix(y, labels)\nprint(\"교차표:\\n\", conf_matrix)\n\n\n교차표:\n [[10  0  0]\n [ 3  7  0]\n [ 0  0 10]]\n\n코드# 분류 보고서 생성\nclass_report = classification_report(y, labels)\nprint(\"분류 보고서:\\n\", class_report)\n\n\n분류 보고서:\n               precision    recall  f1-score   support\n\n    negative       0.77      1.00      0.87        10\n     neutral       1.00      0.70      0.82        10\n    positive       1.00      1.00      1.00        10\n\n    accuracy                           0.90        30\n   macro avg       0.92      0.90      0.90        30\nweighted avg       0.92      0.90      0.90        30\n\n코드library(reticulate)\nlibrary(tidyverse)\n\nsentiment_tbl &lt;- tibble(label = py$sentiment_pd[[2]], text = py$sentiment_pd[[1]])\n\nsentiment_tbl |&gt;\n  slice(1:10) |&gt; \n  gt::gt()"
  }
]