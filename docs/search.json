[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 1 ë°±ë§Œ ì‚¬ìš©ì \n\n1 ë°±ë§Œ ê°€ì…ìë¥¼ ê°€ì§ˆ ë•Œê¹Œì§€ ê±¸ë¦° ì†Œìš”ì‹œê°„ì„ ë³´ë©´ chatGPT ì˜ ì˜í–¥ë ¥ì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.\n\n\n\n\n\n2 íŒ¨ëŸ¬ë‹¤ì„\n\n\nAndrej Karpathy Twit\n\n\n\nPre-Software: Special-purpose computer\nSoftware 1.0: Design the Algorithm\nSoftware 2.0: Design the Dataset\nSoftware 3.0: Design the Prompt\n\n3 Prompt engineering\n\nInstructions\nQuestion\nInput data\nExamples\n\nXavier (Xavi) Amatriain(January 5, 2023), â€œPrompt Engineering 101 - Introduction and resourcesâ€, Linkedin,Prompt Engineering - Learn how to use AI models with prompt engineering\n\n4 Genearative AI\n\nêµ¬ë¶„\n\ngeneration: text â†’ image\nclassification: image â†’ text\ntransformation: image â†’ image (or text â†’ text)\n\n\nAI í”„ë¡œì íŠ¸\n\nGPT-3\nDalle.2 (text-to-image)\nMetaâ€™s AI (text-to-video)\nGoogle AI (text-to-video)\nStable Diffusion (text-to-image)\nTesla AI (humanoid robot + self-driving)\n\n\ntext-to-X\n\ntext-to-gif (T2G)\ntext-to-3D (T2D)\ntext-to-text (T2T)\ntext-to-NFT (T2N)\ntext-to-code (T2C)\ntext-to-image (T2I)\ntext-to-audio (T2S)\ntext-to-video (T2V)\ntext-to-music (T2M)\ntext-to-motion (T2Mo)\n\n\nê¸°íƒ€\n\nbrain-to-text (B2T)\nimage-to-text (I2T)\nspeech-to-text (S2T)\naudio-to-audio (A2A)\ntweet-to-image (Tt2I)\ntext-to-sound (T2S)\n\n\n\n\n\n\n\n\n5 ë°ì´í„°ì™€ í•˜ë“œì›¨ì–´\n\n\n\n\n\n6 Open Assistant\n\n\n\n\nLabel Asssistant Reply\n\n\n\n\nInitial Prompt\n\n\n\n\nLabel Prompter Reply\n\n\n\n\n\n\nReply as Assistant\n\n\n\n\nReply as User\n\n\n\nê·¸ë¦¼Â 1: Open Assistant"
  },
  {
    "objectID": "project.html#shiny-flex-dashboard---sales-forecasting-and-anomaly-detection",
    "href": "project.html#shiny-flex-dashboard---sales-forecasting-and-anomaly-detection",
    "title": "chatGPT ì™€ ë°ì´í„° ê³¼í•™",
    "section": "Shiny Flex Dashboard - Sales forecasting and anomaly detection",
    "text": "Shiny Flex Dashboard - Sales forecasting and anomaly detection\n\n\nImage 2\n\n\n\nDescription 2"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\nCode1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html",
    "href": "posts/20230126-vscode/ide_vscode.html",
    "title": "Visual Studio Code",
    "section": "",
    "text": "Rì„ ì„¤ì¹˜í•œë‹¤.\n\nlanguageserver íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\n\ninstall.packages(\"languageserver\")\n\n\nVisual Studio Code ì—ì„œ R extensionì„ ì„¤ì¹˜í•œë‹¤.\n\n.R íŒŒì¼ì— ê°œë°œì„ ì‹œì‘í•œë‹¤.\n\n\nR extensionì„ ì„¤ì¹˜í•˜ê²Œ ë˜ë©´ VS Codeì—ì„œ R ì½”ë“œ ê°œë°œì„ ì›í™œíˆ í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤. VS Code ì— í•„ìˆ˜ì ì¸ R extensionì€ ë‹¤ìŒì„ ê¼½ì„ ìˆ˜ ìˆë‹¤. R extensionì„ ì„¤ì¹˜í•˜ë©´ RStudioì—ì„œ ê¸°ë³¸ì„¤ì •ìœ¼ë¡œ ì§€ì •ëœ ë‹¨ì¶•í‚¤ë¥¼ ë³„ë„ ì„¤ì •ì—†ì´ ìë™ ì§€ì •ë˜ê¸° ë•Œë¬¸ì— í¸ë¦¬í•˜ë‹¤.\n\nR - REditorSupport\nR Markdown All in One\nQuarto\nR Debugger\n\n\n\nVS Codeë¥¼ ì‹¤í–‰í•˜ê³  R Extension ì„¤ì¹˜\n\n\n\nR Extension ì„¤ì¹˜ë˜ë©´ ì½”ë“œ ì°½ ìƒë‹¨ì— ì‹¤í–‰ë²„íŠ¼ì´ í™œì„±í™”ë˜ê³  Ctrl + Enter í˜¹ì€ Ctrl + Shift + Enter\n\n\nR ì½”ë“œ ì‹¤í–‰í™”ë©´"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "href": "posts/20230126-vscode/ide_vscode.html#keybindings.json",
    "title": "Visual Studio Code",
    "section": "keybindings.json",
    "text": "keybindings.json\nkeybindings.json íŒŒì¼ì— R í˜¹ì€ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‚½ì…ì‹œí‚¬ ìˆ˜ ìˆëŠ” í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ë¥¼ ë“±ë¡ì‹œí‚¨ë‹¤. ìë£Œì¶œì²˜: VS Code: Add a Rmarkdown Code Chunk Snippet Key Binding\n// Place your key bindings in this file to override the defaults\n[\n    // keybindings for R scripts. \n    {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == r\"\n      },\n      // keybindings for Rmarkdown\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"type\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"editorTextFocus && editorLangId == rmd\"\n      },\n      // keybindings for R terminal (radian included)\n      {\n        \"key\": \"Ctrl+Shift+m\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" %>% \" },\n        \"when\": \"terminalFocus\"\n      },\n      {\n        \"key\": \"Alt+-\",\n        \"command\": \"workbench.action.terminal.sendSequence\",\n        \"args\": { \"text\": \" <- \" },\n        \"when\": \"terminalFocus\"\n      },\n      // Insert R Code chunk\n      {\n        \"key\": \"ctrl+alt+i\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"```{r}\\n$0\\n```\"}\n      },\n      {\n        \"key\": \"ctrl+alt+o\". \n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\": {\"snippet\": \"options(\\n  max.print=100,\\n  vsc.use_httpgd=TRUE,\\n  device='quartz'\\n)\"}\n      },\n      {\n        \"key\": \"ctrl+alt+m\",\n        \"command\": \"editor.action.insertSnippet\",\n        \"when\": \"editorTextFocus\",\n        \"args\":{\n          \"snippet\": \"---\\ntitle: '$0'\\nauthor: 'ì´ê´‘ì¶˜'\\ndate: '2023-01-31'\\noutput:\\n  pagedown::html_paged:\\n    self_contained: true\\n    toc: false\\n---\\n\\n```{r setup, include=FALSE}\\nknitr::opts_chunk\\\\$set(\\n  echo = FALSE,\\n  message = FALSE,\\n  warning=FALSE\\n)\\n```\"\n        }\n      },\n\n]"
  },
  {
    "objectID": "posts/20230126-vscode/ide_vscode.html#html-ë¯¸ë¦¬ë³´ê¸°",
    "href": "posts/20230126-vscode/ide_vscode.html#html-ë¯¸ë¦¬ë³´ê¸°",
    "title": "Visual Studio Code",
    "section": "HTML ë¯¸ë¦¬ë³´ê¸°",
    "text": "HTML ë¯¸ë¦¬ë³´ê¸°\n.Rmd íŒŒì¼ì„  CTRL  +  Shift  +  k  ë‹¨ì¶•í‚¤ë¡œ ì»´íŒŒì¼ì‹œí‚¤ë©´ .html íŒŒì¼ì´ ìƒì„±ëœë‹¤. .html íŒŒì¼ ê²°ê³¼ë¥¼ ì§ì ‘ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ê³ ì í•œë‹¤ë©´, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ê°œë°œí•œ Live Preview - VS Code Extension í”ŒëŸ¬ê·¸ì¸ì„ ì„¤ì¹˜í•œë‹¤."
  },
  {
    "objectID": "posts/20230127-ide/ide_war.html",
    "href": "posts/20230127-ide/ide_war.html",
    "title": "AIê°€ ì˜ì•„ì˜¬ë¦° ì‘ì€ ê³µ",
    "section": "",
    "text": "ë°ì´í„° ê³¼í•™ í¸ì§‘ê¸°\në°ì´í„° ê³¼í•™ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ ê°œë°œì„ ìœ„í•´ì„œ IDE(í†µí•©ê°œë°œí™˜ê²½)ì„ ë‘ê³  RStudioì™€ Jupyter ë‘ ì§„ì˜ìœ¼ë¡œ ë‚˜ëˆ  ì¹˜ì—´í•œ ê²½ìŸì„ í¼ì³¤ë‹¤. ê°ì ì¥ì ì„ ë‘ê³  ë²”ìœ„ë¥¼ í™•ëŒ€í•˜ë©´ì„œ ì§„ì •í•œ ë°ì´í„° ê³¼í•™ íŒ¨ìê°€ ë˜ê³ ì í•œí¸ì˜ ë“œë¼ë§ˆë¥¼ í¼ì³¤ë‹¤.\nê·¸ ì¤‘ì‹¬ì—ëŠ” RStudioì™€ ì•„ë‚˜ì½˜ë‹¤ê°€ ìˆìœ¼ë©° ë§ˆì¹˜ í˜„ëŒ€ì°¨ì™€ ê¸°ì•„ì°¨ì²˜ëŸ¼ ë™ì¼í•œ ìë™ì°¨ì¸ë° ì„¸ë¶€ êµ¬ì„±ê³¼ ë””ìì¸ì— ì°¨ì´ë§Œ ìˆì„ ë¿ ì–´ëŠ ê²ƒì´ ë” ìš°ì›”í•˜ê³  ì¢‹ë‹¤ëŠ” ë§ˆì¼€íŒ…ì„ í¼ì³¤ë‹¤.\n\n\n\në§ˆì´í¬ë¡œì†Œí”„íŠ¸ì˜ ë“±ì¥\në°ì´í„° ê³¼í•™ í¸ì§‘ê¸°ì— Visual Studio Codeê°€ ë“±ì¥í•˜ë©´ì„œ í° ë³€í™”ê°€ ì¼ì–´ë‚˜ê³  ìˆë‹¤. íŠ¹íˆ ì¸ê³µì§€ëŠ¥ ê¸°ëŠ¥ì„ íƒ‘ì¬í•œ Extensionì´ VS Codeì— ì¶”ê°€ë˜ë©´ì„œ ê¸°ì¡´ RStudioì™€ ì¥¬í”¼í„° IDEê°€ í•˜ë˜ ê¸°ëŠ¥ì„ ë„˜ì–´ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ì–´ê°€ê³  ìˆë‹¤.\nê·¸ ì¤‘ì‹¬ì—ëŠ” GitHubì„ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ ì¸ìˆ˜í•˜ë©´ì„œ ìƒˆë¡œ ì¶œì‹œí•œ ë¶€ì¡°ì¢…ì‚¬(Copilot)ì´ ìˆê³  ì¡°ë§Œê°„ CodeGPTë„ ë„ì…ë˜ë©´ ê¸°ì¡´ RStudioì™€ JupyterëŠ” ê¸°ì¡´ê³¼ ì „í˜€ ë‹¤ë¥¸ ìœ„ìƒì„ ê°€ì§€ê²Œ ë  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "chatGPTê°€ ì—° ìƒˆë¡œìš´ ì‹œëŒ€ë¥¼ ë°ì´í„° ê³¼í•™ìì™€ í•¨ê»˜ í•©ë‹ˆë‹¤."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "ë¸”ë¡œê·¸",
    "section": "",
    "text": "AIê°€ ì˜ì•„ì˜¬ë¦° ì‘ì€ ê³µ\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAIê°€ ê¸°ì¡´ ë°ì´í„° ê³¼í•™ íŒ¨ëŸ¬ë‹¤ì„ì„ ë°”ê¾¸ê³  ìˆìŠµë‹ˆë‹¤.\n\n\n\n\n\n\nJan 27, 2023\n\n\nì´ê´‘ì¶˜\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\në¹„ì¥¬ì–¼ ìŠ¤íŠœë””ì˜¤ ì½”ë“œ IDEë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë°œ ìƒì‚°ì„±ì„ ë†’ì¸ë‹¤.\n\n\n\n\n\n\nJan 26, 2023\n\n\nì´ê´‘ì¶˜\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chatGPT",
    "section": "",
    "text": "ê°€ìâ€¦\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nAIê°€ ì˜ì•„ì˜¬ë¦° ì‘ì€ ê³µ\n\n\n\n\n\n\n\nIDE\n\n\nrstudio\n\n\njupyter\n\n\nvscode\n\n\ncopilot\n\n\n\n\nAIê°€ ê¸°ì¡´ ë°ì´í„° ê³¼í•™ íŒ¨ëŸ¬ë‹¤ì„ì„ ë°”ê¾¸ê³  ìˆìŠµë‹ˆë‹¤.\n\n\n\n\n\n\n2023ë…„ 02ì›” 12ì¼\n\n\nì´ê´‘ì¶˜\n\n\n\n\n\n\n  \n\n\n\n\nVisual Studio Code\n\n\n\n\n\n\n\nIDE\n\n\nvscode\n\n\ncopilot\n\n\nchatGPT\n\n\n\n\në¹„ì¥¬ì–¼ ìŠ¤íŠœë””ì˜¤ ì½”ë“œ IDEë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë°œ ìƒì‚°ì„±ì„ ë†’ì¸ë‹¤.\n\n\n\n\n\n\n2023ë…„ 01ì›” 26ì¼\n\n\nì´ê´‘ì¶˜\n\n\n\n\n\n\nì¼ì¹˜ ì—†ìŒ"
  },
  {
    "objectID": "codex.html",
    "href": "codex.html",
    "title": "chatGPT",
    "section": "",
    "text": "1 Codex\nLow-code and GPT-3: easier said than done with OpenAI Codex\n\nì£¼ì„ì„ ì½”ë“œë¡œ ì „í™˜\në§¥ë½ì„ ë³´ê³  ë‹¤ìŒ ì½”ë“œë¥¼ ìë™ ì‘ì„±\në¼ì´ë¸ŒëŸ¬ë¦¬, API ë“± ì¶”ì²œì„ í†µí•´ ìƒˆë¡œìš´ ì§€ì‹ ì „ë‹¬\nì£¼ì„ ìë™ ì¶”ê°€\në™ì¼í•œ ê¸°ëŠ¥ì„ ê°–ì§€ë©´ íš¨ìœ¨ì„± ì¢‹ì€ ì½”ë“œë¡œ ë³€í™˜\n\n2 ì´ë¯¸ì§€ ìƒì„±\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"Create R programming language logo for Korean R user group in a kandinsky and Gustav Klimt style embracing Python programming language supported by many contributors around the world, which must include R logo from R consortium and wikipedia\",\n    n = 1,\n    size = \"256x256\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\nlibrary(magick)\nastronaut <- image_read(response$data$url)\nprint(astronaut)\n#> # A tibble: 1 Ã— 7\n#>   format width height colorspace matte filesize density\n#>   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n#> 1 PNG      256    256 sRGB       FALSE   197109 72x72\n\n\n\n\n\n\n\n\n3 ì˜ˆì¸¡ëª¨í˜•\n\nì½”ë“œpenguins_classification_instruction <- \n  glue::glue(\"# R language\\n\",\n             \"Build sex classification machine learning model withe palmer penguin datatset\\n\",\n             \"Use palmer penguins data package for dataset\\n\",\n             \"Use tidymodels framework\\n\",\n             \"Use random forest model\\n\",\n             \"Include evaluation metrics including accruacy, precision, reall\")\n\nbuild_model <- create_completion(\n    model=\"code-davinci-002\",\n    prompt = penguins_classification_instruction,\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\n\n\nì½”ë“œ\nparsed_code <- str_split(build_model$choices$text, \"\\n\")[[1]]\n\nwrite_lines(parsed_code, \"palmer_penguins.Rmd\")"
  },
  {
    "objectID": "palmer_penguins.html",
    "href": "palmer_penguins.html",
    "title": "chatGPT",
    "section": "",
    "text": "Install packages library  palmerpenguins  and tidymodels\n\nì½”ë“œinstall.packages('palmerpenguins')\ninstall.packages('tidymodels')\n\n\n\nLoad libraries\n\nì½”ë“œlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nì½”ë“œlibrary(palmerpenguins)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nì½”ë“œlibrary(ggplot2)\nlibrary(tidyverse)\n\nâ”€â”€ Attaching packages\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntidyverse 1.3.2 â”€â”€\n\n\nâœ” tibble  3.1.8     âœ” purrr   0.3.5\nâœ” tidyr   1.2.1     âœ” stringr 1.5.0\nâœ” readr   2.1.3     âœ” forcats 0.5.2\nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– data.table::between() masks dplyr::between()\nâœ– dplyr::filter()       masks stats::filter()\nâœ– data.table::first()   masks dplyr::first()\nâœ– dplyr::lag()          masks stats::lag()\nâœ– data.table::last()    masks dplyr::last()\nâœ– purrr::transpose()    masks data.table::transpose()\n\nì½”ë“œlibrary(tidymodels)\n\nâ”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.0.0 â”€â”€\nâœ” broom        1.0.1     âœ” rsample      1.1.1\nâœ” dials        1.1.0     âœ” tune         1.0.1\nâœ” infer        1.0.4     âœ” workflows    1.1.2\nâœ” modeldata    1.0.1     âœ” workflowsets 1.0.0\nâœ” parsnip      1.0.3     âœ” yardstick    1.1.0\nâœ” recipes      1.0.3     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\nâœ– data.table::between() masks dplyr::between()\nâœ– scales::discard()     masks purrr::discard()\nâœ– dplyr::filter()       masks stats::filter()\nâœ– data.table::first()   masks dplyr::first()\nâœ– recipes::fixed()      masks stringr::fixed()\nâœ– dplyr::lag()          masks stats::lag()\nâœ– data.table::last()    masks dplyr::last()\nâœ– yardstick::spec()     masks readr::spec()\nâœ– recipes::step()       masks stats::step()\nâœ– purrr::transpose()    masks data.table::transpose()\nâ€¢ Search for functions across packages at https://www.tidymodels.org/find/\n\nì½”ë“œlibrary(ggfortify)\n\nRegistered S3 method overwritten by 'ggfortify':\n  method          from   \n  autoplot.glmnet parsnip\n\nì½”ë“œlibrary(recipes)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nì½”ë“œlibrary(profvis)\nlibrary(purrr)"
  },
  {
    "objectID": "palmer_penguins.html#load-data",
    "href": "palmer_penguins.html#load-data",
    "title": "chatGPT",
    "section": "Load data",
    "text": "Load data\n\nì½”ë“œpenguins <- penguins %>% \n  mutate_if(is.character, as.factor) %>% \n  drop_na()"
  },
  {
    "objectID": "palmer_penguins.html#eda",
    "href": "palmer_penguins.html#eda",
    "title": "chatGPT",
    "section": "EDA",
    "text": "EDA\nThe penguins dataset includes measurements of flow characteristics of the components. Only pterosaur data are considered in this project\n\nì½”ë“œglimpse(penguins)\n\nRows: 333\nColumns: 7\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelâ€¦\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerseâ€¦\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6â€¦\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2â€¦\n$ flipper_length_mm <int> 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18â€¦\n$ body_mass_g       <int> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800â€¦\n$ sex               <fct> male, female, female, female, male, female, male, feâ€¦\n\n\n\nì½”ë“œsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :146   Biscoe   :163   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :123   1st Qu.:39.50   1st Qu.:15.60  \n Gentoo   :119   Torgersen: 47   Median :44.50   Median :17.30  \n                                 Mean   :43.99   Mean   :17.16  \n                                 3rd Qu.:48.60   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex     \n Min.   :172       Min.   :2700   female:165  \n 1st Qu.:190       1st Qu.:3550   male  :168  \n Median :197       Median :4050               \n Mean   :201       Mean   :4207               \n 3rd Qu.:213       3rd Qu.:4775               \n Max.   :231       Max.   :6300               \n\n\n\nì½”ë“œpenguins %>% select_if(Negate(is.factor)) %>% \n  cor() %>% \n  as.data.frame() %>% \n  rowid_to_column() %>% \n  pivot_longer(- rowid) %>% \n  arrange(desc(abs(value))) %>% \n  filter(value != 1)\n\n# A tibble: 12 Ã— 3\n   rowid name               value\n   <int> <chr>              <dbl>\n 1     3 body_mass_g        0.873\n 2     4 flipper_length_mm  0.873\n 3     1 flipper_length_mm  0.653\n 4     3 bill_length_mm     0.653\n 5     1 body_mass_g        0.589\n 6     4 bill_length_mm     0.589\n 7     2 flipper_length_mm -0.578\n 8     3 bill_depth_mm     -0.578\n 9     2 body_mass_g       -0.472\n10     4 bill_depth_mm     -0.472\n11     1 bill_depth_mm     -0.229\n12     2 bill_length_mm    -0.229\n\n\n\nì½”ë“œsite_number <- 1:4\npdf('penguin_data.pdf')\npar(mfrow = c(2, 2))\nfor (i in site_number)\n{\n  penguins %>% \n    filter(site_number == i) %>% \n    ggplot(aes(x= species, y= flipper_length_mm, fill = species, color= species)) +\n    geom_boxplot() +\n    labs(x = 'Species', y = 'Flipper length (mm)', title = paste('Fvuwerfvczefcfzccfgct', i)) +\n    theme(axis.text = element_text(size = 8))\n}\ndev.off()\n\n\n\nì½”ë“œggviolin(penguins, x = species,\n        y = bill_length_mm+bill_depth_mm,\n        fill = species)\n\n\n\nì½”ë“œglimpse(penguins$sex)\ntable(penguins$sex, useNA='ifany')"
  },
  {
    "objectID": "palmer_penguins.html#data-preparation",
    "href": "palmer_penguins.html#data-preparation",
    "title": "chatGPT",
    "section": "Data preparation",
    "text": "Data preparation\nSet for training and testing data\n\nì½”ë“œset.seed(3223)\ntrain_test_split <- penguins %>% initial_split(prop = .7)\npenguin_train <- training(train_test_split)\npenguin_test <- testing(train_test_split)\nglimpse(penguin_train)\n\n\nCreate recipe\n\nì½”ë“œsoftmaxkitchen <- recipe(sex ~ ., data = penguin_train) %>%\n step_other(antipodean_island, all_nominal())%>%\nstep_novel(all_nominal())%>%\nstep_other(bill_length_mm, one_of('median-virginica'))%>%\nstep_other(bill_depth_mm, one_of('median-virginica'))"
  },
  {
    "objectID": "palmer_penguins.html#visualize-recipe-steps",
    "href": "palmer_penguins.html#visualize-recipe-steps",
    "title": "chatGPT",
    "section": "Visualize recipe steps",
    "text": "Visualize recipe steps\n\nì½”ë“œprint(softmaxkitchen)\n\n\n\nì½”ë“œprepped_penguin <- prep(softmaxkitchen, new_data = penguin_train)\nprepped_penguin %>% juice() %>% get_condition(pen_length_mm) -> penguin_ped_len\nprepped_penguin %>% juice() %>% get_condition(flipper_length_mm) -> penguin_flipper_len\npenguin_ped_len\npenguin_flipper_len\npenguin_sex\nprepped_penguin %>% bake(new_data = penguin_train) -> penguin_data\npenguin_data %>% juice() -> penguin_data_j\npenguin_data_j\npenguin_pen_len <- penguin_data_j %>"
  },
  {
    "objectID": "image2image.html",
    "href": "image2image.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì—­ì‚¬ìƒ ê°€ì¥ ìœ ëª…í•œ í™”í’ì„ chatGPTë¡œë¶€í„° ì¶”ì²œë°›ì•„ ì´ë¥¼ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì‹œê°í™”í•´ë³´ì. ë¬´ë³‘ì¥ìˆ˜(ç„¡ç—…é•·å£½)ë¥¼ ì£¼ì œë¡œ ê·¸ë¦¼ì„ ê·¸ë ¤ë³´ì.\n\në¬´ë³‘ì¥ìˆ˜ ì„¸ìƒì„ ë¥´ë„¤ìƒìŠ¤ í™”í’ìœ¼ë¡œ ê·¸ë ¤ì¤˜ : â€˜draw good health and long life world in a Renaissance styleâ€™\n\n\nrecommend the most famous painting style in history\n\n\n\n\n\n\ncompletion\n\n\n\n\n\nHere are some of the most famous painting styles in history:\n\nRenaissance: The Renaissance was a cultural movement in Italy from the 14th to the 17th century, characterized by a renewed interest in classical art, philosophy, and science. Renaissance paintings are known for their realism, balance, and harmony.\nBaroque: The Baroque style was popular in Europe from the late 16th to the early 18th century. Baroque paintings are known for their dramatic lighting, intense emotions, and dynamic compositions.\nImpressionism: Impressionism was a modernist movement in French painting in the late 19th century. Impressionist paintings are known for their loose brushstrokes, light-filled compositions, and focus on capturing fleeting moments.\nSurrealism: Surrealism was a cultural movement in the 20th century that aimed to liberate the imagination and explore the subconscious. Surrealist paintings are known for their dreamlike and fantastical imagery.\nAbstract Expressionism: Abstract Expressionism was a modernist movement in American painting in the mid-20th century. Abstract Expressionist paintings are known for their large canvases, gestural brushstrokes, and emphasis on the process of creation.\n\nThese are just a few examples of famous painting styles in history. There are many other styles that have influenced and shaped the course of art history.\n\n\n\nOpen AI - Create image API\n\n\në¥´ë„¤ìƒìŠ¤(Renaissance)\në°”ë¡œí¬(Baroque)\nì¸ìƒì£¼ì˜(Impressionism)\nì´ˆí˜„ì‹¤ì£¼ì˜(Surrealism)\nì¶”ìƒí‘œí˜„ì£¼ì˜(Abstract Expressionism)\n\n\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\n# usethis::edit_r_environ(scope = \"project\")\n\nresponse <- create_image(\n    prompt = \"draw good health and long life world in a Renaissance style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nRenaissance <- image_read(response$data$url)\nprint(Renaissance)\n\nimage_write(Renaissance, path = \"images/styles/Renaissance.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Baroque style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nBaroque <- image_read(response$data$url)\nprint(Baroque)\n\nimage_write(Baroque, path = \"images/styles/Baroque.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Impressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nImpressionism <- image_read(response$data$url)\nprint(Impressionism)\n\nimage_write(Impressionism, path = \"images/styles/Impressionism.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Surrealism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nSurrealism <- image_read(response$data$url)\nprint(Surrealism)\n\nimage_write(Surrealism, path = \"images/styles/Surrealism.png\", format = \"png\")\n\n\n\n\n\n\n\n\n\nì½”ë“œresponse <- create_image(\n    prompt = \"draw good health and long life world in a Abstract Expressionism style\",\n    n = 1,\n    size = \"1024x1024\",\n    response_format = \"url\",\n    openai_api_key = Sys.getenv('OPEN_AI_KEY')\n)\n\nexpressionism <- image_read(response$data$url)\nprint(expressionism)\n\nimage_write(expressionism, path = \"images/styles/expressionism.png\", format = \"png\")"
  },
  {
    "objectID": "math.html",
    "href": "math.html",
    "title": "chatGPT",
    "section": "",
    "text": "í•¨ìˆ˜ \\(f(x)=x^3+3 x^2+x-1\\) ì— ëŒ€í•˜ì—¬ \\(f^{\\prime}(1)\\) ì˜ ê°’ì€?\n\n\nì½”ë“œlibrary(tidyverse)\nlibrary(openai)\n\nsolve_math_02 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = '\\\\text { 2. í•¨ìˆ˜ } f(x)=x^3+3 x^2+x-1 \\\\text { ì— ëŒ€í•˜ì—¬ } f^{\\\\prime}(1) \\\\text { ì˜ ê°’ì€? } and explain the answer',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_02$choices$text)\n#> \n#> \n#> f'(1)ì˜ ê°’ì€ 5ì…ë‹ˆë‹¤.\n#> f(x)ëŠ” x^3+3x^2+x-1ì´ë¯€ë¡œ, ë¯¸ë¶„í•˜ë©´ f'(x) = 3x^2 + 6x + 1ì´ ë©ë‹ˆë‹¤. ê·¸ë¦¬ê³  x = 1ì¼ ë•Œ, f'(1) = 3*1^2 + 6*1 + 1 = 5ê°€ ë©ë‹ˆë‹¤.\n\n\n\n\në“±ì°¨ìˆ˜ì—´ \\(\\left\\{a_n\\right\\}\\) ì— ëŒ€í•˜ì—¬ \\[\na_2=6, \\quad a_4+a_6=36\n\\] ì¼ ë•Œ, \\(a_{10}\\) ì˜ ê°’ì€?\n\n\nì½”ë“œsolve_math_03 <- create_completion(\n    model=\"text-davinci-003\",\n    prompt = 'ë“±ì°¨ìˆ˜ì—´ $\\left\\{a_n\\right\\}$ ì— ëŒ€í•˜ì—¬\n$$\na_2=6, \\quad a_4+a_6=36\n$$\nì¼ ë•Œ, $a_{10}$ ì˜ ê°’ì€?',\n    max_tokens=1024,\n    openai_api_key = Sys.getenv(\"OPEN_AI_KEY\")\n)\n\ncat(solve_math_03$choices$text)\n\n\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_4 + a_6 = 36 \\\\\n\\end{align}\n\\]\në“±ì°¨ìˆ˜ì—´ì˜ ì •ì˜ì— ë”°ë¼ \\(a_n = a_1 + (n-1)d\\) ì´ë¯€ë¡œ, \\(a_1\\) ê³¼ \\(d\\) ë¥¼ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤.\n\\[\n\\begin{align}\n& a_2 = 6 \\\\\n& a_2 = a_1 + (2-1)d \\\\\n\\therefore \\quad & a_1 = 6 - d \\\\\n\\end{align}\n\\]\n\\[\n\\begin{align}\n& a_4 + a_6 = 36 \\\\\n& a_4 = a_1 + (4-1)d \\\\\n& a_6 = a_1 + (6-1)d \\\\\n\\therefore \\quad & a_1 + 3d + a_1 + 5d = 36\n\\end{align}\n\\]"
  },
  {
    "objectID": "rcoding.html",
    "href": "rcoding.html",
    "title": "chatGPT",
    "section": "",
    "text": "gpttools GitHub ì €ì¥ì†Œì—ì„œ ë°”ë¡œ ì„¤ì¹˜í•œë‹¤.\nrequire(remotes)\nremotes::install_github(\"JamesHWade/gpttools\")"
  },
  {
    "objectID": "rcoding.html#ì£¼ì„ë‹¬ê¸°",
    "href": "rcoding.html#ì£¼ì„ë‹¬ê¸°",
    "title": "chatGPT",
    "section": "\n4.1 ì£¼ì„ë‹¬ê¸°",
    "text": "4.1 ì£¼ì„ë‹¬ê¸°"
  },
  {
    "objectID": "rcoding.html#roxygen-ì¶”ê°€",
    "href": "rcoding.html#roxygen-ì¶”ê°€",
    "title": "chatGPT",
    "section": "\n4.2 Roxygen ì¶”ê°€",
    "text": "4.2 Roxygen ì¶”ê°€"
  },
  {
    "objectID": "rcoding.html#ìŠ¤í¬ë¦½íŠ¸-í•¨ìˆ˜",
    "href": "rcoding.html#ìŠ¤í¬ë¦½íŠ¸-í•¨ìˆ˜",
    "title": "chatGPT",
    "section": "\n4.3 ìŠ¤í¬ë¦½íŠ¸ â†’ í•¨ìˆ˜",
    "text": "4.3 ìŠ¤í¬ë¦½íŠ¸ â†’ í•¨ìˆ˜"
  },
  {
    "objectID": "rcoding.html#í•¨ìˆ˜ì—-ë‹¨ìœ„-í…ŒìŠ¤íŠ¸-ì¶”ì²œ",
    "href": "rcoding.html#í•¨ìˆ˜ì—-ë‹¨ìœ„-í…ŒìŠ¤íŠ¸-ì¶”ì²œ",
    "title": "chatGPT",
    "section": "\n4.4 í•¨ìˆ˜ì— ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ì²œ",
    "text": "4.4 í•¨ìˆ˜ì— ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ì²œ"
  },
  {
    "objectID": "interview.html",
    "href": "interview.html",
    "title": "chatGPT",
    "section": "",
    "text": "ì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nê¸°ê³„í•™ìŠµ ë¶„ë¥˜ëª¨í˜•ê°œë°œí•  ë•Œ í´ë˜ìŠ¤ ë¶ˆê· í˜•(class imbalance) ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nê¸°ê³„í•™ìŠµëª¨í˜•ì—ì„œ bias ì™€ variance trade-offì—ì„œ ì¡´ì¬í•©ë‹ˆë‹¤. ì–´ë–¤ ê¸°ê³„í•™ìŠµ ëª¨í˜•ì´ bias ì™€ varianceë¥¼ ì¤„ì´ëŠ”ë° íš¨ê³¼ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‚˜ìš”?\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\në¦¬ìŠ¤íŠ¸ì™€ ë°ì´í„°í”„ë ˆì„ ìë£Œêµ¬ì¡°ì˜ ì°¨ì´ì ì— ëŒ€í•´ì„œ ë§ì”€í•´ ì£¼ì„¸ìš”.\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nfeature engineering, data preprocessing, data cleansingì´ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì„¤ëª…í•˜ì„¸ìš”.\n\n\n\n\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nì œí’ˆ ì„¤ëª… ë“± í…ìŠ¤íŠ¸ í•„ë“œ ì¹¼ëŸ¼ì´ ìˆìŠµë‹ˆë‹¤. ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ë¶„ë¥˜ë‚˜ ì˜ˆì¸¡ ëª¨í˜•ì— ì ìš©ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
  },
  {
    "objectID": "interview.html#visualization",
    "href": "interview.html#visualization",
    "title": "chatGPT",
    "section": "\n2.1 Visualization",
    "text": "2.1 Visualization\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\nData Analyticsì—ì„œ ì‹œê°í™”ëŠ” ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–»ê²Œ ê°€ë¥´ì¹ ê²ƒì¸ì§€ ì»¤ëŸ¬í˜ëŸ¼, êµìˆ˜ë°©ë²•, í”„ë¡œì íŠ¸ ì§„í–‰ë°©ë²•, í‰ê°€ë°©ë²•ì— ëŒ€í•´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”. (5ë¶„)"
  },
  {
    "objectID": "interview.html#eda",
    "href": "interview.html#eda",
    "title": "chatGPT",
    "section": "\n2.2 EDA",
    "text": "2.2 EDA\n\n\n\n\n\n\nì§ˆë¬¸/ê³¼ì œ\n\n\n\n\n\níƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)ê°€ í›Œë¥­í•œ ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê°œë°œê³¼ í•¨ê»˜ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì–´ë–»ê²Œ ê°€ë¥´ì¹ ê²ƒì¸ì§€ ì»¤ëŸ¬í˜ëŸ¼, êµìˆ˜ë°©ë²•, í”„ë¡œì íŠ¸ ì§„í–‰ë°©ë²•, í‰ê°€ë°©ë²•ì— ëŒ€í•´ì„œ ë§ì”€í•´ì£¼ì„¸ìš”. (5ë¶„)"
  },
  {
    "objectID": "hf.html",
    "href": "hf.html",
    "title": "chatGPT",
    "section": "",
    "text": "íŒŒì´ì¬ì„ ê³„ì† ì‚¬ìš©í•˜ë‹¤ë³´ë‹ˆ ë¬´ì¡°ê±´ ê°€ìƒí™˜ê²½ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤ëŠ” ê±¸ ì ˆì‹¤íˆ ëŠë¼ê²Œ ëœë‹¤. ì‹œê°„ì´ ì§€ë‚˜ë©´ ì–´ë–¤ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í–ˆì—ˆëŠ”ì§€ í™•ì¸ì´ ë˜ì§€ ì•Šê³  ì–´ë–¤ ê²ƒì´ ë¬¸ì œê°€ ë˜ì–´ ì˜ ëŒë˜ ì½”ë“œê°€ ì œëŒ€ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ”ì§€ íŒŒì•…ì´ í˜ë“œëŠ” ì§€ê²½ì— ì´ë¥´ê²Œ ëœë‹¤.\níŒŒì´ì¬3ì—ì„œ venv, virtualenv ë‘ê°€ì§€ ê°€ìƒí™˜ê²½ íŒ©í‚¤ì§€ê°€ ì œê³µë˜ëŠ”ë° ì„ íƒì„ í•´ì•¼í•œë‹¤. ê²°ë¡ ì€ íŒŒì´ì¬3ì—ì„œ venvê°€ ì§€ì›ë˜ë‹ˆ ë³„ë„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ì—†ì´ venvë¡œ ê°€ëŠ” ê²ƒì´ ì¢‹ë‹¤.\n\npython3 -m venv <ê°€ìƒí™˜ê²½ ëª…ì¹­>\nsource <ê°€ìƒí™˜ê²½ ëª…ì¹­>/bin/activate\npip install -U pip\npip install pandas\npip freeze > requirements.txt\n\nê°€ìƒí™˜ê²½ ìƒì„±ë¶€í„° ì£¼ìš”í•œ ê°€ìƒí™˜ê²½ ì„¤ì • ë°©ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ íŒŒì•…í•´ë³´ì.\n\n\nìƒì„±\ní™œì„±í™”\níŒŒì´ì¬\npip ì„¤ì¹˜\níŒë‹¤ìŠ¤ ì„¤ì¹˜\nfreeze\nrequirements.txt\nê°€ìƒí™˜ê²½ êµ¬ì¡°\ndeactivate\n\n\n\npy-3.10.9 tidyverse in ~/venv\nâ—‹ â†’ python3 -m venv venv\n\n\npy-3.10.9 tidyverse in ~/venv\nâ—‹ â†’ source venv/bin/activate\n\n## .\\venv\\Scripts\\activate ## ìœˆë„ìš°ì¦ˆ\n\n\nâ—‹ â†’ which python\n/Users/tidyverse/venv/venv/bin/python\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip install -U pip\nRequirement already satisfied: pip in ./venv/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Using cached pip-23.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip install pandas\nCollecting pandas\n  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.0/12.0 MB 5.7 MB/s eta 0:00:00\nCollecting pytz>=2020.1\n  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\nCollecting numpy>=1.20.3\n  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.8/19.8 MB 4.3 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.1\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting six>=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, six, numpy, python-dateutil, pandas\nSuccessfully installed numpy-1.24.2 pandas-1.5.3 python-dateutil-2.8.2 pytz-2022.7.1 six-1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip freeze\nnumpy==1.24.2\npandas==1.5.3\npython-dateutil==2.8.2\npytz==2022.7.1\nsix==1.16.0\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ pip freeze > requirements.txt\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ tree -L 2\n.\nâ”œâ”€â”€ requirements.txt\nâ””â”€â”€ venv\n    â”œâ”€â”€ bin\n    â”œâ”€â”€ include\n    â”œâ”€â”€ lib\n    â””â”€â”€ pyvenv.cfg\n\n4 directories, 2 files\n\n\n |venv|py-3.9.6 tidyverse in ~/venv\nâ—‹ â†’ deactivate\n\npy-3.10.9 tidyverse in ~/venv\nâ—‹ â†’"
  },
  {
    "objectID": "hf.html#í™˜ê²½-ì„¤ì •",
    "href": "hf.html#í™˜ê²½-ì„¤ì •",
    "title": "chatGPT",
    "section": "í™˜ê²½ ì„¤ì •",
    "text": "í™˜ê²½ ì„¤ì •\níŒŒì´ì¬ ê°€ìƒí™˜ê²½ì„ ì¤€ë¹„í•˜ê³  transformers ë° ì—°ê´€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\nuse_python(\"~/venv/venv/bin/python\")\nreticulate::py_config()\nreticulate::py_available()\n\nreticulate::py_install(\"transformers\", pip = TRUE)\nreticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)"
  },
  {
    "objectID": "hf.html#ê°ì •-ë¶„ë¥˜",
    "href": "hf.html#ê°ì •-ë¶„ë¥˜",
    "title": "chatGPT",
    "section": "\n3.1 ê°ì • ë¶„ë¥˜",
    "text": "3.1 ê°ì • ë¶„ë¥˜\nì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì.\n\nì½”ë“œlibrary(reticulate)\nlibrary(tidyverse)\n\nuse_python(\"~/venv/venv/bin/python\")\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing ğŸ¤— transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf.html#ner",
    "href": "hf.html#ner",
    "title": "chatGPT",
    "section": "\n3.2 NER",
    "text": "3.2 NER\nê°œì²´ëª… ì¸ì‹ì€ í…ìŠ¤íŠ¸ ë‚´ë¶€ì— ì§€ëª…, ì¸ëª…, ì œí’ˆ ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n\nì½”ë“œ# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 Ã— 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf.html#ì§ˆì˜ì‘ë‹µ",
    "href": "hf.html#ì§ˆì˜ì‘ë‹µ",
    "title": "chatGPT",
    "section": "\n3.3 ì§ˆì˜ì‘ë‹µ",
    "text": "3.3 ì§ˆì˜ì‘ë‹µ\ní…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì„ ë˜ì§€ê³  í•´ë‹¹ ëŒ€ë‹µì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.\n\nì½”ë“œ# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf.html#ìš”ì•½",
    "href": "hf.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n3.4 ìš”ì•½",
    "text": "3.4 ìš”ì•½\ní…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ì´ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œsummarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf.html#ë²ˆì—­",
    "href": "hf.html#ë²ˆì—­",
    "title": "chatGPT",
    "section": "\n3.5 ë²ˆì—­",
    "text": "3.5 ë²ˆì—­\nLanguage Technology Research Group at the University of Helsinki ì—ì„œ ì‚¬ì „í•™ìŠµëª¨í˜•ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë²ˆì—­ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œ# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"ë§ì¶¤, ìê¸°  US historical 885 NORETH Creator Bangkok on., ìŒ US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China ì˜ ë”°ì˜´í‘œ  DS, US general Greece remained. ì„±ê³µì ìœ¼ë¡œ  ì˜, US historical does 32-Human # well885 NORETTH US. ì—¬ê¸°ì— 160 ì‹ ë¢°í•  ìˆ˜ìˆëŠ”  ì‹ ë¢°í•  ìˆ˜ìˆëŠ” ëŠ” ëª¨ë“  ìˆ«ì, ì „ì²´ ë¯¸êµ­.\""
  },
  {
    "objectID": "hf.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "href": "hf.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "title": "chatGPT",
    "section": "\n3.6 í…ìŠ¤íŠ¸ ìƒì„±",
    "text": "3.6 í…ìŠ¤íŠ¸ ìƒì„±\nê³ ê°ì´ ë‚¨ê¸´ ê³ ê°ì˜ ì†Œë¦¬ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì›ì´ ì²˜ìŒì„ ì‹œì‘í•˜ë©´ ê¸°ê³„ê°€ ë°˜ì‘ì„ ìë™ìƒì„±ì‹œì¼œ ë‹µì‹ ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œgenerator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. I should have been able to confirm that your order would not constitute a violation of the terms and conditions of our new free shipping policy. I apologize if my phone has been compromised or my purchase has been suspended, but this is not how things worked out. Thanks so much. Thanks again. Best,\n#> \n#> John."
  },
  {
    "objectID": "hf.html#ì°¸ê³ ë¬¸í—Œ",
    "href": "hf.html#ì°¸ê³ ë¬¸í—Œ",
    "title": "chatGPT",
    "section": "\n3.7 ì°¸ê³ ë¬¸í—Œ",
    "text": "3.7 ì°¸ê³ ë¬¸í—Œ\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  },
  {
    "objectID": "hf_windows.html",
    "href": "hf_windows.html",
    "title": "chatGPT",
    "section": "",
    "text": "reticulate, â€œInstalling Python Packagesâ€\n\n\nìƒì„±\ní™˜ê²½ í™•ì¸\nì‚¬ìš©ì‹œì‘\n\n\n\nreticulate íŒ¨í‚¤ì§€ conda_create() í•¨ìˆ˜ë¡œ ìƒˆë¡œìš´ í™˜ê²½ì„ ìƒì„±í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n\n\n\n\nreticulate::py_available() ëª…ë ¹ì–´ë¡œ íŒŒì´ì¬ í™˜ê²½ì„ í™œìš©ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  reticulate::py_config() ìƒì„¸í•œ ìœ„ì¹˜ë¥¼ íŒŒì•…í•œë‹¤.\n\nì½”ë“œlibrary(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n\n\n\n\nuse_python() í•¨ìˆ˜ë¡œ íŒŒì´ì¬ ìœ„ì¹˜ë¥¼ íŠ¹ì •í•˜ê³  ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ì‹œì‘í•œë‹¤. ì¤€ë¹„ëœ íŒŒì´ì¬ ê°€ìƒí™˜ê²½ì— transformers ë° ì—°ê´€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\nì½”ë“œ\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)"
  },
  {
    "objectID": "hf_windows.html#ê°ì •-ë¶„ë¥˜",
    "href": "hf_windows.html#ê°ì •-ë¶„ë¥˜",
    "title": "chatGPT",
    "section": "\n2.1 ê°ì • ë¶„ë¥˜",
    "text": "2.1 ê°ì • ë¶„ë¥˜\nì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì.\n\nì½”ë“œlibrary(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing ğŸ¤— transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902"
  },
  {
    "objectID": "hf_windows.html#ner",
    "href": "hf_windows.html#ner",
    "title": "chatGPT",
    "section": "\n2.2 NER",
    "text": "2.2 NER\nê°œì²´ëª… ì¸ì‹ì€ í…ìŠ¤íŠ¸ ë‚´ë¶€ì— ì§€ëª…, ì¸ëª…, ì œí’ˆ ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n\nì½”ë“œ# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 Ã— 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511"
  },
  {
    "objectID": "hf_windows.html#ì§ˆì˜ì‘ë‹µ",
    "href": "hf_windows.html#ì§ˆì˜ì‘ë‹µ",
    "title": "chatGPT",
    "section": "\n2.3 ì§ˆì˜ì‘ë‹µ",
    "text": "2.3 ì§ˆì˜ì‘ë‹µ\ní…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì„ ë˜ì§€ê³  í•´ë‹¹ ëŒ€ë‹µì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.\n\nì½”ë“œ# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron"
  },
  {
    "objectID": "hf_windows.html#ìš”ì•½",
    "href": "hf_windows.html#ìš”ì•½",
    "title": "chatGPT",
    "section": "\n2.4 ìš”ì•½",
    "text": "2.4 ìš”ì•½\ní…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ì´ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œsummarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\""
  },
  {
    "objectID": "hf_windows.html#ë²ˆì—­",
    "href": "hf_windows.html#ë²ˆì—­",
    "title": "chatGPT",
    "section": "\n2.5 ë²ˆì—­",
    "text": "2.5 ë²ˆì—­\nLanguage Technology Research Group at the University of Helsinki ì—ì„œ ì‚¬ì „í•™ìŠµëª¨í˜•ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë²ˆì—­ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œ# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"ë§ì¶¤, ìê¸°  US historical 885 NORETH Creator Bangkok on., ìŒ US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China ì˜ ë”°ì˜´í‘œ  DS, US general Greece remained. ì„±ê³µì ìœ¼ë¡œ  ì˜, US historical does 32-Human # well885 NORETTH US. ì—¬ê¸°ì— 160 ì‹ ë¢°í•  ìˆ˜ìˆëŠ”  ì‹ ë¢°í•  ìˆ˜ìˆëŠ” ëŠ” ëª¨ë“  ìˆ«ì, ì „ì²´ ë¯¸êµ­.\""
  },
  {
    "objectID": "hf_windows.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "href": "hf_windows.html#í…ìŠ¤íŠ¸-ìƒì„±",
    "title": "chatGPT",
    "section": "\n2.6 í…ìŠ¤íŠ¸ ìƒì„±",
    "text": "2.6 í…ìŠ¤íŠ¸ ìƒì„±\nê³ ê°ì´ ë‚¨ê¸´ ê³ ê°ì˜ ì†Œë¦¬ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì›ì´ ì²˜ìŒì„ ì‹œì‘í•˜ë©´ ê¸°ê³„ê°€ ë°˜ì‘ì„ ìë™ìƒì„±ì‹œì¼œ ë‹µì‹ ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.\n\nì½”ë“œgenerator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you"
  },
  {
    "objectID": "hf_windows.html#ì°¸ê³ ë¬¸í—Œ",
    "href": "hf_windows.html#ì°¸ê³ ë¬¸í—Œ",
    "title": "chatGPT",
    "section": "\n2.7 ì°¸ê³ ë¬¸í—Œ",
    "text": "2.7 ì°¸ê³ ë¬¸í—Œ\n\nNatural Language Processing with Transformers\nReticulate: R Interface to Python"
  }
]