<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="kr" xml:lang="kr"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="이광춘">
<title>chatGPT</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./images/profile.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색"
  }
}</script><script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-229551680-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script><link rel="stylesheet" href="css/quarto.css">
</head>
<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg navbar-dark "><div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">chatGPT</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
<li class="nav-item">
    <a class="nav-link" href="./index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-ai" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">생성 AI</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-ai">
<li>
    <a class="dropdown-item" href="./trends.html">
 <span class="dropdown-text">추세 트렌드</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./why_llm.html">
 <span class="dropdown-text">왜 거대언어모형인가?</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./architecture.html">
 <span class="dropdown-text">아키텍쳐</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./image2image.html">
 <span class="dropdown-text">이미지 생성</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./rcoding.html">
 <span class="dropdown-text">GPT R 코딩개발</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./rcoding-copilot.html">
 <span class="dropdown-text">부조종사 R 코딩개발</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./math.html">
 <span class="dropdown-text">수학문제</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./interview.html">
 <span class="dropdown-text">데이터 과학문제</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./deepL.html">
 <span class="dropdown-text">DeepL 번역 API</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chatgpt-응용사례" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">chatGPT 응용사례</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-chatgpt-응용사례">
<li>
    <a class="dropdown-item" href="./intro_avi.html">
 <span class="dropdown-text">R 소개영상</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro_book.html">
 <span class="dropdown-text">데이터 과학 책</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./intro_paper.html">
 <span class="dropdown-text">논문 초록</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./middle_school.html">
 <span class="dropdown-text">데이터 문해력</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./interface.html">
 <span class="dropdown-text">인터페이스</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bert" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">BERT</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bert">
<li>
    <a class="dropdown-item" href="./ide.html">
 <span class="dropdown-text">통합개발환경(IDE)</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./reticulate.html">
 <span class="dropdown-text">파이썬 환경구축</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./koGPT.html">
 <span class="dropdown-text">HuggingfaceR - 모형통계</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./BERT.html">
 <span class="dropdown-text">BERT</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./hf.html">
 <span class="dropdown-text">Hugging Face</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./hf_windows.html">
 <span class="dropdown-text">Hugging Face(윈도우)</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./hf_pipeline.html">
 <span class="dropdown-text">HF 파이프라인</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item">
    <a class="nav-link" href="./blog.html">
 <span class="menu-text">게시글</span></a>
  </li>  
</ul>
<ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item compact">
    <a class="nav-link" href="https://github.com/bit2r/chatGPT"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://r2bit.com">
 <span class="menu-text">R사용자회</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/LAION-AI/Open-Assistant"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">Open Assistant</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://rtutor.ai/">
 <span class="menu-text">RTutor</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
<div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default page-columns page-full"><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">chatGPT</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> 코드</button></div></div>
            <p class="subtitle lead">왜 거대언어모형인가?</p>
                      </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">저자</div>
    <div class="quarto-title-meta-heading">소속</div>
    
      <div class="quarto-title-meta-contents">
      <a href="https://www.linkedin.com/in/kwangchunlee/">이광춘</a> 
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              <a href="https://github.com/bit2r">
              한국 R 사용자회
              </a>
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">목차</h2>
   
  <ul>
<li><a href="#%EB%93%A4%EC%96%B4%EA%B0%80%EB%A9%B0" id="toc-들어가며" class="nav-link active" data-scroll-target="#%EB%93%A4%EC%96%B4%EA%B0%80%EB%A9%B0"><span class="toc-section-number">1</span>  들어가며</a></li>
  <li><a href="#%EB%AA%A8%ED%98%95%ED%81%AC%EA%B8%B0" id="toc-모형크기" class="nav-link" data-scroll-target="#%EB%AA%A8%ED%98%95%ED%81%AC%EA%B8%B0"><span class="toc-section-number">2</span>  모형크기</a></li>
  <li><a href="#%EA%B1%B0%EB%8C%80%EC%96%B8%EC%96%B4%EB%AA%A8%ED%98%95-%EC%84%B1%EB%8A%A5" id="toc-거대언어모형-성능" class="nav-link" data-scroll-target="#%EA%B1%B0%EB%8C%80%EC%96%B8%EC%96%B4%EB%AA%A8%ED%98%95-%EC%84%B1%EB%8A%A5"><span class="toc-section-number">3</span>  거대언어모형 성능</a></li>
  <li><a href="#%EC%88%98%ED%95%99" id="toc-수학" class="nav-link" data-scroll-target="#%EC%88%98%ED%95%99"><span class="toc-section-number">4</span>  수학</a></li>
  <li><a href="#%EB%8B%A4%EC%96%91%ED%95%9C-%EC%82%AC%EB%A1%80-palm" id="toc-다양한-사례-palm" class="nav-link" data-scroll-target="#%EB%8B%A4%EC%96%91%ED%95%9C-%EC%82%AC%EB%A1%80-palm"><span class="toc-section-number">5</span>  다양한 사례 (PaLM)</a></li>
  <li><a href="#%EA%B0%9C%EB%B0%9C%EB%B9%84" id="toc-개발비" class="nav-link" data-scroll-target="#%EA%B0%9C%EB%B0%9C%EB%B9%84"><span class="toc-section-number">6</span>  개발비</a></li>
  <li><a href="#%EC%83%9D%EC%84%B1%EB%AA%A8%ED%98%95%EC%9D%98-%EB%B6%80%EC%9E%91%EC%9A%A9" id="toc-생성모형의-부작용" class="nav-link" data-scroll-target="#%EC%83%9D%EC%84%B1%EB%AA%A8%ED%98%95%EC%9D%98-%EB%B6%80%EC%9E%91%EC%9A%A9"><span class="toc-section-number">7</span>  생성모형의 부작용</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content"><div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/tech_giant.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="images/tech_giant.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
<section id="들어가며" class="level1" data-number="1"><h1 data-number="1">
<span class="header-section-number">1</span> 들어가며</h1>
<p><strong>GPT-3(Generative Pre-trained Transformer 3)</strong>와 같은 거대 언어 모델은 인간과 유사한 언어를 처리하고 생성할 수 있기 때문에 이 시대에 중요한 역할을 한다. 이를 통해 자연어 처리, 챗봇, 언어 번역, 콘텐츠 제작, 코딩 등 다양한 애플리케이션에 수많은 가능성을 열었다는 평가를 받고 있다.</p>
<p>거대 언어 모델이 중요한 몇 가지 이유를 꼽으면 다음과 같다.</p>
<ul>
<li><p><strong>자연어 처리(Natural language processing)</strong>: GPT-3와 같은 거대 언어 모델은 대량의 텍스트 데이터를 처리할 수 있고 언어의 문맥과 의미를 이해할 수 있어 감정 분석, 언어 번역, 텍스트 분류와 같은 자연어 처리 작업을 수행할 수 있다.</p></li>
<li><p><strong>챗봇(Chatbot)</strong>: 거대 언어 모델을 사용하여 자연어 쿼리를 이해하고 응답할 수 있는 대화형 대리인(챗봇)를 만들 수 있다. 이러한 챗봇은 고객 지원, 가상 비서 및 기타 다양한 애플리케이션에서 사용할 수 있다.</p></li>
<li><p><strong>언어 번역(Language translation)</strong>: 거대 언어 모델은 여러 언어에 대해 학습할 수 있으며 고품질 언어 번역을 수행한다. 이는 관광, 전자상거래, 국제 무역 등 다양한 산업에서 유용하게 사용될 수 있다.</p></li>
<li><p><strong>콘텐츠 생성(Content creation)</strong>: 거대 언어 모델은 기사, 요약, 시 등 사람과 유사한 텍스트 콘텐츠를 생성할 수 있다. 이는 저널리즘, 콘텐츠 제작, 광고 등 다양한 산업에서 활용할 수 있다.</p></li>
<li><p><strong>코딩(Coding)</strong>: GPT-3는 소프트웨어 개발 및 자동화에 광범위한 영향을 미칠 수 있는 컴퓨터 코드를 생성할 수 있는 능력을 입증했다.</p></li>
</ul>
<p>요약하면, 거대 언어 모델은 우리가 기계와 상호작용하고 작업을 수행하는 방식을 혁신할 수 있는 잠재력을 가지고 있어 우리 시대에 중요한 기술이 될 것임은 자명하다.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">2019년</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">2021년</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">2022년</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_2019.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="[@sanh2019distilbert]"><img src="images/LLM_2019.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption"><span class="citation" data-cites="sanh2019distilbert">(<a href="#ref-sanh2019distilbert" role="doc-biblioref">Sanh et al., 2019</a>)</span></figcaption><p></p>
</figure>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_2021.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Efficient Natural Language Processing"><img src="images/LLM_2021.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption"><a href="https://hanlab.mit.edu/projects/efficientnlp_old/">Efficient Natural Language Processing</a></figcaption><p></p>
</figure>
</div>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p>![<a href="https://songys.github.io/2023Langcon/">langcon 2023 by 신정규</a>(images/LLM_langcon2023.png)</p>
</div>
</div>
</div>
</section><section id="모형크기" class="level1 page-columns page-full" data-number="2"><h1 data-number="2">
<span class="header-section-number">2</span> 모형크기</h1>
<p>question-answering tasks (open-domain closed-book variant), cloze and sentence-completion tasks, Winograd-style tasks, in-context reading comprehension tasks, common-sense reasoning tasks, SuperGLUE tasks, and natural language inference tasks가 포함된 총 29개 작업 중 28개 영역에서 PaLM 540B가 이전 거대 언어모형 GLaM, GPT-3, Megatron-Turing NLG, Gopher, Chinchilla, LaMDA 을 가볍게 능가했다.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><a href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html">Sharan Narang and Aakanksha Chowdhery (APRIL 04, 2022), “Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance”, Software Engineers, Google Research</a></span></div></div>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">LLM 진화</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">80억 패러미터</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">400억</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" role="tab" aria-controls="tabset-2-4" aria-selected="false">640억</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-5" role="tab" aria-controls="tabset-2-5" aria-selected="false">5,400억</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-6" role="tab" aria-controls="tabset-2-6" aria-selected="false">성능</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_tree.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="images/LLM_tree.gif" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_tree_8_billion.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="images/LLM_tree_8_billion.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_tree_40_billion.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="images/LLM_tree_40_billion.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-2-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-4-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_tree_62_billion.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="images/LLM_tree_62_billion.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-2-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-5-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_tree_540_billion.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="images/LLM_tree_540_billion.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-2-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-6-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_tree_performance.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="images/LLM_tree_performance.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
</section><section id="거대언어모형-성능" class="level1" data-number="3"><h1 data-number="3">
<span class="header-section-number">3</span> 거대언어모형 성능</h1>
<p>자연어 처리(NLP) 및 머신 러닝 분야의 여러 발전으로 인해 GPT-3와 같은 대규모 언어 모델의 성능이 이전 모델보다 향상되었다. 주요 원인으로 다음을 꼽을 수 있다.</p>
<ul>
<li><p><strong>규모(Scale)</strong>: 대규모 언어 모델은 방대한 양의 텍스트 데이터로 학습되어 언어의 더 많은 뉘앙스를 포착하고 문맥을 더 잘 이해할 수 있다. GPT-3는 45테라바이트가 넘는 텍스트 데이터셋으로 학습되었다고 알려져 지금까지 사전 학습된 언어 모델 중 가장 큰 규모를 갖고 있다.</p></li>
<li><p><strong>아키텍처(Architecture)</strong>: GPT-3는 병렬 처리가 가능한 트랜스포머(Transformer) 기반 아키텍처를 사용하여 학습 시간을 단축하고 성능을 향상시켰다.</p></li>
<li><p><strong>사전 학습(Pre-training)</strong>: 대규모 언어 모델은 방대한 양의 텍스트 데이터로 사전 학습되어 다양한 작업에 적용할 수 있는 일반적인 언어 패턴과 관계를 학습할 수 있다. GPT-3는 비지도 학습을 사용하여 사전 학습되므로 특정 작업을 염두에 두지 않고 원시 텍스트 데이터에서 학습했다.</p></li>
<li><p><strong>미세 조정(Fine-tuning)</strong>: 언어 번역이나 텍스트 분류와 같은 특정 작업을 위해 대규모 언어 모델을 미세 조정(Fine-tuning) 작업을 수행한다. 이 과정에는 해당 작업에 특화된 소규모 데이터셋로 모델을 추가 학습시켜 성능을 더욱 향상시킨다.</p></li>
<li><p><strong>전이 학습(Transfer learning)</strong>: 대규모 언어 모델은 한 작업에서 학습한 지식을 다른 작업으로 전이시킬 수 있다. 즉, 언어 번역과 같은 한 작업에서 학습된 모델을 더 작은 데이터셋을 사용하여 감정 분석과 같은 다른 작업에 맞게 추가 학습작업(Fine-tuning)을 시킬 수 있다.</p></li>
</ul>
<p>요약하면, 대규모 언어 모델의 성능은 규모, 아키텍처, 사전 학습, 미세 조정 및 전이 학습의 발전으로 인해 이전 모델보다 더 우수하다. 이러한 발전 덕분에 대규모 언어 모델은 다양한 언어 작업에서 최첨단 성능을 달성할 수 있게 되어 자연어 처리 및 머신 러닝 분야에서 강력한 도구가 된 것이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_few_shot.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="[@wei2022emergent]"><img src="images/LLM_few_shot.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption"><span class="citation" data-cites="wei2022emergent">(<a href="#ref-wei2022emergent" role="doc-biblioref">Wei et al., 2022</a>)</span></figcaption><p></p>
</figure>
</div>
</section><section id="수학" class="level1 page-columns page-full" data-number="4"><h1 data-number="4">
<span class="header-section-number">4</span> 수학</h1>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><span class="citation" data-cites="lewkowycz2022solving">Lewkowycz et al. (<a href="#ref-lewkowycz2022solving" role="doc-biblioref">2022</a>)</span></span></div></div>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">미네르바 LM</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">손으로 풀기</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">시각화</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-4" role="tab" aria-controls="tabset-3-4" aria-selected="false">Sympy 해법</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/math_minerva.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="images/math_minerva.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/LLM_hand.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="images/LLM_hand.jpg" class="img-fluid figure-img" style="width:50.0%"></a></p>
</figure>
</div>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">given_line</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>  <span class="fl">10</span> <span class="op">+</span> <span class="fl">4</span> <span class="op">*</span> <span class="va">x</span></span>
<span><span class="va">solve_line</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span><span class="fl">10</span> <span class="op">+</span> <span class="fl">4</span> <span class="op">*</span><span class="va">x</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">5</span>, y <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">given_line</span>, color <span class="op">=</span> <span class="st">"blue"</span>, size <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">solve_line</span>, color <span class="op">=</span> <span class="st">"red"</span>, size <span class="op">=</span> <span class="fl">1.5</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">7</span>, <span class="fl">7</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">7</span>, <span class="fl">7</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">20</span>, <span class="fl">20</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">20</span>, <span class="fl">20</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span><span class="op">)</span> </span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="why_llm_files/figure-html/unnamed-chunk-1-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img src="why_llm_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-3-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-4-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sympy <span class="im">import</span> <span class="op">*</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>x, y, b <span class="op">=</span> symbols(<span class="st">'x y b'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>given_eq <span class="op">=</span> y <span class="op">-</span> (<span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">10</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>parallel_eq <span class="op">=</span> y <span class="op">-</span> (<span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> b)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>intercept_eq <span class="op">=</span> parallel_eq.subs([(x, <span class="dv">5</span>), (y, <span class="dv">10</span>)])</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>solveset(Eq(intercept_eq, <span class="dv">0</span>), b)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; {-10}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section><section id="다양한-사례-palm" class="level1" data-number="5"><h1 data-number="5">
<span class="header-section-number">5</span> 다양한 사례 (PaLM)</h1>
<p>5,400 억 패러미터를 장착한 Pathways Language Model (PaLM)의 성능을 실감해보자.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">다양한 기능</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">추론</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">코딩</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/PaLM_overview.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="images/PaLM_overview.gif" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>추론(Reasoning)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/PaLM_reasoning.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img src="images/PaLM_reasoning.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<p>코딩(Code Generation)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/PaLM_coding.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="images/PaLM_coding.gif" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
</section><section id="개발비" class="level1 page-columns page-full" data-number="6"><h1 data-number="6">
<span class="header-section-number">6</span> 개발비</h1>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><a href="https://blog.heim.xyz/palm-training-cost/">Estimating 🌴PaLM’s training cost</a></span></div></div>
<p>언어 모형 개발은 2010년 이후 개발비용이 급격히 증가하고 있으며 그 추세는 상상을 초월한다.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Our World in Data</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Lennart Heim</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<iframe src="https://ourworldindata.org/grapher/artificial-intelligence-training-computation?yScale=linear&amp;time=2017-06-12..2022-07-01" loading="lazy" style="width: 100%; height: 600px; border: 0px none;">
</iframe>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<iframe src="https://ourworldindata.org/grapher/artificial-intelligence-training-computation?yScale=linear&amp;time=earliest..latest&amp;country=~PaLM+%28540B%29" loading="lazy" style="width: 100%; height: 600px; border: 0px none;">
</iframe>
</div>
</div>
</div>
</section><section id="생성모형의-부작용" class="level1" data-number="7"><h1 data-number="7">
<span class="header-section-number">7</span> 생성모형의 부작용</h1>
<p>생성 AI를 통해 인간이 생성한 데이터와 기계가 생성한 데이터가 무작위로 섞인 지금까지 경험하지 못한 세상이 출현하고 있다. 즉, 생성 AI 모형에서 이미지, 텍스트, 동영상 등 무수히 많은 데이터가 인터넷에 공개 및 공유될 것이며 기계학습 및 딥러닝 생성모형는 결국 실제 데이터와 기계가 생성한 데이터를 입력값으로 인공지능 모형을 생성하게 된다. 하지만 이런 경우 과연 AI 모형은 어떤 특성을 갖게 될 것인가? 데이터 증강(Data Augmentation)처럼 더 좋은 성능을 갖는 AI 모형이 될 것이가 아니면 그 반대의 모습을 가지게 될 것인가? 논문<span class="citation" data-cites="hataya2022will">(<a href="#ref-hataya2022will" role="doc-biblioref">Hataya et al., 2022</a>)</span>에서는 부정적인 효과도 있다고 주장하고 있다.</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">현재 상황</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">기계오염된 데이터</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/training_data_corrupt.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img src="images/training_data_corrupt.png" width="150" class="figure-img"></a></p>
</figure>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><a href="images/corrupt_images.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18" title="기계생성 데이터 사용하여 나온 결과물"><img src="images/corrupt_images.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">기계생성 데이터 사용하여 나온 결과물</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>


<!-- -->


</section><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">참고문헌</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-hataya2022will" class="csl-entry" role="doc-biblioentry">
Hataya, R., Bao, H., &amp; Arai, H. (2022). Will large-scale generative models corrupt future datasets? <em>arXiv Preprint arXiv:2211.08095</em>.
</div>
<div id="ref-lewkowycz2022solving" class="csl-entry" role="doc-biblioentry">
Lewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramasesh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., et al. (2022). Solving quantitative reasoning problems with language models. <em>arXiv Preprint arXiv:2206.14858</em>.
</div>
<div id="ref-sanh2019distilbert" class="csl-entry" role="doc-biblioentry">
Sanh, V., Debut, L., Chaumond, J., &amp; Wolf, T. (2019). DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. <em>arXiv Preprint arXiv:1910.01108</em>.
</div>
<div id="ref-wei2022emergent" class="csl-entry" role="doc-biblioentry">
Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. (2022). Emergent abilities of large language models. <em>arXiv Preprint arXiv:2206.07682</em>.
</div>
</div></section></div></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">소스 코드</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb3" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "chatGPT"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "왜 거대언어모형인가?"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: 이광춘</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://www.linkedin.com/in/kwangchunlee/</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: 한국 R 사용자회</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation-url: https://github.com/bit2r</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> true</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#title-block-banner: "#562457"</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">    css: css/quarto.css</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: flatly</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: 목차</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co">    highlight-style: github    </span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co">    self-contained: false</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="an">filters:</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">   - lightbox</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="an">lightbox:</span><span class="co"> auto</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="an">knitr:</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co">  opts_chunk: </span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co">    message: false</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co">    warning: false</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co">    collapse: true</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co">    comment: "#&gt;" </span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co">    R.options:</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co">      knitr.graphics.auto_pdf: true</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="an">editor_options:</span><span class="co"> </span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co">  chunk_output_type: console</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> bibliography.bib</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="an">link-citations:</span><span class="co"> yes</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="an">csl:</span><span class="co"> apa-single-spaced.csl</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/tech_giant.png)</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="fu"># 들어가며</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>**GPT-3(Generative Pre-trained Transformer 3)**와 같은 거대 언어 모델은 인간과 유사한 언어를 처리하고 생성할 수 있기 때문에 이 시대에 중요한 역할을 한다. 이를 통해 자연어 처리, 챗봇, 언어 번역, 콘텐츠 제작, 코딩 등 다양한 애플리케이션에 수많은 가능성을 열었다는 평가를 받고 있다.</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>거대 언어 모델이 중요한 몇 가지 이유를 꼽으면 다음과 같다.</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**자연어 처리(Natural language processing)**: GPT-3와 같은 거대 언어 모델은 대량의 텍스트 데이터를 처리할 수 있고 언어의 문맥과 의미를 이해할 수 있어 감정 분석, 언어 번역, 텍스트 분류와 같은 자연어 처리 작업을 수행할 수 있다.</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**챗봇(Chatbot)**: 거대 언어 모델을 사용하여 자연어 쿼리를 이해하고 응답할 수 있는 대화형 대리인(챗봇)를 만들 수 있다. 이러한 챗봇은 고객 지원, 가상 비서 및 기타 다양한 애플리케이션에서 사용할 수 있다.</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**언어 번역(Language translation)**: 거대 언어 모델은 여러 언어에 대해 학습할 수 있으며 고품질 언어 번역을 수행한다. 이는 관광, 전자상거래, 국제 무역 등 다양한 산업에서 유용하게 사용될 수 있다.</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**콘텐츠 생성(Content creation)**: 거대 언어 모델은 기사, 요약, 시 등 사람과 유사한 텍스트 콘텐츠를 생성할 수 있다. 이는 저널리즘, 콘텐츠 제작, 광고 등 다양한 산업에서 활용할 수 있다.</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**코딩(Coding)**: GPT-3는 소프트웨어 개발 및 자동화에 광범위한 영향을 미칠 수 있는 컴퓨터 코드를 생성할 수 있는 능력을 입증했다.</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>요약하면, 거대 언어 모델은 우리가 기계와 상호작용하고 작업을 수행하는 방식을 혁신할 수 있는 잠재력을 가지고 있어 우리 시대에 중요한 기술이 될 것임은 자명하다.</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>:::{.panel-tabset}</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2019년 </span></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@sanh2019distilbert</span><span class="co">]</span>](images/LLM_2019.png)</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2021년</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">Efficient Natural Language Processing</span><span class="co">](https://hanlab.mit.edu/projects/efficientnlp_old/)</span>](images/LLM_2021.png)</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2022년 </span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">langcon 2023 by 신정규</span><span class="co">](https://songys.github.io/2023Langcon/)</span>(images/LLM_langcon2023.png)</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a><span class="fu"># 모형크기</span></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>question-answering tasks (open-domain closed-book variant), cloze and sentence-completion tasks, Winograd-style tasks, in-context reading comprehension tasks, common-sense reasoning tasks, SuperGLUE tasks, and natural language inference tasks가 포함된 총 29개 작업 중 28개 영역에서 PaLM 540B가 이전 거대 언어모형 GLaM, GPT-3, Megatron-Turing NLG, Gopher, Chinchilla, LaMDA 을 가볍게 능가했다.</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>[<span class="co">[</span><span class="ot">Sharan Narang and Aakanksha Chowdhery (APRIL 04, 2022), "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance", Software Engineers, Google Research</span><span class="co">](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)</span>]{.aside}</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>:::{.panel-tabset}</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a><span class="fu">## LLM 진화</span></span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_tree.gif)</span></span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a><span class="fu">## 80억 패러미터</span></span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_tree_8_billion.png)</span></span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a><span class="fu">## 400억 </span></span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_tree_40_billion.png)</span></span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a><span class="fu">## 640억 </span></span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_tree_62_billion.png)</span></span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5,400억 </span></span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_tree_540_billion.png)</span></span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a><span class="fu">## 성능</span></span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_tree_performance.png)</span></span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-115"><a href="#cb3-115" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-116"><a href="#cb3-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-117"><a href="#cb3-117" aria-hidden="true" tabindex="-1"></a><span class="fu"># 거대언어모형 성능</span></span>
<span id="cb3-118"><a href="#cb3-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-119"><a href="#cb3-119" aria-hidden="true" tabindex="-1"></a>자연어 처리(NLP) 및 머신 러닝 분야의 여러 발전으로 인해 GPT-3와 같은 대규모 언어 모델의 성능이 이전 모델보다 향상되었다. 주요 원인으로 다음을 꼽을 수 있다.</span>
<span id="cb3-120"><a href="#cb3-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-121"><a href="#cb3-121" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**규모(Scale)**: 대규모 언어 모델은 방대한 양의 텍스트 데이터로 학습되어 언어의 더 많은 뉘앙스를 포착하고 문맥을 더 잘 이해할 수 있다. GPT-3는 45테라바이트가 넘는 텍스트 데이터셋으로 학습되었다고 알려져 지금까지 사전 학습된 언어 모델 중 가장 큰 규모를 갖고 있다.</span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**아키텍처(Architecture)**: GPT-3는 병렬 처리가 가능한 트랜스포머(Transformer) 기반 아키텍처를 사용하여 학습 시간을 단축하고 성능을 향상시켰다.</span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**사전 학습(Pre-training)**: 대규모 언어 모델은 방대한 양의 텍스트 데이터로 사전 학습되어 다양한 작업에 적용할 수 있는 일반적인 언어 패턴과 관계를 학습할 수 있다. GPT-3는 비지도 학습을 사용하여 사전 학습되므로 특정 작업을 염두에 두지 않고 원시 텍스트 데이터에서 학습했다.</span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**미세 조정(Fine-tuning)**: 언어 번역이나 텍스트 분류와 같은 특정 작업을 위해 대규모 언어 모델을 미세 조정(Fine-tuning) 작업을 수행한다. 이 과정에는 해당 작업에 특화된 소규모 데이터셋로 모델을 추가 학습시켜 성능을 더욱 향상시킨다.</span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**전이 학습(Transfer learning)**: 대규모 언어 모델은 한 작업에서 학습한 지식을 다른 작업으로 전이시킬 수 있다. 즉, 언어 번역과 같은 한 작업에서 학습된 모델을 더 작은 데이터셋을 사용하여 감정 분석과 같은 다른 작업에 맞게 추가 학습작업(Fine-tuning)을 시킬 수 있다.</span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-131"><a href="#cb3-131" aria-hidden="true" tabindex="-1"></a>요약하면, 대규모 언어 모델의 성능은 규모, 아키텍처, 사전 학습, 미세 조정 및 전이 학습의 발전으로 인해 이전 모델보다 더 우수하다. 이러한 발전 덕분에 대규모 언어 모델은 다양한 언어 작업에서 최첨단 성능을 달성할 수 있게 되어 자연어 처리 및 머신 러닝 분야에서 강력한 도구가 된 것이다.</span>
<span id="cb3-132"><a href="#cb3-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-133"><a href="#cb3-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-134"><a href="#cb3-134" aria-hidden="true" tabindex="-1"></a>![<span class="co">[</span><span class="ot">@wei2022emergent</span><span class="co">]</span>](images/LLM_few_shot.png)</span>
<span id="cb3-135"><a href="#cb3-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-136"><a href="#cb3-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-137"><a href="#cb3-137" aria-hidden="true" tabindex="-1"></a><span class="fu"># 수학</span></span>
<span id="cb3-138"><a href="#cb3-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-139"><a href="#cb3-139" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">@lewkowycz2022solving</span><span class="co">]</span>{.aside}</span>
<span id="cb3-140"><a href="#cb3-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-141"><a href="#cb3-141" aria-hidden="true" tabindex="-1"></a>:::{.panel-tabset}</span>
<span id="cb3-142"><a href="#cb3-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-143"><a href="#cb3-143" aria-hidden="true" tabindex="-1"></a><span class="fu">## 미네르바 LM</span></span>
<span id="cb3-144"><a href="#cb3-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-145"><a href="#cb3-145" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/math_minerva.png)</span></span>
<span id="cb3-146"><a href="#cb3-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-147"><a href="#cb3-147" aria-hidden="true" tabindex="-1"></a><span class="fu">## 손으로 풀기</span></span>
<span id="cb3-148"><a href="#cb3-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-149"><a href="#cb3-149" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/LLM_hand.jpg)</span>{width=50%}</span>
<span id="cb3-150"><a href="#cb3-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-151"><a href="#cb3-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-152"><a href="#cb3-152" aria-hidden="true" tabindex="-1"></a><span class="fu">## 시각화</span></span>
<span id="cb3-153"><a href="#cb3-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-156"><a href="#cb3-156" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb3-157"><a href="#cb3-157" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-158"><a href="#cb3-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-159"><a href="#cb3-159" aria-hidden="true" tabindex="-1"></a>given_line <span class="ot">&lt;-</span> <span class="cf">function</span>(x)  <span class="dv">10</span> <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span> x</span>
<span id="cb3-160"><a href="#cb3-160" aria-hidden="true" tabindex="-1"></a>solve_line <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="sc">-</span><span class="dv">10</span> <span class="sc">+</span> <span class="dv">4</span> <span class="sc">*</span>x</span>
<span id="cb3-161"><a href="#cb3-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-162"><a href="#cb3-162" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb3-163"><a href="#cb3-163" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">5</span>, <span class="at">y =</span> <span class="dv">10</span>), <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb3-164"><a href="#cb3-164" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> given_line, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb3-165"><a href="#cb3-165" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_function</span>(<span class="at">fun =</span> solve_line, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb3-166"><a href="#cb3-166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb3-167"><a href="#cb3-167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">7</span>), <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb3-168"><a href="#cb3-168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">20</span>), <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">20</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb3-169"><a href="#cb3-169" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb3-170"><a href="#cb3-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>) </span>
<span id="cb3-171"><a href="#cb3-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-172"><a href="#cb3-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb3-173"><a href="#cb3-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-174"><a href="#cb3-174" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sympy 해법</span></span>
<span id="cb3-175"><a href="#cb3-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-178"><a href="#cb3-178" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb3-179"><a href="#cb3-179" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sympy <span class="im">import</span> <span class="op">*</span></span>
<span id="cb3-180"><a href="#cb3-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-181"><a href="#cb3-181" aria-hidden="true" tabindex="-1"></a>x, y, b <span class="op">=</span> symbols(<span class="st">'x y b'</span>)</span>
<span id="cb3-182"><a href="#cb3-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-183"><a href="#cb3-183" aria-hidden="true" tabindex="-1"></a>given_eq <span class="op">=</span> y <span class="op">-</span> (<span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">10</span>)</span>
<span id="cb3-184"><a href="#cb3-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-185"><a href="#cb3-185" aria-hidden="true" tabindex="-1"></a>parallel_eq <span class="op">=</span> y <span class="op">-</span> (<span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> b)</span>
<span id="cb3-186"><a href="#cb3-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-187"><a href="#cb3-187" aria-hidden="true" tabindex="-1"></a>intercept_eq <span class="op">=</span> parallel_eq.subs([(x, <span class="dv">5</span>), (y, <span class="dv">10</span>)])</span>
<span id="cb3-188"><a href="#cb3-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-189"><a href="#cb3-189" aria-hidden="true" tabindex="-1"></a>solveset(Eq(intercept_eq, <span class="dv">0</span>), b)</span>
<span id="cb3-190"><a href="#cb3-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-191"><a href="#cb3-191" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb3-192"><a href="#cb3-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-193"><a href="#cb3-193" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-194"><a href="#cb3-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-195"><a href="#cb3-195" aria-hidden="true" tabindex="-1"></a><span class="fu"># 다양한 사례 (PaLM)</span></span>
<span id="cb3-196"><a href="#cb3-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-197"><a href="#cb3-197" aria-hidden="true" tabindex="-1"></a>5,400 억 패러미터를 장착한 Pathways Language Model (PaLM)의 성능을 실감해보자.</span>
<span id="cb3-198"><a href="#cb3-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-199"><a href="#cb3-199" aria-hidden="true" tabindex="-1"></a>:::{.panel-tabset}</span>
<span id="cb3-200"><a href="#cb3-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-201"><a href="#cb3-201" aria-hidden="true" tabindex="-1"></a><span class="fu">## 다양한 기능</span></span>
<span id="cb3-202"><a href="#cb3-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-203"><a href="#cb3-203" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/PaLM_overview.gif)</span></span>
<span id="cb3-204"><a href="#cb3-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-205"><a href="#cb3-205" aria-hidden="true" tabindex="-1"></a><span class="fu">## 추론</span></span>
<span id="cb3-206"><a href="#cb3-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-207"><a href="#cb3-207" aria-hidden="true" tabindex="-1"></a>추론(Reasoning)</span>
<span id="cb3-208"><a href="#cb3-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-209"><a href="#cb3-209" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/PaLM_reasoning.png)</span></span>
<span id="cb3-210"><a href="#cb3-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-211"><a href="#cb3-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-212"><a href="#cb3-212" aria-hidden="true" tabindex="-1"></a><span class="fu">## 코딩</span></span>
<span id="cb3-213"><a href="#cb3-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-214"><a href="#cb3-214" aria-hidden="true" tabindex="-1"></a>코딩(Code Generation)</span>
<span id="cb3-215"><a href="#cb3-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-216"><a href="#cb3-216" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/PaLM_coding.gif)</span></span>
<span id="cb3-217"><a href="#cb3-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-218"><a href="#cb3-218" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-219"><a href="#cb3-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-220"><a href="#cb3-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-221"><a href="#cb3-221" aria-hidden="true" tabindex="-1"></a><span class="fu"># 개발비</span></span>
<span id="cb3-222"><a href="#cb3-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-223"><a href="#cb3-223" aria-hidden="true" tabindex="-1"></a>[<span class="co">[</span><span class="ot">Estimating 🌴PaLM's training cost</span><span class="co">](https://blog.heim.xyz/palm-training-cost/)</span>]{.aside}</span>
<span id="cb3-224"><a href="#cb3-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-225"><a href="#cb3-225" aria-hidden="true" tabindex="-1"></a>언어 모형 개발은 2010년 이후 개발비용이 급격히 증가하고 있으며 그 추세는 상상을 초월한다.</span>
<span id="cb3-226"><a href="#cb3-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-227"><a href="#cb3-227" aria-hidden="true" tabindex="-1"></a>:::{.panel-tabset}</span>
<span id="cb3-228"><a href="#cb3-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-229"><a href="#cb3-229" aria-hidden="true" tabindex="-1"></a><span class="fu">## Our World in Data</span></span>
<span id="cb3-230"><a href="#cb3-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-231"><a href="#cb3-231" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;iframe</span> <span class="er">src</span><span class="ot">=</span><span class="st">"https://ourworldindata.org/grapher/artificial-intelligence-training-computation?yScale=linear</span><span class="er">&amp;</span><span class="st">time=2017-06-12..2022-07-01"</span> <span class="er">loading</span><span class="ot">=</span><span class="st">"lazy"</span> <span class="er">style</span><span class="ot">=</span><span class="st">"width: 100%; height: 600px; border: 0px none;"</span><span class="kw">&gt;&lt;/iframe&gt;</span></span>
<span id="cb3-232"><a href="#cb3-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-233"><a href="#cb3-233" aria-hidden="true" tabindex="-1"></a><span class="fu">## Lennart Heim</span></span>
<span id="cb3-234"><a href="#cb3-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-235"><a href="#cb3-235" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;iframe</span> <span class="er">src</span><span class="ot">=</span><span class="st">"https://ourworldindata.org/grapher/artificial-intelligence-training-computation?yScale=linear</span><span class="er">&amp;</span><span class="st">time=earliest..latest</span><span class="er">&amp;</span><span class="st">country=~PaLM+%28540B%29"</span> <span class="er">loading</span><span class="ot">=</span><span class="st">"lazy"</span> <span class="er">style</span><span class="ot">=</span><span class="st">"width: 100%; height: 600px; border: 0px none;"</span><span class="kw">&gt;&lt;/iframe&gt;</span></span>
<span id="cb3-236"><a href="#cb3-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-237"><a href="#cb3-237" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-238"><a href="#cb3-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-239"><a href="#cb3-239" aria-hidden="true" tabindex="-1"></a><span class="fu"># 생성모형의 부작용</span></span>
<span id="cb3-240"><a href="#cb3-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-241"><a href="#cb3-241" aria-hidden="true" tabindex="-1"></a>생성 AI를 통해 인간이 생성한 데이터와 기계가 생성한 데이터가 무작위로 섞인 </span>
<span id="cb3-242"><a href="#cb3-242" aria-hidden="true" tabindex="-1"></a>지금까지 경험하지 못한 세상이 출현하고 있다. </span>
<span id="cb3-243"><a href="#cb3-243" aria-hidden="true" tabindex="-1"></a>즉, 생성 AI 모형에서 이미지, 텍스트, 동영상 등 무수히 많은 데이터가 인터넷에 공개 및 공유될 것이며</span>
<span id="cb3-244"><a href="#cb3-244" aria-hidden="true" tabindex="-1"></a>기계학습 및 딥러닝 생성모형는 결국 실제 데이터와 기계가 생성한 데이터를 입력값으로 </span>
<span id="cb3-245"><a href="#cb3-245" aria-hidden="true" tabindex="-1"></a>인공지능 모형을 생성하게 된다.</span>
<span id="cb3-246"><a href="#cb3-246" aria-hidden="true" tabindex="-1"></a>하지만 이런 경우 과연 AI 모형은 어떤 특성을 갖게 될 것인가? </span>
<span id="cb3-247"><a href="#cb3-247" aria-hidden="true" tabindex="-1"></a>데이터 증강(Data Augmentation)처럼 더 좋은 성능을 갖는 AI 모형이 될 것이가 아니면 그 반대의 모습을 가지게 될 것인가? 논문<span class="co">[</span><span class="ot">@hataya2022will</span><span class="co">]</span>에서는 부정적인 효과도 있다고 주장하고 있다.</span>
<span id="cb3-248"><a href="#cb3-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-249"><a href="#cb3-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-250"><a href="#cb3-250" aria-hidden="true" tabindex="-1"></a>::: {.panel-tabset}</span>
<span id="cb3-251"><a href="#cb3-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-252"><a href="#cb3-252" aria-hidden="true" tabindex="-1"></a><span class="fu">## 현재 상황</span></span>
<span id="cb3-253"><a href="#cb3-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-254"><a href="#cb3-254" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/training_data_corrupt.png)</span>{height=300px, width=150px}</span>
<span id="cb3-255"><a href="#cb3-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-256"><a href="#cb3-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-257"><a href="#cb3-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-258"><a href="#cb3-258" aria-hidden="true" tabindex="-1"></a><span class="fu">## 기계오염된 데이터</span></span>
<span id="cb3-259"><a href="#cb3-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-260"><a href="#cb3-260" aria-hidden="true" tabindex="-1"></a><span class="al">![기계생성 데이터 사용하여 나온 결과물](images/corrupt_images.png)</span></span>
<span id="cb3-261"><a href="#cb3-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-262"><a href="#cb3-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-263"><a href="#cb3-263" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-264"><a href="#cb3-264" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left"><a href="https://quarto.org/">Quarto</a> 개발</div>   
      <div class="nav-footer-center"><a href="mailto:admin@r2bit.com">한국 R 사용자회</a></div>
    <div class="nav-footer-right"><a href="https://github.com/bit2r/chatGPT">Github 코드 저장소</a></div>
  </div>
</footer><script>var lightboxQuarto = GLightbox({"openEffect":"zoom","loop":true,"descPosition":"bottom","selector":".lightbox","closeEffect":"zoom"});</script>


</body></html>