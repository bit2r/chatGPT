{
  "hash": "11e07ce2fce25275e57576bb1e9ac61b",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"삼성전자 주가예측\"\ndescription: |\n  `chatGPT` 코딩 기능을 활용하여 주가를 예측해보자.\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\n   - line-highlight   \nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n![](images/samsung_codex.jpg)\n\n삼성전자 주가를 예측하는 프로그램을 OpenAI chatGPT를 활용하여 작성해보자.\n\n# 데이터 크롤링\n\n삼성전자 주가를 예측하기 위해서는 데이터가 필요하다. \n이를 위해서 다음과 같이 지시명령어(prompt)를 작성하여 `chatGPT`에 요청한다.\n\n:::{.callout-warning collapse=\"false\"}\n### 지시명령어\n\n> 파이썬으로 최근 3년간 삼성전자 주가 데이터를 크롤링하여 samsung.csv 파일로 저장하는 코드를 작성해 주세요.\n:::\n\n\n[**대한민국 영업일수** ![](images/samsung_working_day.jpg)]{.aside}\n\n:::{.panel-tabset}\n\n## chatGPT 코드 {.unnumbered}\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport requests\nimport pandas as pd\n\n# URL of Samsung Electronics stock historical data\nurl = \"https://finance.naver.com/item/sise_day.naver?code=005930&page=\"\n\n# Empty list to store stock price data\ndata = []\n\n# Loop through the last 3 years of pages (60 pages in total)\nfor page in range(1, 61):\n    # Send a GET request to the URL with the current page number\n    response = requests.get(url + str(page))\n\n    # Read the HTML table into a pandas dataframe\n    df = pd.read_html(response.content)[0]\n\n    # Drop the last row which is just a duplicate of the column headers\n    df = df.drop(len(df) - 1)\n\n    # Append the dataframe to the list\n    data.append(df)\n\n# Concatenate all dataframes into a single dataframe\ndf = pd.concat(data)\n\n# Reverse the order of rows to start from the earliest date\ndf = df.iloc[::-1]\n\n# Set the date column as the index and remove unnecessary columns\ndf = df.set_index('날짜')[['종가', '거래량']]\n\n# Convert the data types of columns to float and int\ndf['종가'] = df['종가'].astype(float)\ndf['거래량'] = df['거래량'].str.replace(',', '').astype(int)\n\n# Print the resulting dataframe\nprint(df)\n```\n:::\n\n\n통상 영업일기준으로 1년을 보통 247일가 된다. 해당 웹사이트 [삼성전자 주식 첫페이지](https://finance.naver.com/item/sise_day.naver?code=005930&page=1)를 일별하면\n한 페이지에 10 영업일 주식거래 데이터가 담겨있어 총 약 반년치 데이터가 누락되어 2.5년 정도 된다고 보면 된다.\n\n## 오류 수정코드 {.unnumbered}\n\n\n::: {.cell source-line-numbers='14,46,39,49'}\n\n```{.python .cell-code  code-line-numbers=\"true\"}\n\nimport requests\nimport pandas as pd\n\n# URL of Samsung Electronics stock historical data\nurl = \"https://finance.naver.com/item/sise_day.naver?code=005930&page=\"\n\n# Empty list to store stock price data\ndata = []\n\n# Loop through the last 3 years of pages (60 pages in total)\nfor page in range(1, 61):\n    # Send a GET request to the URL with the current page number\n    response = requests.get(url + str(page), headers={'User-agent': 'Mozilla/5.0'})\n    \n\n    # Check if the response is successful\n    if response.status_code == 200:\n        # Read the HTML table into a pandas dataframe\n        df_list = pd.read_html(response.text, flavor='html5lib')\n\n        # Check if the list of dataframes is not empty\n        if df_list:\n            # Get the first dataframe\n            df = df_list[0]\n\n            # Drop the last row which is just a duplicate of the column headers\n            df = df.drop(len(df) - 1)\n\n            # Append the dataframe to the list\n            data.append(df)\n\n# Concatenate all dataframes into a single dataframe\ndf = pd.concat(data)\n\n# Reverse the order of rows to start from the earliest date\ndf = df.iloc[::-1]\n\ndf = df.dropna()\n\n# Set the date column as the index and remove unnecessary columns\ndf = df.set_index('날짜')[['종가', '거래량']]\n\n# Convert the data types of columns to float and int\ndf['종가'] = df['종가'].astype(float)\ndf['거래량'] = df['거래량'].astype(int)\n\n# Save the dataframe as a CSV file\ndf.to_csv('data/samsung.csv')\n\n# Print a confirmation message\nprint('samsung.csv saved successfully.')\n```\n:::\n\n\n네이버 주식 일별시세를 읽어오는 경우 `ValueError: No tables found`가 발생되어 \n[네이버 주식 일별 시세 pandas read_html() ValueError: No tables found 오류](https://dasom.net/147) 참조하여 \n오류수정, 크롤링 데이터에 결측값이 포함되어 이를 수정작업 후에ㅏ 마지막으로 자료형 오류수정 후 데이터를 `data/samsung.csv` 파일로 다운로드하여 작업마무리한다.\n\n:::\n\n## 오류 수정\n\n`lxml` 패키지가 설치되지 않는 오류가 발생되었다.\n\n```\nImportError: lxml not found, please install it\nValueError: No objects to concatenate\n```\n\n:::{.callout-warning collapse=\"false\"}\n### 지시명령어\n\n> fix the bug <br>\n> ImportError: lxml not found, please install it <br>\n> ValueError: No objects to concatenate <br>\n> Answer in Korean.\n\n`pip install lxml`\n\n:::\n\n# 시각화\n\n앞서 크롤링하여 `.csv` 파일로 저장한 데이터를 `pandas` 데이터프레임 자료구조와\n시각화를 위해서 `matplotlib`으로 시각화하는 코드를 작성하게 지시한다.\n\n:::{.callout-warning collapse=\"false\"}\n## 지시명령어\n\n> 삼성전자 주가데이터가 'data/samsung.csv' 파일에 저장되어 있습니다. pandas 데이터프레임으로 불러읽어와서 x 축에는 '날짜' y축에는 '종가'로 하여 시계열 그래프를 matplotlib으로 작성해주세요\n:::\n\n:::{.panel-tabset}\n\n## chatGPT 파이썬 코드 {.unumbered}\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the Samsung Electronics stock price data from the 'data/samsung.csv' file into a pandas dataframe\ndf = pd.read_csv('data/samsung.csv', index_col='날짜', parse_dates=True)\n\n# Create a time series graph with matplotlib\nplt.plot(df.index, df['종가'])\n\n# Set the x-axis label to 'Date'\nplt.xlabel('Date')\n\n# Set the y-axis label to 'Closing Price'\nplt.ylabel('Closing Price')\n\n# Set the title of the graph to 'Samsung Electronics Stock Price'\nplt.title('Samsung Electronics Stock Price')\n\n# Show the graph\nplt.show()\n\n# PNG 저장\nplt.savefig('images/samsung_matplotlib.png')\n```\n:::\n\n\n![](images/samsung_matplotlib.png)\n\n## 사람작성 R 코드 {.unumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nextrafont::loadfonts()\n\nsamsung_tbl <- read_csv(\"data/samsung.csv\")\n\nsamsung_tbl %>% \n  ## 자료형 변환 -----------\n  mutate(날짜 = lubridate::ymd(날짜)) %>% \n  ggplot(aes(x = 날짜, y = 종가)) +\n    geom_line() +\n    scale_x_date(date_labels = \"%y년 %m월\") +\n    scale_y_continuous(labels = scales::comma) +\n    theme_bw(base_family = \"MaruBuri Bold\") +\n    labs(x = \"\",\n         title = \"삼성전자주가 최근 3년 주가 추세\",\n         subtitle = \"주가 데이터 크롤링을 chatGPT가 파이썬으로 작성\",\n         caption = \"출처: https://r2bit.com/chatGPT/samsung.html\")\n```\n\n::: {.cell-output-display}\n![](samsung_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n:::\n\n\n# 예측\n\n:::{.callout-warning collapse=\"false\"}\n## 지시명령어\n\n> 삼성전자 주가 종가기준 1달 예측하는 모형을 제작하고 예측값을 pandas 데이터프레임에 붙여줘 <br>\n> 선형 회귀모형 대신 ARIMA 모형으로 예측모형을 바꿔서 다시 작성해줘 <br>\n> 삼성전자 주가를 예측하는데  pmdarima 패키지를 사용해서 1달 예측하는 코드를 작성해주세요. \n:::\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport pmdarima as pm\n\n# Load the Samsung Electronics stock price data from the 'data/samsung.csv' file into a pandas dataframe\ndf = pd.read_csv('data/samsung.csv', index_col='날짜', parse_dates=True)\n\n# Extract the '종가' column as a pandas series\nclosing_prices = df['종가']\n\n# Create an ARIMA model using pmdarima\nmodel = pm.auto_arima(closing_prices, seasonal=False, error_action='ignore', suppress_warnings=True)\n\n# Make a prediction for the next 30 days\nforecast = model.predict(n_periods=30)\n\n# Create a new column in the dataframe to store the predicted prices\ndf['Predicted Price'] = None\n\n# Calculate the predicted prices for the next 30 days\nlast_price = closing_prices[-1]\nfor i in range(30):\n    predicted_price = last_price * (1 + forecast[i])\n    date = closing_prices.index[-1] + pd.DateOffset(days=i+1)\n    df.at[date, 'Predicted Price'] = predicted_price\n\n# Print the dataframe with the predicted prices\nprint(df)\n\n```\n:::\n",
    "supporting": [
      "samsung_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}