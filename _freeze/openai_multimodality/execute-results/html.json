{
  "hash": "4b3998a7d3e5d025b0427d510c60847f",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"OpenAI 다중 모드성(Multimodality)\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\nlightbox: auto\nlink-citations: true\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\nbibliography: bibliography.bib\ncsl: apa-single-spaced.csl    \neditor: \n  markdown: \n    wrap: sentence\n---\n\n\n# API 설정\n\n2023년 11월 열린 OpenAI 개발자 컨퍼런스에서 기존 OpenAI API 인터페이스가 대대적인 개선작업이 이뤄졌다.\n\n# 텍스트\n\nOpenAI의 다중 모드성 API를 사용하여 한국의 유명 인사들에 대한 정보를 조회하고 처리하는 과정을 보여준다.\n먼저, 필요한 라이브러리들을 임포트하고, 환경변수를 로드한다.\nOpenAI 클라이언트를 초기화하고, GPT-3.5 모델을 이용하여 '대한민국 최고 유명인 3명'에 대한 질문을 제출한다.\n이 요청은 JSON 형식의 출력을 반환하도록 설정되어 있다.\n반환된 JSON 문자열은 파싱되어 Python 딕셔너리로 변환되며, 딕셔너리를 Pandas DataFrame으로 변환되어 출력된다.\nOpenAI API를 활용하여 텍스트 데이터를 구조화하는 전형적인 방법을 보여준다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\nimport json\nimport pandas as pd\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\ntext_response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo-1106\",\n    max_tokens=256,\n    temperature=0,\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"대한민국 최고 역사전문가로 역할을 수행해줘. 출력결과는 JSON 형식으로 부탁해\",\n        },      \n        {\n            \"role\": \"user\",\n            \"content\": \"대한민국 최고 유명인 3 명은 누구야?\",\n        }\n    ],\n    response_format={ \"type\": \"json_object\" }\n)\n\n\n# JSON 문자열 예시\ntext_output_json = text_response.choices[0].message.content\ntext_dict = json.loads(text_output_json)\n\ntext_df = pd.DataFrame(list(text_dict.values()), index=text_dict.keys(), columns=['유명인'])\nprint(text_df)\n```\n:::\n\n\n```         \n   유명인\n1  윤보선\n2   김구\n3  유관순\n```\n\n# 이미지\n\n[Teemu Maatta, \"How to use GPT-4 Vision API? - OpenAI released today API for GPT-4 Turbo Vision. In this tutorial, I will build you an application using this SOTA model.\", medium, 2023-11-07](https://medium.com/@tmmtt/how-to-use-gpt-4-vision-api-ba6b57af569c)\n\n## 이미지 → 텍스트\n\n`gpt-4-vision-preview` 모형을 사용해서 이미지를 설명하는 텍스트를 생성하도록 한다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimage_response = client.chat.completions.create(\n    model=\"gpt-4-vision-preview\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"대한민국 최고 역사전문가로 역할을 수행해줘.\",\n        },      \n        {\n            \"role\": \"user\",\n            \"content\": [\n                { \n                  \"type\": \"text\", \n                  \"text\": \"이미지를 설명해주세요.\"\n                },\n                {\n                  \"type\": \"image_url\",\n                  \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/4/4e/An_Jung-geun.JPG\"\n                },\n            ],\n        }\n    ],\n    max_tokens=500\n)\n\nprint(image_response.choices[0].message.content)\n```\n:::\n\n\n::: columns\n::: column\n![](https://upload.wikimedia.org/wikipedia/commons/4/4e/An_Jung-geun.JPG){fig-align=\"center\" width=\"250\"}\n:::\n\n::: column\n사진 속 인물은 어두운색의 자켓을 입고 있으며, 배경은 흰색으로 보이는 벽으로 추정됩니다.\n이 사람은 카메라를 직시하고 있는데, 표정은 비교적 평온해 보입니다.\n사진의 색조와 품질을 통해 추정컨대 오래된 사진으로 보입니다.\n이 사람의 정체에 관한 정보가 없으므로, 구체적인 역사적 배경이나 이 인물에 대한 자세한 정보를 제공하기는 어렵습니다.\n:::\n:::\n\n## 텍스트 → 이미지\n\n`dall-e-3` 모형을 사용해서 텍스트를 이미지로 생성하도록 한다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom IPython.display import display, Image\nimport requests\n\nresponse = client.images.generate(\n  model=\"dall-e-3\",\n  prompt=\"A black Scottish fold cat with light golden eyes laying down on white sheets\",\n  size=\"1024x1024\",\n  quality=\"standard\",\n  n=1,\n)\n\n# Save the image URL\nimage_url = response.data[0].url\n\n# Fetch the image\nimage_response = requests.get(image_url)\n\n# Display the image\nimg = Image(data=image_response.content)\ndisplay(img)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndownload.file(url = 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-GpPkNlGHcRh9i7pQIlhT18p7/user-Qkv0ntrn5tQoUu6pocAidY5V/img-rypewgc6ys0EPhho7OTn7f5m.png?st=2023-11-16T08%3A52%3A12Z&se=2023-11-16T10%3A52%3A12Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-16T09%3A51%3A05Z&ske=2023-11-17T09%3A51%3A05Z&sks=b&skv=2021-08-06&sig=bPIlrK7Lhflj2Igsg6TWOSnT1DKQ3F2A0/vTTZSwgfI%3D', destfile = \"images/dalle_gpt4_cat.jpg\", mode = \"wb\")\n```\n:::\n\n\n![](images/dalle_gpt4_cat.jpg)\n\n# 오디오\n\n## 텍스트 → 음성\n\n대한민국 헌법 제1장 제1조를 읽어주는 음성을 생성한다.\n\n> 대한민국은 민주공화국이다. 대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom openai import OpenAI\n\nclient = OpenAI()\nresponse = client.audio.speech.create(\n  model=\"tts-1\",\n  voice=\"alloy\",\n  input=\"대한민국은 민주공화국이다. 대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다\",\n)\n\n# Save to an MP3 file.\nwith open(\"data/alloy-korean.mp3\", \"wb\") as file:\n  file.write(response.content)\n  \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(av)\nlibrary(embedr)\n\nhtml_tag_audio <- function(file, type = c(\"wav\")) {\n  type <- match.arg(type)\n  htmltools::tags$audio(\n    controls = \"\",\n    htmltools::tags$source(\n      src = file,\n      type = glue::glue(\"audio/{type}\", type = type)\n    )\n  )\n}\n\nembedr::embed_audio(\"data/alloy-korean.mp3\")\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<audio controls> <source src='data/alloy-korean.mp3' type='audio/mpeg'> Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp </audio>\n```\n\n:::\n:::\n\n\n## 음성 → 텍스트\n\n다음으로 음성을 텍스트로 변환하는 예제를 살펴보자.\n\n[Korean Speech Database for ASR](https://github.com/knlee-voice/AI.Tech/blob/master/docs/KoSpeechDB.md) 웹사이트에서 다양한 한국어 음성 데이터를 다운로드 받을 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nembedr::embed_audio(\"data/audio_0001.wav\", \"wav\")\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<audio controls> <source src='data/audio_0001.wav' type='audio/wav'> Your browser does not support the audio tag;  for browser support, please see:  https://www.w3schools.com/tags/tag_audio.asp </audio>\n```\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"data/audio_0001.wav\", \"rb\")\n\ntranscript = client.audio.transcriptions.create(\n  model=\"whisper-1\", \n  file=audio_file, \n  response_format=\"text\"\n)\n\ntranscript\n#> '커피숍에 쓰는 돈이 월 10만원이 넘더라고요. 소비를 좀 줄이라고 캡슐커피머신 구매했는데 캡슐가격이 너무 나가서 그게 그거인 것 같아요.\\n'\n```\n:::\n\n\n::::: columns\n::: {.column width=\"45%\"}\n### 라벨 음성 텍스트 {.unnumbered}\n\n커피숍에 쓰는 돈이 월 (100000원)/(십만 원)이 (넘더라고요)/(넘더라구요). 소비를 좀 줄이려고 캡슐커피머신 구매했는데 캡슐 가격이 너무 나가서 그게 그거 같아요.\n\n:::\n\n::: {.column width=\"10%\"}\n:::\n\n::: {.column width=\"45%\"}\n### 인식된 음성 텍스트 {.unnumbered}\n\n'커피숍에 쓰는 돈이 월 10만원이 넘더라고요. 소비를 좀 줄이라고 캡슐커피머신 구매했는데 캡슐가격이 너무 나가서 그게 그거인 것 같아요.\\n'\n\n:::\n:::::\n\n## 보정작업\n\nOpenAI [Speech to text](https://platform.openai.com/docs/guides/speech-to-text/quickstart) 문서를 바탕으로 음성 오디오를 필사하는 보정작업을 수행하는 예제를 살펴보자.\n\n\n::: {.cell}\n\n```{.python .cell-code}\naudio_file = open(\"data/audio_0001.wav\", \"rb\")\n\nsystem_prompt = \"You are a helpful assistant for the company Korea R User Group. Your task is to correct any spelling discrepancies in the transcribed text. Make sure that the names of the following products are spelled correctly: Korea R User Group, 한국 R 사용자회. Only add necessary punctuation such as periods, commas, and capitalization, and use only the context provided.\"\n\ndef transcribe(audio_file):\n    transcript = client.audio.transcriptions.create(\n      model=\"whisper-1\", \n      file=audio_file, \n      response_format=\"text\"\n    )\n    \n    return transcript\n  \n# transcribe(audio_file)\n\ndef generate_corrected_transcript(temperature, system_prompt, audio_file):\n    response = client.chat.completions.create(\n        model=\"gpt-4\",\n        temperature=temperature,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": transcribe(audio_file)\n            }\n        ]\n    )\n    return response\n\ncorrected_text = generate_corrected_transcript(0, system_prompt, audio_file)\n\ncorrected_text.choices[0].message.content\n```\n:::\n\n\n```\n'커피숍에 쓰는 돈이 월 10만원이 넘더라고요. 소비를 좀 줄이라고 캡슐 커피 머신을 구매했는데, 캡슐 가격이 너무 나가서 그게 그거인 것 같아요.'\n```\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}