{
  "hash": "bd4cd781ca9b61eee703bca5ed1f2cac",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"프로젝트\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# 1 백만 사용자 {{< fa solid rocket >}}\n\n1 백만 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다.\n\n![](images/one_million_users.jpg)\n\n# 패러다임\n\n[![Andrej Karpathy Twit](images/software_3.jpeg)]{.aside}\n\n[- Pre-Software: Special-purpose computer <br>\n- Software 1.0: Design the Algorithm <br>\n- Software 2.0: Design the Dataset <br>\n- Software 3.0: Design the Prompt]{.aside}\n\n:::{.panel-tabset .column-page}\n\n## Feature Engineering\n\n- **패러다임**: (비신경망)지도학습 (Fully Supervised Learning)\n- **전성기**: 2015년까지 최고 전성기 구가\n- **특징**\n  1. 주로 비신경망 기계학습이 사용\n  1. 수작업으로 Feature를 추출\n- **대표작**  \n  1. 수작업 Feature 추출 후 SVM(support vector machine) 기계학습 모형\n  1. 수작업 Feature 추출 후 CRF(conditional random fields)\n  \n## Architecture Engineering\n\n- **패러다임**: 신경망 지도학습(Fully Supervised Learning)\n- **전성기**: 대략 2013~2018\n- **특징**\n  1. 신경망(Neural Network) 의존\n  1. 수작업으로 Feature를 손볼 필요는 없으나 신경망 네트워크는 수정해야 함(LSTM vs CNN)\n  1. 종종 사전학습된 언어모형을 사용하나 임베딩(embedding) 같은 얕은(shallow) Feature를 적용\n- **대표작**  \n  1. 텍스트 분류작업에 CNN 사용\n\n## Objective Engineering\n\n- **패러다임**: 사전학습(pre-training), 미세조정(fine-tuning)\n- **전성기**: 2017~현재\n- **특징**\n  1. 사전학습된 언어모형을 전체 모형의 초기값으로 사용\n  1. 아키텍쳐 디자인에 작업이 덜 필요하지만 목적함수(Objective function) 엔지니어링은 필요\n- **대표작**  \n  1. BERT &rarr; Fine Tuning\n\n## Prompt Engineering\n\n- **패러다임**: 사전학습(pre-training), 프롬프트(Prompt), 예측(Predict)\n- **전성기**: 2019~현재\n- **특징**\n  1. NLP 작업이 언어모형(Language Model)에 전적으로 의존\n  1. 얕던 깊던 Feature 추출, 예측 등 작업이 전적으로 언어모형에 의존\n  1. 프롬프트 공학이 필요\n- **대표작**  \n  1. GPT3\n\n:::\n\n# Prompt engineering\n\n- Instructions\n- Question\n- Input data\n- Examples\n\n[[Xavier (Xavi) Amatriain(January 5, 2023), \"Prompt Engineering 101 - Introduction and resources\", Linkedin](https://www.linkedin.com/pulse/prompt-engineering-101-introduction-resources-amatriain/),[Prompt Engineering - Learn how to use AI models with prompt engineering](https://microsoft.github.io/prompt-engineering/)]{.aside}\n\n# Genearative AI\n\n- 구분\n  - generation: text &rarr; image\n  - classification: image &rarr; text\n  - transformation: image &rarr; image (or text &rarr; text)\n\n- AI 프로젝트\n  - GPT-3\n  - Dalle.2 (text-to-image)\n  - Meta’s AI (text-to-video)\n  - Google AI (text-to-video)\n  - Stable Diffusion (text-to-image)\n  - Tesla AI (humanoid robot + self-driving)\n\n- text-to-X\n  - text-to-gif (T2G)\n  - text-to-3D (T2D)\n  - text-to-text (T2T)\n  - text-to-NFT (T2N)\n  - text-to-code (T2C)\n  - text-to-image (T2I)\n  - text-to-audio (T2S)\n  - text-to-video (T2V)\n  - text-to-music (T2M)\n  - text-to-motion (T2Mo)\n- 기타\n  - brain-to-text (B2T)\n  - image-to-text (I2T)\n  - speech-to-text (S2T)\n  - audio-to-audio (A2A)\n  - tweet-to-image (Tt2I)\n  - text-to-sound (T2S)\n\n\n![](images/generative_ai.jpg)\n\n\n# 데이터와 하드웨어\n\n![](images/cpu_gpu.jpg)\n\n# Open Assistant\n\n\n::: {#fig-assistant layout-ncol=3}\n\n![Label Asssistant Reply](images/OA_label_assistant_reply.png)\n\n![Initial Prompt](images/OA_label_initial_prompt.png)\n\n![Label Prompter Reply](images/OA_label_prompter_reply.png)\n\n![Reply as Assistant](images/OA_reply_as_assistant.png)\n\n![Reply as User](images/OA_reply_as_user.png)\n\n\n[Open Assistant](https://open-assistant.io/dashboard)\n:::\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}