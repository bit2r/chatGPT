{
  "hash": "7a7d1c9c959aa22b4426ea7b2efb58ab",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"프로젝트\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# 1 백만 사용자 {{< fa solid rocket >}}\n\n1 백만 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다.\n\n![](images/one_million_users.jpg)\n\n# 패러다임\n\n![Andrej Karpathy Twit](images/software_3.jpeg)\n\n- Pre-Software: Special-purpose computer\n- Software 1.0: Design the Algorithm\n- Software 2.0: Design the Dataset\n- Software 3.0: Design the Prompt\n\n# Prompt engineering\n\n- Instructions\n- Question\n- Input data\n- Examples\n\n[[Xavier (Xavi) Amatriain(January 5, 2023), \"Prompt Engineering 101 - Introduction and resources\", Linkedin](https://www.linkedin.com/pulse/prompt-engineering-101-introduction-resources-amatriain/),[Prompt Engineering - Learn how to use AI models with prompt engineering](https://microsoft.github.io/prompt-engineering/)]{.aside}\n\n# Genearative AI\n\n- 구분\n  - generation: text &rarr; image\n  - classification: image &rarr; text\n  - transformation: image &rarr; image (or text &rarr; text)\n\n- AI 프로젝트\n  - GPT-3\n  - Dalle.2 (text-to-image)\n  - Meta’s AI (text-to-video)\n  - Google AI (text-to-video)\n  - Stable Diffusion (text-to-image)\n  - Tesla AI (humanoid robot + self-driving)\n\n- text-to-X\n  - text-to-gif (T2G)\n  - text-to-3D (T2D)\n  - text-to-text (T2T)\n  - text-to-NFT (T2N)\n  - text-to-code (T2C)\n  - text-to-image (T2I)\n  - text-to-audio (T2S)\n  - text-to-video (T2V)\n  - text-to-music (T2M)\n  - text-to-motion (T2Mo)\n- 기타\n  - brain-to-text (B2T)\n  - image-to-text (I2T)\n  - speech-to-text (S2T)\n  - audio-to-audio (A2A)\n  - tweet-to-image (Tt2I)\n  - text-to-sound (T2S)\n\n\n![](images/generative_ai.jpg)\n\n\n# 데이터와 하드웨어\n\n![](images/cpu_gpu.jpg)\n\n# Open Assistant\n\n\n::: {#fig-assistant layout-ncol=3}\n\n![Label Asssistant Reply](images/OA_label_assistant_reply.png)\n\n![Initial Prompt](images/OA_label_initial_prompt.png)\n\n![Label Prompter Reply](images/OA_label_prompter_reply.png)\n\n![Reply as Assistant](images/OA_reply_as_assistant.png)\n\n![Reply as User](images/OA_reply_as_user.png)\n\n\n[Open Assistant](https://open-assistant.io/dashboard)\n:::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}