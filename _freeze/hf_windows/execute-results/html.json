{
  "hash": "62b13ef887e45cb2b21bcb0e0d6ff74d",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"Hugging Face (윈도우즈)\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\n   - interview-callout.lua\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n# 윈도우즈 환경설정\n\n[[reticulate, \"Installing Python Packages\"](https://rstudio.github.io/reticulate/articles/python_packages.html)]{.aside}\n\n\n::: {.panel-tabset}\n\n## 생성\n\n`reticulate` 패키지 `conda_create()` 함수로 새로운 환경을 생성한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n```\n:::\n\n\n## 환경 확인\n\n`reticulate::py_available()` 명령어로 파이썬 환경을 활용가능한지 확인하고 \n`reticulate::py_config()` 상세한 위치를 파악한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n```\n:::\n\n\n\n## 사용시작\n\n`use_python()` 함수로 파이썬 위치를 특정하고 관련 패키지 설치를 시작한다.\n준비된 파이썬 가상환경에 `transformers` 및 연관 패키지를 설치한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)\n```\n:::\n\n\n:::\n\n# NLP 작업 분류\n\n[`Hugging Face`](https://huggingface.co/) 웹사이트에서 Transformer를 다운로드 받아 다양한 자연어 처리 작업을 수행한다.\n\n먼저, 작업흐름은 앞서 준비한 파이썬 가상환경에 허깅 페이스에서 Transfomer를 설치하고 이어 각 NLP 작업(task)에 맞춰 후속작업을 이어나간다.\n\n[[Hello Transformers from R](https://rpubs.com/eR_ic/transfoRmers)]{.aside}\n\n[[R, Reticulate, and Hugging Face Models](https://cengiz.me/posts/huggingface/)]{.aside}\n\n\n```{mermaid}\ngraph LR\n    A[\"venv 가상환경\"] --> T((\"Transformer\"))\n    B[\"R reticulate\"] --> T((\"Transformer\"))\n    T ---> C[\"텍스트 분류(Text Classification)\"]\n    T ---> D[\"개체명인식(NER)\"]\n    T ---> E[\"질의 응답(Question & Answering)\"]\n    T ---> F[\"요약(Summarization)\"]\n    T ---> G[\"번역(Translation)\"]\n    T ---> H[\"텍스트 생성(Text Generation)\"]    \n    style A fill:#FF6655AA\n    style T fill:#88ffFF\n```\n\n\n\n\n## 감정 분류\n\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902\n```\n:::\n\n\n## NER\n\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511\n```\n:::\n\n\n## 질의응답\n\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron\n```\n:::\n\n\n## 요약\n\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\"\n```\n:::\n\n\n## 번역\n\n[Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP) 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\"\n```\n:::\n\n\n## 텍스트 생성\n\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가\n반응을 자동생성시켜 답신을 작성할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenerator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you\n```\n:::\n\n\n## 참고문헌\n\n- [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)\n\n-  [Reticulate: R Interface to Python](https://rstudio.github.io/reticulate/index.html)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}