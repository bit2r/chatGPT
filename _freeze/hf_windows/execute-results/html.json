{
  "hash": "62b13ef887e45cb2b21bcb0e0d6ff74d",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"Hugging Face (ìœˆë„ìš°ì¦ˆ)\"\nauthor:\n  - name: ì´ê´‘ì¶˜\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: í•œêµ­ R ì‚¬ìš©ìíšŒ\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: ëª©ì°¨\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\n   - interview-callout.lua\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n# ìœˆë„ìš°ì¦ˆ í™˜ê²½ì„¤ì •\n\n[[reticulate, \"Installing Python Packages\"](https://rstudio.github.io/reticulate/articles/python_packages.html)]{.aside}\n\n\n::: {.panel-tabset}\n\n## ìƒì„±\n\n`reticulate` íŒ¨í‚¤ì§€ `conda_create()` í•¨ìˆ˜ë¡œ ìƒˆë¡œìš´ í™˜ê²½ì„ ìƒì„±í•œë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\n# create a new environment \nconda_create(\"r-reticulate\")\n```\n:::\n\n\n## í™˜ê²½ í™•ì¸\n\n`reticulate::py_available()` ëª…ë ¹ì–´ë¡œ íŒŒì´ì¬ í™˜ê²½ì„ í™œìš©ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  \n`reticulate::py_config()` ìƒì„¸í•œ ìœ„ì¹˜ë¥¼ íŒŒì•…í•œë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\nreticulate::py_available()\n#> [1] FALSE\n\nreticulate::py_config()\n#> python:         C:/miniconda/envs/r-reticulate/python.exe\n#> libpython:      C:/miniconda/envs/r-reticulate/python38.dll\n#> pythonhome:     C:/miniconda/envs/r-reticulate\n#> version:        3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 15:53:35) [MSC v.1929 64 bit (AMD64)]\n#> Architecture:   64bit\n#> numpy:          C:/miniconda/envs/r-reticulate/Lib/site-packages/numpy\n#> numpy_version:  1.24.2\n#> \n#> NOTE: Python version was forced by RETICULATE_PYTHON_FALLBACK\n```\n:::\n\n\n\n## ì‚¬ìš©ì‹œì‘\n\n`use_python()` í•¨ìˆ˜ë¡œ íŒŒì´ì¬ ìœ„ì¹˜ë¥¼ íŠ¹ì •í•˜ê³  ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ì‹œì‘í•œë‹¤.\nì¤€ë¹„ëœ íŒŒì´ì¬ ê°€ìƒí™˜ê²½ì— `transformers` ë° ì—°ê´€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nuse_python(\"C:/miniconda/envs/r-reticulate/python.exe\")\n\n# reticulate::py_install(\"transformers\", pip = TRUE)\n# reticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n# reticulate::py_install(\"urllib3\", pip = TRUE)\n# reticulate::py_install(\"brotli\", pip = TRUE)\n# reticulate::py_install(\"Pillow\", pip = TRUE)\n# reticulate::py_install(\"scikit-learn\", pip = TRUE)\n```\n:::\n\n\n:::\n\n# NLP ì‘ì—… ë¶„ë¥˜\n\n[`Hugging Face`](https://huggingface.co/) ì›¹ì‚¬ì´íŠ¸ì—ì„œ Transformerë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.\n\në¨¼ì €, ì‘ì—…íë¦„ì€ ì•ì„œ ì¤€ë¹„í•œ íŒŒì´ì¬ ê°€ìƒí™˜ê²½ì— í—ˆê¹… í˜ì´ìŠ¤ì—ì„œ Transfomerë¥¼ ì„¤ì¹˜í•˜ê³  ì´ì–´ ê° NLP ì‘ì—…(task)ì— ë§ì¶° í›„ì†ì‘ì—…ì„ ì´ì–´ë‚˜ê°„ë‹¤.\n\n[[Hello Transformers from R](https://rpubs.com/eR_ic/transfoRmers)]{.aside}\n\n[[R, Reticulate, and Hugging Face Models](https://cengiz.me/posts/huggingface/)]{.aside}\n\n\n```{mermaid}\ngraph LR\n    A[\"venv ê°€ìƒí™˜ê²½\"] --> T((\"Transformer\"))\n    B[\"R reticulate\"] --> T((\"Transformer\"))\n    T ---> C[\"í…ìŠ¤íŠ¸ ë¶„ë¥˜(Text Classification)\"]\n    T ---> D[\"ê°œì²´ëª…ì¸ì‹(NER)\"]\n    T ---> E[\"ì§ˆì˜ ì‘ë‹µ(Question & Answering)\"]\n    T ---> F[\"ìš”ì•½(Summarization)\"]\n    T ---> G[\"ë²ˆì—­(Translation)\"]\n    T ---> H[\"í…ìŠ¤íŠ¸ ìƒì„±(Text Generation)\"]    \n    style A fill:#FF6655AA\n    style T fill:#88ffFF\n```\n\n\n\n\n## ê°ì • ë¶„ë¥˜\n\nì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(tidyverse)\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing ğŸ¤— transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902\n```\n:::\n\n\n## NER\n\nê°œì²´ëª… ì¸ì‹ì€ í…ìŠ¤íŠ¸ ë‚´ë¶€ì— ì§€ëª…, ì¸ëª…, ì œí’ˆ ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 Ã— 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511\n```\n:::\n\n\n## ì§ˆì˜ì‘ë‹µ\n\ní…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì„ ë˜ì§€ê³  í•´ë‹¹ ëŒ€ë‹µì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 Ã— 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron\n```\n:::\n\n\n## ìš”ì•½\n\ní…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ì´ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\"\n```\n:::\n\n\n## ë²ˆì—­\n\n[Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP) ì—ì„œ ì‚¬ì „í•™ìŠµëª¨í˜•ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë²ˆì—­ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"ë§ì¶¤, ìê¸°  US historical 885 NORETH Creator Bangkok on., ìŒ US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China ì˜ ë”°ì˜´í‘œ  DS, US general Greece remained. ì„±ê³µì ìœ¼ë¡œ  ì˜, US historical does 32-Human # well885 NORETTH US. ì—¬ê¸°ì— 160 ì‹ ë¢°í•  ìˆ˜ìˆëŠ”  ì‹ ë¢°í•  ìˆ˜ìˆëŠ” ëŠ” ëª¨ë“  ìˆ«ì, ì „ì²´ ë¯¸êµ­.\"\n```\n:::\n\n\n## í…ìŠ¤íŠ¸ ìƒì„±\n\nê³ ê°ì´ ë‚¨ê¸´ ê³ ê°ì˜ ì†Œë¦¬ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì›ì´ ì²˜ìŒì„ ì‹œì‘í•˜ë©´ ê¸°ê³„ê°€\në°˜ì‘ì„ ìë™ìƒì„±ì‹œì¼œ ë‹µì‹ ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenerator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. This is a complete misunderstanding that must be addressed within the store. We are working to resolve this issue. After all, a purchase from a online retailer is an exchange.\n#> \n#> We should be more specific to your comment on our previous question rather than simply telling you to \"go and make your own copies\"-I just want you\n```\n:::\n\n\n## ì°¸ê³ ë¬¸í—Œ\n\n- [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)\n\n-  [Reticulate: R Interface to Python](https://rstudio.github.io/reticulate/index.html)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}