{
  "hash": "93717e1eefc8a51244c910ddb5743364",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"OpenAI API 예측모형\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\nlightbox: auto\nlink-citations: true\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\nbibliography: bibliography.bib\ncsl: apa-single-spaced.csl    \neditor: \n  markdown: \n    wrap: sentence\n---\n\n\n# 환경설정\n\n윈도우 환경에서 [`scikit-llm`](https://github.com/iryna-kondr/scikit-llm)을 설치할 경우 Visual Studio 커뮤니티 버젼을 설치할 때 C/C++ 빌드 환경도 함께 설치한 후 `scikit-llm` 설치를 권장한다.\n\n[[ScikitLLM – A powerful combination of SKLearn and LLMs](https://mlengineeringplace.com/scikitllm-a-powerful-combination-of-sklearn-and-llms/)]{.aside}\n\n\n::: {.cell}\n\n```{.python .cell-code}\n! pip install scikit-llm\n! pip install palmerpenguins\n```\n:::\n\n\n# ML 모형\n\n전통적인 방식으로 머신러닝 모형을 만들고 예측하는 방법은 다음과 같다.\n펭귄 데이터를 이용하여 의사결정나무 모형을 만들고 예측하는 예제코드를 다음과 \n같이 작성할 수 있다.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom palmerpenguins import load_penguins\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\n\n\n# Load the Iris dataset\npenguins_raw = load_penguins()\n\npenguins = penguins_raw.dropna()\n\ny = penguins.species\n# 설명 변수 선택\nX = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n\n# 데이터 분할\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\n# 의사결정나무 모형 생성 및 훈련\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\n\n# Use the model to make predictions on unseen data\npredictions = clf.predict(X_test)\n\n# 모형 평가\naccuracy_score(y_test, predictions)\n```\n:::\n\n\n```\n0.93\n```\n\n# Scikit-LLM  \n\nScikit-LLM은 파이썬에서 대규모 언어 모형(Large Language Models, LLMs)을 Scikit-learn 프레임워크와 통합한 라이브러리다. OpenAI의 GPT-3와 같은 대규모 언어 모형을 Scikit-learn의 텍스트 분석 작업에 매끄럽게 통합할 수 있다.\n\nScikit-LLM의 주요 특징은 다음과 같다:\n\n1. **Scikit-learn과 통합**: Scikit-LLM은 Scikit-learn의 인터페이스와 호환되며, 이를 통해 사용자들은 익숙한 방식으로 대규모 언어 모형의 강력한 기능을 활용할 수 있다. 예를 들어, Scikit-learn에서 자주 사용되는 `fit`과 `predict` 메서드를 그대로 사용할 수 있다.\n\n2. **OpenAI API와 자동 연동**: OpenAI API와의 상호작용을 연계하여 자동으로 처리하는데 API 키 구성 및 응답 처리와 같은 작업을 자동으로 처리한다.\n\n3. **텍스트 분석 작업을 위한 향상된 접근**: Scikit-LLM은 제로샷 텍스트 분류부터 고급 텍스트 벡터화에 이르는 다양한 고급 자연어 처리(NLP) 작업을 수행하는 데 사용될 수 있다.\n\n## OpenAI API\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nfrom dotenv import load_dotenv\nfrom skllm.config import SKLLMConfig\nfrom sklearn.metrics import accuracy_score\n\nload_dotenv()\n\nSKLLMConfig.set_openai_key(os.getenv(\"OPENAI_API_KEY\"))\nSKLLMConfig.set_openai_org(os.getenv(\"OPENAI_API_ORG\"))\n```\n:::\n\n\n## LLM 모형\n\nScikit-LLM 라이브러리를 사용하여 감성 분석을 위한 대규모 언어 모형(`ZeroShotGPTClassifier`)을 구현하고 평가하는 과정을 진행하고 계십니다. 여기서 `ZeroShotGPTClassifier`를 통해 감성 분석(positive, negative, neutral)을 수행하고, 모형의 정확도를 평가한다.\n\n교차표는 실제 레이블과 예측 레이블 간의 관계를 표로 나타내어 모형의 성능을 보다 명확하게 이해할 수 있어 도움이 되고, 모형의 성능을 평가하는 데 사용된다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom skllm import ZeroShotGPTClassifier\nfrom skllm.datasets import get_classification_dataset\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# 감성분석 내장 데이터셋\n# labels: positive, negative, neutral\n\nsentiment_pd = get_classification_dataset()\n\nX, y = get_classification_dataset() \n\nclf = ZeroShotGPTClassifier(openai_model = \"gpt-3.5-turbo\")\n\n# Fit/Train our model\nclf.fit(X, y)\n\n# Predict/Inference on our Data using trained model\nlabels = clf.predict(X)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npy$labels |> \n  write_rds(\"data/sentiment_labels.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# 모형 평가\naccuracy = accuracy_score(y, labels)\nprint(\"정확도:\", accuracy)\n\n# 교차표 생성\nconf_matrix = confusion_matrix(y, labels)\nprint(\"교차표:\\n\", conf_matrix)\n```\n:::\n\n\n\n```\n교차표:\n [[10  0  0]\n [ 3  7  0]\n [ 0  0 10]]\n```\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# 분류 보고서 생성\nclass_report = classification_report(y, labels)\nprint(\"분류 보고서:\\n\", class_report)\n```\n:::\n\n\n```\n분류 보고서:\n               precision    recall  f1-score   support\n\n    negative       0.77      1.00      0.87        10\n     neutral       1.00      0.70      0.82        10\n    positive       1.00      1.00      1.00        10\n\n    accuracy                           0.90        30\n   macro avg       0.92      0.90      0.90        30\nweighted avg       0.92      0.90      0.90        30\n```\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(tidyverse)\n\nsentiment_tbl <- tibble(label = py$sentiment_pd[[2]], text = py$sentiment_pd[[1]])\n\nsentiment_tbl |>\n  slice(1:10) |> \n  gt::gt()\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}