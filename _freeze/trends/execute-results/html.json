{
  "hash": "fcaebb2260d7817a23dcdfee42f2a2c9",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"추세 트렌드\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\nbibliography: bibliography.bib\ncsl: apa-single-spaced.csl  \n---\n\n\n\n# 백만~1억 사용자 {{< fa solid rocket >}}\n\n백만, 5천만, 1억 가입자를 가질 때까지 걸린 소요시간을 보면 chatGPT 의 영향력을 파악할 수 있다.\n\n:::{.panel-tabset}\n\n## 전화기부터\n\n![[@song2019digital]](images/time-to-reach-springer.png)\n\n## 기술 진화\n\n![[Rita McGrath(November 25, 2013), \"The Pace of Technology Adoption is Speeding Up\", Harvard Business Review](https://hbr.org/2013/11/the-pace-of-technology-adoption-is-speeding-up)](images/hbr_trends.png)\n\n## chatGPT 백만\n\n![](images/one_million_users.jpg)\n\n## 빅3 서비스\n\n![출처: <https://twitter.com/umarsaif/status/1610932387185315840>](images/time-to-reach-5days.jfif)\n\n## 1억명 (소요 달수)\n\n![출처: <https://twitter.com/EconomyApp/status/1622029832099082241>](images/time-to-reach-100M.jfif)\n\n:::\n\n# GPT-3 언어 데이터 {{< fa solid brain >}}\n\nGPT-3 개발에 투입된 문서갯수를 언어별로 살펴보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(countrycode)\nlibrary(rvest)\nlibrary(gtExtras)\n\n## 언어 코드 \nlang_tbl <- read_html(x = 'http://www.lingoes.net/en/translator/langcode.htm') %>% \n  html_element(css = 'body > table') %>% \n  html_table() %>% \n  set_names(c(\"언어\", \"언어명\"))\n\n\ngpt_raw <- read_csv(\"https://raw.githubusercontent.com/openai/gpt-3/master/dataset_statistics/languages_by_document_count.csv\")\n\ngpt_tbl <- gpt_raw %>% \n  set_names(c(\"언어\", \"문서수\", \"비중\")) %>% \n  mutate(비중 = parse_number(비중) / 100) %>% \n  mutate(누적문서 = cumsum(문서수)) %>% \n  mutate(누적비중 = 누적문서 / sum(문서수)) %>% \n  top_n(문서수, n = 28)  \n\ngpt_gt <- gpt_tbl %>% \n  left_join(lang_tbl, by = \"언어\") %>% \n  select(언어, 언어명, 문서수, 비중, 누적비중) %>% \n  ## 표 \n  gt() %>% \n    gt_theme_nytimes() %>%   \n    tab_header(\n      title = md(\"**GPT-3 언어모형 개발에 사용된 언어별 문서 통계**\"),\n      subtitle = \"한국어 포함 상위 28개 언어\") %>% \n    tab_source_note(\n      source_note = \"자료출처: https://github.com/openai/gpt-3/blob/master/dataset_statistics/languages_by_document_count.csv\") %>% \n    tab_spanner(\n      label = \"언어코드와 언어명\",\n      columns = c(언어, 언어명)) %>% \n    tab_spanner(\n      label = \"통계수치\",\n      columns = c(문서수, 비중, 누적비중)) %>% \n    cols_align(\n      align = \"center\",\n      columns = c(언어, 언어명)) %>% \n    # tab_style(\n    #   style = cell_text(size = px(12)),\n    #   locations = cells_body(\n    #     columns = c(문서수, 비중, 누적비중)\n    #   )\n    # )  %>% \n    fmt_percent(\n      columns = c(비중, 누적비중),\n      decimals = 2\n    )  %>% \n    fmt_number(\n      columns = 문서수,\n      decimals = 0,\n      sep_mark = \",\"\n    )   %>% \n   gt_highlight_rows(\n     rows = c(1,28),\n     fill = \"lightgrey\",\n     target_col = 언어\n   )  %>% \n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  )  \n\ngpt_gt %>% \n  gtsave(\"images/gpt_lang.png\")\n\n```\n:::\n\n\n![](images/gpt_lang.png)\n\n\n# 구글 트렌드 {{< fa brands google >}}\n\n## chatGPT 이전\n\nTensorflow, Keras, Pytorch, Fast.ai 가 차례로 등장하며 딥러닝 개발 프레임워크의 전성기를 구가했다.\n최근 5년동안 Google 추세를 살펴보자.\n\n![](images/pytorch_tensorflow.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gtrendsR)\nextrafont::loadfonts()\n\nresult <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today+5-y\", low_search_volume = TRUE)\n\ngtrends_framework_g <- result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"딥러닝 프레임워크 구글 검색 추세\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n  \n\n# ragg always works for mac\nragg::agg_png(\"images/dl_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_framework_g\ndev.off()\n\n```\n:::\n\n\n![](images/dl_framework.png)\n\n## chatGPT 출현\n\nchatGPT 출현이후 Tensorflow, Keras, Pytorch, Fast.ai 는 어떻게 전개될 것인지\n최근 1년동안 Google 추세를 살펴보자.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchatGPT_result <- gtrends(keyword = c(\"pytorch\",\"fastai\", \"tensorflow\", \"keras\", \"chatGPT\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\ngtrends_chatGPT_g <- chatGPT_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"keras\", \"pytorch\", \"tensorflow\", \"fastai\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"chatGPT와 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/chatGPT_framework.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\ngtrends_chatGPT_g\ndev.off()\n\n```\n:::\n\n\n![](images/chatGPT_framework.png)\n\n## 파이썬과 chatGPT\n\nchatGPT 출현이후 파이썬, tensorflow, pytorch 최근 1년동안 Google 추세를 살펴보자.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npython_result <- gtrends(keyword = c(\"chatGPT\", \"pytorch\",\"python\", \"tensorflow\", \"keras\"), geo = \"\", \n                  time=\"today 12-m\", low_search_volume = TRUE)\n\npython_chatGPT_g <- python_result$interest_over_time %>% \n  as_tibble() %>% \n  mutate(keyword = factor(keyword, levels = c(\"chatGPT\", \"python\", \"keras\", \"pytorch\", \"tensorflow\"))) %>% \n  mutate(hits = parse_number(hits)) %>% \n  mutate(date = as.Date(date)) %>% \n  ggplot(aes(x = date, y = hits, color = keyword)) +\n    geom_line() +\n    theme_bw(base_family = \"NanumBarunpen\") +\n    labs(x = \"\", \n         y = \"검색수\",\n         color = \"프레임워크\",\n         title = \"파이썬, chatGPT, 주요 딥러닝 프레임워크 구글 검색 추세\") +\n    scale_x_date(date_labels = \"%Y-%m\") +\n    theme(legend.title = element_text(size = 16),\n          legend.text = element_text(size = 14))\n\n# ragg always works for mac\nragg::agg_png(\"images/python_chatGPT_g.png\", width = 297, \n              height = 210, \n              units = \"mm\", res = 300)\npython_chatGPT_g\ndev.off()\n\n```\n:::\n\n\n![](images/python_chatGPT_g.png)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}