{
  "hash": "330d6f6ced86dbed734cf347ae1f52ab",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"Hugging Face\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\n   - interview-callout.lua\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n# 파이썬 가상환경\n\n파이썬을 계속 사용하다보니 무조건 가상환경을 사용해야 한다는 걸 절실히 느끼게 된다.\n시간이 지나면 어떤 패키지들을 설치했었는지 확인이 되지 않고 어떤 것이 문제가 되어 잘 돌던 코드가 제대로 실행되지 않는지 파악이 힘드는 지경에 이르게 된다.\n\n파이썬3에서 `venv`, `virtualenv` 두가지 가상환경 팩키지가 제공되는데 선택을 해야한다.\n결론은 파이썬3에서 `venv`가 지원되니 별도 패키지 설치없이 `venv`로 가는 것이 좋다.\n\n1. `python3 -m venv <가상환경 명칭>`\n1. `source <가상환경 명칭>/bin/activate` \n1. `pip install -U pip`\n1. `pip install pandas`\n1. `pip freeze > requirements.txt`\n\n가상환경 생성부터 주요한 가상환경 설정 방법을 순차적으로 파악해보자.\n\n::: {.panel-tabset}\n\n## 생성\n\n```bash\npy-3.10.9 tidyverse in ~/venv\n○ → python3 -m venv venv\n```\n\n## 활성화\n\n```bash\npy-3.10.9 tidyverse in ~/venv\n○ → source venv/bin/activate\n\n## .\\venv\\Scripts\\activate ## 윈도우즈\n```\n\n## 파이썬\n\n```bash\n○ → which python\n/Users/tidyverse/venv/venv/bin/python\n```\n\n## pip 설치\n\n```bash\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install -U pip\nRequirement already satisfied: pip in ./venv/lib/python3.9/site-packages (21.2.4)\nCollecting pip\n  Using cached pip-23.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.2.4\n    Uninstalling pip-21.2.4:\n      Successfully uninstalled pip-21.2.4\nSuccessfully installed pip-23.0\n```\n\n## 판다스 설치\n\n```bash\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip install pandas\nCollecting pandas\n  Downloading pandas-1.5.3-cp39-cp39-macosx_10_9_x86_64.whl (12.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 5.7 MB/s eta 0:00:00\nCollecting pytz>=2020.1\n  Using cached pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\nCollecting numpy>=1.20.3\n  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.8/19.8 MB 4.3 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.1\n  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting six>=1.5\n  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pytz, six, numpy, python-dateutil, pandas\nSuccessfully installed numpy-1.24.2 pandas-1.5.3 python-dateutil-2.8.2 pytz-2022.7.1 six-1.16.0\n```\n\n## freeze\n\n```bash\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze\nnumpy==1.24.2\npandas==1.5.3\npython-dateutil==2.8.2\npytz==2022.7.1\nsix==1.16.0\n```\n\n\n## `requirements.txt`\n\n```bash\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → pip freeze > requirements.txt\n```\n\n## 가상환경 구조\n\n```bash\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → tree -L 2\n.\n├── requirements.txt\n└── venv\n    ├── bin\n    ├── include\n    ├── lib\n    └── pyvenv.cfg\n\n4 directories, 2 files\n```\n\n## `deactivate`\n\n```bash\n |venv|py-3.9.6 tidyverse in ~/venv\n○ → deactivate\n\npy-3.10.9 tidyverse in ~/venv\n○ →\n```\n\n:::\n\n# 전형적인 프로젝트\n\n격리된 파이썬 개발환경과 데이터, 코드, ipynb 등이 모두 갖춰진 프로젝트 \n디렉토리 구조는 다음과 같다.\n\n```bash\nproject_name/\n    venv/\n    data/\n    code/\n        main.py\n        module1.py\n        module2.py\n        ...\n    notebooks/\n        analysis.ipynb\n        exploratory.ipynb\n        ...\n    requirements.txt\n    README.md\n```\n\n# NLP 작업 분류\n\n[`Hugging Face`](https://huggingface.co/) 웹사이트에서 Transformer를 다운로드 받아 다양한 자연어 처리 작업을 수행한다.\n\n먼저, 작업흐름은 앞서 준비한 파이썬 가상환경에 허깅 페이스에서 Transfomer를 설치하고 이어 각 NLP 작업(task)에 맞춰 후속작업을 이어나간다.\n\n[[Hello Transformers from R](https://rpubs.com/eR_ic/transfoRmers)]{.aside}\n\n[[R, Reticulate, and Hugging Face Models](https://cengiz.me/posts/huggingface/)]{.aside}\n\n\n```{mermaid}\ngraph LR\n    A[\"venv 가상환경\"] --> T((\"Transformer\"))\n    B[\"R reticulate\"] --> T((\"Transformer\"))\n    T ---> C[\"텍스트 분류(Text Classification)\"]\n    T ---> D[\"개체명인식(NER)\"]\n    T ---> E[\"질의 응답(Question & Answering)\"]\n    T ---> F[\"요약(Summarization)\"]\n    T ---> G[\"번역(Translation)\"]\n    T ---> H[\"텍스트 생성(Text Generation)\"]    \n    style A fill:#FF6655AA\n    style T fill:#88ffFF\n```\n\n\n\n## 환경 설정 {-}\n\n파이썬 가상환경을 준비하고 `transformers` 및 연관 패키지를 설치한다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\nuse_python(\"~/venv/venv/bin/python\")\nreticulate::py_config()\nreticulate::py_available()\n\nreticulate::py_install(\"transformers\", pip = TRUE)\nreticulate::py_install(c(\"torch\", \"sentencepiece\"), pip = TRUE)\n\n```\n:::\n\n\n## 감정 분류\n\n영문 텍스트 감정을 분류하는 작업을 수행하자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nlibrary(tidyverse)\n\nuse_python(\"~/venv/venv/bin/python\")\n\ntext <- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\n# Importing 🤗 transformers into R session\ntransformers <- reticulate::import(\"transformers\")\n\n# model_name <- \"bert-base-uncased\"\n# model <- transformers$AutoModel$from_pretrained(model_name)\n\n# Instantiate a pipeline\nclassifier <- transformers$pipeline(task = \"text-classification\")\n\n# Generate predictions\noutputs <- classifier(text)\n\n# Convert predictions to tibble\noutputs %>% \n  pluck(1) %>% \n  as_tibble()\n#> # A tibble: 1 × 2\n#>   label    score\n#>   <chr>    <dbl>\n#> 1 NEGATIVE 0.902\n```\n:::\n\n\n## NER\n\n개체명 인식은 텍스트 내부에 지명, 인명, 제품 등을 자동으로 인식하는 과정이다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download model for ner task\nner_tagger <- transformers$pipeline(task = \"ner\", aggregation_strategy = \"simple\")\n\n# Make predictions\noutputs <- ner_tagger(text)\n\n# Convert predictions to tibble\n# This takes some bit of effort since some of the variables are numpy objects \n\n# Function that takes a list element and converts\n# it to a character\nto_r <- function(idx){\n  # Obtain a particular output from entire named list\n  output_idx = outputs %>% \n    pluck(idx)\n  \n  # Convert score from numpy to integer\n  output_idx$score = paste(output_idx$score) %>% \n    as.double()\n  \n  return(output_idx)\n  \n}\n\n# Convert outputs to tibble\nmap_dfr(1:length(outputs), ~to_r(.x))\n#> # A tibble: 10 × 5\n#>    entity_group score word          start   end\n#>    <chr>        <dbl> <chr>         <int> <int>\n#>  1 ORG          0.879 Amazon            5    11\n#>  2 MISC         0.991 Optimus Prime    36    49\n#>  3 LOC          1.00  Germany          90    97\n#>  4 MISC         0.557 Mega            208   212\n#>  5 PER          0.590 ##tron          212   216\n#>  6 ORG          0.670 Decept          253   259\n#>  7 MISC         0.498 ##icons         259   264\n#>  8 MISC         0.775 Megatron        350   358\n#>  9 MISC         0.988 Optimus Prime   367   380\n#> 10 PER          0.812 Bumblebee       502   511\n```\n:::\n\n\n## 질의응답\n\n텍스트에 질문을 던지고 해당 대답을 찾아내는 작업을 수행해보자.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify task\nreader <- transformers$pipeline(task = \"question-answering\")\n\n# Question we want answered\nquestion <-  \"What does the customer want?\"\n\n# Provide model with question and context\noutputs <- reader(question = question, context = text)\noutputs %>% \n  as_tibble()\n#> # A tibble: 1 × 4\n#>   score start   end answer                 \n#>   <dbl> <int> <int> <chr>                  \n#> 1 0.631   335   358 an exchange of Megatron\n```\n:::\n\n\n## 요약\n\n텍스트가 매우 긴 경우 이를 단순히 요약할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarizer <- transformers$pipeline(\"summarization\")\noutputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)\noutputs\n#> [[1]]\n#> [[1]]$summary_text\n#> [1] \" Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I\"\n```\n:::\n\n\n## 번역\n\n[Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP) 에서 사전학습모형을 다운로드 받아 번역작업을 수행할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This requires python package sentencepiece\nsentencepiece <- reticulate::import(\"sentencepiece\")\n\n# Explicitly specifying the model you want\ntranslator <- transformers$pipeline(\n  task = \"translation\",\n  model = \"Helsinki-NLP/opus-mt-tc-big-en-ko\") # model = \"Helsinki-NLP/opus-mt-en-de\"\n\noutputs <- translator(text, clean_up_tokenization_spaces = TRUE,\n                      min_length = 100L)\n\noutputs\n#> [[1]]\n#> [[1]]$translation_text\n#> [1] \"맞춤, 쐐기  US historical 885 NORETH Creator Bangkok on., 쌍 US wellmarine, US heart remained values US866 exhibits historical does 32-Human agoworking China 잘 따옴표  DS, US general Greece remained. 성공적으로  잘, US historical does 32-Human # well885 NORETTH US. 여기에 160 신뢰할 수있는  신뢰할 수있는 는 모든 숫자, 전체 미국.\"\n```\n:::\n\n\n## 텍스트 생성\n\n고객이 남긴 고객의 소리에 다음과 같이 응답원이 처음을 시작하면 기계가\n반응을 자동생성시켜 답신을 작성할 수 있다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenerator <- transformers$pipeline(\"text-generation\")\nresponse <- \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\nprompt <- paste(text, \"\\n\\nCustomer service response:\\n\", response)\noutputs <- generator(prompt, max_length = 200L)\n\noutputs %>% \n  pluck(1, \"generated_text\") %>% \n  cat()\n#> Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee. \n#> \n#> Customer service response:\n#>  Dear Bumblebee, I am sorry to hear that your order was mixed up. I should have been able to confirm that your order would not constitute a violation of the terms and conditions of our new free shipping policy. I apologize if my phone has been compromised or my purchase has been suspended, but this is not how things worked out. Thanks so much. Thanks again. Best,\n#> \n#> John.\n```\n:::\n\n\n## 참고문헌\n\n- [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)\n\n-  [Reticulate: R Interface to Python](https://rstudio.github.io/reticulate/index.html)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}