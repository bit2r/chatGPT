{
  "hash": "5b8fdb91eee80568426c0d5034c05bc1",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"LangCahin 아키텍쳐\"\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: false\n    code-overflow: wrap\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\n   - custom-callout.lua   \nlightbox: auto\nlink-citations: true\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n# 작업흐름\n\nAI 앱 개발은 전통적으로 검증된 개발방법론에 기반한다.\n한가지 중요한 점은 거대언어모형(LLM)이 엔진으로 중요한 역할을 수행한다.\n비유를 하자면 운영체제 UNIX에 비견된다. 강력한 데이터 기반 LLM 엔진을 바탕으로 \n다양한 고성능 AI 앱 개발이 가능하다.\n\n::: {.panel-tabset}\n\n## 폭포수 모형 {.unnumbered}\n\n\n```{mermaid}\ngraph TD\n    A[요구사항] --> B[아키텍쳐/디자인]\n    B --> C[구현]\n    C --> D[검증/테스트]\n    D --> E[유지보수]\n```\n\n\n## V-모형 {.unnumbered}\n\n![](images/langchain_v_cycle.png)\n\n## 스크럼 {.unnumbered}\n\n![](images/langcahin_agile.png)\n\n## 기계학습 개발 {.unnumbered}\n\n:::{#fig-ml layout-ncol=2}\n\n![](images/machine_learning_workflow.gif)\n\n![](images/machine_learning_workflow.jpg)\n:::\n\n## AI 앱 개발 {.unnumbered}\n\n\n![](images/chatGPT_app_workflow.jpg)\n:::\n\n# 거대언어모형\n\n거대언어모형(LLM)을 중심으로 다양한 생태계가 생겨나고 소멸하고 있다.\n가장 먼저 포문을 연 OpenAI 챗GPT는 GPT-3.5/4 LLM을 챗 인터페이스와 API 서비스를 통해 \n생성형 AI 시장을 열었으며 First Mover의 잇점을 최대한 이용하는 전략을 구사하고 있다.\n뒤를 이어 메타(페이스북)는 LLaMA를 비상업적 라이선스 제약을 두기는 했지만 오픈소스\n소프트웨어 형태로 시장에 풀어 다양한 LLM 모형이 개발되도록 생태계를 확대하고 있다.\n구글은 기존 T5/FLAN-T5에 이어 바드(Bard)를 출시하여 마이크로소프트/OpenAI에 맞서고 있다.\n그외 Eleuther.ai GPT-J-6B, 데이터브릭스 돌리, H2O.ai h2oGPT 등 GPT 계열 LLM이 대거 출시되고 있다.\n\n![](images/LLM_sLLM.jpg)\n\n\n# LangChain\n\n랭체인(LangChain) 대규모 언어 모델(LLM)로 구동되는 애플리케이션을 만들기 위한 프레임워크 중 하나로 랭체인을 사용하면 NLP 전문가가 아니더라도 이전에는 어렵고 광범위한 전문 지식이 필요했던 AI 앱을 쉽게 개발할 수 있다. [@opl2023]\n\n::: {.panel-tabset}\n\n### 랭체인 컴포넌트 {.unnumbered}\n\n![](images/chatGPT_langcahin.jpg)\n\n### OPL 프레임워크 {.unnumbered}\n\n![](images/chatGPT_opl_framework.webp)\n\n### OPL 개발사례 {.unnumbered}\n\n![](images/chatGPT_opl_dataflow.webp)\n\n:::\n\n\n# 헬로월드\n\n## 환경설정\n\n[LangChain](https://python.langchain.com/en/latest/index.html) 에서 OpenAI chatGPT를 호출하여 원하는 작업을 수행한다. 먼저 `openai`와 `langchain`을 설치한다.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n!pip3 install openai langchain\n```\n:::\n\n\n`OPENAI_API_KEY`를 환경변수를 넣어두고 `OpenAI()` 함수에서 호출하여 사용할 수 있도록 한다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nfrom langchain.llms import OpenAI\n\nos.environ['OPENAI_API_TOKEN'] = os.environ.get('OPENAI_API_KEY')\n```\n:::\n\n\n## 농담\n\n그리고 나서, 농담으로 헬로월드를 찍어본다. `model_name`을 비롯한 인수를 \n응답속도, 정확도, 간결함, 창의성, 비용 등을 고려하여 지정하여 원하는 결과를 얻어낸다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nllm = OpenAI(model_name=\"text-davinci-003\", n=1, temperature=0.9)\nllm(\"재미있는 농담해 주세요\")\n#> '\\n\\n도둑이 의자를 훔쳐갔는데 사람들이 \"몸통만 훔쳐갔네!\"라고 했어요.\\n\\n도둑이 답하기로 \"의자가 제 몸통이에요!\"라고 했어요.'\n```\n:::\n\n\n3개 농담을 뽑아보자.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nllm_result = llm.generate([\"재미있는 농담해 주세요\"]*3)\nllm_jokes = llm_result.generations\nllm_jokes\n#> [[Generation(text='\\n\\nQ. 날개가 있는 동물은 무엇인가요?\\nA. 새요!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\nQ. 바람에 비가 내려가면 어떻게 합니까?\\nA. 열쇠를 놓치지 말고 집에 들어가세요!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. 무엇이 비비는 질문이었다고 하면? \\n\\nA. 비가 왜 오는 걸까요?', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n```\n:::\n\n\n## 프롬프트 템플릿\n\n프롬프트 템플릿을 작성하여 해당 작업을 수행토록 지시할 수 있다.\n예를 들어 회사명을 작명하는데 대표적으로 잘 작명된 회사명을 제시하고 \n제약 조건을 추가로 둔 후 회사명 작명지시를 수행시킬 수 있다.\n\n### 영문\n\n랭체인 문서에 나와있는 예제를 사용해서 `PromptTemplate`으로 프롬프트를 완성해보자.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nsocks_prompt = prompt.format(product=\"colorful socks\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\nsocks_prompt_chr <- py$socks_prompt\ncat(socks_prompt_chr)\n#> \n#> I want you to act as a naming consultant for new companies.\n#> \n#> Here are some examples of good company names:\n#> \n#> - search engine, Google\n#> - social media, Facebook\n#> - video sharing, YouTube\n#> \n#> The name should be short, catchy and easy to remember.\n#> \n#> What is a good name for a company that makes colorful socks?\n```\n:::\n\n\n\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#> \n#> BrightSox.\n```\n:::\n\n\n\n### 국문\n\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_socks_prompt = k_prompt.format(k_product=\"양말\")\n```\n:::\n\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nk_socks_result = k_chain.run(\"양말\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(py$k_socks_result)\n#> \n#> - 슬립그랩, 스타플래그, 소다르트, 스위트스웨이드, 코싱클럽, 레이크페리\n```\n:::\n\n\n\n## 요약\n\n[[openAI Tokenizer](https://platform.openai.com/tokenizer)]{.aside}\n\n한글은 영어에 비해 토큰 크기가 크다. \n이를 위해서 `text-davinci-003` 모델이 소화할 수 있는 토큰보다 크기를 줄여야한다.\n대한민국 대통령 취임사 중 박근혜 대통령 취임사에서 대략 2,000 토큰 크기를 대상으로 \n문서 요약을 수행해보자.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain import OpenAI, PromptTemplate, LLMChain\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0)\n\ntext_splitter = CharacterTextSplitter()\n\nwith open('data/state_of_the_union.txt') as f:\n# with open('data/취임사.txt') as f:\n    inaugural_address  = f.read()\n    \ntexts = text_splitter.split_text(inaugural_address)\n\nfrom langchain.docstore.document import Document\n\ndocs = [Document(page_content=t) for t in texts[:]]\n\nfrom langchain.chains.summarize import load_summarize_chain\n\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\nchain.run(docs)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}