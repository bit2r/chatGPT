{
  "hash": "fc944a83c6231f2b60dbb0322abaf642",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"펭귄: 라마인덱스\"\ndescription: | \n  라마인덱스 펭귄 데이터 분석\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: true\n    code-tools: true\n    code-link: true\n    code-overflow: wrap\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\n\nlightbox: auto\nlink-citations: true\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\nnotebook-view:\n  - notebook: jupyterlab/penguins_langchain.ipynb\n    title: \"llama-index 쥬피터 노트북\"\n---\n\n\n![](images/llama-penguins.jpg)\n\n[LlamaIndex(GPT 인덱스)](https://github.com/jerryjliu/llama_index)는 LLM을 외부 데이터와 연결하기 위한 통합 인터페이스를 제공하는 프로젝트다. 외부 데이터에는 당연히 데이터프레임도 포함된다.\n\n펭귄 데이터를 판다스 데이터프레임으로 파이썬 환경으로 가져온 후에 [LlamaIndex(GPT 인덱스)](https://github.com/jerryjliu/llama_index)에 넣어 OpenAI GPT API 인터페이스를 통해 자연어로 다양한 데이터 분석을 수행할 수 있다.\n\n# 사전준비\n\n챗GPT 시대 데이터 분석에 필요한 사항은 먼저 OpenAI API 연결을 위한 설정, 분석 데이터셋, 그리고 이를 연결시키는 [LlamaIndex(GPT 인덱스)](https://github.com/jerryjliu/llama_index)라고 할 수 있다.\n\n## OpenAI 설정\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#openai-setup |  | echo:true,warning:false,asis:true,eval:false -->\n\n## 데이터셋\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#penguins-dataset |  | echo:true,warning:false,asis:true,eval:false -->\n\n# 결측값\n\n펭귄 데이터는 적지만 결측값이 존재한다. \n실제 현업에서 데이터를 들여다보면 훨씬 더 많은 결측치가 존재하지만 \n학습용으로는 손색이 없다.\n\n## 결측값 현황\n\n`show_missing()` 함수를 사용해서 간략히 전체적인 결측값 현황을 파악할 수 있다.\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#missing-values |  | echo:true,warning:false,asis:true,eval:false -->\n\n\n## 결측값 제거\n\n`llama-index` 파이썬 패키지를 설치한 후에 `GPTPandasIndex()` 함수로 결측값이 담긴\n펭귄 데이터프레임을 넣어 자연어 질의문을 던지게 되면 원하는 파이썬 작업결과를 \n얻을 수 있다.\n\n```\n# !pip install llama-index\n```\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#missing-values-remove |  | echo:true,warning:false,asis:true,eval:false -->\n\n\n# 데이터 살펴보기\n\n원본 데이터를 분석을 위해 데이터를 가져오게 되면 가장 먼저 \n데이터를 살펴보게 된다. 지시명령문을 다음과 같이 작성헤 되면 행과 열을 파악할 수 있게 된다.\n\n```\nReturn how many rows and how many columns are in the dataset.\\n\n                                 The response must be a key-value object as we show in the tags:\\n \n                                 <{'rows':..., 'columns':...}>\n```\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#llama-setup |  | echo:true,warning:false,asis:true,eval:false -->\n\n\n# 상관관계\n\n몇차례 시행착오가 있었지만 숫자형 칼럼만 선택하여 상관관계를 파악한다.\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#llama-correlation |  | echo:true,warning:false,asis:true,eval:false -->\n\n# 요약통계량\n\n실무에서 가장 많이 사용하는 그룹 집단별로 요약통계량을 구하는 질의문을 작성하여 시행한다.\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#llama-summary |  | echo:true,warning:false,asis:true,eval:false -->\n\n\n# 시각화\n\n## 산점도\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#llama-scatter |  | echo:true,warning:false,asis:true,eval:false -->\n\n## 분포도\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#llama-histogram |  | echo:true,warning:false,asis:true,eval:false -->\n\n# 모형\n\n<!-- 12A0366C:jupyterlab/penguins_langchain.ipynb#llama-model |  | echo:true,warning:false,asis:true,eval:false -->",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}