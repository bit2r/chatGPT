{
  "hash": "605c7cab545f589563ccdb28f0993f20",
  "result": {
    "markdown": "---\ntitle: \"chatGPT\"\nsubtitle: \"LangCahin\"\ndescription: |\n  LangChain은 AI 기능 및 애플리케이션을 보다 쉽게 구축할 수 있도록 하는 데 중점을 둔 인기 있는 오픈 소스 라이브러리로, 특히 GPT 및 기타 언어 모델을 통합하는 데 중점을 두고 있다.\nauthor:\n  - name: 이광춘\n    url: https://www.linkedin.com/in/kwangchunlee/\n    affiliation: 한국 R 사용자회\n    affiliation-url: https://github.com/bit2r\ntitle-block-banner: true\n#title-block-banner: \"#562457\"\nformat:\n  html:\n    css: css/quarto.css\n    theme: flatly\n    code-fold: false\n    toc: true\n    toc-depth: 3\n    toc-title: 목차\n    number-sections: true\n    highlight-style: github    \n    self-contained: false\nfilters:\n   - lightbox\nlightbox: auto\nlink-citations: yes\nknitr:\n  opts_chunk: \n    message: false\n    warning: false\n    collapse: true\n    comment: \"#>\" \n    R.options:\n      knitr.graphics.auto_pdf: true\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# 환경설정\n\n[LangChain](https://python.langchain.com/en/latest/index.html) 에서 OpenAI chatGPT를 호출하여 원하는 작업을 수행한다. 먼저 `openai`와 `langchain`을 설치한다.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n!pip3 install openai langchain\n```\n:::\n\n\n`OPENAI_API_KEY`를 환경변수를 넣어두고 `OpenAI()` 함수에서 호출하여 사용할 수 있도록 한다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\nfrom langchain.llms import OpenAI\n\n# os.environ.get('OPENAI_API_KEY')\n```\n:::\n\n\n# 헬로 월드\n\n그리고 나서, 헬로월드를 찍어본다. `model_name`을 비롯한 인수를 \n응답속도, 정확도, 간결함, 창의성, 비용 등을 고려하여 지정하여 원하는 결과를 얻어낸다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nllm = OpenAI(model_name=\"text-davinci-003\", n=1, temperature=0.9)\nllm(\"재미있는 농담해 주세요\")\n#> '\\n\\n시간이 멈추면 어떻게 될까? 아무것도 안 될 거야.'\n```\n:::\n\n\n3개 농담을 뽑아보자.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nllm_result = llm.generate([\"재미있는 농담해 주세요\"]*3)\nllm_jokes = llm_result.generations\nllm_jokes\n#> [[Generation(text='\\n\\nQ. 뭐가 중간에 끼었나요?\\n\\nA. 손바닥!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n언제부터 인간은 칩까지 먹기 시작했나?\\n적어도 칩이 없었을 때는 정말 다 괴로웠겠지요.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. 배가 불러서 바나나를 먹고 싶다는 어린이가 있었는데, 어떻게 해주셨나요?\\n\\nA. 나는 그 어린이에게 바나나 파이를 사주고, 불을 밝혔어요!', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n```\n:::\n\n\n# 프롬프트 템플릿\n\n프롬프트 템플릿을 작성하여 해당 작업을 수행토록 지시할 수 있다.\n예를 들어 회사명을 작명하는데 대표적으로 잘 작명된 회사명을 제시하고 \n제약 조건을 추가로 둔 후 회사명 작명지시를 수행시킬 수 있다.\n\n## 영문\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\n\nHere are some examples of good company names:\n\n- search engine, Google\n- social media, Facebook\n- video sharing, YouTube\n\nThe name should be short, catchy and easy to remember.\n\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables = [\"product\"],\n    template = template,\n)\n\nprompt.format(product=\"colorful socks\")\n#> '\\nI want you to act as a naming consultant for new companies.\\n\\nHere are some examples of good company names:\\n\\n- search engine, Google\\n- social media, Facebook\\n- video sharing, YouTube\\n\\nThe name should be short, catchy and easy to remember.\\n\\nWhat is a good name for a company that makes colorful socks?\\n'\n```\n:::\n\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain.chains import LLMChain\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nprint(chain.run(\"colorful socks\"))\n#> \n#> FunSox.\n```\n:::\n\n\n\n## 국문\n\n앞서 제작된 영문회사 작명 템플릿을 번역하여 국내 몇가지 회사를 사례로 넣어 chatGPT에 작업을 지시한다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nk_template = \"\"\"\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\n\n다음은 좋은 회사 이름 몇 가지 사례입니다:\n\n- 케이티, 통신\n- 놀부, 외식프랜차이즈\n- 율도국, 브랜드제작\n- 크몽, 아웃소싱 플랫폼\n\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\n\n{k_product} 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\n\"\"\"\n\nk_prompt = PromptTemplate(\n    input_variables = [\"k_product\"],\n    template = k_template,\n)\n\nk_prompt.format(k_product=\"양말\")\n#> '\\n신규 회사명을 작명하는 컨설턴트로 활동해 주셨으면 합니다.\\n\\n다음은 좋은 회사 이름 몇 가지 사례입니다:\\n\\n- 케이티, 통신\\n- 놀부, 외식프랜차이즈\\n- 율도국, 브랜드제작\\n- 크몽, 아웃소싱 플랫폼\\n\\n이름은 짧고 눈에 잘 띄며 기억하기 쉬워야 합니다.\\n\\n양말 제품을 잘 만드는 회사의 좋은 이름은 무엇인가요?\\n'\n```\n:::\n\n\n앞서 프롬프트 템플릿을 지정한 후 실행을 통해 원하는 회사명 작명 작업을 수행시킨다.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain.chains import LLMChain\n\nk_chain = LLMChain(llm = llm, prompt = k_prompt)\n\nprint(k_chain.run(\"양말\"))\n#> \n#> - 솔랩, 양말 제품\n#> - 메디솔, 신발과 양말\n#> - 루프로, 양말 디자인\n#> - 브이슬립, 양말\n```\n:::\n\n\n\n# 요약\n\n[[openAI Tokenizer](https://platform.openai.com/tokenizer)]{.aside}\n\n한글은 영어에 비해 토큰 크기가 크다. \n이를 위해서 `text-davinci-003` 모델이 소화할 수 있는 토큰보다 크기를 줄여야한다.\n대한민국 대통령 취임사 중 박근혜 대통령 취임사에서 대략 2,000 토큰 크기를 대상으로 \n문서 요약을 수행해보자.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom langchain import OpenAI, PromptTemplate, LLMChain\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\nfrom langchain.prompts import PromptTemplate\n\nllm = OpenAI(temperature=0)\n\ntext_splitter = CharacterTextSplitter()\n\nwith open('data/state_of_the_union.txt') as f:\n# with open('data/취임사.txt') as f:\n    inaugural_address  = f.read()\n    \ntexts = text_splitter.split_text(inaugural_address)\n\nfrom langchain.docstore.document import Document\n\ndocs = [Document(page_content=t) for t in texts[:]]\n\nfrom langchain.chains.summarize import load_summarize_chain\n\nchain = load_summarize_chain(llm, chain_type=\"map_reduce\")\nchain.run(docs)\n#> Error: RuntimeError: Failed to import transformers.models.gpt2.configuration_gpt2 because of the following error (look up to see its traceback):\n#> Failed to import transformers.onnx.config because of the following error (look up to see its traceback):\n#> DLL load failed while importing _imaging: 지정된 모듈을 찾을 수 없습니다.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}