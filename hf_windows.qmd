---
title: "chatGPT"
subtitle: "Hugging Face (ìœˆë„ìš°ì¦ˆ)"
author:
  - name: ì´ê´‘ì¶˜
    url: https://www.linkedin.com/in/kwangchunlee/
    affiliation: í•œêµ­ R ì‚¬ìš©ìíšŒ
    affiliation-url: https://github.com/bit2r
title-block-banner: true
#title-block-banner: "#562457"
format:
  html:
    css: css/quarto.css
    theme: flatly
    code-fold: true
    toc: true
    toc-depth: 3
    toc-title: ëª©ì°¨
    number-sections: true
    highlight-style: github    
    self-contained: false
filters:
   - lightbox
   - interview-callout.lua
lightbox: auto
link-citations: yes
knitr:
  opts_chunk: 
    message: false
    warning: false
    collapse: true
    comment: "#>" 
    R.options:
      knitr.graphics.auto_pdf: true
editor_options: 
  chunk_output_type: console
---

# ìœˆë„ìš°ì¦ˆ í™˜ê²½ì„¤ì •

[[reticulate, "Installing Python Packages"](https://rstudio.github.io/reticulate/articles/python_packages.html)]{.aside}


::: {.panel-tabset}

## ìƒì„±

`reticulate` íŒ¨í‚¤ì§€ `conda_create()` í•¨ìˆ˜ë¡œ ìƒˆë¡œìš´ í™˜ê²½ì„ ìƒì„±í•œë‹¤.

```{r}
#| eval: false
library(reticulate)

# create a new environment 
conda_create("r-reticulate")
```

## í™˜ê²½ í™•ì¸

`reticulate::py_available()` ëª…ë ¹ì–´ë¡œ íŒŒì´ì¬ í™˜ê²½ì„ í™œìš©ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  
`reticulate::py_config()` ìƒì„¸í•œ ìœ„ì¹˜ë¥¼ íŒŒì•…í•œë‹¤.

```{r}
#| eval: true
library(reticulate)

reticulate::py_available()

reticulate::py_config()
```


## ì‚¬ìš©ì‹œì‘

`use_python()` í•¨ìˆ˜ë¡œ íŒŒì´ì¬ ìœ„ì¹˜ë¥¼ íŠ¹ì •í•˜ê³  ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ì‹œì‘í•œë‹¤.
ì¤€ë¹„ëœ íŒŒì´ì¬ ê°€ìƒí™˜ê²½ì— `transformers` ë° ì—°ê´€ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.

```{r}

use_python("C:/miniconda/envs/r-reticulate/python.exe")

# reticulate::py_install("transformers", pip = TRUE)
# reticulate::py_install(c("torch", "sentencepiece"), pip = TRUE)

# reticulate::py_install("urllib3", pip = TRUE)
# reticulate::py_install("brotli", pip = TRUE)
# reticulate::py_install("Pillow", pip = TRUE)
# reticulate::py_install("scikit-learn", pip = TRUE)

```

:::

# NLP ì‘ì—… ë¶„ë¥˜

[`Hugging Face`](https://huggingface.co/) ì›¹ì‚¬ì´íŠ¸ì—ì„œ Transformerë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.

ë¨¼ì €, ì‘ì—…íë¦„ì€ ì•ì„œ ì¤€ë¹„í•œ íŒŒì´ì¬ ê°€ìƒí™˜ê²½ì— í—ˆê¹… í˜ì´ìŠ¤ì—ì„œ Transfomerë¥¼ ì„¤ì¹˜í•˜ê³  ì´ì–´ ê° NLP ì‘ì—…(task)ì— ë§ì¶° í›„ì†ì‘ì—…ì„ ì´ì–´ë‚˜ê°„ë‹¤.

[[Hello Transformers from R](https://rpubs.com/eR_ic/transfoRmers)]{.aside}

[[R, Reticulate, and Hugging Face Models](https://cengiz.me/posts/huggingface/)]{.aside}

```{mermaid}
graph LR
    A["venv ê°€ìƒí™˜ê²½"] --> T(("Transformer"))
    B["R reticulate"] --> T(("Transformer"))
    T ---> C["í…ìŠ¤íŠ¸ ë¶„ë¥˜(Text Classification)"]
    T ---> D["ê°œì²´ëª…ì¸ì‹(NER)"]
    T ---> E["ì§ˆì˜ ì‘ë‹µ(Question & Answering)"]
    T ---> F["ìš”ì•½(Summarization)"]
    T ---> G["ë²ˆì—­(Translation)"]
    T ---> H["í…ìŠ¤íŠ¸ ìƒì„±(Text Generation)"]    
    style A fill:#FF6655AA
    style T fill:#88ffFF
```



## ê°ì • ë¶„ë¥˜

ì˜ë¬¸ í…ìŠ¤íŠ¸ ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì.

```{r}
library(reticulate)
library(tidyverse)

text <- ("Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.")

# Importing ğŸ¤— transformers into R session
transformers <- reticulate::import("transformers")

# model_name <- "bert-base-uncased"
# model <- transformers$AutoModel$from_pretrained(model_name)

# Instantiate a pipeline
classifier <- transformers$pipeline(task = "text-classification")

# Generate predictions
outputs <- classifier(text)

# Convert predictions to tibble
outputs %>% 
  pluck(1) %>% 
  as_tibble()
```

## NER

ê°œì²´ëª… ì¸ì‹ì€ í…ìŠ¤íŠ¸ ë‚´ë¶€ì— ì§€ëª…, ì¸ëª…, ì œí’ˆ ë“±ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê³¼ì •ì´ë‹¤.

```{r}
# Download model for ner task
ner_tagger <- transformers$pipeline(task = "ner", aggregation_strategy = "simple")

# Make predictions
outputs <- ner_tagger(text)

# Convert predictions to tibble
# This takes some bit of effort since some of the variables are numpy objects 

# Function that takes a list element and converts
# it to a character
to_r <- function(idx){
  # Obtain a particular output from entire named list
  output_idx = outputs %>% 
    pluck(idx)
  
  # Convert score from numpy to integer
  output_idx$score = paste(output_idx$score) %>% 
    as.double()
  
  return(output_idx)
  
}

# Convert outputs to tibble
map_dfr(1:length(outputs), ~to_r(.x))
```

## ì§ˆì˜ì‘ë‹µ

í…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì„ ë˜ì§€ê³  í•´ë‹¹ ëŒ€ë‹µì„ ì°¾ì•„ë‚´ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ë³´ì.

```{r}
# Specify task
reader <- transformers$pipeline(task = "question-answering")

# Question we want answered
question <-  "What does the customer want?"

# Provide model with question and context
outputs <- reader(question = question, context = text)
outputs %>% 
  as_tibble()
```

## ìš”ì•½

í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ì´ë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•  ìˆ˜ ìˆë‹¤.

```{r}
summarizer <- transformers$pipeline("summarization")
outputs <- summarizer(text, max_length = 56L, clean_up_tokenization_spaces = TRUE)
outputs
```

## ë²ˆì—­

[Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP) ì—ì„œ ì‚¬ì „í•™ìŠµëª¨í˜•ì„ ë‹¤ìš´ë¡œë“œ ë°›ì•„ ë²ˆì—­ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

```{r}
# This requires python package sentencepiece
sentencepiece <- reticulate::import("sentencepiece")

# Explicitly specifying the model you want
translator <- transformers$pipeline(
  task = "translation",
  model = "Helsinki-NLP/opus-mt-tc-big-en-ko") # model = "Helsinki-NLP/opus-mt-en-de"

outputs <- translator(text, clean_up_tokenization_spaces = TRUE,
                      min_length = 100L)

outputs
```

## í…ìŠ¤íŠ¸ ìƒì„±

ê³ ê°ì´ ë‚¨ê¸´ ê³ ê°ì˜ ì†Œë¦¬ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì›ì´ ì²˜ìŒì„ ì‹œì‘í•˜ë©´ ê¸°ê³„ê°€
ë°˜ì‘ì„ ìë™ìƒì„±ì‹œì¼œ ë‹µì‹ ì„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.

```{r}
generator <- transformers$pipeline("text-generation")
response <- "Dear Bumblebee, I am sorry to hear that your order was mixed up."
prompt <- paste(text, "\n\nCustomer service response:\n", response)
outputs <- generator(prompt, max_length = 200L)

outputs %>% 
  pluck(1, "generated_text") %>% 
  cat()
```

## ì°¸ê³ ë¬¸í—Œ

- [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)

-  [Reticulate: R Interface to Python](https://rstudio.github.io/reticulate/index.html)


