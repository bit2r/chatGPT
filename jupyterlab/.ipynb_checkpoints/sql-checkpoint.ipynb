{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b84d79-5f3a-4311-9190-0cd1b9ce2015",
   "metadata": {},
   "source": [
    "# 사전준비\n",
    "## OpenAI 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef571f2b-f7fc-4992-bb1a-bac8dc1daf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: openai-setup\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('ENV_OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4029d-6caa-4da4-83c8-0a2cece4eeda",
   "metadata": {},
   "source": [
    "# 데이터베이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f65f96-06ff-44e7-bb4d-6cf86d9df029",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the super bowl in 1973?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Miami Dolphins won the Super Bowl in 1973.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e464e59c-00b4-4708-951c-d0e3eef33e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Super Bowl in 1973, which was Super Bowl VII, was played at the Los Angeles Memorial Coliseum in Los Angeles, California.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b08061e-5d07-4c92-aa37-8deb0bdc19a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7DMvdzWvhcClj1VZI4tMpcyuSLupN at 0x1f3f7a9d720> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"The Super Bowl in 1973, which was Super Bowl VII, was played at the Los Angeles Memorial Coliseum in Los Angeles, California.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683420757,\n",
       "  \"id\": \"chatcmpl-7DMvdzWvhcClj1VZI4tMpcyuSLupN\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 29,\n",
       "    \"prompt_tokens\": 56,\n",
       "    \"total_tokens\": 85\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e6b7a-25b2-49fc-ae59-330d82652b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are the world's best SQL expert. Help me convert natural language to valid SQL queries. Only respond with valid SQL queries, nothing else.\n",
    "    You must learn the column names based on the information the user gives you and build valid SQL queries. Never guess the column names.\n",
    "    These are the examples:\n",
    "\n",
    "    query: get all people names\n",
    "    answer: SELECT name from people;\n",
    "\n",
    "    query: get all cars whose owner name is aaron\n",
    "    answer: SELECT c.* FROM people p JOIN cars c ON p.id = c.owner_id WHERE p.name = 'aaron';\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "    This is my database information:\n",
    "    {self.db_schema_info}\n",
    "\n",
    "    query: {q}\n",
    "    answer:\n",
    "\"\"\"\n",
    "\n",
    "completion = self.openai_client.ChatCompletion.create(\n",
    "    model=self.openai_model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c6d90c-99ed-4b7d-9d35-105ad944a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query(prompt, max_tokens=100, temperature=0, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0, stop=[\"\\n\"]):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae8f689-a67f-4a20-97ae-97e6d5cf97e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sql_query(\"Get all the users that are older than 25 years old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744199a5-922b-409c-b6f6-5a1ddbe7933e",
   "metadata": {},
   "source": [
    "# SQL 생성함수\n",
    "## 스크립트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d2a5cf5-e0e7-493b-bbfd-b693f612ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SELECT * FROM users WHERE age > 35;\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Get all the users that are older than 35 years old\"\n",
    "model = \"text-davinci-002\"\n",
    "temperature = 0.5\n",
    "max_tokens = 50\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=model,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eabbc7-36d5-4b3f-9091-f745993fdee9",
   "metadata": {},
   "source": [
    "## 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "882950ac-89e6-4348-8d9f-de229cda47a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSELECT * FROM users WHERE age > 35;'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sql_query(prompt, max_tokens = 100):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "generate_sql_query(\"Get all the users that are older than 35 years old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e732f0c-dfbf-49f3-9267-91c44665d687",
   "metadata": {},
   "source": [
    "## CLI 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19476fab-de2f-4c6b-8816-fc5c12ea7d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "SQL문 작성 프롬프트를 입력하세요:  user 테이블에서 35세이상 사용자 추출하세요\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "SELECT * FROM user WHERE age >= 35;\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"SQL문 작성 프롬프트를 입력하세요: \")  # user 테이블에서 35세이상 사용자 추출하세요\n",
    "print(generate_sql_query(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
